==========================================
SLURM_JOB_ID = 2504930
SLURM_NODELIST = gnode079
SLURM_JOB_GPUS = 3
==========================================
09/28 14:27:04 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

09/28 14:27:05 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=2, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/segmentation_benchmark/final_data_resized/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=40000,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=50,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 50
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=320000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
randomness = dict(seed=268722126)
resume = True
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/final_data_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=320000, type='IterBasedTrainLoop', val_interval=40000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/segmentation_benchmark/final_data_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/final_data_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/segmentation_benchmark/mmseg_work_dir/mask2former_swin_T_seed_320K'

09/28 14:27:10 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
09/28 14:27:10 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
09/28 14:27:10 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
09/28 14:27:10 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
09/28 14:27:11 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
Did not find last_checkpoint to be resumed.
09/28 14:27:17 - mmengine - INFO - Auto resumed from the latest checkpoint None.
09/28 14:27:17 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
09/28 14:27:17 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
09/28 14:27:17 - mmengine - INFO - Checkpoints will be saved to /scratch/segmentation_benchmark/mmseg_work_dir/mask2former_swin_T_seed_320K.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
09/28 14:27:45 - mmengine - INFO - Iter(train) [    50/320000]  base_lr: 9.9986e-05 lr: 9.9986e-06  eta: 2 days, 0:53:16  time: 0.4768  data_time: 0.0098  memory: 8941  grad_norm: 252.8129  loss: 90.7426  decode.loss_cls: 3.2086  decode.loss_mask: 2.8139  decode.loss_dice: 3.8997  decode.d0.loss_cls: 7.9745  decode.d0.loss_mask: 2.2346  decode.d0.loss_dice: 2.8426  decode.d1.loss_cls: 2.8017  decode.d1.loss_mask: 2.1602  decode.d1.loss_dice: 2.8271  decode.d2.loss_cls: 2.7774  decode.d2.loss_mask: 2.1639  decode.d2.loss_dice: 2.8510  decode.d3.loss_cls: 2.7959  decode.d3.loss_mask: 2.1891  decode.d3.loss_dice: 2.8386  decode.d4.loss_cls: 2.8486  decode.d4.loss_mask: 2.2498  decode.d4.loss_dice: 2.9043  decode.d5.loss_cls: 2.9103  decode.d5.loss_mask: 2.4024  decode.d5.loss_dice: 3.0191  decode.d6.loss_cls: 3.0879  decode.d6.loss_mask: 2.6565  decode.d6.loss_dice: 3.1230  decode.d7.loss_cls: 3.1551  decode.d7.loss_mask: 2.7917  decode.d7.loss_dice: 3.4217  decode.d8.loss_cls: 3.2000  decode.d8.loss_mask: 2.7923  decode.d8.loss_dice: 3.8011
09/28 14:28:09 - mmengine - INFO - Iter(train) [   100/320000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 1 day, 21:41:34  time: 0.4787  data_time: 0.0098  memory: 5819  grad_norm: 417.6185  loss: 74.4476  decode.loss_cls: 2.7766  decode.loss_mask: 2.0953  decode.loss_dice: 2.5769  decode.d0.loss_cls: 7.8216  decode.d0.loss_mask: 1.9111  decode.d0.loss_dice: 2.4589  decode.d1.loss_cls: 2.6126  decode.d1.loss_mask: 1.9380  decode.d1.loss_dice: 2.2348  decode.d2.loss_cls: 2.4698  decode.d2.loss_mask: 1.9282  decode.d2.loss_dice: 2.2331  decode.d3.loss_cls: 2.4200  decode.d3.loss_mask: 1.9667  decode.d3.loss_dice: 2.2406  decode.d4.loss_cls: 2.5046  decode.d4.loss_mask: 2.0279  decode.d4.loss_dice: 2.2555  decode.d5.loss_cls: 2.7130  decode.d5.loss_mask: 1.9554  decode.d5.loss_dice: 2.2217  decode.d6.loss_cls: 2.6838  decode.d6.loss_mask: 2.0230  decode.d6.loss_dice: 2.2695  decode.d7.loss_cls: 2.6724  decode.d7.loss_mask: 2.0480  decode.d7.loss_dice: 2.3277  decode.d8.loss_cls: 2.6345  decode.d8.loss_mask: 2.0587  decode.d8.loss_dice: 2.3677
09/28 14:28:33 - mmengine - INFO - Iter(train) [   150/320000]  base_lr: 9.9958e-05 lr: 9.9958e-06  eta: 1 day, 20:44:51  time: 0.4795  data_time: 0.0100  memory: 5817  grad_norm: 481.6248  loss: 57.3714  decode.loss_cls: 2.3962  decode.loss_mask: 1.3684  decode.loss_dice: 1.6908  decode.d0.loss_cls: 7.7858  decode.d0.loss_mask: 1.2885  decode.d0.loss_dice: 1.8184  decode.d1.loss_cls: 2.3993  decode.d1.loss_mask: 1.2546  decode.d1.loss_dice: 1.5725  decode.d2.loss_cls: 2.2739  decode.d2.loss_mask: 1.1933  decode.d2.loss_dice: 1.5302  decode.d3.loss_cls: 2.1716  decode.d3.loss_mask: 1.1997  decode.d3.loss_dice: 1.5589  decode.d4.loss_cls: 2.3006  decode.d4.loss_mask: 1.2283  decode.d4.loss_dice: 1.5613  decode.d5.loss_cls: 2.2825  decode.d5.loss_mask: 1.2344  decode.d5.loss_dice: 1.5195  decode.d6.loss_cls: 2.3267  decode.d6.loss_mask: 1.2735  decode.d6.loss_dice: 1.5693  decode.d7.loss_cls: 2.3250  decode.d7.loss_mask: 1.2830  decode.d7.loss_dice: 1.5801  decode.d8.loss_cls: 2.3591  decode.d8.loss_mask: 1.3501  decode.d8.loss_dice: 1.6758
09/28 14:28:57 - mmengine - INFO - Iter(train) [   200/320000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 1 day, 20:13:01  time: 0.4801  data_time: 0.0099  memory: 5819  grad_norm: 408.5780  loss: 49.2865  decode.loss_cls: 2.3556  decode.loss_mask: 1.0441  decode.loss_dice: 1.1258  decode.d0.loss_cls: 7.6401  decode.d0.loss_mask: 0.9849  decode.d0.loss_dice: 1.3252  decode.d1.loss_cls: 2.3077  decode.d1.loss_mask: 0.9099  decode.d1.loss_dice: 1.1262  decode.d2.loss_cls: 2.2604  decode.d2.loss_mask: 0.9227  decode.d2.loss_dice: 1.1000  decode.d3.loss_cls: 2.2996  decode.d3.loss_mask: 0.8757  decode.d3.loss_dice: 1.0448  decode.d4.loss_cls: 2.2997  decode.d4.loss_mask: 0.9216  decode.d4.loss_dice: 1.0767  decode.d5.loss_cls: 2.2760  decode.d5.loss_mask: 0.9640  decode.d5.loss_dice: 1.0627  decode.d6.loss_cls: 2.3463  decode.d6.loss_mask: 0.9594  decode.d6.loss_dice: 1.0861  decode.d7.loss_cls: 2.3818  decode.d7.loss_mask: 0.9880  decode.d7.loss_dice: 1.1021  decode.d8.loss_cls: 2.3996  decode.d8.loss_mask: 0.9947  decode.d8.loss_dice: 1.1050
09/28 14:29:21 - mmengine - INFO - Iter(train) [   250/320000]  base_lr: 9.9930e-05 lr: 9.9930e-06  eta: 1 day, 19:59:24  time: 0.4950  data_time: 0.0103  memory: 5817  grad_norm: 527.9736  loss: 45.4591  decode.loss_cls: 2.3344  decode.loss_mask: 0.9243  decode.loss_dice: 1.0715  decode.d0.loss_cls: 7.5208  decode.d0.loss_mask: 0.9414  decode.d0.loss_dice: 1.1181  decode.d1.loss_cls: 2.1879  decode.d1.loss_mask: 0.8590  decode.d1.loss_dice: 0.9435  decode.d2.loss_cls: 2.0763  decode.d2.loss_mask: 0.8735  decode.d2.loss_dice: 0.8960  decode.d3.loss_cls: 2.0532  decode.d3.loss_mask: 0.8958  decode.d3.loss_dice: 0.8964  decode.d4.loss_cls: 2.1785  decode.d4.loss_mask: 0.8891  decode.d4.loss_dice: 0.9727  decode.d5.loss_cls: 2.1251  decode.d5.loss_mask: 0.8510  decode.d5.loss_dice: 0.9218  decode.d6.loss_cls: 2.0623  decode.d6.loss_mask: 0.9474  decode.d6.loss_dice: 0.9530  decode.d7.loss_cls: 2.1049  decode.d7.loss_mask: 0.9050  decode.d7.loss_dice: 0.8641  decode.d8.loss_cls: 2.2007  decode.d8.loss_mask: 0.9591  decode.d8.loss_dice: 0.9322
09/28 14:29:45 - mmengine - INFO - Iter(train) [   300/320000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 1 day, 19:51:10  time: 0.4833  data_time: 0.0098  memory: 5834  grad_norm: 449.0940  loss: 49.1081  decode.loss_cls: 2.2453  decode.loss_mask: 1.1232  decode.loss_dice: 1.0972  decode.d0.loss_cls: 7.3661  decode.d0.loss_mask: 1.2237  decode.d0.loss_dice: 1.4715  decode.d1.loss_cls: 2.3288  decode.d1.loss_mask: 1.0533  decode.d1.loss_dice: 1.1311  decode.d2.loss_cls: 2.2104  decode.d2.loss_mask: 0.9918  decode.d2.loss_dice: 1.1068  decode.d3.loss_cls: 2.1474  decode.d3.loss_mask: 1.0130  decode.d3.loss_dice: 1.0532  decode.d4.loss_cls: 2.1491  decode.d4.loss_mask: 1.0542  decode.d4.loss_dice: 1.1228  decode.d5.loss_cls: 2.1101  decode.d5.loss_mask: 1.0817  decode.d5.loss_dice: 1.0768  decode.d6.loss_cls: 2.0733  decode.d6.loss_mask: 1.1472  decode.d6.loss_dice: 1.0959  decode.d7.loss_cls: 2.1404  decode.d7.loss_mask: 1.1280  decode.d7.loss_dice: 1.0914  decode.d8.loss_cls: 2.2303  decode.d8.loss_mask: 1.0138  decode.d8.loss_dice: 1.0303
09/28 14:30:09 - mmengine - INFO - Iter(train) [   350/320000]  base_lr: 9.9902e-05 lr: 9.9902e-06  eta: 1 day, 19:41:51  time: 0.4827  data_time: 0.0098  memory: 5817  grad_norm: 426.1529  loss: 38.8098  decode.loss_cls: 2.0243  decode.loss_mask: 0.6726  decode.loss_dice: 0.7371  decode.d0.loss_cls: 7.2024  decode.d0.loss_mask: 0.6900  decode.d0.loss_dice: 0.8715  decode.d1.loss_cls: 2.0496  decode.d1.loss_mask: 0.7173  decode.d1.loss_dice: 0.6546  decode.d2.loss_cls: 1.9069  decode.d2.loss_mask: 0.6158  decode.d2.loss_dice: 0.6148  decode.d3.loss_cls: 1.9573  decode.d3.loss_mask: 0.6082  decode.d3.loss_dice: 0.6270  decode.d4.loss_cls: 2.0792  decode.d4.loss_mask: 0.6198  decode.d4.loss_dice: 0.6286  decode.d5.loss_cls: 2.0028  decode.d5.loss_mask: 0.6397  decode.d5.loss_dice: 0.6408  decode.d6.loss_cls: 1.9982  decode.d6.loss_mask: 0.6291  decode.d6.loss_dice: 0.6657  decode.d7.loss_cls: 2.0710  decode.d7.loss_mask: 0.6632  decode.d7.loss_dice: 0.7169  decode.d8.loss_cls: 2.0646  decode.d8.loss_mask: 0.6868  decode.d8.loss_dice: 0.7541
09/28 14:30:34 - mmengine - INFO - Iter(train) [   400/320000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 1 day, 19:34:54  time: 0.4823  data_time: 0.0101  memory: 5834  grad_norm: 356.9551  loss: 35.3350  decode.loss_cls: 1.8337  decode.loss_mask: 0.6805  decode.loss_dice: 0.5408  decode.d0.loss_cls: 7.0117  decode.d0.loss_mask: 0.7231  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 1.6766  decode.d1.loss_mask: 0.6991  decode.d1.loss_dice: 0.5924  decode.d2.loss_cls: 1.6158  decode.d2.loss_mask: 0.6345  decode.d2.loss_dice: 0.5356  decode.d3.loss_cls: 1.6759  decode.d3.loss_mask: 0.6548  decode.d3.loss_dice: 0.5643  decode.d4.loss_cls: 1.6899  decode.d4.loss_mask: 0.7041  decode.d4.loss_dice: 0.5888  decode.d5.loss_cls: 1.7237  decode.d5.loss_mask: 0.6591  decode.d5.loss_dice: 0.5606  decode.d6.loss_cls: 1.7409  decode.d6.loss_mask: 0.7054  decode.d6.loss_dice: 0.5802  decode.d7.loss_cls: 1.7832  decode.d7.loss_mask: 0.7069  decode.d7.loss_dice: 0.5807  decode.d8.loss_cls: 1.7957  decode.d8.loss_mask: 0.7613  decode.d8.loss_dice: 0.5632
09/28 14:30:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 14:30:58 - mmengine - INFO - Iter(train) [   450/320000]  base_lr: 9.9874e-05 lr: 9.9874e-06  eta: 1 day, 19:31:46  time: 0.4828  data_time: 0.0101  memory: 5799  grad_norm: 575.9790  loss: 39.0992  decode.loss_cls: 1.8772  decode.loss_mask: 0.8031  decode.loss_dice: 0.7585  decode.d0.loss_cls: 6.9436  decode.d0.loss_mask: 0.9319  decode.d0.loss_dice: 1.0205  decode.d1.loss_cls: 1.7739  decode.d1.loss_mask: 0.8703  decode.d1.loss_dice: 0.8080  decode.d2.loss_cls: 1.7035  decode.d2.loss_mask: 0.7859  decode.d2.loss_dice: 0.7521  decode.d3.loss_cls: 1.6422  decode.d3.loss_mask: 0.8003  decode.d3.loss_dice: 0.7760  decode.d4.loss_cls: 1.6711  decode.d4.loss_mask: 0.8168  decode.d4.loss_dice: 0.7731  decode.d5.loss_cls: 1.7972  decode.d5.loss_mask: 0.8231  decode.d5.loss_dice: 0.7847  decode.d6.loss_cls: 1.8509  decode.d6.loss_mask: 0.8062  decode.d6.loss_dice: 0.7607  decode.d7.loss_cls: 1.8741  decode.d7.loss_mask: 0.7738  decode.d7.loss_dice: 0.7382  decode.d8.loss_cls: 1.8882  decode.d8.loss_mask: 0.7648  decode.d8.loss_dice: 0.7294
09/28 14:31:22 - mmengine - INFO - Iter(train) [   500/320000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 1 day, 19:27:26  time: 0.4828  data_time: 0.0100  memory: 5817  grad_norm: 519.5199  loss: 37.6845  decode.loss_cls: 1.9113  decode.loss_mask: 0.7381  decode.loss_dice: 0.6408  decode.d0.loss_cls: 6.7601  decode.d0.loss_mask: 0.8186  decode.d0.loss_dice: 0.8525  decode.d1.loss_cls: 1.7071  decode.d1.loss_mask: 0.7908  decode.d1.loss_dice: 0.7207  decode.d2.loss_cls: 1.7238  decode.d2.loss_mask: 0.7817  decode.d2.loss_dice: 0.6722  decode.d3.loss_cls: 1.7752  decode.d3.loss_mask: 0.7732  decode.d3.loss_dice: 0.6250  decode.d4.loss_cls: 1.8810  decode.d4.loss_mask: 0.7646  decode.d4.loss_dice: 0.6217  decode.d5.loss_cls: 1.8649  decode.d5.loss_mask: 0.7952  decode.d5.loss_dice: 0.6477  decode.d6.loss_cls: 1.8834  decode.d6.loss_mask: 0.8062  decode.d6.loss_dice: 0.6329  decode.d7.loss_cls: 1.9065  decode.d7.loss_mask: 0.7575  decode.d7.loss_dice: 0.6188  decode.d8.loss_cls: 1.9144  decode.d8.loss_mask: 0.7055  decode.d8.loss_dice: 0.5932
09/28 14:31:46 - mmengine - INFO - Iter(train) [   550/320000]  base_lr: 9.9846e-05 lr: 9.9846e-06  eta: 1 day, 19:23:45  time: 0.4819  data_time: 0.0095  memory: 5817  grad_norm: 165.4960  loss: 31.5718  decode.loss_cls: 1.7532  decode.loss_mask: 0.4232  decode.loss_dice: 0.4715  decode.d0.loss_cls: 6.5605  decode.d0.loss_mask: 0.4492  decode.d0.loss_dice: 0.6136  decode.d1.loss_cls: 1.6727  decode.d1.loss_mask: 0.4986  decode.d1.loss_dice: 0.5336  decode.d2.loss_cls: 1.6985  decode.d2.loss_mask: 0.4170  decode.d2.loss_dice: 0.4954  decode.d3.loss_cls: 1.7529  decode.d3.loss_mask: 0.4622  decode.d3.loss_dice: 0.4803  decode.d4.loss_cls: 1.7486  decode.d4.loss_mask: 0.4388  decode.d4.loss_dice: 0.4651  decode.d5.loss_cls: 1.8025  decode.d5.loss_mask: 0.4352  decode.d5.loss_dice: 0.5079  decode.d6.loss_cls: 1.7030  decode.d6.loss_mask: 0.4356  decode.d6.loss_dice: 0.4838  decode.d7.loss_cls: 1.7103  decode.d7.loss_mask: 0.4222  decode.d7.loss_dice: 0.4862  decode.d8.loss_cls: 1.7258  decode.d8.loss_mask: 0.4431  decode.d8.loss_dice: 0.4813
09/28 14:32:10 - mmengine - INFO - Iter(train) [   600/320000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 1 day, 19:20:45  time: 0.4840  data_time: 0.0102  memory: 5817  grad_norm: 320.7487  loss: 32.6039  decode.loss_cls: 1.6622  decode.loss_mask: 0.6391  decode.loss_dice: 0.5575  decode.d0.loss_cls: 6.3283  decode.d0.loss_mask: 0.6536  decode.d0.loss_dice: 0.6088  decode.d1.loss_cls: 1.5626  decode.d1.loss_mask: 0.6780  decode.d1.loss_dice: 0.5274  decode.d2.loss_cls: 1.5350  decode.d2.loss_mask: 0.6193  decode.d2.loss_dice: 0.5253  decode.d3.loss_cls: 1.5846  decode.d3.loss_mask: 0.5813  decode.d3.loss_dice: 0.5120  decode.d4.loss_cls: 1.7061  decode.d4.loss_mask: 0.5559  decode.d4.loss_dice: 0.4923  decode.d5.loss_cls: 1.7298  decode.d5.loss_mask: 0.5620  decode.d5.loss_dice: 0.5014  decode.d6.loss_cls: 1.6743  decode.d6.loss_mask: 0.6233  decode.d6.loss_dice: 0.5215  decode.d7.loss_cls: 1.6226  decode.d7.loss_mask: 0.6513  decode.d7.loss_dice: 0.5354  decode.d8.loss_cls: 1.6533  decode.d8.loss_mask: 0.6305  decode.d8.loss_dice: 0.5693
09/28 14:32:34 - mmengine - INFO - Iter(train) [   650/320000]  base_lr: 9.9817e-05 lr: 9.9817e-06  eta: 1 day, 19:18:07  time: 0.4831  data_time: 0.0099  memory: 5834  grad_norm: 407.6663  loss: 28.5199  decode.loss_cls: 1.4232  decode.loss_mask: 0.5400  decode.loss_dice: 0.3948  decode.d0.loss_cls: 6.1987  decode.d0.loss_mask: 0.5240  decode.d0.loss_dice: 0.5461  decode.d1.loss_cls: 1.3479  decode.d1.loss_mask: 0.5299  decode.d1.loss_dice: 0.4763  decode.d2.loss_cls: 1.4048  decode.d2.loss_mask: 0.5207  decode.d2.loss_dice: 0.4333  decode.d3.loss_cls: 1.4184  decode.d3.loss_mask: 0.4845  decode.d3.loss_dice: 0.3761  decode.d4.loss_cls: 1.4597  decode.d4.loss_mask: 0.5152  decode.d4.loss_dice: 0.4237  decode.d5.loss_cls: 1.5178  decode.d5.loss_mask: 0.5315  decode.d5.loss_dice: 0.4153  decode.d6.loss_cls: 1.4418  decode.d6.loss_mask: 0.4924  decode.d6.loss_dice: 0.4012  decode.d7.loss_cls: 1.4100  decode.d7.loss_mask: 0.5174  decode.d7.loss_dice: 0.4181  decode.d8.loss_cls: 1.4359  decode.d8.loss_mask: 0.5250  decode.d8.loss_dice: 0.3965
09/28 14:32:59 - mmengine - INFO - Iter(train) [   700/320000]  base_lr: 9.9803e-05 lr: 9.9803e-06  eta: 1 day, 19:15:45  time: 0.4837  data_time: 0.0099  memory: 5835  grad_norm: 635.3763  loss: 32.0674  decode.loss_cls: 1.5752  decode.loss_mask: 0.6319  decode.loss_dice: 0.5323  decode.d0.loss_cls: 5.9679  decode.d0.loss_mask: 0.6613  decode.d0.loss_dice: 0.6464  decode.d1.loss_cls: 1.4591  decode.d1.loss_mask: 0.6820  decode.d1.loss_dice: 0.5133  decode.d2.loss_cls: 1.4561  decode.d2.loss_mask: 0.6969  decode.d2.loss_dice: 0.5695  decode.d3.loss_cls: 1.5224  decode.d3.loss_mask: 0.6754  decode.d3.loss_dice: 0.5244  decode.d4.loss_cls: 1.5679  decode.d4.loss_mask: 0.6957  decode.d4.loss_dice: 0.5796  decode.d5.loss_cls: 1.5625  decode.d5.loss_mask: 0.7054  decode.d5.loss_dice: 0.5276  decode.d6.loss_cls: 1.5675  decode.d6.loss_mask: 0.6934  decode.d6.loss_dice: 0.5311  decode.d7.loss_cls: 1.5570  decode.d7.loss_mask: 0.6640  decode.d7.loss_dice: 0.5359  decode.d8.loss_cls: 1.5743  decode.d8.loss_mask: 0.6476  decode.d8.loss_dice: 0.5439
09/28 14:33:23 - mmengine - INFO - Iter(train) [   750/320000]  base_lr: 9.9789e-05 lr: 9.9789e-06  eta: 1 day, 19:13:35  time: 0.4826  data_time: 0.0098  memory: 5834  grad_norm: 214.5758  loss: 25.5746  decode.loss_cls: 1.2389  decode.loss_mask: 0.4114  decode.loss_dice: 0.4124  decode.d0.loss_cls: 5.8109  decode.d0.loss_mask: 0.4473  decode.d0.loss_dice: 0.5227  decode.d1.loss_cls: 1.3051  decode.d1.loss_mask: 0.4079  decode.d1.loss_dice: 0.4419  decode.d2.loss_cls: 1.1666  decode.d2.loss_mask: 0.4201  decode.d2.loss_dice: 0.4105  decode.d3.loss_cls: 1.2252  decode.d3.loss_mask: 0.3820  decode.d3.loss_dice: 0.4314  decode.d4.loss_cls: 1.2595  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.4106  decode.d5.loss_cls: 1.2964  decode.d5.loss_mask: 0.3940  decode.d5.loss_dice: 0.4184  decode.d6.loss_cls: 1.2845  decode.d6.loss_mask: 0.3970  decode.d6.loss_dice: 0.3968  decode.d7.loss_cls: 1.3474  decode.d7.loss_mask: 0.3938  decode.d7.loss_dice: 0.4135  decode.d8.loss_cls: 1.3551  decode.d8.loss_mask: 0.3731  decode.d8.loss_dice: 0.4161
09/28 14:33:47 - mmengine - INFO - Iter(train) [   800/320000]  base_lr: 9.9775e-05 lr: 9.9775e-06  eta: 1 day, 19:11:51  time: 0.4833  data_time: 0.0101  memory: 5799  grad_norm: 618.1752  loss: 29.9134  decode.loss_cls: 1.1185  decode.loss_mask: 0.7271  decode.loss_dice: 0.7155  decode.d0.loss_cls: 5.4744  decode.d0.loss_mask: 0.6907  decode.d0.loss_dice: 0.7270  decode.d1.loss_cls: 1.2329  decode.d1.loss_mask: 0.6823  decode.d1.loss_dice: 0.6398  decode.d2.loss_cls: 1.3329  decode.d2.loss_mask: 0.6633  decode.d2.loss_dice: 0.6716  decode.d3.loss_cls: 1.2282  decode.d3.loss_mask: 0.6779  decode.d3.loss_dice: 0.6515  decode.d4.loss_cls: 1.1952  decode.d4.loss_mask: 0.6666  decode.d4.loss_dice: 0.6127  decode.d5.loss_cls: 1.1667  decode.d5.loss_mask: 0.7037  decode.d5.loss_dice: 0.6286  decode.d6.loss_cls: 1.1017  decode.d6.loss_mask: 0.6962  decode.d6.loss_dice: 0.6825  decode.d7.loss_cls: 1.1779  decode.d7.loss_mask: 0.7649  decode.d7.loss_dice: 0.7290  decode.d8.loss_cls: 1.1417  decode.d8.loss_mask: 0.7371  decode.d8.loss_dice: 0.6752
09/28 14:34:11 - mmengine - INFO - Iter(train) [   850/320000]  base_lr: 9.9761e-05 lr: 9.9761e-06  eta: 1 day, 19:10:18  time: 0.4830  data_time: 0.0101  memory: 5817  grad_norm: 256.5893  loss: 24.7027  decode.loss_cls: 1.2611  decode.loss_mask: 0.4494  decode.loss_dice: 0.4431  decode.d0.loss_cls: 5.5554  decode.d0.loss_mask: 0.3908  decode.d0.loss_dice: 0.4749  decode.d1.loss_cls: 1.1597  decode.d1.loss_mask: 0.3720  decode.d1.loss_dice: 0.3893  decode.d2.loss_cls: 1.2015  decode.d2.loss_mask: 0.4108  decode.d2.loss_dice: 0.3968  decode.d3.loss_cls: 1.2252  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.3781  decode.d4.loss_cls: 1.3439  decode.d4.loss_mask: 0.4069  decode.d4.loss_dice: 0.3585  decode.d5.loss_cls: 1.2932  decode.d5.loss_mask: 0.4404  decode.d5.loss_dice: 0.4059  decode.d6.loss_cls: 1.2223  decode.d6.loss_mask: 0.3675  decode.d6.loss_dice: 0.4045  decode.d7.loss_cls: 1.2315  decode.d7.loss_mask: 0.3326  decode.d7.loss_dice: 0.3840  decode.d8.loss_cls: 1.2648  decode.d8.loss_mask: 0.3855  decode.d8.loss_dice: 0.4001
09/28 14:34:35 - mmengine - INFO - Iter(train) [   900/320000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 1 day, 19:08:53  time: 0.4835  data_time: 0.0101  memory: 5819  grad_norm: 677.1439  loss: 30.1499  decode.loss_cls: 1.2773  decode.loss_mask: 0.9675  decode.loss_dice: 0.6176  decode.d0.loss_cls: 5.2373  decode.d0.loss_mask: 0.7489  decode.d0.loss_dice: 0.6318  decode.d1.loss_cls: 1.2034  decode.d1.loss_mask: 0.6683  decode.d1.loss_dice: 0.5596  decode.d2.loss_cls: 1.1521  decode.d2.loss_mask: 0.7306  decode.d2.loss_dice: 0.6148  decode.d3.loss_cls: 1.1856  decode.d3.loss_mask: 0.7737  decode.d3.loss_dice: 0.5806  decode.d4.loss_cls: 1.2607  decode.d4.loss_mask: 0.6539  decode.d4.loss_dice: 0.5821  decode.d5.loss_cls: 1.2866  decode.d5.loss_mask: 0.7125  decode.d5.loss_dice: 0.6125  decode.d6.loss_cls: 1.2183  decode.d6.loss_mask: 0.8169  decode.d6.loss_dice: 0.6398  decode.d7.loss_cls: 1.2243  decode.d7.loss_mask: 0.8443  decode.d7.loss_dice: 0.5955  decode.d8.loss_cls: 1.2582  decode.d8.loss_mask: 0.8514  decode.d8.loss_dice: 0.6440
09/28 14:34:59 - mmengine - INFO - Iter(train) [   950/320000]  base_lr: 9.9733e-05 lr: 9.9733e-06  eta: 1 day, 19:07:37  time: 0.4837  data_time: 0.0099  memory: 5817  grad_norm: 318.4956  loss: 25.1450  decode.loss_cls: 1.2575  decode.loss_mask: 0.4573  decode.loss_dice: 0.4716  decode.d0.loss_cls: 4.9739  decode.d0.loss_mask: 0.4705  decode.d0.loss_dice: 0.4884  decode.d1.loss_cls: 1.1800  decode.d1.loss_mask: 0.4303  decode.d1.loss_dice: 0.4696  decode.d2.loss_cls: 1.1697  decode.d2.loss_mask: 0.4183  decode.d2.loss_dice: 0.4310  decode.d3.loss_cls: 1.1872  decode.d3.loss_mask: 0.4388  decode.d3.loss_dice: 0.4380  decode.d4.loss_cls: 1.2304  decode.d4.loss_mask: 0.4436  decode.d4.loss_dice: 0.4385  decode.d5.loss_cls: 1.2423  decode.d5.loss_mask: 0.4604  decode.d5.loss_dice: 0.4628  decode.d6.loss_cls: 1.2778  decode.d6.loss_mask: 0.4756  decode.d6.loss_dice: 0.5041  decode.d7.loss_cls: 1.2989  decode.d7.loss_mask: 0.4558  decode.d7.loss_dice: 0.4535  decode.d8.loss_cls: 1.2498  decode.d8.loss_mask: 0.4282  decode.d8.loss_dice: 0.4414
09/28 14:35:24 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 14:35:24 - mmengine - INFO - Iter(train) [  1000/320000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 1 day, 19:06:27  time: 0.4843  data_time: 0.0102  memory: 5819  grad_norm: 445.0620  loss: 27.6547  decode.loss_cls: 1.4914  decode.loss_mask: 0.4780  decode.loss_dice: 0.4302  decode.d0.loss_cls: 5.0024  decode.d0.loss_mask: 0.5631  decode.d0.loss_dice: 0.6347  decode.d1.loss_cls: 1.4564  decode.d1.loss_mask: 0.5176  decode.d1.loss_dice: 0.4667  decode.d2.loss_cls: 1.4463  decode.d2.loss_mask: 0.4155  decode.d2.loss_dice: 0.4281  decode.d3.loss_cls: 1.4056  decode.d3.loss_mask: 0.4738  decode.d3.loss_dice: 0.4559  decode.d4.loss_cls: 1.4103  decode.d4.loss_mask: 0.4654  decode.d4.loss_dice: 0.4621  decode.d5.loss_cls: 1.4980  decode.d5.loss_mask: 0.4257  decode.d5.loss_dice: 0.4432  decode.d6.loss_cls: 1.4954  decode.d6.loss_mask: 0.5183  decode.d6.loss_dice: 0.4466  decode.d7.loss_cls: 1.4939  decode.d7.loss_mask: 0.4970  decode.d7.loss_dice: 0.4472  decode.d8.loss_cls: 1.4819  decode.d8.loss_mask: 0.4818  decode.d8.loss_dice: 0.4221
09/28 14:35:48 - mmengine - INFO - Iter(train) [  1050/320000]  base_lr: 9.9705e-05 lr: 9.9705e-06  eta: 1 day, 19:05:45  time: 0.4826  data_time: 0.0098  memory: 5816  grad_norm: 741.4042  loss: 25.7204  decode.loss_cls: 1.0978  decode.loss_mask: 0.6016  decode.loss_dice: 0.4269  decode.d0.loss_cls: 4.7130  decode.d0.loss_mask: 0.6595  decode.d0.loss_dice: 0.5014  decode.d1.loss_cls: 1.2830  decode.d1.loss_mask: 0.6175  decode.d1.loss_dice: 0.4595  decode.d2.loss_cls: 1.1174  decode.d2.loss_mask: 0.6845  decode.d2.loss_dice: 0.4914  decode.d3.loss_cls: 1.1385  decode.d3.loss_mask: 0.6666  decode.d3.loss_dice: 0.4909  decode.d4.loss_cls: 1.2403  decode.d4.loss_mask: 0.6306  decode.d4.loss_dice: 0.4285  decode.d5.loss_cls: 1.1908  decode.d5.loss_mask: 0.6006  decode.d5.loss_dice: 0.3837  decode.d6.loss_cls: 1.1514  decode.d6.loss_mask: 0.5877  decode.d6.loss_dice: 0.3969  decode.d7.loss_cls: 1.0833  decode.d7.loss_mask: 0.5751  decode.d7.loss_dice: 0.3977  decode.d8.loss_cls: 1.0922  decode.d8.loss_mask: 0.5911  decode.d8.loss_dice: 0.4211
09/28 14:36:12 - mmengine - INFO - Iter(train) [  1100/320000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 1 day, 19:04:29  time: 0.4839  data_time: 0.0102  memory: 5816  grad_norm: 225.0989  loss: 21.8759  decode.loss_cls: 1.0483  decode.loss_mask: 0.5047  decode.loss_dice: 0.3139  decode.d0.loss_cls: 4.4232  decode.d0.loss_mask: 0.4654  decode.d0.loss_dice: 0.3160  decode.d1.loss_cls: 1.0938  decode.d1.loss_mask: 0.4685  decode.d1.loss_dice: 0.3042  decode.d2.loss_cls: 1.0237  decode.d2.loss_mask: 0.5035  decode.d2.loss_dice: 0.3189  decode.d3.loss_cls: 1.1175  decode.d3.loss_mask: 0.4771  decode.d3.loss_dice: 0.2883  decode.d4.loss_cls: 1.0554  decode.d4.loss_mask: 0.4966  decode.d4.loss_dice: 0.3008  decode.d5.loss_cls: 1.0434  decode.d5.loss_mask: 0.5025  decode.d5.loss_dice: 0.3505  decode.d6.loss_cls: 1.0108  decode.d6.loss_mask: 0.5023  decode.d6.loss_dice: 0.3175  decode.d7.loss_cls: 1.0347  decode.d7.loss_mask: 0.4757  decode.d7.loss_dice: 0.2968  decode.d8.loss_cls: 1.0418  decode.d8.loss_mask: 0.4754  decode.d8.loss_dice: 0.3048
09/28 14:36:36 - mmengine - INFO - Iter(train) [  1150/320000]  base_lr: 9.9677e-05 lr: 9.9677e-06  eta: 1 day, 19:03:25  time: 0.4832  data_time: 0.0098  memory: 5834  grad_norm: 352.4362  loss: 25.6624  decode.loss_cls: 1.2897  decode.loss_mask: 0.5576  decode.loss_dice: 0.4482  decode.d0.loss_cls: 4.2182  decode.d0.loss_mask: 0.6409  decode.d0.loss_dice: 0.5642  decode.d1.loss_cls: 1.3729  decode.d1.loss_mask: 0.5432  decode.d1.loss_dice: 0.4389  decode.d2.loss_cls: 1.3388  decode.d2.loss_mask: 0.5390  decode.d2.loss_dice: 0.4694  decode.d3.loss_cls: 1.2920  decode.d3.loss_mask: 0.5194  decode.d3.loss_dice: 0.4457  decode.d4.loss_cls: 1.1222  decode.d4.loss_mask: 0.5518  decode.d4.loss_dice: 0.4278  decode.d5.loss_cls: 1.2925  decode.d5.loss_mask: 0.5359  decode.d5.loss_dice: 0.4115  decode.d6.loss_cls: 1.1889  decode.d6.loss_mask: 0.5570  decode.d6.loss_dice: 0.4287  decode.d7.loss_cls: 1.1937  decode.d7.loss_mask: 0.5765  decode.d7.loss_dice: 0.4526  decode.d8.loss_cls: 1.2214  decode.d8.loss_mask: 0.5694  decode.d8.loss_dice: 0.4547
09/28 14:37:00 - mmengine - INFO - Iter(train) [  1200/320000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 1 day, 19:02:19  time: 0.4824  data_time: 0.0098  memory: 5819  grad_norm: 297.9267  loss: 23.4529  decode.loss_cls: 1.2082  decode.loss_mask: 0.4409  decode.loss_dice: 0.4174  decode.d0.loss_cls: 4.1205  decode.d0.loss_mask: 0.4872  decode.d0.loss_dice: 0.4710  decode.d1.loss_cls: 1.1236  decode.d1.loss_mask: 0.4803  decode.d1.loss_dice: 0.4390  decode.d2.loss_cls: 1.2049  decode.d2.loss_mask: 0.4351  decode.d2.loss_dice: 0.3983  decode.d3.loss_cls: 1.1274  decode.d3.loss_mask: 0.4139  decode.d3.loss_dice: 0.4262  decode.d4.loss_cls: 1.1794  decode.d4.loss_mask: 0.4145  decode.d4.loss_dice: 0.4097  decode.d5.loss_cls: 1.2105  decode.d5.loss_mask: 0.4286  decode.d5.loss_dice: 0.4165  decode.d6.loss_cls: 1.1387  decode.d6.loss_mask: 0.4589  decode.d6.loss_dice: 0.4392  decode.d7.loss_cls: 1.2257  decode.d7.loss_mask: 0.4468  decode.d7.loss_dice: 0.4226  decode.d8.loss_cls: 1.2323  decode.d8.loss_mask: 0.4326  decode.d8.loss_dice: 0.4029
09/28 14:37:25 - mmengine - INFO - Iter(train) [  1250/320000]  base_lr: 9.9649e-05 lr: 9.9649e-06  eta: 1 day, 19:01:18  time: 0.4831  data_time: 0.0098  memory: 5817  grad_norm: 576.9076  loss: 21.5784  decode.loss_cls: 1.1352  decode.loss_mask: 0.4827  decode.loss_dice: 0.3713  decode.d0.loss_cls: 3.8173  decode.d0.loss_mask: 0.4628  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.9144  decode.d1.loss_mask: 0.4919  decode.d1.loss_dice: 0.3744  decode.d2.loss_cls: 0.8927  decode.d2.loss_mask: 0.4728  decode.d2.loss_dice: 0.3279  decode.d3.loss_cls: 1.0464  decode.d3.loss_mask: 0.4752  decode.d3.loss_dice: 0.3243  decode.d4.loss_cls: 1.0919  decode.d4.loss_mask: 0.4876  decode.d4.loss_dice: 0.3535  decode.d5.loss_cls: 1.0867  decode.d5.loss_mask: 0.4931  decode.d5.loss_dice: 0.3390  decode.d6.loss_cls: 1.0521  decode.d6.loss_mask: 0.5229  decode.d6.loss_dice: 0.3430  decode.d7.loss_cls: 1.0481  decode.d7.loss_mask: 0.5404  decode.d7.loss_dice: 0.4011  decode.d8.loss_cls: 1.0411  decode.d8.loss_mask: 0.4940  decode.d8.loss_dice: 0.3580
09/28 14:37:49 - mmengine - INFO - Iter(train) [  1300/320000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 1 day, 19:00:23  time: 0.4838  data_time: 0.0101  memory: 5835  grad_norm: 321.9634  loss: 20.3238  decode.loss_cls: 1.0029  decode.loss_mask: 0.4011  decode.loss_dice: 0.3455  decode.d0.loss_cls: 3.6407  decode.d0.loss_mask: 0.3991  decode.d0.loss_dice: 0.3358  decode.d1.loss_cls: 1.0291  decode.d1.loss_mask: 0.4190  decode.d1.loss_dice: 0.3438  decode.d2.loss_cls: 0.9798  decode.d2.loss_mask: 0.4173  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.9531  decode.d3.loss_mask: 0.4182  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.9615  decode.d4.loss_mask: 0.4204  decode.d4.loss_dice: 0.3413  decode.d5.loss_cls: 0.9664  decode.d5.loss_mask: 0.4362  decode.d5.loss_dice: 0.3608  decode.d6.loss_cls: 1.0311  decode.d6.loss_mask: 0.4153  decode.d6.loss_dice: 0.3486  decode.d7.loss_cls: 1.0108  decode.d7.loss_mask: 0.4640  decode.d7.loss_dice: 0.4035  decode.d8.loss_cls: 1.0385  decode.d8.loss_mask: 0.4130  decode.d8.loss_dice: 0.3351
09/28 14:38:13 - mmengine - INFO - Iter(train) [  1350/320000]  base_lr: 9.9621e-05 lr: 9.9621e-06  eta: 1 day, 18:59:31  time: 0.4839  data_time: 0.0099  memory: 5834  grad_norm: 267.8429  loss: 22.7595  decode.loss_cls: 1.1634  decode.loss_mask: 0.4447  decode.loss_dice: 0.4694  decode.d0.loss_cls: 3.4605  decode.d0.loss_mask: 0.4391  decode.d0.loss_dice: 0.5167  decode.d1.loss_cls: 1.1075  decode.d1.loss_mask: 0.4276  decode.d1.loss_dice: 0.4404  decode.d2.loss_cls: 1.0603  decode.d2.loss_mask: 0.4618  decode.d2.loss_dice: 0.4456  decode.d3.loss_cls: 1.0637  decode.d3.loss_mask: 0.4717  decode.d3.loss_dice: 0.4762  decode.d4.loss_cls: 1.1563  decode.d4.loss_mask: 0.4314  decode.d4.loss_dice: 0.4560  decode.d5.loss_cls: 1.1494  decode.d5.loss_mask: 0.4414  decode.d5.loss_dice: 0.4685  decode.d6.loss_cls: 1.1852  decode.d6.loss_mask: 0.4395  decode.d6.loss_dice: 0.4613  decode.d7.loss_cls: 1.1612  decode.d7.loss_mask: 0.4163  decode.d7.loss_dice: 0.4496  decode.d8.loss_cls: 1.1924  decode.d8.loss_mask: 0.4278  decode.d8.loss_dice: 0.4746
09/28 14:38:37 - mmengine - INFO - Iter(train) [  1400/320000]  base_lr: 9.9606e-05 lr: 9.9606e-06  eta: 1 day, 18:58:43  time: 0.4836  data_time: 0.0100  memory: 5817  grad_norm: 207.1831  loss: 18.7883  decode.loss_cls: 0.9377  decode.loss_mask: 0.3799  decode.loss_dice: 0.3000  decode.d0.loss_cls: 3.1906  decode.d0.loss_mask: 0.4369  decode.d0.loss_dice: 0.3473  decode.d1.loss_cls: 0.9789  decode.d1.loss_mask: 0.3943  decode.d1.loss_dice: 0.3151  decode.d2.loss_cls: 0.9320  decode.d2.loss_mask: 0.3773  decode.d2.loss_dice: 0.3044  decode.d3.loss_cls: 0.9228  decode.d3.loss_mask: 0.3773  decode.d3.loss_dice: 0.3036  decode.d4.loss_cls: 0.9479  decode.d4.loss_mask: 0.4076  decode.d4.loss_dice: 0.3180  decode.d5.loss_cls: 1.0044  decode.d5.loss_mask: 0.3887  decode.d5.loss_dice: 0.3000  decode.d6.loss_cls: 0.9769  decode.d6.loss_mask: 0.3958  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 1.0037  decode.d7.loss_mask: 0.3744  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.9454  decode.d8.loss_mask: 0.3680  decode.d8.loss_dice: 0.2933
09/28 14:39:01 - mmengine - INFO - Iter(train) [  1450/320000]  base_lr: 9.9592e-05 lr: 9.9592e-06  eta: 1 day, 18:57:53  time: 0.4829  data_time: 0.0101  memory: 5816  grad_norm: 172.6530  loss: 18.8750  decode.loss_cls: 0.8980  decode.loss_mask: 0.3740  decode.loss_dice: 0.3599  decode.d0.loss_cls: 3.0730  decode.d0.loss_mask: 0.4309  decode.d0.loss_dice: 0.4320  decode.d1.loss_cls: 0.9040  decode.d1.loss_mask: 0.4393  decode.d1.loss_dice: 0.3800  decode.d2.loss_cls: 0.8134  decode.d2.loss_mask: 0.4116  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 0.9252  decode.d3.loss_mask: 0.3833  decode.d3.loss_dice: 0.3599  decode.d4.loss_cls: 0.9180  decode.d4.loss_mask: 0.3931  decode.d4.loss_dice: 0.3638  decode.d5.loss_cls: 0.9208  decode.d5.loss_mask: 0.3687  decode.d5.loss_dice: 0.3483  decode.d6.loss_cls: 0.9161  decode.d6.loss_mask: 0.3703  decode.d6.loss_dice: 0.3481  decode.d7.loss_cls: 0.9827  decode.d7.loss_mask: 0.3840  decode.d7.loss_dice: 0.3544  decode.d8.loss_cls: 0.8669  decode.d8.loss_mask: 0.3922  decode.d8.loss_dice: 0.3715
09/28 14:39:25 - mmengine - INFO - Iter(train) [  1500/320000]  base_lr: 9.9578e-05 lr: 9.9578e-06  eta: 1 day, 18:57:07  time: 0.4836  data_time: 0.0102  memory: 5834  grad_norm: 233.3019  loss: 20.9207  decode.loss_cls: 1.1094  decode.loss_mask: 0.4133  decode.loss_dice: 0.3307  decode.d0.loss_cls: 3.0489  decode.d0.loss_mask: 0.4053  decode.d0.loss_dice: 0.3670  decode.d1.loss_cls: 1.2224  decode.d1.loss_mask: 0.4783  decode.d1.loss_dice: 0.3602  decode.d2.loss_cls: 1.1299  decode.d2.loss_mask: 0.4404  decode.d2.loss_dice: 0.3356  decode.d3.loss_cls: 1.1659  decode.d3.loss_mask: 0.4148  decode.d3.loss_dice: 0.3137  decode.d4.loss_cls: 1.1356  decode.d4.loss_mask: 0.4106  decode.d4.loss_dice: 0.3328  decode.d5.loss_cls: 1.1785  decode.d5.loss_mask: 0.3881  decode.d5.loss_dice: 0.2816  decode.d6.loss_cls: 1.1705  decode.d6.loss_mask: 0.3891  decode.d6.loss_dice: 0.2915  decode.d7.loss_cls: 1.1967  decode.d7.loss_mask: 0.4084  decode.d7.loss_dice: 0.3393  decode.d8.loss_cls: 1.1541  decode.d8.loss_mask: 0.4034  decode.d8.loss_dice: 0.3046
09/28 14:39:50 - mmengine - INFO - Iter(train) [  1550/320000]  base_lr: 9.9564e-05 lr: 9.9564e-06  eta: 1 day, 18:56:22  time: 0.4829  data_time: 0.0101  memory: 5817  grad_norm: 413.9452  loss: 18.9455  decode.loss_cls: 1.0009  decode.loss_mask: 0.4168  decode.loss_dice: 0.4078  decode.d0.loss_cls: 2.8233  decode.d0.loss_mask: 0.4019  decode.d0.loss_dice: 0.3924  decode.d1.loss_cls: 0.9424  decode.d1.loss_mask: 0.4243  decode.d1.loss_dice: 0.4181  decode.d2.loss_cls: 0.7977  decode.d2.loss_mask: 0.4211  decode.d2.loss_dice: 0.3989  decode.d3.loss_cls: 0.7691  decode.d3.loss_mask: 0.4173  decode.d3.loss_dice: 0.4049  decode.d4.loss_cls: 0.8011  decode.d4.loss_mask: 0.4463  decode.d4.loss_dice: 0.4191  decode.d5.loss_cls: 0.8693  decode.d5.loss_mask: 0.4114  decode.d5.loss_dice: 0.3916  decode.d6.loss_cls: 0.8801  decode.d6.loss_mask: 0.3903  decode.d6.loss_dice: 0.3691  decode.d7.loss_cls: 0.9389  decode.d7.loss_mask: 0.4103  decode.d7.loss_dice: 0.4087  decode.d8.loss_cls: 0.9624  decode.d8.loss_mask: 0.4056  decode.d8.loss_dice: 0.4044
09/28 14:40:14 - mmengine - INFO - Iter(train) [  1600/320000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 1 day, 18:55:55  time: 0.4826  data_time: 0.0102  memory: 5834  grad_norm: 228.2852  loss: 20.7002  decode.loss_cls: 1.1621  decode.loss_mask: 0.4183  decode.loss_dice: 0.3610  decode.d0.loss_cls: 2.7535  decode.d0.loss_mask: 0.4171  decode.d0.loss_dice: 0.4435  decode.d1.loss_cls: 1.1410  decode.d1.loss_mask: 0.3922  decode.d1.loss_dice: 0.3908  decode.d2.loss_cls: 1.0697  decode.d2.loss_mask: 0.3540  decode.d2.loss_dice: 0.3437  decode.d3.loss_cls: 0.9258  decode.d3.loss_mask: 0.4292  decode.d3.loss_dice: 0.3979  decode.d4.loss_cls: 1.1253  decode.d4.loss_mask: 0.5063  decode.d4.loss_dice: 0.4257  decode.d5.loss_cls: 1.0777  decode.d5.loss_mask: 0.5013  decode.d5.loss_dice: 0.4063  decode.d6.loss_cls: 1.1132  decode.d6.loss_mask: 0.4174  decode.d6.loss_dice: 0.3720  decode.d7.loss_cls: 1.0616  decode.d7.loss_mask: 0.4425  decode.d7.loss_dice: 0.3835  decode.d8.loss_cls: 1.1519  decode.d8.loss_mask: 0.3782  decode.d8.loss_dice: 0.3375
09/28 14:40:38 - mmengine - INFO - Iter(train) [  1650/320000]  base_lr: 9.9536e-05 lr: 9.9536e-06  eta: 1 day, 18:55:05  time: 0.4821  data_time: 0.0101  memory: 5816  grad_norm: 166.7393  loss: 16.2387  decode.loss_cls: 0.8034  decode.loss_mask: 0.3725  decode.loss_dice: 0.2850  decode.d0.loss_cls: 2.5027  decode.d0.loss_mask: 0.3655  decode.d0.loss_dice: 0.3736  decode.d1.loss_cls: 0.7906  decode.d1.loss_mask: 0.4239  decode.d1.loss_dice: 0.3284  decode.d2.loss_cls: 0.7394  decode.d2.loss_mask: 0.3765  decode.d2.loss_dice: 0.2924  decode.d3.loss_cls: 0.6999  decode.d3.loss_mask: 0.3754  decode.d3.loss_dice: 0.3054  decode.d4.loss_cls: 0.7174  decode.d4.loss_mask: 0.3715  decode.d4.loss_dice: 0.3025  decode.d5.loss_cls: 0.7859  decode.d5.loss_mask: 0.3672  decode.d5.loss_dice: 0.3104  decode.d6.loss_cls: 0.8244  decode.d6.loss_mask: 0.3598  decode.d6.loss_dice: 0.2922  decode.d7.loss_cls: 0.7772  decode.d7.loss_mask: 0.3581  decode.d7.loss_dice: 0.2948  decode.d8.loss_cls: 0.7932  decode.d8.loss_mask: 0.3664  decode.d8.loss_dice: 0.2831
09/28 14:41:02 - mmengine - INFO - Iter(train) [  1700/320000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 1 day, 18:54:12  time: 0.4817  data_time: 0.0098  memory: 5783  grad_norm: 477.7795  loss: 22.8169  decode.loss_cls: 0.9040  decode.loss_mask: 0.7099  decode.loss_dice: 0.5717  decode.d0.loss_cls: 2.3558  decode.d0.loss_mask: 0.5861  decode.d0.loss_dice: 0.6218  decode.d1.loss_cls: 1.0415  decode.d1.loss_mask: 0.6130  decode.d1.loss_dice: 0.5754  decode.d2.loss_cls: 0.9248  decode.d2.loss_mask: 0.6713  decode.d2.loss_dice: 0.5877  decode.d3.loss_cls: 0.9745  decode.d3.loss_mask: 0.6077  decode.d3.loss_dice: 0.5631  decode.d4.loss_cls: 0.8582  decode.d4.loss_mask: 0.6517  decode.d4.loss_dice: 0.5465  decode.d5.loss_cls: 0.8810  decode.d5.loss_mask: 0.6716  decode.d5.loss_dice: 0.5732  decode.d6.loss_cls: 0.8643  decode.d6.loss_mask: 0.7173  decode.d6.loss_dice: 0.5460  decode.d7.loss_cls: 0.8678  decode.d7.loss_mask: 0.6699  decode.d7.loss_dice: 0.5517  decode.d8.loss_cls: 0.8599  decode.d8.loss_mask: 0.6807  decode.d8.loss_dice: 0.5688
09/28 14:41:26 - mmengine - INFO - Iter(train) [  1750/320000]  base_lr: 9.9508e-05 lr: 9.9508e-06  eta: 1 day, 18:53:25  time: 0.4836  data_time: 0.0099  memory: 5799  grad_norm: 393.3151  loss: 19.5554  decode.loss_cls: 0.9652  decode.loss_mask: 0.4701  decode.loss_dice: 0.4167  decode.d0.loss_cls: 2.3622  decode.d0.loss_mask: 0.4384  decode.d0.loss_dice: 0.4523  decode.d1.loss_cls: 1.0117  decode.d1.loss_mask: 0.4437  decode.d1.loss_dice: 0.4243  decode.d2.loss_cls: 0.8840  decode.d2.loss_mask: 0.4481  decode.d2.loss_dice: 0.3843  decode.d3.loss_cls: 0.8233  decode.d3.loss_mask: 0.4729  decode.d3.loss_dice: 0.3890  decode.d4.loss_cls: 0.8991  decode.d4.loss_mask: 0.5129  decode.d4.loss_dice: 0.4050  decode.d5.loss_cls: 0.9355  decode.d5.loss_mask: 0.5093  decode.d5.loss_dice: 0.4110  decode.d6.loss_cls: 0.9479  decode.d6.loss_mask: 0.4638  decode.d6.loss_dice: 0.4166  decode.d7.loss_cls: 1.0019  decode.d7.loss_mask: 0.4481  decode.d7.loss_dice: 0.3945  decode.d8.loss_cls: 0.9705  decode.d8.loss_mask: 0.4476  decode.d8.loss_dice: 0.4056
09/28 14:41:50 - mmengine - INFO - Iter(train) [  1800/320000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 1 day, 18:52:35  time: 0.4832  data_time: 0.0101  memory: 5817  grad_norm: 320.9518  loss: 18.6847  decode.loss_cls: 0.9653  decode.loss_mask: 0.4741  decode.loss_dice: 0.3251  decode.d0.loss_cls: 2.2705  decode.d0.loss_mask: 0.4367  decode.d0.loss_dice: 0.3384  decode.d1.loss_cls: 0.9980  decode.d1.loss_mask: 0.4151  decode.d1.loss_dice: 0.3282  decode.d2.loss_cls: 1.0226  decode.d2.loss_mask: 0.4214  decode.d2.loss_dice: 0.3014  decode.d3.loss_cls: 0.9562  decode.d3.loss_mask: 0.3488  decode.d3.loss_dice: 0.2943  decode.d4.loss_cls: 0.9585  decode.d4.loss_mask: 0.4576  decode.d4.loss_dice: 0.3170  decode.d5.loss_cls: 1.0315  decode.d5.loss_mask: 0.4135  decode.d5.loss_dice: 0.3066  decode.d6.loss_cls: 1.0323  decode.d6.loss_mask: 0.4580  decode.d6.loss_dice: 0.3093  decode.d7.loss_cls: 1.0118  decode.d7.loss_mask: 0.4686  decode.d7.loss_dice: 0.3161  decode.d8.loss_cls: 0.9780  decode.d8.loss_mask: 0.4108  decode.d8.loss_dice: 0.3188
09/28 14:42:15 - mmengine - INFO - Iter(train) [  1850/320000]  base_lr: 9.9480e-05 lr: 9.9480e-06  eta: 1 day, 18:51:52  time: 0.4817  data_time: 0.0097  memory: 5817  grad_norm: 208.7088  loss: 17.7579  decode.loss_cls: 0.8823  decode.loss_mask: 0.4067  decode.loss_dice: 0.3995  decode.d0.loss_cls: 2.1656  decode.d0.loss_mask: 0.3729  decode.d0.loss_dice: 0.3723  decode.d1.loss_cls: 1.0004  decode.d1.loss_mask: 0.3768  decode.d1.loss_dice: 0.3642  decode.d2.loss_cls: 0.9074  decode.d2.loss_mask: 0.3688  decode.d2.loss_dice: 0.3388  decode.d3.loss_cls: 0.9083  decode.d3.loss_mask: 0.3642  decode.d3.loss_dice: 0.3274  decode.d4.loss_cls: 0.8945  decode.d4.loss_mask: 0.3692  decode.d4.loss_dice: 0.3756  decode.d5.loss_cls: 0.8793  decode.d5.loss_mask: 0.3699  decode.d5.loss_dice: 0.3236  decode.d6.loss_cls: 0.9159  decode.d6.loss_mask: 0.3715  decode.d6.loss_dice: 0.3723  decode.d7.loss_cls: 0.8618  decode.d7.loss_mask: 0.4070  decode.d7.loss_dice: 0.3732  decode.d8.loss_cls: 0.8716  decode.d8.loss_mask: 0.4168  decode.d8.loss_dice: 0.4001
09/28 14:42:39 - mmengine - INFO - Iter(train) [  1900/320000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 1 day, 18:51:41  time: 0.4831  data_time: 0.0102  memory: 5835  grad_norm: 508.5370  loss: 21.4038  decode.loss_cls: 1.1507  decode.loss_mask: 0.4576  decode.loss_dice: 0.5152  decode.d0.loss_cls: 1.9808  decode.d0.loss_mask: 0.6017  decode.d0.loss_dice: 0.5729  decode.d1.loss_cls: 1.0096  decode.d1.loss_mask: 0.5952  decode.d1.loss_dice: 0.5496  decode.d2.loss_cls: 0.9371  decode.d2.loss_mask: 0.4771  decode.d2.loss_dice: 0.5310  decode.d3.loss_cls: 1.0415  decode.d3.loss_mask: 0.4703  decode.d3.loss_dice: 0.5198  decode.d4.loss_cls: 0.9883  decode.d4.loss_mask: 0.5181  decode.d4.loss_dice: 0.5140  decode.d5.loss_cls: 1.0805  decode.d5.loss_mask: 0.4867  decode.d5.loss_dice: 0.5047  decode.d6.loss_cls: 0.9547  decode.d6.loss_mask: 0.4756  decode.d6.loss_dice: 0.4752  decode.d7.loss_cls: 1.0758  decode.d7.loss_mask: 0.4248  decode.d7.loss_dice: 0.4646  decode.d8.loss_cls: 1.1338  decode.d8.loss_mask: 0.4142  decode.d8.loss_dice: 0.4822
09/28 14:43:03 - mmengine - INFO - Iter(train) [  1950/320000]  base_lr: 9.9452e-05 lr: 9.9452e-06  eta: 1 day, 18:50:57  time: 0.4832  data_time: 0.0098  memory: 5817  grad_norm: 318.5805  loss: 18.9802  decode.loss_cls: 0.9425  decode.loss_mask: 0.4400  decode.loss_dice: 0.4212  decode.d0.loss_cls: 2.0862  decode.d0.loss_mask: 0.4466  decode.d0.loss_dice: 0.4071  decode.d1.loss_cls: 0.9551  decode.d1.loss_mask: 0.3997  decode.d1.loss_dice: 0.3861  decode.d2.loss_cls: 0.9182  decode.d2.loss_mask: 0.3783  decode.d2.loss_dice: 0.3764  decode.d3.loss_cls: 0.9473  decode.d3.loss_mask: 0.4504  decode.d3.loss_dice: 0.3961  decode.d4.loss_cls: 0.8745  decode.d4.loss_mask: 0.4762  decode.d4.loss_dice: 0.4452  decode.d5.loss_cls: 0.9325  decode.d5.loss_mask: 0.4587  decode.d5.loss_dice: 0.4252  decode.d6.loss_cls: 0.9464  decode.d6.loss_mask: 0.4830  decode.d6.loss_dice: 0.4166  decode.d7.loss_cls: 0.9227  decode.d7.loss_mask: 0.4632  decode.d7.loss_dice: 0.4293  decode.d8.loss_cls: 0.8652  decode.d8.loss_mask: 0.4595  decode.d8.loss_dice: 0.4309
09/28 14:43:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 14:43:27 - mmengine - INFO - Iter(train) [  2000/320000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 1 day, 18:50:16  time: 0.4826  data_time: 0.0098  memory: 5817  grad_norm: 415.0241  loss: 18.9416  decode.loss_cls: 0.8748  decode.loss_mask: 0.5398  decode.loss_dice: 0.4180  decode.d0.loss_cls: 1.8864  decode.d0.loss_mask: 0.4454  decode.d0.loss_dice: 0.4095  decode.d1.loss_cls: 0.8528  decode.d1.loss_mask: 0.5401  decode.d1.loss_dice: 0.4229  decode.d2.loss_cls: 0.8688  decode.d2.loss_mask: 0.5056  decode.d2.loss_dice: 0.4091  decode.d3.loss_cls: 0.8230  decode.d3.loss_mask: 0.5282  decode.d3.loss_dice: 0.4399  decode.d4.loss_cls: 0.8356  decode.d4.loss_mask: 0.5290  decode.d4.loss_dice: 0.4238  decode.d5.loss_cls: 0.8465  decode.d5.loss_mask: 0.5068  decode.d5.loss_dice: 0.3990  decode.d6.loss_cls: 0.9241  decode.d6.loss_mask: 0.4819  decode.d6.loss_dice: 0.3761  decode.d7.loss_cls: 0.9209  decode.d7.loss_mask: 0.4821  decode.d7.loss_dice: 0.3851  decode.d8.loss_cls: 0.9190  decode.d8.loss_mask: 0.5281  decode.d8.loss_dice: 0.4192
09/28 14:43:51 - mmengine - INFO - Iter(train) [  2050/320000]  base_lr: 9.9424e-05 lr: 9.9424e-06  eta: 1 day, 18:49:36  time: 0.4833  data_time: 0.0102  memory: 5800  grad_norm: 180.8853  loss: 16.6448  decode.loss_cls: 0.8271  decode.loss_mask: 0.4155  decode.loss_dice: 0.2882  decode.d0.loss_cls: 1.9187  decode.d0.loss_mask: 0.3856  decode.d0.loss_dice: 0.3045  decode.d1.loss_cls: 0.9968  decode.d1.loss_mask: 0.4007  decode.d1.loss_dice: 0.2975  decode.d2.loss_cls: 0.8355  decode.d2.loss_mask: 0.4067  decode.d2.loss_dice: 0.2930  decode.d3.loss_cls: 0.7651  decode.d3.loss_mask: 0.4165  decode.d3.loss_dice: 0.3280  decode.d4.loss_cls: 0.9032  decode.d4.loss_mask: 0.4107  decode.d4.loss_dice: 0.2929  decode.d5.loss_cls: 0.8284  decode.d5.loss_mask: 0.4168  decode.d5.loss_dice: 0.3221  decode.d6.loss_cls: 0.8069  decode.d6.loss_mask: 0.4244  decode.d6.loss_dice: 0.3052  decode.d7.loss_cls: 0.8381  decode.d7.loss_mask: 0.4119  decode.d7.loss_dice: 0.2964  decode.d8.loss_cls: 0.8004  decode.d8.loss_mask: 0.4144  decode.d8.loss_dice: 0.2935
09/28 14:44:15 - mmengine - INFO - Iter(train) [  2100/320000]  base_lr: 9.9409e-05 lr: 9.9409e-06  eta: 1 day, 18:48:51  time: 0.4812  data_time: 0.0097  memory: 5817  grad_norm: 190.7059  loss: 16.7097  decode.loss_cls: 0.7898  decode.loss_mask: 0.4478  decode.loss_dice: 0.3015  decode.d0.loss_cls: 1.8810  decode.d0.loss_mask: 0.4558  decode.d0.loss_dice: 0.3554  decode.d1.loss_cls: 0.9561  decode.d1.loss_mask: 0.4552  decode.d1.loss_dice: 0.3231  decode.d2.loss_cls: 0.7635  decode.d2.loss_mask: 0.4444  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.7768  decode.d3.loss_mask: 0.4449  decode.d3.loss_dice: 0.2979  decode.d4.loss_cls: 0.7685  decode.d4.loss_mask: 0.4452  decode.d4.loss_dice: 0.3008  decode.d5.loss_cls: 0.7866  decode.d5.loss_mask: 0.4267  decode.d5.loss_dice: 0.3071  decode.d6.loss_cls: 0.8069  decode.d6.loss_mask: 0.4517  decode.d6.loss_dice: 0.3008  decode.d7.loss_cls: 0.8299  decode.d7.loss_mask: 0.4259  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.8174  decode.d8.loss_mask: 0.4424  decode.d8.loss_dice: 0.2984
09/28 14:44:40 - mmengine - INFO - Iter(train) [  2150/320000]  base_lr: 9.9395e-05 lr: 9.9395e-06  eta: 1 day, 18:48:10  time: 0.4844  data_time: 0.0102  memory: 5834  grad_norm: 331.8806  loss: 16.3436  decode.loss_cls: 0.7177  decode.loss_mask: 0.4283  decode.loss_dice: 0.4122  decode.d0.loss_cls: 1.7966  decode.d0.loss_mask: 0.4292  decode.d0.loss_dice: 0.3870  decode.d1.loss_cls: 0.8018  decode.d1.loss_mask: 0.3886  decode.d1.loss_dice: 0.3532  decode.d2.loss_cls: 0.7283  decode.d2.loss_mask: 0.3984  decode.d2.loss_dice: 0.3852  decode.d3.loss_cls: 0.6669  decode.d3.loss_mask: 0.3948  decode.d3.loss_dice: 0.4167  decode.d4.loss_cls: 0.6736  decode.d4.loss_mask: 0.4329  decode.d4.loss_dice: 0.4019  decode.d5.loss_cls: 0.6949  decode.d5.loss_mask: 0.4292  decode.d5.loss_dice: 0.3805  decode.d6.loss_cls: 0.6915  decode.d6.loss_mask: 0.4429  decode.d6.loss_dice: 0.4039  decode.d7.loss_cls: 0.6418  decode.d7.loss_mask: 0.4604  decode.d7.loss_dice: 0.4064  decode.d8.loss_cls: 0.6958  decode.d8.loss_mask: 0.4797  decode.d8.loss_dice: 0.4034
09/28 14:45:04 - mmengine - INFO - Iter(train) [  2200/320000]  base_lr: 9.9381e-05 lr: 9.9381e-06  eta: 1 day, 18:47:23  time: 0.4821  data_time: 0.0097  memory: 5799  grad_norm: 126.5274  loss: 11.9453  decode.loss_cls: 0.5048  decode.loss_mask: 0.3486  decode.loss_dice: 0.2458  decode.d0.loss_cls: 1.5661  decode.d0.loss_mask: 0.3397  decode.d0.loss_dice: 0.2730  decode.d1.loss_cls: 0.5654  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.2577  decode.d2.loss_cls: 0.4492  decode.d2.loss_mask: 0.3310  decode.d2.loss_dice: 0.2663  decode.d3.loss_cls: 0.4485  decode.d3.loss_mask: 0.3251  decode.d3.loss_dice: 0.2674  decode.d4.loss_cls: 0.4765  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.2615  decode.d5.loss_cls: 0.5019  decode.d5.loss_mask: 0.3351  decode.d5.loss_dice: 0.2491  decode.d6.loss_cls: 0.4930  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.2379  decode.d7.loss_cls: 0.4968  decode.d7.loss_mask: 0.3348  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.5197  decode.d8.loss_mask: 0.3447  decode.d8.loss_dice: 0.2569
09/28 14:45:28 - mmengine - INFO - Iter(train) [  2250/320000]  base_lr: 9.9367e-05 lr: 9.9367e-06  eta: 1 day, 18:46:41  time: 0.4840  data_time: 0.0101  memory: 5799  grad_norm: 204.9118  loss: 15.6095  decode.loss_cls: 0.6908  decode.loss_mask: 0.3986  decode.loss_dice: 0.3338  decode.d0.loss_cls: 1.6652  decode.d0.loss_mask: 0.4256  decode.d0.loss_dice: 0.3691  decode.d1.loss_cls: 0.7681  decode.d1.loss_mask: 0.4085  decode.d1.loss_dice: 0.3719  decode.d2.loss_cls: 0.6120  decode.d2.loss_mask: 0.4296  decode.d2.loss_dice: 0.3539  decode.d3.loss_cls: 0.6379  decode.d3.loss_mask: 0.4201  decode.d3.loss_dice: 0.3612  decode.d4.loss_cls: 0.6883  decode.d4.loss_mask: 0.4184  decode.d4.loss_dice: 0.3400  decode.d5.loss_cls: 0.6597  decode.d5.loss_mask: 0.4277  decode.d5.loss_dice: 0.3433  decode.d6.loss_cls: 0.7211  decode.d6.loss_mask: 0.4230  decode.d6.loss_dice: 0.3340  decode.d7.loss_cls: 0.7128  decode.d7.loss_mask: 0.4001  decode.d7.loss_dice: 0.3265  decode.d8.loss_cls: 0.7276  decode.d8.loss_mask: 0.4875  decode.d8.loss_dice: 0.3535
09/28 14:45:52 - mmengine - INFO - Iter(train) [  2300/320000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 1 day, 18:46:00  time: 0.4822  data_time: 0.0093  memory: 5834  grad_norm: 244.2867  loss: 16.0123  decode.loss_cls: 0.7513  decode.loss_mask: 0.4068  decode.loss_dice: 0.3548  decode.d0.loss_cls: 1.5898  decode.d0.loss_mask: 0.4220  decode.d0.loss_dice: 0.3727  decode.d1.loss_cls: 0.8339  decode.d1.loss_mask: 0.4179  decode.d1.loss_dice: 0.3749  decode.d2.loss_cls: 0.6299  decode.d2.loss_mask: 0.4370  decode.d2.loss_dice: 0.3547  decode.d3.loss_cls: 0.6632  decode.d3.loss_mask: 0.4285  decode.d3.loss_dice: 0.3534  decode.d4.loss_cls: 0.7058  decode.d4.loss_mask: 0.4531  decode.d4.loss_dice: 0.3568  decode.d5.loss_cls: 0.7292  decode.d5.loss_mask: 0.4257  decode.d5.loss_dice: 0.3480  decode.d6.loss_cls: 0.7691  decode.d6.loss_mask: 0.4369  decode.d6.loss_dice: 0.3656  decode.d7.loss_cls: 0.7485  decode.d7.loss_mask: 0.4032  decode.d7.loss_dice: 0.3375  decode.d8.loss_cls: 0.7319  decode.d8.loss_mask: 0.4401  decode.d8.loss_dice: 0.3700
09/28 14:46:16 - mmengine - INFO - Iter(train) [  2350/320000]  base_lr: 9.9339e-05 lr: 9.9339e-06  eta: 1 day, 18:45:23  time: 0.4830  data_time: 0.0101  memory: 5799  grad_norm: 261.6458  loss: 19.6967  decode.loss_cls: 0.8700  decode.loss_mask: 0.4814  decode.loss_dice: 0.4951  decode.d0.loss_cls: 1.6777  decode.d0.loss_mask: 0.5580  decode.d0.loss_dice: 0.5535  decode.d1.loss_cls: 0.9018  decode.d1.loss_mask: 0.5137  decode.d1.loss_dice: 0.5065  decode.d2.loss_cls: 0.8705  decode.d2.loss_mask: 0.4917  decode.d2.loss_dice: 0.4979  decode.d3.loss_cls: 0.7907  decode.d3.loss_mask: 0.5218  decode.d3.loss_dice: 0.5094  decode.d4.loss_cls: 0.8221  decode.d4.loss_mask: 0.5288  decode.d4.loss_dice: 0.5231  decode.d5.loss_cls: 0.9285  decode.d5.loss_mask: 0.5188  decode.d5.loss_dice: 0.4947  decode.d6.loss_cls: 0.9224  decode.d6.loss_mask: 0.4934  decode.d6.loss_dice: 0.4856  decode.d7.loss_cls: 0.8842  decode.d7.loss_mask: 0.5088  decode.d7.loss_dice: 0.4718  decode.d8.loss_cls: 0.8798  decode.d8.loss_mask: 0.5057  decode.d8.loss_dice: 0.4891
09/28 14:46:40 - mmengine - INFO - Iter(train) [  2400/320000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 1 day, 18:44:43  time: 0.4829  data_time: 0.0095  memory: 5816  grad_norm: 316.0226  loss: 18.6978  decode.loss_cls: 0.8273  decode.loss_mask: 0.5011  decode.loss_dice: 0.4505  decode.d0.loss_cls: 1.6138  decode.d0.loss_mask: 0.5572  decode.d0.loss_dice: 0.4506  decode.d1.loss_cls: 0.9440  decode.d1.loss_mask: 0.4960  decode.d1.loss_dice: 0.4317  decode.d2.loss_cls: 0.9294  decode.d2.loss_mask: 0.4722  decode.d2.loss_dice: 0.4189  decode.d3.loss_cls: 0.9156  decode.d3.loss_mask: 0.4615  decode.d3.loss_dice: 0.3858  decode.d4.loss_cls: 0.9509  decode.d4.loss_mask: 0.5052  decode.d4.loss_dice: 0.4352  decode.d5.loss_cls: 0.8540  decode.d5.loss_mask: 0.4933  decode.d5.loss_dice: 0.4406  decode.d6.loss_cls: 0.8437  decode.d6.loss_mask: 0.4722  decode.d6.loss_dice: 0.4169  decode.d7.loss_cls: 0.8247  decode.d7.loss_mask: 0.4921  decode.d7.loss_dice: 0.3971  decode.d8.loss_cls: 0.7602  decode.d8.loss_mask: 0.5026  decode.d8.loss_dice: 0.4534
09/28 14:47:04 - mmengine - INFO - Iter(train) [  2450/320000]  base_lr: 9.9311e-05 lr: 9.9311e-06  eta: 1 day, 18:44:07  time: 0.4812  data_time: 0.0098  memory: 5817  grad_norm: 311.5197  loss: 17.1989  decode.loss_cls: 0.8228  decode.loss_mask: 0.4203  decode.loss_dice: 0.4072  decode.d0.loss_cls: 1.4611  decode.d0.loss_mask: 0.4019  decode.d0.loss_dice: 0.3812  decode.d1.loss_cls: 0.9177  decode.d1.loss_mask: 0.4008  decode.d1.loss_dice: 0.3741  decode.d2.loss_cls: 0.7506  decode.d2.loss_mask: 0.3936  decode.d2.loss_dice: 0.4140  decode.d3.loss_cls: 0.8173  decode.d3.loss_mask: 0.3793  decode.d3.loss_dice: 0.3682  decode.d4.loss_cls: 0.8203  decode.d4.loss_mask: 0.3958  decode.d4.loss_dice: 0.4185  decode.d5.loss_cls: 0.9650  decode.d5.loss_mask: 0.3963  decode.d5.loss_dice: 0.4157  decode.d6.loss_cls: 0.9136  decode.d6.loss_mask: 0.3988  decode.d6.loss_dice: 0.4048  decode.d7.loss_cls: 0.9131  decode.d7.loss_mask: 0.3956  decode.d7.loss_dice: 0.3968  decode.d8.loss_cls: 0.8569  decode.d8.loss_mask: 0.3884  decode.d8.loss_dice: 0.4092
09/28 14:47:28 - mmengine - INFO - Iter(train) [  2500/320000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 1 day, 18:43:45  time: 0.4842  data_time: 0.0101  memory: 5835  grad_norm: 310.0178  loss: 18.6427  decode.loss_cls: 0.8758  decode.loss_mask: 0.4755  decode.loss_dice: 0.3230  decode.d0.loss_cls: 1.8307  decode.d0.loss_mask: 0.5207  decode.d0.loss_dice: 0.4352  decode.d1.loss_cls: 0.9511  decode.d1.loss_mask: 0.5158  decode.d1.loss_dice: 0.3753  decode.d2.loss_cls: 0.8123  decode.d2.loss_mask: 0.5006  decode.d2.loss_dice: 0.4326  decode.d3.loss_cls: 0.8592  decode.d3.loss_mask: 0.4896  decode.d3.loss_dice: 0.3938  decode.d4.loss_cls: 0.9170  decode.d4.loss_mask: 0.4799  decode.d4.loss_dice: 0.3750  decode.d5.loss_cls: 0.9180  decode.d5.loss_mask: 0.4921  decode.d5.loss_dice: 0.3739  decode.d6.loss_cls: 0.9347  decode.d6.loss_mask: 0.4882  decode.d6.loss_dice: 0.4025  decode.d7.loss_cls: 0.8824  decode.d7.loss_mask: 0.4949  decode.d7.loss_dice: 0.3658  decode.d8.loss_cls: 0.8647  decode.d8.loss_mask: 0.4999  decode.d8.loss_dice: 0.3624
09/28 14:47:53 - mmengine - INFO - Iter(train) [  2550/320000]  base_lr: 9.9283e-05 lr: 9.9283e-06  eta: 1 day, 18:43:06  time: 0.4829  data_time: 0.0096  memory: 5835  grad_norm: 587.2718  loss: 15.8018  decode.loss_cls: 0.7476  decode.loss_mask: 0.4443  decode.loss_dice: 0.3232  decode.d0.loss_cls: 1.5657  decode.d0.loss_mask: 0.4203  decode.d0.loss_dice: 0.3379  decode.d1.loss_cls: 0.8881  decode.d1.loss_mask: 0.4029  decode.d1.loss_dice: 0.3535  decode.d2.loss_cls: 0.6978  decode.d2.loss_mask: 0.4174  decode.d2.loss_dice: 0.3554  decode.d3.loss_cls: 0.7066  decode.d3.loss_mask: 0.4567  decode.d3.loss_dice: 0.3404  decode.d4.loss_cls: 0.7282  decode.d4.loss_mask: 0.4442  decode.d4.loss_dice: 0.3222  decode.d5.loss_cls: 0.6760  decode.d5.loss_mask: 0.4733  decode.d5.loss_dice: 0.3645  decode.d6.loss_cls: 0.7187  decode.d6.loss_mask: 0.3827  decode.d6.loss_dice: 0.3198  decode.d7.loss_cls: 0.6858  decode.d7.loss_mask: 0.3971  decode.d7.loss_dice: 0.3342  decode.d8.loss_cls: 0.6919  decode.d8.loss_mask: 0.4516  decode.d8.loss_dice: 0.3538
09/28 14:48:17 - mmengine - INFO - Iter(train) [  2600/320000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 1 day, 18:42:31  time: 0.4839  data_time: 0.0101  memory: 5834  grad_norm: 133.0684  loss: 12.1219  decode.loss_cls: 0.4204  decode.loss_mask: 0.3744  decode.loss_dice: 0.3320  decode.d0.loss_cls: 1.4217  decode.d0.loss_mask: 0.3153  decode.d0.loss_dice: 0.3140  decode.d1.loss_cls: 0.5946  decode.d1.loss_mask: 0.3037  decode.d1.loss_dice: 0.3117  decode.d2.loss_cls: 0.4790  decode.d2.loss_mask: 0.2999  decode.d2.loss_dice: 0.2921  decode.d3.loss_cls: 0.4881  decode.d3.loss_mask: 0.3127  decode.d3.loss_dice: 0.3088  decode.d4.loss_cls: 0.4832  decode.d4.loss_mask: 0.3230  decode.d4.loss_dice: 0.2972  decode.d5.loss_cls: 0.4623  decode.d5.loss_mask: 0.3090  decode.d5.loss_dice: 0.3172  decode.d6.loss_cls: 0.4622  decode.d6.loss_mask: 0.3596  decode.d6.loss_dice: 0.3301  decode.d7.loss_cls: 0.4521  decode.d7.loss_mask: 0.3319  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.4718  decode.d8.loss_mask: 0.3493  decode.d8.loss_dice: 0.3065
09/28 14:48:41 - mmengine - INFO - Iter(train) [  2650/320000]  base_lr: 9.9255e-05 lr: 9.9255e-06  eta: 1 day, 18:41:56  time: 0.4809  data_time: 0.0097  memory: 5817  grad_norm: 105.8915  loss: 11.7833  decode.loss_cls: 0.4248  decode.loss_mask: 0.3369  decode.loss_dice: 0.3040  decode.d0.loss_cls: 1.2888  decode.d0.loss_mask: 0.3334  decode.d0.loss_dice: 0.3035  decode.d1.loss_cls: 0.4895  decode.d1.loss_mask: 0.3290  decode.d1.loss_dice: 0.3056  decode.d2.loss_cls: 0.4398  decode.d2.loss_mask: 0.3276  decode.d2.loss_dice: 0.3086  decode.d3.loss_cls: 0.4061  decode.d3.loss_mask: 0.3284  decode.d3.loss_dice: 0.2997  decode.d4.loss_cls: 0.4352  decode.d4.loss_mask: 0.3293  decode.d4.loss_dice: 0.2989  decode.d5.loss_cls: 0.4958  decode.d5.loss_mask: 0.3346  decode.d5.loss_dice: 0.3023  decode.d6.loss_cls: 0.5342  decode.d6.loss_mask: 0.3238  decode.d6.loss_dice: 0.2867  decode.d7.loss_cls: 0.4866  decode.d7.loss_mask: 0.3382  decode.d7.loss_dice: 0.2984  decode.d8.loss_cls: 0.4505  decode.d8.loss_mask: 0.3430  decode.d8.loss_dice: 0.2999
09/28 14:49:05 - mmengine - INFO - Iter(train) [  2700/320000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 1 day, 18:41:29  time: 0.4852  data_time: 0.0105  memory: 5799  grad_norm: 294.4947  loss: 22.5139  decode.loss_cls: 0.9408  decode.loss_mask: 0.6779  decode.loss_dice: 0.5781  decode.d0.loss_cls: 1.5797  decode.d0.loss_mask: 0.6710  decode.d0.loss_dice: 0.6080  decode.d1.loss_cls: 1.0719  decode.d1.loss_mask: 0.5845  decode.d1.loss_dice: 0.5075  decode.d2.loss_cls: 0.9832  decode.d2.loss_mask: 0.5751  decode.d2.loss_dice: 0.5192  decode.d3.loss_cls: 1.0258  decode.d3.loss_mask: 0.5749  decode.d3.loss_dice: 0.5228  decode.d4.loss_cls: 0.9653  decode.d4.loss_mask: 0.6091  decode.d4.loss_dice: 0.5402  decode.d5.loss_cls: 0.9837  decode.d5.loss_mask: 0.6881  decode.d5.loss_dice: 0.5654  decode.d6.loss_cls: 1.0319  decode.d6.loss_mask: 0.6944  decode.d6.loss_dice: 0.5688  decode.d7.loss_cls: 0.9229  decode.d7.loss_mask: 0.8143  decode.d7.loss_dice: 0.5496  decode.d8.loss_cls: 0.9544  decode.d8.loss_mask: 0.6641  decode.d8.loss_dice: 0.5411
09/28 14:49:29 - mmengine - INFO - Iter(train) [  2750/320000]  base_lr: 9.9227e-05 lr: 9.9227e-06  eta: 1 day, 18:40:59  time: 0.4836  data_time: 0.0102  memory: 5819  grad_norm: 315.4627  loss: 15.1555  decode.loss_cls: 0.5936  decode.loss_mask: 0.4693  decode.loss_dice: 0.3035  decode.d0.loss_cls: 1.5153  decode.d0.loss_mask: 0.4391  decode.d0.loss_dice: 0.3412  decode.d1.loss_cls: 0.8151  decode.d1.loss_mask: 0.4503  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.6647  decode.d2.loss_mask: 0.4777  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.5893  decode.d3.loss_mask: 0.5135  decode.d3.loss_dice: 0.3189  decode.d4.loss_cls: 0.5417  decode.d4.loss_mask: 0.4470  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.6500  decode.d5.loss_mask: 0.5181  decode.d5.loss_dice: 0.3111  decode.d6.loss_cls: 0.6600  decode.d6.loss_mask: 0.4756  decode.d6.loss_dice: 0.3408  decode.d7.loss_cls: 0.6606  decode.d7.loss_mask: 0.4859  decode.d7.loss_dice: 0.3089  decode.d8.loss_cls: 0.6139  decode.d8.loss_mask: 0.4854  decode.d8.loss_dice: 0.3094
09/28 14:49:53 - mmengine - INFO - Iter(train) [  2800/320000]  base_lr: 9.9212e-05 lr: 9.9212e-06  eta: 1 day, 18:40:36  time: 0.4843  data_time: 0.0101  memory: 5834  grad_norm: 351.8736  loss: 19.2952  decode.loss_cls: 0.9831  decode.loss_mask: 0.4722  decode.loss_dice: 0.4279  decode.d0.loss_cls: 1.6489  decode.d0.loss_mask: 0.4679  decode.d0.loss_dice: 0.5626  decode.d1.loss_cls: 1.1263  decode.d1.loss_mask: 0.4260  decode.d1.loss_dice: 0.4676  decode.d2.loss_cls: 0.9452  decode.d2.loss_mask: 0.4235  decode.d2.loss_dice: 0.4479  decode.d3.loss_cls: 0.8817  decode.d3.loss_mask: 0.4541  decode.d3.loss_dice: 0.4575  decode.d4.loss_cls: 0.9412  decode.d4.loss_mask: 0.4331  decode.d4.loss_dice: 0.4328  decode.d5.loss_cls: 0.9145  decode.d5.loss_mask: 0.4562  decode.d5.loss_dice: 0.4483  decode.d6.loss_cls: 0.8769  decode.d6.loss_mask: 0.4897  decode.d6.loss_dice: 0.4381  decode.d7.loss_cls: 0.9427  decode.d7.loss_mask: 0.4792  decode.d7.loss_dice: 0.4529  decode.d8.loss_cls: 0.9132  decode.d8.loss_mask: 0.4376  decode.d8.loss_dice: 0.4466
09/28 14:50:18 - mmengine - INFO - Iter(train) [  2850/320000]  base_lr: 9.9198e-05 lr: 9.9198e-06  eta: 1 day, 18:40:10  time: 0.4841  data_time: 0.0101  memory: 5817  grad_norm: 497.4017  loss: 17.2345  decode.loss_cls: 0.8248  decode.loss_mask: 0.4804  decode.loss_dice: 0.3464  decode.d0.loss_cls: 1.5808  decode.d0.loss_mask: 0.4127  decode.d0.loss_dice: 0.3893  decode.d1.loss_cls: 0.8360  decode.d1.loss_mask: 0.4113  decode.d1.loss_dice: 0.3880  decode.d2.loss_cls: 0.7893  decode.d2.loss_mask: 0.4236  decode.d2.loss_dice: 0.3986  decode.d3.loss_cls: 0.7058  decode.d3.loss_mask: 0.4353  decode.d3.loss_dice: 0.3910  decode.d4.loss_cls: 0.7598  decode.d4.loss_mask: 0.5004  decode.d4.loss_dice: 0.4022  decode.d5.loss_cls: 0.8223  decode.d5.loss_mask: 0.4529  decode.d5.loss_dice: 0.3879  decode.d6.loss_cls: 0.8882  decode.d6.loss_mask: 0.4625  decode.d6.loss_dice: 0.3926  decode.d7.loss_cls: 0.8617  decode.d7.loss_mask: 0.4623  decode.d7.loss_dice: 0.3901  decode.d8.loss_cls: 0.7956  decode.d8.loss_mask: 0.4726  decode.d8.loss_dice: 0.3704
09/28 14:50:42 - mmengine - INFO - Iter(train) [  2900/320000]  base_lr: 9.9184e-05 lr: 9.9184e-06  eta: 1 day, 18:39:45  time: 0.4839  data_time: 0.0101  memory: 5816  grad_norm: 217.9628  loss: 11.7761  decode.loss_cls: 0.4253  decode.loss_mask: 0.3764  decode.loss_dice: 0.3339  decode.d0.loss_cls: 1.3470  decode.d0.loss_mask: 0.3422  decode.d0.loss_dice: 0.2964  decode.d1.loss_cls: 0.4934  decode.d1.loss_mask: 0.3137  decode.d1.loss_dice: 0.3036  decode.d2.loss_cls: 0.3647  decode.d2.loss_mask: 0.3236  decode.d2.loss_dice: 0.3285  decode.d3.loss_cls: 0.3500  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3171  decode.d4.loss_cls: 0.3306  decode.d4.loss_mask: 0.4617  decode.d4.loss_dice: 0.3129  decode.d5.loss_cls: 0.3864  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.3117  decode.d6.loss_cls: 0.4139  decode.d6.loss_mask: 0.4420  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.3833  decode.d7.loss_mask: 0.3907  decode.d7.loss_dice: 0.3036  decode.d8.loss_cls: 0.4131  decode.d8.loss_mask: 0.3657  decode.d8.loss_dice: 0.3353
09/28 14:51:06 - mmengine - INFO - Iter(train) [  2950/320000]  base_lr: 9.9170e-05 lr: 9.9170e-06  eta: 1 day, 18:39:20  time: 0.4849  data_time: 0.0102  memory: 5834  grad_norm: 419.5677  loss: 17.2732  decode.loss_cls: 0.8033  decode.loss_mask: 0.5050  decode.loss_dice: 0.4417  decode.d0.loss_cls: 1.6493  decode.d0.loss_mask: 0.4355  decode.d0.loss_dice: 0.4427  decode.d1.loss_cls: 0.8138  decode.d1.loss_mask: 0.4401  decode.d1.loss_dice: 0.3861  decode.d2.loss_cls: 0.7794  decode.d2.loss_mask: 0.3777  decode.d2.loss_dice: 0.3815  decode.d3.loss_cls: 0.7495  decode.d3.loss_mask: 0.4903  decode.d3.loss_dice: 0.4293  decode.d4.loss_cls: 0.7540  decode.d4.loss_mask: 0.4092  decode.d4.loss_dice: 0.4185  decode.d5.loss_cls: 0.7940  decode.d5.loss_mask: 0.3934  decode.d5.loss_dice: 0.4097  decode.d6.loss_cls: 0.8133  decode.d6.loss_mask: 0.4045  decode.d6.loss_dice: 0.4242  decode.d7.loss_cls: 0.8288  decode.d7.loss_mask: 0.4347  decode.d7.loss_dice: 0.3942  decode.d8.loss_cls: 0.8265  decode.d8.loss_mask: 0.4354  decode.d8.loss_dice: 0.4076
09/28 14:51:30 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 14:51:30 - mmengine - INFO - Iter(train) [  3000/320000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 1 day, 18:38:56  time: 0.4843  data_time: 0.0102  memory: 5799  grad_norm: 292.1717  loss: 12.7433  decode.loss_cls: 0.4716  decode.loss_mask: 0.4164  decode.loss_dice: 0.3447  decode.d0.loss_cls: 1.0834  decode.d0.loss_mask: 0.3777  decode.d0.loss_dice: 0.3200  decode.d1.loss_cls: 0.5729  decode.d1.loss_mask: 0.3789  decode.d1.loss_dice: 0.3069  decode.d2.loss_cls: 0.5170  decode.d2.loss_mask: 0.3812  decode.d2.loss_dice: 0.3064  decode.d3.loss_cls: 0.4867  decode.d3.loss_mask: 0.3773  decode.d3.loss_dice: 0.3126  decode.d4.loss_cls: 0.5498  decode.d4.loss_mask: 0.3789  decode.d4.loss_dice: 0.3151  decode.d5.loss_cls: 0.5897  decode.d5.loss_mask: 0.4001  decode.d5.loss_dice: 0.3086  decode.d6.loss_cls: 0.4568  decode.d6.loss_mask: 0.3792  decode.d6.loss_dice: 0.2993  decode.d7.loss_cls: 0.5001  decode.d7.loss_mask: 0.3807  decode.d7.loss_dice: 0.2992  decode.d8.loss_cls: 0.5077  decode.d8.loss_mask: 0.3942  decode.d8.loss_dice: 0.3303
09/28 14:51:55 - mmengine - INFO - Iter(train) [  3050/320000]  base_lr: 9.9142e-05 lr: 9.9142e-06  eta: 1 day, 18:38:39  time: 0.4835  data_time: 0.0099  memory: 5816  grad_norm: 204.4458  loss: 18.0787  decode.loss_cls: 0.7236  decode.loss_mask: 0.4706  decode.loss_dice: 0.4999  decode.d0.loss_cls: 1.5552  decode.d0.loss_mask: 0.4677  decode.d0.loss_dice: 0.4274  decode.d1.loss_cls: 1.0126  decode.d1.loss_mask: 0.4325  decode.d1.loss_dice: 0.4255  decode.d2.loss_cls: 0.7668  decode.d2.loss_mask: 0.5255  decode.d2.loss_dice: 0.4775  decode.d3.loss_cls: 0.6290  decode.d3.loss_mask: 0.5104  decode.d3.loss_dice: 0.5285  decode.d4.loss_cls: 0.6121  decode.d4.loss_mask: 0.4933  decode.d4.loss_dice: 0.4830  decode.d5.loss_cls: 0.7154  decode.d5.loss_mask: 0.5196  decode.d5.loss_dice: 0.4806  decode.d6.loss_cls: 0.8194  decode.d6.loss_mask: 0.4846  decode.d6.loss_dice: 0.4989  decode.d7.loss_cls: 0.7863  decode.d7.loss_mask: 0.4644  decode.d7.loss_dice: 0.5146  decode.d8.loss_cls: 0.7055  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 0.4665
09/28 14:52:19 - mmengine - INFO - Iter(train) [  3100/320000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 1 day, 18:38:14  time: 0.4844  data_time: 0.0101  memory: 5816  grad_norm: 213.5026  loss: 14.3137  decode.loss_cls: 0.6890  decode.loss_mask: 0.3767  decode.loss_dice: 0.2911  decode.d0.loss_cls: 1.3845  decode.d0.loss_mask: 0.3945  decode.d0.loss_dice: 0.2930  decode.d1.loss_cls: 0.7227  decode.d1.loss_mask: 0.4012  decode.d1.loss_dice: 0.2748  decode.d2.loss_cls: 0.7352  decode.d2.loss_mask: 0.3560  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.7267  decode.d3.loss_mask: 0.3947  decode.d3.loss_dice: 0.2586  decode.d4.loss_cls: 0.6709  decode.d4.loss_mask: 0.4052  decode.d4.loss_dice: 0.2640  decode.d5.loss_cls: 0.6872  decode.d5.loss_mask: 0.3433  decode.d5.loss_dice: 0.2614  decode.d6.loss_cls: 0.7317  decode.d6.loss_mask: 0.3759  decode.d6.loss_dice: 0.2592  decode.d7.loss_cls: 0.6946  decode.d7.loss_mask: 0.4150  decode.d7.loss_dice: 0.2830  decode.d8.loss_cls: 0.6831  decode.d8.loss_mask: 0.4071  decode.d8.loss_dice: 0.2786
09/28 14:52:43 - mmengine - INFO - Iter(train) [  3150/320000]  base_lr: 9.9114e-05 lr: 9.9114e-06  eta: 1 day, 18:37:47  time: 0.4834  data_time: 0.0100  memory: 5816  grad_norm: 205.3176  loss: 11.0965  decode.loss_cls: 0.4274  decode.loss_mask: 0.2603  decode.loss_dice: 0.2714  decode.d0.loss_cls: 1.4314  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.2703  decode.d1.loss_cls: 0.6273  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2684  decode.d2.loss_cls: 0.5040  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2502  decode.d3.loss_cls: 0.4790  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.4994  decode.d4.loss_mask: 0.2554  decode.d4.loss_dice: 0.2690  decode.d5.loss_cls: 0.4946  decode.d5.loss_mask: 0.2564  decode.d5.loss_dice: 0.2710  decode.d6.loss_cls: 0.5083  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2684  decode.d7.loss_cls: 0.4325  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.3110  decode.d8.loss_cls: 0.4251  decode.d8.loss_mask: 0.2580  decode.d8.loss_dice: 0.2861
09/28 14:53:07 - mmengine - INFO - Iter(train) [  3200/320000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 1 day, 18:37:21  time: 0.4846  data_time: 0.0102  memory: 5817  grad_norm: 673.6941  loss: 21.5859  decode.loss_cls: 0.9973  decode.loss_mask: 0.5742  decode.loss_dice: 0.5292  decode.d0.loss_cls: 1.5769  decode.d0.loss_mask: 0.6287  decode.d0.loss_dice: 0.5242  decode.d1.loss_cls: 1.0511  decode.d1.loss_mask: 0.5680  decode.d1.loss_dice: 0.4745  decode.d2.loss_cls: 0.9441  decode.d2.loss_mask: 0.5671  decode.d2.loss_dice: 0.4882  decode.d3.loss_cls: 0.9014  decode.d3.loss_mask: 0.5932  decode.d3.loss_dice: 0.4788  decode.d4.loss_cls: 0.9636  decode.d4.loss_mask: 0.5924  decode.d4.loss_dice: 0.4904  decode.d5.loss_cls: 0.9419  decode.d5.loss_mask: 0.6984  decode.d5.loss_dice: 0.5132  decode.d6.loss_cls: 1.0542  decode.d6.loss_mask: 0.6138  decode.d6.loss_dice: 0.5049  decode.d7.loss_cls: 1.0823  decode.d7.loss_mask: 0.5773  decode.d7.loss_dice: 0.4954  decode.d8.loss_cls: 1.0140  decode.d8.loss_mask: 0.6274  decode.d8.loss_dice: 0.5196
09/28 14:53:31 - mmengine - INFO - Iter(train) [  3250/320000]  base_lr: 9.9086e-05 lr: 9.9086e-06  eta: 1 day, 18:36:58  time: 0.4841  data_time: 0.0101  memory: 5817  grad_norm: 365.5408  loss: 13.0740  decode.loss_cls: 0.6456  decode.loss_mask: 0.2938  decode.loss_dice: 0.2765  decode.d0.loss_cls: 1.2245  decode.d0.loss_mask: 0.3265  decode.d0.loss_dice: 0.3240  decode.d1.loss_cls: 0.7287  decode.d1.loss_mask: 0.3177  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.6594  decode.d2.loss_mask: 0.2985  decode.d2.loss_dice: 0.2672  decode.d3.loss_cls: 0.6521  decode.d3.loss_mask: 0.3049  decode.d3.loss_dice: 0.2588  decode.d4.loss_cls: 0.6349  decode.d4.loss_mask: 0.2959  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.6329  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.2738  decode.d6.loss_cls: 0.6880  decode.d6.loss_mask: 0.3117  decode.d6.loss_dice: 0.2769  decode.d7.loss_cls: 0.6501  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.7075  decode.d8.loss_mask: 0.2951  decode.d8.loss_dice: 0.2943
09/28 14:53:56 - mmengine - INFO - Iter(train) [  3300/320000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 1 day, 18:36:34  time: 0.4851  data_time: 0.0104  memory: 5834  grad_norm: 140.6640  loss: 9.8935  decode.loss_cls: 0.3572  decode.loss_mask: 0.2874  decode.loss_dice: 0.2558  decode.d0.loss_cls: 1.1737  decode.d0.loss_mask: 0.2818  decode.d0.loss_dice: 0.2556  decode.d1.loss_cls: 0.3892  decode.d1.loss_mask: 0.2788  decode.d1.loss_dice: 0.2598  decode.d2.loss_cls: 0.3550  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.2303  decode.d3.loss_cls: 0.3367  decode.d3.loss_mask: 0.2711  decode.d3.loss_dice: 0.2432  decode.d4.loss_cls: 0.3828  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.2642  decode.d5.loss_cls: 0.3813  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.2646  decode.d6.loss_cls: 0.3833  decode.d6.loss_mask: 0.2783  decode.d6.loss_dice: 0.2611  decode.d7.loss_cls: 0.3813  decode.d7.loss_mask: 0.3169  decode.d7.loss_dice: 0.2660  decode.d8.loss_cls: 0.3517  decode.d8.loss_mask: 0.3156  decode.d8.loss_dice: 0.2498
09/28 14:54:20 - mmengine - INFO - Iter(train) [  3350/320000]  base_lr: 9.9058e-05 lr: 9.9058e-06  eta: 1 day, 18:36:27  time: 0.4844  data_time: 0.0102  memory: 5799  grad_norm: 272.4641  loss: 16.0151  decode.loss_cls: 0.7062  decode.loss_mask: 0.4347  decode.loss_dice: 0.3712  decode.d0.loss_cls: 1.4918  decode.d0.loss_mask: 0.4052  decode.d0.loss_dice: 0.3829  decode.d1.loss_cls: 0.8780  decode.d1.loss_mask: 0.3844  decode.d1.loss_dice: 0.3508  decode.d2.loss_cls: 0.7558  decode.d2.loss_mask: 0.3899  decode.d2.loss_dice: 0.3515  decode.d3.loss_cls: 0.7498  decode.d3.loss_mask: 0.3740  decode.d3.loss_dice: 0.3619  decode.d4.loss_cls: 0.7405  decode.d4.loss_mask: 0.3895  decode.d4.loss_dice: 0.3519  decode.d5.loss_cls: 0.7192  decode.d5.loss_mask: 0.4275  decode.d5.loss_dice: 0.3520  decode.d6.loss_cls: 0.7777  decode.d6.loss_mask: 0.4034  decode.d6.loss_dice: 0.3457  decode.d7.loss_cls: 0.7298  decode.d7.loss_mask: 0.4602  decode.d7.loss_dice: 0.3848  decode.d8.loss_cls: 0.7510  decode.d8.loss_mask: 0.4366  decode.d8.loss_dice: 0.3572
09/28 14:54:44 - mmengine - INFO - Iter(train) [  3400/320000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 1 day, 18:36:02  time: 0.4841  data_time: 0.0102  memory: 5819  grad_norm: 215.1676  loss: 12.3707  decode.loss_cls: 0.5005  decode.loss_mask: 0.3180  decode.loss_dice: 0.3022  decode.d0.loss_cls: 1.3356  decode.d0.loss_mask: 0.3061  decode.d0.loss_dice: 0.3396  decode.d1.loss_cls: 0.5899  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.3241  decode.d2.loss_cls: 0.4221  decode.d2.loss_mask: 0.3214  decode.d2.loss_dice: 0.3080  decode.d3.loss_cls: 0.5409  decode.d3.loss_mask: 0.3159  decode.d3.loss_dice: 0.2964  decode.d4.loss_cls: 0.5778  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.3300  decode.d5.loss_cls: 0.5787  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.3216  decode.d6.loss_cls: 0.5465  decode.d6.loss_mask: 0.3064  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.5115  decode.d7.loss_mask: 0.3168  decode.d7.loss_dice: 0.3179  decode.d8.loss_cls: 0.4789  decode.d8.loss_mask: 0.3059  decode.d8.loss_dice: 0.3069
09/28 14:55:08 - mmengine - INFO - Iter(train) [  3450/320000]  base_lr: 9.9029e-05 lr: 9.9029e-06  eta: 1 day, 18:35:35  time: 0.4833  data_time: 0.0103  memory: 5816  grad_norm: 178.1249  loss: 12.1318  decode.loss_cls: 0.5095  decode.loss_mask: 0.3677  decode.loss_dice: 0.2715  decode.d0.loss_cls: 1.3122  decode.d0.loss_mask: 0.3546  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.5054  decode.d1.loss_mask: 0.3652  decode.d1.loss_dice: 0.2949  decode.d2.loss_cls: 0.4646  decode.d2.loss_mask: 0.3704  decode.d2.loss_dice: 0.2793  decode.d3.loss_cls: 0.4722  decode.d3.loss_mask: 0.3684  decode.d3.loss_dice: 0.2914  decode.d4.loss_cls: 0.4459  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.2593  decode.d5.loss_cls: 0.5001  decode.d5.loss_mask: 0.3689  decode.d5.loss_dice: 0.2794  decode.d6.loss_cls: 0.4639  decode.d6.loss_mask: 0.3651  decode.d6.loss_dice: 0.2709  decode.d7.loss_cls: 0.4893  decode.d7.loss_mask: 0.3896  decode.d7.loss_dice: 0.3050  decode.d8.loss_cls: 0.4749  decode.d8.loss_mask: 0.3601  decode.d8.loss_dice: 0.2806
09/28 14:55:33 - mmengine - INFO - Iter(train) [  3500/320000]  base_lr: 9.9015e-05 lr: 9.9015e-06  eta: 1 day, 18:35:11  time: 0.4838  data_time: 0.0100  memory: 5800  grad_norm: 295.0023  loss: 15.4022  decode.loss_cls: 0.5724  decode.loss_mask: 0.5360  decode.loss_dice: 0.3667  decode.d0.loss_cls: 1.3525  decode.d0.loss_mask: 0.4557  decode.d0.loss_dice: 0.3715  decode.d1.loss_cls: 0.5904  decode.d1.loss_mask: 0.4906  decode.d1.loss_dice: 0.3767  decode.d2.loss_cls: 0.6019  decode.d2.loss_mask: 0.4764  decode.d2.loss_dice: 0.3578  decode.d3.loss_cls: 0.6269  decode.d3.loss_mask: 0.4583  decode.d3.loss_dice: 0.3686  decode.d4.loss_cls: 0.5713  decode.d4.loss_mask: 0.4919  decode.d4.loss_dice: 0.3840  decode.d5.loss_cls: 0.6166  decode.d5.loss_mask: 0.4865  decode.d5.loss_dice: 0.3648  decode.d6.loss_cls: 0.6345  decode.d6.loss_mask: 0.4622  decode.d6.loss_dice: 0.3417  decode.d7.loss_cls: 0.6896  decode.d7.loss_mask: 0.4944  decode.d7.loss_dice: 0.3567  decode.d8.loss_cls: 0.5921  decode.d8.loss_mask: 0.5340  decode.d8.loss_dice: 0.3793
09/28 14:55:57 - mmengine - INFO - Iter(train) [  3550/320000]  base_lr: 9.9001e-05 lr: 9.9001e-06  eta: 1 day, 18:34:48  time: 0.4852  data_time: 0.0103  memory: 5817  grad_norm: 268.1069  loss: 14.3885  decode.loss_cls: 0.5115  decode.loss_mask: 0.4717  decode.loss_dice: 0.4054  decode.d0.loss_cls: 1.1896  decode.d0.loss_mask: 0.4781  decode.d0.loss_dice: 0.3964  decode.d1.loss_cls: 0.5231  decode.d1.loss_mask: 0.4960  decode.d1.loss_dice: 0.3619  decode.d2.loss_cls: 0.4858  decode.d2.loss_mask: 0.4750  decode.d2.loss_dice: 0.3602  decode.d3.loss_cls: 0.5492  decode.d3.loss_mask: 0.4507  decode.d3.loss_dice: 0.3509  decode.d4.loss_cls: 0.4807  decode.d4.loss_mask: 0.4893  decode.d4.loss_dice: 0.3704  decode.d5.loss_cls: 0.4521  decode.d5.loss_mask: 0.5029  decode.d5.loss_dice: 0.3932  decode.d6.loss_cls: 0.5406  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 0.3906  decode.d7.loss_cls: 0.5870  decode.d7.loss_mask: 0.4390  decode.d7.loss_dice: 0.3722  decode.d8.loss_cls: 0.5685  decode.d8.loss_mask: 0.4452  decode.d8.loss_dice: 0.4005
09/28 14:56:21 - mmengine - INFO - Iter(train) [  3600/320000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 1 day, 18:34:23  time: 0.4838  data_time: 0.0102  memory: 5834  grad_norm: 244.5625  loss: 11.7031  decode.loss_cls: 0.3747  decode.loss_mask: 0.3609  decode.loss_dice: 0.2988  decode.d0.loss_cls: 1.2374  decode.d0.loss_mask: 0.3492  decode.d0.loss_dice: 0.3176  decode.d1.loss_cls: 0.4858  decode.d1.loss_mask: 0.3564  decode.d1.loss_dice: 0.3015  decode.d2.loss_cls: 0.3823  decode.d2.loss_mask: 0.3607  decode.d2.loss_dice: 0.3131  decode.d3.loss_cls: 0.4854  decode.d3.loss_mask: 0.3484  decode.d3.loss_dice: 0.2891  decode.d4.loss_cls: 0.4757  decode.d4.loss_mask: 0.3476  decode.d4.loss_dice: 0.3001  decode.d5.loss_cls: 0.4186  decode.d5.loss_mask: 0.3607  decode.d5.loss_dice: 0.2968  decode.d6.loss_cls: 0.4871  decode.d6.loss_mask: 0.3352  decode.d6.loss_dice: 0.2788  decode.d7.loss_cls: 0.4828  decode.d7.loss_mask: 0.3294  decode.d7.loss_dice: 0.2673  decode.d8.loss_cls: 0.3947  decode.d8.loss_mask: 0.3570  decode.d8.loss_dice: 0.3098
09/28 14:56:45 - mmengine - INFO - Iter(train) [  3650/320000]  base_lr: 9.8973e-05 lr: 9.8973e-06  eta: 1 day, 18:33:58  time: 0.4835  data_time: 0.0100  memory: 5816  grad_norm: 241.9924  loss: 15.8680  decode.loss_cls: 0.6308  decode.loss_mask: 0.4491  decode.loss_dice: 0.4440  decode.d0.loss_cls: 1.3628  decode.d0.loss_mask: 0.4498  decode.d0.loss_dice: 0.4720  decode.d1.loss_cls: 0.6905  decode.d1.loss_mask: 0.4345  decode.d1.loss_dice: 0.4454  decode.d2.loss_cls: 0.5836  decode.d2.loss_mask: 0.4081  decode.d2.loss_dice: 0.4405  decode.d3.loss_cls: 0.6516  decode.d3.loss_mask: 0.4312  decode.d3.loss_dice: 0.4189  decode.d4.loss_cls: 0.6421  decode.d4.loss_mask: 0.4283  decode.d4.loss_dice: 0.4240  decode.d5.loss_cls: 0.6173  decode.d5.loss_mask: 0.4309  decode.d5.loss_dice: 0.4737  decode.d6.loss_cls: 0.6555  decode.d6.loss_mask: 0.4237  decode.d6.loss_dice: 0.4424  decode.d7.loss_cls: 0.6402  decode.d7.loss_mask: 0.4227  decode.d7.loss_dice: 0.4558  decode.d8.loss_cls: 0.6370  decode.d8.loss_mask: 0.4251  decode.d8.loss_dice: 0.4366
09/28 14:57:09 - mmengine - INFO - Iter(train) [  3700/320000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 1 day, 18:33:30  time: 0.4842  data_time: 0.0100  memory: 5817  grad_norm: 239.6599  loss: 10.8867  decode.loss_cls: 0.5148  decode.loss_mask: 0.2847  decode.loss_dice: 0.2145  decode.d0.loss_cls: 1.1959  decode.d0.loss_mask: 0.2919  decode.d0.loss_dice: 0.2660  decode.d1.loss_cls: 0.5465  decode.d1.loss_mask: 0.2951  decode.d1.loss_dice: 0.2383  decode.d2.loss_cls: 0.4809  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.2295  decode.d3.loss_cls: 0.4562  decode.d3.loss_mask: 0.2778  decode.d3.loss_dice: 0.2220  decode.d4.loss_cls: 0.5149  decode.d4.loss_mask: 0.2769  decode.d4.loss_dice: 0.2196  decode.d5.loss_cls: 0.4886  decode.d5.loss_mask: 0.2897  decode.d5.loss_dice: 0.2214  decode.d6.loss_cls: 0.4904  decode.d6.loss_mask: 0.2813  decode.d6.loss_dice: 0.2133  decode.d7.loss_cls: 0.5327  decode.d7.loss_mask: 0.2839  decode.d7.loss_dice: 0.2248  decode.d8.loss_cls: 0.5434  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2225
09/28 14:57:34 - mmengine - INFO - Iter(train) [  3750/320000]  base_lr: 9.8945e-05 lr: 9.8945e-06  eta: 1 day, 18:33:00  time: 0.4819  data_time: 0.0096  memory: 5834  grad_norm: 217.3508  loss: 11.5393  decode.loss_cls: 0.3719  decode.loss_mask: 0.2899  decode.loss_dice: 0.3851  decode.d0.loss_cls: 1.1243  decode.d0.loss_mask: 0.2899  decode.d0.loss_dice: 0.4204  decode.d1.loss_cls: 0.4841  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.4003  decode.d2.loss_cls: 0.3882  decode.d2.loss_mask: 0.2940  decode.d2.loss_dice: 0.3747  decode.d3.loss_cls: 0.3804  decode.d3.loss_mask: 0.2919  decode.d3.loss_dice: 0.3653  decode.d4.loss_cls: 0.3886  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.3643  decode.d5.loss_cls: 0.4061  decode.d5.loss_mask: 0.2919  decode.d5.loss_dice: 0.3601  decode.d6.loss_cls: 0.4423  decode.d6.loss_mask: 0.2914  decode.d6.loss_dice: 0.3781  decode.d7.loss_cls: 0.4203  decode.d7.loss_mask: 0.2880  decode.d7.loss_dice: 0.3599  decode.d8.loss_cls: 0.4060  decode.d8.loss_mask: 0.2939  decode.d8.loss_dice: 0.4093
09/28 14:57:58 - mmengine - INFO - Iter(train) [  3800/320000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 1 day, 18:32:33  time: 0.4843  data_time: 0.0100  memory: 5816  grad_norm: 93.3649  loss: 9.1920  decode.loss_cls: 0.3434  decode.loss_mask: 0.2483  decode.loss_dice: 0.2592  decode.d0.loss_cls: 1.2171  decode.d0.loss_mask: 0.2472  decode.d0.loss_dice: 0.2569  decode.d1.loss_cls: 0.3901  decode.d1.loss_mask: 0.2643  decode.d1.loss_dice: 0.2859  decode.d2.loss_cls: 0.2548  decode.d2.loss_mask: 0.2616  decode.d2.loss_dice: 0.2823  decode.d3.loss_cls: 0.2387  decode.d3.loss_mask: 0.2653  decode.d3.loss_dice: 0.2994  decode.d4.loss_cls: 0.2598  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.2956  decode.d5.loss_cls: 0.2743  decode.d5.loss_mask: 0.2572  decode.d5.loss_dice: 0.2650  decode.d6.loss_cls: 0.3177  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.2777  decode.d7.loss_cls: 0.2961  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.2613  decode.d8.loss_cls: 0.2849  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.2734
09/28 14:58:22 - mmengine - INFO - Iter(train) [  3850/320000]  base_lr: 9.8917e-05 lr: 9.8917e-06  eta: 1 day, 18:32:03  time: 0.4834  data_time: 0.0095  memory: 5817  grad_norm: 136.5507  loss: 11.7252  decode.loss_cls: 0.4031  decode.loss_mask: 0.3077  decode.loss_dice: 0.3642  decode.d0.loss_cls: 1.3281  decode.d0.loss_mask: 0.2800  decode.d0.loss_dice: 0.3678  decode.d1.loss_cls: 0.4559  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.3562  decode.d2.loss_cls: 0.4419  decode.d2.loss_mask: 0.2898  decode.d2.loss_dice: 0.3356  decode.d3.loss_cls: 0.4432  decode.d3.loss_mask: 0.2833  decode.d3.loss_dice: 0.3147  decode.d4.loss_cls: 0.4243  decode.d4.loss_mask: 0.2811  decode.d4.loss_dice: 0.3163  decode.d5.loss_cls: 0.4839  decode.d5.loss_mask: 0.2782  decode.d5.loss_dice: 0.3231  decode.d6.loss_cls: 0.5084  decode.d6.loss_mask: 0.2835  decode.d6.loss_dice: 0.3379  decode.d7.loss_cls: 0.4812  decode.d7.loss_mask: 0.2805  decode.d7.loss_dice: 0.3365  decode.d8.loss_cls: 0.4958  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.3404
09/28 14:58:46 - mmengine - INFO - Iter(train) [  3900/320000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 1 day, 18:31:38  time: 0.4837  data_time: 0.0100  memory: 5847  grad_norm: 284.3261  loss: 15.4801  decode.loss_cls: 0.7000  decode.loss_mask: 0.3998  decode.loss_dice: 0.4132  decode.d0.loss_cls: 1.4837  decode.d0.loss_mask: 0.3799  decode.d0.loss_dice: 0.4027  decode.d1.loss_cls: 0.7479  decode.d1.loss_mask: 0.4648  decode.d1.loss_dice: 0.4069  decode.d2.loss_cls: 0.7257  decode.d2.loss_mask: 0.3744  decode.d2.loss_dice: 0.4206  decode.d3.loss_cls: 0.5987  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.3854  decode.d4.loss_cls: 0.6217  decode.d4.loss_mask: 0.3755  decode.d4.loss_dice: 0.3865  decode.d5.loss_cls: 0.6364  decode.d5.loss_mask: 0.3783  decode.d5.loss_dice: 0.3979  decode.d6.loss_cls: 0.7198  decode.d6.loss_mask: 0.3783  decode.d6.loss_dice: 0.3796  decode.d7.loss_cls: 0.6791  decode.d7.loss_mask: 0.3830  decode.d7.loss_dice: 0.3981  decode.d8.loss_cls: 0.6963  decode.d8.loss_mask: 0.3787  decode.d8.loss_dice: 0.3897
09/28 14:59:10 - mmengine - INFO - Iter(train) [  3950/320000]  base_lr: 9.8889e-05 lr: 9.8889e-06  eta: 1 day, 18:31:17  time: 0.4833  data_time: 0.0099  memory: 5835  grad_norm: 436.6166  loss: 15.6551  decode.loss_cls: 0.6240  decode.loss_mask: 0.4724  decode.loss_dice: 0.4238  decode.d0.loss_cls: 1.5043  decode.d0.loss_mask: 0.4567  decode.d0.loss_dice: 0.4142  decode.d1.loss_cls: 0.5898  decode.d1.loss_mask: 0.4706  decode.d1.loss_dice: 0.4339  decode.d2.loss_cls: 0.5715  decode.d2.loss_mask: 0.4243  decode.d2.loss_dice: 0.3968  decode.d3.loss_cls: 0.5829  decode.d3.loss_mask: 0.4188  decode.d3.loss_dice: 0.3799  decode.d4.loss_cls: 0.5879  decode.d4.loss_mask: 0.4230  decode.d4.loss_dice: 0.3687  decode.d5.loss_cls: 0.7330  decode.d5.loss_mask: 0.4473  decode.d5.loss_dice: 0.4474  decode.d6.loss_cls: 0.6666  decode.d6.loss_mask: 0.4283  decode.d6.loss_dice: 0.3889  decode.d7.loss_cls: 0.6369  decode.d7.loss_mask: 0.4133  decode.d7.loss_dice: 0.3802  decode.d8.loss_cls: 0.6455  decode.d8.loss_mask: 0.4868  decode.d8.loss_dice: 0.4374
09/28 14:59:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 14:59:35 - mmengine - INFO - Iter(train) [  4000/320000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 1 day, 18:30:50  time: 0.4841  data_time: 0.0098  memory: 5834  grad_norm: 245.9165  loss: 10.9904  decode.loss_cls: 0.3426  decode.loss_mask: 0.3341  decode.loss_dice: 0.3214  decode.d0.loss_cls: 1.0792  decode.d0.loss_mask: 0.3292  decode.d0.loss_dice: 0.3076  decode.d1.loss_cls: 0.4208  decode.d1.loss_mask: 0.3653  decode.d1.loss_dice: 0.3112  decode.d2.loss_cls: 0.3749  decode.d2.loss_mask: 0.3555  decode.d2.loss_dice: 0.3187  decode.d3.loss_cls: 0.3631  decode.d3.loss_mask: 0.3391  decode.d3.loss_dice: 0.3099  decode.d4.loss_cls: 0.3420  decode.d4.loss_mask: 0.3545  decode.d4.loss_dice: 0.3134  decode.d5.loss_cls: 0.3895  decode.d5.loss_mask: 0.3460  decode.d5.loss_dice: 0.3081  decode.d6.loss_cls: 0.3390  decode.d6.loss_mask: 0.3755  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.3980  decode.d7.loss_mask: 0.3535  decode.d7.loss_dice: 0.2961  decode.d8.loss_cls: 0.3522  decode.d8.loss_mask: 0.3519  decode.d8.loss_dice: 0.3077
09/28 14:59:59 - mmengine - INFO - Iter(train) [  4050/320000]  base_lr: 9.8860e-05 lr: 9.8860e-06  eta: 1 day, 18:30:24  time: 0.4839  data_time: 0.0101  memory: 5817  grad_norm: 455.0940  loss: 16.0173  decode.loss_cls: 0.6190  decode.loss_mask: 0.4670  decode.loss_dice: 0.3608  decode.d0.loss_cls: 1.3796  decode.d0.loss_mask: 0.4356  decode.d0.loss_dice: 0.3996  decode.d1.loss_cls: 0.7842  decode.d1.loss_mask: 0.4185  decode.d1.loss_dice: 0.3361  decode.d2.loss_cls: 0.6211  decode.d2.loss_mask: 0.4715  decode.d2.loss_dice: 0.3340  decode.d3.loss_cls: 0.6562  decode.d3.loss_mask: 0.4771  decode.d3.loss_dice: 0.3527  decode.d4.loss_cls: 0.7196  decode.d4.loss_mask: 0.4529  decode.d4.loss_dice: 0.3456  decode.d5.loss_cls: 0.7748  decode.d5.loss_mask: 0.4372  decode.d5.loss_dice: 0.3336  decode.d6.loss_cls: 0.7292  decode.d6.loss_mask: 0.4728  decode.d6.loss_dice: 0.3949  decode.d7.loss_cls: 0.8182  decode.d7.loss_mask: 0.4636  decode.d7.loss_dice: 0.3921  decode.d8.loss_cls: 0.6885  decode.d8.loss_mask: 0.4731  decode.d8.loss_dice: 0.4083
09/28 15:00:23 - mmengine - INFO - Iter(train) [  4100/320000]  base_lr: 9.8846e-05 lr: 9.8846e-06  eta: 1 day, 18:30:00  time: 0.4842  data_time: 0.0100  memory: 5835  grad_norm: 163.0820  loss: 11.2350  decode.loss_cls: 0.4403  decode.loss_mask: 0.3914  decode.loss_dice: 0.2571  decode.d0.loss_cls: 1.4064  decode.d0.loss_mask: 0.3498  decode.d0.loss_dice: 0.3136  decode.d1.loss_cls: 0.4418  decode.d1.loss_mask: 0.3739  decode.d1.loss_dice: 0.2998  decode.d2.loss_cls: 0.3826  decode.d2.loss_mask: 0.3357  decode.d2.loss_dice: 0.2950  decode.d3.loss_cls: 0.3457  decode.d3.loss_mask: 0.3580  decode.d3.loss_dice: 0.2599  decode.d4.loss_cls: 0.3508  decode.d4.loss_mask: 0.3451  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.3936  decode.d5.loss_mask: 0.3230  decode.d5.loss_dice: 0.3069  decode.d6.loss_cls: 0.4041  decode.d6.loss_mask: 0.3183  decode.d6.loss_dice: 0.2863  decode.d7.loss_cls: 0.3579  decode.d7.loss_mask: 0.3111  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.3969  decode.d8.loss_mask: 0.3508  decode.d8.loss_dice: 0.2813
09/28 15:00:47 - mmengine - INFO - Iter(train) [  4150/320000]  base_lr: 9.8832e-05 lr: 9.8832e-06  eta: 1 day, 18:29:35  time: 0.4837  data_time: 0.0101  memory: 5817  grad_norm: 188.3078  loss: 11.2786  decode.loss_cls: 0.3526  decode.loss_mask: 0.3813  decode.loss_dice: 0.2749  decode.d0.loss_cls: 1.2876  decode.d0.loss_mask: 0.3825  decode.d0.loss_dice: 0.2998  decode.d1.loss_cls: 0.4472  decode.d1.loss_mask: 0.4010  decode.d1.loss_dice: 0.3068  decode.d2.loss_cls: 0.3586  decode.d2.loss_mask: 0.3976  decode.d2.loss_dice: 0.3134  decode.d3.loss_cls: 0.2807  decode.d3.loss_mask: 0.4007  decode.d3.loss_dice: 0.3051  decode.d4.loss_cls: 0.3328  decode.d4.loss_mask: 0.3978  decode.d4.loss_dice: 0.2900  decode.d5.loss_cls: 0.2867  decode.d5.loss_mask: 0.4044  decode.d5.loss_dice: 0.2764  decode.d6.loss_cls: 0.3964  decode.d6.loss_mask: 0.3892  decode.d6.loss_dice: 0.2791  decode.d7.loss_cls: 0.3742  decode.d7.loss_mask: 0.3832  decode.d7.loss_dice: 0.2885  decode.d8.loss_cls: 0.3158  decode.d8.loss_mask: 0.3896  decode.d8.loss_dice: 0.2844
09/28 15:01:11 - mmengine - INFO - Iter(train) [  4200/320000]  base_lr: 9.8818e-05 lr: 9.8818e-06  eta: 1 day, 18:29:13  time: 0.4852  data_time: 0.0101  memory: 5816  grad_norm: 310.2395  loss: 10.0639  decode.loss_cls: 0.2602  decode.loss_mask: 0.3557  decode.loss_dice: 0.2752  decode.d0.loss_cls: 1.0866  decode.d0.loss_mask: 0.3550  decode.d0.loss_dice: 0.2937  decode.d1.loss_cls: 0.3454  decode.d1.loss_mask: 0.3553  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.2839  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.2818  decode.d3.loss_cls: 0.2358  decode.d3.loss_mask: 0.3587  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.2602  decode.d4.loss_mask: 0.3679  decode.d4.loss_dice: 0.2867  decode.d5.loss_cls: 0.3070  decode.d5.loss_mask: 0.3514  decode.d5.loss_dice: 0.2771  decode.d6.loss_cls: 0.3123  decode.d6.loss_mask: 0.3590  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.3281  decode.d7.loss_mask: 0.3511  decode.d7.loss_dice: 0.2588  decode.d8.loss_cls: 0.2692  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.3005
09/28 15:01:36 - mmengine - INFO - Iter(train) [  4250/320000]  base_lr: 9.8804e-05 lr: 9.8804e-06  eta: 1 day, 18:28:48  time: 0.4833  data_time: 0.0100  memory: 5817  grad_norm: 116.4412  loss: 11.6890  decode.loss_cls: 0.6058  decode.loss_mask: 0.2622  decode.loss_dice: 0.2501  decode.d0.loss_cls: 1.2698  decode.d0.loss_mask: 0.3067  decode.d0.loss_dice: 0.3093  decode.d1.loss_cls: 0.5213  decode.d1.loss_mask: 0.3080  decode.d1.loss_dice: 0.2680  decode.d2.loss_cls: 0.5441  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2619  decode.d3.loss_cls: 0.5116  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.2617  decode.d4.loss_cls: 0.5365  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2592  decode.d5.loss_cls: 0.5680  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.2755  decode.d6.loss_cls: 0.5179  decode.d6.loss_mask: 0.2798  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.5578  decode.d7.loss_mask: 0.2836  decode.d7.loss_dice: 0.2696  decode.d8.loss_cls: 0.5220  decode.d8.loss_mask: 0.2991  decode.d8.loss_dice: 0.2926
09/28 15:02:00 - mmengine - INFO - Iter(train) [  4300/320000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 1 day, 18:28:22  time: 0.4831  data_time: 0.0098  memory: 5819  grad_norm: 1198.7625  loss: 20.5845  decode.loss_cls: 0.7089  decode.loss_mask: 0.7370  decode.loss_dice: 0.5255  decode.d0.loss_cls: 1.2432  decode.d0.loss_mask: 0.6658  decode.d0.loss_dice: 0.5253  decode.d1.loss_cls: 0.8687  decode.d1.loss_mask: 0.5960  decode.d1.loss_dice: 0.5387  decode.d2.loss_cls: 0.8254  decode.d2.loss_mask: 0.6432  decode.d2.loss_dice: 0.5172  decode.d3.loss_cls: 0.7522  decode.d3.loss_mask: 0.6425  decode.d3.loss_dice: 0.5177  decode.d4.loss_cls: 0.8081  decode.d4.loss_mask: 0.7034  decode.d4.loss_dice: 0.5348  decode.d5.loss_cls: 0.7605  decode.d5.loss_mask: 0.6900  decode.d5.loss_dice: 0.5472  decode.d6.loss_cls: 0.7073  decode.d6.loss_mask: 0.7300  decode.d6.loss_dice: 0.5726  decode.d7.loss_cls: 0.8642  decode.d7.loss_mask: 0.6644  decode.d7.loss_dice: 0.5762  decode.d8.loss_cls: 0.6879  decode.d8.loss_mask: 0.8397  decode.d8.loss_dice: 0.5910
09/28 15:02:24 - mmengine - INFO - Iter(train) [  4350/320000]  base_lr: 9.8776e-05 lr: 9.8776e-06  eta: 1 day, 18:27:56  time: 0.4845  data_time: 0.0099  memory: 5800  grad_norm: 572.7242  loss: 18.0484  decode.loss_cls: 0.8612  decode.loss_mask: 0.4485  decode.loss_dice: 0.4157  decode.d0.loss_cls: 1.5996  decode.d0.loss_mask: 0.4465  decode.d0.loss_dice: 0.4330  decode.d1.loss_cls: 0.9077  decode.d1.loss_mask: 0.4385  decode.d1.loss_dice: 0.3847  decode.d2.loss_cls: 0.8639  decode.d2.loss_mask: 0.3990  decode.d2.loss_dice: 0.3690  decode.d3.loss_cls: 0.7871  decode.d3.loss_mask: 0.4097  decode.d3.loss_dice: 0.4004  decode.d4.loss_cls: 0.8264  decode.d4.loss_mask: 0.4650  decode.d4.loss_dice: 0.4315  decode.d5.loss_cls: 0.8872  decode.d5.loss_mask: 0.4603  decode.d5.loss_dice: 0.4314  decode.d6.loss_cls: 0.9363  decode.d6.loss_mask: 0.4426  decode.d6.loss_dice: 0.3879  decode.d7.loss_cls: 0.9761  decode.d7.loss_mask: 0.4516  decode.d7.loss_dice: 0.3990  decode.d8.loss_cls: 0.9739  decode.d8.loss_mask: 0.4192  decode.d8.loss_dice: 0.3954
09/28 15:02:48 - mmengine - INFO - Iter(train) [  4400/320000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 1 day, 18:27:30  time: 0.4836  data_time: 0.0100  memory: 5817  grad_norm: 244.1005  loss: 12.2554  decode.loss_cls: 0.4696  decode.loss_mask: 0.3099  decode.loss_dice: 0.3070  decode.d0.loss_cls: 1.2580  decode.d0.loss_mask: 0.3284  decode.d0.loss_dice: 0.3136  decode.d1.loss_cls: 0.4782  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.3129  decode.d2.loss_cls: 0.3856  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.4342  decode.d3.loss_mask: 0.3382  decode.d3.loss_dice: 0.3155  decode.d4.loss_cls: 0.5485  decode.d4.loss_mask: 0.3175  decode.d4.loss_dice: 0.3158  decode.d5.loss_cls: 0.4982  decode.d5.loss_mask: 0.3680  decode.d5.loss_dice: 0.3535  decode.d6.loss_cls: 0.4984  decode.d6.loss_mask: 0.3505  decode.d6.loss_dice: 0.3710  decode.d7.loss_cls: 0.5237  decode.d7.loss_mask: 0.3555  decode.d7.loss_dice: 0.3560  decode.d8.loss_cls: 0.5298  decode.d8.loss_mask: 0.3368  decode.d8.loss_dice: 0.3394
09/28 15:03:13 - mmengine - INFO - Iter(train) [  4450/320000]  base_lr: 9.8748e-05 lr: 9.8748e-06  eta: 1 day, 18:27:12  time: 0.4934  data_time: 0.0101  memory: 5816  grad_norm: 497.1294  loss: 14.9131  decode.loss_cls: 0.5108  decode.loss_mask: 0.5542  decode.loss_dice: 0.3812  decode.d0.loss_cls: 1.0954  decode.d0.loss_mask: 0.5982  decode.d0.loss_dice: 0.4092  decode.d1.loss_cls: 0.6225  decode.d1.loss_mask: 0.5265  decode.d1.loss_dice: 0.3820  decode.d2.loss_cls: 0.5001  decode.d2.loss_mask: 0.5173  decode.d2.loss_dice: 0.3635  decode.d3.loss_cls: 0.4385  decode.d3.loss_mask: 0.5505  decode.d3.loss_dice: 0.3742  decode.d4.loss_cls: 0.5083  decode.d4.loss_mask: 0.5083  decode.d4.loss_dice: 0.3655  decode.d5.loss_cls: 0.5233  decode.d5.loss_mask: 0.5566  decode.d5.loss_dice: 0.3743  decode.d6.loss_cls: 0.5160  decode.d6.loss_mask: 0.5493  decode.d6.loss_dice: 0.3751  decode.d7.loss_cls: 0.4736  decode.d7.loss_mask: 0.5732  decode.d7.loss_dice: 0.3958  decode.d8.loss_cls: 0.4363  decode.d8.loss_mask: 0.5400  decode.d8.loss_dice: 0.3934
09/28 15:03:37 - mmengine - INFO - Iter(train) [  4500/320000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 1 day, 18:26:46  time: 0.4847  data_time: 0.0101  memory: 5816  grad_norm: 126.1459  loss: 10.1491  decode.loss_cls: 0.2764  decode.loss_mask: 0.3269  decode.loss_dice: 0.2680  decode.d0.loss_cls: 1.1197  decode.d0.loss_mask: 0.2971  decode.d0.loss_dice: 0.2559  decode.d1.loss_cls: 0.3434  decode.d1.loss_mask: 0.3223  decode.d1.loss_dice: 0.2629  decode.d2.loss_cls: 0.2667  decode.d2.loss_mask: 0.3494  decode.d2.loss_dice: 0.2854  decode.d3.loss_cls: 0.3368  decode.d3.loss_mask: 0.3004  decode.d3.loss_dice: 0.2601  decode.d4.loss_cls: 0.3469  decode.d4.loss_mask: 0.3515  decode.d4.loss_dice: 0.2928  decode.d5.loss_cls: 0.3073  decode.d5.loss_mask: 0.4173  decode.d5.loss_dice: 0.2837  decode.d6.loss_cls: 0.3630  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.2635  decode.d7.loss_cls: 0.3754  decode.d7.loss_mask: 0.3108  decode.d7.loss_dice: 0.2678  decode.d8.loss_cls: 0.3019  decode.d8.loss_mask: 0.3834  decode.d8.loss_dice: 0.2854
09/28 15:04:01 - mmengine - INFO - Iter(train) [  4550/320000]  base_lr: 9.8720e-05 lr: 9.8720e-06  eta: 1 day, 18:26:18  time: 0.4831  data_time: 0.0098  memory: 5817  grad_norm: 150.8196  loss: 12.1982  decode.loss_cls: 0.4689  decode.loss_mask: 0.4019  decode.loss_dice: 0.3457  decode.d0.loss_cls: 1.4064  decode.d0.loss_mask: 0.3984  decode.d0.loss_dice: 0.2994  decode.d1.loss_cls: 0.4363  decode.d1.loss_mask: 0.4308  decode.d1.loss_dice: 0.3388  decode.d2.loss_cls: 0.4050  decode.d2.loss_mask: 0.4077  decode.d2.loss_dice: 0.3028  decode.d3.loss_cls: 0.3690  decode.d3.loss_mask: 0.3837  decode.d3.loss_dice: 0.2897  decode.d4.loss_cls: 0.3939  decode.d4.loss_mask: 0.3807  decode.d4.loss_dice: 0.2886  decode.d5.loss_cls: 0.4376  decode.d5.loss_mask: 0.3870  decode.d5.loss_dice: 0.2837  decode.d6.loss_cls: 0.4244  decode.d6.loss_mask: 0.3835  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.4508  decode.d7.loss_mask: 0.3794  decode.d7.loss_dice: 0.2856  decode.d8.loss_cls: 0.4534  decode.d8.loss_mask: 0.3811  decode.d8.loss_dice: 0.2952
09/28 15:04:25 - mmengine - INFO - Iter(train) [  4600/320000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 1 day, 18:25:49  time: 0.4821  data_time: 0.0098  memory: 5817  grad_norm: 275.4139  loss: 12.8536  decode.loss_cls: 0.4864  decode.loss_mask: 0.4597  decode.loss_dice: 0.3414  decode.d0.loss_cls: 1.2569  decode.d0.loss_mask: 0.4207  decode.d0.loss_dice: 0.2818  decode.d1.loss_cls: 0.4332  decode.d1.loss_mask: 0.4440  decode.d1.loss_dice: 0.3075  decode.d2.loss_cls: 0.5118  decode.d2.loss_mask: 0.4022  decode.d2.loss_dice: 0.3025  decode.d3.loss_cls: 0.4347  decode.d3.loss_mask: 0.4151  decode.d3.loss_dice: 0.3198  decode.d4.loss_cls: 0.4784  decode.d4.loss_mask: 0.4217  decode.d4.loss_dice: 0.3127  decode.d5.loss_cls: 0.3909  decode.d5.loss_mask: 0.4311  decode.d5.loss_dice: 0.3484  decode.d6.loss_cls: 0.5330  decode.d6.loss_mask: 0.4142  decode.d6.loss_dice: 0.3265  decode.d7.loss_cls: 0.4188  decode.d7.loss_mask: 0.4425  decode.d7.loss_dice: 0.3505  decode.d8.loss_cls: 0.3930  decode.d8.loss_mask: 0.4377  decode.d8.loss_dice: 0.3362
09/28 15:04:49 - mmengine - INFO - Iter(train) [  4650/320000]  base_lr: 9.8692e-05 lr: 9.8692e-06  eta: 1 day, 18:25:22  time: 0.4835  data_time: 0.0097  memory: 5816  grad_norm: 156.6326  loss: 12.9353  decode.loss_cls: 0.3982  decode.loss_mask: 0.4122  decode.loss_dice: 0.3704  decode.d0.loss_cls: 1.2331  decode.d0.loss_mask: 0.4113  decode.d0.loss_dice: 0.3636  decode.d1.loss_cls: 0.4301  decode.d1.loss_mask: 0.4386  decode.d1.loss_dice: 0.3739  decode.d2.loss_cls: 0.4773  decode.d2.loss_mask: 0.4221  decode.d2.loss_dice: 0.3619  decode.d3.loss_cls: 0.3984  decode.d3.loss_mask: 0.4120  decode.d3.loss_dice: 0.3646  decode.d4.loss_cls: 0.3239  decode.d4.loss_mask: 0.4434  decode.d4.loss_dice: 0.4306  decode.d5.loss_cls: 0.4590  decode.d5.loss_mask: 0.4098  decode.d5.loss_dice: 0.3422  decode.d6.loss_cls: 0.4934  decode.d6.loss_mask: 0.4099  decode.d6.loss_dice: 0.3674  decode.d7.loss_cls: 0.3843  decode.d7.loss_mask: 0.4250  decode.d7.loss_dice: 0.3799  decode.d8.loss_cls: 0.4248  decode.d8.loss_mask: 0.4133  decode.d8.loss_dice: 0.3606
09/28 15:05:13 - mmengine - INFO - Iter(train) [  4700/320000]  base_lr: 9.8677e-05 lr: 9.8677e-06  eta: 1 day, 18:24:55  time: 0.4843  data_time: 0.0101  memory: 5817  grad_norm: 195.3564  loss: 13.2580  decode.loss_cls: 0.6100  decode.loss_mask: 0.2808  decode.loss_dice: 0.3294  decode.d0.loss_cls: 1.3152  decode.d0.loss_mask: 0.2857  decode.d0.loss_dice: 0.3430  decode.d1.loss_cls: 0.6574  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.3320  decode.d2.loss_cls: 0.5841  decode.d2.loss_mask: 0.2944  decode.d2.loss_dice: 0.3145  decode.d3.loss_cls: 0.6303  decode.d3.loss_mask: 0.3015  decode.d3.loss_dice: 0.3408  decode.d4.loss_cls: 0.6489  decode.d4.loss_mask: 0.2887  decode.d4.loss_dice: 0.3196  decode.d5.loss_cls: 0.6566  decode.d5.loss_mask: 0.2906  decode.d5.loss_dice: 0.3240  decode.d6.loss_cls: 0.6690  decode.d6.loss_mask: 0.2966  decode.d6.loss_dice: 0.3247  decode.d7.loss_cls: 0.5935  decode.d7.loss_mask: 0.3228  decode.d7.loss_dice: 0.3369  decode.d8.loss_cls: 0.6165  decode.d8.loss_mask: 0.3094  decode.d8.loss_dice: 0.3340
09/28 15:05:38 - mmengine - INFO - Iter(train) [  4750/320000]  base_lr: 9.8663e-05 lr: 9.8663e-06  eta: 1 day, 18:24:40  time: 0.4994  data_time: 0.0097  memory: 5834  grad_norm: 137.3960  loss: 11.5106  decode.loss_cls: 0.4162  decode.loss_mask: 0.3081  decode.loss_dice: 0.3036  decode.d0.loss_cls: 1.4760  decode.d0.loss_mask: 0.2970  decode.d0.loss_dice: 0.2908  decode.d1.loss_cls: 0.5567  decode.d1.loss_mask: 0.2932  decode.d1.loss_dice: 0.2965  decode.d2.loss_cls: 0.4774  decode.d2.loss_mask: 0.2780  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.4646  decode.d3.loss_mask: 0.2795  decode.d3.loss_dice: 0.2705  decode.d4.loss_cls: 0.4584  decode.d4.loss_mask: 0.2915  decode.d4.loss_dice: 0.3138  decode.d5.loss_cls: 0.4524  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3012  decode.d6.loss_cls: 0.5134  decode.d6.loss_mask: 0.2754  decode.d6.loss_dice: 0.2780  decode.d7.loss_cls: 0.4406  decode.d7.loss_mask: 0.3079  decode.d7.loss_dice: 0.2822  decode.d8.loss_cls: 0.4100  decode.d8.loss_mask: 0.3116  decode.d8.loss_dice: 0.3227
09/28 15:06:02 - mmengine - INFO - Iter(train) [  4800/320000]  base_lr: 9.8649e-05 lr: 9.8649e-06  eta: 1 day, 18:24:13  time: 0.4836  data_time: 0.0098  memory: 5799  grad_norm: 111.6193  loss: 8.1027  decode.loss_cls: 0.0932  decode.loss_mask: 0.2808  decode.loss_dice: 0.2976  decode.d0.loss_cls: 0.9846  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.3144  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.1932  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.3056  decode.d3.loss_cls: 0.1716  decode.d3.loss_mask: 0.2759  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.1224  decode.d4.loss_mask: 0.2814  decode.d4.loss_dice: 0.3110  decode.d5.loss_cls: 0.1267  decode.d5.loss_mask: 0.2727  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.1359  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.2935  decode.d7.loss_cls: 0.1342  decode.d7.loss_mask: 0.2745  decode.d7.loss_dice: 0.2865  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 0.2818  decode.d8.loss_dice: 0.2952
09/28 15:06:26 - mmengine - INFO - Iter(train) [  4850/320000]  base_lr: 9.8635e-05 lr: 9.8635e-06  eta: 1 day, 18:23:47  time: 0.4838  data_time: 0.0100  memory: 5817  grad_norm: 237.9016  loss: 13.5836  decode.loss_cls: 0.4476  decode.loss_mask: 0.4027  decode.loss_dice: 0.3676  decode.d0.loss_cls: 1.3969  decode.d0.loss_mask: 0.3969  decode.d0.loss_dice: 0.3569  decode.d1.loss_cls: 0.6260  decode.d1.loss_mask: 0.4156  decode.d1.loss_dice: 0.3675  decode.d2.loss_cls: 0.5079  decode.d2.loss_mask: 0.4324  decode.d2.loss_dice: 0.3967  decode.d3.loss_cls: 0.4442  decode.d3.loss_mask: 0.4174  decode.d3.loss_dice: 0.3764  decode.d4.loss_cls: 0.4831  decode.d4.loss_mask: 0.3983  decode.d4.loss_dice: 0.3748  decode.d5.loss_cls: 0.4617  decode.d5.loss_mask: 0.3990  decode.d5.loss_dice: 0.3616  decode.d6.loss_cls: 0.4841  decode.d6.loss_mask: 0.3887  decode.d6.loss_dice: 0.3567  decode.d7.loss_cls: 0.4461  decode.d7.loss_mask: 0.4175  decode.d7.loss_dice: 0.4099  decode.d8.loss_cls: 0.4252  decode.d8.loss_mask: 0.4244  decode.d8.loss_dice: 0.3998
09/28 15:06:50 - mmengine - INFO - Iter(train) [  4900/320000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 1 day, 18:23:21  time: 0.4840  data_time: 0.0099  memory: 5835  grad_norm: 766.9891  loss: 14.9063  decode.loss_cls: 0.6159  decode.loss_mask: 0.3936  decode.loss_dice: 0.3737  decode.d0.loss_cls: 1.3790  decode.d0.loss_mask: 0.3685  decode.d0.loss_dice: 0.3878  decode.d1.loss_cls: 0.6568  decode.d1.loss_mask: 0.3324  decode.d1.loss_dice: 0.3728  decode.d2.loss_cls: 0.5833  decode.d2.loss_mask: 0.3802  decode.d2.loss_dice: 0.3743  decode.d3.loss_cls: 0.6473  decode.d3.loss_mask: 0.4297  decode.d3.loss_dice: 0.3718  decode.d4.loss_cls: 0.6433  decode.d4.loss_mask: 0.4290  decode.d4.loss_dice: 0.3838  decode.d5.loss_cls: 0.6432  decode.d5.loss_mask: 0.4269  decode.d5.loss_dice: 0.4208  decode.d6.loss_cls: 0.6461  decode.d6.loss_mask: 0.3969  decode.d6.loss_dice: 0.4128  decode.d7.loss_cls: 0.5598  decode.d7.loss_mask: 0.4554  decode.d7.loss_dice: 0.4194  decode.d8.loss_cls: 0.5917  decode.d8.loss_mask: 0.4202  decode.d8.loss_dice: 0.3897
09/28 15:07:15 - mmengine - INFO - Iter(train) [  4950/320000]  base_lr: 9.8607e-05 lr: 9.8607e-06  eta: 1 day, 18:22:55  time: 0.4839  data_time: 0.0097  memory: 5817  grad_norm: 388.7500  loss: 11.1446  decode.loss_cls: 0.2941  decode.loss_mask: 0.3609  decode.loss_dice: 0.3702  decode.d0.loss_cls: 1.1474  decode.d0.loss_mask: 0.3420  decode.d0.loss_dice: 0.3200  decode.d1.loss_cls: 0.3505  decode.d1.loss_mask: 0.3812  decode.d1.loss_dice: 0.3665  decode.d2.loss_cls: 0.2850  decode.d2.loss_mask: 0.3728  decode.d2.loss_dice: 0.3581  decode.d3.loss_cls: 0.2935  decode.d3.loss_mask: 0.3686  decode.d3.loss_dice: 0.3334  decode.d4.loss_cls: 0.2953  decode.d4.loss_mask: 0.3804  decode.d4.loss_dice: 0.3808  decode.d5.loss_cls: 0.2601  decode.d5.loss_mask: 0.3835  decode.d5.loss_dice: 0.3958  decode.d6.loss_cls: 0.2825  decode.d6.loss_mask: 0.3626  decode.d6.loss_dice: 0.3809  decode.d7.loss_cls: 0.2749  decode.d7.loss_mask: 0.3875  decode.d7.loss_dice: 0.4089  decode.d8.loss_cls: 0.3246  decode.d8.loss_mask: 0.3406  decode.d8.loss_dice: 0.3420
09/28 15:07:39 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:07:39 - mmengine - INFO - Iter(train) [  5000/320000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 1 day, 18:22:31  time: 0.4844  data_time: 0.0100  memory: 5819  grad_norm: 183.6079  loss: 13.1079  decode.loss_cls: 0.4200  decode.loss_mask: 0.3661  decode.loss_dice: 0.3507  decode.d0.loss_cls: 1.3527  decode.d0.loss_mask: 0.3801  decode.d0.loss_dice: 0.3645  decode.d1.loss_cls: 0.5108  decode.d1.loss_mask: 0.3524  decode.d1.loss_dice: 0.3549  decode.d2.loss_cls: 0.5072  decode.d2.loss_mask: 0.3508  decode.d2.loss_dice: 0.3503  decode.d3.loss_cls: 0.4908  decode.d3.loss_mask: 0.3524  decode.d3.loss_dice: 0.3639  decode.d4.loss_cls: 0.4946  decode.d4.loss_mask: 0.3650  decode.d4.loss_dice: 0.3451  decode.d5.loss_cls: 0.5200  decode.d5.loss_mask: 0.3654  decode.d5.loss_dice: 0.3767  decode.d6.loss_cls: 0.5246  decode.d6.loss_mask: 0.3614  decode.d6.loss_dice: 0.3504  decode.d7.loss_cls: 0.5612  decode.d7.loss_mask: 0.3664  decode.d7.loss_dice: 0.3862  decode.d8.loss_cls: 0.5020  decode.d8.loss_mask: 0.3610  decode.d8.loss_dice: 0.3602
09/28 15:08:03 - mmengine - INFO - Iter(train) [  5050/320000]  base_lr: 9.8579e-05 lr: 9.8579e-06  eta: 1 day, 18:22:06  time: 0.4836  data_time: 0.0098  memory: 5816  grad_norm: 260.5370  loss: 13.1533  decode.loss_cls: 0.5932  decode.loss_mask: 0.2806  decode.loss_dice: 0.3967  decode.d0.loss_cls: 1.1150  decode.d0.loss_mask: 0.2807  decode.d0.loss_dice: 0.3637  decode.d1.loss_cls: 0.4930  decode.d1.loss_mask: 0.2807  decode.d1.loss_dice: 0.4213  decode.d2.loss_cls: 0.5076  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.4075  decode.d3.loss_cls: 0.5641  decode.d3.loss_mask: 0.2705  decode.d3.loss_dice: 0.4069  decode.d4.loss_cls: 0.6095  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.4026  decode.d5.loss_cls: 0.6634  decode.d5.loss_mask: 0.2805  decode.d5.loss_dice: 0.4300  decode.d6.loss_cls: 0.6291  decode.d6.loss_mask: 0.2706  decode.d6.loss_dice: 0.4113  decode.d7.loss_cls: 0.5486  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.4134  decode.d8.loss_cls: 0.5253  decode.d8.loss_mask: 0.3195  decode.d8.loss_dice: 0.4533
09/28 15:08:27 - mmengine - INFO - Iter(train) [  5100/320000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 1 day, 18:21:39  time: 0.4837  data_time: 0.0101  memory: 5835  grad_norm: 382.9750  loss: 10.9112  decode.loss_cls: 0.4216  decode.loss_mask: 0.3702  decode.loss_dice: 0.2938  decode.d0.loss_cls: 1.2846  decode.d0.loss_mask: 0.3103  decode.d0.loss_dice: 0.2464  decode.d1.loss_cls: 0.4844  decode.d1.loss_mask: 0.3353  decode.d1.loss_dice: 0.2582  decode.d2.loss_cls: 0.4071  decode.d2.loss_mask: 0.3248  decode.d2.loss_dice: 0.2758  decode.d3.loss_cls: 0.3436  decode.d3.loss_mask: 0.3451  decode.d3.loss_dice: 0.2447  decode.d4.loss_cls: 0.3628  decode.d4.loss_mask: 0.3483  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.3664  decode.d5.loss_mask: 0.3956  decode.d5.loss_dice: 0.3130  decode.d6.loss_cls: 0.3491  decode.d6.loss_mask: 0.3526  decode.d6.loss_dice: 0.2812  decode.d7.loss_cls: 0.3401  decode.d7.loss_mask: 0.3385  decode.d7.loss_dice: 0.2842  decode.d8.loss_cls: 0.3814  decode.d8.loss_mask: 0.3337  decode.d8.loss_dice: 0.2345
09/28 15:08:51 - mmengine - INFO - Iter(train) [  5150/320000]  base_lr: 9.8551e-05 lr: 9.8551e-06  eta: 1 day, 18:21:15  time: 0.4841  data_time: 0.0101  memory: 5834  grad_norm: 297.8993  loss: 14.7399  decode.loss_cls: 0.5538  decode.loss_mask: 0.5057  decode.loss_dice: 0.4067  decode.d0.loss_cls: 1.4633  decode.d0.loss_mask: 0.3767  decode.d0.loss_dice: 0.3636  decode.d1.loss_cls: 0.6406  decode.d1.loss_mask: 0.3943  decode.d1.loss_dice: 0.3762  decode.d2.loss_cls: 0.6622  decode.d2.loss_mask: 0.3443  decode.d2.loss_dice: 0.3272  decode.d3.loss_cls: 0.6247  decode.d3.loss_mask: 0.3668  decode.d3.loss_dice: 0.3404  decode.d4.loss_cls: 0.6175  decode.d4.loss_mask: 0.4496  decode.d4.loss_dice: 0.3252  decode.d5.loss_cls: 0.5678  decode.d5.loss_mask: 0.4377  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.5865  decode.d6.loss_mask: 0.4394  decode.d6.loss_dice: 0.3605  decode.d7.loss_cls: 0.5423  decode.d7.loss_mask: 0.4584  decode.d7.loss_dice: 0.3950  decode.d8.loss_cls: 0.5354  decode.d8.loss_mask: 0.5428  decode.d8.loss_dice: 0.4097
09/28 15:09:16 - mmengine - INFO - Iter(train) [  5200/320000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 1 day, 18:20:51  time: 0.4853  data_time: 0.0099  memory: 5834  grad_norm: 366.1229  loss: 13.8286  decode.loss_cls: 0.5765  decode.loss_mask: 0.3747  decode.loss_dice: 0.3484  decode.d0.loss_cls: 1.2854  decode.d0.loss_mask: 0.4284  decode.d0.loss_dice: 0.4104  decode.d1.loss_cls: 0.5709  decode.d1.loss_mask: 0.3808  decode.d1.loss_dice: 0.3224  decode.d2.loss_cls: 0.5715  decode.d2.loss_mask: 0.3567  decode.d2.loss_dice: 0.3315  decode.d3.loss_cls: 0.5754  decode.d3.loss_mask: 0.3641  decode.d3.loss_dice: 0.3565  decode.d4.loss_cls: 0.5878  decode.d4.loss_mask: 0.3671  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 0.6185  decode.d5.loss_mask: 0.4602  decode.d5.loss_dice: 0.3502  decode.d6.loss_cls: 0.6435  decode.d6.loss_mask: 0.3889  decode.d6.loss_dice: 0.3027  decode.d7.loss_cls: 0.5931  decode.d7.loss_mask: 0.3511  decode.d7.loss_dice: 0.3019  decode.d8.loss_cls: 0.6051  decode.d8.loss_mask: 0.3563  decode.d8.loss_dice: 0.3326
09/28 15:09:40 - mmengine - INFO - Iter(train) [  5250/320000]  base_lr: 9.8522e-05 lr: 9.8522e-06  eta: 1 day, 18:20:24  time: 0.4841  data_time: 0.0098  memory: 5799  grad_norm: 97.8333  loss: 7.7894  decode.loss_cls: 0.2325  decode.loss_mask: 0.2208  decode.loss_dice: 0.2287  decode.d0.loss_cls: 1.3009  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2536  decode.d1.loss_cls: 0.2763  decode.d1.loss_mask: 0.2273  decode.d1.loss_dice: 0.2311  decode.d2.loss_cls: 0.1861  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2115  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 0.2207  decode.d3.loss_dice: 0.2072  decode.d4.loss_cls: 0.2056  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2227  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 0.2293  decode.d5.loss_dice: 0.2197  decode.d6.loss_cls: 0.2358  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2330  decode.d7.loss_cls: 0.2409  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.2400  decode.d8.loss_cls: 0.1997  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2289
09/28 15:10:04 - mmengine - INFO - Iter(train) [  5300/320000]  base_lr: 9.8508e-05 lr: 9.8508e-06  eta: 1 day, 18:19:58  time: 0.4827  data_time: 0.0099  memory: 5819  grad_norm: 213.7414  loss: 10.5249  decode.loss_cls: 0.3333  decode.loss_mask: 0.3851  decode.loss_dice: 0.2800  decode.d0.loss_cls: 1.0946  decode.d0.loss_mask: 0.3924  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.3380  decode.d1.loss_mask: 0.3945  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.2674  decode.d2.loss_mask: 0.4224  decode.d2.loss_dice: 0.2922  decode.d3.loss_cls: 0.2736  decode.d3.loss_mask: 0.4073  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.2676  decode.d4.loss_mask: 0.4159  decode.d4.loss_dice: 0.2723  decode.d5.loss_cls: 0.2700  decode.d5.loss_mask: 0.3840  decode.d5.loss_dice: 0.2773  decode.d6.loss_cls: 0.2589  decode.d6.loss_mask: 0.4107  decode.d6.loss_dice: 0.3023  decode.d7.loss_cls: 0.3024  decode.d7.loss_mask: 0.3912  decode.d7.loss_dice: 0.2809  decode.d8.loss_cls: 0.2917  decode.d8.loss_mask: 0.3977  decode.d8.loss_dice: 0.2919
09/28 15:10:28 - mmengine - INFO - Iter(train) [  5350/320000]  base_lr: 9.8494e-05 lr: 9.8494e-06  eta: 1 day, 18:19:37  time: 0.4930  data_time: 0.0099  memory: 5817  grad_norm: 146.9657  loss: 12.9279  decode.loss_cls: 0.4321  decode.loss_mask: 0.5731  decode.loss_dice: 0.3307  decode.d0.loss_cls: 1.1762  decode.d0.loss_mask: 0.3557  decode.d0.loss_dice: 0.3548  decode.d1.loss_cls: 0.5387  decode.d1.loss_mask: 0.3422  decode.d1.loss_dice: 0.3355  decode.d2.loss_cls: 0.4331  decode.d2.loss_mask: 0.3653  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.4137  decode.d3.loss_mask: 0.3457  decode.d3.loss_dice: 0.3435  decode.d4.loss_cls: 0.4058  decode.d4.loss_mask: 0.3495  decode.d4.loss_dice: 0.3418  decode.d5.loss_cls: 0.4287  decode.d5.loss_mask: 0.4796  decode.d5.loss_dice: 0.3477  decode.d6.loss_cls: 0.4286  decode.d6.loss_mask: 0.4797  decode.d6.loss_dice: 0.3441  decode.d7.loss_cls: 0.4843  decode.d7.loss_mask: 0.5065  decode.d7.loss_dice: 0.3367  decode.d8.loss_cls: 0.4155  decode.d8.loss_mask: 0.5481  decode.d8.loss_dice: 0.3494
09/28 15:10:52 - mmengine - INFO - Iter(train) [  5400/320000]  base_lr: 9.8480e-05 lr: 9.8480e-06  eta: 1 day, 18:19:11  time: 0.4844  data_time: 0.0100  memory: 5800  grad_norm: 169.9750  loss: 13.2987  decode.loss_cls: 0.5487  decode.loss_mask: 0.3881  decode.loss_dice: 0.3661  decode.d0.loss_cls: 1.2659  decode.d0.loss_mask: 0.3756  decode.d0.loss_dice: 0.3711  decode.d1.loss_cls: 0.6602  decode.d1.loss_mask: 0.3655  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.4897  decode.d2.loss_mask: 0.4215  decode.d2.loss_dice: 0.3763  decode.d3.loss_cls: 0.4078  decode.d3.loss_mask: 0.4203  decode.d3.loss_dice: 0.3696  decode.d4.loss_cls: 0.3601  decode.d4.loss_mask: 0.4090  decode.d4.loss_dice: 0.3697  decode.d5.loss_cls: 0.4460  decode.d5.loss_mask: 0.4205  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.5350  decode.d6.loss_mask: 0.3890  decode.d6.loss_dice: 0.3822  decode.d7.loss_cls: 0.4409  decode.d7.loss_mask: 0.3948  decode.d7.loss_dice: 0.3778  decode.d8.loss_cls: 0.4831  decode.d8.loss_mask: 0.3837  decode.d8.loss_dice: 0.3623
09/28 15:11:17 - mmengine - INFO - Iter(train) [  5450/320000]  base_lr: 9.8466e-05 lr: 9.8466e-06  eta: 1 day, 18:18:47  time: 0.4839  data_time: 0.0101  memory: 5817  grad_norm: 180.1412  loss: 11.4197  decode.loss_cls: 0.3406  decode.loss_mask: 0.3357  decode.loss_dice: 0.3259  decode.d0.loss_cls: 1.2527  decode.d0.loss_mask: 0.3121  decode.d0.loss_dice: 0.3249  decode.d1.loss_cls: 0.5005  decode.d1.loss_mask: 0.2930  decode.d1.loss_dice: 0.2989  decode.d2.loss_cls: 0.4065  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.3265  decode.d3.loss_cls: 0.4280  decode.d3.loss_mask: 0.2871  decode.d3.loss_dice: 0.3014  decode.d4.loss_cls: 0.4114  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.3150  decode.d5.loss_cls: 0.4071  decode.d5.loss_mask: 0.3247  decode.d5.loss_dice: 0.3424  decode.d6.loss_cls: 0.3358  decode.d6.loss_mask: 0.4432  decode.d6.loss_dice: 0.3596  decode.d7.loss_cls: 0.3242  decode.d7.loss_mask: 0.4407  decode.d7.loss_dice: 0.3305  decode.d8.loss_cls: 0.3119  decode.d8.loss_mask: 0.4274  decode.d8.loss_dice: 0.3244
09/28 15:11:41 - mmengine - INFO - Iter(train) [  5500/320000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 1 day, 18:18:21  time: 0.4834  data_time: 0.0098  memory: 5816  grad_norm: 172.0162  loss: 9.6110  decode.loss_cls: 0.3071  decode.loss_mask: 0.2881  decode.loss_dice: 0.2750  decode.d0.loss_cls: 1.1438  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.2962  decode.d1.loss_cls: 0.4048  decode.d1.loss_mask: 0.2902  decode.d1.loss_dice: 0.2579  decode.d2.loss_cls: 0.3171  decode.d2.loss_mask: 0.2833  decode.d2.loss_dice: 0.2660  decode.d3.loss_cls: 0.3104  decode.d3.loss_mask: 0.2879  decode.d3.loss_dice: 0.2797  decode.d4.loss_cls: 0.2816  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.2802  decode.d5.loss_cls: 0.3577  decode.d5.loss_mask: 0.2804  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.3324  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.2699  decode.d7.loss_cls: 0.3019  decode.d7.loss_mask: 0.2849  decode.d7.loss_dice: 0.2652  decode.d8.loss_cls: 0.2656  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2667
09/28 15:12:05 - mmengine - INFO - Iter(train) [  5550/320000]  base_lr: 9.8438e-05 lr: 9.8438e-06  eta: 1 day, 18:17:55  time: 0.4837  data_time: 0.0097  memory: 5799  grad_norm: 411.4168  loss: 10.3458  decode.loss_cls: 0.2813  decode.loss_mask: 0.4054  decode.loss_dice: 0.3357  decode.d0.loss_cls: 0.9902  decode.d0.loss_mask: 0.3621  decode.d0.loss_dice: 0.3219  decode.d1.loss_cls: 0.3301  decode.d1.loss_mask: 0.3419  decode.d1.loss_dice: 0.3192  decode.d2.loss_cls: 0.2783  decode.d2.loss_mask: 0.3517  decode.d2.loss_dice: 0.3385  decode.d3.loss_cls: 0.2284  decode.d3.loss_mask: 0.3504  decode.d3.loss_dice: 0.3122  decode.d4.loss_cls: 0.3132  decode.d4.loss_mask: 0.3378  decode.d4.loss_dice: 0.3118  decode.d5.loss_cls: 0.3024  decode.d5.loss_mask: 0.3337  decode.d5.loss_dice: 0.3055  decode.d6.loss_cls: 0.3057  decode.d6.loss_mask: 0.3324  decode.d6.loss_dice: 0.3017  decode.d7.loss_cls: 0.3242  decode.d7.loss_mask: 0.3321  decode.d7.loss_dice: 0.2945  decode.d8.loss_cls: 0.2926  decode.d8.loss_mask: 0.3949  decode.d8.loss_dice: 0.3159
09/28 15:12:29 - mmengine - INFO - Iter(train) [  5600/320000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 1 day, 18:17:30  time: 0.4836  data_time: 0.0097  memory: 5834  grad_norm: 235.7954  loss: 13.6048  decode.loss_cls: 0.3749  decode.loss_mask: 0.5151  decode.loss_dice: 0.3954  decode.d0.loss_cls: 1.0543  decode.d0.loss_mask: 0.5297  decode.d0.loss_dice: 0.4012  decode.d1.loss_cls: 0.5579  decode.d1.loss_mask: 0.4887  decode.d1.loss_dice: 0.3855  decode.d2.loss_cls: 0.3581  decode.d2.loss_mask: 0.5403  decode.d2.loss_dice: 0.4092  decode.d3.loss_cls: 0.3377  decode.d3.loss_mask: 0.5157  decode.d3.loss_dice: 0.3917  decode.d4.loss_cls: 0.3922  decode.d4.loss_mask: 0.5065  decode.d4.loss_dice: 0.3854  decode.d5.loss_cls: 0.3668  decode.d5.loss_mask: 0.5135  decode.d5.loss_dice: 0.3873  decode.d6.loss_cls: 0.3395  decode.d6.loss_mask: 0.4995  decode.d6.loss_dice: 0.3670  decode.d7.loss_cls: 0.3264  decode.d7.loss_mask: 0.5419  decode.d7.loss_dice: 0.3891  decode.d8.loss_cls: 0.3334  decode.d8.loss_mask: 0.5963  decode.d8.loss_dice: 0.4047
09/28 15:12:53 - mmengine - INFO - Iter(train) [  5650/320000]  base_lr: 9.8410e-05 lr: 9.8410e-06  eta: 1 day, 18:17:05  time: 0.4848  data_time: 0.0098  memory: 5817  grad_norm: 203.8332  loss: 11.5944  decode.loss_cls: 0.3591  decode.loss_mask: 0.3943  decode.loss_dice: 0.2918  decode.d0.loss_cls: 1.2354  decode.d0.loss_mask: 0.3395  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.4186  decode.d1.loss_mask: 0.3903  decode.d1.loss_dice: 0.3219  decode.d2.loss_cls: 0.3946  decode.d2.loss_mask: 0.3401  decode.d2.loss_dice: 0.2833  decode.d3.loss_cls: 0.4212  decode.d3.loss_mask: 0.3438  decode.d3.loss_dice: 0.3096  decode.d4.loss_cls: 0.4067  decode.d4.loss_mask: 0.3601  decode.d4.loss_dice: 0.3150  decode.d5.loss_cls: 0.3507  decode.d5.loss_mask: 0.4030  decode.d5.loss_dice: 0.3234  decode.d6.loss_cls: 0.3800  decode.d6.loss_mask: 0.4045  decode.d6.loss_dice: 0.3210  decode.d7.loss_cls: 0.3704  decode.d7.loss_mask: 0.4123  decode.d7.loss_dice: 0.3231  decode.d8.loss_cls: 0.3467  decode.d8.loss_mask: 0.4177  decode.d8.loss_dice: 0.3277
09/28 15:13:18 - mmengine - INFO - Iter(train) [  5700/320000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 1 day, 18:16:39  time: 0.4838  data_time: 0.0099  memory: 5798  grad_norm: 388.1454  loss: 11.6590  decode.loss_cls: 0.5567  decode.loss_mask: 0.2905  decode.loss_dice: 0.2522  decode.d0.loss_cls: 1.5357  decode.d0.loss_mask: 0.2426  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.6351  decode.d1.loss_mask: 0.2875  decode.d1.loss_dice: 0.2639  decode.d2.loss_cls: 0.5310  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.2636  decode.d3.loss_cls: 0.4602  decode.d3.loss_mask: 0.2478  decode.d3.loss_dice: 0.2551  decode.d4.loss_cls: 0.4846  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.2700  decode.d5.loss_cls: 0.5882  decode.d5.loss_mask: 0.2706  decode.d5.loss_dice: 0.2536  decode.d6.loss_cls: 0.5710  decode.d6.loss_mask: 0.2779  decode.d6.loss_dice: 0.2506  decode.d7.loss_cls: 0.5184  decode.d7.loss_mask: 0.2915  decode.d7.loss_dice: 0.2739  decode.d8.loss_cls: 0.5223  decode.d8.loss_mask: 0.2536  decode.d8.loss_dice: 0.2468
09/28 15:13:42 - mmengine - INFO - Iter(train) [  5750/320000]  base_lr: 9.8382e-05 lr: 9.8382e-06  eta: 1 day, 18:16:14  time: 0.4832  data_time: 0.0097  memory: 5834  grad_norm: 238.2311  loss: 13.3712  decode.loss_cls: 0.4180  decode.loss_mask: 0.4014  decode.loss_dice: 0.4507  decode.d0.loss_cls: 1.2720  decode.d0.loss_mask: 0.3651  decode.d0.loss_dice: 0.4521  decode.d1.loss_cls: 0.4705  decode.d1.loss_mask: 0.3839  decode.d1.loss_dice: 0.4490  decode.d2.loss_cls: 0.4246  decode.d2.loss_mask: 0.3625  decode.d2.loss_dice: 0.4478  decode.d3.loss_cls: 0.4093  decode.d3.loss_mask: 0.3648  decode.d3.loss_dice: 0.4463  decode.d4.loss_cls: 0.3818  decode.d4.loss_mask: 0.3655  decode.d4.loss_dice: 0.4330  decode.d5.loss_cls: 0.3921  decode.d5.loss_mask: 0.4026  decode.d5.loss_dice: 0.4596  decode.d6.loss_cls: 0.3883  decode.d6.loss_mask: 0.4333  decode.d6.loss_dice: 0.4574  decode.d7.loss_cls: 0.4785  decode.d7.loss_mask: 0.3872  decode.d7.loss_dice: 0.4352  decode.d8.loss_cls: 0.3972  decode.d8.loss_mask: 0.3905  decode.d8.loss_dice: 0.4511
09/28 15:14:06 - mmengine - INFO - Iter(train) [  5800/320000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 1 day, 18:15:48  time: 0.4833  data_time: 0.0096  memory: 5834  grad_norm: 224.4294  loss: 15.3961  decode.loss_cls: 0.5978  decode.loss_mask: 0.5427  decode.loss_dice: 0.4815  decode.d0.loss_cls: 1.4647  decode.d0.loss_mask: 0.4194  decode.d0.loss_dice: 0.3802  decode.d1.loss_cls: 0.6745  decode.d1.loss_mask: 0.3618  decode.d1.loss_dice: 0.3416  decode.d2.loss_cls: 0.5894  decode.d2.loss_mask: 0.3753  decode.d2.loss_dice: 0.3484  decode.d3.loss_cls: 0.4877  decode.d3.loss_mask: 0.4897  decode.d3.loss_dice: 0.3981  decode.d4.loss_cls: 0.5415  decode.d4.loss_mask: 0.5205  decode.d4.loss_dice: 0.4151  decode.d5.loss_cls: 0.5329  decode.d5.loss_mask: 0.6406  decode.d5.loss_dice: 0.4000  decode.d6.loss_cls: 0.5326  decode.d6.loss_mask: 0.5285  decode.d6.loss_dice: 0.3888  decode.d7.loss_cls: 0.5384  decode.d7.loss_mask: 0.5236  decode.d7.loss_dice: 0.3935  decode.d8.loss_cls: 0.6098  decode.d8.loss_mask: 0.4638  decode.d8.loss_dice: 0.4137
09/28 15:14:30 - mmengine - INFO - Iter(train) [  5850/320000]  base_lr: 9.8353e-05 lr: 9.8353e-06  eta: 1 day, 18:15:22  time: 0.4838  data_time: 0.0098  memory: 5817  grad_norm: 109.4331  loss: 7.0274  decode.loss_cls: 0.1332  decode.loss_mask: 0.2542  decode.loss_dice: 0.2492  decode.d0.loss_cls: 1.0342  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.2394  decode.d1.loss_cls: 0.2038  decode.d1.loss_mask: 0.2574  decode.d1.loss_dice: 0.2511  decode.d2.loss_cls: 0.1086  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.2429  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.2563  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.2545  decode.d4.loss_dice: 0.2288  decode.d5.loss_cls: 0.0929  decode.d5.loss_mask: 0.2540  decode.d5.loss_dice: 0.2323  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.2283  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.2568  decode.d7.loss_dice: 0.2450  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.2484
09/28 15:14:54 - mmengine - INFO - Iter(train) [  5900/320000]  base_lr: 9.8339e-05 lr: 9.8339e-06  eta: 1 day, 18:15:02  time: 0.4836  data_time: 0.0098  memory: 5817  grad_norm: 142.1427  loss: 8.4350  decode.loss_cls: 0.2123  decode.loss_mask: 0.2694  decode.loss_dice: 0.2101  decode.d0.loss_cls: 1.0263  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.2104  decode.d1.loss_cls: 0.4247  decode.d1.loss_mask: 0.2801  decode.d1.loss_dice: 0.2211  decode.d2.loss_cls: 0.3385  decode.d2.loss_mask: 0.2610  decode.d2.loss_dice: 0.2074  decode.d3.loss_cls: 0.3037  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.2072  decode.d4.loss_cls: 0.2817  decode.d4.loss_mask: 0.2732  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.2838  decode.d5.loss_mask: 0.2887  decode.d5.loss_dice: 0.2392  decode.d6.loss_cls: 0.2624  decode.d6.loss_mask: 0.2638  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.2673  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.2148  decode.d8.loss_cls: 0.1893  decode.d8.loss_mask: 0.2617  decode.d8.loss_dice: 0.2169
09/28 15:15:19 - mmengine - INFO - Iter(train) [  5950/320000]  base_lr: 9.8325e-05 lr: 9.8325e-06  eta: 1 day, 18:14:36  time: 0.4834  data_time: 0.0097  memory: 5816  grad_norm: 334.9787  loss: 8.1605  decode.loss_cls: 0.1233  decode.loss_mask: 0.3745  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.9688  decode.d0.loss_mask: 0.4163  decode.d0.loss_dice: 0.2571  decode.d1.loss_cls: 0.1554  decode.d1.loss_mask: 0.3633  decode.d1.loss_dice: 0.2410  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 0.3708  decode.d2.loss_dice: 0.2185  decode.d3.loss_cls: 0.1025  decode.d3.loss_mask: 0.3585  decode.d3.loss_dice: 0.2058  decode.d4.loss_cls: 0.1867  decode.d4.loss_mask: 0.3530  decode.d4.loss_dice: 0.2193  decode.d5.loss_cls: 0.1540  decode.d5.loss_mask: 0.3687  decode.d5.loss_dice: 0.2086  decode.d6.loss_cls: 0.1690  decode.d6.loss_mask: 0.3597  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.1465  decode.d7.loss_mask: 0.3503  decode.d7.loss_dice: 0.2087  decode.d8.loss_cls: 0.1069  decode.d8.loss_mask: 0.3612  decode.d8.loss_dice: 0.2247
09/28 15:15:43 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:15:43 - mmengine - INFO - Iter(train) [  6000/320000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 1 day, 18:14:10  time: 0.4840  data_time: 0.0098  memory: 5834  grad_norm: 179.5672  loss: 8.3471  decode.loss_cls: 0.1993  decode.loss_mask: 0.3159  decode.loss_dice: 0.2881  decode.d0.loss_cls: 0.9433  decode.d0.loss_mask: 0.3140  decode.d0.loss_dice: 0.3064  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.2876  decode.d2.loss_cls: 0.1593  decode.d2.loss_mask: 0.3078  decode.d2.loss_dice: 0.2846  decode.d3.loss_cls: 0.1120  decode.d3.loss_mask: 0.3078  decode.d3.loss_dice: 0.2841  decode.d4.loss_cls: 0.1640  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.3022  decode.d5.loss_cls: 0.1269  decode.d5.loss_mask: 0.3064  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 0.3055  decode.d6.loss_dice: 0.2959  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.3097  decode.d7.loss_dice: 0.3007  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 0.3109  decode.d8.loss_dice: 0.2779
09/28 15:16:07 - mmengine - INFO - Iter(train) [  6050/320000]  base_lr: 9.8297e-05 lr: 9.8297e-06  eta: 1 day, 18:13:44  time: 0.4826  data_time: 0.0097  memory: 5817  grad_norm: 298.8349  loss: 9.0156  decode.loss_cls: 0.2293  decode.loss_mask: 0.3169  decode.loss_dice: 0.2903  decode.d0.loss_cls: 1.1513  decode.d0.loss_mask: 0.3085  decode.d0.loss_dice: 0.2904  decode.d1.loss_cls: 0.2675  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.2832  decode.d2.loss_cls: 0.1632  decode.d2.loss_mask: 0.3005  decode.d2.loss_dice: 0.2712  decode.d3.loss_cls: 0.1636  decode.d3.loss_mask: 0.3130  decode.d3.loss_dice: 0.2726  decode.d4.loss_cls: 0.1102  decode.d4.loss_mask: 0.3137  decode.d4.loss_dice: 0.2762  decode.d5.loss_cls: 0.2084  decode.d5.loss_mask: 0.3334  decode.d5.loss_dice: 0.2812  decode.d6.loss_cls: 0.2149  decode.d6.loss_mask: 0.3104  decode.d6.loss_dice: 0.2877  decode.d7.loss_cls: 0.3145  decode.d7.loss_mask: 0.3161  decode.d7.loss_dice: 0.3064  decode.d8.loss_cls: 0.2027  decode.d8.loss_mask: 0.3296  decode.d8.loss_dice: 0.2860
09/28 15:16:31 - mmengine - INFO - Iter(train) [  6100/320000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 1 day, 18:13:19  time: 0.4836  data_time: 0.0101  memory: 5819  grad_norm: 104.8916  loss: 9.4258  decode.loss_cls: 0.2933  decode.loss_mask: 0.2967  decode.loss_dice: 0.2971  decode.d0.loss_cls: 1.0508  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.3069  decode.d1.loss_cls: 0.3527  decode.d1.loss_mask: 0.3106  decode.d1.loss_dice: 0.2949  decode.d2.loss_cls: 0.3303  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.2898  decode.d3.loss_cls: 0.1837  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.2932  decode.d4.loss_cls: 0.1964  decode.d4.loss_mask: 0.2997  decode.d4.loss_dice: 0.2997  decode.d5.loss_cls: 0.2873  decode.d5.loss_mask: 0.3055  decode.d5.loss_dice: 0.2750  decode.d6.loss_cls: 0.2674  decode.d6.loss_mask: 0.3007  decode.d6.loss_dice: 0.2840  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.2703  decode.d8.loss_cls: 0.2883  decode.d8.loss_mask: 0.3073  decode.d8.loss_dice: 0.3140
09/28 15:16:55 - mmengine - INFO - Iter(train) [  6150/320000]  base_lr: 9.8269e-05 lr: 9.8269e-06  eta: 1 day, 18:12:54  time: 0.4843  data_time: 0.0099  memory: 5799  grad_norm: 603.7061  loss: 9.2401  decode.loss_cls: 0.2720  decode.loss_mask: 0.2852  decode.loss_dice: 0.2550  decode.d0.loss_cls: 1.0890  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.2707  decode.d1.loss_cls: 0.3603  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.2512  decode.d2.loss_cls: 0.3054  decode.d2.loss_mask: 0.2748  decode.d2.loss_dice: 0.2496  decode.d3.loss_cls: 0.2932  decode.d3.loss_mask: 0.2808  decode.d3.loss_dice: 0.2598  decode.d4.loss_cls: 0.2763  decode.d4.loss_mask: 0.2861  decode.d4.loss_dice: 0.2687  decode.d5.loss_cls: 0.2949  decode.d5.loss_mask: 0.3128  decode.d5.loss_dice: 0.2787  decode.d6.loss_cls: 0.2965  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.2443  decode.d7.loss_cls: 0.2928  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.2884  decode.d8.loss_cls: 0.2334  decode.d8.loss_mask: 0.2917  decode.d8.loss_dice: 0.2685
09/28 15:17:20 - mmengine - INFO - Iter(train) [  6200/320000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 1 day, 18:12:40  time: 0.4845  data_time: 0.0101  memory: 5819  grad_norm: 215.6551  loss: 10.4951  decode.loss_cls: 0.3705  decode.loss_mask: 0.3061  decode.loss_dice: 0.3054  decode.d0.loss_cls: 1.2017  decode.d0.loss_mask: 0.3164  decode.d0.loss_dice: 0.2919  decode.d1.loss_cls: 0.4589  decode.d1.loss_mask: 0.3016  decode.d1.loss_dice: 0.2901  decode.d2.loss_cls: 0.3704  decode.d2.loss_mask: 0.3061  decode.d2.loss_dice: 0.2864  decode.d3.loss_cls: 0.3109  decode.d3.loss_mask: 0.3422  decode.d3.loss_dice: 0.3110  decode.d4.loss_cls: 0.2809  decode.d4.loss_mask: 0.3529  decode.d4.loss_dice: 0.3285  decode.d5.loss_cls: 0.2928  decode.d5.loss_mask: 0.3307  decode.d5.loss_dice: 0.3282  decode.d6.loss_cls: 0.2650  decode.d6.loss_mask: 0.3759  decode.d6.loss_dice: 0.3556  decode.d7.loss_cls: 0.2507  decode.d7.loss_mask: 0.3328  decode.d7.loss_dice: 0.3429  decode.d8.loss_cls: 0.2247  decode.d8.loss_mask: 0.3235  decode.d8.loss_dice: 0.3404
09/28 15:17:44 - mmengine - INFO - Iter(train) [  6250/320000]  base_lr: 9.8241e-05 lr: 9.8241e-06  eta: 1 day, 18:12:18  time: 0.4854  data_time: 0.0102  memory: 5835  grad_norm: 703.1332  loss: 12.2321  decode.loss_cls: 0.3800  decode.loss_mask: 0.5003  decode.loss_dice: 0.4080  decode.d0.loss_cls: 1.0898  decode.d0.loss_mask: 0.3673  decode.d0.loss_dice: 0.3014  decode.d1.loss_cls: 0.4984  decode.d1.loss_mask: 0.3513  decode.d1.loss_dice: 0.2917  decode.d2.loss_cls: 0.4145  decode.d2.loss_mask: 0.3682  decode.d2.loss_dice: 0.3054  decode.d3.loss_cls: 0.3089  decode.d3.loss_mask: 0.3849  decode.d3.loss_dice: 0.3010  decode.d4.loss_cls: 0.4246  decode.d4.loss_mask: 0.4161  decode.d4.loss_dice: 0.3515  decode.d5.loss_cls: 0.3356  decode.d5.loss_mask: 0.4362  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.3659  decode.d6.loss_mask: 0.4561  decode.d6.loss_dice: 0.3273  decode.d7.loss_cls: 0.4128  decode.d7.loss_mask: 0.4667  decode.d7.loss_dice: 0.3463  decode.d8.loss_cls: 0.4157  decode.d8.loss_mask: 0.4757  decode.d8.loss_dice: 0.4115
09/28 15:18:08 - mmengine - INFO - Iter(train) [  6300/320000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 1 day, 18:11:55  time: 0.4842  data_time: 0.0103  memory: 5834  grad_norm: 214.2524  loss: 9.0303  decode.loss_cls: 0.1734  decode.loss_mask: 0.3304  decode.loss_dice: 0.3058  decode.d0.loss_cls: 1.0752  decode.d0.loss_mask: 0.3635  decode.d0.loss_dice: 0.3069  decode.d1.loss_cls: 0.1917  decode.d1.loss_mask: 0.3464  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.1530  decode.d2.loss_mask: 0.3477  decode.d2.loss_dice: 0.3106  decode.d3.loss_cls: 0.1607  decode.d3.loss_mask: 0.3437  decode.d3.loss_dice: 0.3080  decode.d4.loss_cls: 0.1590  decode.d4.loss_mask: 0.3532  decode.d4.loss_dice: 0.3117  decode.d5.loss_cls: 0.1531  decode.d5.loss_mask: 0.3508  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.1766  decode.d6.loss_mask: 0.3362  decode.d6.loss_dice: 0.3123  decode.d7.loss_cls: 0.1406  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.3167  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 0.3372  decode.d8.loss_dice: 0.3106
09/28 15:18:32 - mmengine - INFO - Iter(train) [  6350/320000]  base_lr: 9.8213e-05 lr: 9.8213e-06  eta: 1 day, 18:11:32  time: 0.4845  data_time: 0.0102  memory: 5816  grad_norm: 588.0334  loss: 8.3091  decode.loss_cls: 0.2437  decode.loss_mask: 0.2966  decode.loss_dice: 0.2052  decode.d0.loss_cls: 1.0128  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.2111  decode.d1.loss_cls: 0.3774  decode.d1.loss_mask: 0.2923  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.1805  decode.d2.loss_mask: 0.2926  decode.d2.loss_dice: 0.2092  decode.d3.loss_cls: 0.2465  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.2044  decode.d4.loss_cls: 0.2211  decode.d4.loss_mask: 0.2959  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.2232  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.2050  decode.d6.loss_cls: 0.2638  decode.d6.loss_mask: 0.3009  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.2642  decode.d7.loss_mask: 0.2914  decode.d7.loss_dice: 0.2036  decode.d8.loss_cls: 0.2515  decode.d8.loss_mask: 0.2957  decode.d8.loss_dice: 0.2047
09/28 15:18:57 - mmengine - INFO - Iter(train) [  6400/320000]  base_lr: 9.8198e-05 lr: 9.8198e-06  eta: 1 day, 18:11:09  time: 0.4849  data_time: 0.0101  memory: 5816  grad_norm: 264.4507  loss: 10.0565  decode.loss_cls: 0.1924  decode.loss_mask: 0.4718  decode.loss_dice: 0.3181  decode.d0.loss_cls: 1.0816  decode.d0.loss_mask: 0.3515  decode.d0.loss_dice: 0.2989  decode.d1.loss_cls: 0.2522  decode.d1.loss_mask: 0.3640  decode.d1.loss_dice: 0.2715  decode.d2.loss_cls: 0.2430  decode.d2.loss_mask: 0.3388  decode.d2.loss_dice: 0.2536  decode.d3.loss_cls: 0.1934  decode.d3.loss_mask: 0.3526  decode.d3.loss_dice: 0.2884  decode.d4.loss_cls: 0.2717  decode.d4.loss_mask: 0.3386  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.2989  decode.d5.loss_mask: 0.3593  decode.d5.loss_dice: 0.3076  decode.d6.loss_cls: 0.2812  decode.d6.loss_mask: 0.3937  decode.d6.loss_dice: 0.3070  decode.d7.loss_cls: 0.2682  decode.d7.loss_mask: 0.3823  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.1888  decode.d8.loss_mask: 0.4825  decode.d8.loss_dice: 0.3106
09/28 15:19:21 - mmengine - INFO - Iter(train) [  6450/320000]  base_lr: 9.8184e-05 lr: 9.8184e-06  eta: 1 day, 18:10:47  time: 0.4852  data_time: 0.0102  memory: 5817  grad_norm: 181.5591  loss: 9.0570  decode.loss_cls: 0.2100  decode.loss_mask: 0.3497  decode.loss_dice: 0.3164  decode.d0.loss_cls: 1.2589  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.2452  decode.d1.loss_cls: 0.3745  decode.d1.loss_mask: 0.3024  decode.d1.loss_dice: 0.2585  decode.d2.loss_cls: 0.2393  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.2779  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 0.2923  decode.d3.loss_dice: 0.2813  decode.d4.loss_cls: 0.2076  decode.d4.loss_mask: 0.2915  decode.d4.loss_dice: 0.2634  decode.d5.loss_cls: 0.2008  decode.d5.loss_mask: 0.2984  decode.d5.loss_dice: 0.2751  decode.d6.loss_cls: 0.2071  decode.d6.loss_mask: 0.2991  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.2095  decode.d7.loss_mask: 0.3018  decode.d7.loss_dice: 0.2825  decode.d8.loss_cls: 0.2283  decode.d8.loss_mask: 0.2919  decode.d8.loss_dice: 0.2440
09/28 15:19:45 - mmengine - INFO - Iter(train) [  6500/320000]  base_lr: 9.8170e-05 lr: 9.8170e-06  eta: 1 day, 18:10:24  time: 0.4845  data_time: 0.0102  memory: 5800  grad_norm: 82.5762  loss: 10.3485  decode.loss_cls: 0.3852  decode.loss_mask: 0.2916  decode.loss_dice: 0.3078  decode.d0.loss_cls: 1.2025  decode.d0.loss_mask: 0.2908  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.3826  decode.d1.loss_mask: 0.2902  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.3841  decode.d2.loss_mask: 0.2774  decode.d2.loss_dice: 0.2606  decode.d3.loss_cls: 0.3845  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.2744  decode.d4.loss_cls: 0.4344  decode.d4.loss_mask: 0.2759  decode.d4.loss_dice: 0.2588  decode.d5.loss_cls: 0.3350  decode.d5.loss_mask: 0.2753  decode.d5.loss_dice: 0.2618  decode.d6.loss_cls: 0.3570  decode.d6.loss_mask: 0.2914  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.4523  decode.d7.loss_mask: 0.2850  decode.d7.loss_dice: 0.2697  decode.d8.loss_cls: 0.4375  decode.d8.loss_mask: 0.2896  decode.d8.loss_dice: 0.2840
09/28 15:20:09 - mmengine - INFO - Iter(train) [  6550/320000]  base_lr: 9.8156e-05 lr: 9.8156e-06  eta: 1 day, 18:10:01  time: 0.4846  data_time: 0.0101  memory: 5800  grad_norm: 226.7299  loss: 11.3074  decode.loss_cls: 0.3572  decode.loss_mask: 0.3647  decode.loss_dice: 0.2995  decode.d0.loss_cls: 1.1846  decode.d0.loss_mask: 0.3562  decode.d0.loss_dice: 0.2931  decode.d1.loss_cls: 0.2990  decode.d1.loss_mask: 0.3785  decode.d1.loss_dice: 0.3491  decode.d2.loss_cls: 0.2677  decode.d2.loss_mask: 0.4060  decode.d2.loss_dice: 0.3437  decode.d3.loss_cls: 0.3067  decode.d3.loss_mask: 0.3817  decode.d3.loss_dice: 0.3668  decode.d4.loss_cls: 0.3017  decode.d4.loss_mask: 0.4808  decode.d4.loss_dice: 0.3636  decode.d5.loss_cls: 0.3336  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.3514  decode.d6.loss_cls: 0.3257  decode.d6.loss_mask: 0.3982  decode.d6.loss_dice: 0.3659  decode.d7.loss_cls: 0.3170  decode.d7.loss_mask: 0.3868  decode.d7.loss_dice: 0.3542  decode.d8.loss_cls: 0.3041  decode.d8.loss_mask: 0.3680  decode.d8.loss_dice: 0.3133
09/28 15:20:34 - mmengine - INFO - Iter(train) [  6600/320000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 1 day, 18:09:39  time: 0.4858  data_time: 0.0104  memory: 5798  grad_norm: 107.1376  loss: 8.5531  decode.loss_cls: 0.1699  decode.loss_mask: 0.2853  decode.loss_dice: 0.3179  decode.d0.loss_cls: 0.8917  decode.d0.loss_mask: 0.2761  decode.d0.loss_dice: 0.3055  decode.d1.loss_cls: 0.2168  decode.d1.loss_mask: 0.2765  decode.d1.loss_dice: 0.3171  decode.d2.loss_cls: 0.2209  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.3258  decode.d3.loss_cls: 0.2031  decode.d3.loss_mask: 0.2853  decode.d3.loss_dice: 0.3189  decode.d4.loss_cls: 0.1896  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.3073  decode.d5.loss_cls: 0.1610  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.3210  decode.d6.loss_cls: 0.1578  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.3181  decode.d7.loss_cls: 0.1306  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.3241  decode.d8.loss_cls: 0.1835  decode.d8.loss_mask: 0.2909  decode.d8.loss_dice: 0.3241
09/28 15:20:58 - mmengine - INFO - Iter(train) [  6650/320000]  base_lr: 9.8128e-05 lr: 9.8128e-06  eta: 1 day, 18:09:15  time: 0.4846  data_time: 0.0100  memory: 5816  grad_norm: 105.4062  loss: 9.2234  decode.loss_cls: 0.2910  decode.loss_mask: 0.2556  decode.loss_dice: 0.2430  decode.d0.loss_cls: 1.1948  decode.d0.loss_mask: 0.2467  decode.d0.loss_dice: 0.2608  decode.d1.loss_cls: 0.3528  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2624  decode.d2.loss_cls: 0.3295  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.2582  decode.d3.loss_cls: 0.3047  decode.d3.loss_mask: 0.2594  decode.d3.loss_dice: 0.2916  decode.d4.loss_cls: 0.2884  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.2897  decode.d5.loss_mask: 0.2779  decode.d5.loss_dice: 0.2532  decode.d6.loss_cls: 0.3056  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2426  decode.d7.loss_cls: 0.2934  decode.d7.loss_mask: 0.2658  decode.d7.loss_dice: 0.2543  decode.d8.loss_cls: 0.2332  decode.d8.loss_mask: 0.3456  decode.d8.loss_dice: 0.2796
09/28 15:21:22 - mmengine - INFO - Iter(train) [  6700/320000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 1 day, 18:08:52  time: 0.4848  data_time: 0.0102  memory: 5816  grad_norm: 163.4041  loss: 9.5884  decode.loss_cls: 0.2750  decode.loss_mask: 0.2817  decode.loss_dice: 0.3113  decode.d0.loss_cls: 1.0243  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.3345  decode.d1.loss_cls: 0.3918  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.2473  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.3147  decode.d3.loss_cls: 0.2728  decode.d3.loss_mask: 0.2770  decode.d3.loss_dice: 0.3158  decode.d4.loss_cls: 0.3103  decode.d4.loss_mask: 0.2775  decode.d4.loss_dice: 0.3075  decode.d5.loss_cls: 0.2595  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.2952  decode.d6.loss_cls: 0.2825  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.3181  decode.d7.loss_cls: 0.2949  decode.d7.loss_mask: 0.2792  decode.d7.loss_dice: 0.3056  decode.d8.loss_cls: 0.3092  decode.d8.loss_mask: 0.2774  decode.d8.loss_dice: 0.2977
09/28 15:21:46 - mmengine - INFO - Iter(train) [  6750/320000]  base_lr: 9.8100e-05 lr: 9.8100e-06  eta: 1 day, 18:08:30  time: 0.4855  data_time: 0.0101  memory: 5835  grad_norm: 115.0757  loss: 7.7729  decode.loss_cls: 0.1815  decode.loss_mask: 0.2645  decode.loss_dice: 0.2387  decode.d0.loss_cls: 1.0707  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.2630  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 0.2581  decode.d1.loss_dice: 0.2331  decode.d2.loss_cls: 0.2009  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.2350  decode.d3.loss_cls: 0.2011  decode.d3.loss_mask: 0.2478  decode.d3.loss_dice: 0.2381  decode.d4.loss_cls: 0.2125  decode.d4.loss_mask: 0.2574  decode.d4.loss_dice: 0.2210  decode.d5.loss_cls: 0.2243  decode.d5.loss_mask: 0.2613  decode.d5.loss_dice: 0.2193  decode.d6.loss_cls: 0.1931  decode.d6.loss_mask: 0.2580  decode.d6.loss_dice: 0.2452  decode.d7.loss_cls: 0.1804  decode.d7.loss_mask: 0.2599  decode.d7.loss_dice: 0.2235  decode.d8.loss_cls: 0.1662  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2309
09/28 15:22:11 - mmengine - INFO - Iter(train) [  6800/320000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 1 day, 18:08:11  time: 0.4840  data_time: 0.0102  memory: 5798  grad_norm: 218.6491  loss: 6.9925  decode.loss_cls: 0.1394  decode.loss_mask: 0.2580  decode.loss_dice: 0.2216  decode.d0.loss_cls: 0.7912  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.2363  decode.d1.loss_cls: 0.1347  decode.d1.loss_mask: 0.2688  decode.d1.loss_dice: 0.2263  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.2643  decode.d2.loss_dice: 0.2374  decode.d3.loss_cls: 0.1535  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.2344  decode.d4.loss_cls: 0.1173  decode.d4.loss_mask: 0.2673  decode.d4.loss_dice: 0.2278  decode.d5.loss_cls: 0.1629  decode.d5.loss_mask: 0.2646  decode.d5.loss_dice: 0.2460  decode.d6.loss_cls: 0.1463  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.2240  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.2321  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.2611  decode.d8.loss_dice: 0.2297
09/28 15:22:35 - mmengine - INFO - Iter(train) [  6850/320000]  base_lr: 9.8072e-05 lr: 9.8072e-06  eta: 1 day, 18:07:48  time: 0.4858  data_time: 0.0100  memory: 5819  grad_norm: 84.1385  loss: 6.8368  decode.loss_cls: 0.0801  decode.loss_mask: 0.2873  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.9059  decode.d0.loss_mask: 0.2882  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.2178  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.2948  decode.d2.loss_dice: 0.2326  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.3003  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.2209  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.2869  decode.d5.loss_dice: 0.2218  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.2221  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.2250  decode.d8.loss_cls: 0.0656  decode.d8.loss_mask: 0.2897  decode.d8.loss_dice: 0.2317
09/28 15:22:59 - mmengine - INFO - Iter(train) [  6900/320000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 1 day, 18:07:24  time: 0.4847  data_time: 0.0103  memory: 5819  grad_norm: 131.5446  loss: 8.8753  decode.loss_cls: 0.2614  decode.loss_mask: 0.2791  decode.loss_dice: 0.2613  decode.d0.loss_cls: 0.9558  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.2798  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 0.2761  decode.d1.loss_dice: 0.2622  decode.d2.loss_cls: 0.1716  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.2163  decode.d3.loss_mask: 0.2730  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.3126  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.2852  decode.d5.loss_cls: 0.2498  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.2707  decode.d6.loss_cls: 0.3066  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.2555  decode.d7.loss_cls: 0.2912  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.3845  decode.d8.loss_mask: 0.2777  decode.d8.loss_dice: 0.2792
09/28 15:23:23 - mmengine - INFO - Iter(train) [  6950/320000]  base_lr: 9.8043e-05 lr: 9.8043e-06  eta: 1 day, 18:07:01  time: 0.4843  data_time: 0.0101  memory: 5799  grad_norm: 116.1248  loss: 11.2371  decode.loss_cls: 0.2819  decode.loss_mask: 0.4055  decode.loss_dice: 0.3278  decode.d0.loss_cls: 1.1457  decode.d0.loss_mask: 0.4008  decode.d0.loss_dice: 0.3356  decode.d1.loss_cls: 0.3612  decode.d1.loss_mask: 0.3853  decode.d1.loss_dice: 0.3354  decode.d2.loss_cls: 0.3311  decode.d2.loss_mask: 0.3799  decode.d2.loss_dice: 0.3299  decode.d3.loss_cls: 0.3100  decode.d3.loss_mask: 0.3841  decode.d3.loss_dice: 0.3224  decode.d4.loss_cls: 0.2963  decode.d4.loss_mask: 0.3795  decode.d4.loss_dice: 0.3383  decode.d5.loss_cls: 0.3394  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.3241  decode.d6.loss_cls: 0.3565  decode.d6.loss_mask: 0.3824  decode.d6.loss_dice: 0.3173  decode.d7.loss_cls: 0.3874  decode.d7.loss_mask: 0.3851  decode.d7.loss_dice: 0.3157  decode.d8.loss_cls: 0.2789  decode.d8.loss_mask: 0.3835  decode.d8.loss_dice: 0.3277
09/28 15:23:48 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:23:48 - mmengine - INFO - Iter(train) [  7000/320000]  base_lr: 9.8029e-05 lr: 9.8029e-06  eta: 1 day, 18:06:38  time: 0.4844  data_time: 0.0101  memory: 5817  grad_norm: 258.2881  loss: 9.1863  decode.loss_cls: 0.1528  decode.loss_mask: 0.3250  decode.loss_dice: 0.3235  decode.d0.loss_cls: 1.1442  decode.d0.loss_mask: 0.3235  decode.d0.loss_dice: 0.3207  decode.d1.loss_cls: 0.2625  decode.d1.loss_mask: 0.3339  decode.d1.loss_dice: 0.3304  decode.d2.loss_cls: 0.2018  decode.d2.loss_mask: 0.3308  decode.d2.loss_dice: 0.3235  decode.d3.loss_cls: 0.1562  decode.d3.loss_mask: 0.3313  decode.d3.loss_dice: 0.3225  decode.d4.loss_cls: 0.1696  decode.d4.loss_mask: 0.3250  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 0.3189  decode.d5.loss_dice: 0.3007  decode.d6.loss_cls: 0.1812  decode.d6.loss_mask: 0.3161  decode.d6.loss_dice: 0.3070  decode.d7.loss_cls: 0.1844  decode.d7.loss_mask: 0.3212  decode.d7.loss_dice: 0.3070  decode.d8.loss_cls: 0.1563  decode.d8.loss_mask: 0.3297  decode.d8.loss_dice: 0.3020
09/28 15:24:12 - mmengine - INFO - Iter(train) [  7050/320000]  base_lr: 9.8015e-05 lr: 9.8015e-06  eta: 1 day, 18:06:15  time: 0.4847  data_time: 0.0101  memory: 5817  grad_norm: 269.1093  loss: 9.5707  decode.loss_cls: 0.3772  decode.loss_mask: 0.2648  decode.loss_dice: 0.2754  decode.d0.loss_cls: 1.1027  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.3086  decode.d1.loss_cls: 0.3786  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.3489  decode.d2.loss_mask: 0.2600  decode.d2.loss_dice: 0.2714  decode.d3.loss_cls: 0.2982  decode.d3.loss_mask: 0.2610  decode.d3.loss_dice: 0.2692  decode.d4.loss_cls: 0.3268  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.2950  decode.d5.loss_cls: 0.3187  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2702  decode.d6.loss_cls: 0.3763  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2581  decode.d7.loss_cls: 0.3662  decode.d7.loss_mask: 0.2561  decode.d7.loss_dice: 0.2880  decode.d8.loss_cls: 0.3084  decode.d8.loss_mask: 0.2599  decode.d8.loss_dice: 0.2705
09/28 15:24:36 - mmengine - INFO - Iter(train) [  7100/320000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 1 day, 18:05:52  time: 0.4857  data_time: 0.0102  memory: 5816  grad_norm: 120.9102  loss: 7.3140  decode.loss_cls: 0.1274  decode.loss_mask: 0.2840  decode.loss_dice: 0.2531  decode.d0.loss_cls: 0.7988  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.2557  decode.d1.loss_cls: 0.2194  decode.d1.loss_mask: 0.2838  decode.d1.loss_dice: 0.2410  decode.d2.loss_cls: 0.1674  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.2534  decode.d3.loss_cls: 0.1061  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.2503  decode.d4.loss_cls: 0.1168  decode.d4.loss_mask: 0.2834  decode.d4.loss_dice: 0.2370  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.2842  decode.d5.loss_dice: 0.2442  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.2888  decode.d6.loss_dice: 0.2487  decode.d7.loss_cls: 0.1188  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.2394  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.2460
09/28 15:25:00 - mmengine - INFO - Iter(train) [  7150/320000]  base_lr: 9.7987e-05 lr: 9.7987e-06  eta: 1 day, 18:05:30  time: 0.4847  data_time: 0.0100  memory: 5816  grad_norm: 138.6780  loss: 8.2951  decode.loss_cls: 0.2300  decode.loss_mask: 0.2526  decode.loss_dice: 0.2330  decode.d0.loss_cls: 0.8290  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2358  decode.d1.loss_cls: 0.3307  decode.d1.loss_mask: 0.2445  decode.d1.loss_dice: 0.2236  decode.d2.loss_cls: 0.3094  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.3314  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.2055  decode.d4.loss_cls: 0.3160  decode.d4.loss_mask: 0.2397  decode.d4.loss_dice: 0.2370  decode.d5.loss_cls: 0.3372  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.2422  decode.d6.loss_cls: 0.2609  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.2320  decode.d7.loss_cls: 0.3064  decode.d7.loss_mask: 0.2470  decode.d7.loss_dice: 0.2389  decode.d8.loss_cls: 0.2701  decode.d8.loss_mask: 0.2406  decode.d8.loss_dice: 0.2231
09/28 15:25:25 - mmengine - INFO - Iter(train) [  7200/320000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 1 day, 18:05:08  time: 0.4860  data_time: 0.0102  memory: 5816  grad_norm: 331.9000  loss: 9.3415  decode.loss_cls: 0.2095  decode.loss_mask: 0.3334  decode.loss_dice: 0.2340  decode.d0.loss_cls: 0.9863  decode.d0.loss_mask: 0.3448  decode.d0.loss_dice: 0.2739  decode.d1.loss_cls: 0.2635  decode.d1.loss_mask: 0.3434  decode.d1.loss_dice: 0.2586  decode.d2.loss_cls: 0.2389  decode.d2.loss_mask: 0.3884  decode.d2.loss_dice: 0.2743  decode.d3.loss_cls: 0.2333  decode.d3.loss_mask: 0.3836  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.2186  decode.d4.loss_mask: 0.3414  decode.d4.loss_dice: 0.2494  decode.d5.loss_cls: 0.2547  decode.d5.loss_mask: 0.3662  decode.d5.loss_dice: 0.2648  decode.d6.loss_cls: 0.2792  decode.d6.loss_mask: 0.3397  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.2768  decode.d7.loss_mask: 0.3374  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.2643  decode.d8.loss_mask: 0.3485  decode.d8.loss_dice: 0.2451
09/28 15:25:49 - mmengine - INFO - Iter(train) [  7250/320000]  base_lr: 9.7959e-05 lr: 9.7959e-06  eta: 1 day, 18:04:45  time: 0.4849  data_time: 0.0102  memory: 5819  grad_norm: 781.0021  loss: 13.6451  decode.loss_cls: 0.4617  decode.loss_mask: 0.3945  decode.loss_dice: 0.3766  decode.d0.loss_cls: 1.1943  decode.d0.loss_mask: 0.3847  decode.d0.loss_dice: 0.3860  decode.d1.loss_cls: 0.5762  decode.d1.loss_mask: 0.3977  decode.d1.loss_dice: 0.3905  decode.d2.loss_cls: 0.5348  decode.d2.loss_mask: 0.3854  decode.d2.loss_dice: 0.3627  decode.d3.loss_cls: 0.5392  decode.d3.loss_mask: 0.3836  decode.d3.loss_dice: 0.3487  decode.d4.loss_cls: 0.6209  decode.d4.loss_mask: 0.3772  decode.d4.loss_dice: 0.3823  decode.d5.loss_cls: 0.6004  decode.d5.loss_mask: 0.3782  decode.d5.loss_dice: 0.3760  decode.d6.loss_cls: 0.5522  decode.d6.loss_mask: 0.3649  decode.d6.loss_dice: 0.3792  decode.d7.loss_cls: 0.5554  decode.d7.loss_mask: 0.3702  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.4715  decode.d8.loss_mask: 0.3708  decode.d8.loss_dice: 0.3605
09/28 15:26:13 - mmengine - INFO - Iter(train) [  7300/320000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 1 day, 18:04:23  time: 0.4846  data_time: 0.0102  memory: 5817  grad_norm: 110.6570  loss: 8.7997  decode.loss_cls: 0.3114  decode.loss_mask: 0.2719  decode.loss_dice: 0.1907  decode.d0.loss_cls: 1.1656  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.4138  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.1899  decode.d2.loss_cls: 0.3249  decode.d2.loss_mask: 0.2618  decode.d2.loss_dice: 0.1904  decode.d3.loss_cls: 0.3324  decode.d3.loss_mask: 0.2681  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.3489  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.3155  decode.d5.loss_mask: 0.2688  decode.d5.loss_dice: 0.1971  decode.d6.loss_cls: 0.3112  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.1975  decode.d7.loss_cls: 0.3298  decode.d7.loss_mask: 0.2679  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.2960  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.1891
09/28 15:26:38 - mmengine - INFO - Iter(train) [  7350/320000]  base_lr: 9.7931e-05 lr: 9.7931e-06  eta: 1 day, 18:04:05  time: 0.4847  data_time: 0.0099  memory: 5819  grad_norm: 278.3049  loss: 12.3056  decode.loss_cls: 0.3612  decode.loss_mask: 0.4094  decode.loss_dice: 0.3698  decode.d0.loss_cls: 1.2611  decode.d0.loss_mask: 0.4142  decode.d0.loss_dice: 0.3944  decode.d1.loss_cls: 0.4071  decode.d1.loss_mask: 0.4327  decode.d1.loss_dice: 0.3751  decode.d2.loss_cls: 0.3769  decode.d2.loss_mask: 0.4269  decode.d2.loss_dice: 0.3827  decode.d3.loss_cls: 0.3522  decode.d3.loss_mask: 0.4196  decode.d3.loss_dice: 0.3551  decode.d4.loss_cls: 0.3858  decode.d4.loss_mask: 0.3974  decode.d4.loss_dice: 0.3665  decode.d5.loss_cls: 0.3524  decode.d5.loss_mask: 0.3876  decode.d5.loss_dice: 0.3668  decode.d6.loss_cls: 0.3488  decode.d6.loss_mask: 0.3910  decode.d6.loss_dice: 0.3552  decode.d7.loss_cls: 0.3002  decode.d7.loss_mask: 0.3871  decode.d7.loss_dice: 0.3497  decode.d8.loss_cls: 0.3759  decode.d8.loss_mask: 0.4409  decode.d8.loss_dice: 0.3622
09/28 15:27:02 - mmengine - INFO - Iter(train) [  7400/320000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 1 day, 18:03:41  time: 0.4845  data_time: 0.0101  memory: 5834  grad_norm: 112.2146  loss: 7.7256  decode.loss_cls: 0.1157  decode.loss_mask: 0.2853  decode.loss_dice: 0.2987  decode.d0.loss_cls: 1.1170  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.2808  decode.d1.loss_cls: 0.1346  decode.d1.loss_mask: 0.2971  decode.d1.loss_dice: 0.2972  decode.d2.loss_cls: 0.1040  decode.d2.loss_mask: 0.2790  decode.d2.loss_dice: 0.2944  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.2851  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.3006  decode.d5.loss_cls: 0.0874  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.2897  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.2777  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.2923  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 0.2817  decode.d8.loss_dice: 0.2999
09/28 15:27:26 - mmengine - INFO - Iter(train) [  7450/320000]  base_lr: 9.7903e-05 lr: 9.7903e-06  eta: 1 day, 18:03:19  time: 0.4851  data_time: 0.0101  memory: 5800  grad_norm: 299.1251  loss: 8.4609  decode.loss_cls: 0.2433  decode.loss_mask: 0.2572  decode.loss_dice: 0.2672  decode.d0.loss_cls: 1.0781  decode.d0.loss_mask: 0.2465  decode.d0.loss_dice: 0.2863  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.2616  decode.d2.loss_cls: 0.3109  decode.d2.loss_mask: 0.2381  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.2563  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.2820  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.2521  decode.d5.loss_cls: 0.2428  decode.d5.loss_mask: 0.2437  decode.d5.loss_dice: 0.2584  decode.d6.loss_cls: 0.2682  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.2695  decode.d7.loss_cls: 0.2352  decode.d7.loss_mask: 0.2414  decode.d7.loss_dice: 0.2563  decode.d8.loss_cls: 0.2248  decode.d8.loss_mask: 0.2416  decode.d8.loss_dice: 0.2562
09/28 15:27:50 - mmengine - INFO - Iter(train) [  7500/320000]  base_lr: 9.7888e-05 lr: 9.7888e-06  eta: 1 day, 18:02:57  time: 0.4855  data_time: 0.0101  memory: 5834  grad_norm: 69.2864  loss: 8.9162  decode.loss_cls: 0.2424  decode.loss_mask: 0.2863  decode.loss_dice: 0.2542  decode.d0.loss_cls: 1.2689  decode.d0.loss_mask: 0.2859  decode.d0.loss_dice: 0.2496  decode.d1.loss_cls: 0.2731  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.2585  decode.d2.loss_cls: 0.2786  decode.d2.loss_mask: 0.2802  decode.d2.loss_dice: 0.2645  decode.d3.loss_cls: 0.2581  decode.d3.loss_mask: 0.2798  decode.d3.loss_dice: 0.2537  decode.d4.loss_cls: 0.2728  decode.d4.loss_mask: 0.2821  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.2654  decode.d5.loss_mask: 0.2821  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.2538  decode.d6.loss_mask: 0.2796  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.2344  decode.d7.loss_mask: 0.2814  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.2109  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.2439
09/28 15:28:15 - mmengine - INFO - Iter(train) [  7550/320000]  base_lr: 9.7874e-05 lr: 9.7874e-06  eta: 1 day, 18:02:34  time: 0.4845  data_time: 0.0101  memory: 5817  grad_norm: 188.1103  loss: 9.2955  decode.loss_cls: 0.2584  decode.loss_mask: 0.3253  decode.loss_dice: 0.2547  decode.d0.loss_cls: 1.0476  decode.d0.loss_mask: 0.3333  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.4303  decode.d1.loss_mask: 0.2940  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.3671  decode.d2.loss_mask: 0.2978  decode.d2.loss_dice: 0.2794  decode.d3.loss_cls: 0.2225  decode.d3.loss_mask: 0.3317  decode.d3.loss_dice: 0.2587  decode.d4.loss_cls: 0.2243  decode.d4.loss_mask: 0.3341  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.1414  decode.d5.loss_mask: 0.3610  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.2269  decode.d6.loss_mask: 0.3269  decode.d6.loss_dice: 0.2694  decode.d7.loss_cls: 0.2269  decode.d7.loss_mask: 0.3223  decode.d7.loss_dice: 0.2479  decode.d8.loss_cls: 0.2611  decode.d8.loss_mask: 0.3216  decode.d8.loss_dice: 0.2653
09/28 15:28:39 - mmengine - INFO - Iter(train) [  7600/320000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 1 day, 18:02:10  time: 0.4846  data_time: 0.0097  memory: 5816  grad_norm: 163.8248  loss: 10.6511  decode.loss_cls: 0.3845  decode.loss_mask: 0.3106  decode.loss_dice: 0.3586  decode.d0.loss_cls: 1.2029  decode.d0.loss_mask: 0.3011  decode.d0.loss_dice: 0.3270  decode.d1.loss_cls: 0.4570  decode.d1.loss_mask: 0.3009  decode.d1.loss_dice: 0.3439  decode.d2.loss_cls: 0.3173  decode.d2.loss_mask: 0.3072  decode.d2.loss_dice: 0.3299  decode.d3.loss_cls: 0.2830  decode.d3.loss_mask: 0.3333  decode.d3.loss_dice: 0.3397  decode.d4.loss_cls: 0.2788  decode.d4.loss_mask: 0.3129  decode.d4.loss_dice: 0.3192  decode.d5.loss_cls: 0.2954  decode.d5.loss_mask: 0.3203  decode.d5.loss_dice: 0.3521  decode.d6.loss_cls: 0.3389  decode.d6.loss_mask: 0.3074  decode.d6.loss_dice: 0.3376  decode.d7.loss_cls: 0.2800  decode.d7.loss_mask: 0.3110  decode.d7.loss_dice: 0.3451  decode.d8.loss_cls: 0.3165  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.3345
09/28 15:29:03 - mmengine - INFO - Iter(train) [  7650/320000]  base_lr: 9.7846e-05 lr: 9.7846e-06  eta: 1 day, 18:01:55  time: 0.4862  data_time: 0.0102  memory: 5819  grad_norm: 450.0555  loss: 8.0577  decode.loss_cls: 0.1566  decode.loss_mask: 0.2846  decode.loss_dice: 0.2443  decode.d0.loss_cls: 1.0912  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.2149  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.1413  decode.d2.loss_mask: 0.2905  decode.d2.loss_dice: 0.2467  decode.d3.loss_cls: 0.1722  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2551  decode.d4.loss_cls: 0.1871  decode.d4.loss_mask: 0.3008  decode.d4.loss_dice: 0.2580  decode.d5.loss_cls: 0.1711  decode.d5.loss_mask: 0.2946  decode.d5.loss_dice: 0.2542  decode.d6.loss_cls: 0.1766  decode.d6.loss_mask: 0.3055  decode.d6.loss_dice: 0.2571  decode.d7.loss_cls: 0.1796  decode.d7.loss_mask: 0.2872  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.1613  decode.d8.loss_mask: 0.2807  decode.d8.loss_dice: 0.2384
09/28 15:29:28 - mmengine - INFO - Iter(train) [  7700/320000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 1 day, 18:01:30  time: 0.4839  data_time: 0.0100  memory: 5816  grad_norm: 130.2023  loss: 9.5687  decode.loss_cls: 0.2706  decode.loss_mask: 0.2965  decode.loss_dice: 0.3078  decode.d0.loss_cls: 0.9189  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.2551  decode.d1.loss_mask: 0.3085  decode.d1.loss_dice: 0.3257  decode.d2.loss_cls: 0.3097  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.3214  decode.d3.loss_cls: 0.2691  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.3234  decode.d4.loss_cls: 0.2999  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.3197  decode.d5.loss_cls: 0.2891  decode.d5.loss_mask: 0.2957  decode.d5.loss_dice: 0.3168  decode.d6.loss_cls: 0.2876  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.2649  decode.d7.loss_cls: 0.2926  decode.d7.loss_mask: 0.2920  decode.d7.loss_dice: 0.3209  decode.d8.loss_cls: 0.2669  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.3360
09/28 15:29:52 - mmengine - INFO - Iter(train) [  7750/320000]  base_lr: 9.7818e-05 lr: 9.7818e-06  eta: 1 day, 18:01:06  time: 0.4838  data_time: 0.0100  memory: 5800  grad_norm: 162.5352  loss: 9.3016  decode.loss_cls: 0.2494  decode.loss_mask: 0.3710  decode.loss_dice: 0.3482  decode.d0.loss_cls: 1.1201  decode.d0.loss_mask: 0.2755  decode.d0.loss_dice: 0.2907  decode.d1.loss_cls: 0.2463  decode.d1.loss_mask: 0.2794  decode.d1.loss_dice: 0.2943  decode.d2.loss_cls: 0.2297  decode.d2.loss_mask: 0.2803  decode.d2.loss_dice: 0.3146  decode.d3.loss_cls: 0.2583  decode.d3.loss_mask: 0.2642  decode.d3.loss_dice: 0.2906  decode.d4.loss_cls: 0.2871  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.3100  decode.d5.loss_mask: 0.2712  decode.d5.loss_dice: 0.2894  decode.d6.loss_cls: 0.2579  decode.d6.loss_mask: 0.2755  decode.d6.loss_dice: 0.2995  decode.d7.loss_cls: 0.2269  decode.d7.loss_mask: 0.2971  decode.d7.loss_dice: 0.3115  decode.d8.loss_cls: 0.2418  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2934
09/28 15:30:16 - mmengine - INFO - Iter(train) [  7800/320000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 1 day, 18:00:43  time: 0.4845  data_time: 0.0101  memory: 5834  grad_norm: 183.3477  loss: 8.4559  decode.loss_cls: 0.2618  decode.loss_mask: 0.3001  decode.loss_dice: 0.2063  decode.d0.loss_cls: 0.9256  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.2455  decode.d1.loss_mask: 0.2880  decode.d1.loss_dice: 0.2233  decode.d2.loss_cls: 0.2084  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2106  decode.d3.loss_cls: 0.2397  decode.d3.loss_mask: 0.3097  decode.d3.loss_dice: 0.2135  decode.d4.loss_cls: 0.2384  decode.d4.loss_mask: 0.3995  decode.d4.loss_dice: 0.2744  decode.d5.loss_cls: 0.2995  decode.d5.loss_mask: 0.3014  decode.d5.loss_dice: 0.2017  decode.d6.loss_cls: 0.2852  decode.d6.loss_mask: 0.2918  decode.d6.loss_dice: 0.2047  decode.d7.loss_cls: 0.2454  decode.d7.loss_mask: 0.2980  decode.d7.loss_dice: 0.2051  decode.d8.loss_cls: 0.2898  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.2001
09/28 15:30:40 - mmengine - INFO - Iter(train) [  7850/320000]  base_lr: 9.7790e-05 lr: 9.7790e-06  eta: 1 day, 18:00:19  time: 0.4850  data_time: 0.0101  memory: 5834  grad_norm: 176.3619  loss: 9.2867  decode.loss_cls: 0.2917  decode.loss_mask: 0.2571  decode.loss_dice: 0.3047  decode.d0.loss_cls: 1.2319  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.3049  decode.d1.loss_cls: 0.2987  decode.d1.loss_mask: 0.2507  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.2670  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.2773  decode.d3.loss_cls: 0.2694  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.2718  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.2567  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.2893  decode.d6.loss_cls: 0.2768  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.2842  decode.d7.loss_cls: 0.3582  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.2956  decode.d8.loss_cls: 0.3401  decode.d8.loss_mask: 0.2653  decode.d8.loss_dice: 0.2989
09/28 15:31:04 - mmengine - INFO - Iter(train) [  7900/320000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 1 day, 17:59:56  time: 0.4841  data_time: 0.0102  memory: 5834  grad_norm: 209.5451  loss: 11.3108  decode.loss_cls: 0.2879  decode.loss_mask: 0.4771  decode.loss_dice: 0.3297  decode.d0.loss_cls: 1.0268  decode.d0.loss_mask: 0.4065  decode.d0.loss_dice: 0.3012  decode.d1.loss_cls: 0.4292  decode.d1.loss_mask: 0.3993  decode.d1.loss_dice: 0.3110  decode.d2.loss_cls: 0.2349  decode.d2.loss_mask: 0.3698  decode.d2.loss_dice: 0.2870  decode.d3.loss_cls: 0.2784  decode.d3.loss_mask: 0.4589  decode.d3.loss_dice: 0.3208  decode.d4.loss_cls: 0.3023  decode.d4.loss_mask: 0.4058  decode.d4.loss_dice: 0.3230  decode.d5.loss_cls: 0.2535  decode.d5.loss_mask: 0.4133  decode.d5.loss_dice: 0.3171  decode.d6.loss_cls: 0.2946  decode.d6.loss_mask: 0.5848  decode.d6.loss_dice: 0.3117  decode.d7.loss_cls: 0.2896  decode.d7.loss_mask: 0.5304  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.3216  decode.d8.loss_mask: 0.4049  decode.d8.loss_dice: 0.2997
09/28 15:31:29 - mmengine - INFO - Iter(train) [  7950/320000]  base_lr: 9.7762e-05 lr: 9.7762e-06  eta: 1 day, 17:59:32  time: 0.4842  data_time: 0.0100  memory: 5799  grad_norm: 196.5706  loss: 10.1769  decode.loss_cls: 0.3322  decode.loss_mask: 0.3253  decode.loss_dice: 0.2903  decode.d0.loss_cls: 0.9570  decode.d0.loss_mask: 0.3131  decode.d0.loss_dice: 0.2905  decode.d1.loss_cls: 0.4269  decode.d1.loss_mask: 0.3048  decode.d1.loss_dice: 0.3204  decode.d2.loss_cls: 0.3727  decode.d2.loss_mask: 0.3104  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.3690  decode.d3.loss_mask: 0.3021  decode.d3.loss_dice: 0.2761  decode.d4.loss_cls: 0.3911  decode.d4.loss_mask: 0.3005  decode.d4.loss_dice: 0.2850  decode.d5.loss_cls: 0.3409  decode.d5.loss_mask: 0.3015  decode.d5.loss_dice: 0.2775  decode.d6.loss_cls: 0.3263  decode.d6.loss_mask: 0.2995  decode.d6.loss_dice: 0.2688  decode.d7.loss_cls: 0.3639  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.2815  decode.d8.loss_cls: 0.3506  decode.d8.loss_mask: 0.3068  decode.d8.loss_dice: 0.2781
09/28 15:31:53 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:31:53 - mmengine - INFO - Iter(train) [  8000/320000]  base_lr: 9.7747e-05 lr: 9.7747e-06  eta: 1 day, 17:59:08  time: 0.4854  data_time: 0.0103  memory: 5816  grad_norm: 108.9853  loss: 7.3241  decode.loss_cls: 0.1396  decode.loss_mask: 0.2876  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.9897  decode.d0.loss_mask: 0.2722  decode.d0.loss_dice: 0.2295  decode.d1.loss_cls: 0.2628  decode.d1.loss_mask: 0.2770  decode.d1.loss_dice: 0.2063  decode.d2.loss_cls: 0.1335  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2070  decode.d3.loss_cls: 0.1673  decode.d3.loss_mask: 0.2753  decode.d3.loss_dice: 0.2059  decode.d4.loss_cls: 0.1550  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.2074  decode.d6.loss_cls: 0.1406  decode.d6.loss_mask: 0.2775  decode.d6.loss_dice: 0.2153  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.2873  decode.d7.loss_dice: 0.2019  decode.d8.loss_cls: 0.1483  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.2112
09/28 15:32:17 - mmengine - INFO - Iter(train) [  8050/320000]  base_lr: 9.7733e-05 lr: 9.7733e-06  eta: 1 day, 17:58:45  time: 0.4849  data_time: 0.0101  memory: 5816  grad_norm: 231.9515  loss: 10.0922  decode.loss_cls: 0.3916  decode.loss_mask: 0.2728  decode.loss_dice: 0.2487  decode.d0.loss_cls: 1.0906  decode.d0.loss_mask: 0.2805  decode.d0.loss_dice: 0.2614  decode.d1.loss_cls: 0.4004  decode.d1.loss_mask: 0.2745  decode.d1.loss_dice: 0.2589  decode.d2.loss_cls: 0.3635  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.2437  decode.d3.loss_cls: 0.4661  decode.d3.loss_mask: 0.2723  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.3763  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.2634  decode.d5.loss_cls: 0.4200  decode.d5.loss_mask: 0.2827  decode.d5.loss_dice: 0.2594  decode.d6.loss_cls: 0.4861  decode.d6.loss_mask: 0.2859  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.3692  decode.d7.loss_mask: 0.2778  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.4748  decode.d8.loss_mask: 0.2747  decode.d8.loss_dice: 0.2212
09/28 15:32:41 - mmengine - INFO - Iter(train) [  8100/320000]  base_lr: 9.7719e-05 lr: 9.7719e-06  eta: 1 day, 17:58:22  time: 0.4852  data_time: 0.0102  memory: 5816  grad_norm: 217.7409  loss: 9.7454  decode.loss_cls: 0.2737  decode.loss_mask: 0.3180  decode.loss_dice: 0.2613  decode.d0.loss_cls: 0.9946  decode.d0.loss_mask: 0.3199  decode.d0.loss_dice: 0.3049  decode.d1.loss_cls: 0.4485  decode.d1.loss_mask: 0.3104  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.3992  decode.d2.loss_mask: 0.3076  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.3322  decode.d3.loss_mask: 0.3063  decode.d3.loss_dice: 0.2810  decode.d4.loss_cls: 0.2372  decode.d4.loss_mask: 0.3164  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.2880  decode.d5.loss_mask: 0.3202  decode.d5.loss_dice: 0.2807  decode.d6.loss_cls: 0.2975  decode.d6.loss_mask: 0.3139  decode.d6.loss_dice: 0.2860  decode.d7.loss_cls: 0.2769  decode.d7.loss_mask: 0.3177  decode.d7.loss_dice: 0.2765  decode.d8.loss_cls: 0.2421  decode.d8.loss_mask: 0.3198  decode.d8.loss_dice: 0.2838
09/28 15:33:06 - mmengine - INFO - Iter(train) [  8150/320000]  base_lr: 9.7705e-05 lr: 9.7705e-06  eta: 1 day, 17:57:57  time: 0.4849  data_time: 0.0099  memory: 5834  grad_norm: 158.5794  loss: 7.5216  decode.loss_cls: 0.1321  decode.loss_mask: 0.3001  decode.loss_dice: 0.2265  decode.d0.loss_cls: 1.1192  decode.d0.loss_mask: 0.2848  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.1751  decode.d1.loss_mask: 0.3230  decode.d1.loss_dice: 0.2353  decode.d2.loss_cls: 0.1439  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.2228  decode.d3.loss_cls: 0.1305  decode.d3.loss_mask: 0.2920  decode.d3.loss_dice: 0.2156  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 0.2861  decode.d4.loss_dice: 0.2034  decode.d5.loss_cls: 0.1094  decode.d5.loss_mask: 0.2860  decode.d5.loss_dice: 0.2112  decode.d6.loss_cls: 0.1342  decode.d6.loss_mask: 0.3027  decode.d6.loss_dice: 0.2317  decode.d7.loss_cls: 0.1704  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.2076  decode.d8.loss_cls: 0.1464  decode.d8.loss_mask: 0.2955  decode.d8.loss_dice: 0.2171
09/28 15:33:30 - mmengine - INFO - Iter(train) [  8200/320000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 1 day, 17:57:33  time: 0.4838  data_time: 0.0099  memory: 5799  grad_norm: 146.4018  loss: 10.1021  decode.loss_cls: 0.2755  decode.loss_mask: 0.3287  decode.loss_dice: 0.3249  decode.d0.loss_cls: 1.0538  decode.d0.loss_mask: 0.3277  decode.d0.loss_dice: 0.3205  decode.d1.loss_cls: 0.3235  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.3122  decode.d2.loss_cls: 0.3093  decode.d2.loss_mask: 0.3356  decode.d2.loss_dice: 0.3139  decode.d3.loss_cls: 0.2811  decode.d3.loss_mask: 0.3154  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.3045  decode.d4.loss_mask: 0.3265  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.3653  decode.d5.loss_mask: 0.3328  decode.d5.loss_dice: 0.2569  decode.d6.loss_cls: 0.3085  decode.d6.loss_mask: 0.3186  decode.d6.loss_dice: 0.2902  decode.d7.loss_cls: 0.2974  decode.d7.loss_mask: 0.3396  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.3325  decode.d8.loss_mask: 0.3205  decode.d8.loss_dice: 0.2778
09/28 15:33:54 - mmengine - INFO - Iter(train) [  8250/320000]  base_lr: 9.7677e-05 lr: 9.7677e-06  eta: 1 day, 17:57:13  time: 0.4832  data_time: 0.0100  memory: 5816  grad_norm: 226.7922  loss: 7.9996  decode.loss_cls: 0.1608  decode.loss_mask: 0.3954  decode.loss_dice: 0.2318  decode.d0.loss_cls: 0.9623  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.2272  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 0.2759  decode.d1.loss_dice: 0.2492  decode.d2.loss_cls: 0.1922  decode.d2.loss_mask: 0.2681  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 0.2699  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.1601  decode.d4.loss_mask: 0.2671  decode.d4.loss_dice: 0.2431  decode.d5.loss_cls: 0.2286  decode.d5.loss_mask: 0.2713  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.1517  decode.d6.loss_mask: 0.3226  decode.d6.loss_dice: 0.2289  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 0.3928  decode.d7.loss_dice: 0.2290  decode.d8.loss_cls: 0.1865  decode.d8.loss_mask: 0.3578  decode.d8.loss_dice: 0.2184
09/28 15:34:18 - mmengine - INFO - Iter(train) [  8300/320000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 1 day, 17:56:50  time: 0.4863  data_time: 0.0104  memory: 5834  grad_norm: 209.2656  loss: 9.8175  decode.loss_cls: 0.3105  decode.loss_mask: 0.3255  decode.loss_dice: 0.2430  decode.d0.loss_cls: 1.2645  decode.d0.loss_mask: 0.3339  decode.d0.loss_dice: 0.2577  decode.d1.loss_cls: 0.4226  decode.d1.loss_mask: 0.3317  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.3129  decode.d2.loss_mask: 0.3665  decode.d2.loss_dice: 0.2610  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 0.3310  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.2329  decode.d4.loss_mask: 0.3274  decode.d4.loss_dice: 0.2600  decode.d5.loss_cls: 0.3285  decode.d5.loss_mask: 0.3341  decode.d5.loss_dice: 0.2396  decode.d6.loss_cls: 0.2109  decode.d6.loss_mask: 0.3506  decode.d6.loss_dice: 0.2644  decode.d7.loss_cls: 0.2248  decode.d7.loss_mask: 0.3755  decode.d7.loss_dice: 0.2602  decode.d8.loss_cls: 0.3323  decode.d8.loss_mask: 0.3403  decode.d8.loss_dice: 0.2851
09/28 15:34:43 - mmengine - INFO - Iter(train) [  8350/320000]  base_lr: 9.7649e-05 lr: 9.7649e-06  eta: 1 day, 17:56:27  time: 0.4849  data_time: 0.0102  memory: 5835  grad_norm: 275.2251  loss: 7.2221  decode.loss_cls: 0.1624  decode.loss_mask: 0.2436  decode.loss_dice: 0.2350  decode.d0.loss_cls: 1.0967  decode.d0.loss_mask: 0.2332  decode.d0.loss_dice: 0.1847  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2325  decode.d2.loss_cls: 0.1950  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.1733  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.2167  decode.d4.loss_mask: 0.2455  decode.d4.loss_dice: 0.2422  decode.d5.loss_cls: 0.1425  decode.d5.loss_mask: 0.2510  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.1489  decode.d6.loss_mask: 0.2424  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.1733  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.1383  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2011
09/28 15:35:07 - mmengine - INFO - Iter(train) [  8400/320000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 1 day, 17:56:04  time: 0.4851  data_time: 0.0102  memory: 5799  grad_norm: 387.1155  loss: 10.8111  decode.loss_cls: 0.3037  decode.loss_mask: 0.4011  decode.loss_dice: 0.3080  decode.d0.loss_cls: 1.2709  decode.d0.loss_mask: 0.2812  decode.d0.loss_dice: 0.2465  decode.d1.loss_cls: 0.6290  decode.d1.loss_mask: 0.3193  decode.d1.loss_dice: 0.2432  decode.d2.loss_cls: 0.4549  decode.d2.loss_mask: 0.3643  decode.d2.loss_dice: 0.2330  decode.d3.loss_cls: 0.3739  decode.d3.loss_mask: 0.3696  decode.d3.loss_dice: 0.2291  decode.d4.loss_cls: 0.2752  decode.d4.loss_mask: 0.3734  decode.d4.loss_dice: 0.2410  decode.d5.loss_cls: 0.2745  decode.d5.loss_mask: 0.3157  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.3891  decode.d6.loss_mask: 0.3599  decode.d6.loss_dice: 0.2802  decode.d7.loss_cls: 0.3595  decode.d7.loss_mask: 0.4233  decode.d7.loss_dice: 0.2793  decode.d8.loss_cls: 0.3474  decode.d8.loss_mask: 0.3490  decode.d8.loss_dice: 0.2744
09/28 15:35:31 - mmengine - INFO - Iter(train) [  8450/320000]  base_lr: 9.7621e-05 lr: 9.7621e-06  eta: 1 day, 17:55:40  time: 0.4845  data_time: 0.0102  memory: 5799  grad_norm: 683.3232  loss: 12.1992  decode.loss_cls: 0.3369  decode.loss_mask: 0.4146  decode.loss_dice: 0.3897  decode.d0.loss_cls: 1.1702  decode.d0.loss_mask: 0.4657  decode.d0.loss_dice: 0.4009  decode.d1.loss_cls: 0.3071  decode.d1.loss_mask: 0.4713  decode.d1.loss_dice: 0.3808  decode.d2.loss_cls: 0.3083  decode.d2.loss_mask: 0.4484  decode.d2.loss_dice: 0.3885  decode.d3.loss_cls: 0.2524  decode.d3.loss_mask: 0.4395  decode.d3.loss_dice: 0.3786  decode.d4.loss_cls: 0.2547  decode.d4.loss_mask: 0.4276  decode.d4.loss_dice: 0.3870  decode.d5.loss_cls: 0.3423  decode.d5.loss_mask: 0.4331  decode.d5.loss_dice: 0.3854  decode.d6.loss_cls: 0.2494  decode.d6.loss_mask: 0.4308  decode.d6.loss_dice: 0.3904  decode.d7.loss_cls: 0.3451  decode.d7.loss_mask: 0.4376  decode.d7.loss_dice: 0.3919  decode.d8.loss_cls: 0.3700  decode.d8.loss_mask: 0.4201  decode.d8.loss_dice: 0.3812
09/28 15:35:56 - mmengine - INFO - Iter(train) [  8500/320000]  base_lr: 9.7606e-05 lr: 9.7606e-06  eta: 1 day, 17:55:17  time: 0.4854  data_time: 0.0102  memory: 5817  grad_norm: 319.2362  loss: 13.2231  decode.loss_cls: 0.3420  decode.loss_mask: 0.3935  decode.loss_dice: 0.4189  decode.d0.loss_cls: 1.2157  decode.d0.loss_mask: 0.4037  decode.d0.loss_dice: 0.4662  decode.d1.loss_cls: 0.5121  decode.d1.loss_mask: 0.3839  decode.d1.loss_dice: 0.4459  decode.d2.loss_cls: 0.4037  decode.d2.loss_mask: 0.4007  decode.d2.loss_dice: 0.4571  decode.d3.loss_cls: 0.4260  decode.d3.loss_mask: 0.3868  decode.d3.loss_dice: 0.4746  decode.d4.loss_cls: 0.3758  decode.d4.loss_mask: 0.3796  decode.d4.loss_dice: 0.4481  decode.d5.loss_cls: 0.3955  decode.d5.loss_mask: 0.3968  decode.d5.loss_dice: 0.4559  decode.d6.loss_cls: 0.3817  decode.d6.loss_mask: 0.3792  decode.d6.loss_dice: 0.4496  decode.d7.loss_cls: 0.3985  decode.d7.loss_mask: 0.3844  decode.d7.loss_dice: 0.4618  decode.d8.loss_cls: 0.3852  decode.d8.loss_mask: 0.3735  decode.d8.loss_dice: 0.4268
09/28 15:36:20 - mmengine - INFO - Iter(train) [  8550/320000]  base_lr: 9.7592e-05 lr: 9.7592e-06  eta: 1 day, 17:54:54  time: 0.4845  data_time: 0.0100  memory: 5817  grad_norm: 229.9980  loss: 8.2138  decode.loss_cls: 0.1501  decode.loss_mask: 0.3157  decode.loss_dice: 0.2497  decode.d0.loss_cls: 1.0315  decode.d0.loss_mask: 0.2860  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.2230  decode.d1.loss_mask: 0.3079  decode.d1.loss_dice: 0.2429  decode.d2.loss_cls: 0.1850  decode.d2.loss_mask: 0.3076  decode.d2.loss_dice: 0.2463  decode.d3.loss_cls: 0.1715  decode.d3.loss_mask: 0.3266  decode.d3.loss_dice: 0.2651  decode.d4.loss_cls: 0.2032  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.2644  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.2460  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.2365  decode.d7.loss_cls: 0.1559  decode.d7.loss_mask: 0.3072  decode.d7.loss_dice: 0.2474  decode.d8.loss_cls: 0.1927  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.2238
09/28 15:36:44 - mmengine - INFO - Iter(train) [  8600/320000]  base_lr: 9.7578e-05 lr: 9.7578e-06  eta: 1 day, 17:54:31  time: 0.4848  data_time: 0.0101  memory: 5799  grad_norm: 431.7845  loss: 11.7128  decode.loss_cls: 0.3410  decode.loss_mask: 0.4063  decode.loss_dice: 0.3126  decode.d0.loss_cls: 1.1048  decode.d0.loss_mask: 0.4313  decode.d0.loss_dice: 0.3167  decode.d1.loss_cls: 0.3552  decode.d1.loss_mask: 0.4105  decode.d1.loss_dice: 0.3083  decode.d2.loss_cls: 0.3938  decode.d2.loss_mask: 0.4101  decode.d2.loss_dice: 0.2876  decode.d3.loss_cls: 0.3750  decode.d3.loss_mask: 0.3997  decode.d3.loss_dice: 0.2811  decode.d4.loss_cls: 0.3400  decode.d4.loss_mask: 0.4092  decode.d4.loss_dice: 0.2860  decode.d5.loss_cls: 0.3378  decode.d5.loss_mask: 0.4170  decode.d5.loss_dice: 0.3054  decode.d6.loss_cls: 0.3582  decode.d6.loss_mask: 0.4479  decode.d6.loss_dice: 0.3101  decode.d7.loss_cls: 0.2992  decode.d7.loss_mask: 0.5186  decode.d7.loss_dice: 0.3279  decode.d8.loss_cls: 0.3729  decode.d8.loss_mask: 0.5328  decode.d8.loss_dice: 0.3158
09/28 15:37:08 - mmengine - INFO - Iter(train) [  8650/320000]  base_lr: 9.7564e-05 lr: 9.7564e-06  eta: 1 day, 17:54:07  time: 0.4842  data_time: 0.0098  memory: 5834  grad_norm: 113.2777  loss: 10.6956  decode.loss_cls: 0.3716  decode.loss_mask: 0.3261  decode.loss_dice: 0.3291  decode.d0.loss_cls: 1.2287  decode.d0.loss_mask: 0.3230  decode.d0.loss_dice: 0.3529  decode.d1.loss_cls: 0.2979  decode.d1.loss_mask: 0.3294  decode.d1.loss_dice: 0.3200  decode.d2.loss_cls: 0.2642  decode.d2.loss_mask: 0.3269  decode.d2.loss_dice: 0.3041  decode.d3.loss_cls: 0.3233  decode.d3.loss_mask: 0.3256  decode.d3.loss_dice: 0.3366  decode.d4.loss_cls: 0.3180  decode.d4.loss_mask: 0.3204  decode.d4.loss_dice: 0.3231  decode.d5.loss_cls: 0.2957  decode.d5.loss_mask: 0.3343  decode.d5.loss_dice: 0.3369  decode.d6.loss_cls: 0.3350  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.3414  decode.d7.loss_cls: 0.3726  decode.d7.loss_mask: 0.3205  decode.d7.loss_dice: 0.3359  decode.d8.loss_cls: 0.3294  decode.d8.loss_mask: 0.3145  decode.d8.loss_dice: 0.3300
09/28 15:37:32 - mmengine - INFO - Iter(train) [  8700/320000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 1 day, 17:53:42  time: 0.4827  data_time: 0.0099  memory: 5816  grad_norm: 326.5855  loss: 9.6967  decode.loss_cls: 0.3713  decode.loss_mask: 0.3228  decode.loss_dice: 0.2342  decode.d0.loss_cls: 1.2704  decode.d0.loss_mask: 0.3150  decode.d0.loss_dice: 0.2515  decode.d1.loss_cls: 0.3385  decode.d1.loss_mask: 0.3075  decode.d1.loss_dice: 0.2298  decode.d2.loss_cls: 0.2693  decode.d2.loss_mask: 0.3111  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.2871  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.2470  decode.d4.loss_cls: 0.2628  decode.d4.loss_mask: 0.3205  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.2822  decode.d5.loss_mask: 0.3249  decode.d5.loss_dice: 0.2406  decode.d6.loss_cls: 0.2980  decode.d6.loss_mask: 0.3350  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.3330  decode.d7.loss_mask: 0.3208  decode.d7.loss_dice: 0.2431  decode.d8.loss_cls: 0.3568  decode.d8.loss_mask: 0.3257  decode.d8.loss_dice: 0.2458
09/28 15:37:57 - mmengine - INFO - Iter(train) [  8750/320000]  base_lr: 9.7536e-05 lr: 9.7536e-06  eta: 1 day, 17:53:18  time: 0.4859  data_time: 0.0106  memory: 5799  grad_norm: 487.1788  loss: 12.7088  decode.loss_cls: 0.3755  decode.loss_mask: 0.3537  decode.loss_dice: 0.4451  decode.d0.loss_cls: 1.2830  decode.d0.loss_mask: 0.3189  decode.d0.loss_dice: 0.4757  decode.d1.loss_cls: 0.5631  decode.d1.loss_mask: 0.3501  decode.d1.loss_dice: 0.4429  decode.d2.loss_cls: 0.3913  decode.d2.loss_mask: 0.3335  decode.d2.loss_dice: 0.4294  decode.d3.loss_cls: 0.4280  decode.d3.loss_mask: 0.3197  decode.d3.loss_dice: 0.4368  decode.d4.loss_cls: 0.4114  decode.d4.loss_mask: 0.3304  decode.d4.loss_dice: 0.4633  decode.d5.loss_cls: 0.4164  decode.d5.loss_mask: 0.3119  decode.d5.loss_dice: 0.4327  decode.d6.loss_cls: 0.3876  decode.d6.loss_mask: 0.3207  decode.d6.loss_dice: 0.4549  decode.d7.loss_cls: 0.3150  decode.d7.loss_mask: 0.3523  decode.d7.loss_dice: 0.4688  decode.d8.loss_cls: 0.2680  decode.d8.loss_mask: 0.3524  decode.d8.loss_dice: 0.4762
09/28 15:38:21 - mmengine - INFO - Iter(train) [  8800/320000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 1 day, 17:52:58  time: 0.4852  data_time: 0.0103  memory: 5817  grad_norm: 221.1358  loss: 7.8534  decode.loss_cls: 0.1426  decode.loss_mask: 0.3027  decode.loss_dice: 0.2561  decode.d0.loss_cls: 1.0405  decode.d0.loss_mask: 0.3018  decode.d0.loss_dice: 0.2359  decode.d1.loss_cls: 0.1757  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.2516  decode.d2.loss_cls: 0.1790  decode.d2.loss_mask: 0.2840  decode.d2.loss_dice: 0.2420  decode.d3.loss_cls: 0.1191  decode.d3.loss_mask: 0.2855  decode.d3.loss_dice: 0.2225  decode.d4.loss_cls: 0.1032  decode.d4.loss_mask: 0.3023  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.1543  decode.d5.loss_mask: 0.2936  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.1499  decode.d6.loss_mask: 0.2996  decode.d6.loss_dice: 0.2498  decode.d7.loss_cls: 0.1651  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.2555  decode.d8.loss_cls: 0.1499  decode.d8.loss_mask: 0.3223  decode.d8.loss_dice: 0.2661
09/28 15:38:45 - mmengine - INFO - Iter(train) [  8850/320000]  base_lr: 9.7508e-05 lr: 9.7508e-06  eta: 1 day, 17:52:32  time: 0.4838  data_time: 0.0097  memory: 5817  grad_norm: 155.1312  loss: 8.1754  decode.loss_cls: 0.2319  decode.loss_mask: 0.2801  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.9480  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.2449  decode.d1.loss_cls: 0.2495  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.1854  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2300  decode.d3.loss_cls: 0.1906  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.2336  decode.d4.loss_cls: 0.2079  decode.d4.loss_mask: 0.2821  decode.d4.loss_dice: 0.2629  decode.d5.loss_cls: 0.2206  decode.d5.loss_mask: 0.2784  decode.d5.loss_dice: 0.2618  decode.d6.loss_cls: 0.2184  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.2331  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 0.2824  decode.d7.loss_dice: 0.2418  decode.d8.loss_cls: 0.2006  decode.d8.loss_mask: 0.2976  decode.d8.loss_dice: 0.2547
09/28 15:39:09 - mmengine - INFO - Iter(train) [  8900/320000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 1 day, 17:52:08  time: 0.4831  data_time: 0.0101  memory: 5816  grad_norm: 164.3563  loss: 11.1164  decode.loss_cls: 0.4167  decode.loss_mask: 0.3310  decode.loss_dice: 0.2805  decode.d0.loss_cls: 1.1272  decode.d0.loss_mask: 0.4128  decode.d0.loss_dice: 0.3139  decode.d1.loss_cls: 0.5595  decode.d1.loss_mask: 0.3453  decode.d1.loss_dice: 0.2864  decode.d2.loss_cls: 0.4374  decode.d2.loss_mask: 0.3545  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.3945  decode.d3.loss_mask: 0.4076  decode.d3.loss_dice: 0.2807  decode.d4.loss_cls: 0.3807  decode.d4.loss_mask: 0.3217  decode.d4.loss_dice: 0.2973  decode.d5.loss_cls: 0.3581  decode.d5.loss_mask: 0.3144  decode.d5.loss_dice: 0.3077  decode.d6.loss_cls: 0.3128  decode.d6.loss_mask: 0.3358  decode.d6.loss_dice: 0.2818  decode.d7.loss_cls: 0.3687  decode.d7.loss_mask: 0.3419  decode.d7.loss_dice: 0.2890  decode.d8.loss_cls: 0.3449  decode.d8.loss_mask: 0.3693  decode.d8.loss_dice: 0.2812
09/28 15:39:34 - mmengine - INFO - Iter(train) [  8950/320000]  base_lr: 9.7480e-05 lr: 9.7480e-06  eta: 1 day, 17:51:44  time: 0.4856  data_time: 0.0106  memory: 5817  grad_norm: 857.7036  loss: 10.7077  decode.loss_cls: 0.2696  decode.loss_mask: 0.4075  decode.loss_dice: 0.3178  decode.d0.loss_cls: 1.0276  decode.d0.loss_mask: 0.4176  decode.d0.loss_dice: 0.3339  decode.d1.loss_cls: 0.2801  decode.d1.loss_mask: 0.4251  decode.d1.loss_dice: 0.3228  decode.d2.loss_cls: 0.2755  decode.d2.loss_mask: 0.4272  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.2848  decode.d3.loss_mask: 0.4159  decode.d3.loss_dice: 0.3278  decode.d4.loss_cls: 0.2689  decode.d4.loss_mask: 0.3984  decode.d4.loss_dice: 0.3149  decode.d5.loss_cls: 0.2446  decode.d5.loss_mask: 0.3993  decode.d5.loss_dice: 0.3209  decode.d6.loss_cls: 0.2198  decode.d6.loss_mask: 0.3970  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.2307  decode.d7.loss_mask: 0.4019  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.2783  decode.d8.loss_mask: 0.3960  decode.d8.loss_dice: 0.3204
09/28 15:39:58 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:39:58 - mmengine - INFO - Iter(train) [  9000/320000]  base_lr: 9.7465e-05 lr: 9.7465e-06  eta: 1 day, 17:51:18  time: 0.4834  data_time: 0.0098  memory: 5799  grad_norm: 137.8349  loss: 6.2684  decode.loss_cls: 0.0989  decode.loss_mask: 0.2695  decode.loss_dice: 0.1680  decode.d0.loss_cls: 0.8321  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.1788  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.1700  decode.d2.loss_cls: 0.1277  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.1692  decode.d3.loss_cls: 0.1056  decode.d3.loss_mask: 0.2702  decode.d3.loss_dice: 0.1718  decode.d4.loss_cls: 0.1270  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.1694  decode.d5.loss_cls: 0.1227  decode.d5.loss_mask: 0.2686  decode.d5.loss_dice: 0.1682  decode.d6.loss_cls: 0.1255  decode.d6.loss_mask: 0.2653  decode.d6.loss_dice: 0.1662  decode.d7.loss_cls: 0.1262  decode.d7.loss_mask: 0.2655  decode.d7.loss_dice: 0.1691  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.2660  decode.d8.loss_dice: 0.1745
09/28 15:40:22 - mmengine - INFO - Iter(train) [  9050/320000]  base_lr: 9.7451e-05 lr: 9.7451e-06  eta: 1 day, 17:50:53  time: 0.4829  data_time: 0.0099  memory: 5817  grad_norm: 187.9558  loss: 10.3098  decode.loss_cls: 0.3277  decode.loss_mask: 0.3257  decode.loss_dice: 0.3568  decode.d0.loss_cls: 1.1766  decode.d0.loss_mask: 0.3281  decode.d0.loss_dice: 0.3664  decode.d1.loss_cls: 0.3559  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3306  decode.d2.loss_cls: 0.3405  decode.d2.loss_mask: 0.2807  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.3067  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.2337  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 0.2553  decode.d5.loss_mask: 0.2839  decode.d5.loss_dice: 0.3498  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.3561  decode.d7.loss_cls: 0.2733  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.3198  decode.d8.loss_cls: 0.2808  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.3752
09/28 15:40:46 - mmengine - INFO - Iter(train) [  9100/320000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 1 day, 17:50:34  time: 0.4832  data_time: 0.0101  memory: 5817  grad_norm: 161.6468  loss: 7.3537  decode.loss_cls: 0.1880  decode.loss_mask: 0.2664  decode.loss_dice: 0.2103  decode.d0.loss_cls: 0.8587  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.2211  decode.d1.loss_cls: 0.1676  decode.d1.loss_mask: 0.2721  decode.d1.loss_dice: 0.2226  decode.d2.loss_cls: 0.1357  decode.d2.loss_mask: 0.2743  decode.d2.loss_dice: 0.2115  decode.d3.loss_cls: 0.1509  decode.d3.loss_mask: 0.2741  decode.d3.loss_dice: 0.2174  decode.d4.loss_cls: 0.1576  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.2071  decode.d5.loss_cls: 0.2040  decode.d5.loss_mask: 0.2787  decode.d5.loss_dice: 0.2108  decode.d6.loss_cls: 0.1909  decode.d6.loss_mask: 0.2737  decode.d6.loss_dice: 0.2192  decode.d7.loss_cls: 0.1812  decode.d7.loss_mask: 0.2747  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.2281  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.2140
09/28 15:41:11 - mmengine - INFO - Iter(train) [  9150/320000]  base_lr: 9.7423e-05 lr: 9.7423e-06  eta: 1 day, 17:50:11  time: 0.4848  data_time: 0.0104  memory: 5817  grad_norm: 108.4247  loss: 6.7087  decode.loss_cls: 0.1295  decode.loss_mask: 0.2371  decode.loss_dice: 0.2253  decode.d0.loss_cls: 0.8973  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.1920  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.2221  decode.d2.loss_cls: 0.1653  decode.d2.loss_mask: 0.2349  decode.d2.loss_dice: 0.2186  decode.d3.loss_cls: 0.1191  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.1362  decode.d4.loss_mask: 0.2340  decode.d4.loss_dice: 0.2166  decode.d5.loss_cls: 0.1442  decode.d5.loss_mask: 0.2381  decode.d5.loss_dice: 0.2153  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.2362  decode.d7.loss_dice: 0.2144  decode.d8.loss_cls: 0.1191  decode.d8.loss_mask: 0.2415  decode.d8.loss_dice: 0.2252
09/28 15:41:35 - mmengine - INFO - Iter(train) [  9200/320000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 1 day, 17:49:47  time: 0.4856  data_time: 0.0103  memory: 5817  grad_norm: 75.2515  loss: 9.4361  decode.loss_cls: 0.2938  decode.loss_mask: 0.2732  decode.loss_dice: 0.3192  decode.d0.loss_cls: 1.0675  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.3235  decode.d1.loss_cls: 0.3544  decode.d1.loss_mask: 0.2801  decode.d1.loss_dice: 0.3188  decode.d2.loss_cls: 0.2616  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.2754  decode.d3.loss_cls: 0.2711  decode.d3.loss_mask: 0.2673  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.2812  decode.d4.loss_mask: 0.2744  decode.d4.loss_dice: 0.3080  decode.d5.loss_cls: 0.2660  decode.d5.loss_mask: 0.2752  decode.d5.loss_dice: 0.2842  decode.d6.loss_cls: 0.2706  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.3137  decode.d7.loss_cls: 0.2814  decode.d7.loss_mask: 0.2742  decode.d7.loss_dice: 0.3371  decode.d8.loss_cls: 0.2530  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.3359
09/28 15:41:59 - mmengine - INFO - Iter(train) [  9250/320000]  base_lr: 9.7395e-05 lr: 9.7395e-06  eta: 1 day, 17:49:22  time: 0.4842  data_time: 0.0099  memory: 5835  grad_norm: 188.5568  loss: 10.2018  decode.loss_cls: 0.2494  decode.loss_mask: 0.3113  decode.loss_dice: 0.3199  decode.d0.loss_cls: 1.0948  decode.d0.loss_mask: 0.3074  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.4472  decode.d1.loss_mask: 0.3209  decode.d1.loss_dice: 0.3202  decode.d2.loss_cls: 0.2961  decode.d2.loss_mask: 0.3174  decode.d2.loss_dice: 0.3236  decode.d3.loss_cls: 0.3749  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.3322  decode.d4.loss_cls: 0.2582  decode.d4.loss_mask: 0.3186  decode.d4.loss_dice: 0.3161  decode.d5.loss_cls: 0.3192  decode.d5.loss_mask: 0.3158  decode.d5.loss_dice: 0.3243  decode.d6.loss_cls: 0.3259  decode.d6.loss_mask: 0.3152  decode.d6.loss_dice: 0.3057  decode.d7.loss_cls: 0.2619  decode.d7.loss_mask: 0.3176  decode.d7.loss_dice: 0.3283  decode.d8.loss_cls: 0.1982  decode.d8.loss_mask: 0.3169  decode.d8.loss_dice: 0.3229
09/28 15:42:23 - mmengine - INFO - Iter(train) [  9300/320000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 1 day, 17:48:58  time: 0.4832  data_time: 0.0099  memory: 5798  grad_norm: 710.2413  loss: 14.0852  decode.loss_cls: 0.7752  decode.loss_mask: 0.3671  decode.loss_dice: 0.3277  decode.d0.loss_cls: 1.1950  decode.d0.loss_mask: 0.3713  decode.d0.loss_dice: 0.3596  decode.d1.loss_cls: 0.6513  decode.d1.loss_mask: 0.4017  decode.d1.loss_dice: 0.3098  decode.d2.loss_cls: 0.6656  decode.d2.loss_mask: 0.3658  decode.d2.loss_dice: 0.3018  decode.d3.loss_cls: 0.5788  decode.d3.loss_mask: 0.3545  decode.d3.loss_dice: 0.2973  decode.d4.loss_cls: 0.5376  decode.d4.loss_mask: 0.3289  decode.d4.loss_dice: 0.3199  decode.d5.loss_cls: 0.5580  decode.d5.loss_mask: 0.3798  decode.d5.loss_dice: 0.3208  decode.d6.loss_cls: 0.6502  decode.d6.loss_mask: 0.3652  decode.d6.loss_dice: 0.2993  decode.d7.loss_cls: 0.8671  decode.d7.loss_mask: 0.3403  decode.d7.loss_dice: 0.3284  decode.d8.loss_cls: 0.7950  decode.d8.loss_mask: 0.3535  decode.d8.loss_dice: 0.3189
09/28 15:42:48 - mmengine - INFO - Iter(train) [  9350/320000]  base_lr: 9.7367e-05 lr: 9.7367e-06  eta: 1 day, 17:48:34  time: 0.4851  data_time: 0.0103  memory: 5817  grad_norm: 109.6243  loss: 11.0281  decode.loss_cls: 0.3384  decode.loss_mask: 0.2907  decode.loss_dice: 0.3539  decode.d0.loss_cls: 1.1552  decode.d0.loss_mask: 0.3149  decode.d0.loss_dice: 0.3945  decode.d1.loss_cls: 0.5140  decode.d1.loss_mask: 0.2925  decode.d1.loss_dice: 0.3501  decode.d2.loss_cls: 0.4593  decode.d2.loss_mask: 0.3056  decode.d2.loss_dice: 0.3372  decode.d3.loss_cls: 0.5071  decode.d3.loss_mask: 0.2928  decode.d3.loss_dice: 0.3379  decode.d4.loss_cls: 0.3382  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3528  decode.d5.loss_cls: 0.3109  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.3503  decode.d6.loss_cls: 0.2824  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.3547  decode.d7.loss_cls: 0.3319  decode.d7.loss_mask: 0.2906  decode.d7.loss_dice: 0.3303  decode.d8.loss_cls: 0.3210  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.3361
09/28 15:43:12 - mmengine - INFO - Iter(train) [  9400/320000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 1 day, 17:48:10  time: 0.4848  data_time: 0.0097  memory: 5834  grad_norm: 237.3393  loss: 10.0508  decode.loss_cls: 0.2649  decode.loss_mask: 0.3702  decode.loss_dice: 0.2554  decode.d0.loss_cls: 1.0490  decode.d0.loss_mask: 0.3669  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.3083  decode.d1.loss_mask: 0.3686  decode.d1.loss_dice: 0.2593  decode.d2.loss_cls: 0.2910  decode.d2.loss_mask: 0.3699  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.3015  decode.d3.loss_mask: 0.4233  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.2752  decode.d4.loss_mask: 0.4140  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.2658  decode.d5.loss_mask: 0.4089  decode.d5.loss_dice: 0.2769  decode.d6.loss_cls: 0.2700  decode.d6.loss_mask: 0.3849  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.2706  decode.d7.loss_mask: 0.3735  decode.d7.loss_dice: 0.2589  decode.d8.loss_cls: 0.2469  decode.d8.loss_mask: 0.3723  decode.d8.loss_dice: 0.2564
09/28 15:43:36 - mmengine - INFO - Iter(train) [  9450/320000]  base_lr: 9.7338e-05 lr: 9.7338e-06  eta: 1 day, 17:47:46  time: 0.4836  data_time: 0.0100  memory: 5833  grad_norm: 1632.7755  loss: 10.9155  decode.loss_cls: 0.3415  decode.loss_mask: 0.3129  decode.loss_dice: 0.3335  decode.d0.loss_cls: 1.1700  decode.d0.loss_mask: 0.2962  decode.d0.loss_dice: 0.3478  decode.d1.loss_cls: 0.4998  decode.d1.loss_mask: 0.3011  decode.d1.loss_dice: 0.3216  decode.d2.loss_cls: 0.3707  decode.d2.loss_mask: 0.2955  decode.d2.loss_dice: 0.3348  decode.d3.loss_cls: 0.3466  decode.d3.loss_mask: 0.2997  decode.d3.loss_dice: 0.3423  decode.d4.loss_cls: 0.3308  decode.d4.loss_mask: 0.3189  decode.d4.loss_dice: 0.3589  decode.d5.loss_cls: 0.3152  decode.d5.loss_mask: 0.3407  decode.d5.loss_dice: 0.3558  decode.d6.loss_cls: 0.3031  decode.d6.loss_mask: 0.3313  decode.d6.loss_dice: 0.3478  decode.d7.loss_cls: 0.3216  decode.d7.loss_mask: 0.3127  decode.d7.loss_dice: 0.3490  decode.d8.loss_cls: 0.3534  decode.d8.loss_mask: 0.3184  decode.d8.loss_dice: 0.3437
09/28 15:44:00 - mmengine - INFO - Iter(train) [  9500/320000]  base_lr: 9.7324e-05 lr: 9.7324e-06  eta: 1 day, 17:47:23  time: 0.4851  data_time: 0.0102  memory: 5834  grad_norm: 948.3710  loss: 10.6628  decode.loss_cls: 0.3589  decode.loss_mask: 0.3194  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.3237  decode.d0.loss_mask: 0.3026  decode.d0.loss_dice: 0.3153  decode.d1.loss_cls: 0.3595  decode.d1.loss_mask: 0.3310  decode.d1.loss_dice: 0.2806  decode.d2.loss_cls: 0.4002  decode.d2.loss_mask: 0.3193  decode.d2.loss_dice: 0.2873  decode.d3.loss_cls: 0.3905  decode.d3.loss_mask: 0.3155  decode.d3.loss_dice: 0.2745  decode.d4.loss_cls: 0.4218  decode.d4.loss_mask: 0.3096  decode.d4.loss_dice: 0.2771  decode.d5.loss_cls: 0.3806  decode.d5.loss_mask: 0.3356  decode.d5.loss_dice: 0.2930  decode.d6.loss_cls: 0.3059  decode.d6.loss_mask: 0.3224  decode.d6.loss_dice: 0.3053  decode.d7.loss_cls: 0.3063  decode.d7.loss_mask: 0.3226  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.3345  decode.d8.loss_mask: 0.3172  decode.d8.loss_dice: 0.2811
09/28 15:44:25 - mmengine - INFO - Iter(train) [  9550/320000]  base_lr: 9.7310e-05 lr: 9.7310e-06  eta: 1 day, 17:46:59  time: 0.4849  data_time: 0.0102  memory: 5834  grad_norm: 412.9315  loss: 9.9651  decode.loss_cls: 0.1931  decode.loss_mask: 0.4029  decode.loss_dice: 0.3342  decode.d0.loss_cls: 0.7732  decode.d0.loss_mask: 0.4243  decode.d0.loss_dice: 0.3117  decode.d1.loss_cls: 0.2080  decode.d1.loss_mask: 0.4045  decode.d1.loss_dice: 0.2967  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.4093  decode.d2.loss_dice: 0.2923  decode.d3.loss_cls: 0.2393  decode.d3.loss_mask: 0.4101  decode.d3.loss_dice: 0.3203  decode.d4.loss_cls: 0.2542  decode.d4.loss_mask: 0.3561  decode.d4.loss_dice: 0.3040  decode.d5.loss_cls: 0.2577  decode.d5.loss_mask: 0.4033  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.2552  decode.d6.loss_mask: 0.3943  decode.d6.loss_dice: 0.3162  decode.d7.loss_cls: 0.2344  decode.d7.loss_mask: 0.3968  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.3345
09/28 15:44:49 - mmengine - INFO - Iter(train) [  9600/320000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 1 day, 17:46:35  time: 0.4843  data_time: 0.0099  memory: 5834  grad_norm: 92.9559  loss: 7.2501  decode.loss_cls: 0.1143  decode.loss_mask: 0.3274  decode.loss_dice: 0.2203  decode.d0.loss_cls: 0.8554  decode.d0.loss_mask: 0.3325  decode.d0.loss_dice: 0.2120  decode.d1.loss_cls: 0.1387  decode.d1.loss_mask: 0.3182  decode.d1.loss_dice: 0.2051  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 0.3160  decode.d2.loss_dice: 0.2117  decode.d3.loss_cls: 0.1111  decode.d3.loss_mask: 0.3212  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.0967  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.2113  decode.d5.loss_cls: 0.1035  decode.d5.loss_mask: 0.3079  decode.d5.loss_dice: 0.2087  decode.d6.loss_cls: 0.1296  decode.d6.loss_mask: 0.3188  decode.d6.loss_dice: 0.2178  decode.d7.loss_cls: 0.1050  decode.d7.loss_mask: 0.3295  decode.d7.loss_dice: 0.2151  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 0.3411  decode.d8.loss_dice: 0.2155
09/28 15:45:13 - mmengine - INFO - Iter(train) [  9650/320000]  base_lr: 9.7282e-05 lr: 9.7282e-06  eta: 1 day, 17:46:10  time: 0.4837  data_time: 0.0102  memory: 5816  grad_norm: 180.7473  loss: 9.9571  decode.loss_cls: 0.1726  decode.loss_mask: 0.3701  decode.loss_dice: 0.3169  decode.d0.loss_cls: 1.1197  decode.d0.loss_mask: 0.3873  decode.d0.loss_dice: 0.3385  decode.d1.loss_cls: 0.2972  decode.d1.loss_mask: 0.3586  decode.d1.loss_dice: 0.3049  decode.d2.loss_cls: 0.2542  decode.d2.loss_mask: 0.3631  decode.d2.loss_dice: 0.3297  decode.d3.loss_cls: 0.1962  decode.d3.loss_mask: 0.3785  decode.d3.loss_dice: 0.3102  decode.d4.loss_cls: 0.1981  decode.d4.loss_mask: 0.3547  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.2288  decode.d5.loss_mask: 0.3639  decode.d5.loss_dice: 0.3173  decode.d6.loss_cls: 0.2367  decode.d6.loss_mask: 0.4017  decode.d6.loss_dice: 0.3069  decode.d7.loss_cls: 0.1820  decode.d7.loss_mask: 0.3789  decode.d7.loss_dice: 0.3196  decode.d8.loss_cls: 0.1892  decode.d8.loss_mask: 0.3623  decode.d8.loss_dice: 0.3071
09/28 15:45:37 - mmengine - INFO - Iter(train) [  9700/320000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 1 day, 17:45:51  time: 0.4849  data_time: 0.0103  memory: 5834  grad_norm: 740.8586  loss: 9.2239  decode.loss_cls: 0.1902  decode.loss_mask: 0.3166  decode.loss_dice: 0.2726  decode.d0.loss_cls: 1.0327  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.4038  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.3635  decode.d2.loss_mask: 0.3115  decode.d2.loss_dice: 0.2675  decode.d3.loss_cls: 0.2405  decode.d3.loss_mask: 0.3517  decode.d3.loss_dice: 0.2871  decode.d4.loss_cls: 0.2363  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.2642  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.3047  decode.d5.loss_dice: 0.2660  decode.d6.loss_cls: 0.2112  decode.d6.loss_mask: 0.3305  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.2109  decode.d7.loss_mask: 0.3232  decode.d7.loss_dice: 0.2729  decode.d8.loss_cls: 0.1712  decode.d8.loss_mask: 0.3274  decode.d8.loss_dice: 0.2701
09/28 15:46:02 - mmengine - INFO - Iter(train) [  9750/320000]  base_lr: 9.7254e-05 lr: 9.7254e-06  eta: 1 day, 17:45:27  time: 0.4858  data_time: 0.0102  memory: 5816  grad_norm: 51.8601  loss: 5.8973  decode.loss_cls: 0.0274  decode.loss_mask: 0.2420  decode.loss_dice: 0.2330  decode.d0.loss_cls: 0.8457  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.2277  decode.d1.loss_cls: 0.0935  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2268  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.0373  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.2418  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0435  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2305  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2207
09/28 15:46:26 - mmengine - INFO - Iter(train) [  9800/320000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 1 day, 17:45:03  time: 0.4838  data_time: 0.0099  memory: 5817  grad_norm: 426.6102  loss: 10.7861  decode.loss_cls: 0.3147  decode.loss_mask: 0.3492  decode.loss_dice: 0.3297  decode.d0.loss_cls: 1.2739  decode.d0.loss_mask: 0.3414  decode.d0.loss_dice: 0.3238  decode.d1.loss_cls: 0.3480  decode.d1.loss_mask: 0.3574  decode.d1.loss_dice: 0.3087  decode.d2.loss_cls: 0.2724  decode.d2.loss_mask: 0.3219  decode.d2.loss_dice: 0.3001  decode.d3.loss_cls: 0.3131  decode.d3.loss_mask: 0.3260  decode.d3.loss_dice: 0.3269  decode.d4.loss_cls: 0.3389  decode.d4.loss_mask: 0.3293  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 0.2892  decode.d5.loss_mask: 0.3741  decode.d5.loss_dice: 0.3420  decode.d6.loss_cls: 0.3673  decode.d6.loss_mask: 0.3419  decode.d6.loss_dice: 0.3277  decode.d7.loss_cls: 0.4164  decode.d7.loss_mask: 0.3198  decode.d7.loss_dice: 0.3107  decode.d8.loss_cls: 0.2264  decode.d8.loss_mask: 0.3532  decode.d8.loss_dice: 0.3409
09/28 15:46:50 - mmengine - INFO - Iter(train) [  9850/320000]  base_lr: 9.7226e-05 lr: 9.7226e-06  eta: 1 day, 17:44:39  time: 0.4844  data_time: 0.0101  memory: 5816  grad_norm: 211.7072  loss: 10.2563  decode.loss_cls: 0.2975  decode.loss_mask: 0.3798  decode.loss_dice: 0.3903  decode.d0.loss_cls: 1.1620  decode.d0.loss_mask: 0.3273  decode.d0.loss_dice: 0.3220  decode.d1.loss_cls: 0.2851  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3013  decode.d2.loss_cls: 0.2372  decode.d2.loss_mask: 0.3184  decode.d2.loss_dice: 0.3397  decode.d3.loss_cls: 0.2307  decode.d3.loss_mask: 0.3173  decode.d3.loss_dice: 0.3130  decode.d4.loss_cls: 0.2635  decode.d4.loss_mask: 0.3305  decode.d4.loss_dice: 0.3673  decode.d5.loss_cls: 0.2741  decode.d5.loss_mask: 0.3094  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.2462  decode.d6.loss_mask: 0.3147  decode.d6.loss_dice: 0.3194  decode.d7.loss_cls: 0.2511  decode.d7.loss_mask: 0.3320  decode.d7.loss_dice: 0.3545  decode.d8.loss_cls: 0.2683  decode.d8.loss_mask: 0.3762  decode.d8.loss_dice: 0.3875
09/28 15:47:14 - mmengine - INFO - Iter(train) [  9900/320000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 1 day, 17:44:15  time: 0.4867  data_time: 0.0105  memory: 5816  grad_norm: 128.8977  loss: 6.7471  decode.loss_cls: 0.1464  decode.loss_mask: 0.2248  decode.loss_dice: 0.2046  decode.d0.loss_cls: 0.9654  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.1868  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2051  decode.d2.loss_cls: 0.1649  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.2209  decode.d3.loss_cls: 0.1605  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.2121  decode.d4.loss_cls: 0.1340  decode.d4.loss_mask: 0.2282  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.1523  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.2102  decode.d6.loss_cls: 0.1567  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.1724  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.2016  decode.d8.loss_cls: 0.1452  decode.d8.loss_mask: 0.2237  decode.d8.loss_dice: 0.1998
09/28 15:47:39 - mmengine - INFO - Iter(train) [  9950/320000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 1 day, 17:43:51  time: 0.4846  data_time: 0.0099  memory: 5817  grad_norm: 318.7421  loss: 7.0766  decode.loss_cls: 0.0821  decode.loss_mask: 0.2606  decode.loss_dice: 0.2532  decode.d0.loss_cls: 0.8944  decode.d0.loss_mask: 0.2841  decode.d0.loss_dice: 0.2711  decode.d1.loss_cls: 0.1438  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.1167  decode.d2.loss_mask: 0.2683  decode.d2.loss_dice: 0.2538  decode.d3.loss_cls: 0.1059  decode.d3.loss_mask: 0.2675  decode.d3.loss_dice: 0.2579  decode.d4.loss_cls: 0.1225  decode.d4.loss_mask: 0.2665  decode.d4.loss_dice: 0.2550  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.2603  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.2604  decode.d6.loss_dice: 0.2533  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.2639  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.2580  decode.d8.loss_dice: 0.2428
09/28 15:48:03 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:48:03 - mmengine - INFO - Iter(train) [ 10000/320000]  base_lr: 9.7183e-05 lr: 9.7183e-06  eta: 1 day, 17:43:26  time: 0.4829  data_time: 0.0101  memory: 5817  grad_norm: 73.1217  loss: 7.3579  decode.loss_cls: 0.1566  decode.loss_mask: 0.2636  decode.loss_dice: 0.2392  decode.d0.loss_cls: 1.0721  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.1347  decode.d1.loss_mask: 0.2678  decode.d1.loss_dice: 0.2376  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 0.2675  decode.d2.loss_dice: 0.2370  decode.d3.loss_cls: 0.1022  decode.d3.loss_mask: 0.2708  decode.d3.loss_dice: 0.2348  decode.d4.loss_cls: 0.1382  decode.d4.loss_mask: 0.2665  decode.d4.loss_dice: 0.2400  decode.d5.loss_cls: 0.1531  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.2348  decode.d6.loss_cls: 0.1352  decode.d6.loss_mask: 0.2608  decode.d6.loss_dice: 0.2334  decode.d7.loss_cls: 0.1504  decode.d7.loss_mask: 0.2564  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.1587  decode.d8.loss_mask: 0.2643  decode.d8.loss_dice: 0.2251
09/28 15:48:27 - mmengine - INFO - Iter(train) [ 10050/320000]  base_lr: 9.7169e-05 lr: 9.7169e-06  eta: 1 day, 17:43:03  time: 0.4852  data_time: 0.0103  memory: 5817  grad_norm: 294.5501  loss: 11.9862  decode.loss_cls: 0.3319  decode.loss_mask: 0.4164  decode.loss_dice: 0.3474  decode.d0.loss_cls: 0.9887  decode.d0.loss_mask: 0.4254  decode.d0.loss_dice: 0.3924  decode.d1.loss_cls: 0.4201  decode.d1.loss_mask: 0.4345  decode.d1.loss_dice: 0.3690  decode.d2.loss_cls: 0.3510  decode.d2.loss_mask: 0.4175  decode.d2.loss_dice: 0.3508  decode.d3.loss_cls: 0.4235  decode.d3.loss_mask: 0.4091  decode.d3.loss_dice: 0.3443  decode.d4.loss_cls: 0.3173  decode.d4.loss_mask: 0.4057  decode.d4.loss_dice: 0.3403  decode.d5.loss_cls: 0.3632  decode.d5.loss_mask: 0.4138  decode.d5.loss_dice: 0.3495  decode.d6.loss_cls: 0.3674  decode.d6.loss_mask: 0.4145  decode.d6.loss_dice: 0.3352  decode.d7.loss_cls: 0.3605  decode.d7.loss_mask: 0.4138  decode.d7.loss_dice: 0.3571  decode.d8.loss_cls: 0.3508  decode.d8.loss_mask: 0.4172  decode.d8.loss_dice: 0.3579
09/28 15:48:51 - mmengine - INFO - Iter(train) [ 10100/320000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 1 day, 17:42:40  time: 0.4851  data_time: 0.0101  memory: 5835  grad_norm: 82.5085  loss: 7.5563  decode.loss_cls: 0.2524  decode.loss_mask: 0.2256  decode.loss_dice: 0.2167  decode.d0.loss_cls: 0.8369  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.2241  decode.d1.loss_cls: 0.2546  decode.d1.loss_mask: 0.2214  decode.d1.loss_dice: 0.2158  decode.d2.loss_cls: 0.2190  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2187  decode.d3.loss_cls: 0.2511  decode.d3.loss_mask: 0.2258  decode.d3.loss_dice: 0.2235  decode.d4.loss_cls: 0.2673  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.2372  decode.d5.loss_cls: 0.2653  decode.d5.loss_mask: 0.2264  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.2652  decode.d6.loss_mask: 0.2258  decode.d6.loss_dice: 0.2198  decode.d7.loss_cls: 0.2305  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.2111  decode.d8.loss_cls: 0.2306  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.2244
09/28 15:49:16 - mmengine - INFO - Iter(train) [ 10150/320000]  base_lr: 9.7141e-05 lr: 9.7141e-06  eta: 1 day, 17:42:17  time: 0.4848  data_time: 0.0104  memory: 5817  grad_norm: 98.9196  loss: 7.5653  decode.loss_cls: 0.0912  decode.loss_mask: 0.2930  decode.loss_dice: 0.2301  decode.d0.loss_cls: 0.9270  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.2443  decode.d1.loss_cls: 0.1900  decode.d1.loss_mask: 0.3017  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.1333  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.2411  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.2955  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.3007  decode.d4.loss_dice: 0.2506  decode.d5.loss_cls: 0.1452  decode.d5.loss_mask: 0.3004  decode.d5.loss_dice: 0.2584  decode.d6.loss_cls: 0.1566  decode.d6.loss_mask: 0.2991  decode.d6.loss_dice: 0.2552  decode.d7.loss_cls: 0.1487  decode.d7.loss_mask: 0.2980  decode.d7.loss_dice: 0.2549  decode.d8.loss_cls: 0.0949  decode.d8.loss_mask: 0.2941  decode.d8.loss_dice: 0.2429
09/28 15:49:40 - mmengine - INFO - Iter(train) [ 10200/320000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 1 day, 17:41:58  time: 0.4973  data_time: 0.0105  memory: 5834  grad_norm: 201.1391  loss: 9.2343  decode.loss_cls: 0.1734  decode.loss_mask: 0.3674  decode.loss_dice: 0.2873  decode.d0.loss_cls: 1.0976  decode.d0.loss_mask: 0.3504  decode.d0.loss_dice: 0.2955  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 0.3451  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.2044  decode.d2.loss_mask: 0.3506  decode.d2.loss_dice: 0.2970  decode.d3.loss_cls: 0.1991  decode.d3.loss_mask: 0.3478  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.2596  decode.d4.loss_mask: 0.3430  decode.d4.loss_dice: 0.2715  decode.d5.loss_cls: 0.2382  decode.d5.loss_mask: 0.3508  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.1653  decode.d6.loss_mask: 0.3504  decode.d6.loss_dice: 0.2696  decode.d7.loss_cls: 0.2068  decode.d7.loss_mask: 0.3484  decode.d7.loss_dice: 0.2735  decode.d8.loss_cls: 0.2042  decode.d8.loss_mask: 0.3553  decode.d8.loss_dice: 0.2670
09/28 15:50:04 - mmengine - INFO - Iter(train) [ 10250/320000]  base_lr: 9.7113e-05 lr: 9.7113e-06  eta: 1 day, 17:41:34  time: 0.4842  data_time: 0.0100  memory: 5799  grad_norm: 55.6609  loss: 6.9328  decode.loss_cls: 0.0475  decode.loss_mask: 0.3212  decode.loss_dice: 0.2342  decode.d0.loss_cls: 0.8989  decode.d0.loss_mask: 0.3363  decode.d0.loss_dice: 0.2209  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.3251  decode.d1.loss_dice: 0.2328  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.3172  decode.d2.loss_dice: 0.2328  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.3240  decode.d3.loss_dice: 0.2282  decode.d4.loss_cls: 0.0498  decode.d4.loss_mask: 0.3216  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.3276  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.3251  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.3204  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.3243  decode.d8.loss_dice: 0.2334
09/28 15:50:29 - mmengine - INFO - Iter(train) [ 10300/320000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 1 day, 17:41:11  time: 0.4859  data_time: 0.0101  memory: 5800  grad_norm: 239.0252  loss: 10.5949  decode.loss_cls: 0.3460  decode.loss_mask: 0.3338  decode.loss_dice: 0.2655  decode.d0.loss_cls: 1.1445  decode.d0.loss_mask: 0.3192  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.4607  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.2675  decode.d2.loss_cls: 0.3371  decode.d2.loss_mask: 0.3846  decode.d2.loss_dice: 0.2977  decode.d3.loss_cls: 0.2616  decode.d3.loss_mask: 0.4259  decode.d3.loss_dice: 0.2931  decode.d4.loss_cls: 0.3084  decode.d4.loss_mask: 0.3728  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.3494  decode.d5.loss_mask: 0.3728  decode.d5.loss_dice: 0.2786  decode.d6.loss_cls: 0.3538  decode.d6.loss_mask: 0.3692  decode.d6.loss_dice: 0.2736  decode.d7.loss_cls: 0.3493  decode.d7.loss_mask: 0.3618  decode.d7.loss_dice: 0.2922  decode.d8.loss_cls: 0.3214  decode.d8.loss_mask: 0.3259  decode.d8.loss_dice: 0.2904
09/28 15:50:53 - mmengine - INFO - Iter(train) [ 10350/320000]  base_lr: 9.7085e-05 lr: 9.7085e-06  eta: 1 day, 17:40:47  time: 0.4839  data_time: 0.0102  memory: 5834  grad_norm: 114.1173  loss: 9.0822  decode.loss_cls: 0.2543  decode.loss_mask: 0.2863  decode.loss_dice: 0.3007  decode.d0.loss_cls: 1.1008  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.2916  decode.d1.loss_cls: 0.3117  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.2718  decode.d2.loss_cls: 0.2677  decode.d2.loss_mask: 0.2663  decode.d2.loss_dice: 0.2482  decode.d3.loss_cls: 0.3151  decode.d3.loss_mask: 0.2770  decode.d3.loss_dice: 0.2558  decode.d4.loss_cls: 0.2721  decode.d4.loss_mask: 0.2783  decode.d4.loss_dice: 0.2588  decode.d5.loss_cls: 0.3101  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.3161  decode.d6.loss_mask: 0.2866  decode.d6.loss_dice: 0.2529  decode.d7.loss_cls: 0.2282  decode.d7.loss_mask: 0.2856  decode.d7.loss_dice: 0.2595  decode.d8.loss_cls: 0.2233  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.2808
09/28 15:51:17 - mmengine - INFO - Iter(train) [ 10400/320000]  base_lr: 9.7070e-05 lr: 9.7070e-06  eta: 1 day, 17:40:22  time: 0.4837  data_time: 0.0097  memory: 5816  grad_norm: 128.8914  loss: 8.0943  decode.loss_cls: 0.1873  decode.loss_mask: 0.3036  decode.loss_dice: 0.2191  decode.d0.loss_cls: 0.9982  decode.d0.loss_mask: 0.2904  decode.d0.loss_dice: 0.2485  decode.d1.loss_cls: 0.1938  decode.d1.loss_mask: 0.2959  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.3029  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.2430  decode.d3.loss_mask: 0.2990  decode.d3.loss_dice: 0.2466  decode.d4.loss_cls: 0.1763  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1586  decode.d5.loss_mask: 0.3026  decode.d5.loss_dice: 0.2365  decode.d6.loss_cls: 0.1576  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.2337  decode.d7.loss_cls: 0.1965  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.2308  decode.d8.loss_cls: 0.2377  decode.d8.loss_mask: 0.2959  decode.d8.loss_dice: 0.2195
09/28 15:51:41 - mmengine - INFO - Iter(train) [ 10450/320000]  base_lr: 9.7056e-05 lr: 9.7056e-06  eta: 1 day, 17:39:57  time: 0.4825  data_time: 0.0101  memory: 5817  grad_norm: 236.4297  loss: 8.6855  decode.loss_cls: 0.2277  decode.loss_mask: 0.3596  decode.loss_dice: 0.2295  decode.d0.loss_cls: 0.9576  decode.d0.loss_mask: 0.3478  decode.d0.loss_dice: 0.2209  decode.d1.loss_cls: 0.2204  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.2213  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 0.3714  decode.d2.loss_dice: 0.2473  decode.d3.loss_cls: 0.1833  decode.d3.loss_mask: 0.3652  decode.d3.loss_dice: 0.2455  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.3461  decode.d4.loss_dice: 0.2352  decode.d5.loss_cls: 0.2318  decode.d5.loss_mask: 0.3525  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.2525  decode.d6.loss_mask: 0.3505  decode.d6.loss_dice: 0.2221  decode.d7.loss_cls: 0.1913  decode.d7.loss_mask: 0.3389  decode.d7.loss_dice: 0.2226  decode.d8.loss_cls: 0.2200  decode.d8.loss_mask: 0.3386  decode.d8.loss_dice: 0.2299
09/28 15:52:06 - mmengine - INFO - Iter(train) [ 10500/320000]  base_lr: 9.7042e-05 lr: 9.7042e-06  eta: 1 day, 17:39:41  time: 0.5026  data_time: 0.0099  memory: 5834  grad_norm: 136.0776  loss: 11.0227  decode.loss_cls: 0.3972  decode.loss_mask: 0.3324  decode.loss_dice: 0.3163  decode.d0.loss_cls: 1.2152  decode.d0.loss_mask: 0.3758  decode.d0.loss_dice: 0.3510  decode.d1.loss_cls: 0.2480  decode.d1.loss_mask: 0.3416  decode.d1.loss_dice: 0.3590  decode.d2.loss_cls: 0.3203  decode.d2.loss_mask: 0.3335  decode.d2.loss_dice: 0.3192  decode.d3.loss_cls: 0.3630  decode.d3.loss_mask: 0.3982  decode.d3.loss_dice: 0.3082  decode.d4.loss_cls: 0.3705  decode.d4.loss_mask: 0.3827  decode.d4.loss_dice: 0.3293  decode.d5.loss_cls: 0.3098  decode.d5.loss_mask: 0.3455  decode.d5.loss_dice: 0.3187  decode.d6.loss_cls: 0.2703  decode.d6.loss_mask: 0.3768  decode.d6.loss_dice: 0.3336  decode.d7.loss_cls: 0.2576  decode.d7.loss_mask: 0.3705  decode.d7.loss_dice: 0.3568  decode.d8.loss_cls: 0.2605  decode.d8.loss_mask: 0.3920  decode.d8.loss_dice: 0.3692
09/28 15:52:30 - mmengine - INFO - Iter(train) [ 10550/320000]  base_lr: 9.7028e-05 lr: 9.7028e-06  eta: 1 day, 17:39:18  time: 0.4839  data_time: 0.0101  memory: 5816  grad_norm: 413.2782  loss: 10.1641  decode.loss_cls: 0.3251  decode.loss_mask: 0.3041  decode.loss_dice: 0.2633  decode.d0.loss_cls: 1.1465  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.2440  decode.d1.loss_cls: 0.5428  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.3830  decode.d2.loss_mask: 0.3579  decode.d2.loss_dice: 0.2748  decode.d3.loss_cls: 0.3039  decode.d3.loss_mask: 0.3594  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.3819  decode.d4.loss_mask: 0.2622  decode.d4.loss_dice: 0.2279  decode.d5.loss_cls: 0.3439  decode.d5.loss_mask: 0.3152  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.3267  decode.d6.loss_mask: 0.3141  decode.d6.loss_dice: 0.2606  decode.d7.loss_cls: 0.3356  decode.d7.loss_mask: 0.3475  decode.d7.loss_dice: 0.2724  decode.d8.loss_cls: 0.2951  decode.d8.loss_mask: 0.3139  decode.d8.loss_dice: 0.2768
09/28 15:52:54 - mmengine - INFO - Iter(train) [ 10600/320000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 1 day, 17:38:55  time: 0.4857  data_time: 0.0104  memory: 5834  grad_norm: 95.1403  loss: 8.3087  decode.loss_cls: 0.2392  decode.loss_mask: 0.2433  decode.loss_dice: 0.2778  decode.d0.loss_cls: 0.8753  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.2669  decode.d1.loss_cls: 0.4112  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.3070  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.2499  decode.d3.loss_cls: 0.2516  decode.d3.loss_mask: 0.2425  decode.d3.loss_dice: 0.2372  decode.d4.loss_cls: 0.2683  decode.d4.loss_mask: 0.2438  decode.d4.loss_dice: 0.2617  decode.d5.loss_cls: 0.2266  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.2471  decode.d6.loss_cls: 0.2611  decode.d6.loss_mask: 0.2451  decode.d6.loss_dice: 0.2595  decode.d7.loss_cls: 0.2376  decode.d7.loss_mask: 0.2470  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.2411  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.2568
09/28 15:53:18 - mmengine - INFO - Iter(train) [ 10650/320000]  base_lr: 9.7000e-05 lr: 9.7000e-06  eta: 1 day, 17:38:30  time: 0.4841  data_time: 0.0100  memory: 5817  grad_norm: 114.6178  loss: 8.3818  decode.loss_cls: 0.1271  decode.loss_mask: 0.2996  decode.loss_dice: 0.2618  decode.d0.loss_cls: 0.9451  decode.d0.loss_mask: 0.2969  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.2289  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.2535  decode.d2.loss_cls: 0.1889  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.2746  decode.d3.loss_cls: 0.2468  decode.d3.loss_mask: 0.2935  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.2336  decode.d4.loss_mask: 0.2989  decode.d4.loss_dice: 0.2547  decode.d5.loss_cls: 0.2175  decode.d5.loss_mask: 0.3002  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.2409  decode.d6.loss_mask: 0.2995  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 0.2953  decode.d7.loss_dice: 0.2570  decode.d8.loss_cls: 0.1284  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.2696
09/28 15:53:43 - mmengine - INFO - Iter(train) [ 10700/320000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 1 day, 17:38:06  time: 0.4838  data_time: 0.0100  memory: 5817  grad_norm: 253.8206  loss: 9.4242  decode.loss_cls: 0.2428  decode.loss_mask: 0.3692  decode.loss_dice: 0.2857  decode.d0.loss_cls: 0.9589  decode.d0.loss_mask: 0.3796  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.2404  decode.d1.loss_mask: 0.3703  decode.d1.loss_dice: 0.2657  decode.d2.loss_cls: 0.2527  decode.d2.loss_mask: 0.3647  decode.d2.loss_dice: 0.3002  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 0.3934  decode.d3.loss_dice: 0.2720  decode.d4.loss_cls: 0.1875  decode.d4.loss_mask: 0.3776  decode.d4.loss_dice: 0.2700  decode.d5.loss_cls: 0.2159  decode.d5.loss_mask: 0.3727  decode.d5.loss_dice: 0.2757  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 0.3811  decode.d6.loss_dice: 0.2798  decode.d7.loss_cls: 0.2110  decode.d7.loss_mask: 0.3644  decode.d7.loss_dice: 0.2909  decode.d8.loss_cls: 0.2239  decode.d8.loss_mask: 0.3713  decode.d8.loss_dice: 0.2684
09/28 15:54:07 - mmengine - INFO - Iter(train) [ 10750/320000]  base_lr: 9.6972e-05 lr: 9.6972e-06  eta: 1 day, 17:37:44  time: 0.4859  data_time: 0.0105  memory: 5834  grad_norm: 343.6443  loss: 10.2090  decode.loss_cls: 0.1621  decode.loss_mask: 0.4860  decode.loss_dice: 0.2908  decode.d0.loss_cls: 0.9988  decode.d0.loss_mask: 0.4824  decode.d0.loss_dice: 0.2816  decode.d1.loss_cls: 0.2233  decode.d1.loss_mask: 0.4804  decode.d1.loss_dice: 0.2719  decode.d2.loss_cls: 0.1643  decode.d2.loss_mask: 0.4913  decode.d2.loss_dice: 0.2702  decode.d3.loss_cls: 0.1810  decode.d3.loss_mask: 0.4855  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.2030  decode.d4.loss_mask: 0.4786  decode.d4.loss_dice: 0.2839  decode.d5.loss_cls: 0.1535  decode.d5.loss_mask: 0.4859  decode.d5.loss_dice: 0.2745  decode.d6.loss_cls: 0.1923  decode.d6.loss_mask: 0.4835  decode.d6.loss_dice: 0.2872  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.4950  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.4988  decode.d8.loss_dice: 0.2781
09/28 15:54:31 - mmengine - INFO - Iter(train) [ 10800/320000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 1 day, 17:37:21  time: 0.4855  data_time: 0.0101  memory: 5834  grad_norm: 258.0518  loss: 8.7461  decode.loss_cls: 0.2792  decode.loss_mask: 0.2886  decode.loss_dice: 0.2902  decode.d0.loss_cls: 1.0230  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.2870  decode.d1.loss_cls: 0.2142  decode.d1.loss_mask: 0.2971  decode.d1.loss_dice: 0.2855  decode.d2.loss_cls: 0.2601  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.2800  decode.d3.loss_cls: 0.2237  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.1955  decode.d4.loss_mask: 0.2735  decode.d4.loss_dice: 0.2734  decode.d5.loss_cls: 0.1653  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.2895  decode.d6.loss_cls: 0.2715  decode.d6.loss_mask: 0.2729  decode.d6.loss_dice: 0.2503  decode.d7.loss_cls: 0.3088  decode.d7.loss_mask: 0.2734  decode.d7.loss_dice: 0.2687  decode.d8.loss_cls: 0.2464  decode.d8.loss_mask: 0.2777  decode.d8.loss_dice: 0.2650
09/28 15:54:55 - mmengine - INFO - Iter(train) [ 10850/320000]  base_lr: 9.6943e-05 lr: 9.6943e-06  eta: 1 day, 17:36:57  time: 0.4847  data_time: 0.0100  memory: 5834  grad_norm: 145.2514  loss: 9.1522  decode.loss_cls: 0.3032  decode.loss_mask: 0.2575  decode.loss_dice: 0.2994  decode.d0.loss_cls: 1.0903  decode.d0.loss_mask: 0.2468  decode.d0.loss_dice: 0.3105  decode.d1.loss_cls: 0.2725  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.3076  decode.d2.loss_cls: 0.2741  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.2488  decode.d3.loss_mask: 0.2656  decode.d3.loss_dice: 0.2998  decode.d4.loss_cls: 0.3156  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.2984  decode.d5.loss_cls: 0.2364  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.3098  decode.d6.loss_cls: 0.2516  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.3045  decode.d7.loss_cls: 0.2564  decode.d7.loss_mask: 0.2530  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.2989
09/28 15:55:20 - mmengine - INFO - Iter(train) [ 10900/320000]  base_lr: 9.6929e-05 lr: 9.6929e-06  eta: 1 day, 17:36:34  time: 0.4855  data_time: 0.0102  memory: 5800  grad_norm: 696.4870  loss: 12.3463  decode.loss_cls: 0.5057  decode.loss_mask: 0.4945  decode.loss_dice: 0.3546  decode.d0.loss_cls: 1.1049  decode.d0.loss_mask: 0.3835  decode.d0.loss_dice: 0.3433  decode.d1.loss_cls: 0.4163  decode.d1.loss_mask: 0.3866  decode.d1.loss_dice: 0.3174  decode.d2.loss_cls: 0.3374  decode.d2.loss_mask: 0.3599  decode.d2.loss_dice: 0.3145  decode.d3.loss_cls: 0.3137  decode.d3.loss_mask: 0.4419  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.3853  decode.d4.loss_mask: 0.3523  decode.d4.loss_dice: 0.3343  decode.d5.loss_cls: 0.3665  decode.d5.loss_mask: 0.4410  decode.d5.loss_dice: 0.3570  decode.d6.loss_cls: 0.4175  decode.d6.loss_mask: 0.4381  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 0.4483  decode.d7.loss_mask: 0.4752  decode.d7.loss_dice: 0.3196  decode.d8.loss_cls: 0.4589  decode.d8.loss_mask: 0.4771  decode.d8.loss_dice: 0.3460
09/28 15:55:44 - mmengine - INFO - Iter(train) [ 10950/320000]  base_lr: 9.6915e-05 lr: 9.6915e-06  eta: 1 day, 17:36:10  time: 0.4856  data_time: 0.0102  memory: 5800  grad_norm: 110.6095  loss: 8.1447  decode.loss_cls: 0.2008  decode.loss_mask: 0.2487  decode.loss_dice: 0.2310  decode.d0.loss_cls: 1.1928  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.2370  decode.d1.loss_cls: 0.2340  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.2644  decode.d2.loss_cls: 0.1595  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.1907  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2302  decode.d4.loss_cls: 0.2415  decode.d4.loss_mask: 0.2487  decode.d4.loss_dice: 0.2507  decode.d5.loss_cls: 0.2363  decode.d5.loss_mask: 0.2474  decode.d5.loss_dice: 0.2791  decode.d6.loss_cls: 0.2491  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.2707  decode.d7.loss_cls: 0.2099  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.2567  decode.d8.loss_cls: 0.2233  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.2423
09/28 15:56:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 15:56:08 - mmengine - INFO - Iter(train) [ 11000/320000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 1 day, 17:35:46  time: 0.4839  data_time: 0.0102  memory: 5833  grad_norm: 198.8159  loss: 8.2751  decode.loss_cls: 0.0660  decode.loss_mask: 0.3603  decode.loss_dice: 0.2688  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 0.3800  decode.d0.loss_dice: 0.2680  decode.d1.loss_cls: 0.2308  decode.d1.loss_mask: 0.3566  decode.d1.loss_dice: 0.2548  decode.d2.loss_cls: 0.1470  decode.d2.loss_mask: 0.3530  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.1211  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.2616  decode.d4.loss_cls: 0.1636  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.1551  decode.d5.loss_mask: 0.3701  decode.d5.loss_dice: 0.2633  decode.d6.loss_cls: 0.1255  decode.d6.loss_mask: 0.3588  decode.d6.loss_dice: 0.2658  decode.d7.loss_cls: 0.1574  decode.d7.loss_mask: 0.3654  decode.d7.loss_dice: 0.2471  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.3565  decode.d8.loss_dice: 0.2564
09/28 15:56:33 - mmengine - INFO - Iter(train) [ 11050/320000]  base_lr: 9.6887e-05 lr: 9.6887e-06  eta: 1 day, 17:35:23  time: 0.4873  data_time: 0.0108  memory: 5817  grad_norm: 92.3279  loss: 10.0922  decode.loss_cls: 0.2389  decode.loss_mask: 0.4078  decode.loss_dice: 0.2711  decode.d0.loss_cls: 1.1732  decode.d0.loss_mask: 0.3908  decode.d0.loss_dice: 0.3081  decode.d1.loss_cls: 0.3610  decode.d1.loss_mask: 0.3627  decode.d1.loss_dice: 0.2821  decode.d2.loss_cls: 0.2937  decode.d2.loss_mask: 0.3871  decode.d2.loss_dice: 0.2844  decode.d3.loss_cls: 0.2662  decode.d3.loss_mask: 0.3935  decode.d3.loss_dice: 0.2665  decode.d4.loss_cls: 0.2290  decode.d4.loss_mask: 0.3730  decode.d4.loss_dice: 0.2776  decode.d5.loss_cls: 0.2208  decode.d5.loss_mask: 0.3798  decode.d5.loss_dice: 0.2755  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.3734  decode.d6.loss_dice: 0.2788  decode.d7.loss_cls: 0.2250  decode.d7.loss_mask: 0.3823  decode.d7.loss_dice: 0.2799  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 0.3688  decode.d8.loss_dice: 0.2685
09/28 15:56:57 - mmengine - INFO - Iter(train) [ 11100/320000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 1 day, 17:35:03  time: 0.4979  data_time: 0.0102  memory: 5834  grad_norm: 104.0887  loss: 8.0303  decode.loss_cls: 0.2298  decode.loss_mask: 0.2662  decode.loss_dice: 0.2510  decode.d0.loss_cls: 1.2300  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.2683  decode.d1.loss_mask: 0.2689  decode.d1.loss_dice: 0.2350  decode.d2.loss_cls: 0.2298  decode.d2.loss_mask: 0.2599  decode.d2.loss_dice: 0.2331  decode.d3.loss_cls: 0.1841  decode.d3.loss_mask: 0.2644  decode.d3.loss_dice: 0.2401  decode.d4.loss_cls: 0.1189  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.2586  decode.d5.loss_dice: 0.2366  decode.d6.loss_cls: 0.1976  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2360  decode.d7.loss_cls: 0.2098  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.1860  decode.d8.loss_mask: 0.2697  decode.d8.loss_dice: 0.2314
09/28 15:57:21 - mmengine - INFO - Iter(train) [ 11150/320000]  base_lr: 9.6859e-05 lr: 9.6859e-06  eta: 1 day, 17:34:41  time: 0.4865  data_time: 0.0106  memory: 5816  grad_norm: 87.5887  loss: 7.0569  decode.loss_cls: 0.1091  decode.loss_mask: 0.2876  decode.loss_dice: 0.2452  decode.d0.loss_cls: 0.8627  decode.d0.loss_mask: 0.2968  decode.d0.loss_dice: 0.2536  decode.d1.loss_cls: 0.1311  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.2520  decode.d2.loss_cls: 0.1939  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.2322  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.2965  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.2384  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.2948  decode.d5.loss_dice: 0.2361  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.2897  decode.d6.loss_dice: 0.2333  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.2915  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.0895  decode.d8.loss_mask: 0.2913  decode.d8.loss_dice: 0.2280
09/28 15:57:46 - mmengine - INFO - Iter(train) [ 11200/320000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 1 day, 17:34:19  time: 0.4859  data_time: 0.0103  memory: 5817  grad_norm: 125.8299  loss: 10.4227  decode.loss_cls: 0.2441  decode.loss_mask: 0.3366  decode.loss_dice: 0.4118  decode.d0.loss_cls: 0.9259  decode.d0.loss_mask: 0.3691  decode.d0.loss_dice: 0.4317  decode.d1.loss_cls: 0.2036  decode.d1.loss_mask: 0.3426  decode.d1.loss_dice: 0.4042  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 0.3500  decode.d2.loss_dice: 0.4059  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 0.3382  decode.d3.loss_dice: 0.3960  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.3367  decode.d4.loss_dice: 0.3963  decode.d5.loss_cls: 0.2329  decode.d5.loss_mask: 0.3417  decode.d5.loss_dice: 0.3825  decode.d6.loss_cls: 0.2395  decode.d6.loss_mask: 0.3338  decode.d6.loss_dice: 0.3844  decode.d7.loss_cls: 0.2520  decode.d7.loss_mask: 0.3382  decode.d7.loss_dice: 0.3915  decode.d8.loss_cls: 0.2583  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.3895
09/28 15:58:10 - mmengine - INFO - Iter(train) [ 11250/320000]  base_lr: 9.6831e-05 lr: 9.6831e-06  eta: 1 day, 17:33:56  time: 0.4859  data_time: 0.0102  memory: 5847  grad_norm: 332.7435  loss: 13.4232  decode.loss_cls: 0.4015  decode.loss_mask: 0.4218  decode.loss_dice: 0.4492  decode.d0.loss_cls: 1.4170  decode.d0.loss_mask: 0.3920  decode.d0.loss_dice: 0.4514  decode.d1.loss_cls: 0.4936  decode.d1.loss_mask: 0.4107  decode.d1.loss_dice: 0.4358  decode.d2.loss_cls: 0.3580  decode.d2.loss_mask: 0.3787  decode.d2.loss_dice: 0.4040  decode.d3.loss_cls: 0.3697  decode.d3.loss_mask: 0.4507  decode.d3.loss_dice: 0.4040  decode.d4.loss_cls: 0.4715  decode.d4.loss_mask: 0.3871  decode.d4.loss_dice: 0.3896  decode.d5.loss_cls: 0.4135  decode.d5.loss_mask: 0.3865  decode.d5.loss_dice: 0.3998  decode.d6.loss_cls: 0.4386  decode.d6.loss_mask: 0.3705  decode.d6.loss_dice: 0.4091  decode.d7.loss_cls: 0.4761  decode.d7.loss_mask: 0.3937  decode.d7.loss_dice: 0.4237  decode.d8.loss_cls: 0.4424  decode.d8.loss_mask: 0.3843  decode.d8.loss_dice: 0.3988
09/28 15:58:34 - mmengine - INFO - Iter(train) [ 11300/320000]  base_lr: 9.6816e-05 lr: 9.6816e-06  eta: 1 day, 17:33:33  time: 0.4858  data_time: 0.0105  memory: 5817  grad_norm: 184.8456  loss: 7.4644  decode.loss_cls: 0.2442  decode.loss_mask: 0.2399  decode.loss_dice: 0.2039  decode.d0.loss_cls: 0.9984  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2417  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.2241  decode.d2.loss_cls: 0.1491  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.2182  decode.d3.loss_cls: 0.1719  decode.d3.loss_mask: 0.2368  decode.d3.loss_dice: 0.2455  decode.d4.loss_cls: 0.1612  decode.d4.loss_mask: 0.2414  decode.d4.loss_dice: 0.2228  decode.d5.loss_cls: 0.2016  decode.d5.loss_mask: 0.2386  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.2243  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 0.2426  decode.d7.loss_dice: 0.2223  decode.d8.loss_cls: 0.2709  decode.d8.loss_mask: 0.2431  decode.d8.loss_dice: 0.2074
09/28 15:58:58 - mmengine - INFO - Iter(train) [ 11350/320000]  base_lr: 9.6802e-05 lr: 9.6802e-06  eta: 1 day, 17:33:11  time: 0.4853  data_time: 0.0103  memory: 5835  grad_norm: 231.1353  loss: 8.8543  decode.loss_cls: 0.3318  decode.loss_mask: 0.2897  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.9410  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.3128  decode.d1.loss_cls: 0.2155  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.2775  decode.d2.loss_cls: 0.2423  decode.d2.loss_mask: 0.2862  decode.d2.loss_dice: 0.2611  decode.d3.loss_cls: 0.2267  decode.d3.loss_mask: 0.2854  decode.d3.loss_dice: 0.2530  decode.d4.loss_cls: 0.2548  decode.d4.loss_mask: 0.2845  decode.d4.loss_dice: 0.2584  decode.d5.loss_cls: 0.2672  decode.d5.loss_mask: 0.2839  decode.d5.loss_dice: 0.2376  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.2824  decode.d7.loss_cls: 0.2934  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.2620  decode.d8.loss_cls: 0.2902  decode.d8.loss_mask: 0.2880  decode.d8.loss_dice: 0.2490
09/28 15:59:23 - mmengine - INFO - Iter(train) [ 11400/320000]  base_lr: 9.6788e-05 lr: 9.6788e-06  eta: 1 day, 17:32:48  time: 0.4852  data_time: 0.0101  memory: 5819  grad_norm: 502.3647  loss: 10.2223  decode.loss_cls: 0.1826  decode.loss_mask: 0.4352  decode.loss_dice: 0.2862  decode.d0.loss_cls: 1.2152  decode.d0.loss_mask: 0.4405  decode.d0.loss_dice: 0.3282  decode.d1.loss_cls: 0.1652  decode.d1.loss_mask: 0.4667  decode.d1.loss_dice: 0.3290  decode.d2.loss_cls: 0.1326  decode.d2.loss_mask: 0.4471  decode.d2.loss_dice: 0.3099  decode.d3.loss_cls: 0.1943  decode.d3.loss_mask: 0.4307  decode.d3.loss_dice: 0.2934  decode.d4.loss_cls: 0.1968  decode.d4.loss_mask: 0.4442  decode.d4.loss_dice: 0.2903  decode.d5.loss_cls: 0.1783  decode.d5.loss_mask: 0.4413  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 0.4515  decode.d6.loss_dice: 0.2957  decode.d7.loss_cls: 0.1698  decode.d7.loss_mask: 0.4522  decode.d7.loss_dice: 0.2985  decode.d8.loss_cls: 0.1374  decode.d8.loss_mask: 0.4409  decode.d8.loss_dice: 0.2922
09/28 15:59:47 - mmengine - INFO - Iter(train) [ 11450/320000]  base_lr: 9.6774e-05 lr: 9.6774e-06  eta: 1 day, 17:32:25  time: 0.4854  data_time: 0.0104  memory: 5816  grad_norm: 105.8877  loss: 7.4232  decode.loss_cls: 0.2151  decode.loss_mask: 0.2807  decode.loss_dice: 0.2124  decode.d0.loss_cls: 0.8273  decode.d0.loss_mask: 0.2995  decode.d0.loss_dice: 0.2298  decode.d1.loss_cls: 0.1971  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.2218  decode.d2.loss_cls: 0.1452  decode.d2.loss_mask: 0.2871  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 0.2800  decode.d3.loss_dice: 0.2243  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.2822  decode.d5.loss_dice: 0.2242  decode.d6.loss_cls: 0.2099  decode.d6.loss_mask: 0.2930  decode.d6.loss_dice: 0.2233  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.2140  decode.d8.loss_cls: 0.1253  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.2170
09/28 16:00:11 - mmengine - INFO - Iter(train) [ 11500/320000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 1 day, 17:32:03  time: 0.4853  data_time: 0.0103  memory: 5834  grad_norm: 405.0195  loss: 14.8710  decode.loss_cls: 0.5166  decode.loss_mask: 0.4608  decode.loss_dice: 0.3474  decode.d0.loss_cls: 1.2284  decode.d0.loss_mask: 0.4553  decode.d0.loss_dice: 0.4121  decode.d1.loss_cls: 0.6415  decode.d1.loss_mask: 0.5690  decode.d1.loss_dice: 0.3965  decode.d2.loss_cls: 0.4866  decode.d2.loss_mask: 0.5037  decode.d2.loss_dice: 0.3877  decode.d3.loss_cls: 0.4354  decode.d3.loss_mask: 0.6370  decode.d3.loss_dice: 0.3802  decode.d4.loss_cls: 0.5314  decode.d4.loss_mask: 0.4348  decode.d4.loss_dice: 0.3623  decode.d5.loss_cls: 0.5531  decode.d5.loss_mask: 0.4949  decode.d5.loss_dice: 0.3795  decode.d6.loss_cls: 0.4346  decode.d6.loss_mask: 0.7332  decode.d6.loss_dice: 0.3957  decode.d7.loss_cls: 0.4737  decode.d7.loss_mask: 0.5224  decode.d7.loss_dice: 0.3957  decode.d8.loss_cls: 0.5063  decode.d8.loss_mask: 0.4349  decode.d8.loss_dice: 0.3603
09/28 16:00:36 - mmengine - INFO - Iter(train) [ 11550/320000]  base_lr: 9.6746e-05 lr: 9.6746e-06  eta: 1 day, 17:31:40  time: 0.4866  data_time: 0.0102  memory: 5819  grad_norm: 108.2276  loss: 7.3064  decode.loss_cls: 0.1493  decode.loss_mask: 0.2560  decode.loss_dice: 0.2343  decode.d0.loss_cls: 0.8751  decode.d0.loss_mask: 0.2755  decode.d0.loss_dice: 0.2317  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 0.2837  decode.d1.loss_dice: 0.2499  decode.d2.loss_cls: 0.2178  decode.d2.loss_mask: 0.2598  decode.d2.loss_dice: 0.2384  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.2613  decode.d3.loss_dice: 0.2363  decode.d4.loss_cls: 0.1919  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.2309  decode.d5.loss_cls: 0.0965  decode.d5.loss_mask: 0.2662  decode.d5.loss_dice: 0.2412  decode.d6.loss_cls: 0.1658  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.2390  decode.d7.loss_cls: 0.1584  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.1356  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2309
09/28 16:01:00 - mmengine - INFO - Iter(train) [ 11600/320000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 1 day, 17:31:18  time: 0.4852  data_time: 0.0104  memory: 5834  grad_norm: 109.7572  loss: 7.4100  decode.loss_cls: 0.2292  decode.loss_mask: 0.2142  decode.loss_dice: 0.2094  decode.d0.loss_cls: 1.0011  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2003  decode.d1.loss_cls: 0.2880  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.2414  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.1959  decode.d3.loss_cls: 0.2371  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.2023  decode.d4.loss_cls: 0.2364  decode.d4.loss_mask: 0.2124  decode.d4.loss_dice: 0.2024  decode.d5.loss_cls: 0.2547  decode.d5.loss_mask: 0.2107  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.2677  decode.d6.loss_mask: 0.2109  decode.d6.loss_dice: 0.2120  decode.d7.loss_cls: 0.2554  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.1951  decode.d8.loss_cls: 0.2369  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.2021
09/28 16:01:24 - mmengine - INFO - Iter(train) [ 11650/320000]  base_lr: 9.6718e-05 lr: 9.6718e-06  eta: 1 day, 17:30:58  time: 0.4854  data_time: 0.0102  memory: 5834  grad_norm: 145.4942  loss: 8.2921  decode.loss_cls: 0.2830  decode.loss_mask: 0.2375  decode.loss_dice: 0.2456  decode.d0.loss_cls: 1.0196  decode.d0.loss_mask: 0.2381  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.2254  decode.d1.loss_dice: 0.2673  decode.d2.loss_cls: 0.2055  decode.d2.loss_mask: 0.2361  decode.d2.loss_dice: 0.2229  decode.d3.loss_cls: 0.2406  decode.d3.loss_mask: 0.2335  decode.d3.loss_dice: 0.2280  decode.d4.loss_cls: 0.2668  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2902  decode.d5.loss_cls: 0.3285  decode.d5.loss_mask: 0.2338  decode.d5.loss_dice: 0.2760  decode.d6.loss_cls: 0.2700  decode.d6.loss_mask: 0.2429  decode.d6.loss_dice: 0.2519  decode.d7.loss_cls: 0.2909  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.2883  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.2345
09/28 16:01:49 - mmengine - INFO - Iter(train) [ 11700/320000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 1 day, 17:30:35  time: 0.4853  data_time: 0.0102  memory: 5817  grad_norm: 400.8662  loss: 9.1885  decode.loss_cls: 0.2439  decode.loss_mask: 0.2307  decode.loss_dice: 0.2681  decode.d0.loss_cls: 1.4503  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.2670  decode.d1.loss_cls: 0.3622  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.3144  decode.d2.loss_mask: 0.2478  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.3038  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.2583  decode.d4.loss_cls: 0.3291  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.2979  decode.d5.loss_cls: 0.2681  decode.d5.loss_mask: 0.2610  decode.d5.loss_dice: 0.3032  decode.d6.loss_cls: 0.2351  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.2940  decode.d7.loss_mask: 0.2196  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.2837  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.2801
09/28 16:02:13 - mmengine - INFO - Iter(train) [ 11750/320000]  base_lr: 9.6689e-05 lr: 9.6689e-06  eta: 1 day, 17:30:12  time: 0.4854  data_time: 0.0105  memory: 5834  grad_norm: 122.5425  loss: 8.3513  decode.loss_cls: 0.1905  decode.loss_mask: 0.3011  decode.loss_dice: 0.2563  decode.d0.loss_cls: 0.8033  decode.d0.loss_mask: 0.3534  decode.d0.loss_dice: 0.2586  decode.d1.loss_cls: 0.2183  decode.d1.loss_mask: 0.3084  decode.d1.loss_dice: 0.2701  decode.d2.loss_cls: 0.1539  decode.d2.loss_mask: 0.3430  decode.d2.loss_dice: 0.2511  decode.d3.loss_cls: 0.1177  decode.d3.loss_mask: 0.3467  decode.d3.loss_dice: 0.2528  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 0.3067  decode.d4.loss_dice: 0.2651  decode.d5.loss_cls: 0.2209  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.1988  decode.d6.loss_mask: 0.3137  decode.d6.loss_dice: 0.2697  decode.d7.loss_cls: 0.1875  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.2100  decode.d8.loss_mask: 0.3039  decode.d8.loss_dice: 0.2803
09/28 16:02:37 - mmengine - INFO - Iter(train) [ 11800/320000]  base_lr: 9.6675e-05 lr: 9.6675e-06  eta: 1 day, 17:29:49  time: 0.4853  data_time: 0.0102  memory: 5816  grad_norm: 462.1147  loss: 10.6426  decode.loss_cls: 0.3258  decode.loss_mask: 0.3707  decode.loss_dice: 0.3150  decode.d0.loss_cls: 1.0462  decode.d0.loss_mask: 0.3220  decode.d0.loss_dice: 0.2791  decode.d1.loss_cls: 0.3770  decode.d1.loss_mask: 0.2916  decode.d1.loss_dice: 0.2653  decode.d2.loss_cls: 0.2956  decode.d2.loss_mask: 0.3115  decode.d2.loss_dice: 0.2879  decode.d3.loss_cls: 0.3639  decode.d3.loss_mask: 0.4637  decode.d3.loss_dice: 0.3185  decode.d4.loss_cls: 0.4184  decode.d4.loss_mask: 0.4384  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.3401  decode.d5.loss_mask: 0.3626  decode.d5.loss_dice: 0.2852  decode.d6.loss_cls: 0.2840  decode.d6.loss_mask: 0.4231  decode.d6.loss_dice: 0.3059  decode.d7.loss_cls: 0.3577  decode.d7.loss_mask: 0.3143  decode.d7.loss_dice: 0.2826  decode.d8.loss_cls: 0.3219  decode.d8.loss_mask: 0.3099  decode.d8.loss_dice: 0.2763
09/28 16:03:01 - mmengine - INFO - Iter(train) [ 11850/320000]  base_lr: 9.6661e-05 lr: 9.6661e-06  eta: 1 day, 17:29:26  time: 0.4853  data_time: 0.0102  memory: 5798  grad_norm: 122.5909  loss: 8.5704  decode.loss_cls: 0.2370  decode.loss_mask: 0.2782  decode.loss_dice: 0.2958  decode.d0.loss_cls: 0.9432  decode.d0.loss_mask: 0.2759  decode.d0.loss_dice: 0.2944  decode.d1.loss_cls: 0.2420  decode.d1.loss_mask: 0.2811  decode.d1.loss_dice: 0.2817  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 0.2725  decode.d2.loss_dice: 0.3022  decode.d3.loss_cls: 0.2206  decode.d3.loss_mask: 0.2724  decode.d3.loss_dice: 0.2900  decode.d4.loss_cls: 0.2465  decode.d4.loss_mask: 0.2733  decode.d4.loss_dice: 0.2817  decode.d5.loss_cls: 0.2278  decode.d5.loss_mask: 0.2723  decode.d5.loss_dice: 0.2856  decode.d6.loss_cls: 0.1829  decode.d6.loss_mask: 0.2731  decode.d6.loss_dice: 0.2892  decode.d7.loss_cls: 0.2131  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2930  decode.d8.loss_cls: 0.2035  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.3016
09/28 16:03:26 - mmengine - INFO - Iter(train) [ 11900/320000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 1 day, 17:29:03  time: 0.4871  data_time: 0.0107  memory: 5835  grad_norm: 221.1932  loss: 9.3955  decode.loss_cls: 0.2693  decode.loss_mask: 0.3028  decode.loss_dice: 0.2974  decode.d0.loss_cls: 0.9866  decode.d0.loss_mask: 0.2990  decode.d0.loss_dice: 0.2667  decode.d1.loss_cls: 0.2873  decode.d1.loss_mask: 0.2967  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.3614  decode.d2.loss_mask: 0.2933  decode.d2.loss_dice: 0.2460  decode.d3.loss_cls: 0.2884  decode.d3.loss_mask: 0.3026  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.2662  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.2932  decode.d5.loss_cls: 0.3313  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.2808  decode.d6.loss_cls: 0.3343  decode.d6.loss_mask: 0.3085  decode.d6.loss_dice: 0.2497  decode.d7.loss_cls: 0.2799  decode.d7.loss_mask: 0.3106  decode.d7.loss_dice: 0.2761  decode.d8.loss_cls: 0.3262  decode.d8.loss_mask: 0.2977  decode.d8.loss_dice: 0.2368
09/28 16:03:50 - mmengine - INFO - Iter(train) [ 11950/320000]  base_lr: 9.6633e-05 lr: 9.6633e-06  eta: 1 day, 17:28:44  time: 0.4845  data_time: 0.0102  memory: 5816  grad_norm: 164.6862  loss: 7.3980  decode.loss_cls: 0.1985  decode.loss_mask: 0.2559  decode.loss_dice: 0.1983  decode.d0.loss_cls: 1.0627  decode.d0.loss_mask: 0.2620  decode.d0.loss_dice: 0.2053  decode.d1.loss_cls: 0.1460  decode.d1.loss_mask: 0.2573  decode.d1.loss_dice: 0.1969  decode.d2.loss_cls: 0.2217  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.1904  decode.d3.loss_cls: 0.1720  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.2008  decode.d4.loss_cls: 0.1888  decode.d4.loss_mask: 0.2560  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.2123  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.1959  decode.d6.loss_cls: 0.2215  decode.d6.loss_mask: 0.2563  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.2029  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.2008  decode.d8.loss_cls: 0.2187  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.1945
09/28 16:04:14 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 16:04:14 - mmengine - INFO - Iter(train) [ 12000/320000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 1 day, 17:28:20  time: 0.4851  data_time: 0.0104  memory: 5817  grad_norm: 154.9900  loss: 8.1343  decode.loss_cls: 0.1615  decode.loss_mask: 0.3459  decode.loss_dice: 0.2542  decode.d0.loss_cls: 0.8399  decode.d0.loss_mask: 0.3369  decode.d0.loss_dice: 0.2488  decode.d1.loss_cls: 0.1597  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.2499  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.3446  decode.d2.loss_dice: 0.2461  decode.d3.loss_cls: 0.1323  decode.d3.loss_mask: 0.3441  decode.d3.loss_dice: 0.2442  decode.d4.loss_cls: 0.1611  decode.d4.loss_mask: 0.3392  decode.d4.loss_dice: 0.2431  decode.d5.loss_cls: 0.1479  decode.d5.loss_mask: 0.3367  decode.d5.loss_dice: 0.2452  decode.d6.loss_cls: 0.2460  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.2301  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 0.3449  decode.d7.loss_dice: 0.2463  decode.d8.loss_cls: 0.1460  decode.d8.loss_mask: 0.3515  decode.d8.loss_dice: 0.2472
09/28 16:04:39 - mmengine - INFO - Iter(train) [ 12050/320000]  base_lr: 9.6605e-05 lr: 9.6605e-06  eta: 1 day, 17:27:57  time: 0.4852  data_time: 0.0101  memory: 5800  grad_norm: 122.9116  loss: 9.8336  decode.loss_cls: 0.2775  decode.loss_mask: 0.2655  decode.loss_dice: 0.3556  decode.d0.loss_cls: 1.3022  decode.d0.loss_mask: 0.2340  decode.d0.loss_dice: 0.3148  decode.d1.loss_cls: 0.3117  decode.d1.loss_mask: 0.2314  decode.d1.loss_dice: 0.3277  decode.d2.loss_cls: 0.2784  decode.d2.loss_mask: 0.2381  decode.d2.loss_dice: 0.3311  decode.d3.loss_cls: 0.3418  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.2972  decode.d4.loss_cls: 0.3950  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.3285  decode.d5.loss_cls: 0.3862  decode.d5.loss_mask: 0.2534  decode.d5.loss_dice: 0.3234  decode.d6.loss_cls: 0.3122  decode.d6.loss_mask: 0.2208  decode.d6.loss_dice: 0.3087  decode.d7.loss_cls: 0.3222  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.3220  decode.d8.loss_cls: 0.3042  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.3467
09/28 16:05:03 - mmengine - INFO - Iter(train) [ 12100/320000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 1 day, 17:27:33  time: 0.4848  data_time: 0.0102  memory: 5834  grad_norm: 196.8185  loss: 8.9212  decode.loss_cls: 0.2627  decode.loss_mask: 0.2895  decode.loss_dice: 0.2765  decode.d0.loss_cls: 1.0482  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.2845  decode.d1.loss_cls: 0.2688  decode.d1.loss_mask: 0.2831  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.3055  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.2687  decode.d3.loss_cls: 0.2237  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.2668  decode.d4.loss_cls: 0.2409  decode.d4.loss_mask: 0.2856  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.2795  decode.d5.loss_mask: 0.2842  decode.d5.loss_dice: 0.2681  decode.d6.loss_cls: 0.2440  decode.d6.loss_mask: 0.2909  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.2241  decode.d7.loss_mask: 0.2827  decode.d7.loss_dice: 0.2703  decode.d8.loss_cls: 0.2268  decode.d8.loss_mask: 0.3045  decode.d8.loss_dice: 0.2788
09/28 16:05:27 - mmengine - INFO - Iter(train) [ 12150/320000]  base_lr: 9.6577e-05 lr: 9.6577e-06  eta: 1 day, 17:27:10  time: 0.4861  data_time: 0.0104  memory: 5819  grad_norm: 55.0229  loss: 5.6978  decode.loss_cls: 0.0395  decode.loss_mask: 0.2619  decode.loss_dice: 0.1759  decode.d0.loss_cls: 0.8330  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.1865  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.2543  decode.d1.loss_dice: 0.1795  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.2599  decode.d2.loss_dice: 0.1823  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.2560  decode.d4.loss_dice: 0.1812  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.2558  decode.d5.loss_dice: 0.1795  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0305  decode.d7.loss_mask: 0.2530  decode.d7.loss_dice: 0.1812  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.1762
09/28 16:05:51 - mmengine - INFO - Iter(train) [ 12200/320000]  base_lr: 9.6562e-05 lr: 9.6562e-06  eta: 1 day, 17:26:46  time: 0.4847  data_time: 0.0100  memory: 5816  grad_norm: 247.6088  loss: 11.2560  decode.loss_cls: 0.3215  decode.loss_mask: 0.3733  decode.loss_dice: 0.3386  decode.d0.loss_cls: 1.2525  decode.d0.loss_mask: 0.3806  decode.d0.loss_dice: 0.3214  decode.d1.loss_cls: 0.4597  decode.d1.loss_mask: 0.3640  decode.d1.loss_dice: 0.3072  decode.d2.loss_cls: 0.3745  decode.d2.loss_mask: 0.3671  decode.d2.loss_dice: 0.3118  decode.d3.loss_cls: 0.2774  decode.d3.loss_mask: 0.3732  decode.d3.loss_dice: 0.3269  decode.d4.loss_cls: 0.2503  decode.d4.loss_mask: 0.3909  decode.d4.loss_dice: 0.3407  decode.d5.loss_cls: 0.2743  decode.d5.loss_mask: 0.3923  decode.d5.loss_dice: 0.3419  decode.d6.loss_cls: 0.3014  decode.d6.loss_mask: 0.3906  decode.d6.loss_dice: 0.3306  decode.d7.loss_cls: 0.2864  decode.d7.loss_mask: 0.4023  decode.d7.loss_dice: 0.3422  decode.d8.loss_cls: 0.3274  decode.d8.loss_mask: 0.3859  decode.d8.loss_dice: 0.3489
09/28 16:06:16 - mmengine - INFO - Iter(train) [ 12250/320000]  base_lr: 9.6548e-05 lr: 9.6548e-06  eta: 1 day, 17:26:23  time: 0.4849  data_time: 0.0103  memory: 5798  grad_norm: 75.2895  loss: 8.8803  decode.loss_cls: 0.1924  decode.loss_mask: 0.3130  decode.loss_dice: 0.2522  decode.d0.loss_cls: 0.9985  decode.d0.loss_mask: 0.3206  decode.d0.loss_dice: 0.2898  decode.d1.loss_cls: 0.2514  decode.d1.loss_mask: 0.3115  decode.d1.loss_dice: 0.2832  decode.d2.loss_cls: 0.2086  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.2823  decode.d3.loss_cls: 0.2184  decode.d3.loss_mask: 0.3379  decode.d3.loss_dice: 0.2882  decode.d4.loss_cls: 0.2034  decode.d4.loss_mask: 0.3149  decode.d4.loss_dice: 0.2747  decode.d5.loss_cls: 0.2349  decode.d5.loss_mask: 0.3104  decode.d5.loss_dice: 0.2604  decode.d6.loss_cls: 0.2469  decode.d6.loss_mask: 0.3155  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.2225  decode.d7.loss_mask: 0.3275  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.2025  decode.d8.loss_mask: 0.3282  decode.d8.loss_dice: 0.2498
09/28 16:06:40 - mmengine - INFO - Iter(train) [ 12300/320000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 1 day, 17:25:58  time: 0.4850  data_time: 0.0102  memory: 5834  grad_norm: 378.0787  loss: 9.0763  decode.loss_cls: 0.1110  decode.loss_mask: 0.3709  decode.loss_dice: 0.2493  decode.d0.loss_cls: 1.0666  decode.d0.loss_mask: 0.3248  decode.d0.loss_dice: 0.2528  decode.d1.loss_cls: 0.2948  decode.d1.loss_mask: 0.3242  decode.d1.loss_dice: 0.2444  decode.d2.loss_cls: 0.1835  decode.d2.loss_mask: 0.3785  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.2252  decode.d3.loss_mask: 0.3644  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.1906  decode.d4.loss_mask: 0.3644  decode.d4.loss_dice: 0.2582  decode.d5.loss_cls: 0.2250  decode.d5.loss_mask: 0.3801  decode.d5.loss_dice: 0.2591  decode.d6.loss_cls: 0.2473  decode.d6.loss_mask: 0.3735  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.2858  decode.d7.loss_mask: 0.3257  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.1269  decode.d8.loss_mask: 0.3744  decode.d8.loss_dice: 0.2585
09/28 16:07:04 - mmengine - INFO - Iter(train) [ 12350/320000]  base_lr: 9.6520e-05 lr: 9.6520e-06  eta: 1 day, 17:25:34  time: 0.4830  data_time: 0.0100  memory: 5834  grad_norm: 185.8918  loss: 8.6788  decode.loss_cls: 0.2222  decode.loss_mask: 0.3056  decode.loss_dice: 0.2647  decode.d0.loss_cls: 0.9120  decode.d0.loss_mask: 0.2937  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.2283  decode.d1.loss_mask: 0.3285  decode.d1.loss_dice: 0.2781  decode.d2.loss_cls: 0.2210  decode.d2.loss_mask: 0.3086  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.1875  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.2645  decode.d4.loss_cls: 0.1946  decode.d4.loss_mask: 0.3139  decode.d4.loss_dice: 0.2675  decode.d5.loss_cls: 0.1871  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.2470  decode.d6.loss_mask: 0.3144  decode.d6.loss_dice: 0.2786  decode.d7.loss_cls: 0.2234  decode.d7.loss_mask: 0.3047  decode.d7.loss_dice: 0.2754  decode.d8.loss_cls: 0.2103  decode.d8.loss_mask: 0.3255  decode.d8.loss_dice: 0.2981
09/28 16:07:28 - mmengine - INFO - Iter(train) [ 12400/320000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 1 day, 17:25:09  time: 0.4856  data_time: 0.0104  memory: 5817  grad_norm: 264.3864  loss: 11.4302  decode.loss_cls: 0.4075  decode.loss_mask: 0.3537  decode.loss_dice: 0.3602  decode.d0.loss_cls: 1.1703  decode.d0.loss_mask: 0.3516  decode.d0.loss_dice: 0.3722  decode.d1.loss_cls: 0.3459  decode.d1.loss_mask: 0.3521  decode.d1.loss_dice: 0.3548  decode.d2.loss_cls: 0.2939  decode.d2.loss_mask: 0.3473  decode.d2.loss_dice: 0.3397  decode.d3.loss_cls: 0.3569  decode.d3.loss_mask: 0.3524  decode.d3.loss_dice: 0.3455  decode.d4.loss_cls: 0.3158  decode.d4.loss_mask: 0.3541  decode.d4.loss_dice: 0.3509  decode.d5.loss_cls: 0.3689  decode.d5.loss_mask: 0.3585  decode.d5.loss_dice: 0.3421  decode.d6.loss_cls: 0.3344  decode.d6.loss_mask: 0.3573  decode.d6.loss_dice: 0.3476  decode.d7.loss_cls: 0.4246  decode.d7.loss_mask: 0.3584  decode.d7.loss_dice: 0.3648  decode.d8.loss_cls: 0.3412  decode.d8.loss_mask: 0.3555  decode.d8.loss_dice: 0.3521
09/28 16:07:53 - mmengine - INFO - Iter(train) [ 12450/320000]  base_lr: 9.6492e-05 lr: 9.6492e-06  eta: 1 day, 17:24:44  time: 0.4846  data_time: 0.0100  memory: 5817  grad_norm: 120.5866  loss: 7.4149  decode.loss_cls: 0.1887  decode.loss_mask: 0.2664  decode.loss_dice: 0.2598  decode.d0.loss_cls: 0.9970  decode.d0.loss_mask: 0.2690  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.2497  decode.d2.loss_cls: 0.1824  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.2460  decode.d3.loss_cls: 0.0946  decode.d3.loss_mask: 0.2614  decode.d3.loss_dice: 0.2594  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.2585  decode.d5.loss_cls: 0.1811  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.2499  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 0.2598  decode.d6.loss_dice: 0.2532  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.1035  decode.d8.loss_mask: 0.2612  decode.d8.loss_dice: 0.2575
09/28 16:08:17 - mmengine - INFO - Iter(train) [ 12500/320000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 1 day, 17:24:20  time: 0.4833  data_time: 0.0103  memory: 5816  grad_norm: 225.2451  loss: 7.5078  decode.loss_cls: 0.2069  decode.loss_mask: 0.2145  decode.loss_dice: 0.2419  decode.d0.loss_cls: 1.1702  decode.d0.loss_mask: 0.2168  decode.d0.loss_dice: 0.2552  decode.d1.loss_cls: 0.1304  decode.d1.loss_mask: 0.2173  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.2182  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.1300  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.2626  decode.d4.loss_cls: 0.1940  decode.d4.loss_mask: 0.2208  decode.d4.loss_dice: 0.2375  decode.d5.loss_cls: 0.2357  decode.d5.loss_mask: 0.2205  decode.d5.loss_dice: 0.2374  decode.d6.loss_cls: 0.2610  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.2364  decode.d7.loss_cls: 0.2095  decode.d7.loss_mask: 0.2145  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.2038  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.2201
09/28 16:08:41 - mmengine - INFO - Iter(train) [ 12550/320000]  base_lr: 9.6464e-05 lr: 9.6464e-06  eta: 1 day, 17:23:59  time: 0.4844  data_time: 0.0102  memory: 5800  grad_norm: 323.0272  loss: 7.0954  decode.loss_cls: 0.1025  decode.loss_mask: 0.2923  decode.loss_dice: 0.2431  decode.d0.loss_cls: 0.8589  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.2503  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.2505  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.2900  decode.d2.loss_dice: 0.2475  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.2528  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.2471  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 0.2924  decode.d5.loss_dice: 0.2505  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 0.2903  decode.d6.loss_dice: 0.2495  decode.d7.loss_cls: 0.1159  decode.d7.loss_mask: 0.2912  decode.d7.loss_dice: 0.2434  decode.d8.loss_cls: 0.1209  decode.d8.loss_mask: 0.2939  decode.d8.loss_dice: 0.2555
09/28 16:09:06 - mmengine - INFO - Iter(train) [ 12600/320000]  base_lr: 9.6449e-05 lr: 9.6449e-06  eta: 1 day, 17:23:35  time: 0.4856  data_time: 0.0102  memory: 5834  grad_norm: 182.6524  loss: 7.7073  decode.loss_cls: 0.1452  decode.loss_mask: 0.2635  decode.loss_dice: 0.2825  decode.d0.loss_cls: 0.9144  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.2820  decode.d1.loss_cls: 0.1822  decode.d1.loss_mask: 0.2738  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.1077  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.2902  decode.d3.loss_cls: 0.1207  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.1120  decode.d4.loss_mask: 0.2636  decode.d4.loss_dice: 0.2874  decode.d5.loss_cls: 0.1093  decode.d5.loss_mask: 0.2809  decode.d5.loss_dice: 0.3063  decode.d6.loss_cls: 0.1401  decode.d6.loss_mask: 0.2621  decode.d6.loss_dice: 0.2900  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 0.2739  decode.d7.loss_dice: 0.2851  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 0.2703  decode.d8.loss_dice: 0.2878
09/28 16:09:30 - mmengine - INFO - Iter(train) [ 12650/320000]  base_lr: 9.6435e-05 lr: 9.6435e-06  eta: 1 day, 17:23:12  time: 0.4852  data_time: 0.0105  memory: 5834  grad_norm: 578.1430  loss: 11.0275  decode.loss_cls: 0.2554  decode.loss_mask: 0.3718  decode.loss_dice: 0.3429  decode.d0.loss_cls: 1.0813  decode.d0.loss_mask: 0.4017  decode.d0.loss_dice: 0.3931  decode.d1.loss_cls: 0.4407  decode.d1.loss_mask: 0.3808  decode.d1.loss_dice: 0.3590  decode.d2.loss_cls: 0.3375  decode.d2.loss_mask: 0.3854  decode.d2.loss_dice: 0.3249  decode.d3.loss_cls: 0.2065  decode.d3.loss_mask: 0.3696  decode.d3.loss_dice: 0.3314  decode.d4.loss_cls: 0.3345  decode.d4.loss_mask: 0.3716  decode.d4.loss_dice: 0.3287  decode.d5.loss_cls: 0.1985  decode.d5.loss_mask: 0.3734  decode.d5.loss_dice: 0.3754  decode.d6.loss_cls: 0.2897  decode.d6.loss_mask: 0.3770  decode.d6.loss_dice: 0.3407  decode.d7.loss_cls: 0.2558  decode.d7.loss_mask: 0.3704  decode.d7.loss_dice: 0.3721  decode.d8.loss_cls: 0.3325  decode.d8.loss_mask: 0.3719  decode.d8.loss_dice: 0.3530
09/28 16:09:54 - mmengine - INFO - Iter(train) [ 12700/320000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 1 day, 17:22:48  time: 0.4844  data_time: 0.0102  memory: 5799  grad_norm: 298.6055  loss: 10.4305  decode.loss_cls: 0.3162  decode.loss_mask: 0.3277  decode.loss_dice: 0.3008  decode.d0.loss_cls: 1.1746  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.2887  decode.d1.loss_cls: 0.4741  decode.d1.loss_mask: 0.3125  decode.d1.loss_dice: 0.2768  decode.d2.loss_cls: 0.3923  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.2760  decode.d3.loss_cls: 0.4011  decode.d3.loss_mask: 0.3178  decode.d3.loss_dice: 0.2852  decode.d4.loss_cls: 0.3390  decode.d4.loss_mask: 0.3272  decode.d4.loss_dice: 0.2994  decode.d5.loss_cls: 0.3184  decode.d5.loss_mask: 0.3220  decode.d5.loss_dice: 0.3321  decode.d6.loss_cls: 0.2950  decode.d6.loss_mask: 0.3106  decode.d6.loss_dice: 0.3130  decode.d7.loss_cls: 0.3274  decode.d7.loss_mask: 0.3101  decode.d7.loss_dice: 0.2781  decode.d8.loss_cls: 0.2924  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.2888
09/28 16:10:18 - mmengine - INFO - Iter(train) [ 12750/320000]  base_lr: 9.6407e-05 lr: 9.6407e-06  eta: 1 day, 17:22:25  time: 0.4864  data_time: 0.0104  memory: 5834  grad_norm: 118.5008  loss: 8.1009  decode.loss_cls: 0.2586  decode.loss_mask: 0.2975  decode.loss_dice: 0.2427  decode.d0.loss_cls: 0.8463  decode.d0.loss_mask: 0.3261  decode.d0.loss_dice: 0.2635  decode.d1.loss_cls: 0.1850  decode.d1.loss_mask: 0.2808  decode.d1.loss_dice: 0.2243  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.2442  decode.d3.loss_cls: 0.1326  decode.d3.loss_mask: 0.3315  decode.d3.loss_dice: 0.2445  decode.d4.loss_cls: 0.1797  decode.d4.loss_mask: 0.2753  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.2294  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.2256  decode.d6.loss_cls: 0.2611  decode.d6.loss_mask: 0.3033  decode.d6.loss_dice: 0.2481  decode.d7.loss_cls: 0.2225  decode.d7.loss_mask: 0.2995  decode.d7.loss_dice: 0.2429  decode.d8.loss_cls: 0.1883  decode.d8.loss_mask: 0.3199  decode.d8.loss_dice: 0.2796
09/28 16:10:43 - mmengine - INFO - Iter(train) [ 12800/320000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 1 day, 17:22:01  time: 0.4853  data_time: 0.0103  memory: 5799  grad_norm: 61.3885  loss: 5.3354  decode.loss_cls: 0.0630  decode.loss_mask: 0.2268  decode.loss_dice: 0.1735  decode.d0.loss_cls: 0.8538  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.1795  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.1746  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 0.2218  decode.d2.loss_dice: 0.1733  decode.d3.loss_cls: 0.0282  decode.d3.loss_mask: 0.2229  decode.d3.loss_dice: 0.1733  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.2242  decode.d5.loss_dice: 0.1738  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.2237  decode.d6.loss_dice: 0.1786  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.2262  decode.d7.loss_dice: 0.1743  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.1793
09/28 16:11:07 - mmengine - INFO - Iter(train) [ 12850/320000]  base_lr: 9.6379e-05 lr: 9.6379e-06  eta: 1 day, 17:21:37  time: 0.4845  data_time: 0.0103  memory: 5816  grad_norm: 50.2406  loss: 6.3153  decode.loss_cls: 0.0660  decode.loss_mask: 0.2751  decode.loss_dice: 0.2176  decode.d0.loss_cls: 0.8263  decode.d0.loss_mask: 0.2650  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.2118  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.2154  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.2697  decode.d3.loss_dice: 0.2140  decode.d4.loss_cls: 0.0911  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.2133  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.2166  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.2682  decode.d6.loss_dice: 0.1911  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.2715  decode.d7.loss_dice: 0.2119  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.2160
09/28 16:11:31 - mmengine - INFO - Iter(train) [ 12900/320000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 1 day, 17:21:13  time: 0.4852  data_time: 0.0102  memory: 5816  grad_norm: 425.9260  loss: 8.5024  decode.loss_cls: 0.1825  decode.loss_mask: 0.3015  decode.loss_dice: 0.2952  decode.d0.loss_cls: 1.0145  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.2939  decode.d1.loss_cls: 0.2483  decode.d1.loss_mask: 0.3106  decode.d1.loss_dice: 0.2927  decode.d2.loss_cls: 0.1772  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.2865  decode.d3.loss_cls: 0.2213  decode.d3.loss_mask: 0.2961  decode.d3.loss_dice: 0.2849  decode.d4.loss_cls: 0.2160  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.2763  decode.d5.loss_cls: 0.1173  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.2825  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.2919  decode.d6.loss_dice: 0.2896  decode.d7.loss_cls: 0.1758  decode.d7.loss_mask: 0.2962  decode.d7.loss_dice: 0.2865  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.2872
09/28 16:11:55 - mmengine - INFO - Iter(train) [ 12950/320000]  base_lr: 9.6351e-05 lr: 9.6351e-06  eta: 1 day, 17:20:49  time: 0.4868  data_time: 0.0105  memory: 5834  grad_norm: 105.3913  loss: 9.5571  decode.loss_cls: 0.2222  decode.loss_mask: 0.3141  decode.loss_dice: 0.3684  decode.d0.loss_cls: 1.0615  decode.d0.loss_mask: 0.2836  decode.d0.loss_dice: 0.3686  decode.d1.loss_cls: 0.2358  decode.d1.loss_mask: 0.2876  decode.d1.loss_dice: 0.3373  decode.d2.loss_cls: 0.2425  decode.d2.loss_mask: 0.2972  decode.d2.loss_dice: 0.3469  decode.d3.loss_cls: 0.2147  decode.d3.loss_mask: 0.2934  decode.d3.loss_dice: 0.3476  decode.d4.loss_cls: 0.2070  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.3565  decode.d5.loss_cls: 0.2422  decode.d5.loss_mask: 0.3030  decode.d5.loss_dice: 0.3493  decode.d6.loss_cls: 0.2159  decode.d6.loss_mask: 0.2934  decode.d6.loss_dice: 0.3427  decode.d7.loss_cls: 0.1992  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.3586  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 0.3045  decode.d8.loss_dice: 0.3567
09/28 16:12:20 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 16:12:20 - mmengine - INFO - Iter(train) [ 13000/320000]  base_lr: 9.6336e-05 lr: 9.6336e-06  eta: 1 day, 17:20:26  time: 0.4848  data_time: 0.0103  memory: 5835  grad_norm: 107.2815  loss: 6.6786  decode.loss_cls: 0.0833  decode.loss_mask: 0.2678  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.8096  decode.d0.loss_mask: 0.2751  decode.d0.loss_dice: 0.2350  decode.d1.loss_cls: 0.1560  decode.d1.loss_mask: 0.2695  decode.d1.loss_dice: 0.2128  decode.d2.loss_cls: 0.0921  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.2270  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.2647  decode.d3.loss_dice: 0.2076  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 0.2673  decode.d4.loss_dice: 0.2271  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.2141  decode.d6.loss_cls: 0.1394  decode.d6.loss_mask: 0.2708  decode.d6.loss_dice: 0.2207  decode.d7.loss_cls: 0.0838  decode.d7.loss_mask: 0.2689  decode.d7.loss_dice: 0.2386  decode.d8.loss_cls: 0.1222  decode.d8.loss_mask: 0.2692  decode.d8.loss_dice: 0.2319
09/28 16:12:44 - mmengine - INFO - Iter(train) [ 13050/320000]  base_lr: 9.6322e-05 lr: 9.6322e-06  eta: 1 day, 17:20:03  time: 0.4855  data_time: 0.0104  memory: 5834  grad_norm: 567.7324  loss: 14.7452  decode.loss_cls: 0.5641  decode.loss_mask: 0.4143  decode.loss_dice: 0.3939  decode.d0.loss_cls: 1.2538  decode.d0.loss_mask: 0.4394  decode.d0.loss_dice: 0.4058  decode.d1.loss_cls: 0.6454  decode.d1.loss_mask: 0.4322  decode.d1.loss_dice: 0.3315  decode.d2.loss_cls: 0.5799  decode.d2.loss_mask: 0.3940  decode.d2.loss_dice: 0.3468  decode.d3.loss_cls: 0.5197  decode.d3.loss_mask: 0.4433  decode.d3.loss_dice: 0.3549  decode.d4.loss_cls: 0.6038  decode.d4.loss_mask: 0.4371  decode.d4.loss_dice: 0.3865  decode.d5.loss_cls: 0.6619  decode.d5.loss_mask: 0.4490  decode.d5.loss_dice: 0.3965  decode.d6.loss_cls: 0.5577  decode.d6.loss_mask: 0.4209  decode.d6.loss_dice: 0.4007  decode.d7.loss_cls: 0.6471  decode.d7.loss_mask: 0.4977  decode.d7.loss_dice: 0.3939  decode.d8.loss_cls: 0.5939  decode.d8.loss_mask: 0.4047  decode.d8.loss_dice: 0.3749
09/28 16:13:08 - mmengine - INFO - Iter(train) [ 13100/320000]  base_lr: 9.6308e-05 lr: 9.6308e-06  eta: 1 day, 17:19:43  time: 0.4858  data_time: 0.0104  memory: 5799  grad_norm: 132.0733  loss: 6.9281  decode.loss_cls: 0.0941  decode.loss_mask: 0.2374  decode.loss_dice: 0.2631  decode.d0.loss_cls: 1.0123  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.2462  decode.d1.loss_cls: 0.1309  decode.d1.loss_mask: 0.2552  decode.d1.loss_dice: 0.2773  decode.d2.loss_cls: 0.1563  decode.d2.loss_mask: 0.2533  decode.d2.loss_dice: 0.2827  decode.d3.loss_cls: 0.0328  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.2702  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.2418  decode.d5.loss_dice: 0.2725  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.2299  decode.d6.loss_dice: 0.2568  decode.d7.loss_cls: 0.0815  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.2617  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.2523
09/28 16:13:33 - mmengine - INFO - Iter(train) [ 13150/320000]  base_lr: 9.6294e-05 lr: 9.6294e-06  eta: 1 day, 17:19:19  time: 0.4847  data_time: 0.0104  memory: 5817  grad_norm: 288.4939  loss: 8.4791  decode.loss_cls: 0.1597  decode.loss_mask: 0.3036  decode.loss_dice: 0.3234  decode.d0.loss_cls: 0.8545  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.1512  decode.d1.loss_mask: 0.2941  decode.d1.loss_dice: 0.3011  decode.d2.loss_cls: 0.1945  decode.d2.loss_mask: 0.2973  decode.d2.loss_dice: 0.3039  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 0.2950  decode.d3.loss_dice: 0.3048  decode.d4.loss_cls: 0.2005  decode.d4.loss_mask: 0.2954  decode.d4.loss_dice: 0.3008  decode.d5.loss_cls: 0.1890  decode.d5.loss_mask: 0.2923  decode.d5.loss_dice: 0.3035  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.3091  decode.d7.loss_cls: 0.1667  decode.d7.loss_mask: 0.2918  decode.d7.loss_dice: 0.3070  decode.d8.loss_cls: 0.1651  decode.d8.loss_mask: 0.2914  decode.d8.loss_dice: 0.2981
09/28 16:13:57 - mmengine - INFO - Iter(train) [ 13200/320000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 1 day, 17:18:56  time: 0.4853  data_time: 0.0104  memory: 5800  grad_norm: 310.8396  loss: 7.3231  decode.loss_cls: 0.1229  decode.loss_mask: 0.2902  decode.loss_dice: 0.2269  decode.d0.loss_cls: 0.9455  decode.d0.loss_mask: 0.3058  decode.d0.loss_dice: 0.2490  decode.d1.loss_cls: 0.1511  decode.d1.loss_mask: 0.2948  decode.d1.loss_dice: 0.2137  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.2965  decode.d2.loss_dice: 0.2223  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.2978  decode.d3.loss_dice: 0.2110  decode.d4.loss_cls: 0.1291  decode.d4.loss_mask: 0.2936  decode.d4.loss_dice: 0.2156  decode.d5.loss_cls: 0.1165  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.1071  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.3012  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1351  decode.d8.loss_mask: 0.2879  decode.d8.loss_dice: 0.2231
09/28 16:14:21 - mmengine - INFO - Iter(train) [ 13250/320000]  base_lr: 9.6266e-05 lr: 9.6266e-06  eta: 1 day, 17:18:33  time: 0.4855  data_time: 0.0101  memory: 5817  grad_norm: 117.7879  loss: 6.7317  decode.loss_cls: 0.1364  decode.loss_mask: 0.2914  decode.loss_dice: 0.1923  decode.d0.loss_cls: 0.8814  decode.d0.loss_mask: 0.2832  decode.d0.loss_dice: 0.1947  decode.d1.loss_cls: 0.1098  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.2018  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.2751  decode.d2.loss_dice: 0.2001  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.2817  decode.d3.loss_dice: 0.2006  decode.d4.loss_cls: 0.1596  decode.d4.loss_mask: 0.2804  decode.d4.loss_dice: 0.1994  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.2826  decode.d5.loss_dice: 0.1947  decode.d6.loss_cls: 0.0972  decode.d6.loss_mask: 0.2843  decode.d6.loss_dice: 0.1916  decode.d7.loss_cls: 0.1109  decode.d7.loss_mask: 0.2844  decode.d7.loss_dice: 0.1933  decode.d8.loss_cls: 0.1055  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.1922
09/28 16:14:45 - mmengine - INFO - Iter(train) [ 13300/320000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 1 day, 17:18:09  time: 0.4865  data_time: 0.0106  memory: 5817  grad_norm: 160.0335  loss: 8.5630  decode.loss_cls: 0.1484  decode.loss_mask: 0.3007  decode.loss_dice: 0.2934  decode.d0.loss_cls: 1.0461  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.2565  decode.d1.loss_cls: 0.2042  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.2926  decode.d2.loss_cls: 0.1634  decode.d2.loss_mask: 0.2879  decode.d2.loss_dice: 0.2696  decode.d3.loss_cls: 0.1701  decode.d3.loss_mask: 0.2871  decode.d3.loss_dice: 0.2847  decode.d4.loss_cls: 0.2699  decode.d4.loss_mask: 0.2888  decode.d4.loss_dice: 0.2951  decode.d5.loss_cls: 0.3076  decode.d5.loss_mask: 0.2825  decode.d5.loss_dice: 0.2768  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 0.2818  decode.d6.loss_dice: 0.3026  decode.d7.loss_cls: 0.2282  decode.d7.loss_mask: 0.2796  decode.d7.loss_dice: 0.2736  decode.d8.loss_cls: 0.1939  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.2681
09/28 16:15:10 - mmengine - INFO - Iter(train) [ 13350/320000]  base_lr: 9.6238e-05 lr: 9.6238e-06  eta: 1 day, 17:17:46  time: 0.4850  data_time: 0.0104  memory: 5799  grad_norm: 111.1361  loss: 10.4787  decode.loss_cls: 0.1611  decode.loss_mask: 0.4766  decode.loss_dice: 0.2929  decode.d0.loss_cls: 1.0289  decode.d0.loss_mask: 0.3705  decode.d0.loss_dice: 0.2968  decode.d1.loss_cls: 0.2629  decode.d1.loss_mask: 0.4094  decode.d1.loss_dice: 0.3009  decode.d2.loss_cls: 0.1846  decode.d2.loss_mask: 0.5412  decode.d2.loss_dice: 0.2999  decode.d3.loss_cls: 0.2395  decode.d3.loss_mask: 0.4668  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.2698  decode.d4.loss_mask: 0.4343  decode.d4.loss_dice: 0.2952  decode.d5.loss_cls: 0.2571  decode.d5.loss_mask: 0.4049  decode.d5.loss_dice: 0.3028  decode.d6.loss_cls: 0.2003  decode.d6.loss_mask: 0.4884  decode.d6.loss_dice: 0.3131  decode.d7.loss_cls: 0.2297  decode.d7.loss_mask: 0.3694  decode.d7.loss_dice: 0.2970  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.5360  decode.d8.loss_dice: 0.3248
09/28 16:15:34 - mmengine - INFO - Iter(train) [ 13400/320000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 1 day, 17:17:26  time: 0.4851  data_time: 0.0099  memory: 5834  grad_norm: 513.7852  loss: 10.3801  decode.loss_cls: 0.2083  decode.loss_mask: 0.3249  decode.loss_dice: 0.3675  decode.d0.loss_cls: 1.3963  decode.d0.loss_mask: 0.3089  decode.d0.loss_dice: 0.3671  decode.d1.loss_cls: 0.3507  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.3388  decode.d2.loss_cls: 0.2629  decode.d2.loss_mask: 0.3282  decode.d2.loss_dice: 0.3474  decode.d3.loss_cls: 0.2681  decode.d3.loss_mask: 0.3147  decode.d3.loss_dice: 0.3298  decode.d4.loss_cls: 0.2190  decode.d4.loss_mask: 0.2955  decode.d4.loss_dice: 0.3347  decode.d5.loss_cls: 0.2267  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.3690  decode.d6.loss_cls: 0.2268  decode.d6.loss_mask: 0.3238  decode.d6.loss_dice: 0.3858  decode.d7.loss_cls: 0.2476  decode.d7.loss_mask: 0.2958  decode.d7.loss_dice: 0.3784  decode.d8.loss_cls: 0.2956  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.3713
09/28 16:15:58 - mmengine - INFO - Iter(train) [ 13450/320000]  base_lr: 9.6209e-05 lr: 9.6209e-06  eta: 1 day, 17:17:02  time: 0.4846  data_time: 0.0100  memory: 5817  grad_norm: 136.4261  loss: 7.8376  decode.loss_cls: 0.1866  decode.loss_mask: 0.2641  decode.loss_dice: 0.2502  decode.d0.loss_cls: 0.9578  decode.d0.loss_mask: 0.2661  decode.d0.loss_dice: 0.2620  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 0.2695  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.2464  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.2790  decode.d3.loss_cls: 0.2369  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.2227  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 0.2761  decode.d4.loss_dice: 0.2797  decode.d5.loss_cls: 0.1410  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.2591  decode.d6.loss_cls: 0.1715  decode.d6.loss_mask: 0.2630  decode.d6.loss_dice: 0.2551  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.2732  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.1610  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.2290
09/28 16:16:23 - mmengine - INFO - Iter(train) [ 13500/320000]  base_lr: 9.6195e-05 lr: 9.6195e-06  eta: 1 day, 17:16:38  time: 0.4848  data_time: 0.0099  memory: 5835  grad_norm: 98.3162  loss: 8.3892  decode.loss_cls: 0.1974  decode.loss_mask: 0.2898  decode.loss_dice: 0.2712  decode.d0.loss_cls: 1.0282  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.2423  decode.d1.loss_mask: 0.3034  decode.d1.loss_dice: 0.2541  decode.d2.loss_cls: 0.2061  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.2675  decode.d3.loss_cls: 0.1949  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.2138  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.2008  decode.d5.loss_mask: 0.2978  decode.d5.loss_dice: 0.2729  decode.d6.loss_cls: 0.1877  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.2707  decode.d7.loss_cls: 0.1616  decode.d7.loss_mask: 0.3024  decode.d7.loss_dice: 0.2548  decode.d8.loss_cls: 0.1863  decode.d8.loss_mask: 0.2952  decode.d8.loss_dice: 0.2563
09/28 16:16:47 - mmengine - INFO - Iter(train) [ 13550/320000]  base_lr: 9.6181e-05 lr: 9.6181e-06  eta: 1 day, 17:16:13  time: 0.4834  data_time: 0.0100  memory: 5817  grad_norm: 57.7478  loss: 5.8858  decode.loss_cls: 0.0356  decode.loss_mask: 0.2587  decode.loss_dice: 0.1707  decode.d0.loss_cls: 1.0402  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.1743  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.2678  decode.d1.loss_dice: 0.1776  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 0.2661  decode.d2.loss_dice: 0.1818  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.2608  decode.d3.loss_dice: 0.1767  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.2594  decode.d4.loss_dice: 0.1702  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.2588  decode.d6.loss_dice: 0.1749  decode.d7.loss_cls: 0.0389  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.1767  decode.d8.loss_cls: 0.0357  decode.d8.loss_mask: 0.2608  decode.d8.loss_dice: 0.1714
09/28 16:17:11 - mmengine - INFO - Iter(train) [ 13600/320000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 1 day, 17:15:49  time: 0.4853  data_time: 0.0103  memory: 5816  grad_norm: 130.7647  loss: 7.7917  decode.loss_cls: 0.1155  decode.loss_mask: 0.2901  decode.loss_dice: 0.2441  decode.d0.loss_cls: 0.9329  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.2610  decode.d1.loss_cls: 0.2346  decode.d1.loss_mask: 0.2959  decode.d1.loss_dice: 0.2457  decode.d2.loss_cls: 0.1961  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.2386  decode.d3.loss_cls: 0.1735  decode.d3.loss_mask: 0.2912  decode.d3.loss_dice: 0.2444  decode.d4.loss_cls: 0.1704  decode.d4.loss_mask: 0.2911  decode.d4.loss_dice: 0.2609  decode.d5.loss_cls: 0.1846  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.1387  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.2465  decode.d7.loss_cls: 0.1347  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.2512  decode.d8.loss_cls: 0.1149  decode.d8.loss_mask: 0.2897  decode.d8.loss_dice: 0.2434
09/28 16:17:35 - mmengine - INFO - Iter(train) [ 13650/320000]  base_lr: 9.6153e-05 lr: 9.6153e-06  eta: 1 day, 17:15:25  time: 0.4835  data_time: 0.0098  memory: 5817  grad_norm: 254.6271  loss: 7.1931  decode.loss_cls: 0.0866  decode.loss_mask: 0.3111  decode.loss_dice: 0.2286  decode.d0.loss_cls: 0.9905  decode.d0.loss_mask: 0.3141  decode.d0.loss_dice: 0.2176  decode.d1.loss_cls: 0.1306  decode.d1.loss_mask: 0.3082  decode.d1.loss_dice: 0.2210  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.3068  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.0828  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.2551  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.3062  decode.d4.loss_dice: 0.2234  decode.d5.loss_cls: 0.1030  decode.d5.loss_mask: 0.3036  decode.d5.loss_dice: 0.2235  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.2990  decode.d6.loss_dice: 0.2203  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.3015  decode.d7.loss_dice: 0.2170  decode.d8.loss_cls: 0.0958  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.2120
09/28 16:18:00 - mmengine - INFO - Iter(train) [ 13700/320000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 1 day, 17:15:02  time: 0.4847  data_time: 0.0102  memory: 5800  grad_norm: 111.3201  loss: 6.9866  decode.loss_cls: 0.1121  decode.loss_mask: 0.2451  decode.loss_dice: 0.2260  decode.d0.loss_cls: 0.8487  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2337  decode.d1.loss_cls: 0.1672  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2307  decode.d2.loss_cls: 0.1880  decode.d2.loss_mask: 0.2458  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 0.2448  decode.d3.loss_dice: 0.2380  decode.d4.loss_cls: 0.1520  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.2313  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2220  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.2264  decode.d7.loss_cls: 0.1420  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.1429  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2286
09/28 16:18:24 - mmengine - INFO - Iter(train) [ 13750/320000]  base_lr: 9.6125e-05 lr: 9.6125e-06  eta: 1 day, 17:14:38  time: 0.4867  data_time: 0.0104  memory: 5847  grad_norm: 82.2846  loss: 7.1464  decode.loss_cls: 0.1209  decode.loss_mask: 0.3121  decode.loss_dice: 0.2287  decode.d0.loss_cls: 0.9816  decode.d0.loss_mask: 0.3157  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.1297  decode.d1.loss_mask: 0.3134  decode.d1.loss_dice: 0.2297  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.2211  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.3065  decode.d3.loss_dice: 0.2148  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.3008  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 0.2991  decode.d6.loss_dice: 0.2141  decode.d7.loss_cls: 0.1409  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.2168  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.3047  decode.d8.loss_dice: 0.2125
09/28 16:18:48 - mmengine - INFO - Iter(train) [ 13800/320000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 1 day, 17:14:14  time: 0.4833  data_time: 0.0100  memory: 5817  grad_norm: 64.6497  loss: 5.9701  decode.loss_cls: 0.0466  decode.loss_mask: 0.2324  decode.loss_dice: 0.2034  decode.d0.loss_cls: 1.0977  decode.d0.loss_mask: 0.2438  decode.d0.loss_dice: 0.2384  decode.d1.loss_cls: 0.0958  decode.d1.loss_mask: 0.2333  decode.d1.loss_dice: 0.2034  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.2345  decode.d2.loss_dice: 0.2037  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.2351  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.1974  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.2295  decode.d5.loss_dice: 0.1990  decode.d6.loss_cls: 0.0421  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.2060  decode.d7.loss_cls: 0.0586  decode.d7.loss_mask: 0.2347  decode.d7.loss_dice: 0.2005  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.1977
09/28 16:19:12 - mmengine - INFO - Iter(train) [ 13850/320000]  base_lr: 9.6096e-05 lr: 9.6096e-06  eta: 1 day, 17:13:51  time: 0.4864  data_time: 0.0106  memory: 5816  grad_norm: 349.2163  loss: 8.5435  decode.loss_cls: 0.2192  decode.loss_mask: 0.3235  decode.loss_dice: 0.2585  decode.d0.loss_cls: 1.0665  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.2720  decode.d1.loss_cls: 0.2716  decode.d1.loss_mask: 0.3002  decode.d1.loss_dice: 0.2683  decode.d2.loss_cls: 0.1796  decode.d2.loss_mask: 0.2966  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.1764  decode.d3.loss_mask: 0.3033  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.2467  decode.d4.loss_mask: 0.3140  decode.d4.loss_dice: 0.2707  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.2895  decode.d5.loss_dice: 0.2528  decode.d6.loss_cls: 0.2018  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.2463  decode.d7.loss_cls: 0.2142  decode.d7.loss_mask: 0.2986  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.1854  decode.d8.loss_mask: 0.2888  decode.d8.loss_dice: 0.2522
09/28 16:19:37 - mmengine - INFO - Iter(train) [ 13900/320000]  base_lr: 9.6082e-05 lr: 9.6082e-06  eta: 1 day, 17:13:27  time: 0.4855  data_time: 0.0100  memory: 5800  grad_norm: 121.0320  loss: 10.0554  decode.loss_cls: 0.3852  decode.loss_mask: 0.3405  decode.loss_dice: 0.2723  decode.d0.loss_cls: 1.0607  decode.d0.loss_mask: 0.3305  decode.d0.loss_dice: 0.2861  decode.d1.loss_cls: 0.2772  decode.d1.loss_mask: 0.2981  decode.d1.loss_dice: 0.2531  decode.d2.loss_cls: 0.2949  decode.d2.loss_mask: 0.2958  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.2999  decode.d3.loss_mask: 0.3119  decode.d3.loss_dice: 0.2768  decode.d4.loss_cls: 0.3445  decode.d4.loss_mask: 0.3179  decode.d4.loss_dice: 0.3076  decode.d5.loss_cls: 0.2914  decode.d5.loss_mask: 0.3137  decode.d5.loss_dice: 0.3040  decode.d6.loss_cls: 0.3622  decode.d6.loss_mask: 0.3163  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.2845  decode.d7.loss_mask: 0.4271  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.2969  decode.d8.loss_mask: 0.4193  decode.d8.loss_dice: 0.2917
09/28 16:20:01 - mmengine - INFO - Iter(train) [ 13950/320000]  base_lr: 9.6068e-05 lr: 9.6068e-06  eta: 1 day, 17:13:02  time: 0.4833  data_time: 0.0099  memory: 5816  grad_norm: 91.3334  loss: 6.9349  decode.loss_cls: 0.1591  decode.loss_mask: 0.2515  decode.loss_dice: 0.2201  decode.d0.loss_cls: 0.9947  decode.d0.loss_mask: 0.2808  decode.d0.loss_dice: 0.2419  decode.d1.loss_cls: 0.2156  decode.d1.loss_mask: 0.2814  decode.d1.loss_dice: 0.2265  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.2648  decode.d3.loss_dice: 0.2344  decode.d4.loss_cls: 0.1030  decode.d4.loss_mask: 0.2534  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.2392  decode.d6.loss_cls: 0.0896  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.2766  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.0940  decode.d8.loss_mask: 0.2738  decode.d8.loss_dice: 0.2328
09/28 16:20:25 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 16:20:25 - mmengine - INFO - Iter(train) [ 14000/320000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 1 day, 17:12:41  time: 0.4873  data_time: 0.0103  memory: 5817  grad_norm: 100.6502  loss: 10.8428  decode.loss_cls: 0.4093  decode.loss_mask: 0.3644  decode.loss_dice: 0.3026  decode.d0.loss_cls: 1.0290  decode.d0.loss_mask: 0.3766  decode.d0.loss_dice: 0.3510  decode.d1.loss_cls: 0.3053  decode.d1.loss_mask: 0.3728  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.2915  decode.d2.loss_mask: 0.3777  decode.d2.loss_dice: 0.3131  decode.d3.loss_cls: 0.2028  decode.d3.loss_mask: 0.3868  decode.d3.loss_dice: 0.3218  decode.d4.loss_cls: 0.2655  decode.d4.loss_mask: 0.3926  decode.d4.loss_dice: 0.3352  decode.d5.loss_cls: 0.2721  decode.d5.loss_mask: 0.4041  decode.d5.loss_dice: 0.3330  decode.d6.loss_cls: 0.3793  decode.d6.loss_mask: 0.3701  decode.d6.loss_dice: 0.2941  decode.d7.loss_cls: 0.3730  decode.d7.loss_mask: 0.3763  decode.d7.loss_dice: 0.2978  decode.d8.loss_cls: 0.3732  decode.d8.loss_mask: 0.3673  decode.d8.loss_dice: 0.3045
09/28 16:20:50 - mmengine - INFO - Iter(train) [ 14050/320000]  base_lr: 9.6040e-05 lr: 9.6040e-06  eta: 1 day, 17:12:17  time: 0.4844  data_time: 0.0101  memory: 5834  grad_norm: 173.5132  loss: 6.1714  decode.loss_cls: 0.0487  decode.loss_mask: 0.2969  decode.loss_dice: 0.1882  decode.d0.loss_cls: 0.8821  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.1971  decode.d1.loss_cls: 0.0538  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.2060  decode.d2.loss_cls: 0.0388  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.1913  decode.d3.loss_cls: 0.0414  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.2911  decode.d4.loss_dice: 0.1918  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.2969  decode.d5.loss_dice: 0.1911  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.1899  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.1881
09/28 16:21:14 - mmengine - INFO - Iter(train) [ 14100/320000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 1 day, 17:11:54  time: 0.4864  data_time: 0.0105  memory: 5834  grad_norm: 44.9198  loss: 7.8454  decode.loss_cls: 0.2927  decode.loss_mask: 0.2390  decode.loss_dice: 0.2320  decode.d0.loss_cls: 0.8954  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.2578  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.2251  decode.d2.loss_mask: 0.2357  decode.d2.loss_dice: 0.2014  decode.d3.loss_cls: 0.2176  decode.d3.loss_mask: 0.2376  decode.d3.loss_dice: 0.2000  decode.d4.loss_cls: 0.2829  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2023  decode.d5.loss_cls: 0.3134  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.3201  decode.d6.loss_mask: 0.2338  decode.d6.loss_dice: 0.1952  decode.d7.loss_cls: 0.3421  decode.d7.loss_mask: 0.2340  decode.d7.loss_dice: 0.2137  decode.d8.loss_cls: 0.2290  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.2153
09/28 16:21:38 - mmengine - INFO - Iter(train) [ 14150/320000]  base_lr: 9.6012e-05 lr: 9.6012e-06  eta: 1 day, 17:11:30  time: 0.4844  data_time: 0.0101  memory: 5817  grad_norm: 119.8984  loss: 7.5583  decode.loss_cls: 0.1157  decode.loss_mask: 0.3258  decode.loss_dice: 0.2548  decode.d0.loss_cls: 0.7777  decode.d0.loss_mask: 0.3252  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 0.3265  decode.d1.loss_dice: 0.2412  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.3276  decode.d2.loss_dice: 0.2512  decode.d3.loss_cls: 0.1064  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.2369  decode.d4.loss_cls: 0.1369  decode.d4.loss_mask: 0.3213  decode.d4.loss_dice: 0.2480  decode.d5.loss_cls: 0.1148  decode.d5.loss_mask: 0.3236  decode.d5.loss_dice: 0.2468  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.2327  decode.d7.loss_cls: 0.1405  decode.d7.loss_mask: 0.3179  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.1066  decode.d8.loss_mask: 0.3232  decode.d8.loss_dice: 0.2497
09/28 16:22:02 - mmengine - INFO - Iter(train) [ 14200/320000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 1 day, 17:11:06  time: 0.4842  data_time: 0.0100  memory: 5799  grad_norm: 91.2587  loss: 7.2296  decode.loss_cls: 0.2092  decode.loss_mask: 0.1966  decode.loss_dice: 0.2507  decode.d0.loss_cls: 1.0297  decode.d0.loss_mask: 0.1955  decode.d0.loss_dice: 0.2543  decode.d1.loss_cls: 0.2288  decode.d1.loss_mask: 0.1975  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.2092  decode.d2.loss_mask: 0.1949  decode.d2.loss_dice: 0.2377  decode.d3.loss_cls: 0.2039  decode.d3.loss_mask: 0.1944  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.1847  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.1740  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.1576  decode.d6.loss_mask: 0.1957  decode.d6.loss_dice: 0.2379  decode.d7.loss_cls: 0.1949  decode.d7.loss_mask: 0.1962  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.1858  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.2579
09/28 16:22:27 - mmengine - INFO - Iter(train) [ 14250/320000]  base_lr: 9.5983e-05 lr: 9.5983e-06  eta: 1 day, 17:10:42  time: 0.4851  data_time: 0.0104  memory: 5800  grad_norm: 64.2522  loss: 8.3553  decode.loss_cls: 0.3282  decode.loss_mask: 0.2500  decode.loss_dice: 0.1900  decode.d0.loss_cls: 1.0795  decode.d0.loss_mask: 0.2471  decode.d0.loss_dice: 0.1930  decode.d1.loss_cls: 0.3020  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.2097  decode.d2.loss_cls: 0.3230  decode.d2.loss_mask: 0.2457  decode.d2.loss_dice: 0.1993  decode.d3.loss_cls: 0.3275  decode.d3.loss_mask: 0.2516  decode.d3.loss_dice: 0.1950  decode.d4.loss_cls: 0.3332  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.2076  decode.d5.loss_cls: 0.3283  decode.d5.loss_mask: 0.2453  decode.d5.loss_dice: 0.1942  decode.d6.loss_cls: 0.3094  decode.d6.loss_mask: 0.2457  decode.d6.loss_dice: 0.1930  decode.d7.loss_cls: 0.2567  decode.d7.loss_mask: 0.2498  decode.d7.loss_dice: 0.2327  decode.d8.loss_cls: 0.2686  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.1991
09/28 16:22:51 - mmengine - INFO - Iter(train) [ 14300/320000]  base_lr: 9.5969e-05 lr: 9.5969e-06  eta: 1 day, 17:10:19  time: 0.4857  data_time: 0.0107  memory: 5819  grad_norm: 138.7709  loss: 7.2836  decode.loss_cls: 0.1901  decode.loss_mask: 0.2632  decode.loss_dice: 0.2196  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 0.2716  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.1728  decode.d2.loss_mask: 0.2593  decode.d2.loss_dice: 0.2154  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 0.2628  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.1366  decode.d4.loss_mask: 0.2638  decode.d4.loss_dice: 0.2204  decode.d5.loss_cls: 0.1482  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.2311  decode.d6.loss_cls: 0.1674  decode.d6.loss_mask: 0.2664  decode.d6.loss_dice: 0.2258  decode.d7.loss_cls: 0.1647  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.2321  decode.d8.loss_cls: 0.1416  decode.d8.loss_mask: 0.2754  decode.d8.loss_dice: 0.2317
09/28 16:23:15 - mmengine - INFO - Iter(train) [ 14350/320000]  base_lr: 9.5955e-05 lr: 9.5955e-06  eta: 1 day, 17:09:55  time: 0.4850  data_time: 0.0104  memory: 5817  grad_norm: 67.1411  loss: 5.1533  decode.loss_cls: 0.0818  decode.loss_mask: 0.2253  decode.loss_dice: 0.1564  decode.d0.loss_cls: 0.7615  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.1499  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 0.2195  decode.d1.loss_dice: 0.1512  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.2263  decode.d2.loss_dice: 0.1581  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.1548  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.1517  decode.d5.loss_cls: 0.0573  decode.d5.loss_mask: 0.2257  decode.d5.loss_dice: 0.1533  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.1488  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.1491  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.1528
09/28 16:23:40 - mmengine - INFO - Iter(train) [ 14400/320000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 1 day, 17:09:33  time: 0.4880  data_time: 0.0103  memory: 5816  grad_norm: 207.4464  loss: 9.1008  decode.loss_cls: 0.2356  decode.loss_mask: 0.3373  decode.loss_dice: 0.2893  decode.d0.loss_cls: 1.0691  decode.d0.loss_mask: 0.3546  decode.d0.loss_dice: 0.2846  decode.d1.loss_cls: 0.2133  decode.d1.loss_mask: 0.3299  decode.d1.loss_dice: 0.2932  decode.d2.loss_cls: 0.1293  decode.d2.loss_mask: 0.3305  decode.d2.loss_dice: 0.2838  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 0.3852  decode.d3.loss_dice: 0.3096  decode.d4.loss_cls: 0.1462  decode.d4.loss_mask: 0.3573  decode.d4.loss_dice: 0.2829  decode.d5.loss_cls: 0.2215  decode.d5.loss_mask: 0.3440  decode.d5.loss_dice: 0.2646  decode.d6.loss_cls: 0.2172  decode.d6.loss_mask: 0.3344  decode.d6.loss_dice: 0.2786  decode.d7.loss_cls: 0.2543  decode.d7.loss_mask: 0.3387  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.2062  decode.d8.loss_mask: 0.3391  decode.d8.loss_dice: 0.2726
09/28 16:24:04 - mmengine - INFO - Iter(train) [ 14450/320000]  base_lr: 9.5927e-05 lr: 9.5927e-06  eta: 1 day, 17:09:11  time: 0.4858  data_time: 0.0102  memory: 5799  grad_norm: 112.2575  loss: 7.1729  decode.loss_cls: 0.1482  decode.loss_mask: 0.2184  decode.loss_dice: 0.2480  decode.d0.loss_cls: 1.0112  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.2237  decode.d1.loss_cls: 0.1975  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.2198  decode.d2.loss_cls: 0.2264  decode.d2.loss_mask: 0.2192  decode.d2.loss_dice: 0.2288  decode.d3.loss_cls: 0.1244  decode.d3.loss_mask: 0.2191  decode.d3.loss_dice: 0.2382  decode.d4.loss_cls: 0.2341  decode.d4.loss_mask: 0.2168  decode.d4.loss_dice: 0.2316  decode.d5.loss_cls: 0.2185  decode.d5.loss_mask: 0.2136  decode.d5.loss_dice: 0.2103  decode.d6.loss_cls: 0.2259  decode.d6.loss_mask: 0.2141  decode.d6.loss_dice: 0.2335  decode.d7.loss_cls: 0.1394  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2250  decode.d8.loss_cls: 0.1642  decode.d8.loss_mask: 0.2172  decode.d8.loss_dice: 0.2463
09/28 16:24:28 - mmengine - INFO - Iter(train) [ 14500/320000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 1 day, 17:08:48  time: 0.4875  data_time: 0.0102  memory: 5800  grad_norm: 104.5504  loss: 5.9080  decode.loss_cls: 0.0747  decode.loss_mask: 0.2602  decode.loss_dice: 0.1916  decode.d0.loss_cls: 0.7954  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.2023  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.2609  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.1988  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.2564  decode.d3.loss_dice: 0.1974  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.2539  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.2553  decode.d6.loss_dice: 0.1960  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.2564  decode.d7.loss_dice: 0.1910  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.2054
09/28 16:24:53 - mmengine - INFO - Iter(train) [ 14550/320000]  base_lr: 9.5899e-05 lr: 9.5899e-06  eta: 1 day, 17:08:28  time: 0.4861  data_time: 0.0104  memory: 5799  grad_norm: 74.2513  loss: 6.0654  decode.loss_cls: 0.0689  decode.loss_mask: 0.2369  decode.loss_dice: 0.2035  decode.d0.loss_cls: 0.9602  decode.d0.loss_mask: 0.2374  decode.d0.loss_dice: 0.2141  decode.d1.loss_cls: 0.1501  decode.d1.loss_mask: 0.2332  decode.d1.loss_dice: 0.2066  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.2367  decode.d2.loss_dice: 0.2076  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.2359  decode.d3.loss_dice: 0.2165  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.2085  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.2335  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.2307  decode.d6.loss_dice: 0.2166  decode.d7.loss_cls: 0.0710  decode.d7.loss_mask: 0.2309  decode.d7.loss_dice: 0.2032  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.2315  decode.d8.loss_dice: 0.2114
09/28 16:25:17 - mmengine - INFO - Iter(train) [ 14600/320000]  base_lr: 9.5884e-05 lr: 9.5884e-06  eta: 1 day, 17:08:05  time: 0.4862  data_time: 0.0106  memory: 5834  grad_norm: 80.9889  loss: 8.9835  decode.loss_cls: 0.1945  decode.loss_mask: 0.3079  decode.loss_dice: 0.3376  decode.d0.loss_cls: 0.9487  decode.d0.loss_mask: 0.2952  decode.d0.loss_dice: 0.3161  decode.d1.loss_cls: 0.2766  decode.d1.loss_mask: 0.2955  decode.d1.loss_dice: 0.3394  decode.d2.loss_cls: 0.1763  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.3326  decode.d3.loss_cls: 0.1719  decode.d3.loss_mask: 0.2934  decode.d3.loss_dice: 0.3227  decode.d4.loss_cls: 0.1681  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.3376  decode.d5.loss_cls: 0.1570  decode.d5.loss_mask: 0.2980  decode.d5.loss_dice: 0.3372  decode.d6.loss_cls: 0.2213  decode.d6.loss_mask: 0.2922  decode.d6.loss_dice: 0.3191  decode.d7.loss_cls: 0.2067  decode.d7.loss_mask: 0.2975  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.2039  decode.d8.loss_mask: 0.2991  decode.d8.loss_dice: 0.3247
09/28 16:25:41 - mmengine - INFO - Iter(train) [ 14650/320000]  base_lr: 9.5870e-05 lr: 9.5870e-06  eta: 1 day, 17:07:42  time: 0.4870  data_time: 0.0104  memory: 5834  grad_norm: 120.7678  loss: 7.5628  decode.loss_cls: 0.2831  decode.loss_mask: 0.2432  decode.loss_dice: 0.1923  decode.d0.loss_cls: 0.9400  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2162  decode.d1.loss_cls: 0.2284  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.2267  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.2045  decode.d3.loss_cls: 0.2087  decode.d3.loss_mask: 0.2544  decode.d3.loss_dice: 0.2015  decode.d4.loss_cls: 0.2168  decode.d4.loss_mask: 0.2525  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.2430  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.2405  decode.d6.loss_mask: 0.2472  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.2440  decode.d7.loss_mask: 0.2501  decode.d7.loss_dice: 0.1833  decode.d8.loss_cls: 0.2754  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.1926
09/28 16:26:06 - mmengine - INFO - Iter(train) [ 14700/320000]  base_lr: 9.5856e-05 lr: 9.5856e-06  eta: 1 day, 17:07:19  time: 0.4867  data_time: 0.0103  memory: 5834  grad_norm: 148.2166  loss: 7.1017  decode.loss_cls: 0.1889  decode.loss_mask: 0.2228  decode.loss_dice: 0.2366  decode.d0.loss_cls: 0.9159  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.2353  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.2220  decode.d3.loss_cls: 0.1568  decode.d3.loss_mask: 0.2266  decode.d3.loss_dice: 0.2263  decode.d4.loss_cls: 0.1725  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.2346  decode.d5.loss_cls: 0.1648  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.2345  decode.d6.loss_cls: 0.1520  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2281  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2272  decode.d7.loss_dice: 0.2335  decode.d8.loss_cls: 0.1841  decode.d8.loss_mask: 0.2243  decode.d8.loss_dice: 0.2311
09/28 16:26:30 - mmengine - INFO - Iter(train) [ 14750/320000]  base_lr: 9.5842e-05 lr: 9.5842e-06  eta: 1 day, 17:06:56  time: 0.4865  data_time: 0.0106  memory: 5817  grad_norm: 77.3660  loss: 7.6585  decode.loss_cls: 0.3274  decode.loss_mask: 0.2021  decode.loss_dice: 0.1866  decode.d0.loss_cls: 0.9923  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2055  decode.d1.loss_cls: 0.3127  decode.d1.loss_mask: 0.2046  decode.d1.loss_dice: 0.1970  decode.d2.loss_cls: 0.2952  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.1531  decode.d3.loss_cls: 0.3208  decode.d3.loss_mask: 0.2063  decode.d3.loss_dice: 0.1507  decode.d4.loss_cls: 0.3348  decode.d4.loss_mask: 0.2054  decode.d4.loss_dice: 0.1660  decode.d5.loss_cls: 0.2996  decode.d5.loss_mask: 0.2068  decode.d5.loss_dice: 0.1496  decode.d6.loss_cls: 0.3203  decode.d6.loss_mask: 0.2271  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.3222  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1552  decode.d8.loss_cls: 0.2804  decode.d8.loss_mask: 0.2070  decode.d8.loss_dice: 0.2159
09/28 16:26:54 - mmengine - INFO - Iter(train) [ 14800/320000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 1 day, 17:06:33  time: 0.4859  data_time: 0.0104  memory: 5834  grad_norm: 63.9404  loss: 7.2128  decode.loss_cls: 0.1838  decode.loss_mask: 0.2622  decode.loss_dice: 0.2020  decode.d0.loss_cls: 1.0187  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.2371  decode.d1.loss_cls: 0.1266  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.1189  decode.d2.loss_mask: 0.2643  decode.d2.loss_dice: 0.2087  decode.d3.loss_cls: 0.1180  decode.d3.loss_mask: 0.2612  decode.d3.loss_dice: 0.2104  decode.d4.loss_cls: 0.1397  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.1850  decode.d5.loss_mask: 0.2666  decode.d5.loss_dice: 0.2339  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 0.2761  decode.d6.loss_dice: 0.2370  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.1408  decode.d8.loss_mask: 0.2645  decode.d8.loss_dice: 0.2078
09/28 16:27:19 - mmengine - INFO - Iter(train) [ 14850/320000]  base_lr: 9.5814e-05 lr: 9.5814e-06  eta: 1 day, 17:06:14  time: 0.4856  data_time: 0.0104  memory: 5834  grad_norm: 111.3243  loss: 9.2246  decode.loss_cls: 0.2619  decode.loss_mask: 0.3168  decode.loss_dice: 0.2296  decode.d0.loss_cls: 1.1910  decode.d0.loss_mask: 0.3287  decode.d0.loss_dice: 0.2571  decode.d1.loss_cls: 0.2768  decode.d1.loss_mask: 0.3213  decode.d1.loss_dice: 0.2343  decode.d2.loss_cls: 0.1741  decode.d2.loss_mask: 0.3150  decode.d2.loss_dice: 0.2513  decode.d3.loss_cls: 0.2290  decode.d3.loss_mask: 0.3296  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.2760  decode.d4.loss_mask: 0.3392  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.2666  decode.d5.loss_mask: 0.3227  decode.d5.loss_dice: 0.2412  decode.d6.loss_cls: 0.2888  decode.d6.loss_mask: 0.3220  decode.d6.loss_dice: 0.2397  decode.d7.loss_cls: 0.2723  decode.d7.loss_mask: 0.3492  decode.d7.loss_dice: 0.2549  decode.d8.loss_cls: 0.2413  decode.d8.loss_mask: 0.3382  decode.d8.loss_dice: 0.2432
09/28 16:27:43 - mmengine - INFO - Iter(train) [ 14900/320000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 1 day, 17:05:50  time: 0.4851  data_time: 0.0103  memory: 5817  grad_norm: 94.5476  loss: 8.2640  decode.loss_cls: 0.1611  decode.loss_mask: 0.2884  decode.loss_dice: 0.2797  decode.d0.loss_cls: 0.8521  decode.d0.loss_mask: 0.3188  decode.d0.loss_dice: 0.2945  decode.d1.loss_cls: 0.1627  decode.d1.loss_mask: 0.2878  decode.d1.loss_dice: 0.2896  decode.d2.loss_cls: 0.1439  decode.d2.loss_mask: 0.3029  decode.d2.loss_dice: 0.3072  decode.d3.loss_cls: 0.1628  decode.d3.loss_mask: 0.2962  decode.d3.loss_dice: 0.2836  decode.d4.loss_cls: 0.1493  decode.d4.loss_mask: 0.2884  decode.d4.loss_dice: 0.2955  decode.d5.loss_cls: 0.1643  decode.d5.loss_mask: 0.3054  decode.d5.loss_dice: 0.3051  decode.d6.loss_cls: 0.1837  decode.d6.loss_mask: 0.3073  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.1701  decode.d7.loss_mask: 0.2997  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.1701  decode.d8.loss_mask: 0.2921  decode.d8.loss_dice: 0.2803
09/28 16:28:07 - mmengine - INFO - Iter(train) [ 14950/320000]  base_lr: 9.5786e-05 lr: 9.5786e-06  eta: 1 day, 17:05:27  time: 0.4861  data_time: 0.0104  memory: 5817  grad_norm: 355.7064  loss: 9.0666  decode.loss_cls: 0.2944  decode.loss_mask: 0.2951  decode.loss_dice: 0.3019  decode.d0.loss_cls: 1.1434  decode.d0.loss_mask: 0.3559  decode.d0.loss_dice: 0.3372  decode.d1.loss_cls: 0.1780  decode.d1.loss_mask: 0.3119  decode.d1.loss_dice: 0.2765  decode.d2.loss_cls: 0.1850  decode.d2.loss_mask: 0.3090  decode.d2.loss_dice: 0.2695  decode.d3.loss_cls: 0.1570  decode.d3.loss_mask: 0.3045  decode.d3.loss_dice: 0.2883  decode.d4.loss_cls: 0.1708  decode.d4.loss_mask: 0.3028  decode.d4.loss_dice: 0.3028  decode.d5.loss_cls: 0.2047  decode.d5.loss_mask: 0.3004  decode.d5.loss_dice: 0.2979  decode.d6.loss_cls: 0.2200  decode.d6.loss_mask: 0.3115  decode.d6.loss_dice: 0.2988  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.3092  decode.d7.loss_dice: 0.3011  decode.d8.loss_cls: 0.2793  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.3008
09/28 16:28:32 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 16:28:32 - mmengine - INFO - Iter(train) [ 15000/320000]  base_lr: 9.5771e-05 lr: 9.5771e-06  eta: 1 day, 17:05:04  time: 0.4851  data_time: 0.0102  memory: 5834  grad_norm: 267.6641  loss: 10.2885  decode.loss_cls: 0.2024  decode.loss_mask: 0.4747  decode.loss_dice: 0.2945  decode.d0.loss_cls: 1.1457  decode.d0.loss_mask: 0.3059  decode.d0.loss_dice: 0.3069  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 0.3675  decode.d1.loss_dice: 0.2855  decode.d2.loss_cls: 0.2135  decode.d2.loss_mask: 0.4336  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.1569  decode.d3.loss_mask: 0.4021  decode.d3.loss_dice: 0.3039  decode.d4.loss_cls: 0.1499  decode.d4.loss_mask: 0.4647  decode.d4.loss_dice: 0.2922  decode.d5.loss_cls: 0.2435  decode.d5.loss_mask: 0.3971  decode.d5.loss_dice: 0.3054  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 0.5070  decode.d6.loss_dice: 0.3279  decode.d7.loss_cls: 0.2601  decode.d7.loss_mask: 0.4336  decode.d7.loss_dice: 0.3091  decode.d8.loss_cls: 0.2667  decode.d8.loss_mask: 0.4338  decode.d8.loss_dice: 0.2623
09/28 16:28:56 - mmengine - INFO - Iter(train) [ 15050/320000]  base_lr: 9.5757e-05 lr: 9.5757e-06  eta: 1 day, 17:04:40  time: 0.4855  data_time: 0.0103  memory: 5815  grad_norm: 95.6804  loss: 7.3247  decode.loss_cls: 0.1519  decode.loss_mask: 0.2532  decode.loss_dice: 0.2104  decode.d0.loss_cls: 1.0236  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.2232  decode.d1.loss_mask: 0.2611  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.1915  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.2092  decode.d3.loss_cls: 0.2020  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.1717  decode.d4.loss_mask: 0.2566  decode.d4.loss_dice: 0.2175  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.2569  decode.d5.loss_dice: 0.2069  decode.d6.loss_cls: 0.1820  decode.d6.loss_mask: 0.2546  decode.d6.loss_dice: 0.2120  decode.d7.loss_cls: 0.1484  decode.d7.loss_mask: 0.2567  decode.d7.loss_dice: 0.2191  decode.d8.loss_cls: 0.1613  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.2151
09/28 16:29:20 - mmengine - INFO - Iter(train) [ 15100/320000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 1 day, 17:04:17  time: 0.4862  data_time: 0.0103  memory: 5834  grad_norm: 68.1981  loss: 5.1090  decode.loss_cls: 0.0379  decode.loss_mask: 0.1735  decode.loss_dice: 0.2011  decode.d0.loss_cls: 0.9544  decode.d0.loss_mask: 0.1688  decode.d0.loss_dice: 0.1976  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.1716  decode.d1.loss_dice: 0.1971  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.1720  decode.d2.loss_dice: 0.1987  decode.d3.loss_cls: 0.0589  decode.d3.loss_mask: 0.1707  decode.d3.loss_dice: 0.1971  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.1751  decode.d4.loss_dice: 0.2122  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.1744  decode.d5.loss_dice: 0.1972  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.1719  decode.d6.loss_dice: 0.2046  decode.d7.loss_cls: 0.0362  decode.d7.loss_mask: 0.1742  decode.d7.loss_dice: 0.2004  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.1740  decode.d8.loss_dice: 0.2120
09/28 16:29:44 - mmengine - INFO - Iter(train) [ 15150/320000]  base_lr: 9.5729e-05 lr: 9.5729e-06  eta: 1 day, 17:03:54  time: 0.4856  data_time: 0.0102  memory: 5799  grad_norm: 148.8497  loss: 6.9975  decode.loss_cls: 0.2110  decode.loss_mask: 0.2612  decode.loss_dice: 0.2361  decode.d0.loss_cls: 1.1171  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.2116  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.2630  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.0915  decode.d2.loss_mask: 0.2610  decode.d2.loss_dice: 0.2146  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.2170  decode.d4.loss_cls: 0.0626  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.1134  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2287  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.2163  decode.d7.loss_cls: 0.1441  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.2124  decode.d8.loss_cls: 0.1667  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.2196
09/28 16:30:09 - mmengine - INFO - Iter(train) [ 15200/320000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 1 day, 17:03:30  time: 0.4853  data_time: 0.0104  memory: 5817  grad_norm: 174.1210  loss: 11.0021  decode.loss_cls: 0.3899  decode.loss_mask: 0.3486  decode.loss_dice: 0.2790  decode.d0.loss_cls: 0.9856  decode.d0.loss_mask: 0.3156  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.4638  decode.d1.loss_mask: 0.2718  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.4605  decode.d2.loss_mask: 0.2963  decode.d2.loss_dice: 0.2709  decode.d3.loss_cls: 0.4737  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.4309  decode.d4.loss_mask: 0.3966  decode.d4.loss_dice: 0.2520  decode.d5.loss_cls: 0.4395  decode.d5.loss_mask: 0.4147  decode.d5.loss_dice: 0.2469  decode.d6.loss_cls: 0.4237  decode.d6.loss_mask: 0.2973  decode.d6.loss_dice: 0.2914  decode.d7.loss_cls: 0.4585  decode.d7.loss_mask: 0.3952  decode.d7.loss_dice: 0.2991  decode.d8.loss_cls: 0.3790  decode.d8.loss_mask: 0.3857  decode.d8.loss_dice: 0.2870
09/28 16:30:33 - mmengine - INFO - Iter(train) [ 15250/320000]  base_lr: 9.5701e-05 lr: 9.5701e-06  eta: 1 day, 17:03:07  time: 0.4857  data_time: 0.0102  memory: 5817  grad_norm: 185.1350  loss: 9.0862  decode.loss_cls: 0.2442  decode.loss_mask: 0.2991  decode.loss_dice: 0.2958  decode.d0.loss_cls: 0.9673  decode.d0.loss_mask: 0.2992  decode.d0.loss_dice: 0.2876  decode.d1.loss_cls: 0.2569  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.1803  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.1628  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.2723  decode.d4.loss_cls: 0.2422  decode.d4.loss_mask: 0.3017  decode.d4.loss_dice: 0.3141  decode.d5.loss_cls: 0.2233  decode.d5.loss_mask: 0.4424  decode.d5.loss_dice: 0.3300  decode.d6.loss_cls: 0.2683  decode.d6.loss_mask: 0.3097  decode.d6.loss_dice: 0.3068  decode.d7.loss_cls: 0.2389  decode.d7.loss_mask: 0.3263  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.1944  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.2986
09/28 16:30:57 - mmengine - INFO - Iter(train) [ 15300/320000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 1 day, 17:02:43  time: 0.4855  data_time: 0.0103  memory: 5798  grad_norm: 217.9355  loss: 8.1365  decode.loss_cls: 0.2388  decode.loss_mask: 0.2837  decode.loss_dice: 0.2682  decode.d0.loss_cls: 0.8254  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.2911  decode.d1.loss_cls: 0.1811  decode.d1.loss_mask: 0.2776  decode.d1.loss_dice: 0.2675  decode.d2.loss_cls: 0.1739  decode.d2.loss_mask: 0.2811  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.1612  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.2612  decode.d4.loss_cls: 0.1544  decode.d4.loss_mask: 0.2819  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.2365  decode.d5.loss_mask: 0.2814  decode.d5.loss_dice: 0.2604  decode.d6.loss_cls: 0.2305  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.2597  decode.d7.loss_cls: 0.2021  decode.d7.loss_mask: 0.2798  decode.d7.loss_dice: 0.2717  decode.d8.loss_cls: 0.2340  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.2674
09/28 16:31:22 - mmengine - INFO - Iter(train) [ 15350/320000]  base_lr: 9.5673e-05 lr: 9.5673e-06  eta: 1 day, 17:02:20  time: 0.4857  data_time: 0.0103  memory: 5816  grad_norm: 209.8975  loss: 10.7707  decode.loss_cls: 0.2555  decode.loss_mask: 0.3684  decode.loss_dice: 0.3149  decode.d0.loss_cls: 1.0584  decode.d0.loss_mask: 0.3712  decode.d0.loss_dice: 0.3430  decode.d1.loss_cls: 0.3625  decode.d1.loss_mask: 0.3556  decode.d1.loss_dice: 0.3192  decode.d2.loss_cls: 0.3311  decode.d2.loss_mask: 0.3620  decode.d2.loss_dice: 0.3217  decode.d3.loss_cls: 0.3139  decode.d3.loss_mask: 0.3716  decode.d3.loss_dice: 0.3142  decode.d4.loss_cls: 0.2809  decode.d4.loss_mask: 0.3703  decode.d4.loss_dice: 0.3345  decode.d5.loss_cls: 0.3341  decode.d5.loss_mask: 0.3641  decode.d5.loss_dice: 0.3303  decode.d6.loss_cls: 0.3684  decode.d6.loss_mask: 0.3574  decode.d6.loss_dice: 0.3231  decode.d7.loss_cls: 0.3095  decode.d7.loss_mask: 0.3475  decode.d7.loss_dice: 0.3106  decode.d8.loss_cls: 0.3029  decode.d8.loss_mask: 0.3551  decode.d8.loss_dice: 0.3190
09/28 16:31:46 - mmengine - INFO - Iter(train) [ 15400/320000]  base_lr: 9.5658e-05 lr: 9.5658e-06  eta: 1 day, 17:01:56  time: 0.4856  data_time: 0.0103  memory: 5799  grad_norm: 68.0946  loss: 5.6746  decode.loss_cls: 0.0581  decode.loss_mask: 0.1992  decode.loss_dice: 0.1816  decode.d0.loss_cls: 0.9327  decode.d0.loss_mask: 0.2073  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.1593  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.1854  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.2074  decode.d2.loss_dice: 0.2025  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.1974  decode.d4.loss_cls: 0.0722  decode.d4.loss_mask: 0.2054  decode.d4.loss_dice: 0.1963  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.2061  decode.d5.loss_dice: 0.2018  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.2031  decode.d6.loss_dice: 0.2106  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.2027  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.2017
09/28 16:32:10 - mmengine - INFO - Iter(train) [ 15450/320000]  base_lr: 9.5644e-05 lr: 9.5644e-06  eta: 1 day, 17:01:35  time: 0.4860  data_time: 0.0103  memory: 5817  grad_norm: 62.2476  loss: 6.3923  decode.loss_cls: 0.0839  decode.loss_mask: 0.2301  decode.loss_dice: 0.2249  decode.d0.loss_cls: 1.0294  decode.d0.loss_mask: 0.2357  decode.d0.loss_dice: 0.2516  decode.d1.loss_cls: 0.1257  decode.d1.loss_mask: 0.2268  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.1153  decode.d2.loss_mask: 0.2279  decode.d2.loss_dice: 0.2276  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.2267  decode.d3.loss_dice: 0.2241  decode.d4.loss_cls: 0.1015  decode.d4.loss_mask: 0.2300  decode.d4.loss_dice: 0.2231  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2245  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.2241  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.2316  decode.d7.loss_dice: 0.2233  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.2296
09/28 16:32:35 - mmengine - INFO - Iter(train) [ 15500/320000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 1 day, 17:01:11  time: 0.4858  data_time: 0.0103  memory: 5819  grad_norm: 76.3735  loss: 7.6774  decode.loss_cls: 0.2052  decode.loss_mask: 0.2453  decode.loss_dice: 0.2342  decode.d0.loss_cls: 1.0084  decode.d0.loss_mask: 0.2575  decode.d0.loss_dice: 0.2232  decode.d1.loss_cls: 0.2107  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.2205  decode.d2.loss_cls: 0.1884  decode.d2.loss_mask: 0.2450  decode.d2.loss_dice: 0.2492  decode.d3.loss_cls: 0.2093  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.2246  decode.d4.loss_cls: 0.2247  decode.d4.loss_mask: 0.2470  decode.d4.loss_dice: 0.2377  decode.d5.loss_cls: 0.1623  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.2059  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2322  decode.d7.loss_cls: 0.1966  decode.d7.loss_mask: 0.2467  decode.d7.loss_dice: 0.2471  decode.d8.loss_cls: 0.2064  decode.d8.loss_mask: 0.2492  decode.d8.loss_dice: 0.2449
09/28 16:32:59 - mmengine - INFO - Iter(train) [ 15550/320000]  base_lr: 9.5616e-05 lr: 9.5616e-06  eta: 1 day, 17:00:48  time: 0.4855  data_time: 0.0100  memory: 5816  grad_norm: 206.3057  loss: 7.7851  decode.loss_cls: 0.2200  decode.loss_mask: 0.3317  decode.loss_dice: 0.2193  decode.d0.loss_cls: 1.1004  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.2233  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.1890  decode.d3.loss_cls: 0.2653  decode.d3.loss_mask: 0.2843  decode.d3.loss_dice: 0.1944  decode.d4.loss_cls: 0.2037  decode.d4.loss_mask: 0.2817  decode.d4.loss_dice: 0.2051  decode.d5.loss_cls: 0.2010  decode.d5.loss_mask: 0.3178  decode.d5.loss_dice: 0.2180  decode.d6.loss_cls: 0.1863  decode.d6.loss_mask: 0.2668  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.1957  decode.d7.loss_mask: 0.2430  decode.d7.loss_dice: 0.2123  decode.d8.loss_cls: 0.2073  decode.d8.loss_mask: 0.3521  decode.d8.loss_dice: 0.2191
09/28 16:33:23 - mmengine - INFO - Iter(train) [ 15600/320000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 1 day, 17:00:25  time: 0.4865  data_time: 0.0104  memory: 5835  grad_norm: 81.6239  loss: 6.0051  decode.loss_cls: 0.0223  decode.loss_mask: 0.2468  decode.loss_dice: 0.2143  decode.d0.loss_cls: 1.0419  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.2190  decode.d1.loss_cls: 0.0948  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.2244  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.2442  decode.d2.loss_dice: 0.2235  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.2213  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.2138  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.2159  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.2444  decode.d6.loss_dice: 0.2124  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2135  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2201
09/28 16:33:48 - mmengine - INFO - Iter(train) [ 15650/320000]  base_lr: 9.5588e-05 lr: 9.5588e-06  eta: 1 day, 17:00:02  time: 0.4862  data_time: 0.0103  memory: 5835  grad_norm: 89.6496  loss: 5.7611  decode.loss_cls: 0.0255  decode.loss_mask: 0.2689  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.8915  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.1785  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.3011  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.1831  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.2645  decode.d5.loss_dice: 0.1809  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.1805  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.2671  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.2665  decode.d8.loss_dice: 0.1783
09/28 16:34:12 - mmengine - INFO - Iter(train) [ 15700/320000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 1 day, 16:59:39  time: 0.4861  data_time: 0.0105  memory: 5816  grad_norm: 69.5498  loss: 8.2525  decode.loss_cls: 0.1577  decode.loss_mask: 0.3027  decode.loss_dice: 0.2528  decode.d0.loss_cls: 0.7956  decode.d0.loss_mask: 0.3101  decode.d0.loss_dice: 0.2551  decode.d1.loss_cls: 0.2474  decode.d1.loss_mask: 0.3074  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.2388  decode.d2.loss_mask: 0.3091  decode.d2.loss_dice: 0.2559  decode.d3.loss_cls: 0.1993  decode.d3.loss_mask: 0.3070  decode.d3.loss_dice: 0.2545  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.3023  decode.d4.loss_dice: 0.2588  decode.d5.loss_cls: 0.3225  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.2572  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.3072  decode.d6.loss_dice: 0.2864  decode.d7.loss_cls: 0.1643  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.2653  decode.d8.loss_cls: 0.1679  decode.d8.loss_mask: 0.3007  decode.d8.loss_dice: 0.2587
09/28 16:34:36 - mmengine - INFO - Iter(train) [ 15750/320000]  base_lr: 9.5559e-05 lr: 9.5559e-06  eta: 1 day, 16:59:16  time: 0.4867  data_time: 0.0106  memory: 5798  grad_norm: 76.1278  loss: 8.1723  decode.loss_cls: 0.1470  decode.loss_mask: 0.3408  decode.loss_dice: 0.2405  decode.d0.loss_cls: 1.0843  decode.d0.loss_mask: 0.3448  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.2262  decode.d1.loss_mask: 0.3593  decode.d1.loss_dice: 0.2520  decode.d2.loss_cls: 0.1452  decode.d2.loss_mask: 0.3351  decode.d2.loss_dice: 0.2368  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 0.3291  decode.d3.loss_dice: 0.2265  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1447  decode.d5.loss_mask: 0.3375  decode.d5.loss_dice: 0.2351  decode.d6.loss_cls: 0.1050  decode.d6.loss_mask: 0.3351  decode.d6.loss_dice: 0.2351  decode.d7.loss_cls: 0.1365  decode.d7.loss_mask: 0.3318  decode.d7.loss_dice: 0.2300  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 0.3382  decode.d8.loss_dice: 0.2309
09/28 16:35:01 - mmengine - INFO - Iter(train) [ 15800/320000]  base_lr: 9.5545e-05 lr: 9.5545e-06  eta: 1 day, 16:58:53  time: 0.4873  data_time: 0.0105  memory: 5834  grad_norm: 346.6284  loss: 8.4190  decode.loss_cls: 0.1809  decode.loss_mask: 0.3092  decode.loss_dice: 0.3041  decode.d0.loss_cls: 1.1371  decode.d0.loss_mask: 0.3015  decode.d0.loss_dice: 0.2860  decode.d1.loss_cls: 0.1736  decode.d1.loss_mask: 0.2924  decode.d1.loss_dice: 0.2881  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 0.2931  decode.d2.loss_dice: 0.2655  decode.d3.loss_cls: 0.1787  decode.d3.loss_mask: 0.2934  decode.d3.loss_dice: 0.2659  decode.d4.loss_cls: 0.1934  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.2536  decode.d5.loss_cls: 0.1718  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.2771  decode.d6.loss_cls: 0.1829  decode.d6.loss_mask: 0.2894  decode.d6.loss_dice: 0.2597  decode.d7.loss_cls: 0.1775  decode.d7.loss_mask: 0.2897  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.1734  decode.d8.loss_mask: 0.2934  decode.d8.loss_dice: 0.2630
09/28 16:35:25 - mmengine - INFO - Iter(train) [ 15850/320000]  base_lr: 9.5531e-05 lr: 9.5531e-06  eta: 1 day, 16:58:31  time: 0.4864  data_time: 0.0106  memory: 5798  grad_norm: 866.1471  loss: 12.6130  decode.loss_cls: 0.2987  decode.loss_mask: 0.4370  decode.loss_dice: 0.4023  decode.d0.loss_cls: 0.9886  decode.d0.loss_mask: 0.4460  decode.d0.loss_dice: 0.3992  decode.d1.loss_cls: 0.5124  decode.d1.loss_mask: 0.4394  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.3974  decode.d2.loss_mask: 0.4443  decode.d2.loss_dice: 0.3997  decode.d3.loss_cls: 0.3431  decode.d3.loss_mask: 0.4325  decode.d3.loss_dice: 0.4010  decode.d4.loss_cls: 0.3916  decode.d4.loss_mask: 0.4137  decode.d4.loss_dice: 0.3814  decode.d5.loss_cls: 0.3444  decode.d5.loss_mask: 0.4429  decode.d5.loss_dice: 0.3892  decode.d6.loss_cls: 0.3573  decode.d6.loss_mask: 0.4318  decode.d6.loss_dice: 0.3899  decode.d7.loss_cls: 0.3728  decode.d7.loss_mask: 0.4362  decode.d7.loss_dice: 0.4027  decode.d8.loss_cls: 0.3156  decode.d8.loss_mask: 0.4223  decode.d8.loss_dice: 0.3964
09/28 16:35:49 - mmengine - INFO - Iter(train) [ 15900/320000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 1 day, 16:58:08  time: 0.4866  data_time: 0.0107  memory: 5834  grad_norm: 51.8624  loss: 6.1298  decode.loss_cls: 0.0773  decode.loss_mask: 0.2531  decode.loss_dice: 0.1978  decode.d0.loss_cls: 0.9944  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.2067  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.2058  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.2499  decode.d2.loss_dice: 0.2054  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.1963  decode.d4.loss_cls: 0.0485  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.1991  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.1980  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.1999  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.2526  decode.d7.loss_dice: 0.2102  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.1992
09/28 16:36:14 - mmengine - INFO - Iter(train) [ 15950/320000]  base_lr: 9.5503e-05 lr: 9.5503e-06  eta: 1 day, 16:57:48  time: 0.4977  data_time: 0.0103  memory: 5817  grad_norm: 191.0741  loss: 7.2058  decode.loss_cls: 0.0895  decode.loss_mask: 0.2793  decode.loss_dice: 0.2356  decode.d0.loss_cls: 0.9692  decode.d0.loss_mask: 0.2772  decode.d0.loss_dice: 0.2304  decode.d1.loss_cls: 0.2067  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.2276  decode.d2.loss_cls: 0.1497  decode.d2.loss_mask: 0.2758  decode.d2.loss_dice: 0.2484  decode.d3.loss_cls: 0.1493  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.2344  decode.d4.loss_cls: 0.1477  decode.d4.loss_mask: 0.2746  decode.d4.loss_dice: 0.2274  decode.d5.loss_cls: 0.1018  decode.d5.loss_mask: 0.2803  decode.d5.loss_dice: 0.2365  decode.d6.loss_cls: 0.0917  decode.d6.loss_mask: 0.2772  decode.d6.loss_dice: 0.2291  decode.d7.loss_cls: 0.0948  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.2274  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.2269
09/28 16:36:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-80k_MYDATA-512x1024_20250928_142703
09/28 16:36:38 - mmengine - INFO - Iter(train) [ 16000/320000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 1 day, 16:57:25  time: 0.4858  data_time: 0.0106  memory: 5817  grad_norm: 143.7726  loss: 7.2757  decode.loss_cls: 0.0439  decode.loss_mask: 0.3225  decode.loss_dice: 0.2832  decode.d0.loss_cls: 0.7785  decode.d0.loss_mask: 0.3277  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.3234  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.3241  decode.d2.loss_dice: 0.2961  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.3211  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.2755  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.3209  decode.d5.loss_dice: 0.2934  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.3209  decode.d6.loss_dice: 0.2793  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.3237  decode.d7.loss_dice: 0.2557  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.3253  decode.d8.loss_dice: 0.2790
09/28 16:37:02 - mmengine - INFO - Iter(train) [ 16050/320000]  base_lr: 9.5475e-05 lr: 9.5475e-06  eta: 1 day, 16:57:02  time: 0.4859  data_time: 0.0105  memory: 5835  grad_norm: 87.7973  loss: 5.6684  decode.loss_cls: 0.0532  decode.loss_mask: 0.2303  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.7286  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.2082  decode.d1.loss_cls: 0.0461  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.2058  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.2296  decode.d2.loss_dice: 0.2116  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2118  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.1132  decode.d5.loss_mask: 0.2334  decode.d5.loss_dice: 0.2142  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.2119  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.2345  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.2271  decode.d8.loss_dice: 0.2118
09/28 16:37:27 - mmengine - INFO - Iter(train) [ 16100/320000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 1 day, 16:56:39  time: 0.4870  data_time: 0.0106  memory: 5799  grad_norm: 646.2844  loss: 9.6551  decode.loss_cls: 0.1797  decode.loss_mask: 0.3380  decode.loss_dice: 0.3724  decode.d0.loss_cls: 0.8026  decode.d0.loss_mask: 0.3388  decode.d0.loss_dice: 0.3935  decode.d1.loss_cls: 0.2382  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.4034  decode.d2.loss_cls: 0.1761  decode.d2.loss_mask: 0.3313  decode.d2.loss_dice: 0.3778  decode.d3.loss_cls: 0.2064  decode.d3.loss_mask: 0.3328  decode.d3.loss_dice: 0.3804  decode.d4.loss_cls: 0.1487  decode.d4.loss_mask: 0.3386  decode.d4.loss_dice: 0.3835  decode.d5.loss_cls: 0.1919  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.3810  decode.d6.loss_cls: 0.1893  decode.d6.loss_mask: 0.3378  decode.d6.loss_dice: 0.3783  decode.d7.loss_cls: 0.1683  decode.d7.loss_mask: 0.3419  decode.d7.loss_dice: 0.3855  decode.d8.loss_cls: 0.1378  decode.d8.loss_mask: 0.3375  decode.d8.loss_dice: 0.3845
09/28 16:37:51 - mmengine - INFO - Iter(train) [ 16150/320000]  base_lr: 9.5446e-05 lr: 9.5446e-06  eta: 1 day, 16:56:16  time: 0.4870  data_time: 0.0105  memory: 5817  grad_norm: 41.2735  loss: 5.5468  decode.loss_cls: 0.0255  decode.loss_mask: 0.2412  decode.loss_dice: 0.1938  decode.d0.loss_cls: 0.9695  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.1908  decode.d1.loss_cls: 0.0490  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.1930  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.2381  decode.d2.loss_dice: 0.1937  decode.d3.loss_cls: 0.0341  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.1876  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.2373  decode.d4.loss_dice: 0.1896  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.2395  decode.d5.loss_dice: 0.1930  decode.d6.loss_cls: 0.0334  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.1916  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.2379  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.1910
09/28 16:38:15 - mmengine - INFO - Iter(train) [ 16200/320000]  base_lr: 9.5432e-05 lr: 9.5432e-06  eta: 1 day, 16:55:53  time: 0.4871  data_time: 0.0107  memory: 5817  grad_norm: 314.2725  loss: 9.6007  decode.loss_cls: 0.1518  decode.loss_mask: 0.4661  decode.loss_dice: 0.2690  decode.d0.loss_cls: 1.1421  decode.d0.loss_mask: 0.3024  decode.d0.loss_dice: 0.2550  decode.d1.loss_cls: 0.2855  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.2151  decode.d2.loss_mask: 0.2951  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.2047  decode.d3.loss_mask: 0.4156  decode.d3.loss_dice: 0.2791  decode.d4.loss_cls: 0.3079  decode.d4.loss_mask: 0.3163  decode.d4.loss_dice: 0.2913  decode.d5.loss_cls: 0.2721  decode.d5.loss_mask: 0.3527  decode.d5.loss_dice: 0.3014  decode.d6.loss_cls: 0.2208  decode.d6.loss_mask: 0.4670  decode.d6.loss_dice: 0.2467  decode.d7.loss_cls: 0.1961  decode.d7.loss_mask: 0.4723  decode.d7.loss_dice: 0.2638  decode.d8.loss_cls: 0.1499  decode.d8.loss_mask: 0.4643  decode.d8.loss_dice: 0.2655
09/28 16:38:40 - mmengine - INFO - Iter(train) [ 16250/320000]  base_lr: 9.5418e-05 lr: 9.5418e-06  eta: 1 day, 16:55:33  time: 0.5026  data_time: 0.0103  memory: 5817  grad_norm: 106.2351  loss: 6.3982  decode.loss_cls: 0.1040  decode.loss_mask: 0.2357  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.8593  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2279  decode.d1.loss_cls: 0.1078  decode.d1.loss_mask: 0.2362  decode.d1.loss_dice: 0.2266  decode.d2.loss_cls: 0.1057  decode.d2.loss_mask: 0.2322  decode.d2.loss_dice: 0.2181  decode.d3.loss_cls: 0.0892  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.2193  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2271  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2223  decode.d6.loss_cls: 0.1507  decode.d6.loss_mask: 0.2327  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.0951  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.2168  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.2141
09/28 16:39:04 - mmengine - INFO - Iter(train) [ 16300/320000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 1 day, 16:55:10  time: 0.4873  data_time: 0.0106  memory: 5834  grad_norm: 73.2887  loss: 7.9825  decode.loss_cls: 0.1810  decode.loss_mask: 0.2696  decode.loss_dice: 0.2985  decode.d0.loss_cls: 1.0062  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.2285  decode.d1.loss_cls: 0.1649  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.2756  decode.d2.loss_cls: 0.1738  decode.d2.loss_mask: 0.2678  decode.d2.loss_dice: 0.2983  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 0.2659  decode.d3.loss_dice: 0.2974  decode.d4.loss_cls: 0.1941  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.1749  decode.d5.loss_mask: 0.2642  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.1681  decode.d6.loss_mask: 0.2662  decode.d6.loss_dice: 0.2696  decode.d7.loss_cls: 0.1849  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.2660  decode.d8.loss_cls: 0.1996  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.2548
09/28 16:39:28 - mmengine - INFO - Iter(train) [ 16350/320000]  base_lr: 9.5390e-05 lr: 9.5390e-06  eta: 1 day, 16:54:47  time: 0.4864  data_time: 0.0104  memory: 5817  grad_norm: 97.2187  loss: 6.6480  decode.loss_cls: 0.1052  decode.loss_mask: 0.2459  decode.loss_dice: 0.2108  decode.d0.loss_cls: 0.8455  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.2008  decode.d1.loss_cls: 0.1101  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.1921  decode.d2.loss_cls: 0.1212  decode.d2.loss_mask: 0.2485  decode.d2.loss_dice: 0.2086  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.2221  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 0.2458  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.1279  decode.d5.loss_mask: 0.2479  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.2011  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.1991  decode.d7.loss_cls: 0.1844  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.1987
09/28 16:39:53 - mmengine - INFO - Iter(train) [ 16400/320000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 1 day, 16:54:25  time: 0.4864  data_time: 0.0103  memory: 5834  grad_norm: 182.3202  loss: 8.5113  decode.loss_cls: 0.3247  decode.loss_mask: 0.2758  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.9329  decode.d0.loss_mask: 0.2668  decode.d0.loss_dice: 0.2489  decode.d1.loss_cls: 0.2405  decode.d1.loss_mask: 0.2634  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.2305  decode.d2.loss_mask: 0.2736  decode.d2.loss_dice: 0.2920  decode.d3.loss_cls: 0.1976  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.2580  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.2692  decode.d4.loss_dice: 0.2510  decode.d5.loss_cls: 0.2107  decode.d5.loss_mask: 0.2849  decode.d5.loss_dice: 0.2962  decode.d6.loss_cls: 0.2558  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.2109  decode.d7.loss_cls: 0.2355  decode.d7.loss_mask: 0.2921  decode.d7.loss_dice: 0.2935  decode.d8.loss_cls: 0.3198  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.2867
