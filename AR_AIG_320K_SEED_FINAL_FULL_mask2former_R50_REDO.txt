==========================================
SLURM_JOB_ID = 2505486
SLURM_NODELIST = gnode073
SLURM_JOB_GPUS = 0
==========================================
09/30 09:02:45 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

09/30 09:02:46 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=2, enable=False)
crop_size = (
    512,
    1024,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/segmentation_benchmark/food_FINAL_resized/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=40000,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=49,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 49
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=320000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/food_FINAL_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=320000, type='IterBasedTrainLoop', val_interval=40000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/segmentation_benchmark/food_FINAL_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/food_FINAL_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/segmentation_benchmark/mmseg_work_dir/AR_mask2former'

09/30 09:02:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
09/30 09:02:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
09/30 09:02:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
09/30 09:02:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
09/30 09:02:56 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
09/30 09:02:56 - mmengine - INFO - load model from: torchvision://resnet50
09/30 09:02:56 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
09/30 09:03:02 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

09/30 09:03:03 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
09/30 09:03:03 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
09/30 09:03:03 - mmengine - INFO - Checkpoints will be saved to /scratch/segmentation_benchmark/mmseg_work_dir/AR_mask2former.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
09/30 09:03:37 - mmengine - INFO - Iter(train) [    50/320000]  base_lr: 9.9986e-05 lr: 9.9986e-06  eta: 2 days, 13:07:56  time: 0.4199  data_time: 0.0086  memory: 10587  grad_norm: 225.1705  loss: 92.2626  decode.loss_cls: 3.3063  decode.loss_mask: 2.7368  decode.loss_dice: 3.8831  decode.d0.loss_cls: 7.8988  decode.d0.loss_mask: 2.1602  decode.d0.loss_dice: 2.9693  decode.d1.loss_cls: 3.1074  decode.d1.loss_mask: 2.1661  decode.d1.loss_dice: 2.9334  decode.d2.loss_cls: 2.9024  decode.d2.loss_mask: 2.2616  decode.d2.loss_dice: 2.8968  decode.d3.loss_cls: 2.8907  decode.d3.loss_mask: 2.2047  decode.d3.loss_dice: 2.9147  decode.d4.loss_cls: 2.8885  decode.d4.loss_mask: 2.2418  decode.d4.loss_dice: 2.9675  decode.d5.loss_cls: 2.9540  decode.d5.loss_mask: 2.3126  decode.d5.loss_dice: 3.0179  decode.d6.loss_cls: 3.0770  decode.d6.loss_mask: 2.7095  decode.d6.loss_dice: 3.3195  decode.d7.loss_cls: 3.2146  decode.d7.loss_mask: 2.8461  decode.d7.loss_dice: 3.4643  decode.d8.loss_cls: 3.2809  decode.d8.loss_mask: 3.0462  decode.d8.loss_dice: 3.6900
09/30 09:03:58 - mmengine - INFO - Iter(train) [   100/320000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 2 days, 1:19:50  time: 0.4237  data_time: 0.0089  memory: 5180  grad_norm: 409.7046  loss: 69.8492  decode.loss_cls: 2.5822  decode.loss_mask: 2.0165  decode.loss_dice: 2.4088  decode.d0.loss_cls: 7.7036  decode.d0.loss_mask: 1.8138  decode.d0.loss_dice: 2.2177  decode.d1.loss_cls: 2.5399  decode.d1.loss_mask: 1.7823  decode.d1.loss_dice: 2.1859  decode.d2.loss_cls: 2.4612  decode.d2.loss_mask: 1.7127  decode.d2.loss_dice: 2.0494  decode.d3.loss_cls: 2.2486  decode.d3.loss_mask: 1.7796  decode.d3.loss_dice: 2.1509  decode.d4.loss_cls: 2.2583  decode.d4.loss_mask: 1.7640  decode.d4.loss_dice: 2.0941  decode.d5.loss_cls: 2.2787  decode.d5.loss_mask: 1.9098  decode.d5.loss_dice: 2.1738  decode.d6.loss_cls: 2.3660  decode.d6.loss_mask: 1.8878  decode.d6.loss_dice: 2.1437  decode.d7.loss_cls: 2.3863  decode.d7.loss_mask: 1.9010  decode.d7.loss_dice: 2.2742  decode.d8.loss_cls: 2.4822  decode.d8.loss_mask: 1.9818  decode.d8.loss_dice: 2.2944
09/30 09:04:19 - mmengine - INFO - Iter(train) [   150/320000]  base_lr: 9.9958e-05 lr: 9.9958e-06  eta: 1 day, 21:27:47  time: 0.4257  data_time: 0.0086  memory: 5161  grad_norm: 494.3880  loss: 60.2107  decode.loss_cls: 2.2835  decode.loss_mask: 1.6119  decode.loss_dice: 1.6908  decode.d0.loss_cls: 7.6650  decode.d0.loss_mask: 1.4160  decode.d0.loss_dice: 1.7346  decode.d1.loss_cls: 2.4254  decode.d1.loss_mask: 1.5091  decode.d1.loss_dice: 1.5380  decode.d2.loss_cls: 2.3273  decode.d2.loss_mask: 1.5747  decode.d2.loss_dice: 1.4949  decode.d3.loss_cls: 2.2072  decode.d3.loss_mask: 1.7360  decode.d3.loss_dice: 1.5353  decode.d4.loss_cls: 2.2038  decode.d4.loss_mask: 1.7122  decode.d4.loss_dice: 1.5421  decode.d5.loss_cls: 2.2018  decode.d5.loss_mask: 1.7076  decode.d5.loss_dice: 1.5840  decode.d6.loss_cls: 2.1984  decode.d6.loss_mask: 1.7066  decode.d6.loss_dice: 1.6787  decode.d7.loss_cls: 2.1711  decode.d7.loss_mask: 1.6156  decode.d7.loss_dice: 1.6599  decode.d8.loss_cls: 2.1903  decode.d8.loss_mask: 1.6400  decode.d8.loss_dice: 1.6489
09/30 09:04:41 - mmengine - INFO - Iter(train) [   200/320000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 1 day, 19:33:18  time: 0.4258  data_time: 0.0085  memory: 5147  grad_norm: 322.9121  loss: 50.1553  decode.loss_cls: 2.1498  decode.loss_mask: 1.2651  decode.loss_dice: 1.1283  decode.d0.loss_cls: 7.5582  decode.d0.loss_mask: 1.3188  decode.d0.loss_dice: 1.2681  decode.d1.loss_cls: 2.0837  decode.d1.loss_mask: 1.3080  decode.d1.loss_dice: 1.1374  decode.d2.loss_cls: 2.0790  decode.d2.loss_mask: 1.2672  decode.d2.loss_dice: 1.0476  decode.d3.loss_cls: 2.0537  decode.d3.loss_mask: 1.3182  decode.d3.loss_dice: 1.1072  decode.d4.loss_cls: 2.0207  decode.d4.loss_mask: 1.2941  decode.d4.loss_dice: 1.1062  decode.d5.loss_cls: 2.0344  decode.d5.loss_mask: 1.2499  decode.d5.loss_dice: 1.0940  decode.d6.loss_cls: 2.1415  decode.d6.loss_mask: 1.1832  decode.d6.loss_dice: 1.0815  decode.d7.loss_cls: 2.0437  decode.d7.loss_mask: 1.2458  decode.d7.loss_dice: 1.1033  decode.d8.loss_cls: 2.0947  decode.d8.loss_mask: 1.2743  decode.d8.loss_dice: 1.0976
09/30 09:05:02 - mmengine - INFO - Iter(train) [   250/320000]  base_lr: 9.9930e-05 lr: 9.9930e-06  eta: 1 day, 18:26:08  time: 0.4298  data_time: 0.0089  memory: 5180  grad_norm: 453.6443  loss: 49.4665  decode.loss_cls: 2.3082  decode.loss_mask: 0.9210  decode.loss_dice: 1.0476  decode.d0.loss_cls: 7.4027  decode.d0.loss_mask: 1.0256  decode.d0.loss_dice: 1.4039  decode.d1.loss_cls: 2.1899  decode.d1.loss_mask: 1.0996  decode.d1.loss_dice: 1.2108  decode.d2.loss_cls: 2.1694  decode.d2.loss_mask: 1.0811  decode.d2.loss_dice: 1.1846  decode.d3.loss_cls: 2.1199  decode.d3.loss_mask: 1.1474  decode.d3.loss_dice: 1.1259  decode.d4.loss_cls: 2.1628  decode.d4.loss_mask: 1.1426  decode.d4.loss_dice: 1.1414  decode.d5.loss_cls: 2.2076  decode.d5.loss_mask: 1.1283  decode.d5.loss_dice: 1.1220  decode.d6.loss_cls: 2.2929  decode.d6.loss_mask: 1.0496  decode.d6.loss_dice: 1.1098  decode.d7.loss_cls: 2.2794  decode.d7.loss_mask: 0.9946  decode.d7.loss_dice: 1.0827  decode.d8.loss_cls: 2.3391  decode.d8.loss_mask: 0.9257  decode.d8.loss_dice: 1.0502
09/30 09:05:24 - mmengine - INFO - Iter(train) [   300/320000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 1 day, 17:42:12  time: 0.4295  data_time: 0.0086  memory: 5180  grad_norm: 274.7039  loss: 45.4411  decode.loss_cls: 2.2884  decode.loss_mask: 0.9060  decode.loss_dice: 1.0007  decode.d0.loss_cls: 7.2052  decode.d0.loss_mask: 0.8975  decode.d0.loss_dice: 1.2669  decode.d1.loss_cls: 2.2727  decode.d1.loss_mask: 0.8961  decode.d1.loss_dice: 1.0406  decode.d2.loss_cls: 2.1460  decode.d2.loss_mask: 0.7755  decode.d2.loss_dice: 0.9703  decode.d3.loss_cls: 2.1415  decode.d3.loss_mask: 0.8148  decode.d3.loss_dice: 0.9507  decode.d4.loss_cls: 2.2521  decode.d4.loss_mask: 0.6909  decode.d4.loss_dice: 0.9197  decode.d5.loss_cls: 2.3110  decode.d5.loss_mask: 0.7098  decode.d5.loss_dice: 0.9176  decode.d6.loss_cls: 2.3185  decode.d6.loss_mask: 0.7623  decode.d6.loss_dice: 0.9558  decode.d7.loss_cls: 2.3226  decode.d7.loss_mask: 0.7796  decode.d7.loss_dice: 0.9036  decode.d8.loss_cls: 2.2238  decode.d8.loss_mask: 0.8255  decode.d8.loss_dice: 0.9754
09/30 09:05:45 - mmengine - INFO - Iter(train) [   350/320000]  base_lr: 9.9902e-05 lr: 9.9902e-06  eta: 1 day, 17:10:41  time: 0.4290  data_time: 0.0088  memory: 5180  grad_norm: 303.3671  loss: 39.6417  decode.loss_cls: 1.8726  decode.loss_mask: 0.9219  decode.loss_dice: 0.7265  decode.d0.loss_cls: 7.0543  decode.d0.loss_mask: 0.9149  decode.d0.loss_dice: 0.9438  decode.d1.loss_cls: 1.7405  decode.d1.loss_mask: 0.8652  decode.d1.loss_dice: 0.8542  decode.d2.loss_cls: 1.6899  decode.d2.loss_mask: 0.8930  decode.d2.loss_dice: 0.7829  decode.d3.loss_cls: 1.7529  decode.d3.loss_mask: 0.8690  decode.d3.loss_dice: 0.7289  decode.d4.loss_cls: 1.7285  decode.d4.loss_mask: 0.8777  decode.d4.loss_dice: 0.6925  decode.d5.loss_cls: 1.7751  decode.d5.loss_mask: 0.9035  decode.d5.loss_dice: 0.7041  decode.d6.loss_cls: 1.8080  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 0.7125  decode.d7.loss_cls: 1.8116  decode.d7.loss_mask: 0.9174  decode.d7.loss_dice: 0.7256  decode.d8.loss_cls: 1.8061  decode.d8.loss_mask: 0.9585  decode.d8.loss_dice: 0.7261
09/30 09:06:06 - mmengine - INFO - Iter(train) [   400/320000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 1 day, 16:47:04  time: 0.4281  data_time: 0.0085  memory: 5161  grad_norm: 403.3743  loss: 42.6586  decode.loss_cls: 2.0615  decode.loss_mask: 0.9912  decode.loss_dice: 0.8916  decode.d0.loss_cls: 6.9445  decode.d0.loss_mask: 0.9399  decode.d0.loss_dice: 1.0894  decode.d1.loss_cls: 1.9479  decode.d1.loss_mask: 0.9028  decode.d1.loss_dice: 0.8449  decode.d2.loss_cls: 1.9140  decode.d2.loss_mask: 0.9300  decode.d2.loss_dice: 0.8211  decode.d3.loss_cls: 1.9355  decode.d3.loss_mask: 0.9197  decode.d3.loss_dice: 0.8504  decode.d4.loss_cls: 1.9280  decode.d4.loss_mask: 0.9415  decode.d4.loss_dice: 0.8561  decode.d5.loss_cls: 1.9100  decode.d5.loss_mask: 0.8511  decode.d5.loss_dice: 0.9185  decode.d6.loss_cls: 1.9250  decode.d6.loss_mask: 0.8360  decode.d6.loss_dice: 0.8510  decode.d7.loss_cls: 1.9551  decode.d7.loss_mask: 0.9526  decode.d7.loss_dice: 0.9191  decode.d8.loss_cls: 2.0355  decode.d8.loss_mask: 0.9125  decode.d8.loss_dice: 0.8821
09/30 09:06:22 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:06:28 - mmengine - INFO - Iter(train) [   450/320000]  base_lr: 9.9874e-05 lr: 9.9874e-06  eta: 1 day, 16:28:50  time: 0.4297  data_time: 0.0088  memory: 5160  grad_norm: 358.7970  loss: 34.5986  decode.loss_cls: 1.6422  decode.loss_mask: 0.8436  decode.loss_dice: 0.5330  decode.d0.loss_cls: 6.7033  decode.d0.loss_mask: 0.8698  decode.d0.loss_dice: 0.6695  decode.d1.loss_cls: 1.5352  decode.d1.loss_mask: 0.8666  decode.d1.loss_dice: 0.5839  decode.d2.loss_cls: 1.4182  decode.d2.loss_mask: 0.8442  decode.d2.loss_dice: 0.5261  decode.d3.loss_cls: 1.4241  decode.d3.loss_mask: 0.8659  decode.d3.loss_dice: 0.5630  decode.d4.loss_cls: 1.4431  decode.d4.loss_mask: 0.9024  decode.d4.loss_dice: 0.5763  decode.d5.loss_cls: 1.4090  decode.d5.loss_mask: 0.9301  decode.d5.loss_dice: 0.5639  decode.d6.loss_cls: 1.4677  decode.d6.loss_mask: 0.8927  decode.d6.loss_dice: 0.5603  decode.d7.loss_cls: 1.4843  decode.d7.loss_mask: 0.9164  decode.d7.loss_dice: 0.5625  decode.d8.loss_cls: 1.5842  decode.d8.loss_mask: 0.8842  decode.d8.loss_dice: 0.5327
09/30 09:06:49 - mmengine - INFO - Iter(train) [   500/320000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 1 day, 16:15:29  time: 0.4301  data_time: 0.0088  memory: 5147  grad_norm: 237.1181  loss: 34.2204  decode.loss_cls: 1.6469  decode.loss_mask: 0.7062  decode.loss_dice: 0.5665  decode.d0.loss_cls: 6.5127  decode.d0.loss_mask: 0.7263  decode.d0.loss_dice: 0.7794  decode.d1.loss_cls: 1.6754  decode.d1.loss_mask: 0.6768  decode.d1.loss_dice: 0.6093  decode.d2.loss_cls: 1.5605  decode.d2.loss_mask: 0.6988  decode.d2.loss_dice: 0.6212  decode.d3.loss_cls: 1.5735  decode.d3.loss_mask: 0.7147  decode.d3.loss_dice: 0.6247  decode.d4.loss_cls: 1.5520  decode.d4.loss_mask: 0.6999  decode.d4.loss_dice: 0.5799  decode.d5.loss_cls: 1.5929  decode.d5.loss_mask: 0.6807  decode.d5.loss_dice: 0.5464  decode.d6.loss_cls: 1.6350  decode.d6.loss_mask: 0.6633  decode.d6.loss_dice: 0.5616  decode.d7.loss_cls: 1.6895  decode.d7.loss_mask: 0.6973  decode.d7.loss_dice: 0.5997  decode.d8.loss_cls: 1.7049  decode.d8.loss_mask: 0.7069  decode.d8.loss_dice: 0.6174
09/30 09:07:11 - mmengine - INFO - Iter(train) [   550/320000]  base_lr: 9.9846e-05 lr: 9.9846e-06  eta: 1 day, 16:03:59  time: 0.4305  data_time: 0.0086  memory: 5160  grad_norm: 255.8197  loss: 35.1156  decode.loss_cls: 1.6254  decode.loss_mask: 0.8384  decode.loss_dice: 0.5663  decode.d0.loss_cls: 6.3560  decode.d0.loss_mask: 0.7998  decode.d0.loss_dice: 0.7347  decode.d1.loss_cls: 1.6828  decode.d1.loss_mask: 0.7702  decode.d1.loss_dice: 0.6267  decode.d2.loss_cls: 1.6343  decode.d2.loss_mask: 0.7648  decode.d2.loss_dice: 0.5651  decode.d3.loss_cls: 1.6052  decode.d3.loss_mask: 0.7868  decode.d3.loss_dice: 0.5570  decode.d4.loss_cls: 1.6483  decode.d4.loss_mask: 0.8415  decode.d4.loss_dice: 0.6421  decode.d5.loss_cls: 1.6060  decode.d5.loss_mask: 0.7963  decode.d5.loss_dice: 0.6212  decode.d6.loss_cls: 1.6243  decode.d6.loss_mask: 0.7918  decode.d6.loss_dice: 0.5863  decode.d7.loss_cls: 1.6411  decode.d7.loss_mask: 0.7916  decode.d7.loss_dice: 0.6031  decode.d8.loss_cls: 1.7023  decode.d8.loss_mask: 0.7584  decode.d8.loss_dice: 0.5477
09/30 09:07:32 - mmengine - INFO - Iter(train) [   600/320000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 1 day, 15:54:07  time: 0.4304  data_time: 0.0090  memory: 5161  grad_norm: 337.9048  loss: 35.7646  decode.loss_cls: 1.9092  decode.loss_mask: 0.8290  decode.loss_dice: 0.4916  decode.d0.loss_cls: 6.2135  decode.d0.loss_mask: 0.6844  decode.d0.loss_dice: 0.6493  decode.d1.loss_cls: 1.8338  decode.d1.loss_mask: 0.6526  decode.d1.loss_dice: 0.4978  decode.d2.loss_cls: 1.7639  decode.d2.loss_mask: 0.7018  decode.d2.loss_dice: 0.4413  decode.d3.loss_cls: 1.8072  decode.d3.loss_mask: 0.8075  decode.d3.loss_dice: 0.4762  decode.d4.loss_cls: 1.8650  decode.d4.loss_mask: 0.8043  decode.d4.loss_dice: 0.5023  decode.d5.loss_cls: 1.9103  decode.d5.loss_mask: 0.7648  decode.d5.loss_dice: 0.5018  decode.d6.loss_cls: 1.9595  decode.d6.loss_mask: 0.7481  decode.d6.loss_dice: 0.4640  decode.d7.loss_cls: 1.9502  decode.d7.loss_mask: 0.7917  decode.d7.loss_dice: 0.5071  decode.d8.loss_cls: 1.9931  decode.d8.loss_mask: 0.7649  decode.d8.loss_dice: 0.4783
09/30 09:07:54 - mmengine - INFO - Iter(train) [   650/320000]  base_lr: 9.9817e-05 lr: 9.9817e-06  eta: 1 day, 15:45:58  time: 0.4298  data_time: 0.0085  memory: 5180  grad_norm: 331.9722  loss: 33.1630  decode.loss_cls: 1.4685  decode.loss_mask: 0.8133  decode.loss_dice: 0.5778  decode.d0.loss_cls: 5.9867  decode.d0.loss_mask: 0.8764  decode.d0.loss_dice: 0.7225  decode.d1.loss_cls: 1.5013  decode.d1.loss_mask: 0.9565  decode.d1.loss_dice: 0.6232  decode.d2.loss_cls: 1.4116  decode.d2.loss_mask: 0.8619  decode.d2.loss_dice: 0.5495  decode.d3.loss_cls: 1.4525  decode.d3.loss_mask: 0.8534  decode.d3.loss_dice: 0.5206  decode.d4.loss_cls: 1.4089  decode.d4.loss_mask: 0.8199  decode.d4.loss_dice: 0.5294  decode.d5.loss_cls: 1.4331  decode.d5.loss_mask: 0.8706  decode.d5.loss_dice: 0.5314  decode.d6.loss_cls: 1.4290  decode.d6.loss_mask: 0.8478  decode.d6.loss_dice: 0.5218  decode.d7.loss_cls: 1.4116  decode.d7.loss_mask: 0.8439  decode.d7.loss_dice: 0.5260  decode.d8.loss_cls: 1.4654  decode.d8.loss_mask: 0.8129  decode.d8.loss_dice: 0.5357
09/30 09:08:16 - mmengine - INFO - Iter(train) [   700/320000]  base_lr: 9.9803e-05 lr: 9.9803e-06  eta: 1 day, 15:38:38  time: 0.4299  data_time: 0.0084  memory: 5193  grad_norm: 195.2503  loss: 28.8802  decode.loss_cls: 1.5933  decode.loss_mask: 0.4092  decode.loss_dice: 0.3772  decode.d0.loss_cls: 5.8113  decode.d0.loss_mask: 0.4642  decode.d0.loss_dice: 0.5738  decode.d1.loss_cls: 1.6321  decode.d1.loss_mask: 0.3990  decode.d1.loss_dice: 0.4161  decode.d2.loss_cls: 1.5995  decode.d2.loss_mask: 0.4317  decode.d2.loss_dice: 0.3314  decode.d3.loss_cls: 1.6007  decode.d3.loss_mask: 0.4606  decode.d3.loss_dice: 0.3845  decode.d4.loss_cls: 1.6464  decode.d4.loss_mask: 0.4071  decode.d4.loss_dice: 0.3655  decode.d5.loss_cls: 1.6614  decode.d5.loss_mask: 0.4761  decode.d5.loss_dice: 0.4255  decode.d6.loss_cls: 1.6900  decode.d6.loss_mask: 0.3870  decode.d6.loss_dice: 0.3579  decode.d7.loss_cls: 1.7190  decode.d7.loss_mask: 0.4343  decode.d7.loss_dice: 0.3962  decode.d8.loss_cls: 1.6556  decode.d8.loss_mask: 0.4043  decode.d8.loss_dice: 0.3693
09/30 09:08:37 - mmengine - INFO - Iter(train) [   750/320000]  base_lr: 9.9789e-05 lr: 9.9789e-06  eta: 1 day, 15:32:30  time: 0.4303  data_time: 0.0087  memory: 5160  grad_norm: 263.0345  loss: 30.4525  decode.loss_cls: 1.5455  decode.loss_mask: 0.6236  decode.loss_dice: 0.4564  decode.d0.loss_cls: 5.6346  decode.d0.loss_mask: 0.6155  decode.d0.loss_dice: 0.5883  decode.d1.loss_cls: 1.4410  decode.d1.loss_mask: 0.7482  decode.d1.loss_dice: 0.5102  decode.d2.loss_cls: 1.3817  decode.d2.loss_mask: 0.7175  decode.d2.loss_dice: 0.5303  decode.d3.loss_cls: 1.4949  decode.d3.loss_mask: 0.6327  decode.d3.loss_dice: 0.4739  decode.d4.loss_cls: 1.4360  decode.d4.loss_mask: 0.6797  decode.d4.loss_dice: 0.5340  decode.d5.loss_cls: 1.4660  decode.d5.loss_mask: 0.6623  decode.d5.loss_dice: 0.4516  decode.d6.loss_cls: 1.4555  decode.d6.loss_mask: 0.6435  decode.d6.loss_dice: 0.4394  decode.d7.loss_cls: 1.5100  decode.d7.loss_mask: 0.6500  decode.d7.loss_dice: 0.4730  decode.d8.loss_cls: 1.5732  decode.d8.loss_mask: 0.6455  decode.d8.loss_dice: 0.4383
09/30 09:08:59 - mmengine - INFO - Iter(train) [   800/320000]  base_lr: 9.9775e-05 lr: 9.9775e-06  eta: 1 day, 15:26:42  time: 0.4296  data_time: 0.0084  memory: 5145  grad_norm: 222.1036  loss: 34.1816  decode.loss_cls: 1.7373  decode.loss_mask: 0.8118  decode.loss_dice: 0.6220  decode.d0.loss_cls: 5.4729  decode.d0.loss_mask: 0.7214  decode.d0.loss_dice: 0.6815  decode.d1.loss_cls: 1.5165  decode.d1.loss_mask: 0.8158  decode.d1.loss_dice: 0.6362  decode.d2.loss_cls: 1.6359  decode.d2.loss_mask: 0.7627  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 1.6343  decode.d3.loss_mask: 0.7676  decode.d3.loss_dice: 0.5891  decode.d4.loss_cls: 1.5753  decode.d4.loss_mask: 0.8227  decode.d4.loss_dice: 0.5991  decode.d5.loss_cls: 1.6185  decode.d5.loss_mask: 0.7618  decode.d5.loss_dice: 0.5773  decode.d6.loss_cls: 1.6247  decode.d6.loss_mask: 0.8712  decode.d6.loss_dice: 0.6165  decode.d7.loss_cls: 1.7182  decode.d7.loss_mask: 0.7705  decode.d7.loss_dice: 0.6324  decode.d8.loss_cls: 1.6805  decode.d8.loss_mask: 0.6813  decode.d8.loss_dice: 0.6082
09/30 09:09:20 - mmengine - INFO - Iter(train) [   850/320000]  base_lr: 9.9761e-05 lr: 9.9761e-06  eta: 1 day, 15:21:44  time: 0.4310  data_time: 0.0085  memory: 5180  grad_norm: 239.7608  loss: 33.5182  decode.loss_cls: 1.7759  decode.loss_mask: 0.7228  decode.loss_dice: 0.5799  decode.d0.loss_cls: 5.2676  decode.d0.loss_mask: 0.7167  decode.d0.loss_dice: 0.6791  decode.d1.loss_cls: 1.8027  decode.d1.loss_mask: 0.6533  decode.d1.loss_dice: 0.5949  decode.d2.loss_cls: 1.8034  decode.d2.loss_mask: 0.6258  decode.d2.loss_dice: 0.5176  decode.d3.loss_cls: 1.7692  decode.d3.loss_mask: 0.6582  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 1.6772  decode.d4.loss_mask: 0.6960  decode.d4.loss_dice: 0.5705  decode.d5.loss_cls: 1.7970  decode.d5.loss_mask: 0.6622  decode.d5.loss_dice: 0.5528  decode.d6.loss_cls: 1.7716  decode.d6.loss_mask: 0.6315  decode.d6.loss_dice: 0.5150  decode.d7.loss_cls: 1.7457  decode.d7.loss_mask: 0.6647  decode.d7.loss_dice: 0.5345  decode.d8.loss_cls: 1.7982  decode.d8.loss_mask: 0.6566  decode.d8.loss_dice: 0.5254
09/30 09:09:42 - mmengine - INFO - Iter(train) [   900/320000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 1 day, 15:17:18  time: 0.4299  data_time: 0.0085  memory: 5180  grad_norm: 334.9883  loss: 34.7798  decode.loss_cls: 1.8020  decode.loss_mask: 0.7372  decode.loss_dice: 0.6579  decode.d0.loss_cls: 5.0315  decode.d0.loss_mask: 0.7102  decode.d0.loss_dice: 0.8000  decode.d1.loss_cls: 1.8939  decode.d1.loss_mask: 0.5979  decode.d1.loss_dice: 0.6929  decode.d2.loss_cls: 1.8827  decode.d2.loss_mask: 0.5870  decode.d2.loss_dice: 0.6527  decode.d3.loss_cls: 1.8118  decode.d3.loss_mask: 0.5880  decode.d3.loss_dice: 0.6120  decode.d4.loss_cls: 1.7038  decode.d4.loss_mask: 0.7794  decode.d4.loss_dice: 0.6980  decode.d5.loss_cls: 1.7259  decode.d5.loss_mask: 0.7133  decode.d5.loss_dice: 0.6557  decode.d6.loss_cls: 1.7309  decode.d6.loss_mask: 0.7656  decode.d6.loss_dice: 0.6644  decode.d7.loss_cls: 1.7481  decode.d7.loss_mask: 0.7547  decode.d7.loss_dice: 0.6819  decode.d8.loss_cls: 1.7492  decode.d8.loss_mask: 0.7093  decode.d8.loss_dice: 0.6418
09/30 09:10:03 - mmengine - INFO - Iter(train) [   950/320000]  base_lr: 9.9733e-05 lr: 9.9733e-06  eta: 1 day, 15:13:19  time: 0.4306  data_time: 0.0088  memory: 5147  grad_norm: 214.8063  loss: 22.8621  decode.loss_cls: 1.1491  decode.loss_mask: 0.4362  decode.loss_dice: 0.3738  decode.d0.loss_cls: 4.7073  decode.d0.loss_mask: 0.4782  decode.d0.loss_dice: 0.4301  decode.d1.loss_cls: 1.0651  decode.d1.loss_mask: 0.4849  decode.d1.loss_dice: 0.4578  decode.d2.loss_cls: 1.0537  decode.d2.loss_mask: 0.4213  decode.d2.loss_dice: 0.4044  decode.d3.loss_cls: 1.0472  decode.d3.loss_mask: 0.4677  decode.d3.loss_dice: 0.3842  decode.d4.loss_cls: 1.1313  decode.d4.loss_mask: 0.4018  decode.d4.loss_dice: 0.3513  decode.d5.loss_cls: 1.0923  decode.d5.loss_mask: 0.3951  decode.d5.loss_dice: 0.3693  decode.d6.loss_cls: 1.0990  decode.d6.loss_mask: 0.4144  decode.d6.loss_dice: 0.3718  decode.d7.loss_cls: 1.0857  decode.d7.loss_mask: 0.4547  decode.d7.loss_dice: 0.3854  decode.d8.loss_cls: 1.0781  decode.d8.loss_mask: 0.4642  decode.d8.loss_dice: 0.4067
09/30 09:10:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:10:25 - mmengine - INFO - Iter(train) [  1000/320000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 1 day, 15:09:50  time: 0.4303  data_time: 0.0086  memory: 5161  grad_norm: 336.8786  loss: 28.1618  decode.loss_cls: 1.1706  decode.loss_mask: 0.6384  decode.loss_dice: 0.5050  decode.d0.loss_cls: 4.6388  decode.d0.loss_mask: 0.6560  decode.d0.loss_dice: 0.6066  decode.d1.loss_cls: 1.3915  decode.d1.loss_mask: 0.6107  decode.d1.loss_dice: 0.5162  decode.d2.loss_cls: 1.3522  decode.d2.loss_mask: 0.6604  decode.d2.loss_dice: 0.5263  decode.d3.loss_cls: 1.3049  decode.d3.loss_mask: 0.6641  decode.d3.loss_dice: 0.5167  decode.d4.loss_cls: 1.2725  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 0.5157  decode.d5.loss_cls: 1.2180  decode.d5.loss_mask: 0.7515  decode.d5.loss_dice: 0.5440  decode.d6.loss_cls: 1.1618  decode.d6.loss_mask: 0.7853  decode.d6.loss_dice: 0.5493  decode.d7.loss_cls: 1.1884  decode.d7.loss_mask: 0.7277  decode.d7.loss_dice: 0.5184  decode.d8.loss_cls: 1.2414  decode.d8.loss_mask: 0.7504  decode.d8.loss_dice: 0.5322
09/30 09:10:46 - mmengine - INFO - Iter(train) [  1050/320000]  base_lr: 9.9705e-05 lr: 9.9705e-06  eta: 1 day, 15:06:21  time: 0.4294  data_time: 0.0083  memory: 5147  grad_norm: 130.2090  loss: 23.3844  decode.loss_cls: 1.3547  decode.loss_mask: 0.3082  decode.loss_dice: 0.3430  decode.d0.loss_cls: 4.4466  decode.d0.loss_mask: 0.2979  decode.d0.loss_dice: 0.4033  decode.d1.loss_cls: 1.4431  decode.d1.loss_mask: 0.2737  decode.d1.loss_dice: 0.3011  decode.d2.loss_cls: 1.4890  decode.d2.loss_mask: 0.2741  decode.d2.loss_dice: 0.3003  decode.d3.loss_cls: 1.4738  decode.d3.loss_mask: 0.2806  decode.d3.loss_dice: 0.2860  decode.d4.loss_cls: 1.4666  decode.d4.loss_mask: 0.2828  decode.d4.loss_dice: 0.2948  decode.d5.loss_cls: 1.4615  decode.d5.loss_mask: 0.2763  decode.d5.loss_dice: 0.3125  decode.d6.loss_cls: 1.4079  decode.d6.loss_mask: 0.2721  decode.d6.loss_dice: 0.3074  decode.d7.loss_cls: 1.4508  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.2970  decode.d8.loss_cls: 1.4172  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.2887
09/30 09:11:08 - mmengine - INFO - Iter(train) [  1100/320000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 1 day, 15:03:26  time: 0.4318  data_time: 0.0085  memory: 5180  grad_norm: 244.5338  loss: 22.1340  decode.loss_cls: 1.2458  decode.loss_mask: 0.3763  decode.loss_dice: 0.3222  decode.d0.loss_cls: 4.1368  decode.d0.loss_mask: 0.3752  decode.d0.loss_dice: 0.4519  decode.d1.loss_cls: 1.2553  decode.d1.loss_mask: 0.3603  decode.d1.loss_dice: 0.3242  decode.d2.loss_cls: 1.1924  decode.d2.loss_mask: 0.3661  decode.d2.loss_dice: 0.3380  decode.d3.loss_cls: 1.2040  decode.d3.loss_mask: 0.3592  decode.d3.loss_dice: 0.3273  decode.d4.loss_cls: 1.1963  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.3141  decode.d5.loss_cls: 1.1928  decode.d5.loss_mask: 0.3545  decode.d5.loss_dice: 0.3399  decode.d6.loss_cls: 1.1893  decode.d6.loss_mask: 0.3732  decode.d6.loss_dice: 0.3389  decode.d7.loss_cls: 1.1881  decode.d7.loss_mask: 0.3640  decode.d7.loss_dice: 0.3324  decode.d8.loss_cls: 1.2288  decode.d8.loss_mask: 0.3781  decode.d8.loss_dice: 0.3404
09/30 09:11:29 - mmengine - INFO - Iter(train) [  1150/320000]  base_lr: 9.9677e-05 lr: 9.9677e-06  eta: 1 day, 15:00:32  time: 0.4305  data_time: 0.0087  memory: 5180  grad_norm: 159.8827  loss: 25.6956  decode.loss_cls: 1.3478  decode.loss_mask: 0.5075  decode.loss_dice: 0.4674  decode.d0.loss_cls: 3.9894  decode.d0.loss_mask: 0.4555  decode.d0.loss_dice: 0.5395  decode.d1.loss_cls: 1.3835  decode.d1.loss_mask: 0.4605  decode.d1.loss_dice: 0.4703  decode.d2.loss_cls: 1.4065  decode.d2.loss_mask: 0.4270  decode.d2.loss_dice: 0.4705  decode.d3.loss_cls: 1.4069  decode.d3.loss_mask: 0.4417  decode.d3.loss_dice: 0.4615  decode.d4.loss_cls: 1.4247  decode.d4.loss_mask: 0.4461  decode.d4.loss_dice: 0.4642  decode.d5.loss_cls: 1.3243  decode.d5.loss_mask: 0.4529  decode.d5.loss_dice: 0.4543  decode.d6.loss_cls: 1.4447  decode.d6.loss_mask: 0.4445  decode.d6.loss_dice: 0.4374  decode.d7.loss_cls: 1.3774  decode.d7.loss_mask: 0.4458  decode.d7.loss_dice: 0.4738  decode.d8.loss_cls: 1.3088  decode.d8.loss_mask: 0.4663  decode.d8.loss_dice: 0.4951
09/30 09:11:51 - mmengine - INFO - Iter(train) [  1200/320000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 1 day, 14:58:07  time: 0.4307  data_time: 0.0085  memory: 5161  grad_norm: 155.1869  loss: 26.2555  decode.loss_cls: 1.4181  decode.loss_mask: 0.5602  decode.loss_dice: 0.4664  decode.d0.loss_cls: 3.9348  decode.d0.loss_mask: 0.4865  decode.d0.loss_dice: 0.5092  decode.d1.loss_cls: 1.4474  decode.d1.loss_mask: 0.4602  decode.d1.loss_dice: 0.4517  decode.d2.loss_cls: 1.3228  decode.d2.loss_mask: 0.5203  decode.d2.loss_dice: 0.4639  decode.d3.loss_cls: 1.3107  decode.d3.loss_mask: 0.4862  decode.d3.loss_dice: 0.4922  decode.d4.loss_cls: 1.3901  decode.d4.loss_mask: 0.5229  decode.d4.loss_dice: 0.4469  decode.d5.loss_cls: 1.4325  decode.d5.loss_mask: 0.4966  decode.d5.loss_dice: 0.4866  decode.d6.loss_cls: 1.4228  decode.d6.loss_mask: 0.5299  decode.d6.loss_dice: 0.4316  decode.d7.loss_cls: 1.3555  decode.d7.loss_mask: 0.5476  decode.d7.loss_dice: 0.4609  decode.d8.loss_cls: 1.3552  decode.d8.loss_mask: 0.5630  decode.d8.loss_dice: 0.4828
09/30 09:12:12 - mmengine - INFO - Iter(train) [  1250/320000]  base_lr: 9.9649e-05 lr: 9.9649e-06  eta: 1 day, 14:56:35  time: 0.4304  data_time: 0.0085  memory: 5161  grad_norm: 174.7964  loss: 21.4766  decode.loss_cls: 1.0223  decode.loss_mask: 0.4931  decode.loss_dice: 0.3838  decode.d0.loss_cls: 3.5046  decode.d0.loss_mask: 0.5025  decode.d0.loss_dice: 0.4336  decode.d1.loss_cls: 1.1802  decode.d1.loss_mask: 0.4554  decode.d1.loss_dice: 0.3798  decode.d2.loss_cls: 1.1416  decode.d2.loss_mask: 0.4284  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 1.1400  decode.d3.loss_mask: 0.4064  decode.d3.loss_dice: 0.3521  decode.d4.loss_cls: 1.1222  decode.d4.loss_mask: 0.4091  decode.d4.loss_dice: 0.3470  decode.d5.loss_cls: 1.0851  decode.d5.loss_mask: 0.3924  decode.d5.loss_dice: 0.3596  decode.d6.loss_cls: 1.0772  decode.d6.loss_mask: 0.4384  decode.d6.loss_dice: 0.3255  decode.d7.loss_cls: 1.0386  decode.d7.loss_mask: 0.4394  decode.d7.loss_dice: 0.3512  decode.d8.loss_cls: 1.0115  decode.d8.loss_mask: 0.4907  decode.d8.loss_dice: 0.3946
09/30 09:12:34 - mmengine - INFO - Iter(train) [  1300/320000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 1 day, 14:54:24  time: 0.4315  data_time: 0.0085  memory: 5160  grad_norm: 251.1737  loss: 23.1797  decode.loss_cls: 1.1840  decode.loss_mask: 0.4410  decode.loss_dice: 0.4181  decode.d0.loss_cls: 3.3655  decode.d0.loss_mask: 0.4311  decode.d0.loss_dice: 0.4943  decode.d1.loss_cls: 1.2617  decode.d1.loss_mask: 0.4342  decode.d1.loss_dice: 0.4353  decode.d2.loss_cls: 1.2541  decode.d2.loss_mask: 0.4703  decode.d2.loss_dice: 0.4108  decode.d3.loss_cls: 1.2281  decode.d3.loss_mask: 0.4898  decode.d3.loss_dice: 0.4189  decode.d4.loss_cls: 1.2369  decode.d4.loss_mask: 0.4829  decode.d4.loss_dice: 0.4122  decode.d5.loss_cls: 1.2462  decode.d5.loss_mask: 0.4359  decode.d5.loss_dice: 0.4084  decode.d6.loss_cls: 1.2028  decode.d6.loss_mask: 0.4493  decode.d6.loss_dice: 0.4109  decode.d7.loss_cls: 1.2167  decode.d7.loss_mask: 0.4578  decode.d7.loss_dice: 0.4429  decode.d8.loss_cls: 1.1986  decode.d8.loss_mask: 0.4429  decode.d8.loss_dice: 0.3982
09/30 09:12:56 - mmengine - INFO - Iter(train) [  1350/320000]  base_lr: 9.9621e-05 lr: 9.9621e-06  eta: 1 day, 14:52:25  time: 0.4323  data_time: 0.0089  memory: 5161  grad_norm: 234.0474  loss: 21.5285  decode.loss_cls: 1.0573  decode.loss_mask: 0.5094  decode.loss_dice: 0.3517  decode.d0.loss_cls: 3.1100  decode.d0.loss_mask: 0.5016  decode.d0.loss_dice: 0.4306  decode.d1.loss_cls: 1.1234  decode.d1.loss_mask: 0.4811  decode.d1.loss_dice: 0.3771  decode.d2.loss_cls: 1.1221  decode.d2.loss_mask: 0.4784  decode.d2.loss_dice: 0.3697  decode.d3.loss_cls: 1.0428  decode.d3.loss_mask: 0.4914  decode.d3.loss_dice: 0.3612  decode.d4.loss_cls: 1.0913  decode.d4.loss_mask: 0.4987  decode.d4.loss_dice: 0.3578  decode.d5.loss_cls: 1.0472  decode.d5.loss_mask: 0.5162  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 1.1007  decode.d6.loss_mask: 0.5506  decode.d6.loss_dice: 0.3702  decode.d7.loss_cls: 1.0690  decode.d7.loss_mask: 0.5232  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 1.0229  decode.d8.loss_mask: 0.4965  decode.d8.loss_dice: 0.3473
09/30 09:13:17 - mmengine - INFO - Iter(train) [  1400/320000]  base_lr: 9.9606e-05 lr: 9.9606e-06  eta: 1 day, 14:50:30  time: 0.4305  data_time: 0.0085  memory: 5145  grad_norm: 90.6035  loss: 18.9389  decode.loss_cls: 1.0073  decode.loss_mask: 0.2980  decode.loss_dice: 0.3355  decode.d0.loss_cls: 3.0657  decode.d0.loss_mask: 0.3022  decode.d0.loss_dice: 0.4212  decode.d1.loss_cls: 1.0742  decode.d1.loss_mask: 0.3032  decode.d1.loss_dice: 0.3689  decode.d2.loss_cls: 1.0875  decode.d2.loss_mask: 0.3038  decode.d2.loss_dice: 0.3392  decode.d3.loss_cls: 1.0612  decode.d3.loss_mask: 0.2934  decode.d3.loss_dice: 0.3391  decode.d4.loss_cls: 1.0534  decode.d4.loss_mask: 0.2951  decode.d4.loss_dice: 0.3161  decode.d5.loss_cls: 1.0381  decode.d5.loss_mask: 0.2925  decode.d5.loss_dice: 0.3433  decode.d6.loss_cls: 1.0386  decode.d6.loss_mask: 0.2918  decode.d6.loss_dice: 0.3327  decode.d7.loss_cls: 1.0464  decode.d7.loss_mask: 0.2909  decode.d7.loss_dice: 0.3362  decode.d8.loss_cls: 1.0382  decode.d8.loss_mask: 0.2941  decode.d8.loss_dice: 0.3313
09/30 09:13:39 - mmengine - INFO - Iter(train) [  1450/320000]  base_lr: 9.9592e-05 lr: 9.9592e-06  eta: 1 day, 14:48:37  time: 0.4316  data_time: 0.0089  memory: 5180  grad_norm: 218.8976  loss: 19.3898  decode.loss_cls: 0.8947  decode.loss_mask: 0.4152  decode.loss_dice: 0.3976  decode.d0.loss_cls: 2.6892  decode.d0.loss_mask: 0.4254  decode.d0.loss_dice: 0.4569  decode.d1.loss_cls: 1.0019  decode.d1.loss_mask: 0.4130  decode.d1.loss_dice: 0.4130  decode.d2.loss_cls: 0.9901  decode.d2.loss_mask: 0.4094  decode.d2.loss_dice: 0.3967  decode.d3.loss_cls: 0.9972  decode.d3.loss_mask: 0.4000  decode.d3.loss_dice: 0.3763  decode.d4.loss_cls: 0.8926  decode.d4.loss_mask: 0.4313  decode.d4.loss_dice: 0.3988  decode.d5.loss_cls: 0.9217  decode.d5.loss_mask: 0.4078  decode.d5.loss_dice: 0.3912  decode.d6.loss_cls: 0.9330  decode.d6.loss_mask: 0.4017  decode.d6.loss_dice: 0.4015  decode.d7.loss_cls: 0.9564  decode.d7.loss_mask: 0.4103  decode.d7.loss_dice: 0.4257  decode.d8.loss_cls: 0.9312  decode.d8.loss_mask: 0.4094  decode.d8.loss_dice: 0.4009
09/30 09:14:00 - mmengine - INFO - Iter(train) [  1500/320000]  base_lr: 9.9578e-05 lr: 9.9578e-06  eta: 1 day, 14:46:57  time: 0.4305  data_time: 0.0084  memory: 5161  grad_norm: 159.9188  loss: 19.6597  decode.loss_cls: 1.0474  decode.loss_mask: 0.3934  decode.loss_dice: 0.3462  decode.d0.loss_cls: 2.7881  decode.d0.loss_mask: 0.4303  decode.d0.loss_dice: 0.4083  decode.d1.loss_cls: 1.0800  decode.d1.loss_mask: 0.3833  decode.d1.loss_dice: 0.3489  decode.d2.loss_cls: 1.1072  decode.d2.loss_mask: 0.3719  decode.d2.loss_dice: 0.3239  decode.d3.loss_cls: 1.0343  decode.d3.loss_mask: 0.3897  decode.d3.loss_dice: 0.3221  decode.d4.loss_cls: 1.0265  decode.d4.loss_mask: 0.4120  decode.d4.loss_dice: 0.3733  decode.d5.loss_cls: 1.0579  decode.d5.loss_mask: 0.3853  decode.d5.loss_dice: 0.3277  decode.d6.loss_cls: 1.1028  decode.d6.loss_mask: 0.3752  decode.d6.loss_dice: 0.3335  decode.d7.loss_cls: 0.9981  decode.d7.loss_mask: 0.3987  decode.d7.loss_dice: 0.3287  decode.d8.loss_cls: 1.0455  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.3387
09/30 09:14:22 - mmengine - INFO - Iter(train) [  1550/320000]  base_lr: 9.9564e-05 lr: 9.9564e-06  eta: 1 day, 14:45:19  time: 0.4319  data_time: 0.0089  memory: 5161  grad_norm: 148.5545  loss: 21.1039  decode.loss_cls: 1.0049  decode.loss_mask: 0.4892  decode.loss_dice: 0.4058  decode.d0.loss_cls: 2.5754  decode.d0.loss_mask: 0.5132  decode.d0.loss_dice: 0.4620  decode.d1.loss_cls: 1.2428  decode.d1.loss_mask: 0.4844  decode.d1.loss_dice: 0.4166  decode.d2.loss_cls: 1.0691  decode.d2.loss_mask: 0.4832  decode.d2.loss_dice: 0.3761  decode.d3.loss_cls: 1.0298  decode.d3.loss_mask: 0.5156  decode.d3.loss_dice: 0.3924  decode.d4.loss_cls: 1.0203  decode.d4.loss_mask: 0.5010  decode.d4.loss_dice: 0.3843  decode.d5.loss_cls: 1.0019  decode.d5.loss_mask: 0.5185  decode.d5.loss_dice: 0.3994  decode.d6.loss_cls: 1.0435  decode.d6.loss_mask: 0.5011  decode.d6.loss_dice: 0.3852  decode.d7.loss_cls: 1.0448  decode.d7.loss_mask: 0.4932  decode.d7.loss_dice: 0.4066  decode.d8.loss_cls: 1.0384  decode.d8.loss_mask: 0.4975  decode.d8.loss_dice: 0.4079
09/30 09:14:43 - mmengine - INFO - Iter(train) [  1600/320000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 1 day, 14:43:44  time: 0.4298  data_time: 0.0086  memory: 5180  grad_norm: 126.3025  loss: 17.7679  decode.loss_cls: 0.8088  decode.loss_mask: 0.4503  decode.loss_dice: 0.3900  decode.d0.loss_cls: 2.2760  decode.d0.loss_mask: 0.4363  decode.d0.loss_dice: 0.4153  decode.d1.loss_cls: 0.8837  decode.d1.loss_mask: 0.4323  decode.d1.loss_dice: 0.3820  decode.d2.loss_cls: 0.8830  decode.d2.loss_mask: 0.4524  decode.d2.loss_dice: 0.3691  decode.d3.loss_cls: 0.8252  decode.d3.loss_mask: 0.4647  decode.d3.loss_dice: 0.3526  decode.d4.loss_cls: 0.7700  decode.d4.loss_mask: 0.4498  decode.d4.loss_dice: 0.3672  decode.d5.loss_cls: 0.7364  decode.d5.loss_mask: 0.4670  decode.d5.loss_dice: 0.3726  decode.d6.loss_cls: 0.7504  decode.d6.loss_mask: 0.4593  decode.d6.loss_dice: 0.3767  decode.d7.loss_cls: 0.7654  decode.d7.loss_mask: 0.4467  decode.d7.loss_dice: 0.3716  decode.d8.loss_cls: 0.7817  decode.d8.loss_mask: 0.4544  decode.d8.loss_dice: 0.3771
09/30 09:15:05 - mmengine - INFO - Iter(train) [  1650/320000]  base_lr: 9.9536e-05 lr: 9.9536e-06  eta: 1 day, 14:42:12  time: 0.4317  data_time: 0.0088  memory: 5160  grad_norm: 188.6059  loss: 17.3146  decode.loss_cls: 0.7909  decode.loss_mask: 0.4587  decode.loss_dice: 0.3614  decode.d0.loss_cls: 2.3173  decode.d0.loss_mask: 0.4395  decode.d0.loss_dice: 0.4032  decode.d1.loss_cls: 0.8942  decode.d1.loss_mask: 0.4106  decode.d1.loss_dice: 0.3224  decode.d2.loss_cls: 0.8043  decode.d2.loss_mask: 0.4062  decode.d2.loss_dice: 0.3140  decode.d3.loss_cls: 0.7773  decode.d3.loss_mask: 0.4175  decode.d3.loss_dice: 0.3175  decode.d4.loss_cls: 0.7868  decode.d4.loss_mask: 0.4094  decode.d4.loss_dice: 0.3295  decode.d5.loss_cls: 0.7539  decode.d5.loss_mask: 0.4210  decode.d5.loss_dice: 0.3338  decode.d6.loss_cls: 0.8077  decode.d6.loss_mask: 0.4123  decode.d6.loss_dice: 0.3441  decode.d7.loss_cls: 0.8296  decode.d7.loss_mask: 0.4240  decode.d7.loss_dice: 0.3497  decode.d8.loss_cls: 0.7916  decode.d8.loss_mask: 0.4800  decode.d8.loss_dice: 0.4064
09/30 09:15:26 - mmengine - INFO - Iter(train) [  1700/320000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 1 day, 14:40:49  time: 0.4307  data_time: 0.0086  memory: 5160  grad_norm: 157.8234  loss: 14.9281  decode.loss_cls: 0.7987  decode.loss_mask: 0.2873  decode.loss_dice: 0.2143  decode.d0.loss_cls: 2.2569  decode.d0.loss_mask: 0.2809  decode.d0.loss_dice: 0.2713  decode.d1.loss_cls: 0.9191  decode.d1.loss_mask: 0.2925  decode.d1.loss_dice: 0.2206  decode.d2.loss_cls: 0.8630  decode.d2.loss_mask: 0.2896  decode.d2.loss_dice: 0.2151  decode.d3.loss_cls: 0.8694  decode.d3.loss_mask: 0.2821  decode.d3.loss_dice: 0.2051  decode.d4.loss_cls: 0.8475  decode.d4.loss_mask: 0.2978  decode.d4.loss_dice: 0.2113  decode.d5.loss_cls: 0.8314  decode.d5.loss_mask: 0.2898  decode.d5.loss_dice: 0.2090  decode.d6.loss_cls: 0.8190  decode.d6.loss_mask: 0.2904  decode.d6.loss_dice: 0.2103  decode.d7.loss_cls: 0.8598  decode.d7.loss_mask: 0.2876  decode.d7.loss_dice: 0.2070  decode.d8.loss_cls: 0.7821  decode.d8.loss_mask: 0.2933  decode.d8.loss_dice: 0.2260
09/30 09:15:48 - mmengine - INFO - Iter(train) [  1750/320000]  base_lr: 9.9508e-05 lr: 9.9508e-06  eta: 1 day, 14:39:29  time: 0.4323  data_time: 0.0089  memory: 5161  grad_norm: 270.4349  loss: 18.5486  decode.loss_cls: 0.9499  decode.loss_mask: 0.4457  decode.loss_dice: 0.3576  decode.d0.loss_cls: 2.0787  decode.d0.loss_mask: 0.4245  decode.d0.loss_dice: 0.3706  decode.d1.loss_cls: 0.9982  decode.d1.loss_mask: 0.4016  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.9423  decode.d2.loss_mask: 0.3929  decode.d2.loss_dice: 0.3451  decode.d3.loss_cls: 0.9562  decode.d3.loss_mask: 0.4091  decode.d3.loss_dice: 0.3795  decode.d4.loss_cls: 1.0016  decode.d4.loss_mask: 0.4197  decode.d4.loss_dice: 0.3618  decode.d5.loss_cls: 1.0154  decode.d5.loss_mask: 0.3777  decode.d5.loss_dice: 0.3711  decode.d6.loss_cls: 0.9416  decode.d6.loss_mask: 0.4249  decode.d6.loss_dice: 0.3678  decode.d7.loss_cls: 0.9415  decode.d7.loss_mask: 0.4204  decode.d7.loss_dice: 0.3661  decode.d8.loss_cls: 0.9441  decode.d8.loss_mask: 0.4323  decode.d8.loss_dice: 0.3573
09/30 09:16:09 - mmengine - INFO - Iter(train) [  1800/320000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 1 day, 14:38:10  time: 0.4308  data_time: 0.0087  memory: 5160  grad_norm: 181.4968  loss: 21.3530  decode.loss_cls: 1.0269  decode.loss_mask: 0.4662  decode.loss_dice: 0.4339  decode.d0.loss_cls: 2.1027  decode.d0.loss_mask: 0.4902  decode.d0.loss_dice: 0.5710  decode.d1.loss_cls: 1.2998  decode.d1.loss_mask: 0.4326  decode.d1.loss_dice: 0.4443  decode.d2.loss_cls: 1.1526  decode.d2.loss_mask: 0.4577  decode.d2.loss_dice: 0.4632  decode.d3.loss_cls: 1.0802  decode.d3.loss_mask: 0.4992  decode.d3.loss_dice: 0.4392  decode.d4.loss_cls: 1.0070  decode.d4.loss_mask: 0.5065  decode.d4.loss_dice: 0.4559  decode.d5.loss_cls: 1.0764  decode.d5.loss_mask: 0.4727  decode.d5.loss_dice: 0.4286  decode.d6.loss_cls: 1.1270  decode.d6.loss_mask: 0.4712  decode.d6.loss_dice: 0.4623  decode.d7.loss_cls: 1.0655  decode.d7.loss_mask: 0.5055  decode.d7.loss_dice: 0.4467  decode.d8.loss_cls: 1.0351  decode.d8.loss_mask: 0.4605  decode.d8.loss_dice: 0.4721
09/30 09:16:31 - mmengine - INFO - Iter(train) [  1850/320000]  base_lr: 9.9480e-05 lr: 9.9480e-06  eta: 1 day, 14:37:01  time: 0.4317  data_time: 0.0087  memory: 5161  grad_norm: 219.4772  loss: 22.5704  decode.loss_cls: 1.0285  decode.loss_mask: 0.5765  decode.loss_dice: 0.5572  decode.d0.loss_cls: 1.9966  decode.d0.loss_mask: 0.5705  decode.d0.loss_dice: 0.5577  decode.d1.loss_cls: 1.0093  decode.d1.loss_mask: 0.5501  decode.d1.loss_dice: 0.5750  decode.d2.loss_cls: 0.9736  decode.d2.loss_mask: 0.5491  decode.d2.loss_dice: 0.6327  decode.d3.loss_cls: 1.0136  decode.d3.loss_mask: 0.5108  decode.d3.loss_dice: 0.5236  decode.d4.loss_cls: 1.0739  decode.d4.loss_mask: 0.5019  decode.d4.loss_dice: 0.5631  decode.d5.loss_cls: 1.0561  decode.d5.loss_mask: 0.5409  decode.d5.loss_dice: 0.5414  decode.d6.loss_cls: 1.1098  decode.d6.loss_mask: 0.5593  decode.d6.loss_dice: 0.5620  decode.d7.loss_cls: 1.0015  decode.d7.loss_mask: 0.6119  decode.d7.loss_dice: 0.5873  decode.d8.loss_cls: 1.0762  decode.d8.loss_mask: 0.5923  decode.d8.loss_dice: 0.5676
09/30 09:16:53 - mmengine - INFO - Iter(train) [  1900/320000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 1 day, 14:35:44  time: 0.4310  data_time: 0.0087  memory: 5147  grad_norm: 223.1594  loss: 20.2108  decode.loss_cls: 0.9577  decode.loss_mask: 0.4589  decode.loss_dice: 0.5090  decode.d0.loss_cls: 1.8702  decode.d0.loss_mask: 0.4691  decode.d0.loss_dice: 0.4704  decode.d1.loss_cls: 1.1243  decode.d1.loss_mask: 0.4687  decode.d1.loss_dice: 0.4321  decode.d2.loss_cls: 0.9590  decode.d2.loss_mask: 0.5269  decode.d2.loss_dice: 0.4361  decode.d3.loss_cls: 0.9333  decode.d3.loss_mask: 0.4750  decode.d3.loss_dice: 0.4486  decode.d4.loss_cls: 0.9542  decode.d4.loss_mask: 0.5130  decode.d4.loss_dice: 0.4810  decode.d5.loss_cls: 0.9379  decode.d5.loss_mask: 0.4799  decode.d5.loss_dice: 0.4415  decode.d6.loss_cls: 0.9376  decode.d6.loss_mask: 0.5213  decode.d6.loss_dice: 0.4440  decode.d7.loss_cls: 0.9815  decode.d7.loss_mask: 0.4962  decode.d7.loss_dice: 0.4784  decode.d8.loss_cls: 0.9931  decode.d8.loss_mask: 0.5009  decode.d8.loss_dice: 0.5111
09/30 09:17:14 - mmengine - INFO - Iter(train) [  1950/320000]  base_lr: 9.9452e-05 lr: 9.9452e-06  eta: 1 day, 14:34:36  time: 0.4307  data_time: 0.0085  memory: 5147  grad_norm: 148.4679  loss: 14.7008  decode.loss_cls: 0.6006  decode.loss_mask: 0.4277  decode.loss_dice: 0.3745  decode.d0.loss_cls: 1.7085  decode.d0.loss_mask: 0.3254  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.8238  decode.d1.loss_mask: 0.3050  decode.d1.loss_dice: 0.3303  decode.d2.loss_cls: 0.6686  decode.d2.loss_mask: 0.3112  decode.d2.loss_dice: 0.3621  decode.d3.loss_cls: 0.6425  decode.d3.loss_mask: 0.3412  decode.d3.loss_dice: 0.3731  decode.d4.loss_cls: 0.5893  decode.d4.loss_mask: 0.3315  decode.d4.loss_dice: 0.3810  decode.d5.loss_cls: 0.5502  decode.d5.loss_mask: 0.4299  decode.d5.loss_dice: 0.3770  decode.d6.loss_cls: 0.6081  decode.d6.loss_mask: 0.3838  decode.d6.loss_dice: 0.3796  decode.d7.loss_cls: 0.5501  decode.d7.loss_mask: 0.4192  decode.d7.loss_dice: 0.3976  decode.d8.loss_cls: 0.5847  decode.d8.loss_mask: 0.3902  decode.d8.loss_dice: 0.3935
09/30 09:17:36 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:17:36 - mmengine - INFO - Iter(train) [  2000/320000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 1 day, 14:33:29  time: 0.4322  data_time: 0.0088  memory: 5180  grad_norm: 147.8422  loss: 17.9068  decode.loss_cls: 0.8934  decode.loss_mask: 0.3821  decode.loss_dice: 0.3914  decode.d0.loss_cls: 1.8384  decode.d0.loss_mask: 0.4155  decode.d0.loss_dice: 0.4464  decode.d1.loss_cls: 1.1023  decode.d1.loss_mask: 0.3822  decode.d1.loss_dice: 0.4057  decode.d2.loss_cls: 0.9430  decode.d2.loss_mask: 0.3876  decode.d2.loss_dice: 0.4069  decode.d3.loss_cls: 0.9029  decode.d3.loss_mask: 0.3767  decode.d3.loss_dice: 0.3919  decode.d4.loss_cls: 0.8856  decode.d4.loss_mask: 0.3707  decode.d4.loss_dice: 0.3769  decode.d5.loss_cls: 0.8558  decode.d5.loss_mask: 0.3726  decode.d5.loss_dice: 0.3887  decode.d6.loss_cls: 0.8810  decode.d6.loss_mask: 0.3714  decode.d6.loss_dice: 0.3834  decode.d7.loss_cls: 0.9170  decode.d7.loss_mask: 0.3665  decode.d7.loss_dice: 0.3938  decode.d8.loss_cls: 0.9057  decode.d8.loss_mask: 0.3698  decode.d8.loss_dice: 0.4013
09/30 09:17:57 - mmengine - INFO - Iter(train) [  2050/320000]  base_lr: 9.9424e-05 lr: 9.9424e-06  eta: 1 day, 14:32:22  time: 0.4307  data_time: 0.0085  memory: 5145  grad_norm: 164.1092  loss: 15.0943  decode.loss_cls: 0.6826  decode.loss_mask: 0.3982  decode.loss_dice: 0.3368  decode.d0.loss_cls: 1.6895  decode.d0.loss_mask: 0.3861  decode.d0.loss_dice: 0.3678  decode.d1.loss_cls: 0.8001  decode.d1.loss_mask: 0.3791  decode.d1.loss_dice: 0.3224  decode.d2.loss_cls: 0.6949  decode.d2.loss_mask: 0.3744  decode.d2.loss_dice: 0.3319  decode.d3.loss_cls: 0.7346  decode.d3.loss_mask: 0.4111  decode.d3.loss_dice: 0.3238  decode.d4.loss_cls: 0.7341  decode.d4.loss_mask: 0.3661  decode.d4.loss_dice: 0.3245  decode.d5.loss_cls: 0.6950  decode.d5.loss_mask: 0.3752  decode.d5.loss_dice: 0.3108  decode.d6.loss_cls: 0.6530  decode.d6.loss_mask: 0.3778  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.6299  decode.d7.loss_mask: 0.3840  decode.d7.loss_dice: 0.3275  decode.d8.loss_cls: 0.6543  decode.d8.loss_mask: 0.3861  decode.d8.loss_dice: 0.3246
09/30 09:18:19 - mmengine - INFO - Iter(train) [  2100/320000]  base_lr: 9.9409e-05 lr: 9.9409e-06  eta: 1 day, 14:31:18  time: 0.4309  data_time: 0.0088  memory: 5161  grad_norm: 392.2454  loss: 25.3525  decode.loss_cls: 0.9925  decode.loss_mask: 0.7570  decode.loss_dice: 0.5419  decode.d0.loss_cls: 1.8571  decode.d0.loss_mask: 0.7220  decode.d0.loss_dice: 0.6087  decode.d1.loss_cls: 1.2451  decode.d1.loss_mask: 0.7441  decode.d1.loss_dice: 0.5832  decode.d2.loss_cls: 1.2151  decode.d2.loss_mask: 0.6988  decode.d2.loss_dice: 0.5184  decode.d3.loss_cls: 1.1494  decode.d3.loss_mask: 0.7838  decode.d3.loss_dice: 0.5812  decode.d4.loss_cls: 1.1533  decode.d4.loss_mask: 0.7962  decode.d4.loss_dice: 0.5570  decode.d5.loss_cls: 1.0854  decode.d5.loss_mask: 0.7322  decode.d5.loss_dice: 0.5284  decode.d6.loss_cls: 1.1447  decode.d6.loss_mask: 0.7561  decode.d6.loss_dice: 0.5446  decode.d7.loss_cls: 1.1895  decode.d7.loss_mask: 0.7981  decode.d7.loss_dice: 0.5908  decode.d8.loss_cls: 1.1045  decode.d8.loss_mask: 0.7979  decode.d8.loss_dice: 0.5757
09/30 09:18:40 - mmengine - INFO - Iter(train) [  2150/320000]  base_lr: 9.9395e-05 lr: 9.9395e-06  eta: 1 day, 14:30:17  time: 0.4296  data_time: 0.0091  memory: 5161  grad_norm: 289.5546  loss: 17.1674  decode.loss_cls: 0.7574  decode.loss_mask: 0.4786  decode.loss_dice: 0.3703  decode.d0.loss_cls: 1.5208  decode.d0.loss_mask: 0.4819  decode.d0.loss_dice: 0.4565  decode.d1.loss_cls: 0.8529  decode.d1.loss_mask: 0.5198  decode.d1.loss_dice: 0.4046  decode.d2.loss_cls: 0.8071  decode.d2.loss_mask: 0.5042  decode.d2.loss_dice: 0.3887  decode.d3.loss_cls: 0.7200  decode.d3.loss_mask: 0.4748  decode.d3.loss_dice: 0.3611  decode.d4.loss_cls: 0.7578  decode.d4.loss_mask: 0.4937  decode.d4.loss_dice: 0.3493  decode.d5.loss_cls: 0.6985  decode.d5.loss_mask: 0.5023  decode.d5.loss_dice: 0.4000  decode.d6.loss_cls: 0.7039  decode.d6.loss_mask: 0.4778  decode.d6.loss_dice: 0.3853  decode.d7.loss_cls: 0.7305  decode.d7.loss_mask: 0.4906  decode.d7.loss_dice: 0.3981  decode.d8.loss_cls: 0.7970  decode.d8.loss_mask: 0.4873  decode.d8.loss_dice: 0.3968
09/30 09:19:02 - mmengine - INFO - Iter(train) [  2200/320000]  base_lr: 9.9381e-05 lr: 9.9381e-06  eta: 1 day, 14:29:16  time: 0.4307  data_time: 0.0087  memory: 5180  grad_norm: 163.6394  loss: 21.9664  decode.loss_cls: 1.1622  decode.loss_mask: 0.4620  decode.loss_dice: 0.4965  decode.d0.loss_cls: 1.8580  decode.d0.loss_mask: 0.4193  decode.d0.loss_dice: 0.6089  decode.d1.loss_cls: 1.4065  decode.d1.loss_mask: 0.3652  decode.d1.loss_dice: 0.4887  decode.d2.loss_cls: 1.2270  decode.d2.loss_mask: 0.3449  decode.d2.loss_dice: 0.4656  decode.d3.loss_cls: 1.2129  decode.d3.loss_mask: 0.3454  decode.d3.loss_dice: 0.4716  decode.d4.loss_cls: 1.1856  decode.d4.loss_mask: 0.4266  decode.d4.loss_dice: 0.4823  decode.d5.loss_cls: 1.1919  decode.d5.loss_mask: 0.4385  decode.d5.loss_dice: 0.5234  decode.d6.loss_cls: 1.1976  decode.d6.loss_mask: 0.4543  decode.d6.loss_dice: 0.4991  decode.d7.loss_cls: 1.0976  decode.d7.loss_mask: 0.5052  decode.d7.loss_dice: 0.5037  decode.d8.loss_cls: 1.1720  decode.d8.loss_mask: 0.4422  decode.d8.loss_dice: 0.5118
09/30 09:19:23 - mmengine - INFO - Iter(train) [  2250/320000]  base_lr: 9.9367e-05 lr: 9.9367e-06  eta: 1 day, 14:28:16  time: 0.4313  data_time: 0.0090  memory: 5161  grad_norm: 192.5000  loss: 16.6393  decode.loss_cls: 0.7825  decode.loss_mask: 0.3988  decode.loss_dice: 0.3263  decode.d0.loss_cls: 1.6377  decode.d0.loss_mask: 0.4043  decode.d0.loss_dice: 0.3383  decode.d1.loss_cls: 0.8570  decode.d1.loss_mask: 0.4086  decode.d1.loss_dice: 0.3066  decode.d2.loss_cls: 0.8779  decode.d2.loss_mask: 0.3765  decode.d2.loss_dice: 0.3073  decode.d3.loss_cls: 0.8741  decode.d3.loss_mask: 0.3930  decode.d3.loss_dice: 0.3062  decode.d4.loss_cls: 0.8837  decode.d4.loss_mask: 0.4705  decode.d4.loss_dice: 0.3309  decode.d5.loss_cls: 0.8693  decode.d5.loss_mask: 0.4422  decode.d5.loss_dice: 0.3112  decode.d6.loss_cls: 0.8531  decode.d6.loss_mask: 0.4577  decode.d6.loss_dice: 0.3183  decode.d7.loss_cls: 0.8388  decode.d7.loss_mask: 0.3832  decode.d7.loss_dice: 0.3306  decode.d8.loss_cls: 0.8707  decode.d8.loss_mask: 0.3672  decode.d8.loss_dice: 0.3170
09/30 09:19:45 - mmengine - INFO - Iter(train) [  2300/320000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 1 day, 14:27:20  time: 0.4307  data_time: 0.0089  memory: 5147  grad_norm: 107.9415  loss: 13.7383  decode.loss_cls: 0.6514  decode.loss_mask: 0.2714  decode.loss_dice: 0.2937  decode.d0.loss_cls: 1.5390  decode.d0.loss_mask: 0.2735  decode.d0.loss_dice: 0.3445  decode.d1.loss_cls: 0.8448  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.3025  decode.d2.loss_cls: 0.6990  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2968  decode.d3.loss_cls: 0.6459  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.3155  decode.d4.loss_cls: 0.7535  decode.d4.loss_mask: 0.2768  decode.d4.loss_dice: 0.3218  decode.d5.loss_cls: 0.6632  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.3044  decode.d6.loss_cls: 0.6750  decode.d6.loss_mask: 0.3028  decode.d6.loss_dice: 0.3242  decode.d7.loss_cls: 0.6949  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.2985  decode.d8.loss_cls: 0.7008  decode.d8.loss_mask: 0.2810  decode.d8.loss_dice: 0.2924
09/30 09:20:06 - mmengine - INFO - Iter(train) [  2350/320000]  base_lr: 9.9339e-05 lr: 9.9339e-06  eta: 1 day, 14:26:25  time: 0.4307  data_time: 0.0087  memory: 5161  grad_norm: 78.7807  loss: 14.1038  decode.loss_cls: 0.8546  decode.loss_mask: 0.2434  decode.loss_dice: 0.2269  decode.d0.loss_cls: 1.6931  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.2660  decode.d1.loss_cls: 0.8760  decode.d1.loss_mask: 0.2455  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.8764  decode.d2.loss_mask: 0.2508  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.8637  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.2422  decode.d4.loss_cls: 0.8457  decode.d4.loss_mask: 0.2747  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.8225  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.2413  decode.d6.loss_cls: 0.8087  decode.d6.loss_mask: 0.2462  decode.d6.loss_dice: 0.2332  decode.d7.loss_cls: 0.7695  decode.d7.loss_mask: 0.2441  decode.d7.loss_dice: 0.2256  decode.d8.loss_cls: 0.7969  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.2245
09/30 09:20:28 - mmengine - INFO - Iter(train) [  2400/320000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 1 day, 14:25:32  time: 0.4307  data_time: 0.0091  memory: 5180  grad_norm: 310.1958  loss: 14.8891  decode.loss_cls: 0.6889  decode.loss_mask: 0.3366  decode.loss_dice: 0.3254  decode.d0.loss_cls: 1.4440  decode.d0.loss_mask: 0.3698  decode.d0.loss_dice: 0.2879  decode.d1.loss_cls: 0.8331  decode.d1.loss_mask: 0.3948  decode.d1.loss_dice: 0.2943  decode.d2.loss_cls: 0.7285  decode.d2.loss_mask: 0.4068  decode.d2.loss_dice: 0.3019  decode.d3.loss_cls: 0.7383  decode.d3.loss_mask: 0.3657  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.6975  decode.d4.loss_mask: 0.3698  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.7763  decode.d5.loss_mask: 0.3767  decode.d5.loss_dice: 0.2852  decode.d6.loss_cls: 0.7545  decode.d6.loss_mask: 0.3925  decode.d6.loss_dice: 0.3019  decode.d7.loss_cls: 0.7124  decode.d7.loss_mask: 0.3784  decode.d7.loss_dice: 0.3063  decode.d8.loss_cls: 0.7426  decode.d8.loss_mask: 0.4131  decode.d8.loss_dice: 0.3102
09/30 09:20:50 - mmengine - INFO - Iter(train) [  2450/320000]  base_lr: 9.9311e-05 lr: 9.9311e-06  eta: 1 day, 14:24:42  time: 0.4299  data_time: 0.0087  memory: 5161  grad_norm: 253.5415  loss: 18.5303  decode.loss_cls: 0.8192  decode.loss_mask: 0.5399  decode.loss_dice: 0.3993  decode.d0.loss_cls: 1.6067  decode.d0.loss_mask: 0.4953  decode.d0.loss_dice: 0.3796  decode.d1.loss_cls: 1.1049  decode.d1.loss_mask: 0.4695  decode.d1.loss_dice: 0.3315  decode.d2.loss_cls: 0.8736  decode.d2.loss_mask: 0.4773  decode.d2.loss_dice: 0.3663  decode.d3.loss_cls: 0.8369  decode.d3.loss_mask: 0.5731  decode.d3.loss_dice: 0.4099  decode.d4.loss_cls: 0.8536  decode.d4.loss_mask: 0.6039  decode.d4.loss_dice: 0.3829  decode.d5.loss_cls: 0.8017  decode.d5.loss_mask: 0.5155  decode.d5.loss_dice: 0.3679  decode.d6.loss_cls: 0.8278  decode.d6.loss_mask: 0.5356  decode.d6.loss_dice: 0.3976  decode.d7.loss_cls: 0.8030  decode.d7.loss_mask: 0.5603  decode.d7.loss_dice: 0.3906  decode.d8.loss_cls: 0.8249  decode.d8.loss_mask: 0.5717  decode.d8.loss_dice: 0.4105
09/30 09:21:11 - mmengine - INFO - Iter(train) [  2500/320000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 1 day, 14:23:50  time: 0.4314  data_time: 0.0087  memory: 5147  grad_norm: 172.8762  loss: 21.3115  decode.loss_cls: 1.2002  decode.loss_mask: 0.4731  decode.loss_dice: 0.4788  decode.d0.loss_cls: 1.7573  decode.d0.loss_mask: 0.4109  decode.d0.loss_dice: 0.5305  decode.d1.loss_cls: 1.2263  decode.d1.loss_mask: 0.3859  decode.d1.loss_dice: 0.4363  decode.d2.loss_cls: 1.1340  decode.d2.loss_mask: 0.4221  decode.d2.loss_dice: 0.4639  decode.d3.loss_cls: 1.1946  decode.d3.loss_mask: 0.3918  decode.d3.loss_dice: 0.4578  decode.d4.loss_cls: 1.1971  decode.d4.loss_mask: 0.4046  decode.d4.loss_dice: 0.4638  decode.d5.loss_cls: 1.0516  decode.d5.loss_mask: 0.4724  decode.d5.loss_dice: 0.4531  decode.d6.loss_cls: 1.1244  decode.d6.loss_mask: 0.4418  decode.d6.loss_dice: 0.4744  decode.d7.loss_cls: 1.1989  decode.d7.loss_mask: 0.4400  decode.d7.loss_dice: 0.4738  decode.d8.loss_cls: 1.1261  decode.d8.loss_mask: 0.5360  decode.d8.loss_dice: 0.4900
09/30 09:21:33 - mmengine - INFO - Iter(train) [  2550/320000]  base_lr: 9.9283e-05 lr: 9.9283e-06  eta: 1 day, 14:22:59  time: 0.4308  data_time: 0.0088  memory: 5161  grad_norm: 222.2485  loss: 14.4759  decode.loss_cls: 0.7100  decode.loss_mask: 0.4840  decode.loss_dice: 0.2912  decode.d0.loss_cls: 1.4497  decode.d0.loss_mask: 0.3314  decode.d0.loss_dice: 0.3059  decode.d1.loss_cls: 0.7777  decode.d1.loss_mask: 0.3467  decode.d1.loss_dice: 0.2571  decode.d2.loss_cls: 0.6628  decode.d2.loss_mask: 0.4033  decode.d2.loss_dice: 0.2719  decode.d3.loss_cls: 0.6513  decode.d3.loss_mask: 0.4334  decode.d3.loss_dice: 0.2479  decode.d4.loss_cls: 0.6680  decode.d4.loss_mask: 0.4160  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.7110  decode.d5.loss_mask: 0.4140  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.6880  decode.d6.loss_mask: 0.3585  decode.d6.loss_dice: 0.2838  decode.d7.loss_cls: 0.7677  decode.d7.loss_mask: 0.3715  decode.d7.loss_dice: 0.2836  decode.d8.loss_cls: 0.7383  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.3026
09/30 09:21:54 - mmengine - INFO - Iter(train) [  2600/320000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 1 day, 14:22:13  time: 0.4305  data_time: 0.0087  memory: 5180  grad_norm: 340.7953  loss: 13.8363  decode.loss_cls: 0.6122  decode.loss_mask: 0.4202  decode.loss_dice: 0.2554  decode.d0.loss_cls: 1.3756  decode.d0.loss_mask: 0.4284  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.7351  decode.d1.loss_mask: 0.4290  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.6379  decode.d2.loss_mask: 0.4273  decode.d2.loss_dice: 0.2670  decode.d3.loss_cls: 0.5967  decode.d3.loss_mask: 0.4223  decode.d3.loss_dice: 0.2694  decode.d4.loss_cls: 0.6068  decode.d4.loss_mask: 0.4072  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.6302  decode.d5.loss_mask: 0.4203  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.5957  decode.d6.loss_mask: 0.4271  decode.d6.loss_dice: 0.2533  decode.d7.loss_cls: 0.6393  decode.d7.loss_mask: 0.4115  decode.d7.loss_dice: 0.2538  decode.d8.loss_cls: 0.6163  decode.d8.loss_mask: 0.4270  decode.d8.loss_dice: 0.2469
09/30 09:22:16 - mmengine - INFO - Iter(train) [  2650/320000]  base_lr: 9.9255e-05 lr: 9.9255e-06  eta: 1 day, 14:21:27  time: 0.4314  data_time: 0.0088  memory: 5147  grad_norm: 88.5734  loss: 12.8921  decode.loss_cls: 0.5681  decode.loss_mask: 0.3341  decode.loss_dice: 0.3015  decode.d0.loss_cls: 1.3389  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3727  decode.d1.loss_cls: 0.6389  decode.d1.loss_mask: 0.3167  decode.d1.loss_dice: 0.2911  decode.d2.loss_cls: 0.5424  decode.d2.loss_mask: 0.3099  decode.d2.loss_dice: 0.2979  decode.d3.loss_cls: 0.5238  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.3054  decode.d4.loss_cls: 0.5612  decode.d4.loss_mask: 0.3183  decode.d4.loss_dice: 0.2906  decode.d5.loss_cls: 0.5564  decode.d5.loss_mask: 0.3118  decode.d5.loss_dice: 0.3050  decode.d6.loss_cls: 0.5997  decode.d6.loss_mask: 0.3155  decode.d6.loss_dice: 0.3261  decode.d7.loss_cls: 0.6601  decode.d7.loss_mask: 0.3162  decode.d7.loss_dice: 0.3182  decode.d8.loss_cls: 0.6109  decode.d8.loss_mask: 0.3214  decode.d8.loss_dice: 0.3227
09/30 09:22:37 - mmengine - INFO - Iter(train) [  2700/320000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 1 day, 14:20:40  time: 0.4311  data_time: 0.0089  memory: 5161  grad_norm: 147.5363  loss: 14.0691  decode.loss_cls: 0.6360  decode.loss_mask: 0.3107  decode.loss_dice: 0.3467  decode.d0.loss_cls: 1.3421  decode.d0.loss_mask: 0.2910  decode.d0.loss_dice: 0.3301  decode.d1.loss_cls: 0.8174  decode.d1.loss_mask: 0.2737  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.6678  decode.d2.loss_mask: 0.3518  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.6452  decode.d3.loss_mask: 0.3928  decode.d3.loss_dice: 0.3170  decode.d4.loss_cls: 0.6747  decode.d4.loss_mask: 0.4918  decode.d4.loss_dice: 0.3277  decode.d5.loss_cls: 0.6996  decode.d5.loss_mask: 0.3937  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.6622  decode.d6.loss_mask: 0.3702  decode.d6.loss_dice: 0.3181  decode.d7.loss_cls: 0.6069  decode.d7.loss_mask: 0.3432  decode.d7.loss_dice: 0.3009  decode.d8.loss_cls: 0.5953  decode.d8.loss_mask: 0.3361  decode.d8.loss_dice: 0.3051
09/30 09:22:59 - mmengine - INFO - Iter(train) [  2750/320000]  base_lr: 9.9227e-05 lr: 9.9227e-06  eta: 1 day, 14:19:53  time: 0.4296  data_time: 0.0086  memory: 5161  grad_norm: 324.1247  loss: 17.6756  decode.loss_cls: 0.7680  decode.loss_mask: 0.5091  decode.loss_dice: 0.4514  decode.d0.loss_cls: 1.5037  decode.d0.loss_mask: 0.4011  decode.d0.loss_dice: 0.3897  decode.d1.loss_cls: 0.8577  decode.d1.loss_mask: 0.3759  decode.d1.loss_dice: 0.3706  decode.d2.loss_cls: 0.8369  decode.d2.loss_mask: 0.4062  decode.d2.loss_dice: 0.3882  decode.d3.loss_cls: 0.8148  decode.d3.loss_mask: 0.4748  decode.d3.loss_dice: 0.4027  decode.d4.loss_cls: 0.8142  decode.d4.loss_mask: 0.5366  decode.d4.loss_dice: 0.4070  decode.d5.loss_cls: 0.7693  decode.d5.loss_mask: 0.5035  decode.d5.loss_dice: 0.4083  decode.d6.loss_cls: 0.8012  decode.d6.loss_mask: 0.5245  decode.d6.loss_dice: 0.4632  decode.d7.loss_cls: 0.8465  decode.d7.loss_mask: 0.4778  decode.d7.loss_dice: 0.4824  decode.d8.loss_cls: 0.8320  decode.d8.loss_mask: 0.4431  decode.d8.loss_dice: 0.4152
09/30 09:23:20 - mmengine - INFO - Iter(train) [  2800/320000]  base_lr: 9.9212e-05 lr: 9.9212e-06  eta: 1 day, 14:19:08  time: 0.4319  data_time: 0.0090  memory: 5147  grad_norm: 170.8000  loss: 17.1709  decode.loss_cls: 0.9583  decode.loss_mask: 0.3227  decode.loss_dice: 0.3454  decode.d0.loss_cls: 1.5989  decode.d0.loss_mask: 0.3369  decode.d0.loss_dice: 0.4738  decode.d1.loss_cls: 0.9713  decode.d1.loss_mask: 0.3182  decode.d1.loss_dice: 0.3997  decode.d2.loss_cls: 0.9202  decode.d2.loss_mask: 0.3056  decode.d2.loss_dice: 0.3525  decode.d3.loss_cls: 0.9204  decode.d3.loss_mask: 0.3196  decode.d3.loss_dice: 0.3613  decode.d4.loss_cls: 0.9256  decode.d4.loss_mask: 0.3293  decode.d4.loss_dice: 0.3526  decode.d5.loss_cls: 0.9740  decode.d5.loss_mask: 0.3367  decode.d5.loss_dice: 0.3625  decode.d6.loss_cls: 0.9336  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.3569  decode.d7.loss_cls: 0.9677  decode.d7.loss_mask: 0.3416  decode.d7.loss_dice: 0.3784  decode.d8.loss_cls: 0.9723  decode.d8.loss_mask: 0.3469  decode.d8.loss_dice: 0.3684
09/30 09:23:42 - mmengine - INFO - Iter(train) [  2850/320000]  base_lr: 9.9198e-05 lr: 9.9198e-06  eta: 1 day, 14:18:24  time: 0.4316  data_time: 0.0087  memory: 5161  grad_norm: 136.7216  loss: 13.9344  decode.loss_cls: 0.5914  decode.loss_mask: 0.3487  decode.loss_dice: 0.2864  decode.d0.loss_cls: 1.5258  decode.d0.loss_mask: 0.3396  decode.d0.loss_dice: 0.3706  decode.d1.loss_cls: 0.8954  decode.d1.loss_mask: 0.3006  decode.d1.loss_dice: 0.3456  decode.d2.loss_cls: 0.6692  decode.d2.loss_mask: 0.3315  decode.d2.loss_dice: 0.2996  decode.d3.loss_cls: 0.6822  decode.d3.loss_mask: 0.3365  decode.d3.loss_dice: 0.3002  decode.d4.loss_cls: 0.5823  decode.d4.loss_mask: 0.3172  decode.d4.loss_dice: 0.3055  decode.d5.loss_cls: 0.5786  decode.d5.loss_mask: 0.3798  decode.d5.loss_dice: 0.2973  decode.d6.loss_cls: 0.5983  decode.d6.loss_mask: 0.3426  decode.d6.loss_dice: 0.2814  decode.d7.loss_cls: 0.6007  decode.d7.loss_mask: 0.3953  decode.d7.loss_dice: 0.3388  decode.d8.loss_cls: 0.5947  decode.d8.loss_mask: 0.3803  decode.d8.loss_dice: 0.3184
09/30 09:24:04 - mmengine - INFO - Iter(train) [  2900/320000]  base_lr: 9.9184e-05 lr: 9.9184e-06  eta: 1 day, 14:18:02  time: 0.4308  data_time: 0.0088  memory: 5147  grad_norm: 200.3912  loss: 15.8107  decode.loss_cls: 0.6547  decode.loss_mask: 0.5506  decode.loss_dice: 0.3020  decode.d0.loss_cls: 1.2902  decode.d0.loss_mask: 0.4775  decode.d0.loss_dice: 0.3529  decode.d1.loss_cls: 0.7818  decode.d1.loss_mask: 0.5267  decode.d1.loss_dice: 0.3530  decode.d2.loss_cls: 0.7428  decode.d2.loss_mask: 0.5026  decode.d2.loss_dice: 0.3455  decode.d3.loss_cls: 0.7214  decode.d3.loss_mask: 0.4906  decode.d3.loss_dice: 0.3423  decode.d4.loss_cls: 0.6480  decode.d4.loss_mask: 0.5085  decode.d4.loss_dice: 0.3318  decode.d5.loss_cls: 0.6876  decode.d5.loss_mask: 0.4713  decode.d5.loss_dice: 0.3206  decode.d6.loss_cls: 0.6326  decode.d6.loss_mask: 0.4676  decode.d6.loss_dice: 0.3192  decode.d7.loss_cls: 0.6505  decode.d7.loss_mask: 0.4810  decode.d7.loss_dice: 0.3120  decode.d8.loss_cls: 0.7025  decode.d8.loss_mask: 0.5297  decode.d8.loss_dice: 0.3132
09/30 09:24:25 - mmengine - INFO - Iter(train) [  2950/320000]  base_lr: 9.9170e-05 lr: 9.9170e-06  eta: 1 day, 14:17:21  time: 0.4317  data_time: 0.0089  memory: 5161  grad_norm: 231.9795  loss: 16.4164  decode.loss_cls: 0.5530  decode.loss_mask: 0.4964  decode.loss_dice: 0.3594  decode.d0.loss_cls: 1.2881  decode.d0.loss_mask: 0.5478  decode.d0.loss_dice: 0.4118  decode.d1.loss_cls: 0.7819  decode.d1.loss_mask: 0.5221  decode.d1.loss_dice: 0.3757  decode.d2.loss_cls: 0.7263  decode.d2.loss_mask: 0.5239  decode.d2.loss_dice: 0.3574  decode.d3.loss_cls: 0.7025  decode.d3.loss_mask: 0.5069  decode.d3.loss_dice: 0.3461  decode.d4.loss_cls: 0.7450  decode.d4.loss_mask: 0.5181  decode.d4.loss_dice: 0.3699  decode.d5.loss_cls: 0.7149  decode.d5.loss_mask: 0.5206  decode.d5.loss_dice: 0.3771  decode.d6.loss_cls: 0.6902  decode.d6.loss_mask: 0.5082  decode.d6.loss_dice: 0.3670  decode.d7.loss_cls: 0.7026  decode.d7.loss_mask: 0.5049  decode.d7.loss_dice: 0.3660  decode.d8.loss_cls: 0.6573  decode.d8.loss_mask: 0.5116  decode.d8.loss_dice: 0.3635
09/30 09:24:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:24:47 - mmengine - INFO - Iter(train) [  3000/320000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 1 day, 14:16:37  time: 0.4307  data_time: 0.0089  memory: 5180  grad_norm: 177.9724  loss: 17.2376  decode.loss_cls: 0.8816  decode.loss_mask: 0.3715  decode.loss_dice: 0.3601  decode.d0.loss_cls: 1.4193  decode.d0.loss_mask: 0.4036  decode.d0.loss_dice: 0.4075  decode.d1.loss_cls: 0.9271  decode.d1.loss_mask: 0.3762  decode.d1.loss_dice: 0.3525  decode.d2.loss_cls: 0.9043  decode.d2.loss_mask: 0.3619  decode.d2.loss_dice: 0.3464  decode.d3.loss_cls: 0.9450  decode.d3.loss_mask: 0.3739  decode.d3.loss_dice: 0.3552  decode.d4.loss_cls: 0.9213  decode.d4.loss_mask: 0.3586  decode.d4.loss_dice: 0.3600  decode.d5.loss_cls: 0.9219  decode.d5.loss_mask: 0.3679  decode.d5.loss_dice: 0.3453  decode.d6.loss_cls: 0.9893  decode.d6.loss_mask: 0.3542  decode.d6.loss_dice: 0.3675  decode.d7.loss_cls: 1.0358  decode.d7.loss_mask: 0.3578  decode.d7.loss_dice: 0.3435  decode.d8.loss_cls: 1.0172  decode.d8.loss_mask: 0.3554  decode.d8.loss_dice: 0.3556
09/30 09:25:08 - mmengine - INFO - Iter(train) [  3050/320000]  base_lr: 9.9142e-05 lr: 9.9142e-06  eta: 1 day, 14:15:59  time: 0.4320  data_time: 0.0089  memory: 5161  grad_norm: 316.1399  loss: 16.8922  decode.loss_cls: 0.6422  decode.loss_mask: 0.5337  decode.loss_dice: 0.3988  decode.d0.loss_cls: 1.4142  decode.d0.loss_mask: 0.5286  decode.d0.loss_dice: 0.4227  decode.d1.loss_cls: 0.8232  decode.d1.loss_mask: 0.5318  decode.d1.loss_dice: 0.3946  decode.d2.loss_cls: 0.7816  decode.d2.loss_mask: 0.5366  decode.d2.loss_dice: 0.4202  decode.d3.loss_cls: 0.7277  decode.d3.loss_mask: 0.5250  decode.d3.loss_dice: 0.4243  decode.d4.loss_cls: 0.6240  decode.d4.loss_mask: 0.5332  decode.d4.loss_dice: 0.4012  decode.d5.loss_cls: 0.5945  decode.d5.loss_mask: 0.5071  decode.d5.loss_dice: 0.3921  decode.d6.loss_cls: 0.6131  decode.d6.loss_mask: 0.5588  decode.d6.loss_dice: 0.3697  decode.d7.loss_cls: 0.6284  decode.d7.loss_mask: 0.5774  decode.d7.loss_dice: 0.4091  decode.d8.loss_cls: 0.6025  decode.d8.loss_mask: 0.5734  decode.d8.loss_dice: 0.4028
09/30 09:25:30 - mmengine - INFO - Iter(train) [  3100/320000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 1 day, 14:15:20  time: 0.4316  data_time: 0.0088  memory: 5161  grad_norm: 87.3908  loss: 11.0867  decode.loss_cls: 0.5260  decode.loss_mask: 0.2494  decode.loss_dice: 0.2573  decode.d0.loss_cls: 1.2464  decode.d0.loss_mask: 0.2376  decode.d0.loss_dice: 0.2527  decode.d1.loss_cls: 0.6898  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.2756  decode.d2.loss_cls: 0.5355  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2248  decode.d3.loss_cls: 0.5088  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.5215  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.5219  decode.d5.loss_mask: 0.2377  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.5321  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.2465  decode.d7.loss_cls: 0.5128  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.2587  decode.d8.loss_cls: 0.5139  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2555
09/30 09:25:51 - mmengine - INFO - Iter(train) [  3150/320000]  base_lr: 9.9114e-05 lr: 9.9114e-06  eta: 1 day, 14:14:38  time: 0.4305  data_time: 0.0090  memory: 5147  grad_norm: 89.2645  loss: 16.6795  decode.loss_cls: 0.7460  decode.loss_mask: 0.4082  decode.loss_dice: 0.3736  decode.d0.loss_cls: 1.4156  decode.d0.loss_mask: 0.4303  decode.d0.loss_dice: 0.4602  decode.d1.loss_cls: 1.0134  decode.d1.loss_mask: 0.4127  decode.d1.loss_dice: 0.3921  decode.d2.loss_cls: 0.8164  decode.d2.loss_mask: 0.3940  decode.d2.loss_dice: 0.3866  decode.d3.loss_cls: 0.7341  decode.d3.loss_mask: 0.3953  decode.d3.loss_dice: 0.3717  decode.d4.loss_cls: 0.7789  decode.d4.loss_mask: 0.4077  decode.d4.loss_dice: 0.3921  decode.d5.loss_cls: 0.7596  decode.d5.loss_mask: 0.4081  decode.d5.loss_dice: 0.3726  decode.d6.loss_cls: 0.7973  decode.d6.loss_mask: 0.3979  decode.d6.loss_dice: 0.3567  decode.d7.loss_cls: 0.8329  decode.d7.loss_mask: 0.4111  decode.d7.loss_dice: 0.3855  decode.d8.loss_cls: 0.8418  decode.d8.loss_mask: 0.4020  decode.d8.loss_dice: 0.3851
09/30 09:26:13 - mmengine - INFO - Iter(train) [  3200/320000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 1 day, 14:14:00  time: 0.4308  data_time: 0.0088  memory: 5161  grad_norm: 130.2937  loss: 15.5433  decode.loss_cls: 0.8709  decode.loss_mask: 0.2886  decode.loss_dice: 0.2583  decode.d0.loss_cls: 1.6208  decode.d0.loss_mask: 0.3380  decode.d0.loss_dice: 0.3362  decode.d1.loss_cls: 0.9817  decode.d1.loss_mask: 0.3355  decode.d1.loss_dice: 0.2822  decode.d2.loss_cls: 0.9259  decode.d2.loss_mask: 0.3200  decode.d2.loss_dice: 0.2573  decode.d3.loss_cls: 0.9158  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.9010  decode.d4.loss_mask: 0.3151  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.9542  decode.d5.loss_mask: 0.2911  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.8775  decode.d6.loss_mask: 0.3066  decode.d6.loss_dice: 0.2879  decode.d7.loss_cls: 0.8639  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.2570  decode.d8.loss_cls: 0.8462  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.2409
09/30 09:26:35 - mmengine - INFO - Iter(train) [  3250/320000]  base_lr: 9.9086e-05 lr: 9.9086e-06  eta: 1 day, 14:13:22  time: 0.4318  data_time: 0.0089  memory: 5180  grad_norm: 107.9511  loss: 13.8945  decode.loss_cls: 0.7342  decode.loss_mask: 0.3287  decode.loss_dice: 0.3079  decode.d0.loss_cls: 1.4478  decode.d0.loss_mask: 0.3412  decode.d0.loss_dice: 0.3443  decode.d1.loss_cls: 0.7270  decode.d1.loss_mask: 0.3412  decode.d1.loss_dice: 0.3052  decode.d2.loss_cls: 0.7086  decode.d2.loss_mask: 0.3335  decode.d2.loss_dice: 0.2878  decode.d3.loss_cls: 0.6249  decode.d3.loss_mask: 0.3215  decode.d3.loss_dice: 0.3133  decode.d4.loss_cls: 0.6490  decode.d4.loss_mask: 0.3231  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.6524  decode.d5.loss_mask: 0.3386  decode.d5.loss_dice: 0.3171  decode.d6.loss_cls: 0.6114  decode.d6.loss_mask: 0.3421  decode.d6.loss_dice: 0.3180  decode.d7.loss_cls: 0.6474  decode.d7.loss_mask: 0.3338  decode.d7.loss_dice: 0.2656  decode.d8.loss_cls: 0.7281  decode.d8.loss_mask: 0.3287  decode.d8.loss_dice: 0.2900
09/30 09:26:56 - mmengine - INFO - Iter(train) [  3300/320000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 1 day, 14:12:46  time: 0.4316  data_time: 0.0088  memory: 5161  grad_norm: 139.8877  loss: 17.3573  decode.loss_cls: 0.8380  decode.loss_mask: 0.3975  decode.loss_dice: 0.3505  decode.d0.loss_cls: 1.3922  decode.d0.loss_mask: 0.4270  decode.d0.loss_dice: 0.4015  decode.d1.loss_cls: 0.9437  decode.d1.loss_mask: 0.3926  decode.d1.loss_dice: 0.3829  decode.d2.loss_cls: 0.9061  decode.d2.loss_mask: 0.4195  decode.d2.loss_dice: 0.4115  decode.d3.loss_cls: 0.9110  decode.d3.loss_mask: 0.4258  decode.d3.loss_dice: 0.4045  decode.d4.loss_cls: 0.9035  decode.d4.loss_mask: 0.4367  decode.d4.loss_dice: 0.3526  decode.d5.loss_cls: 0.9299  decode.d5.loss_mask: 0.4797  decode.d5.loss_dice: 0.3344  decode.d6.loss_cls: 0.9438  decode.d6.loss_mask: 0.4589  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 0.8741  decode.d7.loss_mask: 0.4248  decode.d7.loss_dice: 0.3235  decode.d8.loss_cls: 0.8606  decode.d8.loss_mask: 0.4001  decode.d8.loss_dice: 0.2995
09/30 09:27:18 - mmengine - INFO - Iter(train) [  3350/320000]  base_lr: 9.9058e-05 lr: 9.9058e-06  eta: 1 day, 14:12:10  time: 0.4314  data_time: 0.0087  memory: 5180  grad_norm: 138.9115  loss: 15.0480  decode.loss_cls: 0.6530  decode.loss_mask: 0.3941  decode.loss_dice: 0.3195  decode.d0.loss_cls: 1.3727  decode.d0.loss_mask: 0.3829  decode.d0.loss_dice: 0.3621  decode.d1.loss_cls: 0.8448  decode.d1.loss_mask: 0.3320  decode.d1.loss_dice: 0.3159  decode.d2.loss_cls: 0.7610  decode.d2.loss_mask: 0.3230  decode.d2.loss_dice: 0.3006  decode.d3.loss_cls: 0.7881  decode.d3.loss_mask: 0.3329  decode.d3.loss_dice: 0.3257  decode.d4.loss_cls: 0.8004  decode.d4.loss_mask: 0.3682  decode.d4.loss_dice: 0.3666  decode.d5.loss_cls: 0.7763  decode.d5.loss_mask: 0.3447  decode.d5.loss_dice: 0.3179  decode.d6.loss_cls: 0.7840  decode.d6.loss_mask: 0.3404  decode.d6.loss_dice: 0.3395  decode.d7.loss_cls: 0.7467  decode.d7.loss_mask: 0.3429  decode.d7.loss_dice: 0.3255  decode.d8.loss_cls: 0.7259  decode.d8.loss_mask: 0.3509  decode.d8.loss_dice: 0.3098
09/30 09:27:39 - mmengine - INFO - Iter(train) [  3400/320000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 1 day, 14:11:35  time: 0.4312  data_time: 0.0088  memory: 5180  grad_norm: 96.5437  loss: 12.5414  decode.loss_cls: 0.5149  decode.loss_mask: 0.2982  decode.loss_dice: 0.3202  decode.d0.loss_cls: 1.2454  decode.d0.loss_mask: 0.2763  decode.d0.loss_dice: 0.3373  decode.d1.loss_cls: 0.7064  decode.d1.loss_mask: 0.2803  decode.d1.loss_dice: 0.3136  decode.d2.loss_cls: 0.6214  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.2975  decode.d3.loss_cls: 0.6068  decode.d3.loss_mask: 0.2713  decode.d3.loss_dice: 0.3087  decode.d4.loss_cls: 0.6933  decode.d4.loss_mask: 0.2813  decode.d4.loss_dice: 0.3032  decode.d5.loss_cls: 0.5662  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.3080  decode.d6.loss_cls: 0.5434  decode.d6.loss_mask: 0.2761  decode.d6.loss_dice: 0.3076  decode.d7.loss_cls: 0.5530  decode.d7.loss_mask: 0.2828  decode.d7.loss_dice: 0.3133  decode.d8.loss_cls: 0.5190  decode.d8.loss_mask: 0.2906  decode.d8.loss_dice: 0.3402
09/30 09:28:01 - mmengine - INFO - Iter(train) [  3450/320000]  base_lr: 9.9029e-05 lr: 9.9029e-06  eta: 1 day, 14:11:00  time: 0.4323  data_time: 0.0088  memory: 5161  grad_norm: 127.3647  loss: 15.5741  decode.loss_cls: 0.7205  decode.loss_mask: 0.2977  decode.loss_dice: 0.4515  decode.d0.loss_cls: 1.2912  decode.d0.loss_mask: 0.3463  decode.d0.loss_dice: 0.5053  decode.d1.loss_cls: 0.7852  decode.d1.loss_mask: 0.2964  decode.d1.loss_dice: 0.4235  decode.d2.loss_cls: 0.6182  decode.d2.loss_mask: 0.3168  decode.d2.loss_dice: 0.4984  decode.d3.loss_cls: 0.7016  decode.d3.loss_mask: 0.2907  decode.d3.loss_dice: 0.4662  decode.d4.loss_cls: 0.6978  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.4590  decode.d5.loss_cls: 0.7447  decode.d5.loss_mask: 0.3238  decode.d5.loss_dice: 0.4666  decode.d6.loss_cls: 0.7501  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.4858  decode.d7.loss_cls: 0.6632  decode.d7.loss_mask: 0.3217  decode.d7.loss_dice: 0.4477  decode.d8.loss_cls: 0.7076  decode.d8.loss_mask: 0.3424  decode.d8.loss_dice: 0.5252
09/30 09:28:22 - mmengine - INFO - Iter(train) [  3500/320000]  base_lr: 9.9015e-05 lr: 9.9015e-06  eta: 1 day, 14:10:25  time: 0.4306  data_time: 0.0085  memory: 5179  grad_norm: 225.0780  loss: 17.9127  decode.loss_cls: 0.8783  decode.loss_mask: 0.3800  decode.loss_dice: 0.4332  decode.d0.loss_cls: 1.6039  decode.d0.loss_mask: 0.3688  decode.d0.loss_dice: 0.4646  decode.d1.loss_cls: 1.0927  decode.d1.loss_mask: 0.3322  decode.d1.loss_dice: 0.4300  decode.d2.loss_cls: 0.8746  decode.d2.loss_mask: 0.3453  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.9277  decode.d3.loss_mask: 0.4005  decode.d3.loss_dice: 0.4045  decode.d4.loss_cls: 0.7931  decode.d4.loss_mask: 0.4031  decode.d4.loss_dice: 0.4479  decode.d5.loss_cls: 0.8293  decode.d5.loss_mask: 0.5195  decode.d5.loss_dice: 0.4444  decode.d6.loss_cls: 0.8997  decode.d6.loss_mask: 0.3794  decode.d6.loss_dice: 0.4104  decode.d7.loss_cls: 0.9472  decode.d7.loss_mask: 0.3607  decode.d7.loss_dice: 0.4138  decode.d8.loss_cls: 0.8778  decode.d8.loss_mask: 0.3846  decode.d8.loss_dice: 0.4555
09/30 09:28:44 - mmengine - INFO - Iter(train) [  3550/320000]  base_lr: 9.9001e-05 lr: 9.9001e-06  eta: 1 day, 14:09:52  time: 0.4314  data_time: 0.0087  memory: 5161  grad_norm: 293.8931  loss: 19.4691  decode.loss_cls: 0.9064  decode.loss_mask: 0.6606  decode.loss_dice: 0.4489  decode.d0.loss_cls: 1.3521  decode.d0.loss_mask: 0.6340  decode.d0.loss_dice: 0.5417  decode.d1.loss_cls: 1.0083  decode.d1.loss_mask: 0.5366  decode.d1.loss_dice: 0.4579  decode.d2.loss_cls: 0.9261  decode.d2.loss_mask: 0.5281  decode.d2.loss_dice: 0.4646  decode.d3.loss_cls: 0.8622  decode.d3.loss_mask: 0.5256  decode.d3.loss_dice: 0.4150  decode.d4.loss_cls: 0.8388  decode.d4.loss_mask: 0.5530  decode.d4.loss_dice: 0.3840  decode.d5.loss_cls: 0.8530  decode.d5.loss_mask: 0.6273  decode.d5.loss_dice: 0.3909  decode.d6.loss_cls: 0.8679  decode.d6.loss_mask: 0.5270  decode.d6.loss_dice: 0.3836  decode.d7.loss_cls: 0.8919  decode.d7.loss_mask: 0.5343  decode.d7.loss_dice: 0.3950  decode.d8.loss_cls: 0.9127  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 0.4511
09/30 09:29:06 - mmengine - INFO - Iter(train) [  3600/320000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 1 day, 14:09:17  time: 0.4314  data_time: 0.0089  memory: 5180  grad_norm: 96.4902  loss: 11.6897  decode.loss_cls: 0.4030  decode.loss_mask: 0.3874  decode.loss_dice: 0.2997  decode.d0.loss_cls: 0.9761  decode.d0.loss_mask: 0.3832  decode.d0.loss_dice: 0.2763  decode.d1.loss_cls: 0.5163  decode.d1.loss_mask: 0.3832  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.4570  decode.d2.loss_mask: 0.3919  decode.d2.loss_dice: 0.2836  decode.d3.loss_cls: 0.4663  decode.d3.loss_mask: 0.3868  decode.d3.loss_dice: 0.2738  decode.d4.loss_cls: 0.4622  decode.d4.loss_mask: 0.3799  decode.d4.loss_dice: 0.2742  decode.d5.loss_cls: 0.4182  decode.d5.loss_mask: 0.3857  decode.d5.loss_dice: 0.2765  decode.d6.loss_cls: 0.4058  decode.d6.loss_mask: 0.3875  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.4446  decode.d7.loss_mask: 0.3823  decode.d7.loss_dice: 0.2878  decode.d8.loss_cls: 0.4574  decode.d8.loss_mask: 0.3866  decode.d8.loss_dice: 0.2917
09/30 09:29:27 - mmengine - INFO - Iter(train) [  3650/320000]  base_lr: 9.8973e-05 lr: 9.8973e-06  eta: 1 day, 14:08:45  time: 0.4317  data_time: 0.0087  memory: 5160  grad_norm: 263.3743  loss: 14.7629  decode.loss_cls: 0.5398  decode.loss_mask: 0.7997  decode.loss_dice: 0.4127  decode.d0.loss_cls: 1.0978  decode.d0.loss_mask: 0.4309  decode.d0.loss_dice: 0.4231  decode.d1.loss_cls: 0.5908  decode.d1.loss_mask: 0.4047  decode.d1.loss_dice: 0.3940  decode.d2.loss_cls: 0.5127  decode.d2.loss_mask: 0.4115  decode.d2.loss_dice: 0.3890  decode.d3.loss_cls: 0.5151  decode.d3.loss_mask: 0.4013  decode.d3.loss_dice: 0.3942  decode.d4.loss_cls: 0.5068  decode.d4.loss_mask: 0.4064  decode.d4.loss_dice: 0.3670  decode.d5.loss_cls: 0.4961  decode.d5.loss_mask: 0.4411  decode.d5.loss_dice: 0.3907  decode.d6.loss_cls: 0.5105  decode.d6.loss_mask: 0.4306  decode.d6.loss_dice: 0.4001  decode.d7.loss_cls: 0.5971  decode.d7.loss_mask: 0.6008  decode.d7.loss_dice: 0.4298  decode.d8.loss_cls: 0.5700  decode.d8.loss_mask: 0.4974  decode.d8.loss_dice: 0.4010
09/30 09:29:49 - mmengine - INFO - Iter(train) [  3700/320000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 1 day, 14:08:12  time: 0.4328  data_time: 0.0089  memory: 5180  grad_norm: 130.3208  loss: 9.8770  decode.loss_cls: 0.3187  decode.loss_mask: 0.2868  decode.loss_dice: 0.3185  decode.d0.loss_cls: 1.1873  decode.d0.loss_mask: 0.2537  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.5258  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.2435  decode.d2.loss_cls: 0.3835  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.3454  decode.d3.loss_mask: 0.2624  decode.d3.loss_dice: 0.2529  decode.d4.loss_cls: 0.3849  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.2629  decode.d5.loss_cls: 0.3985  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.2426  decode.d6.loss_cls: 0.3724  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.2499  decode.d7.loss_cls: 0.3942  decode.d7.loss_mask: 0.2644  decode.d7.loss_dice: 0.2597  decode.d8.loss_cls: 0.3363  decode.d8.loss_mask: 0.2597  decode.d8.loss_dice: 0.2578
09/30 09:30:10 - mmengine - INFO - Iter(train) [  3750/320000]  base_lr: 9.8945e-05 lr: 9.8945e-06  eta: 1 day, 14:07:40  time: 0.4306  data_time: 0.0085  memory: 5146  grad_norm: 117.9622  loss: 11.5938  decode.loss_cls: 0.5635  decode.loss_mask: 0.3056  decode.loss_dice: 0.2752  decode.d0.loss_cls: 1.1736  decode.d0.loss_mask: 0.3361  decode.d0.loss_dice: 0.2628  decode.d1.loss_cls: 0.5982  decode.d1.loss_mask: 0.3547  decode.d1.loss_dice: 0.2716  decode.d2.loss_cls: 0.4888  decode.d2.loss_mask: 0.3100  decode.d2.loss_dice: 0.2707  decode.d3.loss_cls: 0.4656  decode.d3.loss_mask: 0.3008  decode.d3.loss_dice: 0.2823  decode.d4.loss_cls: 0.4943  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.2830  decode.d5.loss_cls: 0.4696  decode.d5.loss_mask: 0.3119  decode.d5.loss_dice: 0.2715  decode.d6.loss_cls: 0.4721  decode.d6.loss_mask: 0.3062  decode.d6.loss_dice: 0.2765  decode.d7.loss_cls: 0.4788  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.5442  decode.d8.loss_mask: 0.3136  decode.d8.loss_dice: 0.2599
09/30 09:30:32 - mmengine - INFO - Iter(train) [  3800/320000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 1 day, 14:07:10  time: 0.4322  data_time: 0.0088  memory: 5145  grad_norm: 173.6175  loss: 15.0440  decode.loss_cls: 0.6458  decode.loss_mask: 0.3969  decode.loss_dice: 0.4135  decode.d0.loss_cls: 1.3238  decode.d0.loss_mask: 0.3523  decode.d0.loss_dice: 0.3987  decode.d1.loss_cls: 0.7500  decode.d1.loss_mask: 0.3285  decode.d1.loss_dice: 0.3705  decode.d2.loss_cls: 0.7301  decode.d2.loss_mask: 0.3388  decode.d2.loss_dice: 0.3741  decode.d3.loss_cls: 0.7337  decode.d3.loss_mask: 0.3136  decode.d3.loss_dice: 0.3561  decode.d4.loss_cls: 0.7041  decode.d4.loss_mask: 0.3476  decode.d4.loss_dice: 0.3594  decode.d5.loss_cls: 0.6903  decode.d5.loss_mask: 0.3231  decode.d5.loss_dice: 0.3559  decode.d6.loss_cls: 0.7463  decode.d6.loss_mask: 0.3379  decode.d6.loss_dice: 0.3903  decode.d7.loss_cls: 0.7324  decode.d7.loss_mask: 0.3273  decode.d7.loss_dice: 0.3990  decode.d8.loss_cls: 0.7663  decode.d8.loss_mask: 0.3413  decode.d8.loss_dice: 0.3963
09/30 09:30:53 - mmengine - INFO - Iter(train) [  3850/320000]  base_lr: 9.8917e-05 lr: 9.8917e-06  eta: 1 day, 14:06:37  time: 0.4315  data_time: 0.0088  memory: 5145  grad_norm: 107.2049  loss: 11.0639  decode.loss_cls: 0.4776  decode.loss_mask: 0.3189  decode.loss_dice: 0.2237  decode.d0.loss_cls: 1.1891  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.2872  decode.d1.loss_cls: 0.5776  decode.d1.loss_mask: 0.3027  decode.d1.loss_dice: 0.2328  decode.d2.loss_cls: 0.4842  decode.d2.loss_mask: 0.3244  decode.d2.loss_dice: 0.2621  decode.d3.loss_cls: 0.4689  decode.d3.loss_mask: 0.3218  decode.d3.loss_dice: 0.2362  decode.d4.loss_cls: 0.4648  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.4503  decode.d5.loss_mask: 0.3158  decode.d5.loss_dice: 0.2264  decode.d6.loss_cls: 0.3987  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.2356  decode.d7.loss_cls: 0.4266  decode.d7.loss_mask: 0.3255  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.5030  decode.d8.loss_mask: 0.3311  decode.d8.loss_dice: 0.2415
09/30 09:31:15 - mmengine - INFO - Iter(train) [  3900/320000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 1 day, 14:06:06  time: 0.4313  data_time: 0.0087  memory: 5160  grad_norm: 86.6982  loss: 12.7875  decode.loss_cls: 0.6335  decode.loss_mask: 0.2677  decode.loss_dice: 0.2526  decode.d0.loss_cls: 1.3433  decode.d0.loss_mask: 0.2817  decode.d0.loss_dice: 0.2976  decode.d1.loss_cls: 0.6932  decode.d1.loss_mask: 0.2780  decode.d1.loss_dice: 0.2520  decode.d2.loss_cls: 0.6616  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.6962  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.2416  decode.d4.loss_cls: 0.6869  decode.d4.loss_mask: 0.2712  decode.d4.loss_dice: 0.2562  decode.d5.loss_cls: 0.6896  decode.d5.loss_mask: 0.2706  decode.d5.loss_dice: 0.2407  decode.d6.loss_cls: 0.7562  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.6783  decode.d7.loss_mask: 0.2711  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.7160  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2278
09/30 09:31:37 - mmengine - INFO - Iter(train) [  3950/320000]  base_lr: 9.8889e-05 lr: 9.8889e-06  eta: 1 day, 14:05:36  time: 0.4323  data_time: 0.0090  memory: 5161  grad_norm: 144.9527  loss: 14.1385  decode.loss_cls: 0.5753  decode.loss_mask: 0.3497  decode.loss_dice: 0.2889  decode.d0.loss_cls: 1.2917  decode.d0.loss_mask: 0.3756  decode.d0.loss_dice: 0.3343  decode.d1.loss_cls: 0.7437  decode.d1.loss_mask: 0.3453  decode.d1.loss_dice: 0.2936  decode.d2.loss_cls: 0.7144  decode.d2.loss_mask: 0.3667  decode.d2.loss_dice: 0.2990  decode.d3.loss_cls: 0.6963  decode.d3.loss_mask: 0.3438  decode.d3.loss_dice: 0.2938  decode.d4.loss_cls: 0.6158  decode.d4.loss_mask: 0.3636  decode.d4.loss_dice: 0.3215  decode.d5.loss_cls: 0.6363  decode.d5.loss_mask: 0.4379  decode.d5.loss_dice: 0.3308  decode.d6.loss_cls: 0.5831  decode.d6.loss_mask: 0.4572  decode.d6.loss_dice: 0.3259  decode.d7.loss_cls: 0.5825  decode.d7.loss_mask: 0.4527  decode.d7.loss_dice: 0.3457  decode.d8.loss_cls: 0.5827  decode.d8.loss_mask: 0.4426  decode.d8.loss_dice: 0.3483
09/30 09:31:58 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:31:58 - mmengine - INFO - Iter(train) [  4000/320000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 1 day, 14:05:05  time: 0.4317  data_time: 0.0088  memory: 5161  grad_norm: 150.9489  loss: 11.9810  decode.loss_cls: 0.5256  decode.loss_mask: 0.3056  decode.loss_dice: 0.2553  decode.d0.loss_cls: 1.1023  decode.d0.loss_mask: 0.2896  decode.d0.loss_dice: 0.2598  decode.d1.loss_cls: 0.6819  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.2284  decode.d2.loss_cls: 0.6554  decode.d2.loss_mask: 0.2762  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.5709  decode.d3.loss_mask: 0.2803  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.6337  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.5823  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.2513  decode.d6.loss_cls: 0.5973  decode.d6.loss_mask: 0.2950  decode.d6.loss_dice: 0.2359  decode.d7.loss_cls: 0.6448  decode.d7.loss_mask: 0.3275  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.5556  decode.d8.loss_mask: 0.3254  decode.d8.loss_dice: 0.2540
09/30 09:32:20 - mmengine - INFO - Iter(train) [  4050/320000]  base_lr: 9.8860e-05 lr: 9.8860e-06  eta: 1 day, 14:04:34  time: 0.4317  data_time: 0.0087  memory: 5160  grad_norm: 146.5712  loss: 12.9819  decode.loss_cls: 0.4939  decode.loss_mask: 0.3469  decode.loss_dice: 0.3200  decode.d0.loss_cls: 1.0419  decode.d0.loss_mask: 0.3727  decode.d0.loss_dice: 0.3768  decode.d1.loss_cls: 0.6235  decode.d1.loss_mask: 0.3634  decode.d1.loss_dice: 0.3523  decode.d2.loss_cls: 0.5738  decode.d2.loss_mask: 0.3484  decode.d2.loss_dice: 0.3476  decode.d3.loss_cls: 0.5186  decode.d3.loss_mask: 0.3483  decode.d3.loss_dice: 0.3766  decode.d4.loss_cls: 0.5056  decode.d4.loss_mask: 0.3541  decode.d4.loss_dice: 0.3786  decode.d5.loss_cls: 0.5269  decode.d5.loss_mask: 0.3809  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.4677  decode.d6.loss_mask: 0.3533  decode.d6.loss_dice: 0.3237  decode.d7.loss_cls: 0.5047  decode.d7.loss_mask: 0.3784  decode.d7.loss_dice: 0.3993  decode.d8.loss_cls: 0.5148  decode.d8.loss_mask: 0.3542  decode.d8.loss_dice: 0.3659
09/30 09:32:41 - mmengine - INFO - Iter(train) [  4100/320000]  base_lr: 9.8846e-05 lr: 9.8846e-06  eta: 1 day, 14:04:04  time: 0.4327  data_time: 0.0087  memory: 5180  grad_norm: 118.5958  loss: 11.3197  decode.loss_cls: 0.4937  decode.loss_mask: 0.2836  decode.loss_dice: 0.2685  decode.d0.loss_cls: 1.3039  decode.d0.loss_mask: 0.2818  decode.d0.loss_dice: 0.2696  decode.d1.loss_cls: 0.5789  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.5278  decode.d2.loss_mask: 0.2756  decode.d2.loss_dice: 0.2317  decode.d3.loss_cls: 0.5110  decode.d3.loss_mask: 0.2945  decode.d3.loss_dice: 0.2508  decode.d4.loss_cls: 0.5339  decode.d4.loss_mask: 0.2898  decode.d4.loss_dice: 0.2385  decode.d5.loss_cls: 0.5353  decode.d5.loss_mask: 0.2736  decode.d5.loss_dice: 0.2230  decode.d6.loss_cls: 0.5344  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.2285  decode.d7.loss_cls: 0.5476  decode.d7.loss_mask: 0.2795  decode.d7.loss_dice: 0.2405  decode.d8.loss_cls: 0.5352  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.2281
09/30 09:33:03 - mmengine - INFO - Iter(train) [  4150/320000]  base_lr: 9.8832e-05 lr: 9.8832e-06  eta: 1 day, 14:03:32  time: 0.4316  data_time: 0.0087  memory: 5180  grad_norm: 103.5503  loss: 12.4690  decode.loss_cls: 0.6532  decode.loss_mask: 0.2548  decode.loss_dice: 0.3369  decode.d0.loss_cls: 1.0265  decode.d0.loss_mask: 0.2737  decode.d0.loss_dice: 0.3961  decode.d1.loss_cls: 0.6181  decode.d1.loss_mask: 0.2603  decode.d1.loss_dice: 0.3239  decode.d2.loss_cls: 0.5644  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.3396  decode.d3.loss_cls: 0.6033  decode.d3.loss_mask: 0.2521  decode.d3.loss_dice: 0.3157  decode.d4.loss_cls: 0.6108  decode.d4.loss_mask: 0.2583  decode.d4.loss_dice: 0.3458  decode.d5.loss_cls: 0.6475  decode.d5.loss_mask: 0.2539  decode.d5.loss_dice: 0.3228  decode.d6.loss_cls: 0.6055  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.3073  decode.d7.loss_cls: 0.5982  decode.d7.loss_mask: 0.2514  decode.d7.loss_dice: 0.3168  decode.d8.loss_cls: 0.6000  decode.d8.loss_mask: 0.2477  decode.d8.loss_dice: 0.3587
09/30 09:33:25 - mmengine - INFO - Iter(train) [  4200/320000]  base_lr: 9.8818e-05 lr: 9.8818e-06  eta: 1 day, 14:03:02  time: 0.4325  data_time: 0.0089  memory: 5161  grad_norm: 89.2565  loss: 11.5104  decode.loss_cls: 0.4226  decode.loss_mask: 0.3638  decode.loss_dice: 0.2663  decode.d0.loss_cls: 1.1152  decode.d0.loss_mask: 0.3090  decode.d0.loss_dice: 0.2633  decode.d1.loss_cls: 0.5358  decode.d1.loss_mask: 0.3302  decode.d1.loss_dice: 0.2672  decode.d2.loss_cls: 0.4977  decode.d2.loss_mask: 0.3613  decode.d2.loss_dice: 0.2622  decode.d3.loss_cls: 0.4078  decode.d3.loss_mask: 0.3725  decode.d3.loss_dice: 0.2689  decode.d4.loss_cls: 0.4275  decode.d4.loss_mask: 0.3467  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.5174  decode.d5.loss_mask: 0.3099  decode.d5.loss_dice: 0.2615  decode.d6.loss_cls: 0.4571  decode.d6.loss_mask: 0.3442  decode.d6.loss_dice: 0.2905  decode.d7.loss_cls: 0.4826  decode.d7.loss_mask: 0.3964  decode.d7.loss_dice: 0.2868  decode.d8.loss_cls: 0.4437  decode.d8.loss_mask: 0.3881  decode.d8.loss_dice: 0.2622
09/30 09:33:46 - mmengine - INFO - Iter(train) [  4250/320000]  base_lr: 9.8804e-05 lr: 9.8804e-06  eta: 1 day, 14:02:33  time: 0.4302  data_time: 0.0085  memory: 5146  grad_norm: 285.4977  loss: 17.8409  decode.loss_cls: 0.7993  decode.loss_mask: 0.4586  decode.loss_dice: 0.4515  decode.d0.loss_cls: 1.5109  decode.d0.loss_mask: 0.4643  decode.d0.loss_dice: 0.5679  decode.d1.loss_cls: 0.9845  decode.d1.loss_mask: 0.4684  decode.d1.loss_dice: 0.4381  decode.d2.loss_cls: 0.8226  decode.d2.loss_mask: 0.4638  decode.d2.loss_dice: 0.4543  decode.d3.loss_cls: 0.8072  decode.d3.loss_mask: 0.4108  decode.d3.loss_dice: 0.4723  decode.d4.loss_cls: 0.7495  decode.d4.loss_mask: 0.4095  decode.d4.loss_dice: 0.4441  decode.d5.loss_cls: 0.7468  decode.d5.loss_mask: 0.4310  decode.d5.loss_dice: 0.4369  decode.d6.loss_cls: 0.7493  decode.d6.loss_mask: 0.4627  decode.d6.loss_dice: 0.5061  decode.d7.loss_cls: 0.7246  decode.d7.loss_mask: 0.4194  decode.d7.loss_dice: 0.4653  decode.d8.loss_cls: 0.7996  decode.d8.loss_mask: 0.4180  decode.d8.loss_dice: 0.5036
09/30 09:34:08 - mmengine - INFO - Iter(train) [  4300/320000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 1 day, 14:02:04  time: 0.4317  data_time: 0.0087  memory: 5146  grad_norm: 100.4425  loss: 11.8533  decode.loss_cls: 0.4472  decode.loss_mask: 0.2885  decode.loss_dice: 0.3668  decode.d0.loss_cls: 1.2793  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.3645  decode.d1.loss_cls: 0.5580  decode.d1.loss_mask: 0.2825  decode.d1.loss_dice: 0.3518  decode.d2.loss_cls: 0.4209  decode.d2.loss_mask: 0.3050  decode.d2.loss_dice: 0.3536  decode.d3.loss_cls: 0.4190  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.3743  decode.d4.loss_cls: 0.4550  decode.d4.loss_mask: 0.2736  decode.d4.loss_dice: 0.3588  decode.d5.loss_cls: 0.4573  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3694  decode.d6.loss_cls: 0.3943  decode.d6.loss_mask: 0.2924  decode.d6.loss_dice: 0.3621  decode.d7.loss_cls: 0.4089  decode.d7.loss_mask: 0.3040  decode.d7.loss_dice: 0.3540  decode.d8.loss_cls: 0.4417  decode.d8.loss_mask: 0.3175  decode.d8.loss_dice: 0.3720
09/30 09:34:29 - mmengine - INFO - Iter(train) [  4350/320000]  base_lr: 9.8776e-05 lr: 9.8776e-06  eta: 1 day, 14:01:34  time: 0.4316  data_time: 0.0086  memory: 5160  grad_norm: 212.7691  loss: 9.0970  decode.loss_cls: 0.3414  decode.loss_mask: 0.2422  decode.loss_dice: 0.2363  decode.d0.loss_cls: 1.2261  decode.d0.loss_mask: 0.2454  decode.d0.loss_dice: 0.2620  decode.d1.loss_cls: 0.4180  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.2107  decode.d2.loss_cls: 0.4079  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.3516  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.2102  decode.d4.loss_cls: 0.3765  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.1995  decode.d5.loss_cls: 0.3569  decode.d5.loss_mask: 0.2697  decode.d5.loss_dice: 0.2176  decode.d6.loss_cls: 0.3361  decode.d6.loss_mask: 0.2509  decode.d6.loss_dice: 0.2035  decode.d7.loss_cls: 0.3133  decode.d7.loss_mask: 0.2470  decode.d7.loss_dice: 0.2079  decode.d8.loss_cls: 0.3093  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.2148
09/30 09:34:51 - mmengine - INFO - Iter(train) [  4400/320000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 1 day, 14:01:06  time: 0.4325  data_time: 0.0089  memory: 5180  grad_norm: 69.7470  loss: 10.8888  decode.loss_cls: 0.3803  decode.loss_mask: 0.2897  decode.loss_dice: 0.3139  decode.d0.loss_cls: 1.1954  decode.d0.loss_mask: 0.2562  decode.d0.loss_dice: 0.3078  decode.d1.loss_cls: 0.5038  decode.d1.loss_mask: 0.2570  decode.d1.loss_dice: 0.3127  decode.d2.loss_cls: 0.3588  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.3375  decode.d3.loss_cls: 0.4321  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.3438  decode.d4.loss_cls: 0.4353  decode.d4.loss_mask: 0.2708  decode.d4.loss_dice: 0.3461  decode.d5.loss_cls: 0.4167  decode.d5.loss_mask: 0.2929  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.3967  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.3213  decode.d7.loss_cls: 0.4032  decode.d7.loss_mask: 0.2986  decode.d7.loss_dice: 0.3195  decode.d8.loss_cls: 0.3599  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.3192
09/30 09:35:12 - mmengine - INFO - Iter(train) [  4450/320000]  base_lr: 9.8748e-05 lr: 9.8748e-06  eta: 1 day, 14:00:37  time: 0.4306  data_time: 0.0086  memory: 5180  grad_norm: 93.2541  loss: 13.6291  decode.loss_cls: 0.5445  decode.loss_mask: 0.4421  decode.loss_dice: 0.3492  decode.d0.loss_cls: 1.0814  decode.d0.loss_mask: 0.3390  decode.d0.loss_dice: 0.3459  decode.d1.loss_cls: 0.6959  decode.d1.loss_mask: 0.3447  decode.d1.loss_dice: 0.3399  decode.d2.loss_cls: 0.6994  decode.d2.loss_mask: 0.3574  decode.d2.loss_dice: 0.3443  decode.d3.loss_cls: 0.5862  decode.d3.loss_mask: 0.3510  decode.d3.loss_dice: 0.3421  decode.d4.loss_cls: 0.5901  decode.d4.loss_mask: 0.3590  decode.d4.loss_dice: 0.3498  decode.d5.loss_cls: 0.6296  decode.d5.loss_mask: 0.3818  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.5379  decode.d6.loss_mask: 0.3582  decode.d6.loss_dice: 0.3327  decode.d7.loss_cls: 0.5691  decode.d7.loss_mask: 0.3751  decode.d7.loss_dice: 0.3475  decode.d8.loss_cls: 0.5857  decode.d8.loss_mask: 0.3806  decode.d8.loss_dice: 0.3305
09/30 09:35:34 - mmengine - INFO - Iter(train) [  4500/320000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 1 day, 14:00:08  time: 0.4314  data_time: 0.0085  memory: 5180  grad_norm: 147.3155  loss: 12.9305  decode.loss_cls: 0.4486  decode.loss_mask: 0.4694  decode.loss_dice: 0.3700  decode.d0.loss_cls: 1.1313  decode.d0.loss_mask: 0.3326  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.5528  decode.d1.loss_mask: 0.4004  decode.d1.loss_dice: 0.3261  decode.d2.loss_cls: 0.5404  decode.d2.loss_mask: 0.3714  decode.d2.loss_dice: 0.3233  decode.d3.loss_cls: 0.5308  decode.d3.loss_mask: 0.3753  decode.d3.loss_dice: 0.3241  decode.d4.loss_cls: 0.5179  decode.d4.loss_mask: 0.4340  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.4968  decode.d5.loss_mask: 0.3300  decode.d5.loss_dice: 0.3479  decode.d6.loss_cls: 0.4770  decode.d6.loss_mask: 0.4529  decode.d6.loss_dice: 0.3345  decode.d7.loss_cls: 0.5037  decode.d7.loss_mask: 0.3145  decode.d7.loss_dice: 0.3562  decode.d8.loss_cls: 0.4968  decode.d8.loss_mask: 0.3861  decode.d8.loss_dice: 0.3248
09/30 09:35:56 - mmengine - INFO - Iter(train) [  4550/320000]  base_lr: 9.8720e-05 lr: 9.8720e-06  eta: 1 day, 13:59:52  time: 0.4314  data_time: 0.0087  memory: 5180  grad_norm: 169.9313  loss: 17.3008  decode.loss_cls: 0.8106  decode.loss_mask: 0.5367  decode.loss_dice: 0.3637  decode.d0.loss_cls: 1.4537  decode.d0.loss_mask: 0.4091  decode.d0.loss_dice: 0.3749  decode.d1.loss_cls: 0.9833  decode.d1.loss_mask: 0.4124  decode.d1.loss_dice: 0.3539  decode.d2.loss_cls: 0.7967  decode.d2.loss_mask: 0.4481  decode.d2.loss_dice: 0.3780  decode.d3.loss_cls: 0.7859  decode.d3.loss_mask: 0.5348  decode.d3.loss_dice: 0.4098  decode.d4.loss_cls: 0.8514  decode.d4.loss_mask: 0.4445  decode.d4.loss_dice: 0.3599  decode.d5.loss_cls: 0.7886  decode.d5.loss_mask: 0.4284  decode.d5.loss_dice: 0.3631  decode.d6.loss_cls: 0.7462  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 0.4142  decode.d7.loss_cls: 0.6714  decode.d7.loss_mask: 0.6002  decode.d7.loss_dice: 0.3991  decode.d8.loss_cls: 0.7961  decode.d8.loss_mask: 0.5432  decode.d8.loss_dice: 0.3845
09/30 09:36:17 - mmengine - INFO - Iter(train) [  4600/320000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 1 day, 13:59:23  time: 0.4327  data_time: 0.0089  memory: 5161  grad_norm: 147.1791  loss: 13.6418  decode.loss_cls: 0.6005  decode.loss_mask: 0.3206  decode.loss_dice: 0.3054  decode.d0.loss_cls: 1.2173  decode.d0.loss_mask: 0.3189  decode.d0.loss_dice: 0.3323  decode.d1.loss_cls: 0.7340  decode.d1.loss_mask: 0.3192  decode.d1.loss_dice: 0.3097  decode.d2.loss_cls: 0.6712  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.2938  decode.d3.loss_cls: 0.6389  decode.d3.loss_mask: 0.3113  decode.d3.loss_dice: 0.2975  decode.d4.loss_cls: 0.7215  decode.d4.loss_mask: 0.3274  decode.d4.loss_dice: 0.3284  decode.d5.loss_cls: 0.6952  decode.d5.loss_mask: 0.3513  decode.d5.loss_dice: 0.3303  decode.d6.loss_cls: 0.6273  decode.d6.loss_mask: 0.3344  decode.d6.loss_dice: 0.3366  decode.d7.loss_cls: 0.6543  decode.d7.loss_mask: 0.3286  decode.d7.loss_dice: 0.3200  decode.d8.loss_cls: 0.6717  decode.d8.loss_mask: 0.3210  decode.d8.loss_dice: 0.3039
09/30 09:36:39 - mmengine - INFO - Iter(train) [  4650/320000]  base_lr: 9.8692e-05 lr: 9.8692e-06  eta: 1 day, 13:58:53  time: 0.4301  data_time: 0.0083  memory: 5180  grad_norm: 110.8209  loss: 10.7631  decode.loss_cls: 0.4266  decode.loss_mask: 0.2497  decode.loss_dice: 0.2715  decode.d0.loss_cls: 1.1577  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.2829  decode.d1.loss_cls: 0.5886  decode.d1.loss_mask: 0.2642  decode.d1.loss_dice: 0.2835  decode.d2.loss_cls: 0.4743  decode.d2.loss_mask: 0.2463  decode.d2.loss_dice: 0.2777  decode.d3.loss_cls: 0.4290  decode.d3.loss_mask: 0.2474  decode.d3.loss_dice: 0.2784  decode.d4.loss_cls: 0.4407  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.4955  decode.d5.loss_mask: 0.2389  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.4804  decode.d6.loss_mask: 0.2763  decode.d6.loss_dice: 0.2986  decode.d7.loss_cls: 0.4413  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.2889  decode.d8.loss_cls: 0.4706  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.2680
09/30 09:37:00 - mmengine - INFO - Iter(train) [  4700/320000]  base_lr: 9.8677e-05 lr: 9.8677e-06  eta: 1 day, 13:58:24  time: 0.4311  data_time: 0.0084  memory: 5161  grad_norm: 105.2091  loss: 10.5072  decode.loss_cls: 0.4090  decode.loss_mask: 0.3355  decode.loss_dice: 0.2397  decode.d0.loss_cls: 1.1678  decode.d0.loss_mask: 0.3551  decode.d0.loss_dice: 0.2762  decode.d1.loss_cls: 0.4744  decode.d1.loss_mask: 0.3456  decode.d1.loss_dice: 0.2272  decode.d2.loss_cls: 0.3813  decode.d2.loss_mask: 0.3401  decode.d2.loss_dice: 0.2288  decode.d3.loss_cls: 0.3851  decode.d3.loss_mask: 0.3412  decode.d3.loss_dice: 0.2255  decode.d4.loss_cls: 0.3776  decode.d4.loss_mask: 0.3418  decode.d4.loss_dice: 0.2169  decode.d5.loss_cls: 0.4004  decode.d5.loss_mask: 0.3319  decode.d5.loss_dice: 0.2210  decode.d6.loss_cls: 0.3899  decode.d6.loss_mask: 0.3382  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.3814  decode.d7.loss_mask: 0.3346  decode.d7.loss_dice: 0.2285  decode.d8.loss_cls: 0.3837  decode.d8.loss_mask: 0.3553  decode.d8.loss_dice: 0.2410
09/30 09:37:22 - mmengine - INFO - Iter(train) [  4750/320000]  base_lr: 9.8663e-05 lr: 9.8663e-06  eta: 1 day, 13:57:53  time: 0.4302  data_time: 0.0088  memory: 5180  grad_norm: 113.8551  loss: 10.9800  decode.loss_cls: 0.4405  decode.loss_mask: 0.2927  decode.loss_dice: 0.2595  decode.d0.loss_cls: 1.1307  decode.d0.loss_mask: 0.3019  decode.d0.loss_dice: 0.3162  decode.d1.loss_cls: 0.6028  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.4510  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.2833  decode.d3.loss_cls: 0.4537  decode.d3.loss_mask: 0.2919  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.4378  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.2908  decode.d5.loss_cls: 0.4120  decode.d5.loss_mask: 0.2974  decode.d5.loss_dice: 0.2817  decode.d6.loss_cls: 0.4464  decode.d6.loss_mask: 0.2906  decode.d6.loss_dice: 0.2714  decode.d7.loss_cls: 0.4347  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.2526  decode.d8.loss_cls: 0.4324  decode.d8.loss_mask: 0.2928  decode.d8.loss_dice: 0.2538
09/30 09:37:44 - mmengine - INFO - Iter(train) [  4800/320000]  base_lr: 9.8649e-05 lr: 9.8649e-06  eta: 1 day, 13:57:25  time: 0.4320  data_time: 0.0088  memory: 5180  grad_norm: 166.5702  loss: 10.6259  decode.loss_cls: 0.3872  decode.loss_mask: 0.3172  decode.loss_dice: 0.2426  decode.d0.loss_cls: 1.0243  decode.d0.loss_mask: 0.3529  decode.d0.loss_dice: 0.2819  decode.d1.loss_cls: 0.4289  decode.d1.loss_mask: 0.3678  decode.d1.loss_dice: 0.3032  decode.d2.loss_cls: 0.3448  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.2427  decode.d3.loss_cls: 0.3826  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.2387  decode.d4.loss_cls: 0.4114  decode.d4.loss_mask: 0.3925  decode.d4.loss_dice: 0.2510  decode.d5.loss_cls: 0.3558  decode.d5.loss_mask: 0.3904  decode.d5.loss_dice: 0.2674  decode.d6.loss_cls: 0.3772  decode.d6.loss_mask: 0.3850  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.4441  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.4032  decode.d8.loss_mask: 0.3170  decode.d8.loss_dice: 0.2462
09/30 09:38:05 - mmengine - INFO - Iter(train) [  4850/320000]  base_lr: 9.8635e-05 lr: 9.8635e-06  eta: 1 day, 13:56:53  time: 0.4308  data_time: 0.0089  memory: 5161  grad_norm: 102.4427  loss: 9.9652  decode.loss_cls: 0.3192  decode.loss_mask: 0.2992  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.0064  decode.d0.loss_mask: 0.3087  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.3850  decode.d1.loss_mask: 0.3173  decode.d1.loss_dice: 0.2896  decode.d2.loss_cls: 0.3744  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.3013  decode.d3.loss_cls: 0.2674  decode.d3.loss_mask: 0.3016  decode.d3.loss_dice: 0.2830  decode.d4.loss_cls: 0.3501  decode.d4.loss_mask: 0.2968  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.3305  decode.d5.loss_mask: 0.2937  decode.d5.loss_dice: 0.2843  decode.d6.loss_cls: 0.2971  decode.d6.loss_mask: 0.3012  decode.d6.loss_dice: 0.2925  decode.d7.loss_cls: 0.3462  decode.d7.loss_mask: 0.3030  decode.d7.loss_dice: 0.3009  decode.d8.loss_cls: 0.3367  decode.d8.loss_mask: 0.2998  decode.d8.loss_dice: 0.2908
09/30 09:38:27 - mmengine - INFO - Iter(train) [  4900/320000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 1 day, 13:56:25  time: 0.4314  data_time: 0.0086  memory: 5161  grad_norm: 224.9407  loss: 13.4748  decode.loss_cls: 0.4737  decode.loss_mask: 0.4341  decode.loss_dice: 0.4082  decode.d0.loss_cls: 1.1650  decode.d0.loss_mask: 0.4358  decode.d0.loss_dice: 0.4799  decode.d1.loss_cls: 0.5377  decode.d1.loss_mask: 0.3615  decode.d1.loss_dice: 0.4138  decode.d2.loss_cls: 0.4907  decode.d2.loss_mask: 0.3613  decode.d2.loss_dice: 0.3823  decode.d3.loss_cls: 0.4764  decode.d3.loss_mask: 0.3672  decode.d3.loss_dice: 0.3865  decode.d4.loss_cls: 0.4548  decode.d4.loss_mask: 0.4223  decode.d4.loss_dice: 0.4021  decode.d5.loss_cls: 0.4392  decode.d5.loss_mask: 0.3913  decode.d5.loss_dice: 0.4094  decode.d6.loss_cls: 0.4287  decode.d6.loss_mask: 0.3944  decode.d6.loss_dice: 0.4018  decode.d7.loss_cls: 0.4610  decode.d7.loss_mask: 0.3838  decode.d7.loss_dice: 0.3866  decode.d8.loss_cls: 0.4459  decode.d8.loss_mask: 0.4604  decode.d8.loss_dice: 0.4191
09/30 09:38:48 - mmengine - INFO - Iter(train) [  4950/320000]  base_lr: 9.8607e-05 lr: 9.8607e-06  eta: 1 day, 13:55:57  time: 0.4313  data_time: 0.0087  memory: 5160  grad_norm: 139.3830  loss: 14.7730  decode.loss_cls: 0.5334  decode.loss_mask: 0.4901  decode.loss_dice: 0.3921  decode.d0.loss_cls: 1.1694  decode.d0.loss_mask: 0.3939  decode.d0.loss_dice: 0.4120  decode.d1.loss_cls: 0.6597  decode.d1.loss_mask: 0.3974  decode.d1.loss_dice: 0.3637  decode.d2.loss_cls: 0.6499  decode.d2.loss_mask: 0.4001  decode.d2.loss_dice: 0.3479  decode.d3.loss_cls: 0.6306  decode.d3.loss_mask: 0.4059  decode.d3.loss_dice: 0.3584  decode.d4.loss_cls: 0.6249  decode.d4.loss_mask: 0.4278  decode.d4.loss_dice: 0.3727  decode.d5.loss_cls: 0.5511  decode.d5.loss_mask: 0.4559  decode.d5.loss_dice: 0.3960  decode.d6.loss_cls: 0.6495  decode.d6.loss_mask: 0.4088  decode.d6.loss_dice: 0.3812  decode.d7.loss_cls: 0.5447  decode.d7.loss_mask: 0.5143  decode.d7.loss_dice: 0.3968  decode.d8.loss_cls: 0.5092  decode.d8.loss_mask: 0.5267  decode.d8.loss_dice: 0.4090
09/30 09:39:10 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:39:10 - mmengine - INFO - Iter(train) [  5000/320000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 1 day, 13:55:27  time: 0.4311  data_time: 0.0085  memory: 5161  grad_norm: 118.3962  loss: 10.9059  decode.loss_cls: 0.3542  decode.loss_mask: 0.3422  decode.loss_dice: 0.3059  decode.d0.loss_cls: 1.0821  decode.d0.loss_mask: 0.3562  decode.d0.loss_dice: 0.3422  decode.d1.loss_cls: 0.4252  decode.d1.loss_mask: 0.3395  decode.d1.loss_dice: 0.3122  decode.d2.loss_cls: 0.3786  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.3071  decode.d3.loss_cls: 0.3692  decode.d3.loss_mask: 0.3390  decode.d3.loss_dice: 0.3171  decode.d4.loss_cls: 0.3555  decode.d4.loss_mask: 0.3358  decode.d4.loss_dice: 0.3150  decode.d5.loss_cls: 0.3488  decode.d5.loss_mask: 0.3343  decode.d5.loss_dice: 0.3139  decode.d6.loss_cls: 0.3788  decode.d6.loss_mask: 0.3333  decode.d6.loss_dice: 0.3169  decode.d7.loss_cls: 0.3228  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.3096  decode.d8.loss_cls: 0.3492  decode.d8.loss_mask: 0.3334  decode.d8.loss_dice: 0.3073
09/30 09:39:31 - mmengine - INFO - Iter(train) [  5050/320000]  base_lr: 9.8579e-05 lr: 9.8579e-06  eta: 1 day, 13:54:58  time: 0.4303  data_time: 0.0086  memory: 5145  grad_norm: 208.3550  loss: 15.0646  decode.loss_cls: 0.5696  decode.loss_mask: 0.4816  decode.loss_dice: 0.3181  decode.d0.loss_cls: 1.2870  decode.d0.loss_mask: 0.5219  decode.d0.loss_dice: 0.3856  decode.d1.loss_cls: 0.6310  decode.d1.loss_mask: 0.4996  decode.d1.loss_dice: 0.3401  decode.d2.loss_cls: 0.6770  decode.d2.loss_mask: 0.4661  decode.d2.loss_dice: 0.3178  decode.d3.loss_cls: 0.6241  decode.d3.loss_mask: 0.4739  decode.d3.loss_dice: 0.3213  decode.d4.loss_cls: 0.5972  decode.d4.loss_mask: 0.4874  decode.d4.loss_dice: 0.3300  decode.d5.loss_cls: 0.5773  decode.d5.loss_mask: 0.4944  decode.d5.loss_dice: 0.3272  decode.d6.loss_cls: 0.5801  decode.d6.loss_mask: 0.4993  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.6359  decode.d7.loss_mask: 0.5044  decode.d7.loss_dice: 0.3406  decode.d8.loss_cls: 0.5925  decode.d8.loss_mask: 0.5109  decode.d8.loss_dice: 0.3355
09/30 09:39:53 - mmengine - INFO - Iter(train) [  5100/320000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 1 day, 13:54:28  time: 0.4311  data_time: 0.0086  memory: 5180  grad_norm: 150.9204  loss: 11.9668  decode.loss_cls: 0.3814  decode.loss_mask: 0.3749  decode.loss_dice: 0.3543  decode.d0.loss_cls: 1.0692  decode.d0.loss_mask: 0.3837  decode.d0.loss_dice: 0.3634  decode.d1.loss_cls: 0.4281  decode.d1.loss_mask: 0.3597  decode.d1.loss_dice: 0.3746  decode.d2.loss_cls: 0.4229  decode.d2.loss_mask: 0.3649  decode.d2.loss_dice: 0.3562  decode.d3.loss_cls: 0.4621  decode.d3.loss_mask: 0.3613  decode.d3.loss_dice: 0.3465  decode.d4.loss_cls: 0.3929  decode.d4.loss_mask: 0.3583  decode.d4.loss_dice: 0.3369  decode.d5.loss_cls: 0.4614  decode.d5.loss_mask: 0.3475  decode.d5.loss_dice: 0.3303  decode.d6.loss_cls: 0.4274  decode.d6.loss_mask: 0.3704  decode.d6.loss_dice: 0.3608  decode.d7.loss_cls: 0.3845  decode.d7.loss_mask: 0.3788  decode.d7.loss_dice: 0.3434  decode.d8.loss_cls: 0.3688  decode.d8.loss_mask: 0.3537  decode.d8.loss_dice: 0.3486
09/30 09:40:14 - mmengine - INFO - Iter(train) [  5150/320000]  base_lr: 9.8551e-05 lr: 9.8551e-06  eta: 1 day, 13:53:59  time: 0.4307  data_time: 0.0084  memory: 5161  grad_norm: 128.8098  loss: 15.9376  decode.loss_cls: 0.6766  decode.loss_mask: 0.4227  decode.loss_dice: 0.4177  decode.d0.loss_cls: 1.2721  decode.d0.loss_mask: 0.4362  decode.d0.loss_dice: 0.4886  decode.d1.loss_cls: 0.8058  decode.d1.loss_mask: 0.4146  decode.d1.loss_dice: 0.4098  decode.d2.loss_cls: 0.7978  decode.d2.loss_mask: 0.4142  decode.d2.loss_dice: 0.3735  decode.d3.loss_cls: 0.7456  decode.d3.loss_mask: 0.4012  decode.d3.loss_dice: 0.3915  decode.d4.loss_cls: 0.6688  decode.d4.loss_mask: 0.4106  decode.d4.loss_dice: 0.3614  decode.d5.loss_cls: 0.6716  decode.d5.loss_mask: 0.3804  decode.d5.loss_dice: 0.4555  decode.d6.loss_cls: 0.6770  decode.d6.loss_mask: 0.4563  decode.d6.loss_dice: 0.4054  decode.d7.loss_cls: 0.5744  decode.d7.loss_mask: 0.4388  decode.d7.loss_dice: 0.4527  decode.d8.loss_cls: 0.6498  decode.d8.loss_mask: 0.4223  decode.d8.loss_dice: 0.4448
09/30 09:40:36 - mmengine - INFO - Iter(train) [  5200/320000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 1 day, 13:53:32  time: 0.4314  data_time: 0.0086  memory: 5147  grad_norm: 63.2489  loss: 7.1084  decode.loss_cls: 0.2002  decode.loss_mask: 0.2478  decode.loss_dice: 0.1867  decode.d0.loss_cls: 0.9473  decode.d0.loss_mask: 0.2509  decode.d0.loss_dice: 0.2199  decode.d1.loss_cls: 0.2670  decode.d1.loss_mask: 0.2494  decode.d1.loss_dice: 0.1910  decode.d2.loss_cls: 0.2319  decode.d2.loss_mask: 0.2395  decode.d2.loss_dice: 0.1868  decode.d3.loss_cls: 0.1895  decode.d3.loss_mask: 0.2477  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.1893  decode.d5.loss_cls: 0.1681  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.1833  decode.d6.loss_cls: 0.1866  decode.d6.loss_mask: 0.2425  decode.d6.loss_dice: 0.1855  decode.d7.loss_cls: 0.1763  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.1958  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 0.2457  decode.d8.loss_dice: 0.1884
09/30 09:40:58 - mmengine - INFO - Iter(train) [  5250/320000]  base_lr: 9.8522e-05 lr: 9.8522e-06  eta: 1 day, 13:53:01  time: 0.4307  data_time: 0.0083  memory: 5180  grad_norm: 76.5303  loss: 8.8515  decode.loss_cls: 0.3061  decode.loss_mask: 0.2446  decode.loss_dice: 0.2371  decode.d0.loss_cls: 0.9918  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.2381  decode.d1.loss_cls: 0.4944  decode.d1.loss_mask: 0.2424  decode.d1.loss_dice: 0.2317  decode.d2.loss_cls: 0.4302  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2183  decode.d3.loss_cls: 0.3673  decode.d3.loss_mask: 0.2409  decode.d3.loss_dice: 0.2220  decode.d4.loss_cls: 0.3326  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.2983  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2313  decode.d6.loss_cls: 0.2997  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.2842  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.2324  decode.d8.loss_cls: 0.3081  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2156
09/30 09:41:19 - mmengine - INFO - Iter(train) [  5300/320000]  base_lr: 9.8508e-05 lr: 9.8508e-06  eta: 1 day, 13:52:34  time: 0.4319  data_time: 0.0086  memory: 5180  grad_norm: 130.1269  loss: 13.9682  decode.loss_cls: 0.5096  decode.loss_mask: 0.4093  decode.loss_dice: 0.3305  decode.d0.loss_cls: 1.2532  decode.d0.loss_mask: 0.4347  decode.d0.loss_dice: 0.4240  decode.d1.loss_cls: 0.6684  decode.d1.loss_mask: 0.4163  decode.d1.loss_dice: 0.3522  decode.d2.loss_cls: 0.6136  decode.d2.loss_mask: 0.4109  decode.d2.loss_dice: 0.3201  decode.d3.loss_cls: 0.5479  decode.d3.loss_mask: 0.4119  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 0.5327  decode.d4.loss_mask: 0.4547  decode.d4.loss_dice: 0.3341  decode.d5.loss_cls: 0.5741  decode.d5.loss_mask: 0.4287  decode.d5.loss_dice: 0.3577  decode.d6.loss_cls: 0.5360  decode.d6.loss_mask: 0.4241  decode.d6.loss_dice: 0.3256  decode.d7.loss_cls: 0.4907  decode.d7.loss_mask: 0.4156  decode.d7.loss_dice: 0.3345  decode.d8.loss_cls: 0.5519  decode.d8.loss_mask: 0.4276  decode.d8.loss_dice: 0.3427
09/30 09:41:41 - mmengine - INFO - Iter(train) [  5350/320000]  base_lr: 9.8494e-05 lr: 9.8494e-06  eta: 1 day, 13:52:05  time: 0.4314  data_time: 0.0088  memory: 5161  grad_norm: 137.6695  loss: 16.4424  decode.loss_cls: 0.6712  decode.loss_mask: 0.3681  decode.loss_dice: 0.4940  decode.d0.loss_cls: 1.4114  decode.d0.loss_mask: 0.3798  decode.d0.loss_dice: 0.6013  decode.d1.loss_cls: 0.6443  decode.d1.loss_mask: 0.3680  decode.d1.loss_dice: 0.5164  decode.d2.loss_cls: 0.6841  decode.d2.loss_mask: 0.3621  decode.d2.loss_dice: 0.5018  decode.d3.loss_cls: 0.6874  decode.d3.loss_mask: 0.3563  decode.d3.loss_dice: 0.5311  decode.d4.loss_cls: 0.6928  decode.d4.loss_mask: 0.3848  decode.d4.loss_dice: 0.5302  decode.d5.loss_cls: 0.6937  decode.d5.loss_mask: 0.3709  decode.d5.loss_dice: 0.5287  decode.d6.loss_cls: 0.6753  decode.d6.loss_mask: 0.3927  decode.d6.loss_dice: 0.5456  decode.d7.loss_cls: 0.6033  decode.d7.loss_mask: 0.4056  decode.d7.loss_dice: 0.5454  decode.d8.loss_cls: 0.5768  decode.d8.loss_mask: 0.3934  decode.d8.loss_dice: 0.5259
09/30 09:42:02 - mmengine - INFO - Iter(train) [  5400/320000]  base_lr: 9.8480e-05 lr: 9.8480e-06  eta: 1 day, 13:51:39  time: 0.4313  data_time: 0.0084  memory: 5180  grad_norm: 134.3266  loss: 10.8005  decode.loss_cls: 0.4069  decode.loss_mask: 0.2835  decode.loss_dice: 0.2663  decode.d0.loss_cls: 1.2978  decode.d0.loss_mask: 0.2692  decode.d0.loss_dice: 0.2976  decode.d1.loss_cls: 0.5004  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.3045  decode.d2.loss_cls: 0.4354  decode.d2.loss_mask: 0.2551  decode.d2.loss_dice: 0.2910  decode.d3.loss_cls: 0.3983  decode.d3.loss_mask: 0.2743  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.4669  decode.d4.loss_mask: 0.2875  decode.d4.loss_dice: 0.2894  decode.d5.loss_cls: 0.5403  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.2458  decode.d6.loss_cls: 0.4316  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.2666  decode.d7.loss_cls: 0.3978  decode.d7.loss_mask: 0.2961  decode.d7.loss_dice: 0.2461  decode.d8.loss_cls: 0.4289  decode.d8.loss_mask: 0.2888  decode.d8.loss_dice: 0.2467
09/30 09:42:24 - mmengine - INFO - Iter(train) [  5450/320000]  base_lr: 9.8466e-05 lr: 9.8466e-06  eta: 1 day, 13:51:14  time: 0.4316  data_time: 0.0084  memory: 5161  grad_norm: 202.4819  loss: 10.7974  decode.loss_cls: 0.3326  decode.loss_mask: 0.2937  decode.loss_dice: 0.2727  decode.d0.loss_cls: 1.0718  decode.d0.loss_mask: 0.3058  decode.d0.loss_dice: 0.3343  decode.d1.loss_cls: 0.4939  decode.d1.loss_mask: 0.3450  decode.d1.loss_dice: 0.3083  decode.d2.loss_cls: 0.4505  decode.d2.loss_mask: 0.3190  decode.d2.loss_dice: 0.3191  decode.d3.loss_cls: 0.4068  decode.d3.loss_mask: 0.3240  decode.d3.loss_dice: 0.3415  decode.d4.loss_cls: 0.3675  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.2876  decode.d5.loss_cls: 0.3912  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.2927  decode.d6.loss_cls: 0.3795  decode.d6.loss_mask: 0.3141  decode.d6.loss_dice: 0.2959  decode.d7.loss_cls: 0.3359  decode.d7.loss_mask: 0.3307  decode.d7.loss_dice: 0.3072  decode.d8.loss_cls: 0.3192  decode.d8.loss_mask: 0.3488  decode.d8.loss_dice: 0.2945
09/30 09:42:45 - mmengine - INFO - Iter(train) [  5500/320000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 1 day, 13:50:48  time: 0.4324  data_time: 0.0089  memory: 5160  grad_norm: 246.3889  loss: 14.0435  decode.loss_cls: 0.7489  decode.loss_mask: 0.4087  decode.loss_dice: 0.2942  decode.d0.loss_cls: 1.1305  decode.d0.loss_mask: 0.3688  decode.d0.loss_dice: 0.3000  decode.d1.loss_cls: 0.8447  decode.d1.loss_mask: 0.3591  decode.d1.loss_dice: 0.2668  decode.d2.loss_cls: 0.7062  decode.d2.loss_mask: 0.3482  decode.d2.loss_dice: 0.2349  decode.d3.loss_cls: 0.7153  decode.d3.loss_mask: 0.3234  decode.d3.loss_dice: 0.2370  decode.d4.loss_cls: 0.7585  decode.d4.loss_mask: 0.3304  decode.d4.loss_dice: 0.2540  decode.d5.loss_cls: 0.6834  decode.d5.loss_mask: 0.3820  decode.d5.loss_dice: 0.2527  decode.d6.loss_cls: 0.7520  decode.d6.loss_mask: 0.3335  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.7231  decode.d7.loss_mask: 0.3805  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.7632  decode.d8.loss_mask: 0.3596  decode.d8.loss_dice: 0.2663
09/30 09:43:07 - mmengine - INFO - Iter(train) [  5550/320000]  base_lr: 9.8438e-05 lr: 9.8438e-06  eta: 1 day, 13:50:22  time: 0.4308  data_time: 0.0084  memory: 5147  grad_norm: 180.1155  loss: 13.1373  decode.loss_cls: 0.5869  decode.loss_mask: 0.3221  decode.loss_dice: 0.3383  decode.d0.loss_cls: 1.2573  decode.d0.loss_mask: 0.3166  decode.d0.loss_dice: 0.3650  decode.d1.loss_cls: 0.6401  decode.d1.loss_mask: 0.3181  decode.d1.loss_dice: 0.3328  decode.d2.loss_cls: 0.5747  decode.d2.loss_mask: 0.3120  decode.d2.loss_dice: 0.3083  decode.d3.loss_cls: 0.6036  decode.d3.loss_mask: 0.3163  decode.d3.loss_dice: 0.3230  decode.d4.loss_cls: 0.6036  decode.d4.loss_mask: 0.3128  decode.d4.loss_dice: 0.3179  decode.d5.loss_cls: 0.5976  decode.d5.loss_mask: 0.3130  decode.d5.loss_dice: 0.3286  decode.d6.loss_cls: 0.6096  decode.d6.loss_mask: 0.3142  decode.d6.loss_dice: 0.3319  decode.d7.loss_cls: 0.5951  decode.d7.loss_mask: 0.3140  decode.d7.loss_dice: 0.3277  decode.d8.loss_cls: 0.6203  decode.d8.loss_mask: 0.3151  decode.d8.loss_dice: 0.3208
09/30 09:43:29 - mmengine - INFO - Iter(train) [  5600/320000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 1 day, 13:49:57  time: 0.4321  data_time: 0.0086  memory: 5160  grad_norm: 131.6579  loss: 11.1711  decode.loss_cls: 0.3294  decode.loss_mask: 0.2862  decode.loss_dice: 0.2988  decode.d0.loss_cls: 1.1760  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.3396  decode.d1.loss_cls: 0.5700  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3118  decode.d2.loss_cls: 0.4586  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.3166  decode.d3.loss_cls: 0.4719  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.4787  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.2943  decode.d5.loss_cls: 0.4322  decode.d5.loss_mask: 0.2880  decode.d5.loss_dice: 0.2970  decode.d6.loss_cls: 0.4602  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.3272  decode.d7.loss_cls: 0.4331  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.3116  decode.d8.loss_cls: 0.3635  decode.d8.loss_mask: 0.2864  decode.d8.loss_dice: 0.3048
09/30 09:43:50 - mmengine - INFO - Iter(train) [  5650/320000]  base_lr: 9.8410e-05 lr: 9.8410e-06  eta: 1 day, 13:49:32  time: 0.4322  data_time: 0.0088  memory: 5147  grad_norm: 414.8088  loss: 17.7980  decode.loss_cls: 0.5932  decode.loss_mask: 0.5354  decode.loss_dice: 0.5892  decode.d0.loss_cls: 1.2954  decode.d0.loss_mask: 0.5297  decode.d0.loss_dice: 0.5447  decode.d1.loss_cls: 0.6323  decode.d1.loss_mask: 0.5287  decode.d1.loss_dice: 0.5099  decode.d2.loss_cls: 0.7236  decode.d2.loss_mask: 0.5071  decode.d2.loss_dice: 0.5055  decode.d3.loss_cls: 0.6601  decode.d3.loss_mask: 0.5429  decode.d3.loss_dice: 0.5116  decode.d4.loss_cls: 0.6180  decode.d4.loss_mask: 0.5895  decode.d4.loss_dice: 0.4803  decode.d5.loss_cls: 0.6300  decode.d5.loss_mask: 0.6035  decode.d5.loss_dice: 0.4832  decode.d6.loss_cls: 0.5762  decode.d6.loss_mask: 0.6340  decode.d6.loss_dice: 0.5478  decode.d7.loss_cls: 0.5402  decode.d7.loss_mask: 0.6144  decode.d7.loss_dice: 0.5396  decode.d8.loss_cls: 0.5772  decode.d8.loss_mask: 0.5869  decode.d8.loss_dice: 0.5679
09/30 09:44:12 - mmengine - INFO - Iter(train) [  5700/320000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 1 day, 13:49:05  time: 0.4308  data_time: 0.0083  memory: 5180  grad_norm: 136.4175  loss: 12.3492  decode.loss_cls: 0.5541  decode.loss_mask: 0.3322  decode.loss_dice: 0.3381  decode.d0.loss_cls: 1.0454  decode.d0.loss_mask: 0.3216  decode.d0.loss_dice: 0.3231  decode.d1.loss_cls: 0.5880  decode.d1.loss_mask: 0.3130  decode.d1.loss_dice: 0.3035  decode.d2.loss_cls: 0.5545  decode.d2.loss_mask: 0.3347  decode.d2.loss_dice: 0.3067  decode.d3.loss_cls: 0.5377  decode.d3.loss_mask: 0.3317  decode.d3.loss_dice: 0.3125  decode.d4.loss_cls: 0.5370  decode.d4.loss_mask: 0.3062  decode.d4.loss_dice: 0.3065  decode.d5.loss_cls: 0.4790  decode.d5.loss_mask: 0.3095  decode.d5.loss_dice: 0.3138  decode.d6.loss_cls: 0.5773  decode.d6.loss_mask: 0.3359  decode.d6.loss_dice: 0.3323  decode.d7.loss_cls: 0.5577  decode.d7.loss_mask: 0.3235  decode.d7.loss_dice: 0.3085  decode.d8.loss_cls: 0.5479  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.3104
09/30 09:44:33 - mmengine - INFO - Iter(train) [  5750/320000]  base_lr: 9.8382e-05 lr: 9.8382e-06  eta: 1 day, 13:48:39  time: 0.4327  data_time: 0.0088  memory: 5180  grad_norm: 105.4045  loss: 11.2715  decode.loss_cls: 0.4459  decode.loss_mask: 0.2937  decode.loss_dice: 0.2645  decode.d0.loss_cls: 1.2879  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.2431  decode.d1.loss_cls: 0.5240  decode.d1.loss_mask: 0.3114  decode.d1.loss_dice: 0.2576  decode.d2.loss_cls: 0.4737  decode.d2.loss_mask: 0.2923  decode.d2.loss_dice: 0.2457  decode.d3.loss_cls: 0.4344  decode.d3.loss_mask: 0.3466  decode.d3.loss_dice: 0.2436  decode.d4.loss_cls: 0.4892  decode.d4.loss_mask: 0.3136  decode.d4.loss_dice: 0.2406  decode.d5.loss_cls: 0.4368  decode.d5.loss_mask: 0.3348  decode.d5.loss_dice: 0.2465  decode.d6.loss_cls: 0.5410  decode.d6.loss_mask: 0.3122  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.5341  decode.d7.loss_mask: 0.3256  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.4970  decode.d8.loss_mask: 0.3202  decode.d8.loss_dice: 0.2443
09/30 09:44:55 - mmengine - INFO - Iter(train) [  5800/320000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 1 day, 13:48:11  time: 0.4303  data_time: 0.0085  memory: 5180  grad_norm: 76.6728  loss: 11.2290  decode.loss_cls: 0.3751  decode.loss_mask: 0.3765  decode.loss_dice: 0.3095  decode.d0.loss_cls: 1.1343  decode.d0.loss_mask: 0.3812  decode.d0.loss_dice: 0.3417  decode.d1.loss_cls: 0.4308  decode.d1.loss_mask: 0.3279  decode.d1.loss_dice: 0.2706  decode.d2.loss_cls: 0.4006  decode.d2.loss_mask: 0.3411  decode.d2.loss_dice: 0.2802  decode.d3.loss_cls: 0.4168  decode.d3.loss_mask: 0.3628  decode.d3.loss_dice: 0.3039  decode.d4.loss_cls: 0.3983  decode.d4.loss_mask: 0.3783  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.3687  decode.d5.loss_mask: 0.3398  decode.d5.loss_dice: 0.2930  decode.d6.loss_cls: 0.3920  decode.d6.loss_mask: 0.3227  decode.d6.loss_dice: 0.2947  decode.d7.loss_cls: 0.3747  decode.d7.loss_mask: 0.3338  decode.d7.loss_dice: 0.2940  decode.d8.loss_cls: 0.4613  decode.d8.loss_mask: 0.3411  decode.d8.loss_dice: 0.2955
09/30 09:45:17 - mmengine - INFO - Iter(train) [  5850/320000]  base_lr: 9.8353e-05 lr: 9.8353e-06  eta: 1 day, 13:47:46  time: 0.4317  data_time: 0.0085  memory: 5161  grad_norm: 145.4820  loss: 15.1146  decode.loss_cls: 0.6805  decode.loss_mask: 0.3831  decode.loss_dice: 0.3490  decode.d0.loss_cls: 1.3751  decode.d0.loss_mask: 0.4107  decode.d0.loss_dice: 0.4035  decode.d1.loss_cls: 0.7370  decode.d1.loss_mask: 0.3865  decode.d1.loss_dice: 0.3640  decode.d2.loss_cls: 0.7127  decode.d2.loss_mask: 0.3864  decode.d2.loss_dice: 0.3529  decode.d3.loss_cls: 0.7183  decode.d3.loss_mask: 0.3958  decode.d3.loss_dice: 0.3608  decode.d4.loss_cls: 0.6652  decode.d4.loss_mask: 0.4170  decode.d4.loss_dice: 0.3779  decode.d5.loss_cls: 0.6760  decode.d5.loss_mask: 0.3915  decode.d5.loss_dice: 0.3605  decode.d6.loss_cls: 0.6260  decode.d6.loss_mask: 0.3904  decode.d6.loss_dice: 0.3645  decode.d7.loss_cls: 0.6544  decode.d7.loss_mask: 0.3954  decode.d7.loss_dice: 0.3362  decode.d8.loss_cls: 0.7065  decode.d8.loss_mask: 0.3922  decode.d8.loss_dice: 0.3444
09/30 09:45:38 - mmengine - INFO - Iter(train) [  5900/320000]  base_lr: 9.8339e-05 lr: 9.8339e-06  eta: 1 day, 13:47:21  time: 0.4325  data_time: 0.0088  memory: 5147  grad_norm: 115.8059  loss: 13.7664  decode.loss_cls: 0.6180  decode.loss_mask: 0.4143  decode.loss_dice: 0.3505  decode.d0.loss_cls: 1.2047  decode.d0.loss_mask: 0.4020  decode.d0.loss_dice: 0.3760  decode.d1.loss_cls: 0.5772  decode.d1.loss_mask: 0.3916  decode.d1.loss_dice: 0.3380  decode.d2.loss_cls: 0.6750  decode.d2.loss_mask: 0.3874  decode.d2.loss_dice: 0.3346  decode.d3.loss_cls: 0.5034  decode.d3.loss_mask: 0.3868  decode.d3.loss_dice: 0.3413  decode.d4.loss_cls: 0.5432  decode.d4.loss_mask: 0.3908  decode.d4.loss_dice: 0.3449  decode.d5.loss_cls: 0.5298  decode.d5.loss_mask: 0.3932  decode.d5.loss_dice: 0.3404  decode.d6.loss_cls: 0.5418  decode.d6.loss_mask: 0.4004  decode.d6.loss_dice: 0.3299  decode.d7.loss_cls: 0.5680  decode.d7.loss_mask: 0.4013  decode.d7.loss_dice: 0.3420  decode.d8.loss_cls: 0.5825  decode.d8.loss_mask: 0.4119  decode.d8.loss_dice: 0.3455
09/30 09:46:00 - mmengine - INFO - Iter(train) [  5950/320000]  base_lr: 9.8325e-05 lr: 9.8325e-06  eta: 1 day, 13:46:55  time: 0.4305  data_time: 0.0087  memory: 5147  grad_norm: 83.6968  loss: 11.5326  decode.loss_cls: 0.4911  decode.loss_mask: 0.3133  decode.loss_dice: 0.2731  decode.d0.loss_cls: 1.1223  decode.d0.loss_mask: 0.3526  decode.d0.loss_dice: 0.3107  decode.d1.loss_cls: 0.5404  decode.d1.loss_mask: 0.3331  decode.d1.loss_dice: 0.2611  decode.d2.loss_cls: 0.5112  decode.d2.loss_mask: 0.3291  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.4333  decode.d3.loss_mask: 0.3223  decode.d3.loss_dice: 0.2816  decode.d4.loss_cls: 0.5366  decode.d4.loss_mask: 0.3190  decode.d4.loss_dice: 0.2750  decode.d5.loss_cls: 0.4314  decode.d5.loss_mask: 0.3177  decode.d5.loss_dice: 0.2940  decode.d6.loss_cls: 0.4754  decode.d6.loss_mask: 0.3102  decode.d6.loss_dice: 0.2766  decode.d7.loss_cls: 0.5000  decode.d7.loss_mask: 0.3073  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.5111  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.2620
09/30 09:46:21 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:46:21 - mmengine - INFO - Iter(train) [  6000/320000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 1 day, 13:46:31  time: 0.4315  data_time: 0.0087  memory: 5161  grad_norm: 145.3175  loss: 9.8418  decode.loss_cls: 0.3233  decode.loss_mask: 0.3618  decode.loss_dice: 0.2862  decode.d0.loss_cls: 0.9600  decode.d0.loss_mask: 0.3429  decode.d0.loss_dice: 0.2945  decode.d1.loss_cls: 0.3544  decode.d1.loss_mask: 0.3243  decode.d1.loss_dice: 0.2624  decode.d2.loss_cls: 0.2891  decode.d2.loss_mask: 0.3199  decode.d2.loss_dice: 0.2411  decode.d3.loss_cls: 0.2836  decode.d3.loss_mask: 0.3322  decode.d3.loss_dice: 0.2597  decode.d4.loss_cls: 0.3328  decode.d4.loss_mask: 0.3248  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.3646  decode.d5.loss_mask: 0.3185  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.3365  decode.d6.loss_mask: 0.3092  decode.d6.loss_dice: 0.2278  decode.d7.loss_cls: 0.4144  decode.d7.loss_mask: 0.3170  decode.d7.loss_dice: 0.2413  decode.d8.loss_cls: 0.3992  decode.d8.loss_mask: 0.3105  decode.d8.loss_dice: 0.2362
09/30 09:46:43 - mmengine - INFO - Iter(train) [  6050/320000]  base_lr: 9.8297e-05 lr: 9.8297e-06  eta: 1 day, 13:46:04  time: 0.4314  data_time: 0.0088  memory: 5161  grad_norm: 53.4686  loss: 8.0178  decode.loss_cls: 0.2337  decode.loss_mask: 0.2766  decode.loss_dice: 0.2118  decode.d0.loss_cls: 0.9437  decode.d0.loss_mask: 0.2757  decode.d0.loss_dice: 0.2208  decode.d1.loss_cls: 0.2566  decode.d1.loss_mask: 0.2725  decode.d1.loss_dice: 0.2052  decode.d2.loss_cls: 0.2662  decode.d2.loss_mask: 0.2793  decode.d2.loss_dice: 0.2148  decode.d3.loss_cls: 0.2226  decode.d3.loss_mask: 0.2808  decode.d3.loss_dice: 0.2174  decode.d4.loss_cls: 0.2220  decode.d4.loss_mask: 0.2761  decode.d4.loss_dice: 0.2136  decode.d5.loss_cls: 0.2264  decode.d5.loss_mask: 0.2755  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.1968  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.2246  decode.d7.loss_cls: 0.2477  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.2639  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.2133
09/30 09:47:04 - mmengine - INFO - Iter(train) [  6100/320000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 1 day, 13:45:38  time: 0.4310  data_time: 0.0089  memory: 5161  grad_norm: 127.5403  loss: 10.7678  decode.loss_cls: 0.2060  decode.loss_mask: 0.3228  decode.loss_dice: 0.3576  decode.d0.loss_cls: 1.0330  decode.d0.loss_mask: 0.3293  decode.d0.loss_dice: 0.3614  decode.d1.loss_cls: 0.3681  decode.d1.loss_mask: 0.3276  decode.d1.loss_dice: 0.3579  decode.d2.loss_cls: 0.4147  decode.d2.loss_mask: 0.3241  decode.d2.loss_dice: 0.3476  decode.d3.loss_cls: 0.4176  decode.d3.loss_mask: 0.3204  decode.d3.loss_dice: 0.3291  decode.d4.loss_cls: 0.4290  decode.d4.loss_mask: 0.3184  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.3517  decode.d5.loss_mask: 0.3243  decode.d5.loss_dice: 0.3485  decode.d6.loss_cls: 0.2827  decode.d6.loss_mask: 0.3252  decode.d6.loss_dice: 0.3644  decode.d7.loss_cls: 0.2926  decode.d7.loss_mask: 0.3217  decode.d7.loss_dice: 0.3345  decode.d8.loss_cls: 0.2722  decode.d8.loss_mask: 0.3208  decode.d8.loss_dice: 0.3442
09/30 09:47:26 - mmengine - INFO - Iter(train) [  6150/320000]  base_lr: 9.8269e-05 lr: 9.8269e-06  eta: 1 day, 13:45:12  time: 0.4322  data_time: 0.0089  memory: 5161  grad_norm: 162.8263  loss: 12.9645  decode.loss_cls: 0.5925  decode.loss_mask: 0.3169  decode.loss_dice: 0.2800  decode.d0.loss_cls: 1.3549  decode.d0.loss_mask: 0.3494  decode.d0.loss_dice: 0.3770  decode.d1.loss_cls: 0.6438  decode.d1.loss_mask: 0.3299  decode.d1.loss_dice: 0.2977  decode.d2.loss_cls: 0.5686  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.3014  decode.d3.loss_cls: 0.5911  decode.d3.loss_mask: 0.3345  decode.d3.loss_dice: 0.3115  decode.d4.loss_cls: 0.5080  decode.d4.loss_mask: 0.3215  decode.d4.loss_dice: 0.2909  decode.d5.loss_cls: 0.5511  decode.d5.loss_mask: 0.3112  decode.d5.loss_dice: 0.2981  decode.d6.loss_cls: 0.6181  decode.d6.loss_mask: 0.3087  decode.d6.loss_dice: 0.2859  decode.d7.loss_cls: 0.5771  decode.d7.loss_mask: 0.3348  decode.d7.loss_dice: 0.3497  decode.d8.loss_cls: 0.5613  decode.d8.loss_mask: 0.3586  decode.d8.loss_dice: 0.3211
09/30 09:47:48 - mmengine - INFO - Iter(train) [  6200/320000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 1 day, 13:44:55  time: 0.4306  data_time: 0.0090  memory: 5180  grad_norm: 65.7736  loss: 9.5850  decode.loss_cls: 0.4217  decode.loss_mask: 0.2972  decode.loss_dice: 0.2136  decode.d0.loss_cls: 0.9823  decode.d0.loss_mask: 0.3064  decode.d0.loss_dice: 0.2281  decode.d1.loss_cls: 0.4358  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.3676  decode.d2.loss_mask: 0.2949  decode.d2.loss_dice: 0.2146  decode.d3.loss_cls: 0.3288  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.2092  decode.d4.loss_cls: 0.3438  decode.d4.loss_mask: 0.2937  decode.d4.loss_dice: 0.2167  decode.d5.loss_cls: 0.4127  decode.d5.loss_mask: 0.2994  decode.d5.loss_dice: 0.2180  decode.d6.loss_cls: 0.3866  decode.d6.loss_mask: 0.3033  decode.d6.loss_dice: 0.2147  decode.d7.loss_cls: 0.3942  decode.d7.loss_mask: 0.2953  decode.d7.loss_dice: 0.2133  decode.d8.loss_cls: 0.3751  decode.d8.loss_mask: 0.2941  decode.d8.loss_dice: 0.2182
09/30 09:48:09 - mmengine - INFO - Iter(train) [  6250/320000]  base_lr: 9.8241e-05 lr: 9.8241e-06  eta: 1 day, 13:44:30  time: 0.4317  data_time: 0.0089  memory: 5161  grad_norm: 127.9812  loss: 9.1581  decode.loss_cls: 0.2673  decode.loss_mask: 0.2701  decode.loss_dice: 0.2262  decode.d0.loss_cls: 0.9351  decode.d0.loss_mask: 0.2977  decode.d0.loss_dice: 0.2738  decode.d1.loss_cls: 0.3617  decode.d1.loss_mask: 0.2865  decode.d1.loss_dice: 0.2386  decode.d2.loss_cls: 0.3780  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.2333  decode.d3.loss_cls: 0.2211  decode.d3.loss_mask: 0.3979  decode.d3.loss_dice: 0.2443  decode.d4.loss_cls: 0.2774  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.2047  decode.d5.loss_mask: 0.3885  decode.d5.loss_dice: 0.2476  decode.d6.loss_cls: 0.2266  decode.d6.loss_mask: 0.3860  decode.d6.loss_dice: 0.2497  decode.d7.loss_cls: 0.2248  decode.d7.loss_mask: 0.3888  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.2094  decode.d8.loss_mask: 0.3913  decode.d8.loss_dice: 0.2573
09/30 09:48:31 - mmengine - INFO - Iter(train) [  6300/320000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 1 day, 13:44:05  time: 0.4326  data_time: 0.0091  memory: 5161  grad_norm: 262.0398  loss: 13.3340  decode.loss_cls: 0.4546  decode.loss_mask: 0.3939  decode.loss_dice: 0.3758  decode.d0.loss_cls: 1.1966  decode.d0.loss_mask: 0.4272  decode.d0.loss_dice: 0.4353  decode.d1.loss_cls: 0.5643  decode.d1.loss_mask: 0.3962  decode.d1.loss_dice: 0.3882  decode.d2.loss_cls: 0.4577  decode.d2.loss_mask: 0.3814  decode.d2.loss_dice: 0.3592  decode.d3.loss_cls: 0.4254  decode.d3.loss_mask: 0.3910  decode.d3.loss_dice: 0.3885  decode.d4.loss_cls: 0.4451  decode.d4.loss_mask: 0.4254  decode.d4.loss_dice: 0.4016  decode.d5.loss_cls: 0.4716  decode.d5.loss_mask: 0.3927  decode.d5.loss_dice: 0.3931  decode.d6.loss_cls: 0.4311  decode.d6.loss_mask: 0.4025  decode.d6.loss_dice: 0.4085  decode.d7.loss_cls: 0.3953  decode.d7.loss_mask: 0.4134  decode.d7.loss_dice: 0.4230  decode.d8.loss_cls: 0.4739  decode.d8.loss_mask: 0.4041  decode.d8.loss_dice: 0.4175
09/30 09:48:52 - mmengine - INFO - Iter(train) [  6350/320000]  base_lr: 9.8213e-05 lr: 9.8213e-06  eta: 1 day, 13:43:39  time: 0.4310  data_time: 0.0089  memory: 5161  grad_norm: 66.4563  loss: 9.2992  decode.loss_cls: 0.2631  decode.loss_mask: 0.2785  decode.loss_dice: 0.2739  decode.d0.loss_cls: 1.0334  decode.d0.loss_mask: 0.2873  decode.d0.loss_dice: 0.3085  decode.d1.loss_cls: 0.4045  decode.d1.loss_mask: 0.2801  decode.d1.loss_dice: 0.2777  decode.d2.loss_cls: 0.2660  decode.d2.loss_mask: 0.2782  decode.d2.loss_dice: 0.2726  decode.d3.loss_cls: 0.2906  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.2688  decode.d4.loss_cls: 0.3177  decode.d4.loss_mask: 0.2802  decode.d4.loss_dice: 0.2875  decode.d5.loss_cls: 0.2951  decode.d5.loss_mask: 0.2842  decode.d5.loss_dice: 0.2815  decode.d6.loss_cls: 0.3390  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.2781  decode.d7.loss_cls: 0.2564  decode.d7.loss_mask: 0.2764  decode.d7.loss_dice: 0.2832  decode.d8.loss_cls: 0.2344  decode.d8.loss_mask: 0.2748  decode.d8.loss_dice: 0.2702
09/30 09:49:14 - mmengine - INFO - Iter(train) [  6400/320000]  base_lr: 9.8198e-05 lr: 9.8198e-06  eta: 1 day, 13:43:14  time: 0.4312  data_time: 0.0089  memory: 5160  grad_norm: 167.7359  loss: 12.2773  decode.loss_cls: 0.4658  decode.loss_mask: 0.3886  decode.loss_dice: 0.2923  decode.d0.loss_cls: 1.1538  decode.d0.loss_mask: 0.3738  decode.d0.loss_dice: 0.2821  decode.d1.loss_cls: 0.5694  decode.d1.loss_mask: 0.3930  decode.d1.loss_dice: 0.3233  decode.d2.loss_cls: 0.5645  decode.d2.loss_mask: 0.3685  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.4499  decode.d3.loss_mask: 0.3890  decode.d3.loss_dice: 0.3227  decode.d4.loss_cls: 0.4563  decode.d4.loss_mask: 0.3993  decode.d4.loss_dice: 0.3033  decode.d5.loss_cls: 0.4647  decode.d5.loss_mask: 0.3866  decode.d5.loss_dice: 0.3086  decode.d6.loss_cls: 0.4865  decode.d6.loss_mask: 0.3273  decode.d6.loss_dice: 0.2863  decode.d7.loss_cls: 0.4696  decode.d7.loss_mask: 0.3462  decode.d7.loss_dice: 0.3042  decode.d8.loss_cls: 0.4762  decode.d8.loss_mask: 0.3707  decode.d8.loss_dice: 0.2675
09/30 09:49:36 - mmengine - INFO - Iter(train) [  6450/320000]  base_lr: 9.8184e-05 lr: 9.8184e-06  eta: 1 day, 13:42:49  time: 0.4313  data_time: 0.0089  memory: 5160  grad_norm: 100.7800  loss: 8.7326  decode.loss_cls: 0.2915  decode.loss_mask: 0.2833  decode.loss_dice: 0.2229  decode.d0.loss_cls: 1.0441  decode.d0.loss_mask: 0.2932  decode.d0.loss_dice: 0.2495  decode.d1.loss_cls: 0.3069  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.3103  decode.d2.loss_mask: 0.2826  decode.d2.loss_dice: 0.2247  decode.d3.loss_cls: 0.3082  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.2273  decode.d4.loss_cls: 0.2610  decode.d4.loss_mask: 0.2758  decode.d4.loss_dice: 0.2315  decode.d5.loss_cls: 0.3057  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.2212  decode.d6.loss_cls: 0.2743  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.2822  decode.d7.loss_mask: 0.2850  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.2762  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.2187
09/30 09:49:57 - mmengine - INFO - Iter(train) [  6500/320000]  base_lr: 9.8170e-05 lr: 9.8170e-06  eta: 1 day, 13:42:23  time: 0.4308  data_time: 0.0087  memory: 5180  grad_norm: 129.3610  loss: 11.8732  decode.loss_cls: 0.4940  decode.loss_mask: 0.2961  decode.loss_dice: 0.3016  decode.d0.loss_cls: 1.2622  decode.d0.loss_mask: 0.2825  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.5308  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.5065  decode.d2.loss_mask: 0.2588  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.5244  decode.d3.loss_mask: 0.2714  decode.d3.loss_dice: 0.3108  decode.d4.loss_cls: 0.5156  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.3404  decode.d5.loss_cls: 0.4771  decode.d5.loss_mask: 0.3519  decode.d5.loss_dice: 0.3286  decode.d6.loss_cls: 0.5501  decode.d6.loss_mask: 0.3116  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.5394  decode.d7.loss_mask: 0.3001  decode.d7.loss_dice: 0.3072  decode.d8.loss_cls: 0.4994  decode.d8.loss_mask: 0.3156  decode.d8.loss_dice: 0.3003
09/30 09:50:19 - mmengine - INFO - Iter(train) [  6550/320000]  base_lr: 9.8156e-05 lr: 9.8156e-06  eta: 1 day, 13:41:58  time: 0.4315  data_time: 0.0089  memory: 5180  grad_norm: 221.6001  loss: 14.8832  decode.loss_cls: 0.6006  decode.loss_mask: 0.4039  decode.loss_dice: 0.3675  decode.d0.loss_cls: 1.2144  decode.d0.loss_mask: 0.4094  decode.d0.loss_dice: 0.4019  decode.d1.loss_cls: 0.7311  decode.d1.loss_mask: 0.4182  decode.d1.loss_dice: 0.3948  decode.d2.loss_cls: 0.6158  decode.d2.loss_mask: 0.4268  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 0.5863  decode.d3.loss_mask: 0.4064  decode.d3.loss_dice: 0.3710  decode.d4.loss_cls: 0.6116  decode.d4.loss_mask: 0.4228  decode.d4.loss_dice: 0.3793  decode.d5.loss_cls: 0.6445  decode.d5.loss_mask: 0.3890  decode.d5.loss_dice: 0.3849  decode.d6.loss_cls: 0.6258  decode.d6.loss_mask: 0.4084  decode.d6.loss_dice: 0.3727  decode.d7.loss_cls: 0.6145  decode.d7.loss_mask: 0.4029  decode.d7.loss_dice: 0.3925  decode.d8.loss_cls: 0.6937  decode.d8.loss_mask: 0.4117  decode.d8.loss_dice: 0.3908
09/30 09:50:40 - mmengine - INFO - Iter(train) [  6600/320000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 1 day, 13:41:33  time: 0.4323  data_time: 0.0087  memory: 5161  grad_norm: 62.7527  loss: 10.9258  decode.loss_cls: 0.3856  decode.loss_mask: 0.2696  decode.loss_dice: 0.2930  decode.d0.loss_cls: 1.1836  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.3168  decode.d1.loss_cls: 0.5481  decode.d1.loss_mask: 0.2782  decode.d1.loss_dice: 0.3089  decode.d2.loss_cls: 0.4510  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.2754  decode.d3.loss_cls: 0.4309  decode.d3.loss_mask: 0.3069  decode.d3.loss_dice: 0.2901  decode.d4.loss_cls: 0.4352  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.3056  decode.d5.loss_cls: 0.4247  decode.d5.loss_mask: 0.2840  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.3967  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.2829  decode.d7.loss_cls: 0.4288  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.2875  decode.d8.loss_cls: 0.4164  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.2985
09/30 09:51:02 - mmengine - INFO - Iter(train) [  6650/320000]  base_lr: 9.8128e-05 lr: 9.8128e-06  eta: 1 day, 13:41:08  time: 0.4316  data_time: 0.0088  memory: 5179  grad_norm: 148.5881  loss: 10.5330  decode.loss_cls: 0.3636  decode.loss_mask: 0.3099  decode.loss_dice: 0.2611  decode.d0.loss_cls: 1.1232  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.2503  decode.d1.loss_cls: 0.4848  decode.d1.loss_mask: 0.3017  decode.d1.loss_dice: 0.2370  decode.d2.loss_cls: 0.3607  decode.d2.loss_mask: 0.3062  decode.d2.loss_dice: 0.2416  decode.d3.loss_cls: 0.4257  decode.d3.loss_mask: 0.3018  decode.d3.loss_dice: 0.2366  decode.d4.loss_cls: 0.4592  decode.d4.loss_mask: 0.3082  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.4278  decode.d5.loss_mask: 0.3155  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.4349  decode.d6.loss_mask: 0.3261  decode.d6.loss_dice: 0.2576  decode.d7.loss_cls: 0.4333  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.2599  decode.d8.loss_cls: 0.3800  decode.d8.loss_mask: 0.3188  decode.d8.loss_dice: 0.2616
09/30 09:51:24 - mmengine - INFO - Iter(train) [  6700/320000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 1 day, 13:40:43  time: 0.4310  data_time: 0.0088  memory: 5146  grad_norm: 65.5738  loss: 8.8802  decode.loss_cls: 0.2194  decode.loss_mask: 0.2848  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.0540  decode.d0.loss_mask: 0.2897  decode.d0.loss_dice: 0.2705  decode.d1.loss_cls: 0.3182  decode.d1.loss_mask: 0.2842  decode.d1.loss_dice: 0.2851  decode.d2.loss_cls: 0.2652  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.2729  decode.d3.loss_cls: 0.2658  decode.d3.loss_mask: 0.2860  decode.d3.loss_dice: 0.2724  decode.d4.loss_cls: 0.2776  decode.d4.loss_mask: 0.2827  decode.d4.loss_dice: 0.2629  decode.d5.loss_cls: 0.2343  decode.d5.loss_mask: 0.2813  decode.d5.loss_dice: 0.2649  decode.d6.loss_cls: 0.2293  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.2712  decode.d7.loss_cls: 0.2171  decode.d7.loss_mask: 0.2789  decode.d7.loss_dice: 0.2635  decode.d8.loss_cls: 0.2811  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.2497
09/30 09:51:45 - mmengine - INFO - Iter(train) [  6750/320000]  base_lr: 9.8100e-05 lr: 9.8100e-06  eta: 1 day, 13:40:19  time: 0.4317  data_time: 0.0089  memory: 5161  grad_norm: 102.9873  loss: 12.9235  decode.loss_cls: 0.5351  decode.loss_mask: 0.3177  decode.loss_dice: 0.2966  decode.d0.loss_cls: 1.1421  decode.d0.loss_mask: 0.3387  decode.d0.loss_dice: 0.3671  decode.d1.loss_cls: 0.6966  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.3165  decode.d2.loss_cls: 0.6215  decode.d2.loss_mask: 0.3273  decode.d2.loss_dice: 0.2950  decode.d3.loss_cls: 0.6034  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.2993  decode.d4.loss_cls: 0.4832  decode.d4.loss_mask: 0.3376  decode.d4.loss_dice: 0.3206  decode.d5.loss_cls: 0.6187  decode.d5.loss_mask: 0.3445  decode.d5.loss_dice: 0.3352  decode.d6.loss_cls: 0.5106  decode.d6.loss_mask: 0.3723  decode.d6.loss_dice: 0.3147  decode.d7.loss_cls: 0.5677  decode.d7.loss_mask: 0.3217  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.6084  decode.d8.loss_mask: 0.3747  decode.d8.loss_dice: 0.3035
09/30 09:52:07 - mmengine - INFO - Iter(train) [  6800/320000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 1 day, 13:39:55  time: 0.4317  data_time: 0.0084  memory: 5161  grad_norm: 171.3397  loss: 15.6275  decode.loss_cls: 0.5077  decode.loss_mask: 0.4636  decode.loss_dice: 0.5206  decode.d0.loss_cls: 1.3178  decode.d0.loss_mask: 0.4472  decode.d0.loss_dice: 0.4698  decode.d1.loss_cls: 0.6649  decode.d1.loss_mask: 0.4477  decode.d1.loss_dice: 0.4704  decode.d2.loss_cls: 0.6319  decode.d2.loss_mask: 0.4106  decode.d2.loss_dice: 0.4395  decode.d3.loss_cls: 0.5908  decode.d3.loss_mask: 0.4184  decode.d3.loss_dice: 0.4712  decode.d4.loss_cls: 0.5854  decode.d4.loss_mask: 0.4032  decode.d4.loss_dice: 0.4665  decode.d5.loss_cls: 0.5165  decode.d5.loss_mask: 0.4307  decode.d5.loss_dice: 0.4892  decode.d6.loss_cls: 0.5220  decode.d6.loss_mask: 0.4305  decode.d6.loss_dice: 0.5054  decode.d7.loss_cls: 0.5166  decode.d7.loss_mask: 0.4742  decode.d7.loss_dice: 0.5131  decode.d8.loss_cls: 0.5392  decode.d8.loss_mask: 0.4356  decode.d8.loss_dice: 0.5273
09/30 09:52:28 - mmengine - INFO - Iter(train) [  6850/320000]  base_lr: 9.8072e-05 lr: 9.8072e-06  eta: 1 day, 13:39:30  time: 0.4322  data_time: 0.0089  memory: 5180  grad_norm: 85.5046  loss: 9.8315  decode.loss_cls: 0.2713  decode.loss_mask: 0.3560  decode.loss_dice: 0.2534  decode.d0.loss_cls: 0.9461  decode.d0.loss_mask: 0.3563  decode.d0.loss_dice: 0.2712  decode.d1.loss_cls: 0.2774  decode.d1.loss_mask: 0.3547  decode.d1.loss_dice: 0.2692  decode.d2.loss_cls: 0.3197  decode.d2.loss_mask: 0.3516  decode.d2.loss_dice: 0.2690  decode.d3.loss_cls: 0.3046  decode.d3.loss_mask: 0.3583  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.3157  decode.d4.loss_mask: 0.3592  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.3099  decode.d5.loss_mask: 0.3534  decode.d5.loss_dice: 0.2528  decode.d6.loss_cls: 0.3007  decode.d6.loss_mask: 0.3495  decode.d6.loss_dice: 0.2506  decode.d7.loss_cls: 0.2948  decode.d7.loss_mask: 0.3475  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.3717  decode.d8.loss_mask: 0.3487  decode.d8.loss_dice: 0.2532
09/30 09:52:50 - mmengine - INFO - Iter(train) [  6900/320000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 1 day, 13:39:06  time: 0.4325  data_time: 0.0090  memory: 5147  grad_norm: 152.8977  loss: 12.4570  decode.loss_cls: 0.4914  decode.loss_mask: 0.3475  decode.loss_dice: 0.3077  decode.d0.loss_cls: 1.2566  decode.d0.loss_mask: 0.3640  decode.d0.loss_dice: 0.3355  decode.d1.loss_cls: 0.6049  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.2513  decode.d2.loss_cls: 0.5878  decode.d2.loss_mask: 0.3477  decode.d2.loss_dice: 0.2925  decode.d3.loss_cls: 0.5489  decode.d3.loss_mask: 0.3232  decode.d3.loss_dice: 0.2967  decode.d4.loss_cls: 0.5743  decode.d4.loss_mask: 0.3514  decode.d4.loss_dice: 0.2866  decode.d5.loss_cls: 0.5708  decode.d5.loss_mask: 0.3356  decode.d5.loss_dice: 0.2941  decode.d6.loss_cls: 0.5172  decode.d6.loss_mask: 0.3470  decode.d6.loss_dice: 0.2990  decode.d7.loss_cls: 0.4719  decode.d7.loss_mask: 0.3316  decode.d7.loss_dice: 0.2760  decode.d8.loss_cls: 0.4892  decode.d8.loss_mask: 0.3331  decode.d8.loss_dice: 0.2902
09/30 09:53:11 - mmengine - INFO - Iter(train) [  6950/320000]  base_lr: 9.8043e-05 lr: 9.8043e-06  eta: 1 day, 13:38:41  time: 0.4318  data_time: 0.0089  memory: 5180  grad_norm: 145.8885  loss: 10.6777  decode.loss_cls: 0.3498  decode.loss_mask: 0.3702  decode.loss_dice: 0.2767  decode.d0.loss_cls: 1.0199  decode.d0.loss_mask: 0.3889  decode.d0.loss_dice: 0.2837  decode.d1.loss_cls: 0.3576  decode.d1.loss_mask: 0.3783  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.3615  decode.d2.loss_mask: 0.3773  decode.d2.loss_dice: 0.2620  decode.d3.loss_cls: 0.3554  decode.d3.loss_mask: 0.3790  decode.d3.loss_dice: 0.2631  decode.d4.loss_cls: 0.4263  decode.d4.loss_mask: 0.3754  decode.d4.loss_dice: 0.2770  decode.d5.loss_cls: 0.3669  decode.d5.loss_mask: 0.3743  decode.d5.loss_dice: 0.2753  decode.d6.loss_cls: 0.2819  decode.d6.loss_mask: 0.3847  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.2995  decode.d7.loss_mask: 0.3869  decode.d7.loss_dice: 0.2831  decode.d8.loss_cls: 0.3293  decode.d8.loss_mask: 0.3725  decode.d8.loss_dice: 0.2721
09/30 09:53:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 09:53:33 - mmengine - INFO - Iter(train) [  7000/320000]  base_lr: 9.8029e-05 lr: 9.8029e-06  eta: 1 day, 13:38:16  time: 0.4315  data_time: 0.0089  memory: 5180  grad_norm: 109.3999  loss: 10.5864  decode.loss_cls: 0.2445  decode.loss_mask: 0.3528  decode.loss_dice: 0.3328  decode.d0.loss_cls: 1.0136  decode.d0.loss_mask: 0.3662  decode.d0.loss_dice: 0.3444  decode.d1.loss_cls: 0.3803  decode.d1.loss_mask: 0.3397  decode.d1.loss_dice: 0.3196  decode.d2.loss_cls: 0.3607  decode.d2.loss_mask: 0.3286  decode.d2.loss_dice: 0.3278  decode.d3.loss_cls: 0.3249  decode.d3.loss_mask: 0.3387  decode.d3.loss_dice: 0.3283  decode.d4.loss_cls: 0.3364  decode.d4.loss_mask: 0.3312  decode.d4.loss_dice: 0.3201  decode.d5.loss_cls: 0.3129  decode.d5.loss_mask: 0.3282  decode.d5.loss_dice: 0.3146  decode.d6.loss_cls: 0.2914  decode.d6.loss_mask: 0.3370  decode.d6.loss_dice: 0.3220  decode.d7.loss_cls: 0.2969  decode.d7.loss_mask: 0.3401  decode.d7.loss_dice: 0.3205  decode.d8.loss_cls: 0.3091  decode.d8.loss_mask: 0.3730  decode.d8.loss_dice: 0.3501
09/30 09:53:55 - mmengine - INFO - Iter(train) [  7050/320000]  base_lr: 9.8015e-05 lr: 9.8015e-06  eta: 1 day, 13:37:51  time: 0.4315  data_time: 0.0090  memory: 5147  grad_norm: 147.2681  loss: 10.2749  decode.loss_cls: 0.3425  decode.loss_mask: 0.3317  decode.loss_dice: 0.2928  decode.d0.loss_cls: 0.9254  decode.d0.loss_mask: 0.3329  decode.d0.loss_dice: 0.3020  decode.d1.loss_cls: 0.3083  decode.d1.loss_mask: 0.3485  decode.d1.loss_dice: 0.3344  decode.d2.loss_cls: 0.3769  decode.d2.loss_mask: 0.3369  decode.d2.loss_dice: 0.3169  decode.d3.loss_cls: 0.3892  decode.d3.loss_mask: 0.3298  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.3684  decode.d4.loss_mask: 0.3279  decode.d4.loss_dice: 0.2806  decode.d5.loss_cls: 0.2824  decode.d5.loss_mask: 0.3357  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.2518  decode.d6.loss_mask: 0.3361  decode.d6.loss_dice: 0.3069  decode.d7.loss_cls: 0.2621  decode.d7.loss_mask: 0.3421  decode.d7.loss_dice: 0.3210  decode.d8.loss_cls: 0.3329  decode.d8.loss_mask: 0.3360  decode.d8.loss_dice: 0.3181
09/30 09:54:16 - mmengine - INFO - Iter(train) [  7100/320000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 1 day, 13:37:29  time: 0.4314  data_time: 0.0087  memory: 5161  grad_norm: 113.2437  loss: 11.5161  decode.loss_cls: 0.4437  decode.loss_mask: 0.3052  decode.loss_dice: 0.2402  decode.d0.loss_cls: 1.2480  decode.d0.loss_mask: 0.3143  decode.d0.loss_dice: 0.2911  decode.d1.loss_cls: 0.6316  decode.d1.loss_mask: 0.2998  decode.d1.loss_dice: 0.2506  decode.d2.loss_cls: 0.5386  decode.d2.loss_mask: 0.2974  decode.d2.loss_dice: 0.2536  decode.d3.loss_cls: 0.5479  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.2432  decode.d4.loss_cls: 0.4800  decode.d4.loss_mask: 0.2979  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.5718  decode.d5.loss_mask: 0.2966  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.4871  decode.d6.loss_mask: 0.3083  decode.d6.loss_dice: 0.2579  decode.d7.loss_cls: 0.5318  decode.d7.loss_mask: 0.3099  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.4799  decode.d8.loss_mask: 0.2988  decode.d8.loss_dice: 0.2489
09/30 09:54:38 - mmengine - INFO - Iter(train) [  7150/320000]  base_lr: 9.7987e-05 lr: 9.7987e-06  eta: 1 day, 13:37:06  time: 0.4317  data_time: 0.0087  memory: 5160  grad_norm: 57.0392  loss: 7.4340  decode.loss_cls: 0.1360  decode.loss_mask: 0.3001  decode.loss_dice: 0.2007  decode.d0.loss_cls: 0.9345  decode.d0.loss_mask: 0.3068  decode.d0.loss_dice: 0.2218  decode.d1.loss_cls: 0.1938  decode.d1.loss_mask: 0.3008  decode.d1.loss_dice: 0.1983  decode.d2.loss_cls: 0.1660  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.2056  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.3017  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.1381  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.2080  decode.d5.loss_cls: 0.1541  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.1941  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.3003  decode.d6.loss_dice: 0.1944  decode.d7.loss_cls: 0.1544  decode.d7.loss_mask: 0.2941  decode.d7.loss_dice: 0.1961  decode.d8.loss_cls: 0.1521  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.2146
09/30 09:54:59 - mmengine - INFO - Iter(train) [  7200/320000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 1 day, 13:36:42  time: 0.4311  data_time: 0.0086  memory: 5180  grad_norm: 314.7445  loss: 9.9521  decode.loss_cls: 0.3376  decode.loss_mask: 0.4030  decode.loss_dice: 0.3260  decode.d0.loss_cls: 0.9300  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.2786  decode.d1.loss_cls: 0.3476  decode.d1.loss_mask: 0.3106  decode.d1.loss_dice: 0.2651  decode.d2.loss_cls: 0.3147  decode.d2.loss_mask: 0.3458  decode.d2.loss_dice: 0.3138  decode.d3.loss_cls: 0.3353  decode.d3.loss_mask: 0.2951  decode.d3.loss_dice: 0.2723  decode.d4.loss_cls: 0.3300  decode.d4.loss_mask: 0.3076  decode.d4.loss_dice: 0.2691  decode.d5.loss_cls: 0.3160  decode.d5.loss_mask: 0.2957  decode.d5.loss_dice: 0.2818  decode.d6.loss_cls: 0.3132  decode.d6.loss_mask: 0.2965  decode.d6.loss_dice: 0.2749  decode.d7.loss_cls: 0.3194  decode.d7.loss_mask: 0.2954  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.3672  decode.d8.loss_mask: 0.3101  decode.d8.loss_dice: 0.2823
09/30 09:55:21 - mmengine - INFO - Iter(train) [  7250/320000]  base_lr: 9.7959e-05 lr: 9.7959e-06  eta: 1 day, 13:36:18  time: 0.4320  data_time: 0.0088  memory: 5146  grad_norm: 144.4174  loss: 8.9024  decode.loss_cls: 0.2384  decode.loss_mask: 0.3395  decode.loss_dice: 0.2525  decode.d0.loss_cls: 0.9361  decode.d0.loss_mask: 0.3442  decode.d0.loss_dice: 0.3220  decode.d1.loss_cls: 0.3946  decode.d1.loss_mask: 0.3339  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.2540  decode.d2.loss_mask: 0.3206  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.2195  decode.d3.loss_mask: 0.3287  decode.d3.loss_dice: 0.2501  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.3334  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.2080  decode.d5.loss_mask: 0.3180  decode.d5.loss_dice: 0.2672  decode.d6.loss_cls: 0.2173  decode.d6.loss_mask: 0.3184  decode.d6.loss_dice: 0.2337  decode.d7.loss_cls: 0.2226  decode.d7.loss_mask: 0.3116  decode.d7.loss_dice: 0.2365  decode.d8.loss_cls: 0.2350  decode.d8.loss_mask: 0.3118  decode.d8.loss_dice: 0.2326
09/30 09:55:43 - mmengine - INFO - Iter(train) [  7300/320000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 1 day, 13:35:55  time: 0.4319  data_time: 0.0088  memory: 5161  grad_norm: 90.5937  loss: 10.5240  decode.loss_cls: 0.4635  decode.loss_mask: 0.2707  decode.loss_dice: 0.2341  decode.d0.loss_cls: 1.0281  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.2635  decode.d1.loss_cls: 0.6684  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.2182  decode.d2.loss_cls: 0.4309  decode.d2.loss_mask: 0.2703  decode.d2.loss_dice: 0.2344  decode.d3.loss_cls: 0.4130  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.2354  decode.d4.loss_cls: 0.4635  decode.d4.loss_mask: 0.2717  decode.d4.loss_dice: 0.2315  decode.d5.loss_cls: 0.4720  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.2281  decode.d6.loss_cls: 0.5354  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.2248  decode.d7.loss_cls: 0.5464  decode.d7.loss_mask: 0.2706  decode.d7.loss_dice: 0.2271  decode.d8.loss_cls: 0.4340  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.2524
09/30 09:56:04 - mmengine - INFO - Iter(train) [  7350/320000]  base_lr: 9.7931e-05 lr: 9.7931e-06  eta: 1 day, 13:35:30  time: 0.4307  data_time: 0.0085  memory: 5160  grad_norm: 236.0372  loss: 10.3647  decode.loss_cls: 0.4117  decode.loss_mask: 0.2902  decode.loss_dice: 0.2490  decode.d0.loss_cls: 1.0652  decode.d0.loss_mask: 0.2967  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.3719  decode.d1.loss_mask: 0.2899  decode.d1.loss_dice: 0.2736  decode.d2.loss_cls: 0.4451  decode.d2.loss_mask: 0.2812  decode.d2.loss_dice: 0.2398  decode.d3.loss_cls: 0.3298  decode.d3.loss_mask: 0.2926  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.3029  decode.d4.loss_mask: 0.4152  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.3564  decode.d5.loss_mask: 0.4067  decode.d5.loss_dice: 0.2736  decode.d6.loss_cls: 0.3274  decode.d6.loss_mask: 0.3873  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.2661  decode.d7.loss_mask: 0.3925  decode.d7.loss_dice: 0.2713  decode.d8.loss_cls: 0.3985  decode.d8.loss_mask: 0.3823  decode.d8.loss_dice: 0.2644
09/30 09:56:26 - mmengine - INFO - Iter(train) [  7400/320000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 1 day, 13:35:06  time: 0.4320  data_time: 0.0089  memory: 5160  grad_norm: 276.5490  loss: 10.1769  decode.loss_cls: 0.3866  decode.loss_mask: 0.2792  decode.loss_dice: 0.2372  decode.d0.loss_cls: 1.2370  decode.d0.loss_mask: 0.2802  decode.d0.loss_dice: 0.2843  decode.d1.loss_cls: 0.4749  decode.d1.loss_mask: 0.2757  decode.d1.loss_dice: 0.2230  decode.d2.loss_cls: 0.3760  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.4202  decode.d3.loss_mask: 0.2801  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.4280  decode.d4.loss_mask: 0.2741  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.4317  decode.d5.loss_mask: 0.2745  decode.d5.loss_dice: 0.2503  decode.d6.loss_cls: 0.4168  decode.d6.loss_mask: 0.2765  decode.d6.loss_dice: 0.2441  decode.d7.loss_cls: 0.3966  decode.d7.loss_mask: 0.2819  decode.d7.loss_dice: 0.2579  decode.d8.loss_cls: 0.3711  decode.d8.loss_mask: 0.2752  decode.d8.loss_dice: 0.2297
09/30 09:56:47 - mmengine - INFO - Iter(train) [  7450/320000]  base_lr: 9.7903e-05 lr: 9.7903e-06  eta: 1 day, 13:34:40  time: 0.4305  data_time: 0.0088  memory: 5180  grad_norm: 129.0048  loss: 11.0283  decode.loss_cls: 0.3998  decode.loss_mask: 0.3680  decode.loss_dice: 0.3667  decode.d0.loss_cls: 0.9388  decode.d0.loss_mask: 0.3696  decode.d0.loss_dice: 0.3551  decode.d1.loss_cls: 0.3896  decode.d1.loss_mask: 0.3400  decode.d1.loss_dice: 0.3130  decode.d2.loss_cls: 0.3080  decode.d2.loss_mask: 0.3385  decode.d2.loss_dice: 0.3084  decode.d3.loss_cls: 0.3241  decode.d3.loss_mask: 0.3412  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 0.3507  decode.d4.loss_mask: 0.3419  decode.d4.loss_dice: 0.3395  decode.d5.loss_cls: 0.3204  decode.d5.loss_mask: 0.3477  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.3303  decode.d6.loss_mask: 0.3542  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.3604  decode.d7.loss_mask: 0.3602  decode.d7.loss_dice: 0.3512  decode.d8.loss_cls: 0.4402  decode.d8.loss_mask: 0.3396  decode.d8.loss_dice: 0.3343
09/30 09:57:09 - mmengine - INFO - Iter(train) [  7500/320000]  base_lr: 9.7888e-05 lr: 9.7888e-06  eta: 1 day, 13:34:16  time: 0.4318  data_time: 0.0085  memory: 5160  grad_norm: 87.6360  loss: 10.3941  decode.loss_cls: 0.3292  decode.loss_mask: 0.3116  decode.loss_dice: 0.3318  decode.d0.loss_cls: 0.9452  decode.d0.loss_mask: 0.3084  decode.d0.loss_dice: 0.3400  decode.d1.loss_cls: 0.3135  decode.d1.loss_mask: 0.3118  decode.d1.loss_dice: 0.3323  decode.d2.loss_cls: 0.3122  decode.d2.loss_mask: 0.3199  decode.d2.loss_dice: 0.3409  decode.d3.loss_cls: 0.3814  decode.d3.loss_mask: 0.3109  decode.d3.loss_dice: 0.3367  decode.d4.loss_cls: 0.3244  decode.d4.loss_mask: 0.3108  decode.d4.loss_dice: 0.3297  decode.d5.loss_cls: 0.3597  decode.d5.loss_mask: 0.3063  decode.d5.loss_dice: 0.3315  decode.d6.loss_cls: 0.3445  decode.d6.loss_mask: 0.3057  decode.d6.loss_dice: 0.3235  decode.d7.loss_cls: 0.3036  decode.d7.loss_mask: 0.3031  decode.d7.loss_dice: 0.3385  decode.d8.loss_cls: 0.3334  decode.d8.loss_mask: 0.3046  decode.d8.loss_dice: 0.3488
09/30 09:57:31 - mmengine - INFO - Iter(train) [  7550/320000]  base_lr: 9.7874e-05 lr: 9.7874e-06  eta: 1 day, 13:33:52  time: 0.4317  data_time: 0.0087  memory: 5160  grad_norm: 55.8370  loss: 7.5868  decode.loss_cls: 0.2928  decode.loss_mask: 0.2350  decode.loss_dice: 0.2012  decode.d0.loss_cls: 0.8727  decode.d0.loss_mask: 0.2233  decode.d0.loss_dice: 0.2185  decode.d1.loss_cls: 0.3544  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1756  decode.d2.loss_cls: 0.2828  decode.d2.loss_mask: 0.2186  decode.d2.loss_dice: 0.1854  decode.d3.loss_cls: 0.2695  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.1913  decode.d4.loss_cls: 0.2202  decode.d4.loss_mask: 0.2328  decode.d4.loss_dice: 0.1926  decode.d5.loss_cls: 0.2597  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.3028  decode.d6.loss_mask: 0.2209  decode.d6.loss_dice: 0.1910  decode.d7.loss_cls: 0.2836  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.1915  decode.d8.loss_cls: 0.2863  decode.d8.loss_mask: 0.2217  decode.d8.loss_dice: 0.1809
09/30 09:57:52 - mmengine - INFO - Iter(train) [  7600/320000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 1 day, 13:33:28  time: 0.4318  data_time: 0.0089  memory: 5180  grad_norm: 125.3559  loss: 11.9220  decode.loss_cls: 0.3509  decode.loss_mask: 0.4932  decode.loss_dice: 0.3564  decode.d0.loss_cls: 1.0545  decode.d0.loss_mask: 0.3880  decode.d0.loss_dice: 0.3654  decode.d1.loss_cls: 0.4180  decode.d1.loss_mask: 0.4035  decode.d1.loss_dice: 0.3400  decode.d2.loss_cls: 0.3837  decode.d2.loss_mask: 0.3726  decode.d2.loss_dice: 0.3164  decode.d3.loss_cls: 0.3398  decode.d3.loss_mask: 0.4131  decode.d3.loss_dice: 0.3396  decode.d4.loss_cls: 0.3548  decode.d4.loss_mask: 0.4114  decode.d4.loss_dice: 0.3697  decode.d5.loss_cls: 0.3644  decode.d5.loss_mask: 0.3876  decode.d5.loss_dice: 0.3467  decode.d6.loss_cls: 0.3948  decode.d6.loss_mask: 0.4013  decode.d6.loss_dice: 0.3713  decode.d7.loss_cls: 0.3669  decode.d7.loss_mask: 0.3955  decode.d7.loss_dice: 0.3591  decode.d8.loss_cls: 0.3426  decode.d8.loss_mask: 0.3823  decode.d8.loss_dice: 0.3387
09/30 09:58:14 - mmengine - INFO - Iter(train) [  7650/320000]  base_lr: 9.7846e-05 lr: 9.7846e-06  eta: 1 day, 13:33:03  time: 0.4315  data_time: 0.0089  memory: 5146  grad_norm: 117.9898  loss: 12.1156  decode.loss_cls: 0.5052  decode.loss_mask: 0.3359  decode.loss_dice: 0.3797  decode.d0.loss_cls: 1.0475  decode.d0.loss_mask: 0.3488  decode.d0.loss_dice: 0.3884  decode.d1.loss_cls: 0.4472  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.3898  decode.d2.loss_cls: 0.5015  decode.d2.loss_mask: 0.3240  decode.d2.loss_dice: 0.3770  decode.d3.loss_cls: 0.4057  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.3882  decode.d4.loss_cls: 0.4055  decode.d4.loss_mask: 0.3270  decode.d4.loss_dice: 0.3653  decode.d5.loss_cls: 0.4442  decode.d5.loss_mask: 0.3179  decode.d5.loss_dice: 0.3573  decode.d6.loss_cls: 0.4179  decode.d6.loss_mask: 0.3439  decode.d6.loss_dice: 0.3811  decode.d7.loss_cls: 0.4117  decode.d7.loss_mask: 0.3349  decode.d7.loss_dice: 0.3603  decode.d8.loss_cls: 0.4550  decode.d8.loss_mask: 0.3255  decode.d8.loss_dice: 0.3649
09/30 09:58:35 - mmengine - INFO - Iter(train) [  7700/320000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 1 day, 13:32:38  time: 0.4314  data_time: 0.0088  memory: 5147  grad_norm: 79.5319  loss: 11.7445  decode.loss_cls: 0.4807  decode.loss_mask: 0.4006  decode.loss_dice: 0.2949  decode.d0.loss_cls: 1.1623  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.6338  decode.d1.loss_mask: 0.2472  decode.d1.loss_dice: 0.2864  decode.d2.loss_cls: 0.5260  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2977  decode.d3.loss_cls: 0.4924  decode.d3.loss_mask: 0.2401  decode.d3.loss_dice: 0.2730  decode.d4.loss_cls: 0.4147  decode.d4.loss_mask: 0.2384  decode.d4.loss_dice: 0.2746  decode.d5.loss_cls: 0.4755  decode.d5.loss_mask: 0.3543  decode.d5.loss_dice: 0.3537  decode.d6.loss_cls: 0.4464  decode.d6.loss_mask: 0.3882  decode.d6.loss_dice: 0.3086  decode.d7.loss_cls: 0.5064  decode.d7.loss_mask: 0.3955  decode.d7.loss_dice: 0.3085  decode.d8.loss_cls: 0.5001  decode.d8.loss_mask: 0.3264  decode.d8.loss_dice: 0.3096
09/30 09:58:57 - mmengine - INFO - Iter(train) [  7750/320000]  base_lr: 9.7818e-05 lr: 9.7818e-06  eta: 1 day, 13:32:14  time: 0.4312  data_time: 0.0087  memory: 5146  grad_norm: 107.2840  loss: 8.8614  decode.loss_cls: 0.2878  decode.loss_mask: 0.2796  decode.loss_dice: 0.2300  decode.d0.loss_cls: 0.9162  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.2430  decode.d1.loss_cls: 0.3196  decode.d1.loss_mask: 0.2789  decode.d1.loss_dice: 0.2218  decode.d2.loss_cls: 0.3184  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.2435  decode.d3.loss_cls: 0.2756  decode.d3.loss_mask: 0.2792  decode.d3.loss_dice: 0.2359  decode.d4.loss_cls: 0.2973  decode.d4.loss_mask: 0.2828  decode.d4.loss_dice: 0.2372  decode.d5.loss_cls: 0.3157  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.2306  decode.d6.loss_cls: 0.2747  decode.d6.loss_mask: 0.2829  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.2124  decode.d7.loss_mask: 0.4168  decode.d7.loss_dice: 0.2497  decode.d8.loss_cls: 0.2682  decode.d8.loss_mask: 0.3097  decode.d8.loss_dice: 0.2623
09/30 09:59:18 - mmengine - INFO - Iter(train) [  7800/320000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 1 day, 13:31:51  time: 0.4322  data_time: 0.0088  memory: 5147  grad_norm: 129.4442  loss: 11.0535  decode.loss_cls: 0.3150  decode.loss_mask: 0.4864  decode.loss_dice: 0.2724  decode.d0.loss_cls: 1.0428  decode.d0.loss_mask: 0.3851  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.4184  decode.d1.loss_mask: 0.4735  decode.d1.loss_dice: 0.3097  decode.d2.loss_cls: 0.3951  decode.d2.loss_mask: 0.4530  decode.d2.loss_dice: 0.2929  decode.d3.loss_cls: 0.3977  decode.d3.loss_mask: 0.4305  decode.d3.loss_dice: 0.2824  decode.d4.loss_cls: 0.4076  decode.d4.loss_mask: 0.3796  decode.d4.loss_dice: 0.2426  decode.d5.loss_cls: 0.3056  decode.d5.loss_mask: 0.3976  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.2146  decode.d6.loss_mask: 0.4158  decode.d6.loss_dice: 0.2473  decode.d7.loss_cls: 0.2813  decode.d7.loss_mask: 0.4081  decode.d7.loss_dice: 0.2402  decode.d8.loss_cls: 0.3338  decode.d8.loss_mask: 0.4375  decode.d8.loss_dice: 0.2807
09/30 09:59:40 - mmengine - INFO - Iter(train) [  7850/320000]  base_lr: 9.7790e-05 lr: 9.7790e-06  eta: 1 day, 13:31:34  time: 0.4318  data_time: 0.0088  memory: 5180  grad_norm: 88.4748  loss: 11.1708  decode.loss_cls: 0.5215  decode.loss_mask: 0.2420  decode.loss_dice: 0.2909  decode.d0.loss_cls: 1.1265  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.3039  decode.d1.loss_cls: 0.7247  decode.d1.loss_mask: 0.2362  decode.d1.loss_dice: 0.2995  decode.d2.loss_cls: 0.5700  decode.d2.loss_mask: 0.2360  decode.d2.loss_dice: 0.2786  decode.d3.loss_cls: 0.5068  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.2695  decode.d4.loss_cls: 0.4949  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.3029  decode.d5.loss_cls: 0.4251  decode.d5.loss_mask: 0.2338  decode.d5.loss_dice: 0.2892  decode.d6.loss_cls: 0.4911  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2813  decode.d7.loss_cls: 0.4807  decode.d7.loss_mask: 0.2595  decode.d7.loss_dice: 0.3153  decode.d8.loss_cls: 0.5181  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.2795
09/30 10:00:02 - mmengine - INFO - Iter(train) [  7900/320000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 1 day, 13:31:10  time: 0.4321  data_time: 0.0085  memory: 5161  grad_norm: 59.4821  loss: 8.9660  decode.loss_cls: 0.2958  decode.loss_mask: 0.2952  decode.loss_dice: 0.2561  decode.d0.loss_cls: 0.9063  decode.d0.loss_mask: 0.3079  decode.d0.loss_dice: 0.2940  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 0.3042  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.2376  decode.d2.loss_mask: 0.2980  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.2934  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.2437  decode.d4.loss_cls: 0.2816  decode.d4.loss_mask: 0.2938  decode.d4.loss_dice: 0.2313  decode.d5.loss_cls: 0.2567  decode.d5.loss_mask: 0.2959  decode.d5.loss_dice: 0.2694  decode.d6.loss_cls: 0.3063  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.2994  decode.d7.loss_mask: 0.2958  decode.d7.loss_dice: 0.2420  decode.d8.loss_cls: 0.2826  decode.d8.loss_mask: 0.2929  decode.d8.loss_dice: 0.2499
09/30 10:00:23 - mmengine - INFO - Iter(train) [  7950/320000]  base_lr: 9.7762e-05 lr: 9.7762e-06  eta: 1 day, 13:30:47  time: 0.4321  data_time: 0.0087  memory: 5180  grad_norm: 144.0139  loss: 11.2670  decode.loss_cls: 0.2907  decode.loss_mask: 0.3787  decode.loss_dice: 0.3093  decode.d0.loss_cls: 1.2729  decode.d0.loss_mask: 0.4020  decode.d0.loss_dice: 0.3388  decode.d1.loss_cls: 0.4688  decode.d1.loss_mask: 0.3938  decode.d1.loss_dice: 0.3346  decode.d2.loss_cls: 0.3617  decode.d2.loss_mask: 0.3543  decode.d2.loss_dice: 0.3022  decode.d3.loss_cls: 0.3515  decode.d3.loss_mask: 0.4143  decode.d3.loss_dice: 0.3276  decode.d4.loss_cls: 0.3508  decode.d4.loss_mask: 0.3573  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.3247  decode.d5.loss_mask: 0.3815  decode.d5.loss_dice: 0.3163  decode.d6.loss_cls: 0.2919  decode.d6.loss_mask: 0.3735  decode.d6.loss_dice: 0.3246  decode.d7.loss_cls: 0.3124  decode.d7.loss_mask: 0.3472  decode.d7.loss_dice: 0.2890  decode.d8.loss_cls: 0.3387  decode.d8.loss_mask: 0.3653  decode.d8.loss_dice: 0.2995
09/30 10:00:45 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:00:45 - mmengine - INFO - Iter(train) [  8000/320000]  base_lr: 9.7747e-05 lr: 9.7747e-06  eta: 1 day, 13:30:23  time: 0.4313  data_time: 0.0084  memory: 5180  grad_norm: 86.9884  loss: 9.7249  decode.loss_cls: 0.4551  decode.loss_mask: 0.2039  decode.loss_dice: 0.2463  decode.d0.loss_cls: 1.3221  decode.d0.loss_mask: 0.2291  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.4204  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.2479  decode.d2.loss_cls: 0.3643  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.3737  decode.d3.loss_mask: 0.2080  decode.d3.loss_dice: 0.2174  decode.d4.loss_cls: 0.3971  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2459  decode.d5.loss_cls: 0.3867  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.3646  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2766  decode.d7.loss_cls: 0.3726  decode.d7.loss_mask: 0.2698  decode.d7.loss_dice: 0.2753  decode.d8.loss_cls: 0.4537  decode.d8.loss_mask: 0.2042  decode.d8.loss_dice: 0.2586
09/30 10:01:07 - mmengine - INFO - Iter(train) [  8050/320000]  base_lr: 9.7733e-05 lr: 9.7733e-06  eta: 1 day, 13:30:00  time: 0.4331  data_time: 0.0088  memory: 5160  grad_norm: 109.4369  loss: 10.5689  decode.loss_cls: 0.3509  decode.loss_mask: 0.3036  decode.loss_dice: 0.3323  decode.d0.loss_cls: 1.1784  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.3141  decode.d1.loss_cls: 0.5073  decode.d1.loss_mask: 0.2686  decode.d1.loss_dice: 0.3241  decode.d2.loss_cls: 0.4194  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.3224  decode.d3.loss_cls: 0.4006  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.2947  decode.d4.loss_cls: 0.3916  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.3042  decode.d5.loss_cls: 0.3738  decode.d5.loss_mask: 0.2737  decode.d5.loss_dice: 0.3276  decode.d6.loss_cls: 0.3891  decode.d6.loss_mask: 0.2739  decode.d6.loss_dice: 0.3115  decode.d7.loss_cls: 0.3596  decode.d7.loss_mask: 0.2907  decode.d7.loss_dice: 0.3274  decode.d8.loss_cls: 0.2852  decode.d8.loss_mask: 0.2929  decode.d8.loss_dice: 0.3252
09/30 10:01:28 - mmengine - INFO - Iter(train) [  8100/320000]  base_lr: 9.7719e-05 lr: 9.7719e-06  eta: 1 day, 13:29:37  time: 0.4327  data_time: 0.0090  memory: 5180  grad_norm: 49.6592  loss: 7.2721  decode.loss_cls: 0.1512  decode.loss_mask: 0.2425  decode.loss_dice: 0.2172  decode.d0.loss_cls: 0.8545  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.2560  decode.d1.loss_cls: 0.1834  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.2263  decode.d2.loss_cls: 0.2108  decode.d2.loss_mask: 0.2450  decode.d2.loss_dice: 0.2250  decode.d3.loss_cls: 0.2091  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.2028  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.2080  decode.d5.loss_cls: 0.1950  decode.d5.loss_mask: 0.2454  decode.d5.loss_dice: 0.2241  decode.d6.loss_cls: 0.1746  decode.d6.loss_mask: 0.2430  decode.d6.loss_dice: 0.2195  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2275
09/30 10:01:50 - mmengine - INFO - Iter(train) [  8150/320000]  base_lr: 9.7705e-05 lr: 9.7705e-06  eta: 1 day, 13:29:14  time: 0.4317  data_time: 0.0088  memory: 5180  grad_norm: 98.7778  loss: 10.4788  decode.loss_cls: 0.2223  decode.loss_mask: 0.3914  decode.loss_dice: 0.3443  decode.d0.loss_cls: 1.1806  decode.d0.loss_mask: 0.3724  decode.d0.loss_dice: 0.3003  decode.d1.loss_cls: 0.2365  decode.d1.loss_mask: 0.3592  decode.d1.loss_dice: 0.3295  decode.d2.loss_cls: 0.1760  decode.d2.loss_mask: 0.3684  decode.d2.loss_dice: 0.3508  decode.d3.loss_cls: 0.1871  decode.d3.loss_mask: 0.3670  decode.d3.loss_dice: 0.3435  decode.d4.loss_cls: 0.2154  decode.d4.loss_mask: 0.3804  decode.d4.loss_dice: 0.3485  decode.d5.loss_cls: 0.1900  decode.d5.loss_mask: 0.4219  decode.d5.loss_dice: 0.3560  decode.d6.loss_cls: 0.2169  decode.d6.loss_mask: 0.4552  decode.d6.loss_dice: 0.3767  decode.d7.loss_cls: 0.2527  decode.d7.loss_mask: 0.4008  decode.d7.loss_dice: 0.3582  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.4064  decode.d8.loss_dice: 0.3411
09/30 10:02:11 - mmengine - INFO - Iter(train) [  8200/320000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 1 day, 13:28:52  time: 0.4323  data_time: 0.0086  memory: 5161  grad_norm: 65.9560  loss: 8.0958  decode.loss_cls: 0.1688  decode.loss_mask: 0.3168  decode.loss_dice: 0.2075  decode.d0.loss_cls: 0.9738  decode.d0.loss_mask: 0.3302  decode.d0.loss_dice: 0.2385  decode.d1.loss_cls: 0.3049  decode.d1.loss_mask: 0.3200  decode.d1.loss_dice: 0.2249  decode.d2.loss_cls: 0.2188  decode.d2.loss_mask: 0.3238  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.1969  decode.d3.loss_mask: 0.3218  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 0.3189  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.1726  decode.d5.loss_mask: 0.3179  decode.d5.loss_dice: 0.2057  decode.d6.loss_cls: 0.1621  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.2259  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.2092  decode.d8.loss_cls: 0.1963  decode.d8.loss_mask: 0.3205  decode.d8.loss_dice: 0.2106
09/30 10:02:33 - mmengine - INFO - Iter(train) [  8250/320000]  base_lr: 9.7677e-05 lr: 9.7677e-06  eta: 1 day, 13:28:29  time: 0.4321  data_time: 0.0087  memory: 5180  grad_norm: 58.9332  loss: 9.5773  decode.loss_cls: 0.3285  decode.loss_mask: 0.2606  decode.loss_dice: 0.2909  decode.d0.loss_cls: 1.0212  decode.d0.loss_mask: 0.2769  decode.d0.loss_dice: 0.3143  decode.d1.loss_cls: 0.4387  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.2838  decode.d2.loss_cls: 0.3691  decode.d2.loss_mask: 0.2529  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.4041  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.2910  decode.d4.loss_cls: 0.3566  decode.d4.loss_mask: 0.2558  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.3185  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2797  decode.d6.loss_cls: 0.3178  decode.d6.loss_mask: 0.2559  decode.d6.loss_dice: 0.2677  decode.d7.loss_cls: 0.3238  decode.d7.loss_mask: 0.2586  decode.d7.loss_dice: 0.2699  decode.d8.loss_cls: 0.3128  decode.d8.loss_mask: 0.2565  decode.d8.loss_dice: 0.2640
09/30 10:02:55 - mmengine - INFO - Iter(train) [  8300/320000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 1 day, 13:28:05  time: 0.4328  data_time: 0.0089  memory: 5180  grad_norm: 143.3722  loss: 9.6756  decode.loss_cls: 0.3144  decode.loss_mask: 0.2878  decode.loss_dice: 0.2428  decode.d0.loss_cls: 1.0332  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.2934  decode.d1.loss_cls: 0.4055  decode.d1.loss_mask: 0.2983  decode.d1.loss_dice: 0.2616  decode.d2.loss_cls: 0.3651  decode.d2.loss_mask: 0.2893  decode.d2.loss_dice: 0.2464  decode.d3.loss_cls: 0.3392  decode.d3.loss_mask: 0.2953  decode.d3.loss_dice: 0.2442  decode.d4.loss_cls: 0.4042  decode.d4.loss_mask: 0.2616  decode.d4.loss_dice: 0.2352  decode.d5.loss_cls: 0.3445  decode.d5.loss_mask: 0.2875  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.3284  decode.d6.loss_mask: 0.2843  decode.d6.loss_dice: 0.2589  decode.d7.loss_cls: 0.3322  decode.d7.loss_mask: 0.2964  decode.d7.loss_dice: 0.3050  decode.d8.loss_cls: 0.3037  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.2691
09/30 10:03:16 - mmengine - INFO - Iter(train) [  8350/320000]  base_lr: 9.7649e-05 lr: 9.7649e-06  eta: 1 day, 13:27:42  time: 0.4319  data_time: 0.0088  memory: 5160  grad_norm: 152.0375  loss: 13.0422  decode.loss_cls: 0.5027  decode.loss_mask: 0.3005  decode.loss_dice: 0.3442  decode.d0.loss_cls: 1.3928  decode.d0.loss_mask: 0.3248  decode.d0.loss_dice: 0.4356  decode.d1.loss_cls: 0.6162  decode.d1.loss_mask: 0.2986  decode.d1.loss_dice: 0.3767  decode.d2.loss_cls: 0.5355  decode.d2.loss_mask: 0.2974  decode.d2.loss_dice: 0.3592  decode.d3.loss_cls: 0.6208  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.3386  decode.d4.loss_cls: 0.5452  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.3400  decode.d5.loss_cls: 0.5572  decode.d5.loss_mask: 0.3231  decode.d5.loss_dice: 0.3503  decode.d6.loss_cls: 0.5576  decode.d6.loss_mask: 0.3075  decode.d6.loss_dice: 0.3696  decode.d7.loss_cls: 0.5159  decode.d7.loss_mask: 0.3030  decode.d7.loss_dice: 0.3382  decode.d8.loss_cls: 0.5251  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.3700
09/30 10:03:38 - mmengine - INFO - Iter(train) [  8400/320000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 1 day, 13:27:20  time: 0.4319  data_time: 0.0087  memory: 5180  grad_norm: 115.8570  loss: 8.4408  decode.loss_cls: 0.2303  decode.loss_mask: 0.3078  decode.loss_dice: 0.2622  decode.d0.loss_cls: 0.8374  decode.d0.loss_mask: 0.3014  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.1978  decode.d1.loss_mask: 0.3109  decode.d1.loss_dice: 0.2497  decode.d2.loss_cls: 0.1987  decode.d2.loss_mask: 0.3021  decode.d2.loss_dice: 0.2796  decode.d3.loss_cls: 0.1799  decode.d3.loss_mask: 0.3134  decode.d3.loss_dice: 0.2843  decode.d4.loss_cls: 0.1889  decode.d4.loss_mask: 0.3276  decode.d4.loss_dice: 0.2631  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 0.3190  decode.d5.loss_dice: 0.2561  decode.d6.loss_cls: 0.2004  decode.d6.loss_mask: 0.3457  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.2004  decode.d7.loss_mask: 0.3159  decode.d7.loss_dice: 0.2575  decode.d8.loss_cls: 0.1311  decode.d8.loss_mask: 0.4071  decode.d8.loss_dice: 0.2272
09/30 10:03:59 - mmengine - INFO - Iter(train) [  8450/320000]  base_lr: 9.7621e-05 lr: 9.7621e-06  eta: 1 day, 13:26:57  time: 0.4321  data_time: 0.0089  memory: 5180  grad_norm: 184.4904  loss: 11.0742  decode.loss_cls: 0.3337  decode.loss_mask: 0.3700  decode.loss_dice: 0.2908  decode.d0.loss_cls: 0.9992  decode.d0.loss_mask: 0.3816  decode.d0.loss_dice: 0.3082  decode.d1.loss_cls: 0.4235  decode.d1.loss_mask: 0.3672  decode.d1.loss_dice: 0.2918  decode.d2.loss_cls: 0.3964  decode.d2.loss_mask: 0.3773  decode.d2.loss_dice: 0.3009  decode.d3.loss_cls: 0.4022  decode.d3.loss_mask: 0.3812  decode.d3.loss_dice: 0.3027  decode.d4.loss_cls: 0.3344  decode.d4.loss_mask: 0.3909  decode.d4.loss_dice: 0.3268  decode.d5.loss_cls: 0.3971  decode.d5.loss_mask: 0.3806  decode.d5.loss_dice: 0.2878  decode.d6.loss_cls: 0.3372  decode.d6.loss_mask: 0.4055  decode.d6.loss_dice: 0.2944  decode.d7.loss_cls: 0.3263  decode.d7.loss_mask: 0.3792  decode.d7.loss_dice: 0.3006  decode.d8.loss_cls: 0.3212  decode.d8.loss_mask: 0.3730  decode.d8.loss_dice: 0.2923
09/30 10:04:21 - mmengine - INFO - Iter(train) [  8500/320000]  base_lr: 9.7606e-05 lr: 9.7606e-06  eta: 1 day, 13:26:34  time: 0.4318  data_time: 0.0088  memory: 5161  grad_norm: 151.3775  loss: 9.5109  decode.loss_cls: 0.2792  decode.loss_mask: 0.3662  decode.loss_dice: 0.2389  decode.d0.loss_cls: 1.0297  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.2837  decode.d1.loss_mask: 0.3353  decode.d1.loss_dice: 0.2672  decode.d2.loss_cls: 0.2913  decode.d2.loss_mask: 0.3408  decode.d2.loss_dice: 0.2580  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 0.3460  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.2968  decode.d4.loss_mask: 0.3432  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.2425  decode.d5.loss_mask: 0.3516  decode.d5.loss_dice: 0.2648  decode.d6.loss_cls: 0.2415  decode.d6.loss_mask: 0.3552  decode.d6.loss_dice: 0.2632  decode.d7.loss_cls: 0.2417  decode.d7.loss_mask: 0.3699  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.2858  decode.d8.loss_mask: 0.3671  decode.d8.loss_dice: 0.2454
09/30 10:04:43 - mmengine - INFO - Iter(train) [  8550/320000]  base_lr: 9.7592e-05 lr: 9.7592e-06  eta: 1 day, 13:26:10  time: 0.4326  data_time: 0.0089  memory: 5161  grad_norm: 144.0129  loss: 13.3775  decode.loss_cls: 0.5261  decode.loss_mask: 0.3955  decode.loss_dice: 0.2896  decode.d0.loss_cls: 1.4286  decode.d0.loss_mask: 0.3780  decode.d0.loss_dice: 0.3149  decode.d1.loss_cls: 0.5570  decode.d1.loss_mask: 0.3833  decode.d1.loss_dice: 0.2861  decode.d2.loss_cls: 0.6156  decode.d2.loss_mask: 0.4002  decode.d2.loss_dice: 0.2912  decode.d3.loss_cls: 0.5630  decode.d3.loss_mask: 0.3781  decode.d3.loss_dice: 0.2889  decode.d4.loss_cls: 0.5645  decode.d4.loss_mask: 0.4131  decode.d4.loss_dice: 0.2941  decode.d5.loss_cls: 0.5441  decode.d5.loss_mask: 0.4082  decode.d5.loss_dice: 0.3024  decode.d6.loss_cls: 0.5566  decode.d6.loss_mask: 0.4114  decode.d6.loss_dice: 0.3037  decode.d7.loss_cls: 0.4824  decode.d7.loss_mask: 0.4335  decode.d7.loss_dice: 0.3217  decode.d8.loss_cls: 0.5561  decode.d8.loss_mask: 0.3943  decode.d8.loss_dice: 0.2954
09/30 10:05:04 - mmengine - INFO - Iter(train) [  8600/320000]  base_lr: 9.7578e-05 lr: 9.7578e-06  eta: 1 day, 13:25:48  time: 0.4321  data_time: 0.0089  memory: 5161  grad_norm: 107.3320  loss: 7.7541  decode.loss_cls: 0.1562  decode.loss_mask: 0.2570  decode.loss_dice: 0.2567  decode.d0.loss_cls: 0.9071  decode.d0.loss_mask: 0.2688  decode.d0.loss_dice: 0.2712  decode.d1.loss_cls: 0.1940  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.2831  decode.d2.loss_cls: 0.2308  decode.d2.loss_mask: 0.2538  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.1828  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.2635  decode.d4.loss_cls: 0.1512  decode.d4.loss_mask: 0.2566  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.1948  decode.d5.loss_mask: 0.2542  decode.d5.loss_dice: 0.2691  decode.d6.loss_cls: 0.1424  decode.d6.loss_mask: 0.2560  decode.d6.loss_dice: 0.2757  decode.d7.loss_cls: 0.1474  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.2771  decode.d8.loss_cls: 0.1716  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.2615
09/30 10:05:26 - mmengine - INFO - Iter(train) [  8650/320000]  base_lr: 9.7564e-05 lr: 9.7564e-06  eta: 1 day, 13:25:26  time: 0.4324  data_time: 0.0090  memory: 5147  grad_norm: 131.6957  loss: 11.6166  decode.loss_cls: 0.5698  decode.loss_mask: 0.3065  decode.loss_dice: 0.2962  decode.d0.loss_cls: 0.9083  decode.d0.loss_mask: 0.3211  decode.d0.loss_dice: 0.2766  decode.d1.loss_cls: 0.4739  decode.d1.loss_mask: 0.3199  decode.d1.loss_dice: 0.2661  decode.d2.loss_cls: 0.4350  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.3035  decode.d3.loss_cls: 0.5135  decode.d3.loss_mask: 0.3257  decode.d3.loss_dice: 0.3170  decode.d4.loss_cls: 0.5017  decode.d4.loss_mask: 0.3197  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.5296  decode.d5.loss_mask: 0.3175  decode.d5.loss_dice: 0.2641  decode.d6.loss_cls: 0.5019  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.3067  decode.d7.loss_cls: 0.5606  decode.d7.loss_mask: 0.3091  decode.d7.loss_dice: 0.2939  decode.d8.loss_cls: 0.5904  decode.d8.loss_mask: 0.3164  decode.d8.loss_dice: 0.2784
09/30 10:05:47 - mmengine - INFO - Iter(train) [  8700/320000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 1 day, 13:25:04  time: 0.4326  data_time: 0.0089  memory: 5160  grad_norm: 122.2691  loss: 10.4308  decode.loss_cls: 0.4324  decode.loss_mask: 0.3715  decode.loss_dice: 0.2822  decode.d0.loss_cls: 1.0398  decode.d0.loss_mask: 0.3257  decode.d0.loss_dice: 0.2637  decode.d1.loss_cls: 0.3680  decode.d1.loss_mask: 0.3553  decode.d1.loss_dice: 0.2555  decode.d2.loss_cls: 0.3755  decode.d2.loss_mask: 0.3378  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.3121  decode.d3.loss_mask: 0.3381  decode.d3.loss_dice: 0.2675  decode.d4.loss_cls: 0.3122  decode.d4.loss_mask: 0.3354  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.2914  decode.d5.loss_mask: 0.4492  decode.d5.loss_dice: 0.2675  decode.d6.loss_cls: 0.3794  decode.d6.loss_mask: 0.3925  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.3084  decode.d7.loss_mask: 0.3646  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.3047  decode.d8.loss_mask: 0.3684  decode.d8.loss_dice: 0.2795
09/30 10:06:09 - mmengine - INFO - Iter(train) [  8750/320000]  base_lr: 9.7536e-05 lr: 9.7536e-06  eta: 1 day, 13:24:43  time: 0.4329  data_time: 0.0088  memory: 5180  grad_norm: 58.7288  loss: 9.3618  decode.loss_cls: 0.2671  decode.loss_mask: 0.2631  decode.loss_dice: 0.2883  decode.d0.loss_cls: 0.9113  decode.d0.loss_mask: 0.2682  decode.d0.loss_dice: 0.2940  decode.d1.loss_cls: 0.3001  decode.d1.loss_mask: 0.2673  decode.d1.loss_dice: 0.2951  decode.d2.loss_cls: 0.2364  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.3072  decode.d3.loss_cls: 0.3509  decode.d3.loss_mask: 0.2635  decode.d3.loss_dice: 0.2788  decode.d4.loss_cls: 0.3713  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.3024  decode.d5.loss_cls: 0.3222  decode.d5.loss_mask: 0.2671  decode.d5.loss_dice: 0.3169  decode.d6.loss_cls: 0.3553  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.2973  decode.d7.loss_cls: 0.3562  decode.d7.loss_mask: 0.2591  decode.d7.loss_dice: 0.2847  decode.d8.loss_cls: 0.3091  decode.d8.loss_mask: 0.2605  decode.d8.loss_dice: 0.2785
09/30 10:06:31 - mmengine - INFO - Iter(train) [  8800/320000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 1 day, 13:24:20  time: 0.4332  data_time: 0.0090  memory: 5160  grad_norm: 172.8168  loss: 13.9074  decode.loss_cls: 0.5870  decode.loss_mask: 0.3269  decode.loss_dice: 0.3842  decode.d0.loss_cls: 1.2208  decode.d0.loss_mask: 0.4099  decode.d0.loss_dice: 0.4111  decode.d1.loss_cls: 0.6220  decode.d1.loss_mask: 0.3735  decode.d1.loss_dice: 0.4031  decode.d2.loss_cls: 0.6290  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.3537  decode.d3.loss_cls: 0.5814  decode.d3.loss_mask: 0.3322  decode.d3.loss_dice: 0.3533  decode.d4.loss_cls: 0.5923  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.3601  decode.d5.loss_cls: 0.6113  decode.d5.loss_mask: 0.3272  decode.d5.loss_dice: 0.3678  decode.d6.loss_cls: 0.5257  decode.d6.loss_mask: 0.3794  decode.d6.loss_dice: 0.3864  decode.d7.loss_cls: 0.5038  decode.d7.loss_mask: 0.4220  decode.d7.loss_dice: 0.3929  decode.d8.loss_cls: 0.6067  decode.d8.loss_mask: 0.3788  decode.d8.loss_dice: 0.4103
09/30 10:06:52 - mmengine - INFO - Iter(train) [  8850/320000]  base_lr: 9.7508e-05 lr: 9.7508e-06  eta: 1 day, 13:23:57  time: 0.4309  data_time: 0.0088  memory: 5160  grad_norm: 143.0933  loss: 12.8575  decode.loss_cls: 0.5541  decode.loss_mask: 0.3505  decode.loss_dice: 0.3304  decode.d0.loss_cls: 1.2131  decode.d0.loss_mask: 0.3624  decode.d0.loss_dice: 0.3364  decode.d1.loss_cls: 0.5606  decode.d1.loss_mask: 0.3467  decode.d1.loss_dice: 0.3157  decode.d2.loss_cls: 0.5338  decode.d2.loss_mask: 0.3532  decode.d2.loss_dice: 0.3219  decode.d3.loss_cls: 0.5202  decode.d3.loss_mask: 0.3470  decode.d3.loss_dice: 0.2562  decode.d4.loss_cls: 0.5073  decode.d4.loss_mask: 0.3468  decode.d4.loss_dice: 0.2941  decode.d5.loss_cls: 0.5416  decode.d5.loss_mask: 0.3693  decode.d5.loss_dice: 0.3398  decode.d6.loss_cls: 0.6143  decode.d6.loss_mask: 0.3409  decode.d6.loss_dice: 0.3171  decode.d7.loss_cls: 0.6059  decode.d7.loss_mask: 0.3354  decode.d7.loss_dice: 0.2845  decode.d8.loss_cls: 0.6277  decode.d8.loss_mask: 0.3312  decode.d8.loss_dice: 0.2994
09/30 10:07:14 - mmengine - INFO - Iter(train) [  8900/320000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 1 day, 13:23:34  time: 0.4316  data_time: 0.0085  memory: 5180  grad_norm: 137.1857  loss: 9.4479  decode.loss_cls: 0.2761  decode.loss_mask: 0.3105  decode.loss_dice: 0.2586  decode.d0.loss_cls: 1.3361  decode.d0.loss_mask: 0.3528  decode.d0.loss_dice: 0.2997  decode.d1.loss_cls: 0.3464  decode.d1.loss_mask: 0.3179  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.2507  decode.d2.loss_mask: 0.3372  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.2165  decode.d4.loss_cls: 0.2711  decode.d4.loss_mask: 0.3158  decode.d4.loss_dice: 0.2449  decode.d5.loss_cls: 0.2855  decode.d5.loss_mask: 0.3110  decode.d5.loss_dice: 0.2335  decode.d6.loss_cls: 0.2666  decode.d6.loss_mask: 0.3209  decode.d6.loss_dice: 0.2380  decode.d7.loss_cls: 0.2713  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.2367  decode.d8.loss_cls: 0.2941  decode.d8.loss_mask: 0.3109  decode.d8.loss_dice: 0.2380
09/30 10:07:35 - mmengine - INFO - Iter(train) [  8950/320000]  base_lr: 9.7480e-05 lr: 9.7480e-06  eta: 1 day, 13:23:11  time: 0.4316  data_time: 0.0088  memory: 5147  grad_norm: 98.5055  loss: 10.4367  decode.loss_cls: 0.4670  decode.loss_mask: 0.3096  decode.loss_dice: 0.2196  decode.d0.loss_cls: 0.9648  decode.d0.loss_mask: 0.3319  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.5466  decode.d1.loss_mask: 0.3115  decode.d1.loss_dice: 0.2238  decode.d2.loss_cls: 0.4859  decode.d2.loss_mask: 0.3084  decode.d2.loss_dice: 0.2200  decode.d3.loss_cls: 0.4481  decode.d3.loss_mask: 0.3161  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.4592  decode.d4.loss_mask: 0.3138  decode.d4.loss_dice: 0.2341  decode.d5.loss_cls: 0.4285  decode.d5.loss_mask: 0.3060  decode.d5.loss_dice: 0.2179  decode.d6.loss_cls: 0.4172  decode.d6.loss_mask: 0.3151  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.4266  decode.d7.loss_mask: 0.3082  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.4331  decode.d8.loss_mask: 0.3074  decode.d8.loss_dice: 0.2175
09/30 10:07:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:07:57 - mmengine - INFO - Iter(train) [  9000/320000]  base_lr: 9.7465e-05 lr: 9.7465e-06  eta: 1 day, 13:22:49  time: 0.4335  data_time: 0.0087  memory: 5180  grad_norm: 129.6680  loss: 9.5462  decode.loss_cls: 0.2181  decode.loss_mask: 0.3579  decode.loss_dice: 0.2828  decode.d0.loss_cls: 1.1202  decode.d0.loss_mask: 0.3781  decode.d0.loss_dice: 0.2745  decode.d1.loss_cls: 0.2052  decode.d1.loss_mask: 0.3735  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.2292  decode.d2.loss_mask: 0.3638  decode.d2.loss_dice: 0.2750  decode.d3.loss_cls: 0.2716  decode.d3.loss_mask: 0.3566  decode.d3.loss_dice: 0.2742  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 0.3610  decode.d4.loss_dice: 0.2651  decode.d5.loss_cls: 0.1725  decode.d5.loss_mask: 0.3581  decode.d5.loss_dice: 0.2735  decode.d6.loss_cls: 0.2119  decode.d6.loss_mask: 0.3631  decode.d6.loss_dice: 0.2690  decode.d7.loss_cls: 0.2418  decode.d7.loss_mask: 0.3581  decode.d7.loss_dice: 0.2744  decode.d8.loss_cls: 0.2875  decode.d8.loss_mask: 0.3661  decode.d8.loss_dice: 0.2727
09/30 10:08:19 - mmengine - INFO - Iter(train) [  9050/320000]  base_lr: 9.7451e-05 lr: 9.7451e-06  eta: 1 day, 13:22:25  time: 0.4315  data_time: 0.0086  memory: 5161  grad_norm: 89.9783  loss: 9.6885  decode.loss_cls: 0.3037  decode.loss_mask: 0.2589  decode.loss_dice: 0.3152  decode.d0.loss_cls: 0.9691  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2943  decode.d1.loss_cls: 0.3715  decode.d1.loss_mask: 0.2642  decode.d1.loss_dice: 0.2918  decode.d2.loss_cls: 0.3050  decode.d2.loss_mask: 0.2677  decode.d2.loss_dice: 0.3170  decode.d3.loss_cls: 0.3418  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.3135  decode.d4.loss_cls: 0.4053  decode.d4.loss_mask: 0.2514  decode.d4.loss_dice: 0.3001  decode.d5.loss_cls: 0.3640  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.3206  decode.d6.loss_cls: 0.3885  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.2962  decode.d7.loss_cls: 0.2613  decode.d7.loss_mask: 0.2525  decode.d7.loss_dice: 0.3014  decode.d8.loss_cls: 0.3460  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.3115
09/30 10:08:40 - mmengine - INFO - Iter(train) [  9100/320000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 1 day, 13:22:01  time: 0.4305  data_time: 0.0083  memory: 5146  grad_norm: 76.0190  loss: 8.2136  decode.loss_cls: 0.2123  decode.loss_mask: 0.3080  decode.loss_dice: 0.2279  decode.d0.loss_cls: 0.9405  decode.d0.loss_mask: 0.3175  decode.d0.loss_dice: 0.2643  decode.d1.loss_cls: 0.2834  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.1601  decode.d2.loss_mask: 0.3095  decode.d2.loss_dice: 0.2422  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.2596  decode.d4.loss_cls: 0.1749  decode.d4.loss_mask: 0.3082  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 0.3075  decode.d5.loss_dice: 0.2457  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 0.3210  decode.d6.loss_dice: 0.2638  decode.d7.loss_cls: 0.1360  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.2625  decode.d8.loss_cls: 0.2111  decode.d8.loss_mask: 0.3091  decode.d8.loss_dice: 0.2255
09/30 10:09:02 - mmengine - INFO - Iter(train) [  9150/320000]  base_lr: 9.7423e-05 lr: 9.7423e-06  eta: 1 day, 13:21:38  time: 0.4313  data_time: 0.0088  memory: 5160  grad_norm: 215.6349  loss: 12.9540  decode.loss_cls: 0.4704  decode.loss_mask: 0.3694  decode.loss_dice: 0.3430  decode.d0.loss_cls: 1.2771  decode.d0.loss_mask: 0.3754  decode.d0.loss_dice: 0.3797  decode.d1.loss_cls: 0.5549  decode.d1.loss_mask: 0.3618  decode.d1.loss_dice: 0.4003  decode.d2.loss_cls: 0.5666  decode.d2.loss_mask: 0.3585  decode.d2.loss_dice: 0.3724  decode.d3.loss_cls: 0.4712  decode.d3.loss_mask: 0.3665  decode.d3.loss_dice: 0.3676  decode.d4.loss_cls: 0.4588  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.3451  decode.d5.loss_cls: 0.4714  decode.d5.loss_mask: 0.3634  decode.d5.loss_dice: 0.3612  decode.d6.loss_cls: 0.4141  decode.d6.loss_mask: 0.3738  decode.d6.loss_dice: 0.3680  decode.d7.loss_cls: 0.4472  decode.d7.loss_mask: 0.3788  decode.d7.loss_dice: 0.3822  decode.d8.loss_cls: 0.4622  decode.d8.loss_mask: 0.3830  decode.d8.loss_dice: 0.3445
09/30 10:09:23 - mmengine - INFO - Iter(train) [  9200/320000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 1 day, 13:21:13  time: 0.4322  data_time: 0.0085  memory: 5161  grad_norm: 92.2377  loss: 8.0916  decode.loss_cls: 0.2096  decode.loss_mask: 0.2712  decode.loss_dice: 0.2343  decode.d0.loss_cls: 1.1290  decode.d0.loss_mask: 0.2752  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.3206  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.1892  decode.d2.loss_mask: 0.2677  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.2155  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.1779  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.2360  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.2709  decode.d5.loss_dice: 0.2311  decode.d6.loss_cls: 0.2161  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.2305  decode.d7.loss_cls: 0.1895  decode.d7.loss_mask: 0.2698  decode.d7.loss_dice: 0.2342  decode.d8.loss_cls: 0.2495  decode.d8.loss_mask: 0.2703  decode.d8.loss_dice: 0.2391
09/30 10:09:45 - mmengine - INFO - Iter(train) [  9250/320000]  base_lr: 9.7395e-05 lr: 9.7395e-06  eta: 1 day, 13:20:50  time: 0.4309  data_time: 0.0085  memory: 5147  grad_norm: 98.6179  loss: 10.3008  decode.loss_cls: 0.2437  decode.loss_mask: 0.4663  decode.loss_dice: 0.2902  decode.d0.loss_cls: 0.7809  decode.d0.loss_mask: 0.4720  decode.d0.loss_dice: 0.2977  decode.d1.loss_cls: 0.2023  decode.d1.loss_mask: 0.4790  decode.d1.loss_dice: 0.2929  decode.d2.loss_cls: 0.2182  decode.d2.loss_mask: 0.4582  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.1847  decode.d3.loss_mask: 0.4578  decode.d3.loss_dice: 0.3000  decode.d4.loss_cls: 0.1918  decode.d4.loss_mask: 0.4559  decode.d4.loss_dice: 0.2831  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 0.4693  decode.d5.loss_dice: 0.3206  decode.d6.loss_cls: 0.2336  decode.d6.loss_mask: 0.4608  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.2041  decode.d7.loss_mask: 0.4644  decode.d7.loss_dice: 0.2850  decode.d8.loss_cls: 0.2666  decode.d8.loss_mask: 0.4666  decode.d8.loss_dice: 0.2961
09/30 10:10:07 - mmengine - INFO - Iter(train) [  9300/320000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 1 day, 13:20:26  time: 0.4320  data_time: 0.0086  memory: 5161  grad_norm: 173.8698  loss: 10.7108  decode.loss_cls: 0.3533  decode.loss_mask: 0.3067  decode.loss_dice: 0.3233  decode.d0.loss_cls: 1.0051  decode.d0.loss_mask: 0.2866  decode.d0.loss_dice: 0.3431  decode.d1.loss_cls: 0.3661  decode.d1.loss_mask: 0.2796  decode.d1.loss_dice: 0.3328  decode.d2.loss_cls: 0.3287  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.3152  decode.d3.loss_cls: 0.3572  decode.d3.loss_mask: 0.3260  decode.d3.loss_dice: 0.3285  decode.d4.loss_cls: 0.3828  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.3062  decode.d5.loss_cls: 0.3758  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.3924  decode.d6.loss_mask: 0.3340  decode.d6.loss_dice: 0.3261  decode.d7.loss_cls: 0.4301  decode.d7.loss_mask: 0.3455  decode.d7.loss_dice: 0.3358  decode.d8.loss_cls: 0.2961  decode.d8.loss_mask: 0.4059  decode.d8.loss_dice: 0.3375
09/30 10:10:28 - mmengine - INFO - Iter(train) [  9350/320000]  base_lr: 9.7367e-05 lr: 9.7367e-06  eta: 1 day, 13:20:03  time: 0.4313  data_time: 0.0087  memory: 5161  grad_norm: 86.5285  loss: 7.6848  decode.loss_cls: 0.1896  decode.loss_mask: 0.2456  decode.loss_dice: 0.2001  decode.d0.loss_cls: 1.0862  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.2394  decode.d1.loss_cls: 0.3827  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.2095  decode.d2.loss_cls: 0.3011  decode.d2.loss_mask: 0.2418  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.1728  decode.d3.loss_mask: 0.2531  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.1860  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2345  decode.d5.loss_cls: 0.1574  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2278  decode.d6.loss_cls: 0.1589  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2011  decode.d7.loss_cls: 0.1666  decode.d7.loss_mask: 0.2498  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.2096  decode.d8.loss_mask: 0.2532  decode.d8.loss_dice: 0.2188
09/30 10:10:50 - mmengine - INFO - Iter(train) [  9400/320000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 1 day, 13:19:40  time: 0.4321  data_time: 0.0087  memory: 5147  grad_norm: 184.6544  loss: 12.5112  decode.loss_cls: 0.3411  decode.loss_mask: 0.3667  decode.loss_dice: 0.3524  decode.d0.loss_cls: 1.2974  decode.d0.loss_mask: 0.4334  decode.d0.loss_dice: 0.4068  decode.d1.loss_cls: 0.5954  decode.d1.loss_mask: 0.4183  decode.d1.loss_dice: 0.3791  decode.d2.loss_cls: 0.4519  decode.d2.loss_mask: 0.3975  decode.d2.loss_dice: 0.3736  decode.d3.loss_cls: 0.4226  decode.d3.loss_mask: 0.3864  decode.d3.loss_dice: 0.3842  decode.d4.loss_cls: 0.3922  decode.d4.loss_mask: 0.3806  decode.d4.loss_dice: 0.3947  decode.d5.loss_cls: 0.3878  decode.d5.loss_mask: 0.3726  decode.d5.loss_dice: 0.3626  decode.d6.loss_cls: 0.3343  decode.d6.loss_mask: 0.3718  decode.d6.loss_dice: 0.3511  decode.d7.loss_cls: 0.3245  decode.d7.loss_mask: 0.3832  decode.d7.loss_dice: 0.3564  decode.d8.loss_cls: 0.3173  decode.d8.loss_mask: 0.3812  decode.d8.loss_dice: 0.3940
09/30 10:11:11 - mmengine - INFO - Iter(train) [  9450/320000]  base_lr: 9.7338e-05 lr: 9.7338e-06  eta: 1 day, 13:19:17  time: 0.4314  data_time: 0.0086  memory: 5161  grad_norm: 118.3367  loss: 7.3542  decode.loss_cls: 0.1453  decode.loss_mask: 0.3030  decode.loss_dice: 0.2296  decode.d0.loss_cls: 0.9973  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.2157  decode.d1.loss_cls: 0.2056  decode.d1.loss_mask: 0.2418  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.1745  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2540  decode.d3.loss_cls: 0.1664  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.2192  decode.d4.loss_cls: 0.1802  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2236  decode.d5.loss_cls: 0.1559  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.2136  decode.d6.loss_cls: 0.1444  decode.d6.loss_mask: 0.2788  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.2034  decode.d7.loss_mask: 0.3054  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.1499  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.2111
09/30 10:11:33 - mmengine - INFO - Iter(train) [  9500/320000]  base_lr: 9.7324e-05 lr: 9.7324e-06  eta: 1 day, 13:18:58  time: 0.4466  data_time: 0.0085  memory: 5180  grad_norm: 53.1367  loss: 7.9239  decode.loss_cls: 0.1785  decode.loss_mask: 0.2566  decode.loss_dice: 0.2177  decode.d0.loss_cls: 0.9853  decode.d0.loss_mask: 0.2794  decode.d0.loss_dice: 0.2480  decode.d1.loss_cls: 0.2848  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.2155  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.2285  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.2199  decode.d4.loss_cls: 0.2533  decode.d4.loss_mask: 0.2588  decode.d4.loss_dice: 0.2233  decode.d5.loss_cls: 0.2273  decode.d5.loss_mask: 0.2651  decode.d5.loss_dice: 0.2174  decode.d6.loss_cls: 0.2216  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.2335  decode.d7.loss_cls: 0.2362  decode.d7.loss_mask: 0.2657  decode.d7.loss_dice: 0.2206  decode.d8.loss_cls: 0.2205  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.2192
09/30 10:11:55 - mmengine - INFO - Iter(train) [  9550/320000]  base_lr: 9.7310e-05 lr: 9.7310e-06  eta: 1 day, 13:18:36  time: 0.4312  data_time: 0.0084  memory: 5161  grad_norm: 54.4238  loss: 7.1528  decode.loss_cls: 0.1581  decode.loss_mask: 0.1909  decode.loss_dice: 0.2313  decode.d0.loss_cls: 0.9308  decode.d0.loss_mask: 0.1982  decode.d0.loss_dice: 0.2508  decode.d1.loss_cls: 0.3199  decode.d1.loss_mask: 0.2087  decode.d1.loss_dice: 0.2656  decode.d2.loss_cls: 0.2238  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.2279  decode.d3.loss_cls: 0.1931  decode.d3.loss_mask: 0.1961  decode.d3.loss_dice: 0.2135  decode.d4.loss_cls: 0.2215  decode.d4.loss_mask: 0.1969  decode.d4.loss_dice: 0.2197  decode.d5.loss_cls: 0.2412  decode.d5.loss_mask: 0.1937  decode.d5.loss_dice: 0.2151  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 0.1916  decode.d6.loss_dice: 0.2332  decode.d7.loss_cls: 0.2059  decode.d7.loss_mask: 0.1938  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.2201  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.2243
09/30 10:12:16 - mmengine - INFO - Iter(train) [  9600/320000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 1 day, 13:18:13  time: 0.4316  data_time: 0.0086  memory: 5147  grad_norm: 141.8842  loss: 9.0462  decode.loss_cls: 0.3167  decode.loss_mask: 0.2913  decode.loss_dice: 0.2316  decode.d0.loss_cls: 1.0432  decode.d0.loss_mask: 0.3029  decode.d0.loss_dice: 0.2610  decode.d1.loss_cls: 0.3740  decode.d1.loss_mask: 0.2700  decode.d1.loss_dice: 0.2084  decode.d2.loss_cls: 0.2621  decode.d2.loss_mask: 0.3065  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.2802  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.2720  decode.d4.loss_mask: 0.2991  decode.d4.loss_dice: 0.2449  decode.d5.loss_cls: 0.2574  decode.d5.loss_mask: 0.2985  decode.d5.loss_dice: 0.2537  decode.d6.loss_cls: 0.3035  decode.d6.loss_mask: 0.2741  decode.d6.loss_dice: 0.2452  decode.d7.loss_cls: 0.2970  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.2505  decode.d8.loss_cls: 0.3158  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.2347
09/30 10:12:38 - mmengine - INFO - Iter(train) [  9650/320000]  base_lr: 9.7282e-05 lr: 9.7282e-06  eta: 1 day, 13:17:50  time: 0.4325  data_time: 0.0087  memory: 5146  grad_norm: 82.5416  loss: 8.8028  decode.loss_cls: 0.3719  decode.loss_mask: 0.2680  decode.loss_dice: 0.2318  decode.d0.loss_cls: 1.0923  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.4101  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2148  decode.d2.loss_cls: 0.3503  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.1913  decode.d3.loss_cls: 0.3362  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.3191  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.2992  decode.d5.loss_mask: 0.2511  decode.d5.loss_dice: 0.2320  decode.d6.loss_cls: 0.2626  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.3380  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.2300  decode.d8.loss_cls: 0.2944  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.2182
09/30 10:12:59 - mmengine - INFO - Iter(train) [  9700/320000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 1 day, 13:17:27  time: 0.4326  data_time: 0.0088  memory: 5180  grad_norm: 148.8102  loss: 15.0944  decode.loss_cls: 0.6646  decode.loss_mask: 0.3788  decode.loss_dice: 0.3841  decode.d0.loss_cls: 1.1987  decode.d0.loss_mask: 0.4111  decode.d0.loss_dice: 0.4794  decode.d1.loss_cls: 0.7366  decode.d1.loss_mask: 0.3931  decode.d1.loss_dice: 0.4053  decode.d2.loss_cls: 0.6964  decode.d2.loss_mask: 0.3683  decode.d2.loss_dice: 0.3904  decode.d3.loss_cls: 0.7437  decode.d3.loss_mask: 0.3702  decode.d3.loss_dice: 0.3662  decode.d4.loss_cls: 0.6544  decode.d4.loss_mask: 0.3860  decode.d4.loss_dice: 0.3670  decode.d5.loss_cls: 0.6423  decode.d5.loss_mask: 0.4029  decode.d5.loss_dice: 0.3568  decode.d6.loss_cls: 0.7247  decode.d6.loss_mask: 0.3929  decode.d6.loss_dice: 0.3686  decode.d7.loss_cls: 0.6489  decode.d7.loss_mask: 0.3808  decode.d7.loss_dice: 0.3650  decode.d8.loss_cls: 0.6689  decode.d8.loss_mask: 0.3764  decode.d8.loss_dice: 0.3719
09/30 10:13:21 - mmengine - INFO - Iter(train) [  9750/320000]  base_lr: 9.7254e-05 lr: 9.7254e-06  eta: 1 day, 13:17:04  time: 0.4318  data_time: 0.0088  memory: 5161  grad_norm: 87.5947  loss: 12.1558  decode.loss_cls: 0.4252  decode.loss_mask: 0.3510  decode.loss_dice: 0.2919  decode.d0.loss_cls: 1.0399  decode.d0.loss_mask: 0.4783  decode.d0.loss_dice: 0.3632  decode.d1.loss_cls: 0.4524  decode.d1.loss_mask: 0.4447  decode.d1.loss_dice: 0.3207  decode.d2.loss_cls: 0.4076  decode.d2.loss_mask: 0.4470  decode.d2.loss_dice: 0.3196  decode.d3.loss_cls: 0.3440  decode.d3.loss_mask: 0.4282  decode.d3.loss_dice: 0.3159  decode.d4.loss_cls: 0.3511  decode.d4.loss_mask: 0.4707  decode.d4.loss_dice: 0.3394  decode.d5.loss_cls: 0.3912  decode.d5.loss_mask: 0.4308  decode.d5.loss_dice: 0.3399  decode.d6.loss_cls: 0.3193  decode.d6.loss_mask: 0.4448  decode.d6.loss_dice: 0.3313  decode.d7.loss_cls: 0.4341  decode.d7.loss_mask: 0.3815  decode.d7.loss_dice: 0.3297  decode.d8.loss_cls: 0.4214  decode.d8.loss_mask: 0.4337  decode.d8.loss_dice: 0.3074
09/30 10:13:43 - mmengine - INFO - Iter(train) [  9800/320000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 1 day, 13:16:42  time: 0.4316  data_time: 0.0087  memory: 5146  grad_norm: 76.1849  loss: 8.2589  decode.loss_cls: 0.2375  decode.loss_mask: 0.2821  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.8407  decode.d0.loss_mask: 0.2776  decode.d0.loss_dice: 0.3051  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 0.2706  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.1719  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2894  decode.d3.loss_cls: 0.2358  decode.d3.loss_mask: 0.2675  decode.d3.loss_dice: 0.2748  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 0.2659  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 0.2712  decode.d5.loss_dice: 0.2682  decode.d6.loss_cls: 0.2675  decode.d6.loss_mask: 0.2688  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.2424  decode.d7.loss_mask: 0.2643  decode.d7.loss_dice: 0.2609  decode.d8.loss_cls: 0.2263  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.2690
09/30 10:14:04 - mmengine - INFO - Iter(train) [  9850/320000]  base_lr: 9.7226e-05 lr: 9.7226e-06  eta: 1 day, 13:16:19  time: 0.4312  data_time: 0.0086  memory: 5161  grad_norm: 66.7074  loss: 8.8271  decode.loss_cls: 0.2343  decode.loss_mask: 0.2947  decode.loss_dice: 0.2287  decode.d0.loss_cls: 1.0690  decode.d0.loss_mask: 0.3021  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.3829  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.2959  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.2370  decode.d3.loss_cls: 0.2692  decode.d3.loss_mask: 0.2878  decode.d3.loss_dice: 0.2310  decode.d4.loss_cls: 0.2443  decode.d4.loss_mask: 0.2852  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.2424  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.2521  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.2603  decode.d7.loss_cls: 0.2684  decode.d7.loss_mask: 0.2852  decode.d7.loss_dice: 0.2572  decode.d8.loss_cls: 0.2560  decode.d8.loss_mask: 0.2921  decode.d8.loss_dice: 0.2471
09/30 10:14:26 - mmengine - INFO - Iter(train) [  9900/320000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 1 day, 13:15:56  time: 0.4314  data_time: 0.0087  memory: 5132  grad_norm: 73.5477  loss: 6.3577  decode.loss_cls: 0.0958  decode.loss_mask: 0.2664  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.9982  decode.d0.loss_mask: 0.2714  decode.d0.loss_dice: 0.1880  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.1691  decode.d2.loss_cls: 0.1515  decode.d2.loss_mask: 0.2649  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.1017  decode.d3.loss_mask: 0.2706  decode.d3.loss_dice: 0.1712  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 0.2650  decode.d4.loss_dice: 0.1667  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.2693  decode.d5.loss_dice: 0.1711  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.2705  decode.d6.loss_dice: 0.1763  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.2701  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.2676  decode.d8.loss_dice: 0.1678
09/30 10:14:47 - mmengine - INFO - Iter(train) [  9950/320000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 1 day, 13:15:33  time: 0.4328  data_time: 0.0088  memory: 5180  grad_norm: 100.9532  loss: 11.7531  decode.loss_cls: 0.4472  decode.loss_mask: 0.3893  decode.loss_dice: 0.3273  decode.d0.loss_cls: 1.0326  decode.d0.loss_mask: 0.3600  decode.d0.loss_dice: 0.3510  decode.d1.loss_cls: 0.4682  decode.d1.loss_mask: 0.3570  decode.d1.loss_dice: 0.3116  decode.d2.loss_cls: 0.3295  decode.d2.loss_mask: 0.3616  decode.d2.loss_dice: 0.3274  decode.d3.loss_cls: 0.3844  decode.d3.loss_mask: 0.3575  decode.d3.loss_dice: 0.3271  decode.d4.loss_cls: 0.4431  decode.d4.loss_mask: 0.3601  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 0.4315  decode.d5.loss_mask: 0.3539  decode.d5.loss_dice: 0.3159  decode.d6.loss_cls: 0.4548  decode.d6.loss_mask: 0.3668  decode.d6.loss_dice: 0.3280  decode.d7.loss_cls: 0.4562  decode.d7.loss_mask: 0.3683  decode.d7.loss_dice: 0.3135  decode.d8.loss_cls: 0.4373  decode.d8.loss_mask: 0.3796  decode.d8.loss_dice: 0.3112
09/30 10:15:09 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:15:09 - mmengine - INFO - Iter(train) [ 10000/320000]  base_lr: 9.7183e-05 lr: 9.7183e-06  eta: 1 day, 13:15:11  time: 0.4325  data_time: 0.0088  memory: 5160  grad_norm: 356.8860  loss: 15.1555  decode.loss_cls: 0.4583  decode.loss_mask: 0.5216  decode.loss_dice: 0.4197  decode.d0.loss_cls: 1.3169  decode.d0.loss_mask: 0.5285  decode.d0.loss_dice: 0.4063  decode.d1.loss_cls: 0.4953  decode.d1.loss_mask: 0.5264  decode.d1.loss_dice: 0.4214  decode.d2.loss_cls: 0.4874  decode.d2.loss_mask: 0.5063  decode.d2.loss_dice: 0.4000  decode.d3.loss_cls: 0.4828  decode.d3.loss_mask: 0.5322  decode.d3.loss_dice: 0.4026  decode.d4.loss_cls: 0.4571  decode.d4.loss_mask: 0.5008  decode.d4.loss_dice: 0.3894  decode.d5.loss_cls: 0.4772  decode.d5.loss_mask: 0.5803  decode.d5.loss_dice: 0.4165  decode.d6.loss_cls: 0.4819  decode.d6.loss_mask: 0.5782  decode.d6.loss_dice: 0.4319  decode.d7.loss_cls: 0.4865  decode.d7.loss_mask: 0.5324  decode.d7.loss_dice: 0.4043  decode.d8.loss_cls: 0.4743  decode.d8.loss_mask: 0.6058  decode.d8.loss_dice: 0.4331
09/30 10:15:31 - mmengine - INFO - Iter(train) [ 10050/320000]  base_lr: 9.7169e-05 lr: 9.7169e-06  eta: 1 day, 13:14:48  time: 0.4321  data_time: 0.0088  memory: 5160  grad_norm: 184.5324  loss: 15.1434  decode.loss_cls: 0.3640  decode.loss_mask: 0.9115  decode.loss_dice: 0.3460  decode.d0.loss_cls: 1.2024  decode.d0.loss_mask: 0.4769  decode.d0.loss_dice: 0.3782  decode.d1.loss_cls: 0.5511  decode.d1.loss_mask: 0.4793  decode.d1.loss_dice: 0.3148  decode.d2.loss_cls: 0.5253  decode.d2.loss_mask: 0.4945  decode.d2.loss_dice: 0.2937  decode.d3.loss_cls: 0.4875  decode.d3.loss_mask: 0.4951  decode.d3.loss_dice: 0.3544  decode.d4.loss_cls: 0.4226  decode.d4.loss_mask: 0.7281  decode.d4.loss_dice: 0.3095  decode.d5.loss_cls: 0.5461  decode.d5.loss_mask: 0.4888  decode.d5.loss_dice: 0.3281  decode.d6.loss_cls: 0.5478  decode.d6.loss_mask: 0.5080  decode.d6.loss_dice: 0.3134  decode.d7.loss_cls: 0.3931  decode.d7.loss_mask: 0.7527  decode.d7.loss_dice: 0.3751  decode.d8.loss_cls: 0.3964  decode.d8.loss_mask: 1.0128  decode.d8.loss_dice: 0.3459
09/30 10:15:52 - mmengine - INFO - Iter(train) [ 10100/320000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 1 day, 13:14:24  time: 0.4305  data_time: 0.0087  memory: 5180  grad_norm: 66.5665  loss: 7.1246  decode.loss_cls: 0.2192  decode.loss_mask: 0.2435  decode.loss_dice: 0.1731  decode.d0.loss_cls: 1.0032  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.2152  decode.d1.loss_mask: 0.2576  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.2052  decode.d3.loss_mask: 0.2479  decode.d3.loss_dice: 0.1690  decode.d4.loss_cls: 0.2246  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.1689  decode.d5.loss_cls: 0.2192  decode.d5.loss_mask: 0.2529  decode.d5.loss_dice: 0.1773  decode.d6.loss_cls: 0.1999  decode.d6.loss_mask: 0.2438  decode.d6.loss_dice: 0.1706  decode.d7.loss_cls: 0.2061  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.1750  decode.d8.loss_cls: 0.1993  decode.d8.loss_mask: 0.2488  decode.d8.loss_dice: 0.1742
09/30 10:16:14 - mmengine - INFO - Iter(train) [ 10150/320000]  base_lr: 9.7141e-05 lr: 9.7141e-06  eta: 1 day, 13:14:01  time: 0.4313  data_time: 0.0084  memory: 5160  grad_norm: 146.7148  loss: 11.4465  decode.loss_cls: 0.4665  decode.loss_mask: 0.3473  decode.loss_dice: 0.2564  decode.d0.loss_cls: 1.4712  decode.d0.loss_mask: 0.4036  decode.d0.loss_dice: 0.3410  decode.d1.loss_cls: 0.5271  decode.d1.loss_mask: 0.3653  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.4381  decode.d2.loss_mask: 0.3312  decode.d2.loss_dice: 0.2834  decode.d3.loss_cls: 0.3823  decode.d3.loss_mask: 0.3201  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.3669  decode.d4.loss_mask: 0.3099  decode.d4.loss_dice: 0.2566  decode.d5.loss_cls: 0.4035  decode.d5.loss_mask: 0.3391  decode.d5.loss_dice: 0.2606  decode.d6.loss_cls: 0.4074  decode.d6.loss_mask: 0.3274  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.4481  decode.d7.loss_mask: 0.3307  decode.d7.loss_dice: 0.2627  decode.d8.loss_cls: 0.4108  decode.d8.loss_mask: 0.3217  decode.d8.loss_dice: 0.2670
09/30 10:16:35 - mmengine - INFO - Iter(train) [ 10200/320000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 1 day, 13:13:37  time: 0.4316  data_time: 0.0086  memory: 5179  grad_norm: 49.6348  loss: 6.9076  decode.loss_cls: 0.1618  decode.loss_mask: 0.2682  decode.loss_dice: 0.1771  decode.d0.loss_cls: 0.9832  decode.d0.loss_mask: 0.2736  decode.d0.loss_dice: 0.2124  decode.d1.loss_cls: 0.1626  decode.d1.loss_mask: 0.2740  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.1510  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.1486  decode.d3.loss_mask: 0.2652  decode.d3.loss_dice: 0.1977  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.2711  decode.d4.loss_dice: 0.1976  decode.d5.loss_cls: 0.1424  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.1272  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.1974  decode.d7.loss_cls: 0.1381  decode.d7.loss_mask: 0.2680  decode.d7.loss_dice: 0.1958  decode.d8.loss_cls: 0.1467  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.1891
09/30 10:16:57 - mmengine - INFO - Iter(train) [ 10250/320000]  base_lr: 9.7113e-05 lr: 9.7113e-06  eta: 1 day, 13:13:13  time: 0.4307  data_time: 0.0083  memory: 5180  grad_norm: 197.7228  loss: 11.9588  decode.loss_cls: 0.4096  decode.loss_mask: 0.3431  decode.loss_dice: 0.2918  decode.d0.loss_cls: 1.1382  decode.d0.loss_mask: 0.3672  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.4837  decode.d1.loss_mask: 0.3742  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.5125  decode.d2.loss_mask: 0.3639  decode.d2.loss_dice: 0.2754  decode.d3.loss_cls: 0.5258  decode.d3.loss_mask: 0.3509  decode.d3.loss_dice: 0.2625  decode.d4.loss_cls: 0.4840  decode.d4.loss_mask: 0.3671  decode.d4.loss_dice: 0.2903  decode.d5.loss_cls: 0.4732  decode.d5.loss_mask: 0.3985  decode.d5.loss_dice: 0.2882  decode.d6.loss_cls: 0.5030  decode.d6.loss_mask: 0.3605  decode.d6.loss_dice: 0.2844  decode.d7.loss_cls: 0.5734  decode.d7.loss_mask: 0.3454  decode.d7.loss_dice: 0.2889  decode.d8.loss_cls: 0.4206  decode.d8.loss_mask: 0.3496  decode.d8.loss_dice: 0.2768
09/30 10:17:18 - mmengine - INFO - Iter(train) [ 10300/320000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 1 day, 13:12:51  time: 0.4320  data_time: 0.0087  memory: 5180  grad_norm: 143.8030  loss: 8.3529  decode.loss_cls: 0.2086  decode.loss_mask: 0.2257  decode.loss_dice: 0.2662  decode.d0.loss_cls: 0.9540  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.2272  decode.d1.loss_cls: 0.3597  decode.d1.loss_mask: 0.2228  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.3435  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.2547  decode.d3.loss_cls: 0.2575  decode.d3.loss_mask: 0.2276  decode.d3.loss_dice: 0.2714  decode.d4.loss_cls: 0.2728  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.2711  decode.d5.loss_cls: 0.2375  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.2964  decode.d6.loss_cls: 0.3108  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2518  decode.d7.loss_cls: 0.2594  decode.d7.loss_mask: 0.2289  decode.d7.loss_dice: 0.2476  decode.d8.loss_cls: 0.2685  decode.d8.loss_mask: 0.2355  decode.d8.loss_dice: 0.2583
09/30 10:17:40 - mmengine - INFO - Iter(train) [ 10350/320000]  base_lr: 9.7085e-05 lr: 9.7085e-06  eta: 1 day, 13:12:28  time: 0.4313  data_time: 0.0088  memory: 5161  grad_norm: 121.7700  loss: 10.9665  decode.loss_cls: 0.2282  decode.loss_mask: 0.4041  decode.loss_dice: 0.3515  decode.d0.loss_cls: 1.0476  decode.d0.loss_mask: 0.4136  decode.d0.loss_dice: 0.3622  decode.d1.loss_cls: 0.3331  decode.d1.loss_mask: 0.4083  decode.d1.loss_dice: 0.3327  decode.d2.loss_cls: 0.2774  decode.d2.loss_mask: 0.4091  decode.d2.loss_dice: 0.3241  decode.d3.loss_cls: 0.2859  decode.d3.loss_mask: 0.4059  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 0.3063  decode.d4.loss_mask: 0.3995  decode.d4.loss_dice: 0.3395  decode.d5.loss_cls: 0.2861  decode.d5.loss_mask: 0.4078  decode.d5.loss_dice: 0.3327  decode.d6.loss_cls: 0.2482  decode.d6.loss_mask: 0.4058  decode.d6.loss_dice: 0.3408  decode.d7.loss_cls: 0.2402  decode.d7.loss_mask: 0.4048  decode.d7.loss_dice: 0.3534  decode.d8.loss_cls: 0.2206  decode.d8.loss_mask: 0.4061  decode.d8.loss_dice: 0.3618
09/30 10:18:02 - mmengine - INFO - Iter(train) [ 10400/320000]  base_lr: 9.7070e-05 lr: 9.7070e-06  eta: 1 day, 13:12:06  time: 0.4325  data_time: 0.0089  memory: 5161  grad_norm: 135.4844  loss: 7.9738  decode.loss_cls: 0.2506  decode.loss_mask: 0.2866  decode.loss_dice: 0.2425  decode.d0.loss_cls: 0.8700  decode.d0.loss_mask: 0.2838  decode.d0.loss_dice: 0.2365  decode.d1.loss_cls: 0.2146  decode.d1.loss_mask: 0.2706  decode.d1.loss_dice: 0.2324  decode.d2.loss_cls: 0.2266  decode.d2.loss_mask: 0.2846  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.2026  decode.d3.loss_mask: 0.2755  decode.d3.loss_dice: 0.2190  decode.d4.loss_cls: 0.2309  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.2201  decode.d5.loss_cls: 0.2250  decode.d5.loss_mask: 0.2775  decode.d5.loss_dice: 0.2207  decode.d6.loss_cls: 0.2017  decode.d6.loss_mask: 0.2797  decode.d6.loss_dice: 0.2270  decode.d7.loss_cls: 0.2526  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.2230  decode.d8.loss_cls: 0.2323  decode.d8.loss_mask: 0.2863  decode.d8.loss_dice: 0.2229
09/30 10:18:23 - mmengine - INFO - Iter(train) [ 10450/320000]  base_lr: 9.7056e-05 lr: 9.7056e-06  eta: 1 day, 13:11:43  time: 0.4321  data_time: 0.0085  memory: 5180  grad_norm: 56.8347  loss: 8.7438  decode.loss_cls: 0.2511  decode.loss_mask: 0.2665  decode.loss_dice: 0.2566  decode.d0.loss_cls: 0.9852  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.3585  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.3060  decode.d2.loss_cls: 0.2653  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.2656  decode.d3.loss_cls: 0.2526  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2610  decode.d4.loss_cls: 0.2441  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.2574  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2721  decode.d6.loss_cls: 0.2573  decode.d6.loss_mask: 0.2723  decode.d6.loss_dice: 0.2772  decode.d7.loss_cls: 0.2714  decode.d7.loss_mask: 0.2626  decode.d7.loss_dice: 0.2646  decode.d8.loss_cls: 0.2460  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2634
09/30 10:18:45 - mmengine - INFO - Iter(train) [ 10500/320000]  base_lr: 9.7042e-05 lr: 9.7042e-06  eta: 1 day, 13:11:21  time: 0.4317  data_time: 0.0086  memory: 5160  grad_norm: 79.4162  loss: 7.9997  decode.loss_cls: 0.1341  decode.loss_mask: 0.2997  decode.loss_dice: 0.2349  decode.d0.loss_cls: 0.8989  decode.d0.loss_mask: 0.3145  decode.d0.loss_dice: 0.2447  decode.d1.loss_cls: 0.2772  decode.d1.loss_mask: 0.2966  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.2247  decode.d2.loss_mask: 0.2965  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.1844  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.2152  decode.d4.loss_mask: 0.2940  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.1926  decode.d5.loss_mask: 0.2921  decode.d5.loss_dice: 0.2291  decode.d6.loss_cls: 0.1964  decode.d6.loss_mask: 0.2957  decode.d6.loss_dice: 0.2335  decode.d7.loss_cls: 0.2023  decode.d7.loss_mask: 0.2943  decode.d7.loss_dice: 0.2386  decode.d8.loss_cls: 0.1330  decode.d8.loss_mask: 0.2976  decode.d8.loss_dice: 0.2359
09/30 10:19:06 - mmengine - INFO - Iter(train) [ 10550/320000]  base_lr: 9.7028e-05 lr: 9.7028e-06  eta: 1 day, 13:10:58  time: 0.4322  data_time: 0.0087  memory: 5161  grad_norm: 132.0740  loss: 9.3919  decode.loss_cls: 0.1978  decode.loss_mask: 0.3159  decode.loss_dice: 0.3236  decode.d0.loss_cls: 0.9821  decode.d0.loss_mask: 0.2936  decode.d0.loss_dice: 0.2851  decode.d1.loss_cls: 0.2920  decode.d1.loss_mask: 0.3173  decode.d1.loss_dice: 0.3050  decode.d2.loss_cls: 0.2678  decode.d2.loss_mask: 0.3377  decode.d2.loss_dice: 0.2912  decode.d3.loss_cls: 0.2368  decode.d3.loss_mask: 0.3213  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.2513  decode.d4.loss_mask: 0.3127  decode.d4.loss_dice: 0.2986  decode.d5.loss_cls: 0.2172  decode.d5.loss_mask: 0.3062  decode.d5.loss_dice: 0.2994  decode.d6.loss_cls: 0.2622  decode.d6.loss_mask: 0.3038  decode.d6.loss_dice: 0.2975  decode.d7.loss_cls: 0.2847  decode.d7.loss_mask: 0.3178  decode.d7.loss_dice: 0.3120  decode.d8.loss_cls: 0.2358  decode.d8.loss_mask: 0.3167  decode.d8.loss_dice: 0.3132
09/30 10:19:28 - mmengine - INFO - Iter(train) [ 10600/320000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 1 day, 13:10:35  time: 0.4314  data_time: 0.0088  memory: 5160  grad_norm: 110.1955  loss: 11.3924  decode.loss_cls: 0.4199  decode.loss_mask: 0.3274  decode.loss_dice: 0.2569  decode.d0.loss_cls: 1.4275  decode.d0.loss_mask: 0.3550  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.5525  decode.d1.loss_mask: 0.3400  decode.d1.loss_dice: 0.2715  decode.d2.loss_cls: 0.4139  decode.d2.loss_mask: 0.3677  decode.d2.loss_dice: 0.2421  decode.d3.loss_cls: 0.3991  decode.d3.loss_mask: 0.3635  decode.d3.loss_dice: 0.2606  decode.d4.loss_cls: 0.4502  decode.d4.loss_mask: 0.3376  decode.d4.loss_dice: 0.2479  decode.d5.loss_cls: 0.4596  decode.d5.loss_mask: 0.3306  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.4462  decode.d6.loss_mask: 0.3357  decode.d6.loss_dice: 0.2518  decode.d7.loss_cls: 0.4695  decode.d7.loss_mask: 0.3315  decode.d7.loss_dice: 0.2403  decode.d8.loss_cls: 0.3933  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.2466
09/30 10:19:50 - mmengine - INFO - Iter(train) [ 10650/320000]  base_lr: 9.7000e-05 lr: 9.7000e-06  eta: 1 day, 13:10:13  time: 0.4310  data_time: 0.0087  memory: 5160  grad_norm: 67.5458  loss: 8.5426  decode.loss_cls: 0.2665  decode.loss_mask: 0.2806  decode.loss_dice: 0.2350  decode.d0.loss_cls: 0.9303  decode.d0.loss_mask: 0.2769  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.2984  decode.d1.loss_mask: 0.2876  decode.d1.loss_dice: 0.2238  decode.d2.loss_cls: 0.2368  decode.d2.loss_mask: 0.2825  decode.d2.loss_dice: 0.2221  decode.d3.loss_cls: 0.2431  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.2323  decode.d4.loss_cls: 0.2674  decode.d4.loss_mask: 0.2783  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.2782  decode.d5.loss_mask: 0.2853  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.2771  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.2549  decode.d7.loss_cls: 0.2901  decode.d7.loss_mask: 0.2806  decode.d7.loss_dice: 0.2550  decode.d8.loss_cls: 0.2420  decode.d8.loss_mask: 0.2849  decode.d8.loss_dice: 0.2315
09/30 10:20:11 - mmengine - INFO - Iter(train) [ 10700/320000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 1 day, 13:09:51  time: 0.4330  data_time: 0.0086  memory: 5180  grad_norm: 217.0639  loss: 12.8607  decode.loss_cls: 0.4990  decode.loss_mask: 0.2985  decode.loss_dice: 0.3126  decode.d0.loss_cls: 1.2362  decode.d0.loss_mask: 0.3032  decode.d0.loss_dice: 0.3750  decode.d1.loss_cls: 0.6926  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.3259  decode.d2.loss_cls: 0.5433  decode.d2.loss_mask: 0.2943  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.6199  decode.d3.loss_mask: 0.2991  decode.d3.loss_dice: 0.3360  decode.d4.loss_cls: 0.6915  decode.d4.loss_mask: 0.2889  decode.d4.loss_dice: 0.3099  decode.d5.loss_cls: 0.5329  decode.d5.loss_mask: 0.2846  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.5973  decode.d6.loss_mask: 0.3142  decode.d6.loss_dice: 0.3397  decode.d7.loss_cls: 0.5476  decode.d7.loss_mask: 0.4005  decode.d7.loss_dice: 0.3531  decode.d8.loss_cls: 0.5019  decode.d8.loss_mask: 0.3344  decode.d8.loss_dice: 0.3367
09/30 10:20:33 - mmengine - INFO - Iter(train) [ 10750/320000]  base_lr: 9.6972e-05 lr: 9.6972e-06  eta: 1 day, 13:09:29  time: 0.4330  data_time: 0.0083  memory: 5180  grad_norm: 75.4275  loss: 9.2318  decode.loss_cls: 0.3514  decode.loss_mask: 0.2499  decode.loss_dice: 0.2474  decode.d0.loss_cls: 1.2266  decode.d0.loss_mask: 0.2428  decode.d0.loss_dice: 0.2462  decode.d1.loss_cls: 0.5116  decode.d1.loss_mask: 0.2393  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.3265  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.2891  decode.d3.loss_mask: 0.2386  decode.d3.loss_dice: 0.2353  decode.d4.loss_cls: 0.3444  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.3059  decode.d5.loss_mask: 0.2416  decode.d5.loss_dice: 0.2517  decode.d6.loss_cls: 0.3097  decode.d6.loss_mask: 0.2360  decode.d6.loss_dice: 0.2341  decode.d7.loss_cls: 0.3440  decode.d7.loss_mask: 0.2377  decode.d7.loss_dice: 0.2440  decode.d8.loss_cls: 0.4165  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.2356
09/30 10:20:55 - mmengine - INFO - Iter(train) [ 10800/320000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 1 day, 13:09:08  time: 0.4324  data_time: 0.0085  memory: 5145  grad_norm: 110.7498  loss: 10.6851  decode.loss_cls: 0.4223  decode.loss_mask: 0.2835  decode.loss_dice: 0.2735  decode.d0.loss_cls: 1.1044  decode.d0.loss_mask: 0.2735  decode.d0.loss_dice: 0.2852  decode.d1.loss_cls: 0.4367  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.2737  decode.d2.loss_cls: 0.3456  decode.d2.loss_mask: 0.3318  decode.d2.loss_dice: 0.2848  decode.d3.loss_cls: 0.3900  decode.d3.loss_mask: 0.3180  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.3806  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.2738  decode.d5.loss_cls: 0.3974  decode.d5.loss_mask: 0.3294  decode.d5.loss_dice: 0.2838  decode.d6.loss_cls: 0.4045  decode.d6.loss_mask: 0.3053  decode.d6.loss_dice: 0.2860  decode.d7.loss_cls: 0.4268  decode.d7.loss_mask: 0.3473  decode.d7.loss_dice: 0.2896  decode.d8.loss_cls: 0.4453  decode.d8.loss_mask: 0.3391  decode.d8.loss_dice: 0.2877
09/30 10:21:16 - mmengine - INFO - Iter(train) [ 10850/320000]  base_lr: 9.6943e-05 lr: 9.6943e-06  eta: 1 day, 13:08:47  time: 0.4312  data_time: 0.0086  memory: 5180  grad_norm: 98.8186  loss: 9.9915  decode.loss_cls: 0.2720  decode.loss_mask: 0.3503  decode.loss_dice: 0.3281  decode.d0.loss_cls: 1.0380  decode.d0.loss_mask: 0.3273  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.2293  decode.d1.loss_mask: 0.3482  decode.d1.loss_dice: 0.3390  decode.d2.loss_cls: 0.2491  decode.d2.loss_mask: 0.3311  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.2696  decode.d3.loss_mask: 0.3471  decode.d3.loss_dice: 0.3323  decode.d4.loss_cls: 0.2453  decode.d4.loss_mask: 0.3348  decode.d4.loss_dice: 0.3202  decode.d5.loss_cls: 0.2198  decode.d5.loss_mask: 0.3553  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.2333  decode.d6.loss_mask: 0.3615  decode.d6.loss_dice: 0.3148  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 0.3593  decode.d7.loss_dice: 0.3282  decode.d8.loss_cls: 0.2508  decode.d8.loss_mask: 0.3472  decode.d8.loss_dice: 0.3215
09/30 10:21:38 - mmengine - INFO - Iter(train) [ 10900/320000]  base_lr: 9.6929e-05 lr: 9.6929e-06  eta: 1 day, 13:08:25  time: 0.4321  data_time: 0.0088  memory: 5161  grad_norm: 47.8875  loss: 7.4518  decode.loss_cls: 0.1509  decode.loss_mask: 0.2712  decode.loss_dice: 0.2024  decode.d0.loss_cls: 0.9949  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.2423  decode.d1.loss_cls: 0.2137  decode.d1.loss_mask: 0.2682  decode.d1.loss_dice: 0.2258  decode.d2.loss_cls: 0.2328  decode.d2.loss_mask: 0.2714  decode.d2.loss_dice: 0.2237  decode.d3.loss_cls: 0.1746  decode.d3.loss_mask: 0.2666  decode.d3.loss_dice: 0.2177  decode.d4.loss_cls: 0.1709  decode.d4.loss_mask: 0.2724  decode.d4.loss_dice: 0.2126  decode.d5.loss_cls: 0.1701  decode.d5.loss_mask: 0.2712  decode.d5.loss_dice: 0.2169  decode.d6.loss_cls: 0.1925  decode.d6.loss_mask: 0.2702  decode.d6.loss_dice: 0.1980  decode.d7.loss_cls: 0.1312  decode.d7.loss_mask: 0.2703  decode.d7.loss_dice: 0.2059  decode.d8.loss_cls: 0.1689  decode.d8.loss_mask: 0.2686  decode.d8.loss_dice: 0.1992
09/30 10:21:59 - mmengine - INFO - Iter(train) [ 10950/320000]  base_lr: 9.6915e-05 lr: 9.6915e-06  eta: 1 day, 13:08:04  time: 0.4316  data_time: 0.0085  memory: 5161  grad_norm: 127.6968  loss: 9.2138  decode.loss_cls: 0.2538  decode.loss_mask: 0.3243  decode.loss_dice: 0.2640  decode.d0.loss_cls: 0.9157  decode.d0.loss_mask: 0.3261  decode.d0.loss_dice: 0.3066  decode.d1.loss_cls: 0.2380  decode.d1.loss_mask: 0.3169  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.3252  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.2833  decode.d3.loss_cls: 0.2441  decode.d3.loss_mask: 0.3428  decode.d3.loss_dice: 0.2646  decode.d4.loss_cls: 0.2991  decode.d4.loss_mask: 0.3020  decode.d4.loss_dice: 0.2646  decode.d5.loss_cls: 0.2755  decode.d5.loss_mask: 0.3287  decode.d5.loss_dice: 0.2429  decode.d6.loss_cls: 0.2631  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.2507  decode.d7.loss_cls: 0.2322  decode.d7.loss_mask: 0.3023  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.2560  decode.d8.loss_mask: 0.3424  decode.d8.loss_dice: 0.2907
09/30 10:22:21 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:22:21 - mmengine - INFO - Iter(train) [ 11000/320000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 1 day, 13:07:43  time: 0.4331  data_time: 0.0088  memory: 5180  grad_norm: 109.8551  loss: 7.9984  decode.loss_cls: 0.1325  decode.loss_mask: 0.2947  decode.loss_dice: 0.2613  decode.d0.loss_cls: 0.8854  decode.d0.loss_mask: 0.3022  decode.d0.loss_dice: 0.2687  decode.d1.loss_cls: 0.2177  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.2749  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 0.2948  decode.d2.loss_dice: 0.2596  decode.d3.loss_cls: 0.1657  decode.d3.loss_mask: 0.2963  decode.d3.loss_dice: 0.2500  decode.d4.loss_cls: 0.1650  decode.d4.loss_mask: 0.2869  decode.d4.loss_dice: 0.2610  decode.d5.loss_cls: 0.1859  decode.d5.loss_mask: 0.2835  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.1936  decode.d6.loss_mask: 0.2892  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.1992  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.2494  decode.d8.loss_cls: 0.1802  decode.d8.loss_mask: 0.2925  decode.d8.loss_dice: 0.2505
09/30 10:22:43 - mmengine - INFO - Iter(train) [ 11050/320000]  base_lr: 9.6887e-05 lr: 9.6887e-06  eta: 1 day, 13:07:21  time: 0.4319  data_time: 0.0085  memory: 5161  grad_norm: 311.8745  loss: 10.7245  decode.loss_cls: 0.2769  decode.loss_mask: 0.3671  decode.loss_dice: 0.3598  decode.d0.loss_cls: 1.0635  decode.d0.loss_mask: 0.3917  decode.d0.loss_dice: 0.3740  decode.d1.loss_cls: 0.3453  decode.d1.loss_mask: 0.3308  decode.d1.loss_dice: 0.3325  decode.d2.loss_cls: 0.2917  decode.d2.loss_mask: 0.3406  decode.d2.loss_dice: 0.3335  decode.d3.loss_cls: 0.2744  decode.d3.loss_mask: 0.3660  decode.d3.loss_dice: 0.3442  decode.d4.loss_cls: 0.3464  decode.d4.loss_mask: 0.3418  decode.d4.loss_dice: 0.3460  decode.d5.loss_cls: 0.2738  decode.d5.loss_mask: 0.3936  decode.d5.loss_dice: 0.3675  decode.d6.loss_cls: 0.3363  decode.d6.loss_mask: 0.3240  decode.d6.loss_dice: 0.3167  decode.d7.loss_cls: 0.2941  decode.d7.loss_mask: 0.3178  decode.d7.loss_dice: 0.2980  decode.d8.loss_cls: 0.2776  decode.d8.loss_mask: 0.3569  decode.d8.loss_dice: 0.3418
09/30 10:23:04 - mmengine - INFO - Iter(train) [ 11100/320000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 1 day, 13:06:58  time: 0.4311  data_time: 0.0086  memory: 5147  grad_norm: 62.0605  loss: 9.1922  decode.loss_cls: 0.2217  decode.loss_mask: 0.2752  decode.loss_dice: 0.2989  decode.d0.loss_cls: 0.8213  decode.d0.loss_mask: 0.2679  decode.d0.loss_dice: 0.3482  decode.d1.loss_cls: 0.4920  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.3150  decode.d2.loss_cls: 0.2174  decode.d2.loss_mask: 0.2782  decode.d2.loss_dice: 0.3291  decode.d3.loss_cls: 0.2188  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.3164  decode.d4.loss_cls: 0.3517  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.3189  decode.d5.loss_cls: 0.3201  decode.d5.loss_mask: 0.2517  decode.d5.loss_dice: 0.3064  decode.d6.loss_cls: 0.2115  decode.d6.loss_mask: 0.2847  decode.d6.loss_dice: 0.3132  decode.d7.loss_cls: 0.2777  decode.d7.loss_mask: 0.2637  decode.d7.loss_dice: 0.3192  decode.d8.loss_cls: 0.2032  decode.d8.loss_mask: 0.2773  decode.d8.loss_dice: 0.3024
09/30 10:23:26 - mmengine - INFO - Iter(train) [ 11150/320000]  base_lr: 9.6859e-05 lr: 9.6859e-06  eta: 1 day, 13:06:40  time: 0.4488  data_time: 0.0084  memory: 5160  grad_norm: 67.3946  loss: 8.6621  decode.loss_cls: 0.1745  decode.loss_mask: 0.2959  decode.loss_dice: 0.2469  decode.d0.loss_cls: 1.1502  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.2483  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.2952  decode.d2.loss_mask: 0.2974  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.2093  decode.d3.loss_mask: 0.3037  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.2055  decode.d4.loss_mask: 0.3034  decode.d4.loss_dice: 0.2367  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 0.2964  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.2971  decode.d6.loss_mask: 0.2931  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.2071  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.2300  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.2331
09/30 10:23:48 - mmengine - INFO - Iter(train) [ 11200/320000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 1 day, 13:06:17  time: 0.4322  data_time: 0.0086  memory: 5161  grad_norm: 119.6967  loss: 15.6594  decode.loss_cls: 0.5505  decode.loss_mask: 0.6118  decode.loss_dice: 0.4461  decode.d0.loss_cls: 1.1667  decode.d0.loss_mask: 0.4035  decode.d0.loss_dice: 0.4523  decode.d1.loss_cls: 0.6915  decode.d1.loss_mask: 0.4451  decode.d1.loss_dice: 0.4398  decode.d2.loss_cls: 0.5746  decode.d2.loss_mask: 0.4193  decode.d2.loss_dice: 0.4322  decode.d3.loss_cls: 0.5092  decode.d3.loss_mask: 0.3909  decode.d3.loss_dice: 0.4300  decode.d4.loss_cls: 0.6373  decode.d4.loss_mask: 0.4996  decode.d4.loss_dice: 0.4163  decode.d5.loss_cls: 0.5314  decode.d5.loss_mask: 0.5326  decode.d5.loss_dice: 0.4171  decode.d6.loss_cls: 0.6788  decode.d6.loss_mask: 0.4709  decode.d6.loss_dice: 0.4325  decode.d7.loss_cls: 0.5940  decode.d7.loss_mask: 0.5120  decode.d7.loss_dice: 0.4609  decode.d8.loss_cls: 0.5182  decode.d8.loss_mask: 0.5274  decode.d8.loss_dice: 0.4671
09/30 10:24:09 - mmengine - INFO - Iter(train) [ 11250/320000]  base_lr: 9.6831e-05 lr: 9.6831e-06  eta: 1 day, 13:05:54  time: 0.4319  data_time: 0.0087  memory: 5161  grad_norm: 193.9095  loss: 9.0192  decode.loss_cls: 0.2690  decode.loss_mask: 0.3109  decode.loss_dice: 0.2218  decode.d0.loss_cls: 1.1371  decode.d0.loss_mask: 0.3314  decode.d0.loss_dice: 0.2496  decode.d1.loss_cls: 0.2481  decode.d1.loss_mask: 0.3321  decode.d1.loss_dice: 0.2363  decode.d2.loss_cls: 0.2449  decode.d2.loss_mask: 0.3202  decode.d2.loss_dice: 0.2513  decode.d3.loss_cls: 0.2308  decode.d3.loss_mask: 0.3240  decode.d3.loss_dice: 0.2390  decode.d4.loss_cls: 0.2568  decode.d4.loss_mask: 0.3201  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.2108  decode.d5.loss_mask: 0.3328  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.1742  decode.d6.loss_mask: 0.3437  decode.d6.loss_dice: 0.2560  decode.d7.loss_cls: 0.2174  decode.d7.loss_mask: 0.3613  decode.d7.loss_dice: 0.2579  decode.d8.loss_cls: 0.2925  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.2322
09/30 10:24:31 - mmengine - INFO - Iter(train) [ 11300/320000]  base_lr: 9.6816e-05 lr: 9.6816e-06  eta: 1 day, 13:05:31  time: 0.4310  data_time: 0.0085  memory: 5145  grad_norm: 176.7901  loss: 8.9285  decode.loss_cls: 0.2571  decode.loss_mask: 0.2607  decode.loss_dice: 0.2575  decode.d0.loss_cls: 1.0399  decode.d0.loss_mask: 0.2804  decode.d0.loss_dice: 0.3028  decode.d1.loss_cls: 0.3457  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.3322  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.2721  decode.d3.loss_cls: 0.3002  decode.d3.loss_mask: 0.2663  decode.d3.loss_dice: 0.2496  decode.d4.loss_cls: 0.2950  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.2484  decode.d5.loss_cls: 0.2922  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.2620  decode.d6.loss_cls: 0.2954  decode.d6.loss_mask: 0.2639  decode.d6.loss_dice: 0.2647  decode.d7.loss_cls: 0.2450  decode.d7.loss_mask: 0.2663  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.2344  decode.d8.loss_mask: 0.2620  decode.d8.loss_dice: 0.2410
09/30 10:24:52 - mmengine - INFO - Iter(train) [ 11350/320000]  base_lr: 9.6802e-05 lr: 9.6802e-06  eta: 1 day, 13:05:09  time: 0.4320  data_time: 0.0085  memory: 5161  grad_norm: 164.3440  loss: 9.7188  decode.loss_cls: 0.2645  decode.loss_mask: 0.3303  decode.loss_dice: 0.2928  decode.d0.loss_cls: 1.3016  decode.d0.loss_mask: 0.3321  decode.d0.loss_dice: 0.2750  decode.d1.loss_cls: 0.3281  decode.d1.loss_mask: 0.3476  decode.d1.loss_dice: 0.2687  decode.d2.loss_cls: 0.2564  decode.d2.loss_mask: 0.3384  decode.d2.loss_dice: 0.2650  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 0.3298  decode.d3.loss_dice: 0.2766  decode.d4.loss_cls: 0.2139  decode.d4.loss_mask: 0.3248  decode.d4.loss_dice: 0.2701  decode.d5.loss_cls: 0.2243  decode.d5.loss_mask: 0.3072  decode.d5.loss_dice: 0.2591  decode.d6.loss_cls: 0.2799  decode.d6.loss_mask: 0.3400  decode.d6.loss_dice: 0.2994  decode.d7.loss_cls: 0.3080  decode.d7.loss_mask: 0.3308  decode.d7.loss_dice: 0.2663  decode.d8.loss_cls: 0.2723  decode.d8.loss_mask: 0.3230  decode.d8.loss_dice: 0.2724
09/30 10:25:14 - mmengine - INFO - Iter(train) [ 11400/320000]  base_lr: 9.6788e-05 lr: 9.6788e-06  eta: 1 day, 13:04:47  time: 0.4319  data_time: 0.0085  memory: 5180  grad_norm: 188.0704  loss: 11.6863  decode.loss_cls: 0.4326  decode.loss_mask: 0.3906  decode.loss_dice: 0.3339  decode.d0.loss_cls: 1.3365  decode.d0.loss_mask: 0.3491  decode.d0.loss_dice: 0.3167  decode.d1.loss_cls: 0.4420  decode.d1.loss_mask: 0.3366  decode.d1.loss_dice: 0.2843  decode.d2.loss_cls: 0.3398  decode.d2.loss_mask: 0.3668  decode.d2.loss_dice: 0.3044  decode.d3.loss_cls: 0.3302  decode.d3.loss_mask: 0.3740  decode.d3.loss_dice: 0.3007  decode.d4.loss_cls: 0.3941  decode.d4.loss_mask: 0.3728  decode.d4.loss_dice: 0.3017  decode.d5.loss_cls: 0.4200  decode.d5.loss_mask: 0.3552  decode.d5.loss_dice: 0.3165  decode.d6.loss_cls: 0.3385  decode.d6.loss_mask: 0.4046  decode.d6.loss_dice: 0.3369  decode.d7.loss_cls: 0.3368  decode.d7.loss_mask: 0.4009  decode.d7.loss_dice: 0.3214  decode.d8.loss_cls: 0.4471  decode.d8.loss_mask: 0.3758  decode.d8.loss_dice: 0.3258
09/30 10:25:36 - mmengine - INFO - Iter(train) [ 11450/320000]  base_lr: 9.6774e-05 lr: 9.6774e-06  eta: 1 day, 13:04:25  time: 0.4320  data_time: 0.0086  memory: 5161  grad_norm: 102.2224  loss: 7.9703  decode.loss_cls: 0.1199  decode.loss_mask: 0.3025  decode.loss_dice: 0.2133  decode.d0.loss_cls: 1.1223  decode.d0.loss_mask: 0.3152  decode.d0.loss_dice: 0.2075  decode.d1.loss_cls: 0.2413  decode.d1.loss_mask: 0.3011  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.1935  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.2210  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 0.3091  decode.d3.loss_dice: 0.2120  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 0.3060  decode.d4.loss_dice: 0.2304  decode.d5.loss_cls: 0.1835  decode.d5.loss_mask: 0.3127  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.1769  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.2238  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 0.3144  decode.d7.loss_dice: 0.2196  decode.d8.loss_cls: 0.1249  decode.d8.loss_mask: 0.3019  decode.d8.loss_dice: 0.2238
09/30 10:25:57 - mmengine - INFO - Iter(train) [ 11500/320000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 1 day, 13:04:03  time: 0.4317  data_time: 0.0086  memory: 5180  grad_norm: 150.8027  loss: 13.4937  decode.loss_cls: 0.4214  decode.loss_mask: 0.4614  decode.loss_dice: 0.3722  decode.d0.loss_cls: 1.2967  decode.d0.loss_mask: 0.4136  decode.d0.loss_dice: 0.3926  decode.d1.loss_cls: 0.5593  decode.d1.loss_mask: 0.3643  decode.d1.loss_dice: 0.3480  decode.d2.loss_cls: 0.5378  decode.d2.loss_mask: 0.3985  decode.d2.loss_dice: 0.4111  decode.d3.loss_cls: 0.5099  decode.d3.loss_mask: 0.3515  decode.d3.loss_dice: 0.3782  decode.d4.loss_cls: 0.4488  decode.d4.loss_mask: 0.4250  decode.d4.loss_dice: 0.3748  decode.d5.loss_cls: 0.5545  decode.d5.loss_mask: 0.3619  decode.d5.loss_dice: 0.3632  decode.d6.loss_cls: 0.5185  decode.d6.loss_mask: 0.3507  decode.d6.loss_dice: 0.3576  decode.d7.loss_cls: 0.4986  decode.d7.loss_mask: 0.3986  decode.d7.loss_dice: 0.3893  decode.d8.loss_cls: 0.4755  decode.d8.loss_mask: 0.3482  decode.d8.loss_dice: 0.4118
09/30 10:26:19 - mmengine - INFO - Iter(train) [ 11550/320000]  base_lr: 9.6746e-05 lr: 9.6746e-06  eta: 1 day, 13:03:41  time: 0.4328  data_time: 0.0085  memory: 5180  grad_norm: 118.0154  loss: 7.5714  decode.loss_cls: 0.1174  decode.loss_mask: 0.2980  decode.loss_dice: 0.2079  decode.d0.loss_cls: 0.8855  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.2344  decode.d1.loss_cls: 0.2275  decode.d1.loss_mask: 0.2958  decode.d1.loss_dice: 0.2098  decode.d2.loss_cls: 0.1861  decode.d2.loss_mask: 0.2940  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.1852  decode.d3.loss_mask: 0.2952  decode.d3.loss_dice: 0.2130  decode.d4.loss_cls: 0.2251  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.2123  decode.d5.loss_cls: 0.1815  decode.d5.loss_mask: 0.2992  decode.d5.loss_dice: 0.2138  decode.d6.loss_cls: 0.1242  decode.d6.loss_mask: 0.3001  decode.d6.loss_dice: 0.2132  decode.d7.loss_cls: 0.2003  decode.d7.loss_mask: 0.3025  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.1055  decode.d8.loss_mask: 0.2988  decode.d8.loss_dice: 0.2067
09/30 10:26:41 - mmengine - INFO - Iter(train) [ 11600/320000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 1 day, 13:03:19  time: 0.4326  data_time: 0.0087  memory: 5180  grad_norm: 86.4412  loss: 7.6456  decode.loss_cls: 0.1613  decode.loss_mask: 0.2774  decode.loss_dice: 0.2199  decode.d0.loss_cls: 1.1003  decode.d0.loss_mask: 0.2680  decode.d0.loss_dice: 0.2109  decode.d1.loss_cls: 0.2287  decode.d1.loss_mask: 0.2669  decode.d1.loss_dice: 0.2194  decode.d2.loss_cls: 0.1782  decode.d2.loss_mask: 0.2731  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.1473  decode.d3.loss_mask: 0.2686  decode.d3.loss_dice: 0.2292  decode.d4.loss_cls: 0.1585  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.2201  decode.d5.loss_cls: 0.1625  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.2216  decode.d6.loss_cls: 0.1733  decode.d6.loss_mask: 0.2645  decode.d6.loss_dice: 0.2066  decode.d7.loss_cls: 0.1459  decode.d7.loss_mask: 0.2939  decode.d7.loss_dice: 0.2710  decode.d8.loss_cls: 0.1541  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2766
09/30 10:27:02 - mmengine - INFO - Iter(train) [ 11650/320000]  base_lr: 9.6718e-05 lr: 9.6718e-06  eta: 1 day, 13:02:57  time: 0.4331  data_time: 0.0090  memory: 5161  grad_norm: 86.3970  loss: 9.5641  decode.loss_cls: 0.3174  decode.loss_mask: 0.2804  decode.loss_dice: 0.2263  decode.d0.loss_cls: 1.0978  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.2461  decode.d1.loss_cls: 0.4314  decode.d1.loss_mask: 0.2814  decode.d1.loss_dice: 0.2286  decode.d2.loss_cls: 0.4124  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.2227  decode.d3.loss_cls: 0.3988  decode.d3.loss_mask: 0.2860  decode.d3.loss_dice: 0.2146  decode.d4.loss_cls: 0.3692  decode.d4.loss_mask: 0.2803  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.3876  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.2256  decode.d6.loss_cls: 0.3555  decode.d6.loss_mask: 0.2794  decode.d6.loss_dice: 0.2222  decode.d7.loss_cls: 0.3605  decode.d7.loss_mask: 0.2810  decode.d7.loss_dice: 0.2258  decode.d8.loss_cls: 0.3550  decode.d8.loss_mask: 0.2884  decode.d8.loss_dice: 0.2192
09/30 10:27:24 - mmengine - INFO - Iter(train) [ 11700/320000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 1 day, 13:02:35  time: 0.4326  data_time: 0.0090  memory: 5132  grad_norm: 112.8367  loss: 11.5484  decode.loss_cls: 0.3782  decode.loss_mask: 0.3450  decode.loss_dice: 0.3260  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.3377  decode.d0.loss_dice: 0.3347  decode.d1.loss_cls: 0.4465  decode.d1.loss_mask: 0.3483  decode.d1.loss_dice: 0.3157  decode.d2.loss_cls: 0.3961  decode.d2.loss_mask: 0.3542  decode.d2.loss_dice: 0.3022  decode.d3.loss_cls: 0.4523  decode.d3.loss_mask: 0.3418  decode.d3.loss_dice: 0.3000  decode.d4.loss_cls: 0.4205  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3402  decode.d5.loss_cls: 0.4384  decode.d5.loss_mask: 0.3573  decode.d5.loss_dice: 0.3515  decode.d6.loss_cls: 0.4505  decode.d6.loss_mask: 0.3982  decode.d6.loss_dice: 0.3676  decode.d7.loss_cls: 0.4942  decode.d7.loss_mask: 0.3457  decode.d7.loss_dice: 0.3448  decode.d8.loss_cls: 0.3551  decode.d8.loss_mask: 0.3424  decode.d8.loss_dice: 0.3489
09/30 10:27:45 - mmengine - INFO - Iter(train) [ 11750/320000]  base_lr: 9.6689e-05 lr: 9.6689e-06  eta: 1 day, 13:02:13  time: 0.4321  data_time: 0.0086  memory: 5161  grad_norm: 114.6937  loss: 8.6089  decode.loss_cls: 0.2544  decode.loss_mask: 0.2571  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.9866  decode.d0.loss_mask: 0.2705  decode.d0.loss_dice: 0.2734  decode.d1.loss_cls: 0.2983  decode.d1.loss_mask: 0.2548  decode.d1.loss_dice: 0.2456  decode.d2.loss_cls: 0.2713  decode.d2.loss_mask: 0.2598  decode.d2.loss_dice: 0.2573  decode.d3.loss_cls: 0.3216  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.2675  decode.d4.loss_cls: 0.2236  decode.d4.loss_mask: 0.2619  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.2387  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.2738  decode.d6.loss_cls: 0.2479  decode.d6.loss_mask: 0.2691  decode.d6.loss_dice: 0.2717  decode.d7.loss_cls: 0.2617  decode.d7.loss_mask: 0.2610  decode.d7.loss_dice: 0.2829  decode.d8.loss_cls: 0.2283  decode.d8.loss_mask: 0.2549  decode.d8.loss_dice: 0.2437
09/30 10:28:07 - mmengine - INFO - Iter(train) [ 11800/320000]  base_lr: 9.6675e-05 lr: 9.6675e-06  eta: 1 day, 13:01:51  time: 0.4325  data_time: 0.0089  memory: 5146  grad_norm: 162.2013  loss: 11.8257  decode.loss_cls: 0.2550  decode.loss_mask: 0.5103  decode.loss_dice: 0.3500  decode.d0.loss_cls: 1.0823  decode.d0.loss_mask: 0.4246  decode.d0.loss_dice: 0.4002  decode.d1.loss_cls: 0.3117  decode.d1.loss_mask: 0.4177  decode.d1.loss_dice: 0.3486  decode.d2.loss_cls: 0.3761  decode.d2.loss_mask: 0.4158  decode.d2.loss_dice: 0.3377  decode.d3.loss_cls: 0.3396  decode.d3.loss_mask: 0.4346  decode.d3.loss_dice: 0.3320  decode.d4.loss_cls: 0.3623  decode.d4.loss_mask: 0.3704  decode.d4.loss_dice: 0.3051  decode.d5.loss_cls: 0.3634  decode.d5.loss_mask: 0.3847  decode.d5.loss_dice: 0.3492  decode.d6.loss_cls: 0.3038  decode.d6.loss_mask: 0.5006  decode.d6.loss_dice: 0.3886  decode.d7.loss_cls: 0.2395  decode.d7.loss_mask: 0.4690  decode.d7.loss_dice: 0.3737  decode.d8.loss_cls: 0.2791  decode.d8.loss_mask: 0.4201  decode.d8.loss_dice: 0.3802
09/30 10:28:29 - mmengine - INFO - Iter(train) [ 11850/320000]  base_lr: 9.6661e-05 lr: 9.6661e-06  eta: 1 day, 13:01:29  time: 0.4331  data_time: 0.0088  memory: 5160  grad_norm: 49.7323  loss: 8.4064  decode.loss_cls: 0.1760  decode.loss_mask: 0.3477  decode.loss_dice: 0.2333  decode.d0.loss_cls: 0.9849  decode.d0.loss_mask: 0.3523  decode.d0.loss_dice: 0.2987  decode.d1.loss_cls: 0.2448  decode.d1.loss_mask: 0.3586  decode.d1.loss_dice: 0.2677  decode.d2.loss_cls: 0.2050  decode.d2.loss_mask: 0.3502  decode.d2.loss_dice: 0.2299  decode.d3.loss_cls: 0.1534  decode.d3.loss_mask: 0.3472  decode.d3.loss_dice: 0.2372  decode.d4.loss_cls: 0.1315  decode.d4.loss_mask: 0.3413  decode.d4.loss_dice: 0.2377  decode.d5.loss_cls: 0.1630  decode.d5.loss_mask: 0.3437  decode.d5.loss_dice: 0.2481  decode.d6.loss_cls: 0.1281  decode.d6.loss_mask: 0.3398  decode.d6.loss_dice: 0.2363  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 0.3451  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.1393  decode.d8.loss_mask: 0.3509  decode.d8.loss_dice: 0.2427
09/30 10:28:50 - mmengine - INFO - Iter(train) [ 11900/320000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 1 day, 13:01:07  time: 0.4318  data_time: 0.0088  memory: 5161  grad_norm: 61.5653  loss: 10.2346  decode.loss_cls: 0.3106  decode.loss_mask: 0.3039  decode.loss_dice: 0.3304  decode.d0.loss_cls: 1.1379  decode.d0.loss_mask: 0.2684  decode.d0.loss_dice: 0.3486  decode.d1.loss_cls: 0.4090  decode.d1.loss_mask: 0.2644  decode.d1.loss_dice: 0.3558  decode.d2.loss_cls: 0.3149  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.3343  decode.d3.loss_cls: 0.3585  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.3381  decode.d4.loss_cls: 0.3369  decode.d4.loss_mask: 0.2518  decode.d4.loss_dice: 0.3509  decode.d5.loss_cls: 0.3248  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.3416  decode.d6.loss_cls: 0.3033  decode.d6.loss_mask: 0.2558  decode.d6.loss_dice: 0.3532  decode.d7.loss_cls: 0.2997  decode.d7.loss_mask: 0.2624  decode.d7.loss_dice: 0.3220  decode.d8.loss_cls: 0.3317  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.3314
09/30 10:29:12 - mmengine - INFO - Iter(train) [ 11950/320000]  base_lr: 9.6633e-05 lr: 9.6633e-06  eta: 1 day, 13:00:44  time: 0.4315  data_time: 0.0084  memory: 5180  grad_norm: 125.8131  loss: 12.0839  decode.loss_cls: 0.3777  decode.loss_mask: 0.3364  decode.loss_dice: 0.3256  decode.d0.loss_cls: 1.2008  decode.d0.loss_mask: 0.3444  decode.d0.loss_dice: 0.3490  decode.d1.loss_cls: 0.5883  decode.d1.loss_mask: 0.3476  decode.d1.loss_dice: 0.3494  decode.d2.loss_cls: 0.4773  decode.d2.loss_mask: 0.3376  decode.d2.loss_dice: 0.3093  decode.d3.loss_cls: 0.4439  decode.d3.loss_mask: 0.3409  decode.d3.loss_dice: 0.3297  decode.d4.loss_cls: 0.5408  decode.d4.loss_mask: 0.3439  decode.d4.loss_dice: 0.3258  decode.d5.loss_cls: 0.5264  decode.d5.loss_mask: 0.3310  decode.d5.loss_dice: 0.3026  decode.d6.loss_cls: 0.5106  decode.d6.loss_mask: 0.3337  decode.d6.loss_dice: 0.3310  decode.d7.loss_cls: 0.4303  decode.d7.loss_mask: 0.3364  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.3841  decode.d8.loss_mask: 0.3314  decode.d8.loss_dice: 0.2958
09/30 10:29:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:29:33 - mmengine - INFO - Iter(train) [ 12000/320000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 1 day, 13:00:22  time: 0.4321  data_time: 0.0086  memory: 5161  grad_norm: 137.9114  loss: 9.5954  decode.loss_cls: 0.2668  decode.loss_mask: 0.3616  decode.loss_dice: 0.2709  decode.d0.loss_cls: 1.1543  decode.d0.loss_mask: 0.3285  decode.d0.loss_dice: 0.2769  decode.d1.loss_cls: 0.2902  decode.d1.loss_mask: 0.3534  decode.d1.loss_dice: 0.2760  decode.d2.loss_cls: 0.2917  decode.d2.loss_mask: 0.3489  decode.d2.loss_dice: 0.2740  decode.d3.loss_cls: 0.2859  decode.d3.loss_mask: 0.3390  decode.d3.loss_dice: 0.2796  decode.d4.loss_cls: 0.2246  decode.d4.loss_mask: 0.3372  decode.d4.loss_dice: 0.2666  decode.d5.loss_cls: 0.2455  decode.d5.loss_mask: 0.3442  decode.d5.loss_dice: 0.2874  decode.d6.loss_cls: 0.1904  decode.d6.loss_mask: 0.3804  decode.d6.loss_dice: 0.2659  decode.d7.loss_cls: 0.1814  decode.d7.loss_mask: 0.3878  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.1627  decode.d8.loss_mask: 0.3828  decode.d8.loss_dice: 0.2697
09/30 10:29:55 - mmengine - INFO - Iter(train) [ 12050/320000]  base_lr: 9.6605e-05 lr: 9.6605e-06  eta: 1 day, 13:00:00  time: 0.4313  data_time: 0.0085  memory: 5161  grad_norm: 201.7465  loss: 10.9144  decode.loss_cls: 0.3781  decode.loss_mask: 0.3594  decode.loss_dice: 0.2668  decode.d0.loss_cls: 1.2204  decode.d0.loss_mask: 0.3575  decode.d0.loss_dice: 0.2898  decode.d1.loss_cls: 0.4272  decode.d1.loss_mask: 0.3531  decode.d1.loss_dice: 0.2700  decode.d2.loss_cls: 0.3748  decode.d2.loss_mask: 0.3444  decode.d2.loss_dice: 0.3177  decode.d3.loss_cls: 0.3817  decode.d3.loss_mask: 0.3454  decode.d3.loss_dice: 0.2648  decode.d4.loss_cls: 0.3243  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.3014  decode.d5.loss_cls: 0.3195  decode.d5.loss_mask: 0.3535  decode.d5.loss_dice: 0.3160  decode.d6.loss_cls: 0.3121  decode.d6.loss_mask: 0.3591  decode.d6.loss_dice: 0.2655  decode.d7.loss_cls: 0.3772  decode.d7.loss_mask: 0.3536  decode.d7.loss_dice: 0.3019  decode.d8.loss_cls: 0.3695  decode.d8.loss_mask: 0.3508  decode.d8.loss_dice: 0.2906
09/30 10:30:17 - mmengine - INFO - Iter(train) [ 12100/320000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 1 day, 12:59:38  time: 0.4321  data_time: 0.0087  memory: 5180  grad_norm: 99.4419  loss: 8.7115  decode.loss_cls: 0.2406  decode.loss_mask: 0.2990  decode.loss_dice: 0.2773  decode.d0.loss_cls: 0.9495  decode.d0.loss_mask: 0.3243  decode.d0.loss_dice: 0.2821  decode.d1.loss_cls: 0.2270  decode.d1.loss_mask: 0.3048  decode.d1.loss_dice: 0.2568  decode.d2.loss_cls: 0.2371  decode.d2.loss_mask: 0.3031  decode.d2.loss_dice: 0.2907  decode.d3.loss_cls: 0.2316  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.2356  decode.d4.loss_mask: 0.3049  decode.d4.loss_dice: 0.2566  decode.d5.loss_cls: 0.2145  decode.d5.loss_mask: 0.3067  decode.d5.loss_dice: 0.2538  decode.d6.loss_cls: 0.2047  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.2420  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.2634  decode.d8.loss_cls: 0.2291  decode.d8.loss_mask: 0.2978  decode.d8.loss_dice: 0.2523
09/30 10:30:38 - mmengine - INFO - Iter(train) [ 12150/320000]  base_lr: 9.6577e-05 lr: 9.6577e-06  eta: 1 day, 12:59:16  time: 0.4325  data_time: 0.0086  memory: 5161  grad_norm: 555.7147  loss: 13.1309  decode.loss_cls: 0.3205  decode.loss_mask: 0.4548  decode.loss_dice: 0.4038  decode.d0.loss_cls: 1.0583  decode.d0.loss_mask: 0.4097  decode.d0.loss_dice: 0.4319  decode.d1.loss_cls: 0.5366  decode.d1.loss_mask: 0.3821  decode.d1.loss_dice: 0.4079  decode.d2.loss_cls: 0.5259  decode.d2.loss_mask: 0.3725  decode.d2.loss_dice: 0.3761  decode.d3.loss_cls: 0.4700  decode.d3.loss_mask: 0.3631  decode.d3.loss_dice: 0.3798  decode.d4.loss_cls: 0.4706  decode.d4.loss_mask: 0.3846  decode.d4.loss_dice: 0.3814  decode.d5.loss_cls: 0.4771  decode.d5.loss_mask: 0.3959  decode.d5.loss_dice: 0.4050  decode.d6.loss_cls: 0.4297  decode.d6.loss_mask: 0.4277  decode.d6.loss_dice: 0.4362  decode.d7.loss_cls: 0.3848  decode.d7.loss_mask: 0.4745  decode.d7.loss_dice: 0.3975  decode.d8.loss_cls: 0.3058  decode.d8.loss_mask: 0.4642  decode.d8.loss_dice: 0.4032
09/30 10:31:00 - mmengine - INFO - Iter(train) [ 12200/320000]  base_lr: 9.6562e-05 lr: 9.6562e-06  eta: 1 day, 12:58:53  time: 0.4315  data_time: 0.0086  memory: 5147  grad_norm: 103.2884  loss: 7.4717  decode.loss_cls: 0.0655  decode.loss_mask: 0.3552  decode.loss_dice: 0.2232  decode.d0.loss_cls: 0.8701  decode.d0.loss_mask: 0.3599  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.1502  decode.d1.loss_mask: 0.3545  decode.d1.loss_dice: 0.2108  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.3505  decode.d2.loss_dice: 0.2062  decode.d3.loss_cls: 0.1116  decode.d3.loss_mask: 0.3521  decode.d3.loss_dice: 0.2282  decode.d4.loss_cls: 0.0969  decode.d4.loss_mask: 0.3518  decode.d4.loss_dice: 0.2258  decode.d5.loss_cls: 0.0949  decode.d5.loss_mask: 0.3578  decode.d5.loss_dice: 0.2220  decode.d6.loss_cls: 0.0847  decode.d6.loss_mask: 0.3568  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.3522  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.0833  decode.d8.loss_mask: 0.3591  decode.d8.loss_dice: 0.2122
09/30 10:31:21 - mmengine - INFO - Iter(train) [ 12250/320000]  base_lr: 9.6548e-05 lr: 9.6548e-06  eta: 1 day, 12:58:31  time: 0.4332  data_time: 0.0089  memory: 5160  grad_norm: 55.6404  loss: 8.6380  decode.loss_cls: 0.2130  decode.loss_mask: 0.2930  decode.loss_dice: 0.2586  decode.d0.loss_cls: 0.9578  decode.d0.loss_mask: 0.2887  decode.d0.loss_dice: 0.2812  decode.d1.loss_cls: 0.4014  decode.d1.loss_mask: 0.2824  decode.d1.loss_dice: 0.2741  decode.d2.loss_cls: 0.2581  decode.d2.loss_mask: 0.2790  decode.d2.loss_dice: 0.2498  decode.d3.loss_cls: 0.2417  decode.d3.loss_mask: 0.2787  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 0.2826  decode.d4.loss_dice: 0.2332  decode.d5.loss_cls: 0.2794  decode.d5.loss_mask: 0.2875  decode.d5.loss_dice: 0.2398  decode.d6.loss_cls: 0.2599  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.2453  decode.d7.loss_cls: 0.2318  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.2412  decode.d8.loss_cls: 0.2240  decode.d8.loss_mask: 0.2923  decode.d8.loss_dice: 0.2528
09/30 10:31:43 - mmengine - INFO - Iter(train) [ 12300/320000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 1 day, 12:58:09  time: 0.4317  data_time: 0.0086  memory: 5161  grad_norm: 58.8842  loss: 9.8033  decode.loss_cls: 0.4157  decode.loss_mask: 0.3128  decode.loss_dice: 0.3105  decode.d0.loss_cls: 1.1395  decode.d0.loss_mask: 0.2820  decode.d0.loss_dice: 0.2593  decode.d1.loss_cls: 0.3998  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.2388  decode.d2.loss_cls: 0.3435  decode.d2.loss_mask: 0.2795  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.2941  decode.d3.loss_mask: 0.2728  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.3537  decode.d4.loss_mask: 0.2722  decode.d4.loss_dice: 0.2563  decode.d5.loss_cls: 0.3215  decode.d5.loss_mask: 0.2717  decode.d5.loss_dice: 0.2595  decode.d6.loss_cls: 0.3785  decode.d6.loss_mask: 0.2731  decode.d6.loss_dice: 0.2576  decode.d7.loss_cls: 0.3576  decode.d7.loss_mask: 0.2748  decode.d7.loss_dice: 0.2572  decode.d8.loss_cls: 0.3507  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.2800
09/30 10:32:05 - mmengine - INFO - Iter(train) [ 12350/320000]  base_lr: 9.6520e-05 lr: 9.6520e-06  eta: 1 day, 12:57:46  time: 0.4308  data_time: 0.0086  memory: 5161  grad_norm: 151.7750  loss: 10.0147  decode.loss_cls: 0.2634  decode.loss_mask: 0.3576  decode.loss_dice: 0.3043  decode.d0.loss_cls: 1.0543  decode.d0.loss_mask: 0.3711  decode.d0.loss_dice: 0.3426  decode.d1.loss_cls: 0.3304  decode.d1.loss_mask: 0.3385  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.2773  decode.d2.loss_mask: 0.3480  decode.d2.loss_dice: 0.2831  decode.d3.loss_cls: 0.2534  decode.d3.loss_mask: 0.3389  decode.d3.loss_dice: 0.2739  decode.d4.loss_cls: 0.3514  decode.d4.loss_mask: 0.3390  decode.d4.loss_dice: 0.2615  decode.d5.loss_cls: 0.2654  decode.d5.loss_mask: 0.3714  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.2376  decode.d6.loss_mask: 0.3447  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.2588  decode.d7.loss_mask: 0.3461  decode.d7.loss_dice: 0.2979  decode.d8.loss_cls: 0.2775  decode.d8.loss_mask: 0.3510  decode.d8.loss_dice: 0.3003
09/30 10:32:26 - mmengine - INFO - Iter(train) [ 12400/320000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 1 day, 12:57:23  time: 0.4318  data_time: 0.0089  memory: 5160  grad_norm: 85.4773  loss: 8.7614  decode.loss_cls: 0.1828  decode.loss_mask: 0.3587  decode.loss_dice: 0.2591  decode.d0.loss_cls: 1.2037  decode.d0.loss_mask: 0.3065  decode.d0.loss_dice: 0.2488  decode.d1.loss_cls: 0.2389  decode.d1.loss_mask: 0.3165  decode.d1.loss_dice: 0.2431  decode.d2.loss_cls: 0.2267  decode.d2.loss_mask: 0.3109  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.2210  decode.d3.loss_mask: 0.3359  decode.d3.loss_dice: 0.2365  decode.d4.loss_cls: 0.2144  decode.d4.loss_mask: 0.3328  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.1863  decode.d5.loss_mask: 0.3089  decode.d5.loss_dice: 0.2435  decode.d6.loss_cls: 0.2296  decode.d6.loss_mask: 0.3078  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.2399  decode.d7.loss_mask: 0.3048  decode.d7.loss_dice: 0.2395  decode.d8.loss_cls: 0.2070  decode.d8.loss_mask: 0.3145  decode.d8.loss_dice: 0.2389
09/30 10:32:48 - mmengine - INFO - Iter(train) [ 12450/320000]  base_lr: 9.6492e-05 lr: 9.6492e-06  eta: 1 day, 12:57:00  time: 0.4319  data_time: 0.0088  memory: 5161  grad_norm: 125.2549  loss: 8.2466  decode.loss_cls: 0.1595  decode.loss_mask: 0.3130  decode.loss_dice: 0.2478  decode.d0.loss_cls: 1.0181  decode.d0.loss_mask: 0.3143  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.1958  decode.d1.loss_mask: 0.3254  decode.d1.loss_dice: 0.3108  decode.d2.loss_cls: 0.1253  decode.d2.loss_mask: 0.2963  decode.d2.loss_dice: 0.2837  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.3005  decode.d3.loss_dice: 0.2869  decode.d4.loss_cls: 0.1699  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.1660  decode.d5.loss_mask: 0.2851  decode.d5.loss_dice: 0.2273  decode.d6.loss_cls: 0.1635  decode.d6.loss_mask: 0.2893  decode.d6.loss_dice: 0.2847  decode.d7.loss_cls: 0.1717  decode.d7.loss_mask: 0.3051  decode.d7.loss_dice: 0.2589  decode.d8.loss_cls: 0.1793  decode.d8.loss_mask: 0.3451  decode.d8.loss_dice: 0.2655
09/30 10:33:09 - mmengine - INFO - Iter(train) [ 12500/320000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 1 day, 12:56:38  time: 0.4327  data_time: 0.0089  memory: 5180  grad_norm: 105.7942  loss: 7.9683  decode.loss_cls: 0.0923  decode.loss_mask: 0.3225  decode.loss_dice: 0.2568  decode.d0.loss_cls: 1.0154  decode.d0.loss_mask: 0.3048  decode.d0.loss_dice: 0.2889  decode.d1.loss_cls: 0.1417  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.2803  decode.d2.loss_cls: 0.1122  decode.d2.loss_mask: 0.3020  decode.d2.loss_dice: 0.2555  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.3107  decode.d3.loss_dice: 0.2678  decode.d4.loss_cls: 0.1669  decode.d4.loss_mask: 0.3294  decode.d4.loss_dice: 0.2720  decode.d5.loss_cls: 0.1262  decode.d5.loss_mask: 0.3466  decode.d5.loss_dice: 0.2741  decode.d6.loss_cls: 0.1062  decode.d6.loss_mask: 0.3323  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.1197  decode.d7.loss_mask: 0.3346  decode.d7.loss_dice: 0.2703  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.3229  decode.d8.loss_dice: 0.2583
09/30 10:33:31 - mmengine - INFO - Iter(train) [ 12550/320000]  base_lr: 9.6464e-05 lr: 9.6464e-06  eta: 1 day, 12:56:16  time: 0.4332  data_time: 0.0089  memory: 5180  grad_norm: 59.5253  loss: 9.3512  decode.loss_cls: 0.3738  decode.loss_mask: 0.2615  decode.loss_dice: 0.2992  decode.d0.loss_cls: 1.0086  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.3032  decode.d1.loss_cls: 0.3653  decode.d1.loss_mask: 0.2374  decode.d1.loss_dice: 0.2768  decode.d2.loss_cls: 0.3725  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.2781  decode.d3.loss_cls: 0.3326  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2621  decode.d4.loss_cls: 0.3361  decode.d4.loss_mask: 0.2326  decode.d4.loss_dice: 0.2771  decode.d5.loss_cls: 0.3286  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2822  decode.d6.loss_cls: 0.3467  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.3434  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.3820  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.2605
09/30 10:33:53 - mmengine - INFO - Iter(train) [ 12600/320000]  base_lr: 9.6449e-05 lr: 9.6449e-06  eta: 1 day, 12:55:54  time: 0.4333  data_time: 0.0089  memory: 5161  grad_norm: 33.1483  loss: 7.8315  decode.loss_cls: 0.1898  decode.loss_mask: 0.3206  decode.loss_dice: 0.2191  decode.d0.loss_cls: 0.8923  decode.d0.loss_mask: 0.2948  decode.d0.loss_dice: 0.2609  decode.d1.loss_cls: 0.1920  decode.d1.loss_mask: 0.3119  decode.d1.loss_dice: 0.2251  decode.d2.loss_cls: 0.0897  decode.d2.loss_mask: 0.3218  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.2513  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.2291  decode.d4.loss_cls: 0.1668  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.2109  decode.d5.loss_cls: 0.2012  decode.d5.loss_mask: 0.3094  decode.d5.loss_dice: 0.2378  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.3341  decode.d6.loss_dice: 0.2118  decode.d7.loss_cls: 0.2545  decode.d7.loss_mask: 0.2928  decode.d7.loss_dice: 0.2180  decode.d8.loss_cls: 0.1645  decode.d8.loss_mask: 0.3105  decode.d8.loss_dice: 0.2197
09/30 10:34:14 - mmengine - INFO - Iter(train) [ 12650/320000]  base_lr: 9.6435e-05 lr: 9.6435e-06  eta: 1 day, 12:55:32  time: 0.4314  data_time: 0.0089  memory: 5145  grad_norm: 124.8110  loss: 10.5546  decode.loss_cls: 0.1961  decode.loss_mask: 0.4300  decode.loss_dice: 0.3155  decode.d0.loss_cls: 1.2012  decode.d0.loss_mask: 0.4088  decode.d0.loss_dice: 0.3530  decode.d1.loss_cls: 0.2695  decode.d1.loss_mask: 0.4173  decode.d1.loss_dice: 0.3155  decode.d2.loss_cls: 0.2696  decode.d2.loss_mask: 0.4228  decode.d2.loss_dice: 0.3181  decode.d3.loss_cls: 0.2423  decode.d3.loss_mask: 0.4294  decode.d3.loss_dice: 0.2998  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.4230  decode.d4.loss_dice: 0.2995  decode.d5.loss_cls: 0.1938  decode.d5.loss_mask: 0.4332  decode.d5.loss_dice: 0.3222  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.4301  decode.d6.loss_dice: 0.3052  decode.d7.loss_cls: 0.1859  decode.d7.loss_mask: 0.4362  decode.d7.loss_dice: 0.3250  decode.d8.loss_cls: 0.1817  decode.d8.loss_mask: 0.4250  decode.d8.loss_dice: 0.3234
09/30 10:34:36 - mmengine - INFO - Iter(train) [ 12700/320000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 1 day, 12:55:10  time: 0.4324  data_time: 0.0089  memory: 5161  grad_norm: 80.9927  loss: 9.0164  decode.loss_cls: 0.2974  decode.loss_mask: 0.2804  decode.loss_dice: 0.2645  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 0.2772  decode.d0.loss_dice: 0.2833  decode.d1.loss_cls: 0.3601  decode.d1.loss_mask: 0.2818  decode.d1.loss_dice: 0.3048  decode.d2.loss_cls: 0.2881  decode.d2.loss_mask: 0.2824  decode.d2.loss_dice: 0.2164  decode.d3.loss_cls: 0.2737  decode.d3.loss_mask: 0.2853  decode.d3.loss_dice: 0.2429  decode.d4.loss_cls: 0.3092  decode.d4.loss_mask: 0.2843  decode.d4.loss_dice: 0.2602  decode.d5.loss_cls: 0.3002  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.2669  decode.d6.loss_cls: 0.3197  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.2447  decode.d7.loss_cls: 0.3045  decode.d7.loss_mask: 0.2827  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.3272  decode.d8.loss_mask: 0.2792  decode.d8.loss_dice: 0.2765
09/30 10:34:57 - mmengine - INFO - Iter(train) [ 12750/320000]  base_lr: 9.6407e-05 lr: 9.6407e-06  eta: 1 day, 12:54:48  time: 0.4322  data_time: 0.0089  memory: 5161  grad_norm: 110.2120  loss: 9.5725  decode.loss_cls: 0.2869  decode.loss_mask: 0.3203  decode.loss_dice: 0.3088  decode.d0.loss_cls: 1.0089  decode.d0.loss_mask: 0.3389  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.2790  decode.d1.loss_mask: 0.3278  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.3069  decode.d2.loss_mask: 0.3306  decode.d2.loss_dice: 0.2602  decode.d3.loss_cls: 0.2800  decode.d3.loss_mask: 0.3273  decode.d3.loss_dice: 0.3065  decode.d4.loss_cls: 0.2561  decode.d4.loss_mask: 0.3180  decode.d4.loss_dice: 0.2883  decode.d5.loss_cls: 0.2706  decode.d5.loss_mask: 0.3159  decode.d5.loss_dice: 0.2656  decode.d6.loss_cls: 0.2609  decode.d6.loss_mask: 0.3157  decode.d6.loss_dice: 0.2783  decode.d7.loss_cls: 0.2893  decode.d7.loss_mask: 0.3172  decode.d7.loss_dice: 0.2838  decode.d8.loss_cls: 0.2984  decode.d8.loss_mask: 0.3152  decode.d8.loss_dice: 0.2641
09/30 10:35:19 - mmengine - INFO - Iter(train) [ 12800/320000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 1 day, 12:54:32  time: 0.4517  data_time: 0.0089  memory: 5147  grad_norm: 143.6535  loss: 8.4237  decode.loss_cls: 0.2152  decode.loss_mask: 0.2886  decode.loss_dice: 0.2162  decode.d0.loss_cls: 1.1979  decode.d0.loss_mask: 0.2476  decode.d0.loss_dice: 0.2324  decode.d1.loss_cls: 0.3997  decode.d1.loss_mask: 0.2544  decode.d1.loss_dice: 0.2299  decode.d2.loss_cls: 0.2663  decode.d2.loss_mask: 0.2606  decode.d2.loss_dice: 0.2188  decode.d3.loss_cls: 0.2731  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2102  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 0.2581  decode.d4.loss_dice: 0.2022  decode.d5.loss_cls: 0.2358  decode.d5.loss_mask: 0.2702  decode.d5.loss_dice: 0.2039  decode.d6.loss_cls: 0.2508  decode.d6.loss_mask: 0.2773  decode.d6.loss_dice: 0.2235  decode.d7.loss_cls: 0.2475  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.1846  decode.d8.loss_mask: 0.3210  decode.d8.loss_dice: 0.2276
09/30 10:35:41 - mmengine - INFO - Iter(train) [ 12850/320000]  base_lr: 9.6379e-05 lr: 9.6379e-06  eta: 1 day, 12:54:11  time: 0.4330  data_time: 0.0090  memory: 5160  grad_norm: 156.1267  loss: 8.4883  decode.loss_cls: 0.1660  decode.loss_mask: 0.3121  decode.loss_dice: 0.2628  decode.d0.loss_cls: 0.9410  decode.d0.loss_mask: 0.3538  decode.d0.loss_dice: 0.2551  decode.d1.loss_cls: 0.2625  decode.d1.loss_mask: 0.3218  decode.d1.loss_dice: 0.2643  decode.d2.loss_cls: 0.2672  decode.d2.loss_mask: 0.3066  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.1589  decode.d3.loss_mask: 0.3129  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.1754  decode.d4.loss_mask: 0.3114  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.2018  decode.d5.loss_mask: 0.3100  decode.d5.loss_dice: 0.2499  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 0.3108  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.1620  decode.d7.loss_mask: 0.3188  decode.d7.loss_dice: 0.2501  decode.d8.loss_cls: 0.1998  decode.d8.loss_mask: 0.3170  decode.d8.loss_dice: 0.2746
09/30 10:36:03 - mmengine - INFO - Iter(train) [ 12900/320000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 1 day, 12:53:50  time: 0.4323  data_time: 0.0089  memory: 5180  grad_norm: 144.9229  loss: 12.6784  decode.loss_cls: 0.4665  decode.loss_mask: 0.4365  decode.loss_dice: 0.3902  decode.d0.loss_cls: 1.2419  decode.d0.loss_mask: 0.3063  decode.d0.loss_dice: 0.3501  decode.d1.loss_cls: 0.4707  decode.d1.loss_mask: 0.3050  decode.d1.loss_dice: 0.3210  decode.d2.loss_cls: 0.5072  decode.d2.loss_mask: 0.3028  decode.d2.loss_dice: 0.3494  decode.d3.loss_cls: 0.5477  decode.d3.loss_mask: 0.3440  decode.d3.loss_dice: 0.3240  decode.d4.loss_cls: 0.5196  decode.d4.loss_mask: 0.3380  decode.d4.loss_dice: 0.3519  decode.d5.loss_cls: 0.5499  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.3319  decode.d6.loss_cls: 0.6225  decode.d6.loss_mask: 0.2957  decode.d6.loss_dice: 0.3088  decode.d7.loss_cls: 0.5311  decode.d7.loss_mask: 0.3608  decode.d7.loss_dice: 0.3130  decode.d8.loss_cls: 0.4842  decode.d8.loss_mask: 0.3292  decode.d8.loss_dice: 0.3745
09/30 10:36:24 - mmengine - INFO - Iter(train) [ 12950/320000]  base_lr: 9.6351e-05 lr: 9.6351e-06  eta: 1 day, 12:53:28  time: 0.4320  data_time: 0.0087  memory: 5161  grad_norm: 102.2851  loss: 10.3386  decode.loss_cls: 0.3307  decode.loss_mask: 0.3483  decode.loss_dice: 0.2499  decode.d0.loss_cls: 1.3109  decode.d0.loss_mask: 0.3197  decode.d0.loss_dice: 0.2795  decode.d1.loss_cls: 0.4657  decode.d1.loss_mask: 0.3571  decode.d1.loss_dice: 0.2647  decode.d2.loss_cls: 0.3666  decode.d2.loss_mask: 0.3364  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.4277  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.2300  decode.d4.loss_cls: 0.3305  decode.d4.loss_mask: 0.3427  decode.d4.loss_dice: 0.2454  decode.d5.loss_cls: 0.3082  decode.d5.loss_mask: 0.3530  decode.d5.loss_dice: 0.2460  decode.d6.loss_cls: 0.2791  decode.d6.loss_mask: 0.3746  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2916  decode.d7.loss_mask: 0.3480  decode.d7.loss_dice: 0.2393  decode.d8.loss_cls: 0.2821  decode.d8.loss_mask: 0.3443  decode.d8.loss_dice: 0.2679
09/30 10:36:46 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:36:46 - mmengine - INFO - Iter(train) [ 13000/320000]  base_lr: 9.6336e-05 lr: 9.6336e-06  eta: 1 day, 12:53:07  time: 0.4322  data_time: 0.0088  memory: 5180  grad_norm: 127.9517  loss: 9.7206  decode.loss_cls: 0.3335  decode.loss_mask: 0.2951  decode.loss_dice: 0.2877  decode.d0.loss_cls: 0.9040  decode.d0.loss_mask: 0.2393  decode.d0.loss_dice: 0.2929  decode.d1.loss_cls: 0.3837  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.3270  decode.d2.loss_mask: 0.2739  decode.d2.loss_dice: 0.2827  decode.d3.loss_cls: 0.3665  decode.d3.loss_mask: 0.2833  decode.d3.loss_dice: 0.2890  decode.d4.loss_cls: 0.4303  decode.d4.loss_mask: 0.2654  decode.d4.loss_dice: 0.2838  decode.d5.loss_cls: 0.3640  decode.d5.loss_mask: 0.2666  decode.d5.loss_dice: 0.2923  decode.d6.loss_cls: 0.3561  decode.d6.loss_mask: 0.2836  decode.d6.loss_dice: 0.2770  decode.d7.loss_cls: 0.3585  decode.d7.loss_mask: 0.2749  decode.d7.loss_dice: 0.2729  decode.d8.loss_cls: 0.3467  decode.d8.loss_mask: 0.3040  decode.d8.loss_dice: 0.2774
09/30 10:37:08 - mmengine - INFO - Iter(train) [ 13050/320000]  base_lr: 9.6322e-05 lr: 9.6322e-06  eta: 1 day, 12:52:46  time: 0.4326  data_time: 0.0088  memory: 5161  grad_norm: 90.0786  loss: 8.3279  decode.loss_cls: 0.1829  decode.loss_mask: 0.2724  decode.loss_dice: 0.2225  decode.d0.loss_cls: 1.0734  decode.d0.loss_mask: 0.2725  decode.d0.loss_dice: 0.2019  decode.d1.loss_cls: 0.3947  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2289  decode.d2.loss_cls: 0.3274  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.2188  decode.d3.loss_cls: 0.2871  decode.d3.loss_mask: 0.2665  decode.d3.loss_dice: 0.2231  decode.d4.loss_cls: 0.2552  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.2106  decode.d5.loss_cls: 0.2497  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2264  decode.d6.loss_cls: 0.2090  decode.d6.loss_mask: 0.2690  decode.d6.loss_dice: 0.2116  decode.d7.loss_cls: 0.2125  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.2212  decode.d8.loss_cls: 0.2409  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.2275
09/30 10:37:29 - mmengine - INFO - Iter(train) [ 13100/320000]  base_lr: 9.6308e-05 lr: 9.6308e-06  eta: 1 day, 12:52:24  time: 0.4339  data_time: 0.0091  memory: 5160  grad_norm: 150.9118  loss: 11.7586  decode.loss_cls: 0.3686  decode.loss_mask: 0.3798  decode.loss_dice: 0.3595  decode.d0.loss_cls: 1.0040  decode.d0.loss_mask: 0.3934  decode.d0.loss_dice: 0.3526  decode.d1.loss_cls: 0.4605  decode.d1.loss_mask: 0.3867  decode.d1.loss_dice: 0.3432  decode.d2.loss_cls: 0.3671  decode.d2.loss_mask: 0.3792  decode.d2.loss_dice: 0.3475  decode.d3.loss_cls: 0.3422  decode.d3.loss_mask: 0.3829  decode.d3.loss_dice: 0.3337  decode.d4.loss_cls: 0.3812  decode.d4.loss_mask: 0.3867  decode.d4.loss_dice: 0.3412  decode.d5.loss_cls: 0.3725  decode.d5.loss_mask: 0.3992  decode.d5.loss_dice: 0.3343  decode.d6.loss_cls: 0.3282  decode.d6.loss_mask: 0.3870  decode.d6.loss_dice: 0.3415  decode.d7.loss_cls: 0.3782  decode.d7.loss_mask: 0.3914  decode.d7.loss_dice: 0.3525  decode.d8.loss_cls: 0.4136  decode.d8.loss_mask: 0.3898  decode.d8.loss_dice: 0.3602
09/30 10:37:51 - mmengine - INFO - Iter(train) [ 13150/320000]  base_lr: 9.6294e-05 lr: 9.6294e-06  eta: 1 day, 12:52:02  time: 0.4336  data_time: 0.0091  memory: 5160  grad_norm: 197.2427  loss: 9.9304  decode.loss_cls: 0.4090  decode.loss_mask: 0.2866  decode.loss_dice: 0.2995  decode.d0.loss_cls: 1.1361  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.3206  decode.d1.loss_cls: 0.3895  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.2833  decode.d2.loss_cls: 0.3167  decode.d2.loss_mask: 0.2831  decode.d2.loss_dice: 0.2841  decode.d3.loss_cls: 0.2777  decode.d3.loss_mask: 0.2855  decode.d3.loss_dice: 0.2927  decode.d4.loss_cls: 0.2712  decode.d4.loss_mask: 0.2831  decode.d4.loss_dice: 0.3037  decode.d5.loss_cls: 0.2961  decode.d5.loss_mask: 0.2850  decode.d5.loss_dice: 0.3115  decode.d6.loss_cls: 0.3306  decode.d6.loss_mask: 0.2815  decode.d6.loss_dice: 0.2874  decode.d7.loss_cls: 0.3008  decode.d7.loss_mask: 0.2856  decode.d7.loss_dice: 0.3036  decode.d8.loss_cls: 0.3774  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2968
09/30 10:38:12 - mmengine - INFO - Iter(train) [ 13200/320000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 1 day, 12:51:41  time: 0.4333  data_time: 0.0090  memory: 5145  grad_norm: 154.0445  loss: 8.0915  decode.loss_cls: 0.2265  decode.loss_mask: 0.2819  decode.loss_dice: 0.2299  decode.d0.loss_cls: 0.9665  decode.d0.loss_mask: 0.3118  decode.d0.loss_dice: 0.2564  decode.d1.loss_cls: 0.2868  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.2400  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.2401  decode.d3.loss_cls: 0.1821  decode.d3.loss_mask: 0.2916  decode.d3.loss_dice: 0.2253  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 0.2966  decode.d4.loss_dice: 0.2217  decode.d5.loss_cls: 0.2002  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.2173  decode.d6.loss_cls: 0.1876  decode.d6.loss_mask: 0.2915  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.2527  decode.d8.loss_cls: 0.1797  decode.d8.loss_mask: 0.2860  decode.d8.loss_dice: 0.2293
09/30 10:38:34 - mmengine - INFO - Iter(train) [ 13250/320000]  base_lr: 9.6266e-05 lr: 9.6266e-06  eta: 1 day, 12:51:20  time: 0.4337  data_time: 0.0090  memory: 5180  grad_norm: 58.1818  loss: 9.6885  decode.loss_cls: 0.3217  decode.loss_mask: 0.2800  decode.loss_dice: 0.3356  decode.d0.loss_cls: 1.2396  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.3240  decode.d1.loss_cls: 0.3449  decode.d1.loss_mask: 0.2311  decode.d1.loss_dice: 0.3076  decode.d2.loss_cls: 0.2872  decode.d2.loss_mask: 0.2342  decode.d2.loss_dice: 0.3067  decode.d3.loss_cls: 0.3186  decode.d3.loss_mask: 0.2329  decode.d3.loss_dice: 0.2762  decode.d4.loss_cls: 0.3330  decode.d4.loss_mask: 0.2381  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.3083  decode.d5.loss_dice: 0.3472  decode.d6.loss_cls: 0.3317  decode.d6.loss_mask: 0.2500  decode.d6.loss_dice: 0.3114  decode.d7.loss_cls: 0.3359  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2884  decode.d8.loss_cls: 0.3683  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.2976
09/30 10:38:56 - mmengine - INFO - Iter(train) [ 13300/320000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 1 day, 12:50:58  time: 0.4328  data_time: 0.0089  memory: 5161  grad_norm: 75.9977  loss: 7.8435  decode.loss_cls: 0.1655  decode.loss_mask: 0.3077  decode.loss_dice: 0.2606  decode.d0.loss_cls: 0.9947  decode.d0.loss_mask: 0.2915  decode.d0.loss_dice: 0.2188  decode.d1.loss_cls: 0.2220  decode.d1.loss_mask: 0.2979  decode.d1.loss_dice: 0.2011  decode.d2.loss_cls: 0.1671  decode.d2.loss_mask: 0.2977  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2196  decode.d4.loss_cls: 0.1419  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.2110  decode.d5.loss_cls: 0.1509  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.2430  decode.d6.loss_cls: 0.1513  decode.d6.loss_mask: 0.2971  decode.d6.loss_dice: 0.2502  decode.d7.loss_cls: 0.1288  decode.d7.loss_mask: 0.3481  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 0.3120  decode.d8.loss_dice: 0.2745
09/30 10:39:17 - mmengine - INFO - Iter(train) [ 13350/320000]  base_lr: 9.6238e-05 lr: 9.6238e-06  eta: 1 day, 12:50:36  time: 0.4318  data_time: 0.0088  memory: 5180  grad_norm: 75.1183  loss: 9.1324  decode.loss_cls: 0.2950  decode.loss_mask: 0.2771  decode.loss_dice: 0.2562  decode.d0.loss_cls: 1.1256  decode.d0.loss_mask: 0.2794  decode.d0.loss_dice: 0.2450  decode.d1.loss_cls: 0.3366  decode.d1.loss_mask: 0.2720  decode.d1.loss_dice: 0.2507  decode.d2.loss_cls: 0.3109  decode.d2.loss_mask: 0.2774  decode.d2.loss_dice: 0.2578  decode.d3.loss_cls: 0.2713  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.2600  decode.d4.loss_cls: 0.3304  decode.d4.loss_mask: 0.2708  decode.d4.loss_dice: 0.2602  decode.d5.loss_cls: 0.3052  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2505  decode.d6.loss_cls: 0.2914  decode.d6.loss_mask: 0.2711  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.2724  decode.d7.loss_mask: 0.2738  decode.d7.loss_dice: 0.2559  decode.d8.loss_cls: 0.3159  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.2585
09/30 10:39:39 - mmengine - INFO - Iter(train) [ 13400/320000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 1 day, 12:50:14  time: 0.4324  data_time: 0.0089  memory: 5147  grad_norm: 171.6095  loss: 9.2159  decode.loss_cls: 0.2635  decode.loss_mask: 0.3089  decode.loss_dice: 0.2457  decode.d0.loss_cls: 1.0990  decode.d0.loss_mask: 0.3038  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.3156  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.2228  decode.d2.loss_cls: 0.2244  decode.d2.loss_mask: 0.3307  decode.d2.loss_dice: 0.2240  decode.d3.loss_cls: 0.3918  decode.d3.loss_mask: 0.2925  decode.d3.loss_dice: 0.2233  decode.d4.loss_cls: 0.3265  decode.d4.loss_mask: 0.2989  decode.d4.loss_dice: 0.2135  decode.d5.loss_cls: 0.3110  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.2621  decode.d6.loss_mask: 0.3156  decode.d6.loss_dice: 0.2534  decode.d7.loss_cls: 0.2711  decode.d7.loss_mask: 0.3304  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.2854  decode.d8.loss_mask: 0.3123  decode.d8.loss_dice: 0.2562
09/30 10:40:01 - mmengine - INFO - Iter(train) [ 13450/320000]  base_lr: 9.6209e-05 lr: 9.6209e-06  eta: 1 day, 12:49:53  time: 0.4320  data_time: 0.0089  memory: 5161  grad_norm: 97.1704  loss: 7.6366  decode.loss_cls: 0.1869  decode.loss_mask: 0.3205  decode.loss_dice: 0.2059  decode.d0.loss_cls: 0.9488  decode.d0.loss_mask: 0.3055  decode.d0.loss_dice: 0.2065  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.2043  decode.d2.loss_cls: 0.2018  decode.d2.loss_mask: 0.3081  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.1913  decode.d3.loss_mask: 0.2998  decode.d3.loss_dice: 0.1991  decode.d4.loss_cls: 0.1769  decode.d4.loss_mask: 0.3018  decode.d4.loss_dice: 0.2020  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 0.3019  decode.d5.loss_dice: 0.2012  decode.d6.loss_cls: 0.1652  decode.d6.loss_mask: 0.2973  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.1603  decode.d7.loss_mask: 0.3270  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.1419  decode.d8.loss_mask: 0.3262  decode.d8.loss_dice: 0.1950
09/30 10:40:22 - mmengine - INFO - Iter(train) [ 13500/320000]  base_lr: 9.6195e-05 lr: 9.6195e-06  eta: 1 day, 12:49:32  time: 0.4332  data_time: 0.0092  memory: 5161  grad_norm: 70.5977  loss: 9.5433  decode.loss_cls: 0.2265  decode.loss_mask: 0.3545  decode.loss_dice: 0.2646  decode.d0.loss_cls: 1.2867  decode.d0.loss_mask: 0.3566  decode.d0.loss_dice: 0.2583  decode.d1.loss_cls: 0.3089  decode.d1.loss_mask: 0.3531  decode.d1.loss_dice: 0.2398  decode.d2.loss_cls: 0.2404  decode.d2.loss_mask: 0.3462  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.2456  decode.d3.loss_mask: 0.3504  decode.d3.loss_dice: 0.2511  decode.d4.loss_cls: 0.2168  decode.d4.loss_mask: 0.3497  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.2431  decode.d5.loss_mask: 0.3430  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.2645  decode.d6.loss_mask: 0.3511  decode.d6.loss_dice: 0.2627  decode.d7.loss_cls: 0.2046  decode.d7.loss_mask: 0.3589  decode.d7.loss_dice: 0.2562  decode.d8.loss_cls: 0.2158  decode.d8.loss_mask: 0.3575  decode.d8.loss_dice: 0.2641
09/30 10:40:44 - mmengine - INFO - Iter(train) [ 13550/320000]  base_lr: 9.6181e-05 lr: 9.6181e-06  eta: 1 day, 12:49:11  time: 0.4329  data_time: 0.0091  memory: 5160  grad_norm: 119.7393  loss: 9.3467  decode.loss_cls: 0.2870  decode.loss_mask: 0.3619  decode.loss_dice: 0.2257  decode.d0.loss_cls: 1.0595  decode.d0.loss_mask: 0.3087  decode.d0.loss_dice: 0.2548  decode.d1.loss_cls: 0.4579  decode.d1.loss_mask: 0.3683  decode.d1.loss_dice: 0.2246  decode.d2.loss_cls: 0.4011  decode.d2.loss_mask: 0.2794  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.2729  decode.d3.loss_mask: 0.3712  decode.d3.loss_dice: 0.2436  decode.d4.loss_cls: 0.2899  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.2103  decode.d5.loss_cls: 0.2253  decode.d5.loss_mask: 0.3699  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.2562  decode.d6.loss_mask: 0.2904  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.2190  decode.d7.loss_mask: 0.3844  decode.d7.loss_dice: 0.2341  decode.d8.loss_cls: 0.2497  decode.d8.loss_mask: 0.3576  decode.d8.loss_dice: 0.2312
09/30 10:41:06 - mmengine - INFO - Iter(train) [ 13600/320000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 1 day, 12:48:50  time: 0.4328  data_time: 0.0091  memory: 5145  grad_norm: 85.0814  loss: 9.6096  decode.loss_cls: 0.2987  decode.loss_mask: 0.2916  decode.loss_dice: 0.2673  decode.d0.loss_cls: 1.0996  decode.d0.loss_mask: 0.2882  decode.d0.loss_dice: 0.3124  decode.d1.loss_cls: 0.3239  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.2800  decode.d2.loss_cls: 0.3428  decode.d2.loss_mask: 0.2927  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.3391  decode.d3.loss_mask: 0.2655  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.3578  decode.d4.loss_mask: 0.2692  decode.d4.loss_dice: 0.2589  decode.d5.loss_cls: 0.3115  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2700  decode.d6.loss_cls: 0.3116  decode.d6.loss_mask: 0.2768  decode.d6.loss_dice: 0.2498  decode.d7.loss_cls: 0.3552  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2488  decode.d8.loss_cls: 0.4174  decode.d8.loss_mask: 0.2787  decode.d8.loss_dice: 0.2535
09/30 10:41:27 - mmengine - INFO - Iter(train) [ 13650/320000]  base_lr: 9.6153e-05 lr: 9.6153e-06  eta: 1 day, 12:48:28  time: 0.4328  data_time: 0.0091  memory: 5161  grad_norm: 74.3241  loss: 8.2681  decode.loss_cls: 0.1256  decode.loss_mask: 0.3096  decode.loss_dice: 0.2766  decode.d0.loss_cls: 1.0488  decode.d0.loss_mask: 0.3239  decode.d0.loss_dice: 0.2609  decode.d1.loss_cls: 0.1702  decode.d1.loss_mask: 0.3193  decode.d1.loss_dice: 0.2888  decode.d2.loss_cls: 0.2065  decode.d2.loss_mask: 0.3179  decode.d2.loss_dice: 0.2970  decode.d3.loss_cls: 0.1464  decode.d3.loss_mask: 0.3138  decode.d3.loss_dice: 0.2790  decode.d4.loss_cls: 0.1488  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.1449  decode.d5.loss_mask: 0.3099  decode.d5.loss_dice: 0.2645  decode.d6.loss_cls: 0.1392  decode.d6.loss_mask: 0.3120  decode.d6.loss_dice: 0.2733  decode.d7.loss_cls: 0.1178  decode.d7.loss_mask: 0.3134  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 0.3155  decode.d8.loss_dice: 0.2749
09/30 10:41:49 - mmengine - INFO - Iter(train) [ 13700/320000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 1 day, 12:48:08  time: 0.4334  data_time: 0.0091  memory: 5160  grad_norm: 43.8089  loss: 8.3826  decode.loss_cls: 0.2004  decode.loss_mask: 0.2849  decode.loss_dice: 0.2734  decode.d0.loss_cls: 0.9321  decode.d0.loss_mask: 0.3331  decode.d0.loss_dice: 0.2807  decode.d1.loss_cls: 0.2769  decode.d1.loss_mask: 0.2914  decode.d1.loss_dice: 0.2342  decode.d2.loss_cls: 0.2203  decode.d2.loss_mask: 0.2888  decode.d2.loss_dice: 0.2790  decode.d3.loss_cls: 0.1438  decode.d3.loss_mask: 0.3434  decode.d3.loss_dice: 0.2937  decode.d4.loss_cls: 0.1471  decode.d4.loss_mask: 0.3348  decode.d4.loss_dice: 0.3078  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 0.3297  decode.d5.loss_dice: 0.2684  decode.d6.loss_cls: 0.1674  decode.d6.loss_mask: 0.2895  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.2772  decode.d8.loss_cls: 0.1783  decode.d8.loss_mask: 0.2948  decode.d8.loss_dice: 0.2436
09/30 10:42:11 - mmengine - INFO - Iter(train) [ 13750/320000]  base_lr: 9.6125e-05 lr: 9.6125e-06  eta: 1 day, 12:47:47  time: 0.4330  data_time: 0.0090  memory: 5160  grad_norm: 167.1847  loss: 13.3215  decode.loss_cls: 0.5122  decode.loss_mask: 0.4143  decode.loss_dice: 0.3433  decode.d0.loss_cls: 1.2787  decode.d0.loss_mask: 0.4161  decode.d0.loss_dice: 0.3849  decode.d1.loss_cls: 0.6486  decode.d1.loss_mask: 0.3872  decode.d1.loss_dice: 0.3538  decode.d2.loss_cls: 0.4998  decode.d2.loss_mask: 0.4467  decode.d2.loss_dice: 0.3505  decode.d3.loss_cls: 0.3953  decode.d3.loss_mask: 0.4611  decode.d3.loss_dice: 0.3537  decode.d4.loss_cls: 0.4114  decode.d4.loss_mask: 0.4523  decode.d4.loss_dice: 0.3650  decode.d5.loss_cls: 0.4677  decode.d5.loss_mask: 0.4098  decode.d5.loss_dice: 0.3814  decode.d6.loss_cls: 0.3755  decode.d6.loss_mask: 0.3907  decode.d6.loss_dice: 0.3520  decode.d7.loss_cls: 0.4785  decode.d7.loss_mask: 0.4097  decode.d7.loss_dice: 0.3544  decode.d8.loss_cls: 0.4588  decode.d8.loss_mask: 0.3751  decode.d8.loss_dice: 0.3930
09/30 10:42:32 - mmengine - INFO - Iter(train) [ 13800/320000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 1 day, 12:47:26  time: 0.4327  data_time: 0.0089  memory: 5161  grad_norm: 103.4867  loss: 6.9797  decode.loss_cls: 0.1692  decode.loss_mask: 0.2499  decode.loss_dice: 0.2187  decode.d0.loss_cls: 0.8505  decode.d0.loss_mask: 0.2496  decode.d0.loss_dice: 0.2376  decode.d1.loss_cls: 0.2389  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.2276  decode.d2.loss_cls: 0.1504  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.2332  decode.d3.loss_cls: 0.1314  decode.d3.loss_mask: 0.2491  decode.d3.loss_dice: 0.2323  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.2208  decode.d5.loss_cls: 0.1254  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2256  decode.d6.loss_cls: 0.1197  decode.d6.loss_mask: 0.2475  decode.d6.loss_dice: 0.2249  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.2494  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.1457  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2208
09/30 10:42:54 - mmengine - INFO - Iter(train) [ 13850/320000]  base_lr: 9.6096e-05 lr: 9.6096e-06  eta: 1 day, 12:47:04  time: 0.4322  data_time: 0.0090  memory: 5160  grad_norm: 178.3837  loss: 10.2652  decode.loss_cls: 0.2392  decode.loss_mask: 0.3987  decode.loss_dice: 0.3246  decode.d0.loss_cls: 0.9156  decode.d0.loss_mask: 0.3825  decode.d0.loss_dice: 0.2977  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.3918  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.2272  decode.d2.loss_mask: 0.4043  decode.d2.loss_dice: 0.3034  decode.d3.loss_cls: 0.2253  decode.d3.loss_mask: 0.3914  decode.d3.loss_dice: 0.3309  decode.d4.loss_cls: 0.3054  decode.d4.loss_mask: 0.4001  decode.d4.loss_dice: 0.3469  decode.d5.loss_cls: 0.2294  decode.d5.loss_mask: 0.4136  decode.d5.loss_dice: 0.3248  decode.d6.loss_cls: 0.2397  decode.d6.loss_mask: 0.4046  decode.d6.loss_dice: 0.3159  decode.d7.loss_cls: 0.2782  decode.d7.loss_mask: 0.3735  decode.d7.loss_dice: 0.3086  decode.d8.loss_cls: 0.2991  decode.d8.loss_mask: 0.3799  decode.d8.loss_dice: 0.3104
09/30 10:43:15 - mmengine - INFO - Iter(train) [ 13900/320000]  base_lr: 9.6082e-05 lr: 9.6082e-06  eta: 1 day, 12:46:42  time: 0.4330  data_time: 0.0090  memory: 5160  grad_norm: 59.5836  loss: 7.4922  decode.loss_cls: 0.1669  decode.loss_mask: 0.2477  decode.loss_dice: 0.2211  decode.d0.loss_cls: 1.0437  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.2726  decode.d1.loss_cls: 0.1849  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.2589  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.2480  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.1715  decode.d3.loss_mask: 0.2626  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.1504  decode.d4.loss_mask: 0.2665  decode.d4.loss_dice: 0.2434  decode.d5.loss_cls: 0.1436  decode.d5.loss_mask: 0.2726  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.1218  decode.d6.loss_mask: 0.2711  decode.d6.loss_dice: 0.2440  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.2414  decode.d8.loss_cls: 0.1152  decode.d8.loss_mask: 0.2483  decode.d8.loss_dice: 0.2382
09/30 10:43:37 - mmengine - INFO - Iter(train) [ 13950/320000]  base_lr: 9.6068e-05 lr: 9.6068e-06  eta: 1 day, 12:46:21  time: 0.4328  data_time: 0.0087  memory: 5160  grad_norm: 84.9692  loss: 10.3134  decode.loss_cls: 0.2785  decode.loss_mask: 0.3768  decode.loss_dice: 0.2707  decode.d0.loss_cls: 1.0028  decode.d0.loss_mask: 0.4225  decode.d0.loss_dice: 0.3106  decode.d1.loss_cls: 0.3399  decode.d1.loss_mask: 0.3815  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.3148  decode.d2.loss_mask: 0.3950  decode.d2.loss_dice: 0.2518  decode.d3.loss_cls: 0.2974  decode.d3.loss_mask: 0.3948  decode.d3.loss_dice: 0.2755  decode.d4.loss_cls: 0.3299  decode.d4.loss_mask: 0.3910  decode.d4.loss_dice: 0.2585  decode.d5.loss_cls: 0.3010  decode.d5.loss_mask: 0.3840  decode.d5.loss_dice: 0.2602  decode.d6.loss_cls: 0.2889  decode.d6.loss_mask: 0.3948  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.2801  decode.d7.loss_mask: 0.3811  decode.d7.loss_dice: 0.2678  decode.d8.loss_cls: 0.2967  decode.d8.loss_mask: 0.3842  decode.d8.loss_dice: 0.2585
09/30 10:43:59 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:43:59 - mmengine - INFO - Iter(train) [ 14000/320000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 1 day, 12:45:59  time: 0.4323  data_time: 0.0086  memory: 5160  grad_norm: 65.3106  loss: 8.6763  decode.loss_cls: 0.2248  decode.loss_mask: 0.3148  decode.loss_dice: 0.2482  decode.d0.loss_cls: 1.0416  decode.d0.loss_mask: 0.3157  decode.d0.loss_dice: 0.2520  decode.d1.loss_cls: 0.2609  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.1940  decode.d2.loss_mask: 0.3254  decode.d2.loss_dice: 0.2400  decode.d3.loss_cls: 0.1711  decode.d3.loss_mask: 0.3225  decode.d3.loss_dice: 0.2436  decode.d4.loss_cls: 0.2091  decode.d4.loss_mask: 0.3234  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.2430  decode.d6.loss_mask: 0.3148  decode.d6.loss_dice: 0.2524  decode.d7.loss_cls: 0.2031  decode.d7.loss_mask: 0.3186  decode.d7.loss_dice: 0.2494  decode.d8.loss_cls: 0.2275  decode.d8.loss_mask: 0.3174  decode.d8.loss_dice: 0.2514
09/30 10:44:20 - mmengine - INFO - Iter(train) [ 14050/320000]  base_lr: 9.6040e-05 lr: 9.6040e-06  eta: 1 day, 12:45:37  time: 0.4322  data_time: 0.0087  memory: 5160  grad_norm: 96.6168  loss: 8.2399  decode.loss_cls: 0.1923  decode.loss_mask: 0.2662  decode.loss_dice: 0.2491  decode.d0.loss_cls: 0.9409  decode.d0.loss_mask: 0.2792  decode.d0.loss_dice: 0.2507  decode.d1.loss_cls: 0.2903  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.2523  decode.d2.loss_cls: 0.2518  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.2429  decode.d3.loss_cls: 0.2345  decode.d3.loss_mask: 0.2695  decode.d3.loss_dice: 0.2363  decode.d4.loss_cls: 0.2472  decode.d4.loss_mask: 0.2701  decode.d4.loss_dice: 0.2378  decode.d5.loss_cls: 0.2230  decode.d5.loss_mask: 0.2676  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.2650  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.2789  decode.d7.loss_mask: 0.2699  decode.d7.loss_dice: 0.2357  decode.d8.loss_cls: 0.1981  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.2404
09/30 10:44:42 - mmengine - INFO - Iter(train) [ 14100/320000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 1 day, 12:45:15  time: 0.4319  data_time: 0.0088  memory: 5147  grad_norm: 51.8928  loss: 8.0633  decode.loss_cls: 0.2341  decode.loss_mask: 0.2731  decode.loss_dice: 0.2274  decode.d0.loss_cls: 1.0129  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.2412  decode.d1.loss_cls: 0.2275  decode.d1.loss_mask: 0.2713  decode.d1.loss_dice: 0.2215  decode.d2.loss_cls: 0.2379  decode.d2.loss_mask: 0.2742  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.2186  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2385  decode.d4.loss_cls: 0.2120  decode.d4.loss_mask: 0.2737  decode.d4.loss_dice: 0.2348  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 0.2728  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.2214  decode.d6.loss_mask: 0.2726  decode.d6.loss_dice: 0.2255  decode.d7.loss_cls: 0.2013  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.2362  decode.d8.loss_cls: 0.2233  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.2461
09/30 10:45:03 - mmengine - INFO - Iter(train) [ 14150/320000]  base_lr: 9.6012e-05 lr: 9.6012e-06  eta: 1 day, 12:44:52  time: 0.4303  data_time: 0.0085  memory: 5160  grad_norm: 271.8429  loss: 8.3039  decode.loss_cls: 0.1320  decode.loss_mask: 0.3684  decode.loss_dice: 0.2381  decode.d0.loss_cls: 0.9325  decode.d0.loss_mask: 0.3889  decode.d0.loss_dice: 0.2449  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.3590  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.1359  decode.d2.loss_mask: 0.3693  decode.d2.loss_dice: 0.2391  decode.d3.loss_cls: 0.1436  decode.d3.loss_mask: 0.3709  decode.d3.loss_dice: 0.2519  decode.d4.loss_cls: 0.1765  decode.d4.loss_mask: 0.3624  decode.d4.loss_dice: 0.2356  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 0.3682  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.1303  decode.d6.loss_mask: 0.3633  decode.d6.loss_dice: 0.2277  decode.d7.loss_cls: 0.1367  decode.d7.loss_mask: 0.3601  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.1131  decode.d8.loss_mask: 0.3647  decode.d8.loss_dice: 0.2339
09/30 10:45:25 - mmengine - INFO - Iter(train) [ 14200/320000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 1 day, 12:44:29  time: 0.4312  data_time: 0.0085  memory: 5160  grad_norm: 76.0666  loss: 9.5968  decode.loss_cls: 0.2938  decode.loss_mask: 0.2409  decode.loss_dice: 0.3538  decode.d0.loss_cls: 1.0615  decode.d0.loss_mask: 0.2452  decode.d0.loss_dice: 0.3507  decode.d1.loss_cls: 0.2754  decode.d1.loss_mask: 0.2462  decode.d1.loss_dice: 0.3462  decode.d2.loss_cls: 0.2614  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.3443  decode.d3.loss_cls: 0.2814  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.3471  decode.d4.loss_cls: 0.2992  decode.d4.loss_mask: 0.2439  decode.d4.loss_dice: 0.3443  decode.d5.loss_cls: 0.2486  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.3536  decode.d6.loss_cls: 0.3324  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.3499  decode.d7.loss_cls: 0.3050  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.3561  decode.d8.loss_cls: 0.2996  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.3607
09/30 10:45:47 - mmengine - INFO - Iter(train) [ 14250/320000]  base_lr: 9.5983e-05 lr: 9.5983e-06  eta: 1 day, 12:44:06  time: 0.4319  data_time: 0.0090  memory: 5161  grad_norm: 283.5120  loss: 10.1245  decode.loss_cls: 0.1691  decode.loss_mask: 0.4550  decode.loss_dice: 0.3267  decode.d0.loss_cls: 0.9516  decode.d0.loss_mask: 0.4028  decode.d0.loss_dice: 0.2787  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.4287  decode.d1.loss_dice: 0.2744  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.4314  decode.d2.loss_dice: 0.2965  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.4571  decode.d3.loss_dice: 0.3246  decode.d4.loss_cls: 0.1703  decode.d4.loss_mask: 0.5779  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 0.1491  decode.d5.loss_mask: 0.5679  decode.d5.loss_dice: 0.3378  decode.d6.loss_cls: 0.1365  decode.d6.loss_mask: 0.4527  decode.d6.loss_dice: 0.3189  decode.d7.loss_cls: 0.1332  decode.d7.loss_mask: 0.4324  decode.d7.loss_dice: 0.3269  decode.d8.loss_cls: 0.1842  decode.d8.loss_mask: 0.5848  decode.d8.loss_dice: 0.3218
09/30 10:46:08 - mmengine - INFO - Iter(train) [ 14300/320000]  base_lr: 9.5969e-05 lr: 9.5969e-06  eta: 1 day, 12:43:45  time: 0.4337  data_time: 0.0089  memory: 5160  grad_norm: 134.9089  loss: 8.2231  decode.loss_cls: 0.1689  decode.loss_mask: 0.2808  decode.loss_dice: 0.2166  decode.d0.loss_cls: 1.4143  decode.d0.loss_mask: 0.2812  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.2817  decode.d1.loss_mask: 0.2914  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.1986  decode.d2.loss_mask: 0.2767  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.2173  decode.d3.loss_mask: 0.2810  decode.d3.loss_dice: 0.2202  decode.d4.loss_cls: 0.2113  decode.d4.loss_mask: 0.2797  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.1656  decode.d5.loss_mask: 0.2767  decode.d5.loss_dice: 0.2182  decode.d6.loss_cls: 0.1585  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.2134  decode.d7.loss_cls: 0.1667  decode.d7.loss_mask: 0.2821  decode.d7.loss_dice: 0.2287  decode.d8.loss_cls: 0.1728  decode.d8.loss_mask: 0.2744  decode.d8.loss_dice: 0.2194
09/30 10:46:30 - mmengine - INFO - Iter(train) [ 14350/320000]  base_lr: 9.5955e-05 lr: 9.5955e-06  eta: 1 day, 12:43:23  time: 0.4330  data_time: 0.0091  memory: 5147  grad_norm: 233.4881  loss: 13.4057  decode.loss_cls: 0.5625  decode.loss_mask: 0.3706  decode.loss_dice: 0.3785  decode.d0.loss_cls: 1.1007  decode.d0.loss_mask: 0.3816  decode.d0.loss_dice: 0.3954  decode.d1.loss_cls: 0.6262  decode.d1.loss_mask: 0.3618  decode.d1.loss_dice: 0.3631  decode.d2.loss_cls: 0.5803  decode.d2.loss_mask: 0.3598  decode.d2.loss_dice: 0.3671  decode.d3.loss_cls: 0.5276  decode.d3.loss_mask: 0.3564  decode.d3.loss_dice: 0.3653  decode.d4.loss_cls: 0.5397  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.3646  decode.d5.loss_cls: 0.5338  decode.d5.loss_mask: 0.3663  decode.d5.loss_dice: 0.3942  decode.d6.loss_cls: 0.4917  decode.d6.loss_mask: 0.3619  decode.d6.loss_dice: 0.3620  decode.d7.loss_cls: 0.5061  decode.d7.loss_mask: 0.3682  decode.d7.loss_dice: 0.3870  decode.d8.loss_cls: 0.5325  decode.d8.loss_mask: 0.3573  decode.d8.loss_dice: 0.3779
09/30 10:46:51 - mmengine - INFO - Iter(train) [ 14400/320000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 1 day, 12:43:01  time: 0.4320  data_time: 0.0088  memory: 5161  grad_norm: 92.9625  loss: 6.8960  decode.loss_cls: 0.1329  decode.loss_mask: 0.2707  decode.loss_dice: 0.1900  decode.d0.loss_cls: 1.0285  decode.d0.loss_mask: 0.2530  decode.d0.loss_dice: 0.1948  decode.d1.loss_cls: 0.2190  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.1851  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.1894  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.1568  decode.d5.loss_mask: 0.2472  decode.d5.loss_dice: 0.1884  decode.d6.loss_cls: 0.1259  decode.d6.loss_mask: 0.2551  decode.d6.loss_dice: 0.1773  decode.d7.loss_cls: 0.1394  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.1889  decode.d8.loss_cls: 0.1698  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.1840
09/30 10:47:13 - mmengine - INFO - Iter(train) [ 14450/320000]  base_lr: 9.5927e-05 lr: 9.5927e-06  eta: 1 day, 12:42:44  time: 0.4498  data_time: 0.0087  memory: 5180  grad_norm: 81.9987  loss: 7.7608  decode.loss_cls: 0.2088  decode.loss_mask: 0.2295  decode.loss_dice: 0.2472  decode.d0.loss_cls: 1.1342  decode.d0.loss_mask: 0.2037  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.2973  decode.d1.loss_mask: 0.2267  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.2931  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.2171  decode.d3.loss_mask: 0.2288  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.2317  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.2116  decode.d5.loss_cls: 0.1982  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.1934  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2356  decode.d7.loss_cls: 0.2029  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.2310  decode.d8.loss_cls: 0.1974  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.2293
09/30 10:47:35 - mmengine - INFO - Iter(train) [ 14500/320000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 1 day, 12:42:22  time: 0.4328  data_time: 0.0088  memory: 5160  grad_norm: 128.8837  loss: 10.4642  decode.loss_cls: 0.2956  decode.loss_mask: 0.4134  decode.loss_dice: 0.3090  decode.d0.loss_cls: 1.2308  decode.d0.loss_mask: 0.2953  decode.d0.loss_dice: 0.3007  decode.d1.loss_cls: 0.3787  decode.d1.loss_mask: 0.3049  decode.d1.loss_dice: 0.2922  decode.d2.loss_cls: 0.4031  decode.d2.loss_mask: 0.3230  decode.d2.loss_dice: 0.3008  decode.d3.loss_cls: 0.3096  decode.d3.loss_mask: 0.3599  decode.d3.loss_dice: 0.2835  decode.d4.loss_cls: 0.2660  decode.d4.loss_mask: 0.3546  decode.d4.loss_dice: 0.3013  decode.d5.loss_cls: 0.2821  decode.d5.loss_mask: 0.3224  decode.d5.loss_dice: 0.2997  decode.d6.loss_cls: 0.2671  decode.d6.loss_mask: 0.3207  decode.d6.loss_dice: 0.3042  decode.d7.loss_cls: 0.2803  decode.d7.loss_mask: 0.3198  decode.d7.loss_dice: 0.2974  decode.d8.loss_cls: 0.3181  decode.d8.loss_mask: 0.4239  decode.d8.loss_dice: 0.3061
09/30 10:47:57 - mmengine - INFO - Iter(train) [ 14550/320000]  base_lr: 9.5899e-05 lr: 9.5899e-06  eta: 1 day, 12:42:00  time: 0.4325  data_time: 0.0089  memory: 5161  grad_norm: 120.6302  loss: 6.8152  decode.loss_cls: 0.1288  decode.loss_mask: 0.2912  decode.loss_dice: 0.2599  decode.d0.loss_cls: 0.8293  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.2183  decode.d1.loss_cls: 0.1289  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.1213  decode.d2.loss_mask: 0.2300  decode.d2.loss_dice: 0.2272  decode.d3.loss_cls: 0.1462  decode.d3.loss_mask: 0.2237  decode.d3.loss_dice: 0.2226  decode.d4.loss_cls: 0.1272  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.2323  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.2253  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.1343  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2482  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.2643  decode.d7.loss_dice: 0.2495  decode.d8.loss_cls: 0.1051  decode.d8.loss_mask: 0.3207  decode.d8.loss_dice: 0.2531
09/30 10:48:18 - mmengine - INFO - Iter(train) [ 14600/320000]  base_lr: 9.5884e-05 lr: 9.5884e-06  eta: 1 day, 12:41:38  time: 0.4321  data_time: 0.0088  memory: 5147  grad_norm: 383.1806  loss: 10.4865  decode.loss_cls: 0.2426  decode.loss_mask: 0.3432  decode.loss_dice: 0.3117  decode.d0.loss_cls: 1.0049  decode.d0.loss_mask: 0.3546  decode.d0.loss_dice: 0.3470  decode.d1.loss_cls: 0.4201  decode.d1.loss_mask: 0.3320  decode.d1.loss_dice: 0.3300  decode.d2.loss_cls: 0.3036  decode.d2.loss_mask: 0.3644  decode.d2.loss_dice: 0.3438  decode.d3.loss_cls: 0.3371  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.3114  decode.d4.loss_cls: 0.2831  decode.d4.loss_mask: 0.3440  decode.d4.loss_dice: 0.3234  decode.d5.loss_cls: 0.3507  decode.d5.loss_mask: 0.3294  decode.d5.loss_dice: 0.3299  decode.d6.loss_cls: 0.3051  decode.d6.loss_mask: 0.3401  decode.d6.loss_dice: 0.3344  decode.d7.loss_cls: 0.2817  decode.d7.loss_mask: 0.3249  decode.d7.loss_dice: 0.3435  decode.d8.loss_cls: 0.2089  decode.d8.loss_mask: 0.3432  decode.d8.loss_dice: 0.3449
09/30 10:48:40 - mmengine - INFO - Iter(train) [ 14650/320000]  base_lr: 9.5870e-05 lr: 9.5870e-06  eta: 1 day, 12:41:16  time: 0.4331  data_time: 0.0088  memory: 5160  grad_norm: 58.5514  loss: 7.6426  decode.loss_cls: 0.1795  decode.loss_mask: 0.2543  decode.loss_dice: 0.2345  decode.d0.loss_cls: 0.9927  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.2451  decode.d1.loss_cls: 0.2766  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2312  decode.d2.loss_cls: 0.2194  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2334  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 0.2486  decode.d3.loss_dice: 0.2223  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.2205  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.2288  decode.d6.loss_cls: 0.1885  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.2204  decode.d7.loss_cls: 0.1668  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.2219  decode.d8.loss_cls: 0.1665  decode.d8.loss_mask: 0.2531  decode.d8.loss_dice: 0.2253
09/30 10:49:01 - mmengine - INFO - Iter(train) [ 14700/320000]  base_lr: 9.5856e-05 lr: 9.5856e-06  eta: 1 day, 12:40:55  time: 0.4322  data_time: 0.0088  memory: 5161  grad_norm: 33.5989  loss: 6.1202  decode.loss_cls: 0.1272  decode.loss_mask: 0.2193  decode.loss_dice: 0.1815  decode.d0.loss_cls: 0.8270  decode.d0.loss_mask: 0.2281  decode.d0.loss_dice: 0.1873  decode.d1.loss_cls: 0.1485  decode.d1.loss_mask: 0.2239  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.1083  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.1816  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.1857  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.1869  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.1900  decode.d6.loss_cls: 0.1332  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.1890  decode.d7.loss_cls: 0.1297  decode.d7.loss_mask: 0.2207  decode.d7.loss_dice: 0.1856  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.1985
09/30 10:49:23 - mmengine - INFO - Iter(train) [ 14750/320000]  base_lr: 9.5842e-05 lr: 9.5842e-06  eta: 1 day, 12:40:33  time: 0.4329  data_time: 0.0089  memory: 5180  grad_norm: 89.2543  loss: 9.7552  decode.loss_cls: 0.3566  decode.loss_mask: 0.3103  decode.loss_dice: 0.2833  decode.d0.loss_cls: 0.9429  decode.d0.loss_mask: 0.3123  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.3911  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.2974  decode.d2.loss_cls: 0.3193  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.3037  decode.d3.loss_cls: 0.2122  decode.d3.loss_mask: 0.3120  decode.d3.loss_dice: 0.2880  decode.d4.loss_cls: 0.2827  decode.d4.loss_mask: 0.3153  decode.d4.loss_dice: 0.2932  decode.d5.loss_cls: 0.2868  decode.d5.loss_mask: 0.3092  decode.d5.loss_dice: 0.2855  decode.d6.loss_cls: 0.2870  decode.d6.loss_mask: 0.3212  decode.d6.loss_dice: 0.2797  decode.d7.loss_cls: 0.2666  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.2937  decode.d8.loss_cls: 0.3429  decode.d8.loss_mask: 0.3213  decode.d8.loss_dice: 0.2877
09/30 10:49:45 - mmengine - INFO - Iter(train) [ 14800/320000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 1 day, 12:40:11  time: 0.4309  data_time: 0.0087  memory: 5179  grad_norm: 91.1090  loss: 7.9676  decode.loss_cls: 0.1948  decode.loss_mask: 0.2389  decode.loss_dice: 0.2895  decode.d0.loss_cls: 0.8459  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.3010  decode.d1.loss_cls: 0.2712  decode.d1.loss_mask: 0.2328  decode.d1.loss_dice: 0.2877  decode.d2.loss_cls: 0.2203  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.2962  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.3083  decode.d4.loss_cls: 0.2199  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.2092  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.3080  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.1812  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.2885  decode.d8.loss_cls: 0.2193  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.2843
09/30 10:50:06 - mmengine - INFO - Iter(train) [ 14850/320000]  base_lr: 9.5814e-05 lr: 9.5814e-06  eta: 1 day, 12:39:48  time: 0.4315  data_time: 0.0087  memory: 5147  grad_norm: 67.0125  loss: 6.9156  decode.loss_cls: 0.1611  decode.loss_mask: 0.2320  decode.loss_dice: 0.2136  decode.d0.loss_cls: 0.9388  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.1951  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.1626  decode.d2.loss_mask: 0.2310  decode.d2.loss_dice: 0.2215  decode.d3.loss_cls: 0.1671  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.1628  decode.d4.loss_mask: 0.2290  decode.d4.loss_dice: 0.2090  decode.d5.loss_cls: 0.1507  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.2054  decode.d6.loss_cls: 0.1644  decode.d6.loss_mask: 0.2314  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.1476  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.2174
09/30 10:50:28 - mmengine - INFO - Iter(train) [ 14900/320000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 1 day, 12:39:27  time: 0.4318  data_time: 0.0089  memory: 5161  grad_norm: 41.7052  loss: 7.1744  decode.loss_cls: 0.1136  decode.loss_mask: 0.2040  decode.loss_dice: 0.2633  decode.d0.loss_cls: 1.0295  decode.d0.loss_mask: 0.2072  decode.d0.loss_dice: 0.2557  decode.d1.loss_cls: 0.2849  decode.d1.loss_mask: 0.2050  decode.d1.loss_dice: 0.2200  decode.d2.loss_cls: 0.2505  decode.d2.loss_mask: 0.2040  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1496  decode.d3.loss_mask: 0.2058  decode.d3.loss_dice: 0.2511  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 0.2043  decode.d4.loss_dice: 0.2503  decode.d5.loss_cls: 0.2148  decode.d5.loss_mask: 0.2057  decode.d5.loss_dice: 0.2444  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 0.2032  decode.d6.loss_dice: 0.2471  decode.d7.loss_cls: 0.2290  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.2329  decode.d8.loss_cls: 0.1682  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.2471
09/30 10:50:49 - mmengine - INFO - Iter(train) [ 14950/320000]  base_lr: 9.5786e-05 lr: 9.5786e-06  eta: 1 day, 12:39:04  time: 0.4318  data_time: 0.0089  memory: 5161  grad_norm: 44.3418  loss: 6.5624  decode.loss_cls: 0.1402  decode.loss_mask: 0.2419  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.7825  decode.d0.loss_mask: 0.2505  decode.d0.loss_dice: 0.2129  decode.d1.loss_cls: 0.1487  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.1937  decode.d2.loss_cls: 0.1769  decode.d2.loss_mask: 0.2427  decode.d2.loss_dice: 0.1946  decode.d3.loss_cls: 0.1809  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.1971  decode.d4.loss_cls: 0.1711  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.1255  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.1444  decode.d7.loss_mask: 0.2431  decode.d7.loss_dice: 0.1963  decode.d8.loss_cls: 0.1458  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.1997
09/30 10:51:11 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:51:11 - mmengine - INFO - Iter(train) [ 15000/320000]  base_lr: 9.5771e-05 lr: 9.5771e-06  eta: 1 day, 12:38:42  time: 0.4324  data_time: 0.0086  memory: 5180  grad_norm: 141.8387  loss: 11.8582  decode.loss_cls: 0.3343  decode.loss_mask: 0.3913  decode.loss_dice: 0.2915  decode.d0.loss_cls: 1.0512  decode.d0.loss_mask: 0.3037  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.4138  decode.d1.loss_mask: 0.4077  decode.d1.loss_dice: 0.3170  decode.d2.loss_cls: 0.4194  decode.d2.loss_mask: 0.3455  decode.d2.loss_dice: 0.2666  decode.d3.loss_cls: 0.4171  decode.d3.loss_mask: 0.3513  decode.d3.loss_dice: 0.3112  decode.d4.loss_cls: 0.3824  decode.d4.loss_mask: 0.3678  decode.d4.loss_dice: 0.3134  decode.d5.loss_cls: 0.4097  decode.d5.loss_mask: 0.5548  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.3989  decode.d6.loss_mask: 0.5070  decode.d6.loss_dice: 0.3464  decode.d7.loss_cls: 0.3790  decode.d7.loss_mask: 0.4362  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.3609  decode.d8.loss_mask: 0.5711  decode.d8.loss_dice: 0.3386
09/30 10:51:33 - mmengine - INFO - Iter(train) [ 15050/320000]  base_lr: 9.5757e-05 lr: 9.5757e-06  eta: 1 day, 12:38:20  time: 0.4323  data_time: 0.0088  memory: 5180  grad_norm: 354.1036  loss: 10.4699  decode.loss_cls: 0.1158  decode.loss_mask: 0.4533  decode.loss_dice: 0.3518  decode.d0.loss_cls: 0.9012  decode.d0.loss_mask: 0.4714  decode.d0.loss_dice: 0.3667  decode.d1.loss_cls: 0.1741  decode.d1.loss_mask: 0.4559  decode.d1.loss_dice: 0.3576  decode.d2.loss_cls: 0.1583  decode.d2.loss_mask: 0.4431  decode.d2.loss_dice: 0.3577  decode.d3.loss_cls: 0.1583  decode.d3.loss_mask: 0.4378  decode.d3.loss_dice: 0.3316  decode.d4.loss_cls: 0.2075  decode.d4.loss_mask: 0.4448  decode.d4.loss_dice: 0.3634  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.4392  decode.d5.loss_dice: 0.3535  decode.d6.loss_cls: 0.1904  decode.d6.loss_mask: 0.4424  decode.d6.loss_dice: 0.3485  decode.d7.loss_cls: 0.1685  decode.d7.loss_mask: 0.4568  decode.d7.loss_dice: 0.3511  decode.d8.loss_cls: 0.1494  decode.d8.loss_mask: 0.4563  decode.d8.loss_dice: 0.3568
09/30 10:51:54 - mmengine - INFO - Iter(train) [ 15100/320000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 1 day, 12:37:58  time: 0.4336  data_time: 0.0088  memory: 5180  grad_norm: 64.1931  loss: 8.0204  decode.loss_cls: 0.1649  decode.loss_mask: 0.2154  decode.loss_dice: 0.3380  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.3654  decode.d1.loss_cls: 0.3116  decode.d1.loss_mask: 0.2173  decode.d1.loss_dice: 0.3283  decode.d2.loss_cls: 0.2361  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.3102  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.3577  decode.d4.loss_cls: 0.1593  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.3195  decode.d5.loss_cls: 0.1394  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.2948  decode.d6.loss_cls: 0.1438  decode.d6.loss_mask: 0.2178  decode.d6.loss_dice: 0.3220  decode.d7.loss_cls: 0.1509  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.3403  decode.d8.loss_cls: 0.1884  decode.d8.loss_mask: 0.2161  decode.d8.loss_dice: 0.3352
09/30 10:52:16 - mmengine - INFO - Iter(train) [ 15150/320000]  base_lr: 9.5729e-05 lr: 9.5729e-06  eta: 1 day, 12:37:36  time: 0.4328  data_time: 0.0088  memory: 5132  grad_norm: 89.1128  loss: 9.8046  decode.loss_cls: 0.2668  decode.loss_mask: 0.3299  decode.loss_dice: 0.3287  decode.d0.loss_cls: 0.9539  decode.d0.loss_mask: 0.3602  decode.d0.loss_dice: 0.3634  decode.d1.loss_cls: 0.2108  decode.d1.loss_mask: 0.3323  decode.d1.loss_dice: 0.3380  decode.d2.loss_cls: 0.1903  decode.d2.loss_mask: 0.3335  decode.d2.loss_dice: 0.3483  decode.d3.loss_cls: 0.2155  decode.d3.loss_mask: 0.3236  decode.d3.loss_dice: 0.3275  decode.d4.loss_cls: 0.2359  decode.d4.loss_mask: 0.3266  decode.d4.loss_dice: 0.3242  decode.d5.loss_cls: 0.2420  decode.d5.loss_mask: 0.3216  decode.d5.loss_dice: 0.3278  decode.d6.loss_cls: 0.2384  decode.d6.loss_mask: 0.3356  decode.d6.loss_dice: 0.3568  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 0.3801  decode.d7.loss_dice: 0.3561  decode.d8.loss_cls: 0.2387  decode.d8.loss_mask: 0.3461  decode.d8.loss_dice: 0.3548
09/30 10:52:37 - mmengine - INFO - Iter(train) [ 15200/320000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 1 day, 12:37:14  time: 0.4327  data_time: 0.0087  memory: 5180  grad_norm: 59.9281  loss: 8.1949  decode.loss_cls: 0.2214  decode.loss_mask: 0.2960  decode.loss_dice: 0.2016  decode.d0.loss_cls: 0.9482  decode.d0.loss_mask: 0.3070  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.2569  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.2896  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.2031  decode.d3.loss_cls: 0.2696  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.2222  decode.d4.loss_cls: 0.2351  decode.d4.loss_mask: 0.2984  decode.d4.loss_dice: 0.2043  decode.d5.loss_cls: 0.2305  decode.d5.loss_mask: 0.2996  decode.d5.loss_dice: 0.2005  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 0.3011  decode.d6.loss_dice: 0.2088  decode.d7.loss_cls: 0.2261  decode.d7.loss_mask: 0.2994  decode.d7.loss_dice: 0.2049  decode.d8.loss_cls: 0.2481  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.2051
09/30 10:52:59 - mmengine - INFO - Iter(train) [ 15250/320000]  base_lr: 9.5701e-05 lr: 9.5701e-06  eta: 1 day, 12:36:52  time: 0.4329  data_time: 0.0088  memory: 5147  grad_norm: 40.6881  loss: 6.4465  decode.loss_cls: 0.0618  decode.loss_mask: 0.2610  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.9798  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.1857  decode.d1.loss_cls: 0.1848  decode.d1.loss_mask: 0.2586  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.1531  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.1831  decode.d3.loss_cls: 0.1154  decode.d3.loss_mask: 0.2552  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.1118  decode.d4.loss_mask: 0.2544  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.1094  decode.d5.loss_mask: 0.2553  decode.d5.loss_dice: 0.1944  decode.d6.loss_cls: 0.1025  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.0997  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.1878
09/30 10:53:21 - mmengine - INFO - Iter(train) [ 15300/320000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 1 day, 12:36:30  time: 0.4311  data_time: 0.0088  memory: 5180  grad_norm: 61.8203  loss: 7.5283  decode.loss_cls: 0.0958  decode.loss_mask: 0.3110  decode.loss_dice: 0.2546  decode.d0.loss_cls: 0.9690  decode.d0.loss_mask: 0.3108  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.1247  decode.d1.loss_mask: 0.3060  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.1095  decode.d2.loss_mask: 0.3148  decode.d2.loss_dice: 0.2500  decode.d3.loss_cls: 0.0827  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.2467  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.3189  decode.d4.loss_dice: 0.2673  decode.d5.loss_cls: 0.0827  decode.d5.loss_mask: 0.3133  decode.d5.loss_dice: 0.2634  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.3125  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.0878  decode.d7.loss_mask: 0.3129  decode.d7.loss_dice: 0.2988  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.3070  decode.d8.loss_dice: 0.2483
09/30 10:53:42 - mmengine - INFO - Iter(train) [ 15350/320000]  base_lr: 9.5673e-05 lr: 9.5673e-06  eta: 1 day, 12:36:09  time: 0.4321  data_time: 0.0091  memory: 5161  grad_norm: 73.0743  loss: 9.0881  decode.loss_cls: 0.1699  decode.loss_mask: 0.3559  decode.loss_dice: 0.2833  decode.d0.loss_cls: 1.0209  decode.d0.loss_mask: 0.3426  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.2350  decode.d1.loss_mask: 0.3392  decode.d1.loss_dice: 0.2736  decode.d2.loss_cls: 0.1995  decode.d2.loss_mask: 0.3479  decode.d2.loss_dice: 0.2976  decode.d3.loss_cls: 0.2016  decode.d3.loss_mask: 0.3400  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.2246  decode.d4.loss_mask: 0.3335  decode.d4.loss_dice: 0.2714  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.3495  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.2259  decode.d6.loss_mask: 0.3452  decode.d6.loss_dice: 0.2842  decode.d7.loss_cls: 0.2069  decode.d7.loss_mask: 0.3472  decode.d7.loss_dice: 0.2785  decode.d8.loss_cls: 0.1486  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.2897
09/30 10:54:04 - mmengine - INFO - Iter(train) [ 15400/320000]  base_lr: 9.5658e-05 lr: 9.5658e-06  eta: 1 day, 12:35:47  time: 0.4321  data_time: 0.0089  memory: 5161  grad_norm: 171.5274  loss: 9.2247  decode.loss_cls: 0.1789  decode.loss_mask: 0.3427  decode.loss_dice: 0.3028  decode.d0.loss_cls: 0.9837  decode.d0.loss_mask: 0.3627  decode.d0.loss_dice: 0.3194  decode.d1.loss_cls: 0.2788  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.3047  decode.d2.loss_cls: 0.2374  decode.d2.loss_mask: 0.3426  decode.d2.loss_dice: 0.3022  decode.d3.loss_cls: 0.2226  decode.d3.loss_mask: 0.3408  decode.d3.loss_dice: 0.2903  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.3445  decode.d4.loss_dice: 0.2868  decode.d5.loss_cls: 0.1873  decode.d5.loss_mask: 0.3395  decode.d5.loss_dice: 0.2803  decode.d6.loss_cls: 0.1928  decode.d6.loss_mask: 0.3451  decode.d6.loss_dice: 0.2805  decode.d7.loss_cls: 0.1985  decode.d7.loss_mask: 0.3413  decode.d7.loss_dice: 0.2812  decode.d8.loss_cls: 0.1984  decode.d8.loss_mask: 0.3388  decode.d8.loss_dice: 0.2776
09/30 10:54:26 - mmengine - INFO - Iter(train) [ 15450/320000]  base_lr: 9.5644e-05 lr: 9.5644e-06  eta: 1 day, 12:35:25  time: 0.4325  data_time: 0.0091  memory: 5161  grad_norm: 597.1580  loss: 11.0859  decode.loss_cls: 0.4548  decode.loss_mask: 0.3186  decode.loss_dice: 0.2936  decode.d0.loss_cls: 0.9297  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.3068  decode.d1.loss_cls: 0.4996  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.2823  decode.d2.loss_cls: 0.4171  decode.d2.loss_mask: 0.3303  decode.d2.loss_dice: 0.3226  decode.d3.loss_cls: 0.4118  decode.d3.loss_mask: 0.3085  decode.d3.loss_dice: 0.2918  decode.d4.loss_cls: 0.4259  decode.d4.loss_mask: 0.4424  decode.d4.loss_dice: 0.3197  decode.d5.loss_cls: 0.4078  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.3211  decode.d6.loss_cls: 0.4007  decode.d6.loss_mask: 0.3106  decode.d6.loss_dice: 0.2873  decode.d7.loss_cls: 0.4530  decode.d7.loss_mask: 0.3194  decode.d7.loss_dice: 0.2985  decode.d8.loss_cls: 0.4099  decode.d8.loss_mask: 0.3098  decode.d8.loss_dice: 0.2795
09/30 10:54:47 - mmengine - INFO - Iter(train) [ 15500/320000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 1 day, 12:35:04  time: 0.4332  data_time: 0.0092  memory: 5180  grad_norm: 36.6529  loss: 5.7744  decode.loss_cls: 0.0450  decode.loss_mask: 0.2192  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.9386  decode.d0.loss_mask: 0.2215  decode.d0.loss_dice: 0.2270  decode.d1.loss_cls: 0.1115  decode.d1.loss_mask: 0.2165  decode.d1.loss_dice: 0.2174  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.2187  decode.d2.loss_dice: 0.2063  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.2163  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.0425  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.2209  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.2199  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.2207  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.2186  decode.d8.loss_dice: 0.2155
09/30 10:55:09 - mmengine - INFO - Iter(train) [ 15550/320000]  base_lr: 9.5616e-05 lr: 9.5616e-06  eta: 1 day, 12:34:42  time: 0.4327  data_time: 0.0089  memory: 5160  grad_norm: 79.9881  loss: 9.9927  decode.loss_cls: 0.3256  decode.loss_mask: 0.2800  decode.loss_dice: 0.3164  decode.d0.loss_cls: 1.1382  decode.d0.loss_mask: 0.2857  decode.d0.loss_dice: 0.3472  decode.d1.loss_cls: 0.3577  decode.d1.loss_mask: 0.2781  decode.d1.loss_dice: 0.3177  decode.d2.loss_cls: 0.3051  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.3266  decode.d3.loss_cls: 0.2771  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.3329  decode.d4.loss_cls: 0.2469  decode.d4.loss_mask: 0.2759  decode.d4.loss_dice: 0.3355  decode.d5.loss_cls: 0.3037  decode.d5.loss_mask: 0.2717  decode.d5.loss_dice: 0.3107  decode.d6.loss_cls: 0.3147  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.3028  decode.d7.loss_cls: 0.3156  decode.d7.loss_mask: 0.2909  decode.d7.loss_dice: 0.3194  decode.d8.loss_cls: 0.3159  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.3161
09/30 10:55:30 - mmengine - INFO - Iter(train) [ 15600/320000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 1 day, 12:34:20  time: 0.4323  data_time: 0.0089  memory: 5147  grad_norm: 91.9561  loss: 7.2456  decode.loss_cls: 0.1421  decode.loss_mask: 0.2540  decode.loss_dice: 0.2316  decode.d0.loss_cls: 0.9965  decode.d0.loss_mask: 0.2508  decode.d0.loss_dice: 0.2235  decode.d1.loss_cls: 0.2192  decode.d1.loss_mask: 0.2733  decode.d1.loss_dice: 0.2333  decode.d2.loss_cls: 0.1736  decode.d2.loss_mask: 0.2701  decode.d2.loss_dice: 0.1988  decode.d3.loss_cls: 0.1741  decode.d3.loss_mask: 0.2620  decode.d3.loss_dice: 0.2257  decode.d4.loss_cls: 0.1616  decode.d4.loss_mask: 0.2584  decode.d4.loss_dice: 0.2047  decode.d5.loss_cls: 0.1558  decode.d5.loss_mask: 0.2553  decode.d5.loss_dice: 0.2280  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.1578  decode.d8.loss_mask: 0.2477  decode.d8.loss_dice: 0.2225
09/30 10:55:52 - mmengine - INFO - Iter(train) [ 15650/320000]  base_lr: 9.5588e-05 lr: 9.5588e-06  eta: 1 day, 12:33:59  time: 0.4348  data_time: 0.0090  memory: 5160  grad_norm: 87.4146  loss: 9.8992  decode.loss_cls: 0.2642  decode.loss_mask: 0.3086  decode.loss_dice: 0.3139  decode.d0.loss_cls: 1.0125  decode.d0.loss_mask: 0.3078  decode.d0.loss_dice: 0.3587  decode.d1.loss_cls: 0.3555  decode.d1.loss_mask: 0.3031  decode.d1.loss_dice: 0.3120  decode.d2.loss_cls: 0.3590  decode.d2.loss_mask: 0.3048  decode.d2.loss_dice: 0.3102  decode.d3.loss_cls: 0.2735  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.3132  decode.d4.loss_cls: 0.2933  decode.d4.loss_mask: 0.3099  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.3127  decode.d5.loss_mask: 0.3159  decode.d5.loss_dice: 0.3150  decode.d6.loss_cls: 0.2986  decode.d6.loss_mask: 0.3030  decode.d6.loss_dice: 0.3170  decode.d7.loss_cls: 0.2370  decode.d7.loss_mask: 0.3001  decode.d7.loss_dice: 0.3113  decode.d8.loss_cls: 0.2552  decode.d8.loss_mask: 0.3056  decode.d8.loss_dice: 0.3121
09/30 10:56:14 - mmengine - INFO - Iter(train) [ 15700/320000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 1 day, 12:33:39  time: 0.4341  data_time: 0.0087  memory: 5160  grad_norm: 343.3165  loss: 10.2905  decode.loss_cls: 0.1173  decode.loss_mask: 0.4420  decode.loss_dice: 0.3337  decode.d0.loss_cls: 1.1036  decode.d0.loss_mask: 0.3829  decode.d0.loss_dice: 0.3628  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 0.3558  decode.d1.loss_dice: 0.3391  decode.d2.loss_cls: 0.2387  decode.d2.loss_mask: 0.3857  decode.d2.loss_dice: 0.3473  decode.d3.loss_cls: 0.1315  decode.d3.loss_mask: 0.4560  decode.d3.loss_dice: 0.3499  decode.d4.loss_cls: 0.2066  decode.d4.loss_mask: 0.3920  decode.d4.loss_dice: 0.3457  decode.d5.loss_cls: 0.2136  decode.d5.loss_mask: 0.3676  decode.d5.loss_dice: 0.3383  decode.d6.loss_cls: 0.1183  decode.d6.loss_mask: 0.4516  decode.d6.loss_dice: 0.3472  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.4848  decode.d7.loss_dice: 0.3502  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 0.4352  decode.d8.loss_dice: 0.3469
09/30 10:56:36 - mmengine - INFO - Iter(train) [ 15750/320000]  base_lr: 9.5559e-05 lr: 9.5559e-06  eta: 1 day, 12:33:18  time: 0.4317  data_time: 0.0091  memory: 5146  grad_norm: 39.8100  loss: 7.7841  decode.loss_cls: 0.1110  decode.loss_mask: 0.3568  decode.loss_dice: 0.2187  decode.d0.loss_cls: 1.0861  decode.d0.loss_mask: 0.3353  decode.d0.loss_dice: 0.2157  decode.d1.loss_cls: 0.1314  decode.d1.loss_mask: 0.3321  decode.d1.loss_dice: 0.2240  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.3236  decode.d2.loss_dice: 0.2129  decode.d3.loss_cls: 0.1010  decode.d3.loss_mask: 0.3291  decode.d3.loss_dice: 0.2161  decode.d4.loss_cls: 0.1102  decode.d4.loss_mask: 0.3499  decode.d4.loss_dice: 0.2133  decode.d5.loss_cls: 0.1103  decode.d5.loss_mask: 0.3673  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.1294  decode.d6.loss_mask: 0.3700  decode.d6.loss_dice: 0.2152  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 0.3755  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.1029  decode.d8.loss_mask: 0.3295  decode.d8.loss_dice: 0.2185
09/30 10:56:57 - mmengine - INFO - Iter(train) [ 15800/320000]  base_lr: 9.5545e-05 lr: 9.5545e-06  eta: 1 day, 12:32:58  time: 0.4343  data_time: 0.0089  memory: 5180  grad_norm: 83.7144  loss: 7.3125  decode.loss_cls: 0.1309  decode.loss_mask: 0.3322  decode.loss_dice: 0.1898  decode.d0.loss_cls: 0.9283  decode.d0.loss_mask: 0.3393  decode.d0.loss_dice: 0.1956  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.3354  decode.d1.loss_dice: 0.1881  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.3381  decode.d2.loss_dice: 0.1895  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.3294  decode.d3.loss_dice: 0.1892  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 0.3348  decode.d4.loss_dice: 0.1918  decode.d5.loss_cls: 0.1441  decode.d5.loss_mask: 0.3354  decode.d5.loss_dice: 0.1922  decode.d6.loss_cls: 0.1256  decode.d6.loss_mask: 0.3306  decode.d6.loss_dice: 0.1940  decode.d7.loss_cls: 0.1344  decode.d7.loss_mask: 0.3339  decode.d7.loss_dice: 0.1896  decode.d8.loss_cls: 0.1479  decode.d8.loss_mask: 0.3399  decode.d8.loss_dice: 0.1924
09/30 10:57:19 - mmengine - INFO - Iter(train) [ 15850/320000]  base_lr: 9.5531e-05 lr: 9.5531e-06  eta: 1 day, 12:32:38  time: 0.4342  data_time: 0.0087  memory: 5180  grad_norm: 158.3987  loss: 9.3867  decode.loss_cls: 0.2058  decode.loss_mask: 0.3903  decode.loss_dice: 0.2881  decode.d0.loss_cls: 1.1215  decode.d0.loss_mask: 0.3019  decode.d0.loss_dice: 0.2952  decode.d1.loss_cls: 0.2358  decode.d1.loss_mask: 0.3177  decode.d1.loss_dice: 0.2783  decode.d2.loss_cls: 0.1913  decode.d2.loss_mask: 0.3181  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.2102  decode.d3.loss_mask: 0.3254  decode.d3.loss_dice: 0.2874  decode.d4.loss_cls: 0.2493  decode.d4.loss_mask: 0.3059  decode.d4.loss_dice: 0.2680  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.3414  decode.d5.loss_dice: 0.2905  decode.d6.loss_cls: 0.2151  decode.d6.loss_mask: 0.3957  decode.d6.loss_dice: 0.2991  decode.d7.loss_cls: 0.2820  decode.d7.loss_mask: 0.3563  decode.d7.loss_dice: 0.2876  decode.d8.loss_cls: 0.1688  decode.d8.loss_mask: 0.3798  decode.d8.loss_dice: 0.2969
09/30 10:57:41 - mmengine - INFO - Iter(train) [ 15900/320000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 1 day, 12:32:19  time: 0.4344  data_time: 0.0088  memory: 5160  grad_norm: 164.6363  loss: 9.0583  decode.loss_cls: 0.2416  decode.loss_mask: 0.2837  decode.loss_dice: 0.2958  decode.d0.loss_cls: 1.0850  decode.d0.loss_mask: 0.2884  decode.d0.loss_dice: 0.2772  decode.d1.loss_cls: 0.3576  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.2649  decode.d2.loss_cls: 0.2816  decode.d2.loss_mask: 0.2497  decode.d2.loss_dice: 0.2400  decode.d3.loss_cls: 0.2701  decode.d3.loss_mask: 0.2759  decode.d3.loss_dice: 0.2424  decode.d4.loss_cls: 0.2949  decode.d4.loss_mask: 0.3881  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.2537  decode.d5.loss_mask: 0.3015  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.2645  decode.d6.loss_mask: 0.2504  decode.d6.loss_dice: 0.2239  decode.d7.loss_cls: 0.2434  decode.d7.loss_mask: 0.2821  decode.d7.loss_dice: 0.2835  decode.d8.loss_cls: 0.1991  decode.d8.loss_mask: 0.3439  decode.d8.loss_dice: 0.2862
09/30 10:58:02 - mmengine - INFO - Iter(train) [ 15950/320000]  base_lr: 9.5503e-05 lr: 9.5503e-06  eta: 1 day, 12:31:58  time: 0.4343  data_time: 0.0088  memory: 5160  grad_norm: 252.6723  loss: 9.8706  decode.loss_cls: 0.1915  decode.loss_mask: 0.3488  decode.loss_dice: 0.3000  decode.d0.loss_cls: 1.1841  decode.d0.loss_mask: 0.3634  decode.d0.loss_dice: 0.3227  decode.d1.loss_cls: 0.3606  decode.d1.loss_mask: 0.3393  decode.d1.loss_dice: 0.2697  decode.d2.loss_cls: 0.2416  decode.d2.loss_mask: 0.3374  decode.d2.loss_dice: 0.2965  decode.d3.loss_cls: 0.2076  decode.d3.loss_mask: 0.3632  decode.d3.loss_dice: 0.3078  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.3854  decode.d4.loss_dice: 0.3166  decode.d5.loss_cls: 0.2464  decode.d5.loss_mask: 0.3655  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.2229  decode.d6.loss_mask: 0.3655  decode.d6.loss_dice: 0.3015  decode.d7.loss_cls: 0.2032  decode.d7.loss_mask: 0.3600  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.2040  decode.d8.loss_mask: 0.3540  decode.d8.loss_dice: 0.3047
09/30 10:58:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 10:58:24 - mmengine - INFO - Iter(train) [ 16000/320000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 1 day, 12:31:38  time: 0.4348  data_time: 0.0090  memory: 5161  grad_norm: 97.7488  loss: 7.9432  decode.loss_cls: 0.1322  decode.loss_mask: 0.2713  decode.loss_dice: 0.2602  decode.d0.loss_cls: 0.9267  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.2847  decode.d1.loss_cls: 0.2892  decode.d1.loss_mask: 0.3071  decode.d1.loss_dice: 0.2770  decode.d2.loss_cls: 0.3145  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.2714  decode.d3.loss_cls: 0.2211  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.2617  decode.d4.loss_cls: 0.1625  decode.d4.loss_mask: 0.2744  decode.d4.loss_dice: 0.2542  decode.d5.loss_cls: 0.1208  decode.d5.loss_mask: 0.2770  decode.d5.loss_dice: 0.2566  decode.d6.loss_cls: 0.1254  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.2602  decode.d7.loss_cls: 0.1008  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.2520  decode.d8.loss_cls: 0.1193  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.2605
09/30 10:58:46 - mmengine - INFO - Iter(train) [ 16050/320000]  base_lr: 9.5475e-05 lr: 9.5475e-06  eta: 1 day, 12:31:19  time: 0.4342  data_time: 0.0090  memory: 5180  grad_norm: 145.0446  loss: 9.3304  decode.loss_cls: 0.1605  decode.loss_mask: 0.3480  decode.loss_dice: 0.2717  decode.d0.loss_cls: 1.1575  decode.d0.loss_mask: 0.3598  decode.d0.loss_dice: 0.3158  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.3457  decode.d1.loss_dice: 0.2858  decode.d2.loss_cls: 0.2050  decode.d2.loss_mask: 0.3542  decode.d2.loss_dice: 0.2806  decode.d3.loss_cls: 0.2610  decode.d3.loss_mask: 0.3462  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.1901  decode.d4.loss_mask: 0.3581  decode.d4.loss_dice: 0.2790  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.3512  decode.d5.loss_dice: 0.2758  decode.d6.loss_cls: 0.1676  decode.d6.loss_mask: 0.3482  decode.d6.loss_dice: 0.2825  decode.d7.loss_cls: 0.1911  decode.d7.loss_mask: 0.3528  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.2076  decode.d8.loss_mask: 0.3522  decode.d8.loss_dice: 0.2657
09/30 10:59:08 - mmengine - INFO - Iter(train) [ 16100/320000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 1 day, 12:31:02  time: 0.4524  data_time: 0.0089  memory: 5180  grad_norm: 138.1879  loss: 7.8022  decode.loss_cls: 0.2004  decode.loss_mask: 0.2518  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.9388  decode.d0.loss_mask: 0.2549  decode.d0.loss_dice: 0.2547  decode.d1.loss_cls: 0.2480  decode.d1.loss_mask: 0.2510  decode.d1.loss_dice: 0.2337  decode.d2.loss_cls: 0.2100  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.2236  decode.d3.loss_cls: 0.2333  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2410  decode.d4.loss_cls: 0.2352  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.2292  decode.d5.loss_cls: 0.2524  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.2271  decode.d6.loss_cls: 0.1944  decode.d6.loss_mask: 0.2555  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.2254  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2286  decode.d8.loss_cls: 0.2242  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.2298
09/30 10:59:29 - mmengine - INFO - Iter(train) [ 16150/320000]  base_lr: 9.5446e-05 lr: 9.5446e-06  eta: 1 day, 12:30:43  time: 0.4338  data_time: 0.0086  memory: 5180  grad_norm: 97.7254  loss: 8.7150  decode.loss_cls: 0.1884  decode.loss_mask: 0.3898  decode.loss_dice: 0.3180  decode.d0.loss_cls: 0.9859  decode.d0.loss_mask: 0.3177  decode.d0.loss_dice: 0.2322  decode.d1.loss_cls: 0.2631  decode.d1.loss_mask: 0.2779  decode.d1.loss_dice: 0.2332  decode.d2.loss_cls: 0.1573  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.2280  decode.d4.loss_cls: 0.2634  decode.d4.loss_mask: 0.3528  decode.d4.loss_dice: 0.2443  decode.d5.loss_cls: 0.2902  decode.d5.loss_mask: 0.2795  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.2313  decode.d6.loss_mask: 0.3396  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.2456  decode.d7.loss_mask: 0.3120  decode.d7.loss_dice: 0.2471  decode.d8.loss_cls: 0.1839  decode.d8.loss_mask: 0.3716  decode.d8.loss_dice: 0.2702
09/30 10:59:51 - mmengine - INFO - Iter(train) [ 16200/320000]  base_lr: 9.5432e-05 lr: 9.5432e-06  eta: 1 day, 12:30:21  time: 0.4314  data_time: 0.0086  memory: 5161  grad_norm: 75.3905  loss: 7.2577  decode.loss_cls: 0.1712  decode.loss_mask: 0.2270  decode.loss_dice: 0.2085  decode.d0.loss_cls: 0.9056  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.2916  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.1990  decode.d2.loss_cls: 0.1779  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.2331  decode.d3.loss_cls: 0.1764  decode.d3.loss_mask: 0.2469  decode.d3.loss_dice: 0.2367  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.2150  decode.d5.loss_cls: 0.1753  decode.d5.loss_mask: 0.2788  decode.d5.loss_dice: 0.2321  decode.d6.loss_cls: 0.2209  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.1627  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.2110
09/30 11:00:13 - mmengine - INFO - Iter(train) [ 16250/320000]  base_lr: 9.5418e-05 lr: 9.5418e-06  eta: 1 day, 12:29:59  time: 0.4328  data_time: 0.0090  memory: 5180  grad_norm: 94.6174  loss: 8.7238  decode.loss_cls: 0.1535  decode.loss_mask: 0.2924  decode.loss_dice: 0.3112  decode.d0.loss_cls: 0.9266  decode.d0.loss_mask: 0.3044  decode.d0.loss_dice: 0.2980  decode.d1.loss_cls: 0.2676  decode.d1.loss_mask: 0.2945  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.2084  decode.d2.loss_mask: 0.2946  decode.d2.loss_dice: 0.3055  decode.d3.loss_cls: 0.2421  decode.d3.loss_mask: 0.2979  decode.d3.loss_dice: 0.2925  decode.d4.loss_cls: 0.2093  decode.d4.loss_mask: 0.2933  decode.d4.loss_dice: 0.3085  decode.d5.loss_cls: 0.2315  decode.d5.loss_mask: 0.2899  decode.d5.loss_dice: 0.2991  decode.d6.loss_cls: 0.1690  decode.d6.loss_mask: 0.2931  decode.d6.loss_dice: 0.3117  decode.d7.loss_cls: 0.1690  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.3205  decode.d8.loss_cls: 0.1932  decode.d8.loss_mask: 0.2879  decode.d8.loss_dice: 0.3013
09/30 11:00:34 - mmengine - INFO - Iter(train) [ 16300/320000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 1 day, 12:29:37  time: 0.4327  data_time: 0.0088  memory: 5180  grad_norm: 363.9782  loss: 7.3698  decode.loss_cls: 0.0957  decode.loss_mask: 0.3732  decode.loss_dice: 0.2130  decode.d0.loss_cls: 0.9402  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.2070  decode.d1.loss_mask: 0.2880  decode.d1.loss_dice: 0.2112  decode.d2.loss_cls: 0.1272  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.2291  decode.d3.loss_cls: 0.1179  decode.d3.loss_mask: 0.2940  decode.d3.loss_dice: 0.2207  decode.d4.loss_cls: 0.1097  decode.d4.loss_mask: 0.3114  decode.d4.loss_dice: 0.2173  decode.d5.loss_cls: 0.1258  decode.d5.loss_mask: 0.3227  decode.d5.loss_dice: 0.2160  decode.d6.loss_cls: 0.1243  decode.d6.loss_mask: 0.3446  decode.d6.loss_dice: 0.2201  decode.d7.loss_cls: 0.1051  decode.d7.loss_mask: 0.3270  decode.d7.loss_dice: 0.2191  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.3172  decode.d8.loss_dice: 0.2241
09/30 11:00:56 - mmengine - INFO - Iter(train) [ 16350/320000]  base_lr: 9.5390e-05 lr: 9.5390e-06  eta: 1 day, 12:29:17  time: 0.4332  data_time: 0.0086  memory: 5161  grad_norm: 81.1350  loss: 7.0097  decode.loss_cls: 0.1898  decode.loss_mask: 0.2179  decode.loss_dice: 0.1962  decode.d0.loss_cls: 1.0649  decode.d0.loss_mask: 0.2271  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.1675  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.1901  decode.d2.loss_cls: 0.1973  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.1753  decode.d3.loss_mask: 0.2237  decode.d3.loss_dice: 0.2191  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.2163  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.1856  decode.d5.loss_mask: 0.2176  decode.d5.loss_dice: 0.2005  decode.d6.loss_cls: 0.2188  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.1816  decode.d7.loss_cls: 0.2078  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.1905  decode.d8.loss_cls: 0.2174  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2024
09/30 11:01:18 - mmengine - INFO - Iter(train) [ 16400/320000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 1 day, 12:28:55  time: 0.4328  data_time: 0.0088  memory: 5180  grad_norm: 189.7336  loss: 10.3002  decode.loss_cls: 0.2664  decode.loss_mask: 0.3498  decode.loss_dice: 0.2487  decode.d0.loss_cls: 1.0881  decode.d0.loss_mask: 0.3743  decode.d0.loss_dice: 0.2566  decode.d1.loss_cls: 0.3501  decode.d1.loss_mask: 0.3763  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.3451  decode.d2.loss_mask: 0.4077  decode.d2.loss_dice: 0.3194  decode.d3.loss_cls: 0.2748  decode.d3.loss_mask: 0.3719  decode.d3.loss_dice: 0.2963  decode.d4.loss_cls: 0.3629  decode.d4.loss_mask: 0.3450  decode.d4.loss_dice: 0.2737  decode.d5.loss_cls: 0.2548  decode.d5.loss_mask: 0.3487  decode.d5.loss_dice: 0.2991  decode.d6.loss_cls: 0.3312  decode.d6.loss_mask: 0.3696  decode.d6.loss_dice: 0.2783  decode.d7.loss_cls: 0.3109  decode.d7.loss_mask: 0.3388  decode.d7.loss_dice: 0.2587  decode.d8.loss_cls: 0.3031  decode.d8.loss_mask: 0.3453  decode.d8.loss_dice: 0.2740
09/30 11:01:39 - mmengine - INFO - Iter(train) [ 16450/320000]  base_lr: 9.5362e-05 lr: 9.5362e-06  eta: 1 day, 12:28:34  time: 0.4323  data_time: 0.0089  memory: 5161  grad_norm: 69.7954  loss: 6.6574  decode.loss_cls: 0.1474  decode.loss_mask: 0.2252  decode.loss_dice: 0.2181  decode.d0.loss_cls: 0.8573  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2395  decode.d1.loss_cls: 0.1635  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.2242  decode.d2.loss_cls: 0.1351  decode.d2.loss_mask: 0.2259  decode.d2.loss_dice: 0.2321  decode.d3.loss_cls: 0.1155  decode.d3.loss_mask: 0.2271  decode.d3.loss_dice: 0.2286  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.2330  decode.d5.loss_cls: 0.1172  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.2240  decode.d6.loss_dice: 0.2212  decode.d7.loss_cls: 0.1403  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.2247  decode.d8.loss_cls: 0.1822  decode.d8.loss_mask: 0.2267  decode.d8.loss_dice: 0.2206
09/30 11:02:01 - mmengine - INFO - Iter(train) [ 16500/320000]  base_lr: 9.5347e-05 lr: 9.5347e-06  eta: 1 day, 12:28:11  time: 0.4306  data_time: 0.0087  memory: 5180  grad_norm: 80.0847  loss: 8.3675  decode.loss_cls: 0.1439  decode.loss_mask: 0.3458  decode.loss_dice: 0.2627  decode.d0.loss_cls: 0.7993  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.2606  decode.d1.loss_cls: 0.3120  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.2939  decode.d2.loss_mask: 0.3520  decode.d2.loss_dice: 0.2392  decode.d3.loss_cls: 0.2181  decode.d3.loss_mask: 0.3318  decode.d3.loss_dice: 0.2781  decode.d4.loss_cls: 0.1431  decode.d4.loss_mask: 0.3512  decode.d4.loss_dice: 0.2329  decode.d5.loss_cls: 0.1656  decode.d5.loss_mask: 0.3535  decode.d5.loss_dice: 0.2334  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.3525  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.1459  decode.d7.loss_mask: 0.3463  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.1379  decode.d8.loss_mask: 0.3493  decode.d8.loss_dice: 0.2549
09/30 11:02:22 - mmengine - INFO - Iter(train) [ 16550/320000]  base_lr: 9.5333e-05 lr: 9.5333e-06  eta: 1 day, 12:27:49  time: 0.4321  data_time: 0.0088  memory: 5180  grad_norm: 269.3652  loss: 8.4817  decode.loss_cls: 0.1057  decode.loss_mask: 0.3739  decode.loss_dice: 0.2575  decode.d0.loss_cls: 0.9626  decode.d0.loss_mask: 0.3072  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.2011  decode.d1.loss_mask: 0.3332  decode.d1.loss_dice: 0.2582  decode.d2.loss_cls: 0.1947  decode.d2.loss_mask: 0.3476  decode.d2.loss_dice: 0.2641  decode.d3.loss_cls: 0.1465  decode.d3.loss_mask: 0.3276  decode.d3.loss_dice: 0.2464  decode.d4.loss_cls: 0.1627  decode.d4.loss_mask: 0.3483  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.1784  decode.d5.loss_mask: 0.3272  decode.d5.loss_dice: 0.2373  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 0.3440  decode.d6.loss_dice: 0.2616  decode.d7.loss_cls: 0.1580  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.2754  decode.d8.loss_cls: 0.1430  decode.d8.loss_mask: 0.3786  decode.d8.loss_dice: 0.2723
09/30 11:02:44 - mmengine - INFO - Iter(train) [ 16600/320000]  base_lr: 9.5319e-05 lr: 9.5319e-06  eta: 1 day, 12:27:28  time: 0.4337  data_time: 0.0090  memory: 5180  grad_norm: 67.7190  loss: 7.4401  decode.loss_cls: 0.1930  decode.loss_mask: 0.2683  decode.loss_dice: 0.2175  decode.d0.loss_cls: 0.9694  decode.d0.loss_mask: 0.2536  decode.d0.loss_dice: 0.2164  decode.d1.loss_cls: 0.1613  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.2461  decode.d2.loss_cls: 0.1323  decode.d2.loss_mask: 0.2514  decode.d2.loss_dice: 0.1990  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 0.2880  decode.d3.loss_dice: 0.2081  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 0.3165  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.1883  decode.d5.loss_mask: 0.2647  decode.d5.loss_dice: 0.2059  decode.d6.loss_cls: 0.2023  decode.d6.loss_mask: 0.3030  decode.d6.loss_dice: 0.2098  decode.d7.loss_cls: 0.1764  decode.d7.loss_mask: 0.2676  decode.d7.loss_dice: 0.2135  decode.d8.loss_cls: 0.2299  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.2199
09/30 11:03:06 - mmengine - INFO - Iter(train) [ 16650/320000]  base_lr: 9.5305e-05 lr: 9.5305e-06  eta: 1 day, 12:27:07  time: 0.4321  data_time: 0.0088  memory: 5180  grad_norm: 69.7395  loss: 7.3100  decode.loss_cls: 0.1478  decode.loss_mask: 0.2808  decode.loss_dice: 0.1948  decode.d0.loss_cls: 1.0989  decode.d0.loss_mask: 0.2860  decode.d0.loss_dice: 0.1974  decode.d1.loss_cls: 0.1461  decode.d1.loss_mask: 0.2848  decode.d1.loss_dice: 0.1984  decode.d2.loss_cls: 0.1566  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.2231  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.2001  decode.d4.loss_cls: 0.1691  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.1400  decode.d5.loss_mask: 0.2860  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.1455  decode.d6.loss_mask: 0.2760  decode.d6.loss_dice: 0.1962  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 0.2873  decode.d7.loss_dice: 0.2222  decode.d8.loss_cls: 0.1330  decode.d8.loss_mask: 0.2845  decode.d8.loss_dice: 0.2012
09/30 11:03:27 - mmengine - INFO - Iter(train) [ 16700/320000]  base_lr: 9.5291e-05 lr: 9.5291e-06  eta: 1 day, 12:26:45  time: 0.4324  data_time: 0.0086  memory: 5180  grad_norm: 60.8672  loss: 6.9939  decode.loss_cls: 0.1921  decode.loss_mask: 0.2590  decode.loss_dice: 0.2060  decode.d0.loss_cls: 1.0215  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.2006  decode.d1.loss_cls: 0.2050  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.1864  decode.d2.loss_cls: 0.1713  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.1956  decode.d3.loss_cls: 0.1882  decode.d3.loss_mask: 0.2377  decode.d3.loss_dice: 0.1891  decode.d4.loss_cls: 0.1895  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.1816  decode.d5.loss_cls: 0.2053  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.1949  decode.d6.loss_cls: 0.1765  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.2074  decode.d7.loss_cls: 0.1715  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.1910  decode.d8.loss_cls: 0.1906  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1944
09/30 11:03:49 - mmengine - INFO - Iter(train) [ 16750/320000]  base_lr: 9.5277e-05 lr: 9.5277e-06  eta: 1 day, 12:26:23  time: 0.4319  data_time: 0.0088  memory: 5161  grad_norm: 83.9032  loss: 7.9792  decode.loss_cls: 0.0759  decode.loss_mask: 0.4103  decode.loss_dice: 0.2253  decode.d0.loss_cls: 0.8859  decode.d0.loss_mask: 0.4109  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.1343  decode.d1.loss_mask: 0.4041  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.4101  decode.d2.loss_dice: 0.2322  decode.d3.loss_cls: 0.0857  decode.d3.loss_mask: 0.4086  decode.d3.loss_dice: 0.2330  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.4039  decode.d4.loss_dice: 0.2293  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.3907  decode.d5.loss_dice: 0.2271  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.3966  decode.d6.loss_dice: 0.2300  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.3884  decode.d7.loss_dice: 0.2274  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.3955  decode.d8.loss_dice: 0.2204
09/30 11:04:11 - mmengine - INFO - Iter(train) [ 16800/320000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 1 day, 12:26:02  time: 0.4326  data_time: 0.0088  memory: 5147  grad_norm: 94.1137  loss: 10.2419  decode.loss_cls: 0.3973  decode.loss_mask: 0.3033  decode.loss_dice: 0.3639  decode.d0.loss_cls: 0.9628  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.3383  decode.d1.loss_cls: 0.4828  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.3027  decode.d2.loss_cls: 0.2663  decode.d2.loss_mask: 0.2890  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 0.2671  decode.d3.loss_mask: 0.3123  decode.d3.loss_dice: 0.3404  decode.d4.loss_cls: 0.2525  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.2979  decode.d5.loss_cls: 0.2597  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.3536  decode.d6.loss_cls: 0.3231  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.3276  decode.d7.loss_cls: 0.3034  decode.d7.loss_mask: 0.2928  decode.d7.loss_dice: 0.3364  decode.d8.loss_cls: 0.3331  decode.d8.loss_mask: 0.3370  decode.d8.loss_dice: 0.3372
09/30 11:04:32 - mmengine - INFO - Iter(train) [ 16850/320000]  base_lr: 9.5248e-05 lr: 9.5248e-06  eta: 1 day, 12:25:40  time: 0.4319  data_time: 0.0089  memory: 5180  grad_norm: 78.5350  loss: 7.4617  decode.loss_cls: 0.1373  decode.loss_mask: 0.2730  decode.loss_dice: 0.2597  decode.d0.loss_cls: 0.9613  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.2737  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.2575  decode.d2.loss_cls: 0.1925  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.2632  decode.d3.loss_cls: 0.1364  decode.d3.loss_mask: 0.2702  decode.d3.loss_dice: 0.2518  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2404  decode.d6.loss_cls: 0.1154  decode.d6.loss_mask: 0.2686  decode.d6.loss_dice: 0.2360  decode.d7.loss_cls: 0.1271  decode.d7.loss_mask: 0.2744  decode.d7.loss_dice: 0.2527  decode.d8.loss_cls: 0.1388  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.2547
09/30 11:04:54 - mmengine - INFO - Iter(train) [ 16900/320000]  base_lr: 9.5234e-05 lr: 9.5234e-06  eta: 1 day, 12:25:18  time: 0.4313  data_time: 0.0087  memory: 5160  grad_norm: 99.6273  loss: 8.1861  decode.loss_cls: 0.2014  decode.loss_mask: 0.2941  decode.loss_dice: 0.2342  decode.d0.loss_cls: 0.9638  decode.d0.loss_mask: 0.3522  decode.d0.loss_dice: 0.2805  decode.d1.loss_cls: 0.2479  decode.d1.loss_mask: 0.2994  decode.d1.loss_dice: 0.2496  decode.d2.loss_cls: 0.1937  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.2471  decode.d3.loss_cls: 0.1668  decode.d3.loss_mask: 0.2927  decode.d3.loss_dice: 0.2477  decode.d4.loss_cls: 0.2121  decode.d4.loss_mask: 0.2931  decode.d4.loss_dice: 0.2293  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 0.2900  decode.d5.loss_dice: 0.2413  decode.d6.loss_cls: 0.2093  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.2300  decode.d7.loss_cls: 0.2000  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.2366  decode.d8.loss_cls: 0.2024  decode.d8.loss_mask: 0.2896  decode.d8.loss_dice: 0.2322
09/30 11:05:16 - mmengine - INFO - Iter(train) [ 16950/320000]  base_lr: 9.5220e-05 lr: 9.5220e-06  eta: 1 day, 12:24:56  time: 0.4323  data_time: 0.0087  memory: 5161  grad_norm: 42.6702  loss: 5.9329  decode.loss_cls: 0.0769  decode.loss_mask: 0.2392  decode.loss_dice: 0.1997  decode.d0.loss_cls: 0.8285  decode.d0.loss_mask: 0.2428  decode.d0.loss_dice: 0.2062  decode.d1.loss_cls: 0.0822  decode.d1.loss_mask: 0.2405  decode.d1.loss_dice: 0.2004  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.2415  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2060  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.2375  decode.d4.loss_dice: 0.1955  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.2419  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.0636  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2044  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.2024  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2014
09/30 11:05:37 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:05:37 - mmengine - INFO - Iter(train) [ 17000/320000]  base_lr: 9.5206e-05 lr: 9.5206e-06  eta: 1 day, 12:24:34  time: 0.4318  data_time: 0.0087  memory: 5161  grad_norm: 144.8753  loss: 9.7979  decode.loss_cls: 0.2417  decode.loss_mask: 0.3190  decode.loss_dice: 0.2730  decode.d0.loss_cls: 1.0071  decode.d0.loss_mask: 0.3447  decode.d0.loss_dice: 0.2719  decode.d1.loss_cls: 0.3754  decode.d1.loss_mask: 0.3163  decode.d1.loss_dice: 0.2747  decode.d2.loss_cls: 0.3345  decode.d2.loss_mask: 0.3732  decode.d2.loss_dice: 0.2928  decode.d3.loss_cls: 0.2395  decode.d3.loss_mask: 0.3224  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.2534  decode.d4.loss_mask: 0.3980  decode.d4.loss_dice: 0.3016  decode.d5.loss_cls: 0.2586  decode.d5.loss_mask: 0.3791  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.2252  decode.d6.loss_mask: 0.3507  decode.d6.loss_dice: 0.2912  decode.d7.loss_cls: 0.2390  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.3046  decode.d8.loss_cls: 0.2521  decode.d8.loss_mask: 0.3328  decode.d8.loss_dice: 0.3025
09/30 11:05:59 - mmengine - INFO - Iter(train) [ 17050/320000]  base_lr: 9.5192e-05 lr: 9.5192e-06  eta: 1 day, 12:24:13  time: 0.4324  data_time: 0.0090  memory: 5146  grad_norm: 162.7434  loss: 12.3586  decode.loss_cls: 0.4527  decode.loss_mask: 0.4099  decode.loss_dice: 0.3411  decode.d0.loss_cls: 1.0728  decode.d0.loss_mask: 0.3660  decode.d0.loss_dice: 0.3501  decode.d1.loss_cls: 0.3792  decode.d1.loss_mask: 0.4072  decode.d1.loss_dice: 0.3317  decode.d2.loss_cls: 0.4262  decode.d2.loss_mask: 0.3875  decode.d2.loss_dice: 0.3233  decode.d3.loss_cls: 0.3715  decode.d3.loss_mask: 0.3947  decode.d3.loss_dice: 0.3260  decode.d4.loss_cls: 0.4559  decode.d4.loss_mask: 0.4414  decode.d4.loss_dice: 0.3249  decode.d5.loss_cls: 0.4500  decode.d5.loss_mask: 0.4055  decode.d5.loss_dice: 0.3290  decode.d6.loss_cls: 0.4309  decode.d6.loss_mask: 0.4536  decode.d6.loss_dice: 0.3307  decode.d7.loss_cls: 0.4224  decode.d7.loss_mask: 0.4498  decode.d7.loss_dice: 0.3463  decode.d8.loss_cls: 0.4456  decode.d8.loss_mask: 0.4014  decode.d8.loss_dice: 0.3311
09/30 11:06:20 - mmengine - INFO - Iter(train) [ 17100/320000]  base_lr: 9.5178e-05 lr: 9.5178e-06  eta: 1 day, 12:23:51  time: 0.4322  data_time: 0.0090  memory: 5180  grad_norm: 121.9148  loss: 12.2917  decode.loss_cls: 0.4014  decode.loss_mask: 0.3436  decode.loss_dice: 0.4074  decode.d0.loss_cls: 1.2515  decode.d0.loss_mask: 0.3311  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.6233  decode.d1.loss_mask: 0.3235  decode.d1.loss_dice: 0.3605  decode.d2.loss_cls: 0.4740  decode.d2.loss_mask: 0.3239  decode.d2.loss_dice: 0.3351  decode.d3.loss_cls: 0.4299  decode.d3.loss_mask: 0.3320  decode.d3.loss_dice: 0.3397  decode.d4.loss_cls: 0.4783  decode.d4.loss_mask: 0.3307  decode.d4.loss_dice: 0.3518  decode.d5.loss_cls: 0.4433  decode.d5.loss_mask: 0.3327  decode.d5.loss_dice: 0.3717  decode.d6.loss_cls: 0.4303  decode.d6.loss_mask: 0.3305  decode.d6.loss_dice: 0.3763  decode.d7.loss_cls: 0.3378  decode.d7.loss_mask: 0.3320  decode.d7.loss_dice: 0.3712  decode.d8.loss_cls: 0.3669  decode.d8.loss_mask: 0.3488  decode.d8.loss_dice: 0.4286
09/30 11:06:42 - mmengine - INFO - Iter(train) [ 17150/320000]  base_lr: 9.5164e-05 lr: 9.5164e-06  eta: 1 day, 12:23:29  time: 0.4324  data_time: 0.0089  memory: 5147  grad_norm: 50.9522  loss: 7.1453  decode.loss_cls: 0.2231  decode.loss_mask: 0.2406  decode.loss_dice: 0.2006  decode.d0.loss_cls: 0.8535  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2319  decode.d1.loss_cls: 0.1421  decode.d1.loss_mask: 0.2411  decode.d1.loss_dice: 0.2045  decode.d2.loss_cls: 0.1575  decode.d2.loss_mask: 0.2436  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.1836  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.2011  decode.d4.loss_cls: 0.2488  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2130  decode.d5.loss_cls: 0.2214  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2083  decode.d6.loss_cls: 0.2064  decode.d6.loss_mask: 0.2382  decode.d6.loss_dice: 0.2033  decode.d7.loss_cls: 0.2096  decode.d7.loss_mask: 0.2419  decode.d7.loss_dice: 0.2080  decode.d8.loss_cls: 0.2212  decode.d8.loss_mask: 0.2399  decode.d8.loss_dice: 0.1922
09/30 11:07:04 - mmengine - INFO - Iter(train) [ 17200/320000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 1 day, 12:23:08  time: 0.4330  data_time: 0.0087  memory: 5161  grad_norm: 37.5042  loss: 5.1941  decode.loss_cls: 0.1097  decode.loss_mask: 0.1713  decode.loss_dice: 0.1618  decode.d0.loss_cls: 0.8913  decode.d0.loss_mask: 0.1733  decode.d0.loss_dice: 0.1969  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 0.1729  decode.d1.loss_dice: 0.1578  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.1727  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.1728  decode.d3.loss_dice: 0.2055  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.1739  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 0.1712  decode.d5.loss_dice: 0.1927  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.1735  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0710  decode.d7.loss_mask: 0.1724  decode.d7.loss_dice: 0.2080  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.1724  decode.d8.loss_dice: 0.2116
09/30 11:07:25 - mmengine - INFO - Iter(train) [ 17250/320000]  base_lr: 9.5135e-05 lr: 9.5135e-06  eta: 1 day, 12:22:46  time: 0.4322  data_time: 0.0089  memory: 5160  grad_norm: 481.0744  loss: 9.9426  decode.loss_cls: 0.2315  decode.loss_mask: 0.4890  decode.loss_dice: 0.3058  decode.d0.loss_cls: 0.9579  decode.d0.loss_mask: 0.3920  decode.d0.loss_dice: 0.3052  decode.d1.loss_cls: 0.2400  decode.d1.loss_mask: 0.4262  decode.d1.loss_dice: 0.2833  decode.d2.loss_cls: 0.2117  decode.d2.loss_mask: 0.3812  decode.d2.loss_dice: 0.2769  decode.d3.loss_cls: 0.2333  decode.d3.loss_mask: 0.3698  decode.d3.loss_dice: 0.2736  decode.d4.loss_cls: 0.2752  decode.d4.loss_mask: 0.3793  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.2277  decode.d5.loss_mask: 0.3895  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.2383  decode.d6.loss_mask: 0.3891  decode.d6.loss_dice: 0.2794  decode.d7.loss_cls: 0.2349  decode.d7.loss_mask: 0.4034  decode.d7.loss_dice: 0.2852  decode.d8.loss_cls: 0.2221  decode.d8.loss_mask: 0.3994  decode.d8.loss_dice: 0.2939
09/30 11:07:47 - mmengine - INFO - Iter(train) [ 17300/320000]  base_lr: 9.5121e-05 lr: 9.5121e-06  eta: 1 day, 12:22:23  time: 0.4320  data_time: 0.0088  memory: 5161  grad_norm: 115.8033  loss: 9.7936  decode.loss_cls: 0.1729  decode.loss_mask: 0.3172  decode.loss_dice: 0.3266  decode.d0.loss_cls: 1.0272  decode.d0.loss_mask: 0.3332  decode.d0.loss_dice: 0.3532  decode.d1.loss_cls: 0.2390  decode.d1.loss_mask: 0.3322  decode.d1.loss_dice: 0.3426  decode.d2.loss_cls: 0.2302  decode.d2.loss_mask: 0.3290  decode.d2.loss_dice: 0.3679  decode.d3.loss_cls: 0.1874  decode.d3.loss_mask: 0.3451  decode.d3.loss_dice: 0.3607  decode.d4.loss_cls: 0.2115  decode.d4.loss_mask: 0.3331  decode.d4.loss_dice: 0.3380  decode.d5.loss_cls: 0.2293  decode.d5.loss_mask: 0.3367  decode.d5.loss_dice: 0.3216  decode.d6.loss_cls: 0.1995  decode.d6.loss_mask: 0.4173  decode.d6.loss_dice: 0.3713  decode.d7.loss_cls: 0.1465  decode.d7.loss_mask: 0.3631  decode.d7.loss_dice: 0.3438  decode.d8.loss_cls: 0.1591  decode.d8.loss_mask: 0.3788  decode.d8.loss_dice: 0.3797
09/30 11:08:09 - mmengine - INFO - Iter(train) [ 17350/320000]  base_lr: 9.5107e-05 lr: 9.5107e-06  eta: 1 day, 12:22:02  time: 0.4355  data_time: 0.0091  memory: 5147  grad_norm: 41.2678  loss: 6.8467  decode.loss_cls: 0.1788  decode.loss_mask: 0.2511  decode.loss_dice: 0.2122  decode.d0.loss_cls: 0.8077  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.2093  decode.d1.loss_cls: 0.1770  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2145  decode.d2.loss_cls: 0.1866  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.2148  decode.d3.loss_cls: 0.2230  decode.d3.loss_mask: 0.2456  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.1724  decode.d4.loss_mask: 0.2395  decode.d4.loss_dice: 0.2233  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.2089  decode.d6.loss_cls: 0.1176  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.2044  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.2174  decode.d8.loss_cls: 0.1498  decode.d8.loss_mask: 0.2543  decode.d8.loss_dice: 0.2078
09/30 11:08:30 - mmengine - INFO - Iter(train) [ 17400/320000]  base_lr: 9.5093e-05 lr: 9.5093e-06  eta: 1 day, 12:21:40  time: 0.4328  data_time: 0.0091  memory: 5160  grad_norm: 44.1074  loss: 8.4641  decode.loss_cls: 0.2790  decode.loss_mask: 0.2513  decode.loss_dice: 0.2170  decode.d0.loss_cls: 1.0044  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.2214  decode.d1.loss_cls: 0.3265  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.3145  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.2962  decode.d3.loss_mask: 0.2514  decode.d3.loss_dice: 0.2431  decode.d4.loss_cls: 0.2789  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2238  decode.d5.loss_cls: 0.2785  decode.d5.loss_mask: 0.2487  decode.d5.loss_dice: 0.2292  decode.d6.loss_cls: 0.3047  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.2254  decode.d7.loss_cls: 0.3044  decode.d7.loss_mask: 0.2519  decode.d7.loss_dice: 0.2180  decode.d8.loss_cls: 0.2795  decode.d8.loss_mask: 0.2545  decode.d8.loss_dice: 0.2208
09/30 11:08:52 - mmengine - INFO - Iter(train) [ 17450/320000]  base_lr: 9.5079e-05 lr: 9.5079e-06  eta: 1 day, 12:21:19  time: 0.4331  data_time: 0.0090  memory: 5180  grad_norm: 181.9502  loss: 10.6069  decode.loss_cls: 0.2902  decode.loss_mask: 0.4605  decode.loss_dice: 0.3262  decode.d0.loss_cls: 0.9307  decode.d0.loss_mask: 0.2672  decode.d0.loss_dice: 0.3580  decode.d1.loss_cls: 0.4645  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.2962  decode.d2.loss_cls: 0.3578  decode.d2.loss_mask: 0.2823  decode.d2.loss_dice: 0.3322  decode.d3.loss_cls: 0.3678  decode.d3.loss_mask: 0.2604  decode.d3.loss_dice: 0.3597  decode.d4.loss_cls: 0.3928  decode.d4.loss_mask: 0.2941  decode.d4.loss_dice: 0.3476  decode.d5.loss_cls: 0.4236  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.3552  decode.d6.loss_cls: 0.2957  decode.d6.loss_mask: 0.3321  decode.d6.loss_dice: 0.2938  decode.d7.loss_cls: 0.2731  decode.d7.loss_mask: 0.4172  decode.d7.loss_dice: 0.3425  decode.d8.loss_cls: 0.2501  decode.d8.loss_mask: 0.3734  decode.d8.loss_dice: 0.3540
09/30 11:09:13 - mmengine - INFO - Iter(train) [ 17500/320000]  base_lr: 9.5065e-05 lr: 9.5065e-06  eta: 1 day, 12:20:57  time: 0.4333  data_time: 0.0091  memory: 5147  grad_norm: 197.7818  loss: 8.5948  decode.loss_cls: 0.2524  decode.loss_mask: 0.2526  decode.loss_dice: 0.2206  decode.d0.loss_cls: 1.0521  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.2303  decode.d1.loss_cls: 0.4310  decode.d1.loss_mask: 0.2350  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.3296  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.2131  decode.d3.loss_cls: 0.3235  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.1972  decode.d4.loss_cls: 0.2834  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.3459  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2214  decode.d6.loss_cls: 0.2929  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.2168  decode.d7.loss_cls: 0.3040  decode.d7.loss_mask: 0.2980  decode.d7.loss_dice: 0.2265  decode.d8.loss_cls: 0.2838  decode.d8.loss_mask: 0.2557  decode.d8.loss_dice: 0.2203
09/30 11:09:35 - mmengine - INFO - Iter(train) [ 17550/320000]  base_lr: 9.5051e-05 lr: 9.5051e-06  eta: 1 day, 12:20:36  time: 0.4324  data_time: 0.0091  memory: 5160  grad_norm: 76.9010  loss: 7.4317  decode.loss_cls: 0.1507  decode.loss_mask: 0.3107  decode.loss_dice: 0.2082  decode.d0.loss_cls: 1.0141  decode.d0.loss_mask: 0.3237  decode.d0.loss_dice: 0.2397  decode.d1.loss_cls: 0.1447  decode.d1.loss_mask: 0.3111  decode.d1.loss_dice: 0.2173  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.2232  decode.d3.loss_cls: 0.0933  decode.d3.loss_mask: 0.3175  decode.d3.loss_dice: 0.2209  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.3115  decode.d4.loss_dice: 0.2183  decode.d5.loss_cls: 0.0914  decode.d5.loss_mask: 0.3186  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.1334  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.1066  decode.d7.loss_mask: 0.3175  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.3175  decode.d8.loss_dice: 0.2077
09/30 11:09:57 - mmengine - INFO - Iter(train) [ 17600/320000]  base_lr: 9.5036e-05 lr: 9.5036e-06  eta: 1 day, 12:20:14  time: 0.4325  data_time: 0.0089  memory: 5160  grad_norm: 44.1243  loss: 7.3472  decode.loss_cls: 0.2014  decode.loss_mask: 0.2407  decode.loss_dice: 0.2104  decode.d0.loss_cls: 1.1774  decode.d0.loss_mask: 0.2370  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.3418  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2085  decode.d2.loss_cls: 0.1977  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2057  decode.d3.loss_cls: 0.1510  decode.d3.loss_mask: 0.2347  decode.d3.loss_dice: 0.2054  decode.d4.loss_cls: 0.1540  decode.d4.loss_mask: 0.2318  decode.d4.loss_dice: 0.2059  decode.d5.loss_cls: 0.1751  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2004  decode.d6.loss_cls: 0.1951  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.1929  decode.d7.loss_cls: 0.1906  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.1946  decode.d8.loss_cls: 0.1816  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.2041
09/30 11:10:18 - mmengine - INFO - Iter(train) [ 17650/320000]  base_lr: 9.5022e-05 lr: 9.5022e-06  eta: 1 day, 12:19:53  time: 0.4316  data_time: 0.0090  memory: 5147  grad_norm: 322.0771  loss: 8.2602  decode.loss_cls: 0.1651  decode.loss_mask: 0.4165  decode.loss_dice: 0.2460  decode.d0.loss_cls: 0.9525  decode.d0.loss_mask: 0.2579  decode.d0.loss_dice: 0.2144  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.1833  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 0.2963  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.2034  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.2128  decode.d4.loss_cls: 0.1579  decode.d4.loss_mask: 0.3821  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.1737  decode.d5.loss_mask: 0.4365  decode.d5.loss_dice: 0.2337  decode.d6.loss_cls: 0.2030  decode.d6.loss_mask: 0.3204  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.1524  decode.d7.loss_mask: 0.3978  decode.d7.loss_dice: 0.2408  decode.d8.loss_cls: 0.1873  decode.d8.loss_mask: 0.3212  decode.d8.loss_dice: 0.2552
09/30 11:10:40 - mmengine - INFO - Iter(train) [ 17700/320000]  base_lr: 9.5008e-05 lr: 9.5008e-06  eta: 1 day, 12:19:31  time: 0.4320  data_time: 0.0087  memory: 5161  grad_norm: 58.3846  loss: 5.7798  decode.loss_cls: 0.1077  decode.loss_mask: 0.1973  decode.loss_dice: 0.1843  decode.d0.loss_cls: 0.9263  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.1933  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.1861  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.1958  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.1107  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.1878  decode.d5.loss_cls: 0.1154  decode.d5.loss_mask: 0.2041  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.1146  decode.d6.loss_mask: 0.2031  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.1063  decode.d7.loss_mask: 0.1999  decode.d7.loss_dice: 0.1850  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.1977  decode.d8.loss_dice: 0.1832
09/30 11:11:02 - mmengine - INFO - Iter(train) [ 17750/320000]  base_lr: 9.4994e-05 lr: 9.4994e-06  eta: 1 day, 12:19:13  time: 0.4515  data_time: 0.0091  memory: 5160  grad_norm: 135.6557  loss: 6.9232  decode.loss_cls: 0.1832  decode.loss_mask: 0.2284  decode.loss_dice: 0.2058  decode.d0.loss_cls: 1.0598  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2183  decode.d1.loss_cls: 0.1661  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.2065  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.2120  decode.d3.loss_cls: 0.1503  decode.d3.loss_mask: 0.2309  decode.d3.loss_dice: 0.2018  decode.d4.loss_cls: 0.1523  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.1999  decode.d5.loss_cls: 0.1845  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.1985  decode.d6.loss_cls: 0.1774  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.2099  decode.d7.loss_cls: 0.1712  decode.d7.loss_mask: 0.2287  decode.d7.loss_dice: 0.2050  decode.d8.loss_cls: 0.1571  decode.d8.loss_mask: 0.2427  decode.d8.loss_dice: 0.2171
09/30 11:11:23 - mmengine - INFO - Iter(train) [ 17800/320000]  base_lr: 9.4980e-05 lr: 9.4980e-06  eta: 1 day, 12:18:51  time: 0.4328  data_time: 0.0090  memory: 5180  grad_norm: 66.6397  loss: 7.4298  decode.loss_cls: 0.1295  decode.loss_mask: 0.2966  decode.loss_dice: 0.2799  decode.d0.loss_cls: 0.8747  decode.d0.loss_mask: 0.3002  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.1514  decode.d1.loss_mask: 0.2877  decode.d1.loss_dice: 0.2508  decode.d2.loss_cls: 0.1122  decode.d2.loss_mask: 0.2956  decode.d2.loss_dice: 0.2652  decode.d3.loss_cls: 0.1082  decode.d3.loss_mask: 0.2919  decode.d3.loss_dice: 0.2730  decode.d4.loss_cls: 0.1215  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.2532  decode.d5.loss_cls: 0.1022  decode.d5.loss_mask: 0.2928  decode.d5.loss_dice: 0.2365  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.2590  decode.d7.loss_cls: 0.1051  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.2534  decode.d8.loss_cls: 0.0998  decode.d8.loss_mask: 0.2891  decode.d8.loss_dice: 0.2538
09/30 11:11:45 - mmengine - INFO - Iter(train) [ 17850/320000]  base_lr: 9.4966e-05 lr: 9.4966e-06  eta: 1 day, 12:18:30  time: 0.4335  data_time: 0.0093  memory: 5180  grad_norm: 82.8015  loss: 8.1064  decode.loss_cls: 0.1562  decode.loss_mask: 0.3113  decode.loss_dice: 0.2457  decode.d0.loss_cls: 0.7756  decode.d0.loss_mask: 0.3429  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.1761  decode.d1.loss_mask: 0.3174  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.1872  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.2472  decode.d4.loss_cls: 0.2280  decode.d4.loss_mask: 0.3105  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.1701  decode.d5.loss_mask: 0.3252  decode.d5.loss_dice: 0.2676  decode.d6.loss_cls: 0.1833  decode.d6.loss_mask: 0.3112  decode.d6.loss_dice: 0.2484  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 0.3155  decode.d7.loss_dice: 0.2561  decode.d8.loss_cls: 0.1021  decode.d8.loss_mask: 0.3318  decode.d8.loss_dice: 0.2665
09/30 11:12:07 - mmengine - INFO - Iter(train) [ 17900/320000]  base_lr: 9.4952e-05 lr: 9.4952e-06  eta: 1 day, 12:18:09  time: 0.4340  data_time: 0.0094  memory: 5180  grad_norm: 143.1337  loss: 9.3308  decode.loss_cls: 0.2568  decode.loss_mask: 0.3053  decode.loss_dice: 0.3219  decode.d0.loss_cls: 1.1552  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.2478  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 0.2692  decode.d1.loss_dice: 0.2989  decode.d2.loss_cls: 0.2937  decode.d2.loss_mask: 0.2593  decode.d2.loss_dice: 0.2865  decode.d3.loss_cls: 0.2448  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2572  decode.d4.loss_cls: 0.2470  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.3307  decode.d5.loss_cls: 0.0977  decode.d5.loss_mask: 0.4156  decode.d5.loss_dice: 0.3396  decode.d6.loss_cls: 0.2536  decode.d6.loss_mask: 0.2890  decode.d6.loss_dice: 0.3620  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.3560  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.3387
09/30 11:12:28 - mmengine - INFO - Iter(train) [ 17950/320000]  base_lr: 9.4937e-05 lr: 9.4937e-06  eta: 1 day, 12:17:47  time: 0.4326  data_time: 0.0090  memory: 5160  grad_norm: 25.9225  loss: 4.1300  decode.loss_cls: 0.0301  decode.loss_mask: 0.1731  decode.loss_dice: 0.1304  decode.d0.loss_cls: 0.8060  decode.d0.loss_mask: 0.1939  decode.d0.loss_dice: 0.1559  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.1732  decode.d1.loss_dice: 0.1324  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.1749  decode.d2.loss_dice: 0.1261  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.1735  decode.d3.loss_dice: 0.1295  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.1747  decode.d4.loss_dice: 0.1305  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.1747  decode.d5.loss_dice: 0.1298  decode.d6.loss_cls: 0.0240  decode.d6.loss_mask: 0.1737  decode.d6.loss_dice: 0.1300  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.1752  decode.d7.loss_dice: 0.1302  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.1755  decode.d8.loss_dice: 0.1329
09/30 11:12:50 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:12:50 - mmengine - INFO - Iter(train) [ 18000/320000]  base_lr: 9.4923e-05 lr: 9.4923e-06  eta: 1 day, 12:17:26  time: 0.4333  data_time: 0.0090  memory: 5161  grad_norm: 96.2714  loss: 8.4654  decode.loss_cls: 0.2009  decode.loss_mask: 0.2988  decode.loss_dice: 0.2394  decode.d0.loss_cls: 1.0498  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.2458  decode.d1.loss_cls: 0.2414  decode.d1.loss_mask: 0.3029  decode.d1.loss_dice: 0.2614  decode.d2.loss_cls: 0.1606  decode.d2.loss_mask: 0.3253  decode.d2.loss_dice: 0.2464  decode.d3.loss_cls: 0.1677  decode.d3.loss_mask: 0.3121  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.2001  decode.d4.loss_mask: 0.4093  decode.d4.loss_dice: 0.2613  decode.d5.loss_cls: 0.1904  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.2433  decode.d6.loss_cls: 0.1644  decode.d6.loss_mask: 0.3055  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.1859  decode.d7.loss_mask: 0.3016  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.2121  decode.d8.loss_mask: 0.3175  decode.d8.loss_dice: 0.2595
09/30 11:13:12 - mmengine - INFO - Iter(train) [ 18050/320000]  base_lr: 9.4909e-05 lr: 9.4909e-06  eta: 1 day, 12:17:04  time: 0.4331  data_time: 0.0089  memory: 5180  grad_norm: 68.4435  loss: 7.3168  decode.loss_cls: 0.2302  decode.loss_mask: 0.2053  decode.loss_dice: 0.2064  decode.d0.loss_cls: 1.0816  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.2394  decode.d1.loss_cls: 0.2099  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.2512  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.2464  decode.d2.loss_dice: 0.2262  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.2222  decode.d4.loss_cls: 0.2073  decode.d4.loss_mask: 0.2126  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.1712  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 0.2111  decode.d6.loss_dice: 0.2435  decode.d7.loss_cls: 0.1867  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.2180  decode.d8.loss_cls: 0.2375  decode.d8.loss_mask: 0.2106  decode.d8.loss_dice: 0.2276
09/30 11:13:33 - mmengine - INFO - Iter(train) [ 18100/320000]  base_lr: 9.4895e-05 lr: 9.4895e-06  eta: 1 day, 12:16:42  time: 0.4316  data_time: 0.0089  memory: 5180  grad_norm: 88.4518  loss: 9.1564  decode.loss_cls: 0.1955  decode.loss_mask: 0.4169  decode.loss_dice: 0.2667  decode.d0.loss_cls: 1.0730  decode.d0.loss_mask: 0.3381  decode.d0.loss_dice: 0.2508  decode.d1.loss_cls: 0.2527  decode.d1.loss_mask: 0.3285  decode.d1.loss_dice: 0.2740  decode.d2.loss_cls: 0.1599  decode.d2.loss_mask: 0.3598  decode.d2.loss_dice: 0.2501  decode.d3.loss_cls: 0.2440  decode.d3.loss_mask: 0.3255  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.2327  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.2599  decode.d5.loss_cls: 0.2475  decode.d5.loss_mask: 0.3670  decode.d5.loss_dice: 0.2722  decode.d6.loss_cls: 0.1945  decode.d6.loss_mask: 0.3994  decode.d6.loss_dice: 0.2573  decode.d7.loss_cls: 0.1193  decode.d7.loss_mask: 0.4120  decode.d7.loss_dice: 0.2712  decode.d8.loss_cls: 0.1056  decode.d8.loss_mask: 0.4019  decode.d8.loss_dice: 0.2655
09/30 11:13:55 - mmengine - INFO - Iter(train) [ 18150/320000]  base_lr: 9.4881e-05 lr: 9.4881e-06  eta: 1 day, 12:16:21  time: 0.4313  data_time: 0.0088  memory: 5160  grad_norm: 38.5979  loss: 5.7011  decode.loss_cls: 0.0484  decode.loss_mask: 0.2253  decode.loss_dice: 0.1927  decode.d0.loss_cls: 0.8327  decode.d0.loss_mask: 0.2316  decode.d0.loss_dice: 0.2054  decode.d1.loss_cls: 0.0832  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1908  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.1943  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.1947  decode.d4.loss_cls: 0.1179  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.1893  decode.d5.loss_cls: 0.1057  decode.d5.loss_mask: 0.2227  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.1935  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.1978  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.1949
09/30 11:14:17 - mmengine - INFO - Iter(train) [ 18200/320000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 1 day, 12:15:59  time: 0.4315  data_time: 0.0088  memory: 5161  grad_norm: 46.3945  loss: 6.5189  decode.loss_cls: 0.1194  decode.loss_mask: 0.2615  decode.loss_dice: 0.2245  decode.d0.loss_cls: 0.7818  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.2325  decode.d1.loss_cls: 0.1123  decode.d1.loss_mask: 0.2577  decode.d1.loss_dice: 0.2327  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.2600  decode.d2.loss_dice: 0.2279  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.2067  decode.d5.loss_cls: 0.1009  decode.d5.loss_mask: 0.2618  decode.d5.loss_dice: 0.2097  decode.d6.loss_cls: 0.1188  decode.d6.loss_mask: 0.2631  decode.d6.loss_dice: 0.2267  decode.d7.loss_cls: 0.1531  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.2227  decode.d8.loss_cls: 0.0886  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.1973
09/30 11:14:38 - mmengine - INFO - Iter(train) [ 18250/320000]  base_lr: 9.4853e-05 lr: 9.4853e-06  eta: 1 day, 12:15:37  time: 0.4318  data_time: 0.0091  memory: 5146  grad_norm: 74.9595  loss: 6.2684  decode.loss_cls: 0.0959  decode.loss_mask: 0.2666  decode.loss_dice: 0.2049  decode.d0.loss_cls: 0.7810  decode.d0.loss_mask: 0.2728  decode.d0.loss_dice: 0.2110  decode.d1.loss_cls: 0.1600  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.1929  decode.d2.loss_cls: 0.1019  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.1910  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.2715  decode.d3.loss_dice: 0.2019  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2032  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.2714  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.2683  decode.d6.loss_dice: 0.1981  decode.d7.loss_cls: 0.0998  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.2052  decode.d8.loss_cls: 0.0813  decode.d8.loss_mask: 0.2660  decode.d8.loss_dice: 0.1985
09/30 11:15:00 - mmengine - INFO - Iter(train) [ 18300/320000]  base_lr: 9.4838e-05 lr: 9.4838e-06  eta: 1 day, 12:15:16  time: 0.4325  data_time: 0.0093  memory: 5160  grad_norm: 158.4410  loss: 7.9735  decode.loss_cls: 0.1067  decode.loss_mask: 0.3347  decode.loss_dice: 0.2560  decode.d0.loss_cls: 0.9502  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.1650  decode.d1.loss_mask: 0.3338  decode.d1.loss_dice: 0.2454  decode.d2.loss_cls: 0.2112  decode.d2.loss_mask: 0.3267  decode.d2.loss_dice: 0.2491  decode.d3.loss_cls: 0.1387  decode.d3.loss_mask: 0.3272  decode.d3.loss_dice: 0.2461  decode.d4.loss_cls: 0.1944  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 0.3200  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 0.3235  decode.d6.loss_dice: 0.2445  decode.d7.loss_cls: 0.1034  decode.d7.loss_mask: 0.3153  decode.d7.loss_dice: 0.2364  decode.d8.loss_cls: 0.1035  decode.d8.loss_mask: 0.3402  decode.d8.loss_dice: 0.2655
09/30 11:15:21 - mmengine - INFO - Iter(train) [ 18350/320000]  base_lr: 9.4824e-05 lr: 9.4824e-06  eta: 1 day, 12:14:54  time: 0.4328  data_time: 0.0092  memory: 5180  grad_norm: 367.5590  loss: 12.6696  decode.loss_cls: 0.1532  decode.loss_mask: 1.1047  decode.loss_dice: 0.3606  decode.d0.loss_cls: 1.2838  decode.d0.loss_mask: 0.4124  decode.d0.loss_dice: 0.3330  decode.d1.loss_cls: 0.4341  decode.d1.loss_mask: 0.3820  decode.d1.loss_dice: 0.3150  decode.d2.loss_cls: 0.4359  decode.d2.loss_mask: 0.3499  decode.d2.loss_dice: 0.2998  decode.d3.loss_cls: 0.3709  decode.d3.loss_mask: 0.3753  decode.d3.loss_dice: 0.3175  decode.d4.loss_cls: 0.3967  decode.d4.loss_mask: 0.3375  decode.d4.loss_dice: 0.3035  decode.d5.loss_cls: 0.3032  decode.d5.loss_mask: 0.4228  decode.d5.loss_dice: 0.3302  decode.d6.loss_cls: 0.3461  decode.d6.loss_mask: 0.3899  decode.d6.loss_dice: 0.3079  decode.d7.loss_cls: 0.3508  decode.d7.loss_mask: 0.3862  decode.d7.loss_dice: 0.3190  decode.d8.loss_cls: 0.1553  decode.d8.loss_mask: 1.0430  decode.d8.loss_dice: 0.3492
09/30 11:15:43 - mmengine - INFO - Iter(train) [ 18400/320000]  base_lr: 9.4810e-05 lr: 9.4810e-06  eta: 1 day, 12:14:33  time: 0.4323  data_time: 0.0091  memory: 5160  grad_norm: 33.4527  loss: 5.2764  decode.loss_cls: 0.0375  decode.loss_mask: 0.2226  decode.loss_dice: 0.1896  decode.d0.loss_cls: 0.8509  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.1738  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.1725  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.1764  decode.d3.loss_cls: 0.0392  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.1754  decode.d4.loss_cls: 0.0570  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.1740  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.2242  decode.d5.loss_dice: 0.1718  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.1725  decode.d7.loss_cls: 0.0423  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.1793  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.1849
09/30 11:16:05 - mmengine - INFO - Iter(train) [ 18450/320000]  base_lr: 9.4796e-05 lr: 9.4796e-06  eta: 1 day, 12:14:11  time: 0.4336  data_time: 0.0091  memory: 5180  grad_norm: 32.5796  loss: 5.0866  decode.loss_cls: 0.0530  decode.loss_mask: 0.1873  decode.loss_dice: 0.1634  decode.d0.loss_cls: 0.8102  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1736  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.1682  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.1855  decode.d2.loss_dice: 0.1674  decode.d3.loss_cls: 0.1160  decode.d3.loss_mask: 0.1858  decode.d3.loss_dice: 0.1691  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.1833  decode.d4.loss_dice: 0.1698  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.1858  decode.d5.loss_dice: 0.1634  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.1857  decode.d6.loss_dice: 0.1652  decode.d7.loss_cls: 0.0829  decode.d7.loss_mask: 0.1867  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.1839  decode.d8.loss_dice: 0.1588
09/30 11:16:26 - mmengine - INFO - Iter(train) [ 18500/320000]  base_lr: 9.4782e-05 lr: 9.4782e-06  eta: 1 day, 12:13:50  time: 0.4340  data_time: 0.0090  memory: 5161  grad_norm: 32.7249  loss: 5.4472  decode.loss_cls: 0.0306  decode.loss_mask: 0.2445  decode.loss_dice: 0.1892  decode.d0.loss_cls: 0.7690  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.1884  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.2428  decode.d2.loss_dice: 0.1817  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0319  decode.d5.loss_mask: 0.2460  decode.d5.loss_dice: 0.1840  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.2452  decode.d6.loss_dice: 0.1850  decode.d7.loss_cls: 0.0358  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.2425  decode.d8.loss_dice: 0.1907
09/30 11:16:48 - mmengine - INFO - Iter(train) [ 18550/320000]  base_lr: 9.4768e-05 lr: 9.4768e-06  eta: 1 day, 12:13:28  time: 0.4325  data_time: 0.0090  memory: 5180  grad_norm: 66.2923  loss: 8.0006  decode.loss_cls: 0.2736  decode.loss_mask: 0.3018  decode.loss_dice: 0.2265  decode.d0.loss_cls: 0.9429  decode.d0.loss_mask: 0.2476  decode.d0.loss_dice: 0.1959  decode.d1.loss_cls: 0.2426  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.1845  decode.d2.loss_cls: 0.2276  decode.d2.loss_mask: 0.2420  decode.d2.loss_dice: 0.1781  decode.d3.loss_cls: 0.2105  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.1841  decode.d4.loss_cls: 0.2720  decode.d4.loss_mask: 0.2810  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.2059  decode.d5.loss_mask: 0.3456  decode.d5.loss_dice: 0.2502  decode.d6.loss_cls: 0.1572  decode.d6.loss_mask: 0.4227  decode.d6.loss_dice: 0.2292  decode.d7.loss_cls: 0.2051  decode.d7.loss_mask: 0.3032  decode.d7.loss_dice: 0.2401  decode.d8.loss_cls: 0.1963  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.2439
09/30 11:17:10 - mmengine - INFO - Iter(train) [ 18600/320000]  base_lr: 9.4753e-05 lr: 9.4753e-06  eta: 1 day, 12:13:06  time: 0.4315  data_time: 0.0087  memory: 5161  grad_norm: 37.3203  loss: 6.0230  decode.loss_cls: 0.0270  decode.loss_mask: 0.2731  decode.loss_dice: 0.2189  decode.d0.loss_cls: 0.7063  decode.d0.loss_mask: 0.2728  decode.d0.loss_dice: 0.2170  decode.d1.loss_cls: 0.1360  decode.d1.loss_mask: 0.2705  decode.d1.loss_dice: 0.2181  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.2737  decode.d2.loss_dice: 0.2183  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2734  decode.d3.loss_dice: 0.2225  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.2746  decode.d4.loss_dice: 0.2172  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.2724  decode.d5.loss_dice: 0.2185  decode.d6.loss_cls: 0.0271  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.2207  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.2238  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.2709  decode.d8.loss_dice: 0.2312
09/30 11:17:31 - mmengine - INFO - Iter(train) [ 18650/320000]  base_lr: 9.4739e-05 lr: 9.4739e-06  eta: 1 day, 12:12:45  time: 0.4317  data_time: 0.0090  memory: 5161  grad_norm: 72.6868  loss: 6.2395  decode.loss_cls: 0.0413  decode.loss_mask: 0.3016  decode.loss_dice: 0.2085  decode.d0.loss_cls: 0.8634  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.1867  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.1935  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.2670  decode.d2.loss_dice: 0.2043  decode.d3.loss_cls: 0.0570  decode.d3.loss_mask: 0.2737  decode.d3.loss_dice: 0.2044  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.2056  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.3376  decode.d5.loss_dice: 0.2086  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 0.2636  decode.d6.loss_dice: 0.1895  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.1557  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.2023
09/30 11:17:53 - mmengine - INFO - Iter(train) [ 18700/320000]  base_lr: 9.4725e-05 lr: 9.4725e-06  eta: 1 day, 12:12:24  time: 0.4340  data_time: 0.0092  memory: 5160  grad_norm: 54.9317  loss: 6.7568  decode.loss_cls: 0.1356  decode.loss_mask: 0.2356  decode.loss_dice: 0.1912  decode.d0.loss_cls: 1.0058  decode.d0.loss_mask: 0.2408  decode.d0.loss_dice: 0.1930  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 0.2368  decode.d1.loss_dice: 0.1916  decode.d2.loss_cls: 0.1351  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.1871  decode.d3.loss_cls: 0.1725  decode.d3.loss_mask: 0.2446  decode.d3.loss_dice: 0.1912  decode.d4.loss_cls: 0.1999  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.1860  decode.d5.loss_cls: 0.1948  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.1747  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.1870  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.2367  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.2343  decode.d8.loss_dice: 0.1901
09/30 11:18:15 - mmengine - INFO - Iter(train) [ 18750/320000]  base_lr: 9.4711e-05 lr: 9.4711e-06  eta: 1 day, 12:12:02  time: 0.4331  data_time: 0.0091  memory: 5160  grad_norm: 63.4023  loss: 6.0724  decode.loss_cls: 0.1180  decode.loss_mask: 0.2332  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.8495  decode.d0.loss_mask: 0.2436  decode.d0.loss_dice: 0.2009  decode.d1.loss_cls: 0.1987  decode.d1.loss_mask: 0.2355  decode.d1.loss_dice: 0.1724  decode.d2.loss_cls: 0.1383  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.1740  decode.d3.loss_cls: 0.1391  decode.d3.loss_mask: 0.2309  decode.d3.loss_dice: 0.1647  decode.d4.loss_cls: 0.1248  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.1750  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.1714  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.2313  decode.d6.loss_dice: 0.1655  decode.d7.loss_cls: 0.0906  decode.d7.loss_mask: 0.2323  decode.d7.loss_dice: 0.1714  decode.d8.loss_cls: 0.1099  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.1777
09/30 11:18:36 - mmengine - INFO - Iter(train) [ 18800/320000]  base_lr: 9.4697e-05 lr: 9.4697e-06  eta: 1 day, 12:11:41  time: 0.4322  data_time: 0.0090  memory: 5160  grad_norm: 58.6607  loss: 7.4023  decode.loss_cls: 0.1175  decode.loss_mask: 0.2779  decode.loss_dice: 0.2669  decode.d0.loss_cls: 0.7794  decode.d0.loss_mask: 0.2844  decode.d0.loss_dice: 0.2595  decode.d1.loss_cls: 0.1699  decode.d1.loss_mask: 0.2795  decode.d1.loss_dice: 0.2560  decode.d2.loss_cls: 0.1384  decode.d2.loss_mask: 0.2821  decode.d2.loss_dice: 0.2392  decode.d3.loss_cls: 0.1302  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.1544  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.2637  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2473  decode.d6.loss_cls: 0.1637  decode.d6.loss_mask: 0.2793  decode.d6.loss_dice: 0.2617  decode.d7.loss_cls: 0.0960  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.1110  decode.d8.loss_mask: 0.2795  decode.d8.loss_dice: 0.2642
09/30 11:18:58 - mmengine - INFO - Iter(train) [ 18850/320000]  base_lr: 9.4683e-05 lr: 9.4683e-06  eta: 1 day, 12:11:20  time: 0.4330  data_time: 0.0092  memory: 5147  grad_norm: 104.3530  loss: 9.6192  decode.loss_cls: 0.3213  decode.loss_mask: 0.2728  decode.loss_dice: 0.3265  decode.d0.loss_cls: 1.0054  decode.d0.loss_mask: 0.2661  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.2777  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.3050  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.2928  decode.d3.loss_cls: 0.3121  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.3146  decode.d4.loss_cls: 0.3175  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.3100  decode.d5.loss_cls: 0.3123  decode.d5.loss_mask: 0.2802  decode.d5.loss_dice: 0.3136  decode.d6.loss_cls: 0.2922  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.3257  decode.d7.loss_cls: 0.3228  decode.d7.loss_mask: 0.2870  decode.d7.loss_dice: 0.2772  decode.d8.loss_cls: 0.3583  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.2631
09/30 11:19:20 - mmengine - INFO - Iter(train) [ 18900/320000]  base_lr: 9.4669e-05 lr: 9.4669e-06  eta: 1 day, 12:10:59  time: 0.4336  data_time: 0.0092  memory: 5161  grad_norm: 96.8079  loss: 9.0241  decode.loss_cls: 0.1689  decode.loss_mask: 0.3686  decode.loss_dice: 0.2913  decode.d0.loss_cls: 0.9570  decode.d0.loss_mask: 0.3692  decode.d0.loss_dice: 0.3070  decode.d1.loss_cls: 0.2248  decode.d1.loss_mask: 0.3507  decode.d1.loss_dice: 0.2933  decode.d2.loss_cls: 0.1510  decode.d2.loss_mask: 0.3729  decode.d2.loss_dice: 0.2990  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 0.3691  decode.d3.loss_dice: 0.2917  decode.d4.loss_cls: 0.1688  decode.d4.loss_mask: 0.3592  decode.d4.loss_dice: 0.2656  decode.d5.loss_cls: 0.1397  decode.d5.loss_mask: 0.3618  decode.d5.loss_dice: 0.2929  decode.d6.loss_cls: 0.1687  decode.d6.loss_mask: 0.3682  decode.d6.loss_dice: 0.2856  decode.d7.loss_cls: 0.1749  decode.d7.loss_mask: 0.3629  decode.d7.loss_dice: 0.2865  decode.d8.loss_cls: 0.1701  decode.d8.loss_mask: 0.3719  decode.d8.loss_dice: 0.2749
09/30 11:19:41 - mmengine - INFO - Iter(train) [ 18950/320000]  base_lr: 9.4654e-05 lr: 9.4654e-06  eta: 1 day, 12:10:38  time: 0.4331  data_time: 0.0089  memory: 5145  grad_norm: 85.3118  loss: 7.9597  decode.loss_cls: 0.1375  decode.loss_mask: 0.2919  decode.loss_dice: 0.2711  decode.d0.loss_cls: 1.0271  decode.d0.loss_mask: 0.3210  decode.d0.loss_dice: 0.3095  decode.d1.loss_cls: 0.1743  decode.d1.loss_mask: 0.2851  decode.d1.loss_dice: 0.2547  decode.d2.loss_cls: 0.1745  decode.d2.loss_mask: 0.2895  decode.d2.loss_dice: 0.2504  decode.d3.loss_cls: 0.1291  decode.d3.loss_mask: 0.3002  decode.d3.loss_dice: 0.2755  decode.d4.loss_cls: 0.1883  decode.d4.loss_mask: 0.2792  decode.d4.loss_dice: 0.2503  decode.d5.loss_cls: 0.1271  decode.d5.loss_mask: 0.2994  decode.d5.loss_dice: 0.2589  decode.d6.loss_cls: 0.1435  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1501  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.2546  decode.d8.loss_cls: 0.1461  decode.d8.loss_mask: 0.2864  decode.d8.loss_dice: 0.2491
09/30 11:20:03 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:20:03 - mmengine - INFO - Iter(train) [ 19000/320000]  base_lr: 9.4640e-05 lr: 9.4640e-06  eta: 1 day, 12:10:16  time: 0.4329  data_time: 0.0090  memory: 5180  grad_norm: 149.1348  loss: 8.8411  decode.loss_cls: 0.1913  decode.loss_mask: 0.3214  decode.loss_dice: 0.2306  decode.d0.loss_cls: 0.9556  decode.d0.loss_mask: 0.3188  decode.d0.loss_dice: 0.2618  decode.d1.loss_cls: 0.2017  decode.d1.loss_mask: 0.3449  decode.d1.loss_dice: 0.2527  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.3181  decode.d2.loss_dice: 0.2585  decode.d3.loss_cls: 0.2054  decode.d3.loss_mask: 0.3652  decode.d3.loss_dice: 0.2803  decode.d4.loss_cls: 0.1965  decode.d4.loss_mask: 0.3752  decode.d4.loss_dice: 0.2866  decode.d5.loss_cls: 0.2090  decode.d5.loss_mask: 0.4629  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.1987  decode.d6.loss_mask: 0.3485  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 0.3390  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.2050  decode.d8.loss_mask: 0.3179  decode.d8.loss_dice: 0.2354
09/30 11:20:25 - mmengine - INFO - Iter(train) [ 19050/320000]  base_lr: 9.4626e-05 lr: 9.4626e-06  eta: 1 day, 12:09:55  time: 0.4327  data_time: 0.0089  memory: 5160  grad_norm: 83.1131  loss: 7.3227  decode.loss_cls: 0.0930  decode.loss_mask: 0.2742  decode.loss_dice: 0.2622  decode.d0.loss_cls: 0.9045  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.2682  decode.d1.loss_cls: 0.1545  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.1006  decode.d2.loss_mask: 0.2794  decode.d2.loss_dice: 0.2567  decode.d3.loss_cls: 0.1297  decode.d3.loss_mask: 0.2779  decode.d3.loss_dice: 0.2598  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.2252  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.2815  decode.d5.loss_dice: 0.2742  decode.d6.loss_cls: 0.1224  decode.d6.loss_mask: 0.2794  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.1288  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.2356  decode.d8.loss_cls: 0.1019  decode.d8.loss_mask: 0.2746  decode.d8.loss_dice: 0.2564
09/30 11:20:46 - mmengine - INFO - Iter(train) [ 19100/320000]  base_lr: 9.4612e-05 lr: 9.4612e-06  eta: 1 day, 12:09:33  time: 0.4327  data_time: 0.0091  memory: 5161  grad_norm: 78.5616  loss: 7.3966  decode.loss_cls: 0.1306  decode.loss_mask: 0.2818  decode.loss_dice: 0.2301  decode.d0.loss_cls: 0.9484  decode.d0.loss_mask: 0.2831  decode.d0.loss_dice: 0.2662  decode.d1.loss_cls: 0.2086  decode.d1.loss_mask: 0.2887  decode.d1.loss_dice: 0.2429  decode.d2.loss_cls: 0.1271  decode.d2.loss_mask: 0.2849  decode.d2.loss_dice: 0.2407  decode.d3.loss_cls: 0.1050  decode.d3.loss_mask: 0.2859  decode.d3.loss_dice: 0.2512  decode.d4.loss_cls: 0.1110  decode.d4.loss_mask: 0.2832  decode.d4.loss_dice: 0.2422  decode.d5.loss_cls: 0.1151  decode.d5.loss_mask: 0.2898  decode.d5.loss_dice: 0.2437  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 0.2915  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.1064  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.2401  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 0.2826  decode.d8.loss_dice: 0.2402
09/30 11:21:08 - mmengine - INFO - Iter(train) [ 19150/320000]  base_lr: 9.4598e-05 lr: 9.4598e-06  eta: 1 day, 12:09:12  time: 0.4328  data_time: 0.0089  memory: 5161  grad_norm: 40.8312  loss: 6.9362  decode.loss_cls: 0.0826  decode.loss_mask: 0.2971  decode.loss_dice: 0.2400  decode.d0.loss_cls: 0.7723  decode.d0.loss_mask: 0.3091  decode.d0.loss_dice: 0.2424  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.3046  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0677  decode.d2.loss_mask: 0.3037  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.3028  decode.d3.loss_dice: 0.2395  decode.d4.loss_cls: 0.0899  decode.d4.loss_mask: 0.3009  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 0.3015  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.2981  decode.d8.loss_dice: 0.2372
09/30 11:21:30 - mmengine - INFO - Iter(train) [ 19200/320000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 1 day, 12:08:50  time: 0.4322  data_time: 0.0092  memory: 5161  grad_norm: 40.7865  loss: 5.7673  decode.loss_cls: 0.0257  decode.loss_mask: 0.2795  decode.loss_dice: 0.1926  decode.d0.loss_cls: 0.8254  decode.d0.loss_mask: 0.2788  decode.d0.loss_dice: 0.1918  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.1857  decode.d2.loss_cls: 0.0373  decode.d2.loss_mask: 0.2760  decode.d2.loss_dice: 0.1826  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.2780  decode.d3.loss_dice: 0.1911  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.1932  decode.d5.loss_cls: 0.0220  decode.d5.loss_mask: 0.2753  decode.d5.loss_dice: 0.1854  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.1931  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.2779  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.2778  decode.d8.loss_dice: 0.1878
09/30 11:21:51 - mmengine - INFO - Iter(train) [ 19250/320000]  base_lr: 9.4570e-05 lr: 9.4570e-06  eta: 1 day, 12:08:29  time: 0.4321  data_time: 0.0090  memory: 5180  grad_norm: 38.6111  loss: 5.7581  decode.loss_cls: 0.0613  decode.loss_mask: 0.2340  decode.loss_dice: 0.1740  decode.d0.loss_cls: 0.8877  decode.d0.loss_mask: 0.2391  decode.d0.loss_dice: 0.2046  decode.d1.loss_cls: 0.0809  decode.d1.loss_mask: 0.2348  decode.d1.loss_dice: 0.1844  decode.d2.loss_cls: 0.1138  decode.d2.loss_mask: 0.2348  decode.d2.loss_dice: 0.1804  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.1811  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.1838  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.1819  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.2307  decode.d7.loss_dice: 0.1848  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.1768
09/30 11:22:13 - mmengine - INFO - Iter(train) [ 19300/320000]  base_lr: 9.4555e-05 lr: 9.4555e-06  eta: 1 day, 12:08:08  time: 0.4314  data_time: 0.0088  memory: 5161  grad_norm: 147.4510  loss: 7.2819  decode.loss_cls: 0.1151  decode.loss_mask: 0.2769  decode.loss_dice: 0.2021  decode.d0.loss_cls: 1.1077  decode.d0.loss_mask: 0.2514  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.1718  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.2059  decode.d2.loss_cls: 0.2096  decode.d2.loss_mask: 0.2878  decode.d2.loss_dice: 0.2060  decode.d3.loss_cls: 0.1468  decode.d3.loss_mask: 0.2738  decode.d3.loss_dice: 0.2057  decode.d4.loss_cls: 0.1676  decode.d4.loss_mask: 0.2621  decode.d4.loss_dice: 0.2015  decode.d5.loss_cls: 0.1591  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.2228  decode.d6.loss_mask: 0.2660  decode.d6.loss_dice: 0.2058  decode.d7.loss_cls: 0.2074  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.1820  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 0.2628  decode.d8.loss_dice: 0.1995
09/30 11:22:34 - mmengine - INFO - Iter(train) [ 19350/320000]  base_lr: 9.4541e-05 lr: 9.4541e-06  eta: 1 day, 12:07:46  time: 0.4324  data_time: 0.0090  memory: 5161  grad_norm: 58.6948  loss: 6.8112  decode.loss_cls: 0.1956  decode.loss_mask: 0.2362  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.8900  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.2197  decode.d1.loss_cls: 0.2542  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.1695  decode.d2.loss_cls: 0.1753  decode.d2.loss_mask: 0.2386  decode.d2.loss_dice: 0.2087  decode.d3.loss_cls: 0.1319  decode.d3.loss_mask: 0.2376  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.1887  decode.d5.loss_cls: 0.1227  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.1916  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.2404  decode.d6.loss_dice: 0.2132  decode.d7.loss_cls: 0.1806  decode.d7.loss_mask: 0.2413  decode.d7.loss_dice: 0.1946  decode.d8.loss_cls: 0.2369  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.1814
09/30 11:22:56 - mmengine - INFO - Iter(train) [ 19400/320000]  base_lr: 9.4527e-05 lr: 9.4527e-06  eta: 1 day, 12:07:28  time: 0.4492  data_time: 0.0090  memory: 5161  grad_norm: 178.8273  loss: 9.0537  decode.loss_cls: 0.0849  decode.loss_mask: 0.4709  decode.loss_dice: 0.2554  decode.d0.loss_cls: 0.9110  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.2320  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.2325  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 0.3218  decode.d2.loss_dice: 0.2356  decode.d3.loss_cls: 0.1506  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.2303  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.5033  decode.d4.loss_dice: 0.2634  decode.d5.loss_cls: 0.1611  decode.d5.loss_mask: 0.5881  decode.d5.loss_dice: 0.2761  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.4806  decode.d6.loss_dice: 0.2631  decode.d7.loss_cls: 0.1327  decode.d7.loss_mask: 0.5054  decode.d7.loss_dice: 0.2668  decode.d8.loss_cls: 0.1949  decode.d8.loss_mask: 0.5358  decode.d8.loss_dice: 0.2977
09/30 11:23:18 - mmengine - INFO - Iter(train) [ 19450/320000]  base_lr: 9.4513e-05 lr: 9.4513e-06  eta: 1 day, 12:07:06  time: 0.4333  data_time: 0.0093  memory: 5180  grad_norm: 63.8308  loss: 6.9131  decode.loss_cls: 0.1129  decode.loss_mask: 0.2583  decode.loss_dice: 0.1869  decode.d0.loss_cls: 0.9765  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.1764  decode.d1.loss_cls: 0.2115  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.1683  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.1513  decode.d3.loss_mask: 0.2575  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.1973  decode.d5.loss_cls: 0.2304  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.1968  decode.d6.loss_cls: 0.2008  decode.d6.loss_mask: 0.2491  decode.d6.loss_dice: 0.1849  decode.d7.loss_cls: 0.1078  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.2002  decode.d8.loss_cls: 0.1257  decode.d8.loss_mask: 0.2471  decode.d8.loss_dice: 0.1882
09/30 11:23:40 - mmengine - INFO - Iter(train) [ 19500/320000]  base_lr: 9.4499e-05 lr: 9.4499e-06  eta: 1 day, 12:06:45  time: 0.4331  data_time: 0.0092  memory: 5146  grad_norm: 140.5923  loss: 9.7796  decode.loss_cls: 0.2980  decode.loss_mask: 0.3685  decode.loss_dice: 0.2926  decode.d0.loss_cls: 1.0009  decode.d0.loss_mask: 0.3627  decode.d0.loss_dice: 0.2850  decode.d1.loss_cls: 0.2142  decode.d1.loss_mask: 0.3534  decode.d1.loss_dice: 0.2645  decode.d2.loss_cls: 0.3261  decode.d2.loss_mask: 0.3517  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.2575  decode.d3.loss_mask: 0.3539  decode.d3.loss_dice: 0.2488  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 0.3691  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.2691  decode.d5.loss_mask: 0.3487  decode.d5.loss_dice: 0.2589  decode.d6.loss_cls: 0.3299  decode.d6.loss_mask: 0.3466  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.2826  decode.d7.loss_mask: 0.3482  decode.d7.loss_dice: 0.2904  decode.d8.loss_cls: 0.2727  decode.d8.loss_mask: 0.3363  decode.d8.loss_dice: 0.2883
09/30 11:24:01 - mmengine - INFO - Iter(train) [ 19550/320000]  base_lr: 9.4485e-05 lr: 9.4485e-06  eta: 1 day, 12:06:24  time: 0.4329  data_time: 0.0093  memory: 5161  grad_norm: 84.7236  loss: 7.9620  decode.loss_cls: 0.2579  decode.loss_mask: 0.2852  decode.loss_dice: 0.2167  decode.d0.loss_cls: 0.9524  decode.d0.loss_mask: 0.2364  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.2930  decode.d1.loss_mask: 0.2383  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.2677  decode.d2.loss_mask: 0.2572  decode.d2.loss_dice: 0.2163  decode.d3.loss_cls: 0.2919  decode.d3.loss_mask: 0.2672  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.3082  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2062  decode.d5.loss_cls: 0.2839  decode.d5.loss_mask: 0.2485  decode.d5.loss_dice: 0.2141  decode.d6.loss_cls: 0.2350  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.2024  decode.d7.loss_cls: 0.2736  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.2320  decode.d8.loss_mask: 0.2358  decode.d8.loss_dice: 0.1954
09/30 11:24:23 - mmengine - INFO - Iter(train) [ 19600/320000]  base_lr: 9.4470e-05 lr: 9.4470e-06  eta: 1 day, 12:06:03  time: 0.4334  data_time: 0.0091  memory: 5160  grad_norm: 69.0910  loss: 7.4326  decode.loss_cls: 0.2358  decode.loss_mask: 0.2424  decode.loss_dice: 0.2267  decode.d0.loss_cls: 1.1275  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.1738  decode.d1.loss_mask: 0.2424  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.2077  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.1920  decode.d3.loss_cls: 0.1771  decode.d3.loss_mask: 0.2300  decode.d3.loss_dice: 0.1886  decode.d4.loss_cls: 0.1777  decode.d4.loss_mask: 0.2299  decode.d4.loss_dice: 0.1852  decode.d5.loss_cls: 0.1791  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.1930  decode.d6.loss_cls: 0.1862  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.2376  decode.d7.loss_cls: 0.1969  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.1939  decode.d8.loss_cls: 0.1965  decode.d8.loss_mask: 0.2928  decode.d8.loss_dice: 0.2434
09/30 11:24:45 - mmengine - INFO - Iter(train) [ 19650/320000]  base_lr: 9.4456e-05 lr: 9.4456e-06  eta: 1 day, 12:05:42  time: 0.4345  data_time: 0.0094  memory: 5160  grad_norm: 45.7796  loss: 6.6074  decode.loss_cls: 0.1314  decode.loss_mask: 0.2664  decode.loss_dice: 0.2128  decode.d0.loss_cls: 0.8365  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.2108  decode.d1.loss_cls: 0.0864  decode.d1.loss_mask: 0.2662  decode.d1.loss_dice: 0.2148  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.2662  decode.d2.loss_dice: 0.2136  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 0.2683  decode.d3.loss_dice: 0.2197  decode.d4.loss_cls: 0.1362  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.2652  decode.d5.loss_dice: 0.2168  decode.d6.loss_cls: 0.0967  decode.d6.loss_mask: 0.2684  decode.d6.loss_dice: 0.2090  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.2672  decode.d7.loss_dice: 0.2116  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.2701  decode.d8.loss_dice: 0.2122
09/30 11:25:06 - mmengine - INFO - Iter(train) [ 19700/320000]  base_lr: 9.4442e-05 lr: 9.4442e-06  eta: 1 day, 12:05:21  time: 0.4340  data_time: 0.0092  memory: 5160  grad_norm: 130.8534  loss: 9.3726  decode.loss_cls: 0.2024  decode.loss_mask: 0.3437  decode.loss_dice: 0.3325  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.3378  decode.d0.loss_dice: 0.3286  decode.d1.loss_cls: 0.1590  decode.d1.loss_mask: 0.3380  decode.d1.loss_dice: 0.3179  decode.d2.loss_cls: 0.2078  decode.d2.loss_mask: 0.3480  decode.d2.loss_dice: 0.3239  decode.d3.loss_cls: 0.2093  decode.d3.loss_mask: 0.3505  decode.d3.loss_dice: 0.3138  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.3562  decode.d4.loss_dice: 0.3184  decode.d5.loss_cls: 0.1866  decode.d5.loss_mask: 0.3546  decode.d5.loss_dice: 0.3188  decode.d6.loss_cls: 0.1836  decode.d6.loss_mask: 0.3554  decode.d6.loss_dice: 0.3165  decode.d7.loss_cls: 0.2007  decode.d7.loss_mask: 0.3560  decode.d7.loss_dice: 0.3241  decode.d8.loss_cls: 0.2009  decode.d8.loss_mask: 0.3576  decode.d8.loss_dice: 0.3221
09/30 11:25:28 - mmengine - INFO - Iter(train) [ 19750/320000]  base_lr: 9.4428e-05 lr: 9.4428e-06  eta: 1 day, 12:05:00  time: 0.4335  data_time: 0.0093  memory: 5161  grad_norm: 134.0066  loss: 6.5098  decode.loss_cls: 0.0273  decode.loss_mask: 0.3087  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.8571  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.1964  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.2087  decode.d2.loss_cls: 0.1138  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.2021  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.3042  decode.d3.loss_dice: 0.2044  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.3064  decode.d4.loss_dice: 0.2092  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.2203  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.3000  decode.d6.loss_dice: 0.2089  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.3032  decode.d7.loss_dice: 0.2045  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.3079  decode.d8.loss_dice: 0.2174
09/30 11:25:50 - mmengine - INFO - Iter(train) [ 19800/320000]  base_lr: 9.4414e-05 lr: 9.4414e-06  eta: 1 day, 12:04:38  time: 0.4334  data_time: 0.0091  memory: 5146  grad_norm: 96.6200  loss: 6.8965  decode.loss_cls: 0.1430  decode.loss_mask: 0.2815  decode.loss_dice: 0.2098  decode.d0.loss_cls: 0.8816  decode.d0.loss_mask: 0.2811  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.2820  decode.d1.loss_dice: 0.2061  decode.d2.loss_cls: 0.1479  decode.d2.loss_mask: 0.2810  decode.d2.loss_dice: 0.2020  decode.d3.loss_cls: 0.1476  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2031  decode.d4.loss_cls: 0.1422  decode.d4.loss_mask: 0.2815  decode.d4.loss_dice: 0.2094  decode.d5.loss_cls: 0.1338  decode.d5.loss_mask: 0.2772  decode.d5.loss_dice: 0.2027  decode.d6.loss_cls: 0.1152  decode.d6.loss_mask: 0.2766  decode.d6.loss_dice: 0.2008  decode.d7.loss_cls: 0.1142  decode.d7.loss_mask: 0.2795  decode.d7.loss_dice: 0.2103  decode.d8.loss_cls: 0.1534  decode.d8.loss_mask: 0.2741  decode.d8.loss_dice: 0.2006
09/30 11:26:11 - mmengine - INFO - Iter(train) [ 19850/320000]  base_lr: 9.4400e-05 lr: 9.4400e-06  eta: 1 day, 12:04:16  time: 0.4327  data_time: 0.0088  memory: 5147  grad_norm: 180.6898  loss: 11.1350  decode.loss_cls: 0.1976  decode.loss_mask: 0.4203  decode.loss_dice: 0.2502  decode.d0.loss_cls: 0.9472  decode.d0.loss_mask: 0.2651  decode.d0.loss_dice: 0.2263  decode.d1.loss_cls: 0.2803  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.2259  decode.d2.loss_cls: 0.2139  decode.d2.loss_mask: 0.3776  decode.d2.loss_dice: 0.2702  decode.d3.loss_cls: 0.1954  decode.d3.loss_mask: 0.3621  decode.d3.loss_dice: 0.2630  decode.d4.loss_cls: 0.1465  decode.d4.loss_mask: 0.9808  decode.d4.loss_dice: 0.3408  decode.d5.loss_cls: 0.2083  decode.d5.loss_mask: 0.2519  decode.d5.loss_dice: 0.2250  decode.d6.loss_cls: 0.1385  decode.d6.loss_mask: 0.9165  decode.d6.loss_dice: 0.3330  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 0.9501  decode.d7.loss_dice: 0.3450  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.9558  decode.d8.loss_dice: 0.3295
09/30 11:26:33 - mmengine - INFO - Iter(train) [ 19900/320000]  base_lr: 9.4386e-05 lr: 9.4386e-06  eta: 1 day, 12:03:55  time: 0.4336  data_time: 0.0092  memory: 5180  grad_norm: 81.4678  loss: 5.7454  decode.loss_cls: 0.0696  decode.loss_mask: 0.2635  decode.loss_dice: 0.1772  decode.d0.loss_cls: 0.8189  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.1742  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.2634  decode.d1.loss_dice: 0.1726  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.1654  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.2539  decode.d3.loss_dice: 0.1684  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.1717  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.2664  decode.d5.loss_dice: 0.1766  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.1665  decode.d7.loss_cls: 0.0940  decode.d7.loss_mask: 0.2536  decode.d7.loss_dice: 0.1628  decode.d8.loss_cls: 0.0999  decode.d8.loss_mask: 0.2505  decode.d8.loss_dice: 0.1677
09/30 11:26:54 - mmengine - INFO - Iter(train) [ 19950/320000]  base_lr: 9.4371e-05 lr: 9.4371e-06  eta: 1 day, 12:03:33  time: 0.4330  data_time: 0.0093  memory: 5146  grad_norm: 93.9782  loss: 8.4147  decode.loss_cls: 0.0925  decode.loss_mask: 0.3086  decode.loss_dice: 0.2648  decode.d0.loss_cls: 1.0295  decode.d0.loss_mask: 0.3907  decode.d0.loss_dice: 0.2597  decode.d1.loss_cls: 0.1592  decode.d1.loss_mask: 0.3829  decode.d1.loss_dice: 0.2773  decode.d2.loss_cls: 0.1737  decode.d2.loss_mask: 0.3171  decode.d2.loss_dice: 0.2739  decode.d3.loss_cls: 0.1329  decode.d3.loss_mask: 0.3741  decode.d3.loss_dice: 0.2661  decode.d4.loss_cls: 0.1553  decode.d4.loss_mask: 0.3747  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.1164  decode.d5.loss_mask: 0.3690  decode.d5.loss_dice: 0.2529  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 0.3758  decode.d6.loss_dice: 0.2757  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.3725  decode.d7.loss_dice: 0.2701  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.3697  decode.d8.loss_dice: 0.2644
09/30 11:27:16 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:27:16 - mmengine - INFO - Iter(train) [ 20000/320000]  base_lr: 9.4357e-05 lr: 9.4357e-06  eta: 1 day, 12:03:12  time: 0.4331  data_time: 0.0093  memory: 5180  grad_norm: 131.3985  loss: 12.4346  decode.loss_cls: 0.5850  decode.loss_mask: 0.2498  decode.loss_dice: 0.3393  decode.d0.loss_cls: 1.2604  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.3627  decode.d1.loss_cls: 0.6707  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.3419  decode.d2.loss_cls: 0.6446  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.3032  decode.d3.loss_cls: 0.5947  decode.d3.loss_mask: 0.2384  decode.d3.loss_dice: 0.3023  decode.d4.loss_cls: 0.6005  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.3280  decode.d5.loss_cls: 0.6543  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.3036  decode.d6.loss_cls: 0.6332  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.3197  decode.d7.loss_cls: 0.5940  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.5658  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.3223
09/30 11:27:38 - mmengine - INFO - Iter(train) [ 20050/320000]  base_lr: 9.4343e-05 lr: 9.4343e-06  eta: 1 day, 12:02:50  time: 0.4329  data_time: 0.0091  memory: 5147  grad_norm: 63.7715  loss: 8.6367  decode.loss_cls: 0.1318  decode.loss_mask: 0.3418  decode.loss_dice: 0.2489  decode.d0.loss_cls: 1.1250  decode.d0.loss_mask: 0.3531  decode.d0.loss_dice: 0.2516  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 0.3586  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.3474  decode.d2.loss_dice: 0.2567  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 0.3477  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.1564  decode.d4.loss_mask: 0.3437  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.1619  decode.d5.loss_mask: 0.3402  decode.d5.loss_dice: 0.2515  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.3421  decode.d6.loss_dice: 0.2480  decode.d7.loss_cls: 0.1595  decode.d7.loss_mask: 0.3446  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.1466  decode.d8.loss_mask: 0.3518  decode.d8.loss_dice: 0.2480
09/30 11:27:59 - mmengine - INFO - Iter(train) [ 20100/320000]  base_lr: 9.4329e-05 lr: 9.4329e-06  eta: 1 day, 12:02:29  time: 0.4336  data_time: 0.0093  memory: 5160  grad_norm: 92.1140  loss: 8.2386  decode.loss_cls: 0.1850  decode.loss_mask: 0.2892  decode.loss_dice: 0.2471  decode.d0.loss_cls: 0.8722  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.2431  decode.d1.loss_cls: 0.3074  decode.d1.loss_mask: 0.3124  decode.d1.loss_dice: 0.2370  decode.d2.loss_cls: 0.1995  decode.d2.loss_mask: 0.3017  decode.d2.loss_dice: 0.2486  decode.d3.loss_cls: 0.1865  decode.d3.loss_mask: 0.3024  decode.d3.loss_dice: 0.2380  decode.d4.loss_cls: 0.2427  decode.d4.loss_mask: 0.2905  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.2151  decode.d5.loss_mask: 0.2929  decode.d5.loss_dice: 0.2292  decode.d6.loss_cls: 0.2429  decode.d6.loss_mask: 0.2962  decode.d6.loss_dice: 0.2334  decode.d7.loss_cls: 0.2546  decode.d7.loss_mask: 0.2894  decode.d7.loss_dice: 0.2263  decode.d8.loss_cls: 0.2040  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.2271
09/30 11:28:21 - mmengine - INFO - Iter(train) [ 20150/320000]  base_lr: 9.4315e-05 lr: 9.4315e-06  eta: 1 day, 12:02:08  time: 0.4336  data_time: 0.0091  memory: 5161  grad_norm: 82.9189  loss: 7.2218  decode.loss_cls: 0.1013  decode.loss_mask: 0.2332  decode.loss_dice: 0.2727  decode.d0.loss_cls: 1.0868  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.2815  decode.d1.loss_cls: 0.1770  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.2726  decode.d2.loss_cls: 0.1072  decode.d2.loss_mask: 0.2480  decode.d2.loss_dice: 0.2849  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.2778  decode.d4.loss_cls: 0.1050  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.2582  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2716  decode.d6.loss_cls: 0.1037  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2684  decode.d7.loss_cls: 0.0957  decode.d7.loss_mask: 0.2420  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2726
09/30 11:28:43 - mmengine - INFO - Iter(train) [ 20200/320000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 1 day, 12:01:47  time: 0.4336  data_time: 0.0093  memory: 5161  grad_norm: 79.3894  loss: 6.4302  decode.loss_cls: 0.0980  decode.loss_mask: 0.2451  decode.loss_dice: 0.1983  decode.d0.loss_cls: 1.0075  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.1043  decode.d1.loss_mask: 0.2453  decode.d1.loss_dice: 0.2053  decode.d2.loss_cls: 0.1055  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.2041  decode.d3.loss_cls: 0.1082  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2061  decode.d4.loss_cls: 0.1205  decode.d4.loss_mask: 0.2475  decode.d4.loss_dice: 0.1995  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.2447  decode.d5.loss_dice: 0.2046  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2460  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.1056  decode.d7.loss_mask: 0.2442  decode.d7.loss_dice: 0.1982  decode.d8.loss_cls: 0.0854  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.1958
09/30 11:29:04 - mmengine - INFO - Iter(train) [ 20250/320000]  base_lr: 9.4286e-05 lr: 9.4286e-06  eta: 1 day, 12:01:26  time: 0.4339  data_time: 0.0092  memory: 5160  grad_norm: 55.6239  loss: 7.2423  decode.loss_cls: 0.1813  decode.loss_mask: 0.2614  decode.loss_dice: 0.2714  decode.d0.loss_cls: 1.0557  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.2349  decode.d1.loss_cls: 0.1735  decode.d1.loss_mask: 0.2544  decode.d1.loss_dice: 0.2223  decode.d2.loss_cls: 0.1541  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.1418  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.2256  decode.d4.loss_cls: 0.1143  decode.d4.loss_mask: 0.2511  decode.d4.loss_dice: 0.2015  decode.d5.loss_cls: 0.1318  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.2236  decode.d6.loss_cls: 0.1161  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2197  decode.d7.loss_cls: 0.1746  decode.d7.loss_mask: 0.2709  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.1736  decode.d8.loss_mask: 0.2544  decode.d8.loss_dice: 0.2443
09/30 11:29:26 - mmengine - INFO - Iter(train) [ 20300/320000]  base_lr: 9.4272e-05 lr: 9.4272e-06  eta: 1 day, 12:01:05  time: 0.4325  data_time: 0.0090  memory: 5161  grad_norm: 104.6626  loss: 8.5850  decode.loss_cls: 0.1161  decode.loss_mask: 0.4279  decode.loss_dice: 0.2535  decode.d0.loss_cls: 0.8757  decode.d0.loss_mask: 0.3483  decode.d0.loss_dice: 0.2761  decode.d1.loss_cls: 0.1761  decode.d1.loss_mask: 0.4308  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.1596  decode.d2.loss_mask: 0.3421  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.1502  decode.d3.loss_mask: 0.3472  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.0746  decode.d4.loss_mask: 0.4403  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.4377  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.1015  decode.d6.loss_mask: 0.4388  decode.d6.loss_dice: 0.2623  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.4358  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.4287  decode.d8.loss_dice: 0.2574
09/30 11:29:48 - mmengine - INFO - Iter(train) [ 20350/320000]  base_lr: 9.4258e-05 lr: 9.4258e-06  eta: 1 day, 12:00:44  time: 0.4336  data_time: 0.0091  memory: 5161  grad_norm: 66.7055  loss: 7.2235  decode.loss_cls: 0.1116  decode.loss_mask: 0.2781  decode.loss_dice: 0.2271  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.2863  decode.d0.loss_dice: 0.2282  decode.d1.loss_cls: 0.1851  decode.d1.loss_mask: 0.2768  decode.d1.loss_dice: 0.2081  decode.d2.loss_cls: 0.1754  decode.d2.loss_mask: 0.2778  decode.d2.loss_dice: 0.2162  decode.d3.loss_cls: 0.1838  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.2298  decode.d4.loss_cls: 0.1587  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.1352  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2103  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 0.2803  decode.d6.loss_dice: 0.2301  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 0.2808  decode.d7.loss_dice: 0.2166  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.2192
09/30 11:30:09 - mmengine - INFO - Iter(train) [ 20400/320000]  base_lr: 9.4244e-05 lr: 9.4244e-06  eta: 1 day, 12:00:22  time: 0.4336  data_time: 0.0089  memory: 5180  grad_norm: 82.3883  loss: 8.9095  decode.loss_cls: 0.2601  decode.loss_mask: 0.3121  decode.loss_dice: 0.2353  decode.d0.loss_cls: 1.0933  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.2230  decode.d1.loss_cls: 0.3317  decode.d1.loss_mask: 0.2847  decode.d1.loss_dice: 0.2250  decode.d2.loss_cls: 0.2901  decode.d2.loss_mask: 0.2859  decode.d2.loss_dice: 0.2104  decode.d3.loss_cls: 0.2221  decode.d3.loss_mask: 0.3187  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.2552  decode.d4.loss_mask: 0.3084  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.2167  decode.d5.loss_mask: 0.3026  decode.d5.loss_dice: 0.2447  decode.d6.loss_cls: 0.2474  decode.d6.loss_mask: 0.3505  decode.d6.loss_dice: 0.2255  decode.d7.loss_cls: 0.2539  decode.d7.loss_mask: 0.3514  decode.d7.loss_dice: 0.2380  decode.d8.loss_cls: 0.2685  decode.d8.loss_mask: 0.3244  decode.d8.loss_dice: 0.2410
09/30 11:30:31 - mmengine - INFO - Iter(train) [ 20450/320000]  base_lr: 9.4230e-05 lr: 9.4230e-06  eta: 1 day, 12:00:01  time: 0.4331  data_time: 0.0089  memory: 5160  grad_norm: 89.1827  loss: 7.9088  decode.loss_cls: 0.2114  decode.loss_mask: 0.2741  decode.loss_dice: 0.2526  decode.d0.loss_cls: 0.9833  decode.d0.loss_mask: 0.2962  decode.d0.loss_dice: 0.2224  decode.d1.loss_cls: 0.2042  decode.d1.loss_mask: 0.2727  decode.d1.loss_dice: 0.2259  decode.d2.loss_cls: 0.1924  decode.d2.loss_mask: 0.2759  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.2516  decode.d4.loss_cls: 0.1758  decode.d4.loss_mask: 0.2737  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.2738  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.2138  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.2231  decode.d7.loss_mask: 0.2803  decode.d7.loss_dice: 0.2189  decode.d8.loss_cls: 0.2329  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.2506
09/30 11:30:53 - mmengine - INFO - Iter(train) [ 20500/320000]  base_lr: 9.4216e-05 lr: 9.4216e-06  eta: 1 day, 11:59:39  time: 0.4330  data_time: 0.0090  memory: 5146  grad_norm: 94.7219  loss: 10.6182  decode.loss_cls: 0.4359  decode.loss_mask: 0.2251  decode.loss_dice: 0.3049  decode.d0.loss_cls: 0.9527  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.3425  decode.d1.loss_cls: 0.5415  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.3278  decode.d2.loss_cls: 0.4459  decode.d2.loss_mask: 0.2862  decode.d2.loss_dice: 0.3497  decode.d3.loss_cls: 0.3927  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.3311  decode.d4.loss_cls: 0.4196  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.3283  decode.d5.loss_cls: 0.3974  decode.d5.loss_mask: 0.2537  decode.d5.loss_dice: 0.3052  decode.d6.loss_cls: 0.4103  decode.d6.loss_mask: 0.2983  decode.d6.loss_dice: 0.3173  decode.d7.loss_cls: 0.4458  decode.d7.loss_mask: 0.2836  decode.d7.loss_dice: 0.2954  decode.d8.loss_cls: 0.4362  decode.d8.loss_mask: 0.2433  decode.d8.loss_dice: 0.3171
09/30 11:31:14 - mmengine - INFO - Iter(train) [ 20550/320000]  base_lr: 9.4202e-05 lr: 9.4202e-06  eta: 1 day, 11:59:18  time: 0.4324  data_time: 0.0089  memory: 5160  grad_norm: 160.1022  loss: 10.4617  decode.loss_cls: 0.4897  decode.loss_mask: 0.3109  decode.loss_dice: 0.2096  decode.d0.loss_cls: 1.2394  decode.d0.loss_mask: 0.2633  decode.d0.loss_dice: 0.1943  decode.d1.loss_cls: 0.5022  decode.d1.loss_mask: 0.2599  decode.d1.loss_dice: 0.1966  decode.d2.loss_cls: 0.4041  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.4361  decode.d3.loss_mask: 0.2631  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.4929  decode.d4.loss_mask: 0.2666  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.4315  decode.d5.loss_mask: 0.2700  decode.d5.loss_dice: 0.2277  decode.d6.loss_cls: 0.4334  decode.d6.loss_mask: 0.2910  decode.d6.loss_dice: 0.2419  decode.d7.loss_cls: 0.5039  decode.d7.loss_mask: 0.3476  decode.d7.loss_dice: 0.2320  decode.d8.loss_cls: 0.4802  decode.d8.loss_mask: 0.3214  decode.d8.loss_dice: 0.2301
09/30 11:31:36 - mmengine - INFO - Iter(train) [ 20600/320000]  base_lr: 9.4187e-05 lr: 9.4187e-06  eta: 1 day, 11:58:57  time: 0.4334  data_time: 0.0090  memory: 5160  grad_norm: 103.7209  loss: 6.9028  decode.loss_cls: 0.1392  decode.loss_mask: 0.2329  decode.loss_dice: 0.1837  decode.d0.loss_cls: 0.9160  decode.d0.loss_mask: 0.2205  decode.d0.loss_dice: 0.1946  decode.d1.loss_cls: 0.3176  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.2128  decode.d2.loss_cls: 0.2391  decode.d2.loss_mask: 0.2184  decode.d2.loss_dice: 0.1803  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 0.2183  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.2153  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.1798  decode.d5.loss_cls: 0.2103  decode.d5.loss_mask: 0.2171  decode.d5.loss_dice: 0.1769  decode.d6.loss_cls: 0.2125  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.1799  decode.d7.loss_cls: 0.1951  decode.d7.loss_mask: 0.2133  decode.d7.loss_dice: 0.1793  decode.d8.loss_cls: 0.1981  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.1803
09/30 11:31:58 - mmengine - INFO - Iter(train) [ 20650/320000]  base_lr: 9.4173e-05 lr: 9.4173e-06  eta: 1 day, 11:58:36  time: 0.4343  data_time: 0.0092  memory: 5161  grad_norm: 77.8316  loss: 8.3236  decode.loss_cls: 0.3355  decode.loss_mask: 0.2715  decode.loss_dice: 0.2359  decode.d0.loss_cls: 0.9491  decode.d0.loss_mask: 0.2750  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.2725  decode.d1.loss_mask: 0.2690  decode.d1.loss_dice: 0.2352  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 0.2698  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.1884  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.2289  decode.d4.loss_cls: 0.2365  decode.d4.loss_mask: 0.2713  decode.d4.loss_dice: 0.2250  decode.d5.loss_cls: 0.2613  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2277  decode.d6.loss_cls: 0.2703  decode.d6.loss_mask: 0.2714  decode.d6.loss_dice: 0.2319  decode.d7.loss_cls: 0.2698  decode.d7.loss_mask: 0.2780  decode.d7.loss_dice: 0.2356  decode.d8.loss_cls: 0.2520  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.2327
09/30 11:32:19 - mmengine - INFO - Iter(train) [ 20700/320000]  base_lr: 9.4159e-05 lr: 9.4159e-06  eta: 1 day, 11:58:15  time: 0.4322  data_time: 0.0088  memory: 5161  grad_norm: 127.2674  loss: 6.0150  decode.loss_cls: 0.1352  decode.loss_mask: 0.2023  decode.loss_dice: 0.1824  decode.d0.loss_cls: 0.8490  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.1986  decode.d1.loss_cls: 0.2107  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.1917  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.1714  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 0.2079  decode.d3.loss_dice: 0.1759  decode.d4.loss_cls: 0.1463  decode.d4.loss_mask: 0.2046  decode.d4.loss_dice: 0.1741  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.2007  decode.d5.loss_dice: 0.1719  decode.d6.loss_cls: 0.1536  decode.d6.loss_mask: 0.2006  decode.d6.loss_dice: 0.1770  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.1755  decode.d8.loss_cls: 0.1352  decode.d8.loss_mask: 0.2024  decode.d8.loss_dice: 0.1734
09/30 11:32:41 - mmengine - INFO - Iter(train) [ 20750/320000]  base_lr: 9.4145e-05 lr: 9.4145e-06  eta: 1 day, 11:57:53  time: 0.4326  data_time: 0.0089  memory: 5147  grad_norm: 53.8924  loss: 6.3494  decode.loss_cls: 0.1577  decode.loss_mask: 0.2075  decode.loss_dice: 0.1850  decode.d0.loss_cls: 1.0849  decode.d0.loss_mask: 0.2162  decode.d0.loss_dice: 0.2090  decode.d1.loss_cls: 0.1697  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1869  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.2052  decode.d2.loss_dice: 0.1815  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 0.2060  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.1656  decode.d4.loss_mask: 0.2088  decode.d4.loss_dice: 0.1830  decode.d5.loss_cls: 0.1531  decode.d5.loss_mask: 0.2023  decode.d5.loss_dice: 0.1809  decode.d6.loss_cls: 0.1436  decode.d6.loss_mask: 0.2065  decode.d6.loss_dice: 0.1818  decode.d7.loss_cls: 0.1191  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.1318  decode.d8.loss_mask: 0.2067  decode.d8.loss_dice: 0.1846
09/30 11:33:03 - mmengine - INFO - Iter(train) [ 20800/320000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 1 day, 11:57:32  time: 0.4319  data_time: 0.0089  memory: 5180  grad_norm: 68.3741  loss: 9.0323  decode.loss_cls: 0.2353  decode.loss_mask: 0.2948  decode.loss_dice: 0.2436  decode.d0.loss_cls: 1.1601  decode.d0.loss_mask: 0.3114  decode.d0.loss_dice: 0.2594  decode.d1.loss_cls: 0.2855  decode.d1.loss_mask: 0.3133  decode.d1.loss_dice: 0.2632  decode.d2.loss_cls: 0.2790  decode.d2.loss_mask: 0.3118  decode.d2.loss_dice: 0.2644  decode.d3.loss_cls: 0.2893  decode.d3.loss_mask: 0.3089  decode.d3.loss_dice: 0.2461  decode.d4.loss_cls: 0.2862  decode.d4.loss_mask: 0.3005  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.2443  decode.d5.loss_mask: 0.2984  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.2330  decode.d6.loss_mask: 0.2988  decode.d6.loss_dice: 0.2406  decode.d7.loss_cls: 0.2475  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.2646  decode.d8.loss_cls: 0.2399  decode.d8.loss_mask: 0.2958  decode.d8.loss_dice: 0.2459
09/30 11:33:24 - mmengine - INFO - Iter(train) [ 20850/320000]  base_lr: 9.4117e-05 lr: 9.4117e-06  eta: 1 day, 11:57:10  time: 0.4324  data_time: 0.0088  memory: 5161  grad_norm: 374.7635  loss: 10.6628  decode.loss_cls: 0.2682  decode.loss_mask: 0.3879  decode.loss_dice: 0.3052  decode.d0.loss_cls: 1.0051  decode.d0.loss_mask: 0.3822  decode.d0.loss_dice: 0.2832  decode.d1.loss_cls: 0.4296  decode.d1.loss_mask: 0.3804  decode.d1.loss_dice: 0.2827  decode.d2.loss_cls: 0.3801  decode.d2.loss_mask: 0.3947  decode.d2.loss_dice: 0.2832  decode.d3.loss_cls: 0.3246  decode.d3.loss_mask: 0.3992  decode.d3.loss_dice: 0.3098  decode.d4.loss_cls: 0.3183  decode.d4.loss_mask: 0.3858  decode.d4.loss_dice: 0.2910  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 0.3979  decode.d5.loss_dice: 0.2973  decode.d6.loss_cls: 0.2502  decode.d6.loss_mask: 0.3990  decode.d6.loss_dice: 0.3096  decode.d7.loss_cls: 0.2639  decode.d7.loss_mask: 0.3966  decode.d7.loss_dice: 0.3060  decode.d8.loss_cls: 0.2887  decode.d8.loss_mask: 0.3881  decode.d8.loss_dice: 0.2913
09/30 11:33:46 - mmengine - INFO - Iter(train) [ 20900/320000]  base_lr: 9.4102e-05 lr: 9.4102e-06  eta: 1 day, 11:56:49  time: 0.4329  data_time: 0.0092  memory: 5160  grad_norm: 106.3181  loss: 9.4079  decode.loss_cls: 0.1034  decode.loss_mask: 0.4373  decode.loss_dice: 0.3019  decode.d0.loss_cls: 0.9290  decode.d0.loss_mask: 0.4250  decode.d0.loss_dice: 0.3155  decode.d1.loss_cls: 0.1136  decode.d1.loss_mask: 0.4482  decode.d1.loss_dice: 0.3373  decode.d2.loss_cls: 0.2357  decode.d2.loss_mask: 0.3990  decode.d2.loss_dice: 0.3026  decode.d3.loss_cls: 0.1173  decode.d3.loss_mask: 0.4401  decode.d3.loss_dice: 0.2992  decode.d4.loss_cls: 0.1397  decode.d4.loss_mask: 0.4425  decode.d4.loss_dice: 0.3057  decode.d5.loss_cls: 0.1234  decode.d5.loss_mask: 0.4418  decode.d5.loss_dice: 0.2953  decode.d6.loss_cls: 0.0865  decode.d6.loss_mask: 0.4389  decode.d6.loss_dice: 0.2962  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 0.4417  decode.d7.loss_dice: 0.2974  decode.d8.loss_cls: 0.0933  decode.d8.loss_mask: 0.4328  decode.d8.loss_dice: 0.2982
09/30 11:34:08 - mmengine - INFO - Iter(train) [ 20950/320000]  base_lr: 9.4088e-05 lr: 9.4088e-06  eta: 1 day, 11:56:27  time: 0.4331  data_time: 0.0092  memory: 5160  grad_norm: 43.8762  loss: 6.0413  decode.loss_cls: 0.1159  decode.loss_mask: 0.2367  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.8745  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.1865  decode.d1.loss_cls: 0.1633  decode.d1.loss_mask: 0.2362  decode.d1.loss_dice: 0.1889  decode.d2.loss_cls: 0.1020  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 0.2367  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.1847  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.1833  decode.d6.loss_cls: 0.0911  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.1787  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.2360  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0990  decode.d8.loss_mask: 0.2350  decode.d8.loss_dice: 0.1855
09/30 11:34:29 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:34:29 - mmengine - INFO - Iter(train) [ 21000/320000]  base_lr: 9.4074e-05 lr: 9.4074e-06  eta: 1 day, 11:56:06  time: 0.4327  data_time: 0.0091  memory: 5160  grad_norm: 70.2765  loss: 6.7635  decode.loss_cls: 0.0671  decode.loss_mask: 0.3349  decode.loss_dice: 0.2012  decode.d0.loss_cls: 0.8646  decode.d0.loss_mask: 0.3332  decode.d0.loss_dice: 0.1940  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.3365  decode.d1.loss_dice: 0.1907  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.3338  decode.d2.loss_dice: 0.1953  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.3299  decode.d3.loss_dice: 0.1986  decode.d4.loss_cls: 0.0756  decode.d4.loss_mask: 0.3350  decode.d4.loss_dice: 0.1987  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0568  decode.d6.loss_mask: 0.3242  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.2006  decode.d8.loss_cls: 0.0524  decode.d8.loss_mask: 0.3370  decode.d8.loss_dice: 0.1971
09/30 11:34:51 - mmengine - INFO - Iter(train) [ 21050/320000]  base_lr: 9.4060e-05 lr: 9.4060e-06  eta: 1 day, 11:55:47  time: 0.4511  data_time: 0.0089  memory: 5161  grad_norm: 35.2622  loss: 6.1006  decode.loss_cls: 0.0947  decode.loss_mask: 0.2322  decode.loss_dice: 0.1759  decode.d0.loss_cls: 0.8438  decode.d0.loss_mask: 0.2376  decode.d0.loss_dice: 0.1770  decode.d1.loss_cls: 0.1667  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.1725  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 0.2374  decode.d2.loss_dice: 0.1744  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.1342  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.1729  decode.d6.loss_cls: 0.1366  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.1768  decode.d7.loss_cls: 0.1267  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.1771  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.1799
09/30 11:35:13 - mmengine - INFO - Iter(train) [ 21100/320000]  base_lr: 9.4046e-05 lr: 9.4046e-06  eta: 1 day, 11:55:25  time: 0.4337  data_time: 0.0094  memory: 5161  grad_norm: 65.2131  loss: 6.6281  decode.loss_cls: 0.0932  decode.loss_mask: 0.2677  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.8690  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.2400  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.2829  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.0429  decode.d2.loss_mask: 0.2728  decode.d2.loss_dice: 0.2462  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2741  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.2680  decode.d4.loss_dice: 0.2389  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.2648  decode.d5.loss_dice: 0.2334  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.2657  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2426
09/30 11:35:34 - mmengine - INFO - Iter(train) [ 21150/320000]  base_lr: 9.4032e-05 lr: 9.4032e-06  eta: 1 day, 11:55:04  time: 0.4330  data_time: 0.0090  memory: 5161  grad_norm: 127.6505  loss: 6.2959  decode.loss_cls: 0.0565  decode.loss_mask: 0.2678  decode.loss_dice: 0.1953  decode.d0.loss_cls: 0.9301  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.1886  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.2844  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.2798  decode.d2.loss_dice: 0.1902  decode.d3.loss_cls: 0.0589  decode.d3.loss_mask: 0.2721  decode.d3.loss_dice: 0.1841  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.2699  decode.d4.loss_dice: 0.1858  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.2814  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.2777  decode.d6.loss_dice: 0.2059  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.2749  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.3759  decode.d8.loss_dice: 0.2283
09/30 11:35:56 - mmengine - INFO - Iter(train) [ 21200/320000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 1 day, 11:54:43  time: 0.4325  data_time: 0.0091  memory: 5161  grad_norm: 113.2268  loss: 8.5316  decode.loss_cls: 0.2629  decode.loss_mask: 0.2920  decode.loss_dice: 0.2788  decode.d0.loss_cls: 0.8305  decode.d0.loss_mask: 0.2968  decode.d0.loss_dice: 0.2956  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.2625  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 0.2901  decode.d2.loss_dice: 0.2824  decode.d3.loss_cls: 0.2128  decode.d3.loss_mask: 0.2913  decode.d3.loss_dice: 0.2808  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 0.3005  decode.d4.loss_dice: 0.3028  decode.d5.loss_cls: 0.1868  decode.d5.loss_mask: 0.2920  decode.d5.loss_dice: 0.2807  decode.d6.loss_cls: 0.2163  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.2109  decode.d7.loss_mask: 0.2909  decode.d7.loss_dice: 0.2687  decode.d8.loss_cls: 0.2458  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.2866
09/30 11:36:18 - mmengine - INFO - Iter(train) [ 21250/320000]  base_lr: 9.4003e-05 lr: 9.4003e-06  eta: 1 day, 11:54:22  time: 0.4343  data_time: 0.0093  memory: 5180  grad_norm: 114.3005  loss: 7.8421  decode.loss_cls: 0.1140  decode.loss_mask: 0.3190  decode.loss_dice: 0.2837  decode.d0.loss_cls: 0.8686  decode.d0.loss_mask: 0.3177  decode.d0.loss_dice: 0.2684  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.3175  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.1651  decode.d2.loss_mask: 0.3236  decode.d2.loss_dice: 0.2703  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.3189  decode.d3.loss_dice: 0.2644  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 0.3178  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.3189  decode.d5.loss_dice: 0.2638  decode.d6.loss_cls: 0.1119  decode.d6.loss_mask: 0.3158  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.3168  decode.d7.loss_dice: 0.2726  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.3365  decode.d8.loss_dice: 0.2871
09/30 11:36:39 - mmengine - INFO - Iter(train) [ 21300/320000]  base_lr: 9.3989e-05 lr: 9.3989e-06  eta: 1 day, 11:54:01  time: 0.4335  data_time: 0.0092  memory: 5180  grad_norm: 209.8446  loss: 11.7129  decode.loss_cls: 0.3770  decode.loss_mask: 0.3539  decode.loss_dice: 0.3411  decode.d0.loss_cls: 1.1527  decode.d0.loss_mask: 0.3315  decode.d0.loss_dice: 0.3676  decode.d1.loss_cls: 0.4425  decode.d1.loss_mask: 0.3248  decode.d1.loss_dice: 0.3065  decode.d2.loss_cls: 0.4335  decode.d2.loss_mask: 0.3237  decode.d2.loss_dice: 0.3169  decode.d3.loss_cls: 0.4009  decode.d3.loss_mask: 0.3670  decode.d3.loss_dice: 0.3522  decode.d4.loss_cls: 0.4185  decode.d4.loss_mask: 0.3564  decode.d4.loss_dice: 0.3361  decode.d5.loss_cls: 0.4236  decode.d5.loss_mask: 0.3153  decode.d5.loss_dice: 0.2999  decode.d6.loss_cls: 0.4959  decode.d6.loss_mask: 0.3300  decode.d6.loss_dice: 0.3368  decode.d7.loss_cls: 0.4443  decode.d7.loss_mask: 0.3143  decode.d7.loss_dice: 0.3255  decode.d8.loss_cls: 0.4340  decode.d8.loss_mask: 0.3582  decode.d8.loss_dice: 0.3322
09/30 11:37:01 - mmengine - INFO - Iter(train) [ 21350/320000]  base_lr: 9.3975e-05 lr: 9.3975e-06  eta: 1 day, 11:53:40  time: 0.4343  data_time: 0.0094  memory: 5147  grad_norm: 98.3962  loss: 7.4238  decode.loss_cls: 0.2322  decode.loss_mask: 0.2374  decode.loss_dice: 0.1860  decode.d0.loss_cls: 0.9607  decode.d0.loss_mask: 0.2473  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.3079  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.1784  decode.d3.loss_cls: 0.2849  decode.d3.loss_mask: 0.2376  decode.d3.loss_dice: 0.1720  decode.d4.loss_cls: 0.2394  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.1784  decode.d5.loss_cls: 0.2340  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.1736  decode.d6.loss_cls: 0.2281  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.1762  decode.d7.loss_cls: 0.2308  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.1910  decode.d8.loss_cls: 0.2447  decode.d8.loss_mask: 0.2371  decode.d8.loss_dice: 0.1922
09/30 11:37:23 - mmengine - INFO - Iter(train) [ 21400/320000]  base_lr: 9.3961e-05 lr: 9.3961e-06  eta: 1 day, 11:53:19  time: 0.4333  data_time: 0.0092  memory: 5161  grad_norm: 54.8536  loss: 6.5559  decode.loss_cls: 0.0336  decode.loss_mask: 0.2339  decode.loss_dice: 0.2525  decode.d0.loss_cls: 0.9919  decode.d0.loss_mask: 0.2306  decode.d0.loss_dice: 0.2149  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.2358  decode.d2.loss_cls: 0.1796  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.1299  decode.d3.loss_mask: 0.2273  decode.d3.loss_dice: 0.2183  decode.d4.loss_cls: 0.1775  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.1077  decode.d5.loss_mask: 0.2303  decode.d5.loss_dice: 0.2387  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2453  decode.d8.loss_cls: 0.1098  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2038
09/30 11:37:45 - mmengine - INFO - Iter(train) [ 21450/320000]  base_lr: 9.3947e-05 lr: 9.3947e-06  eta: 1 day, 11:52:58  time: 0.4344  data_time: 0.0094  memory: 5161  grad_norm: 75.8094  loss: 5.7427  decode.loss_cls: 0.0702  decode.loss_mask: 0.2091  decode.loss_dice: 0.1934  decode.d0.loss_cls: 0.8370  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1925  decode.d2.loss_cls: 0.1115  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.1964  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.2107  decode.d3.loss_dice: 0.1892  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.2145  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.2085  decode.d5.loss_dice: 0.1940  decode.d6.loss_cls: 0.1096  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.2011  decode.d7.loss_cls: 0.0936  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1933  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.2087  decode.d8.loss_dice: 0.1944
09/30 11:38:06 - mmengine - INFO - Iter(train) [ 21500/320000]  base_lr: 9.3933e-05 lr: 9.3933e-06  eta: 1 day, 11:52:37  time: 0.4341  data_time: 0.0091  memory: 5145  grad_norm: 50.5855  loss: 7.2027  decode.loss_cls: 0.0745  decode.loss_mask: 0.3027  decode.loss_dice: 0.2711  decode.d0.loss_cls: 0.7065  decode.d0.loss_mask: 0.3044  decode.d0.loss_dice: 0.2676  decode.d1.loss_cls: 0.1512  decode.d1.loss_mask: 0.2986  decode.d1.loss_dice: 0.2365  decode.d2.loss_cls: 0.1286  decode.d2.loss_mask: 0.3006  decode.d2.loss_dice: 0.2310  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.3023  decode.d3.loss_dice: 0.2651  decode.d4.loss_cls: 0.1133  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.1146  decode.d5.loss_mask: 0.2967  decode.d5.loss_dice: 0.2422  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.3030  decode.d6.loss_dice: 0.2588  decode.d7.loss_cls: 0.0999  decode.d7.loss_mask: 0.3023  decode.d7.loss_dice: 0.2654  decode.d8.loss_cls: 0.1030  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.2341
09/30 11:38:28 - mmengine - INFO - Iter(train) [ 21550/320000]  base_lr: 9.3918e-05 lr: 9.3918e-06  eta: 1 day, 11:52:16  time: 0.4341  data_time: 0.0091  memory: 5147  grad_norm: 37.3453  loss: 5.8596  decode.loss_cls: 0.1276  decode.loss_mask: 0.2429  decode.loss_dice: 0.1584  decode.d0.loss_cls: 0.8544  decode.d0.loss_mask: 0.2473  decode.d0.loss_dice: 0.1546  decode.d1.loss_cls: 0.1215  decode.d1.loss_mask: 0.2418  decode.d1.loss_dice: 0.1588  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.1545  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.2474  decode.d3.loss_dice: 0.1523  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.2549  decode.d4.loss_dice: 0.1531  decode.d5.loss_cls: 0.1023  decode.d5.loss_mask: 0.2478  decode.d5.loss_dice: 0.1534  decode.d6.loss_cls: 0.1086  decode.d6.loss_mask: 0.2436  decode.d6.loss_dice: 0.1530  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 0.2465  decode.d7.loss_dice: 0.1511  decode.d8.loss_cls: 0.1197  decode.d8.loss_mask: 0.2469  decode.d8.loss_dice: 0.1590
09/30 11:38:50 - mmengine - INFO - Iter(train) [ 21600/320000]  base_lr: 9.3904e-05 lr: 9.3904e-06  eta: 1 day, 11:51:56  time: 0.4337  data_time: 0.0092  memory: 5180  grad_norm: 35.5200  loss: 7.0382  decode.loss_cls: 0.1521  decode.loss_mask: 0.2240  decode.loss_dice: 0.2538  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 0.2281  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.1599  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2401  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 0.2257  decode.d2.loss_dice: 0.2384  decode.d3.loss_cls: 0.1636  decode.d3.loss_mask: 0.2227  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.2513  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.1721  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.1598  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.2473  decode.d8.loss_cls: 0.1418  decode.d8.loss_mask: 0.2232  decode.d8.loss_dice: 0.2489
09/30 11:39:11 - mmengine - INFO - Iter(train) [ 21650/320000]  base_lr: 9.3890e-05 lr: 9.3890e-06  eta: 1 day, 11:51:35  time: 0.4338  data_time: 0.0093  memory: 5161  grad_norm: 49.3719  loss: 6.9812  decode.loss_cls: 0.1090  decode.loss_mask: 0.2869  decode.loss_dice: 0.2221  decode.d0.loss_cls: 0.8942  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.2098  decode.d1.loss_cls: 0.1268  decode.d1.loss_mask: 0.2904  decode.d1.loss_dice: 0.2320  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.2941  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.1353  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.2226  decode.d4.loss_cls: 0.0958  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.2266  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.2223  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.2126  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.2193  decode.d8.loss_cls: 0.1010  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.2131
09/30 11:39:33 - mmengine - INFO - Iter(train) [ 21700/320000]  base_lr: 9.3876e-05 lr: 9.3876e-06  eta: 1 day, 11:51:14  time: 0.4328  data_time: 0.0092  memory: 5160  grad_norm: 98.0631  loss: 8.6260  decode.loss_cls: 0.2601  decode.loss_mask: 0.3353  decode.loss_dice: 0.2303  decode.d0.loss_cls: 0.9026  decode.d0.loss_mask: 0.3500  decode.d0.loss_dice: 0.2285  decode.d1.loss_cls: 0.2727  decode.d1.loss_mask: 0.3399  decode.d1.loss_dice: 0.2233  decode.d2.loss_cls: 0.2123  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.2396  decode.d3.loss_cls: 0.2628  decode.d3.loss_mask: 0.3353  decode.d3.loss_dice: 0.2366  decode.d4.loss_cls: 0.2336  decode.d4.loss_mask: 0.3374  decode.d4.loss_dice: 0.2347  decode.d5.loss_cls: 0.1659  decode.d5.loss_mask: 0.3455  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.1985  decode.d6.loss_mask: 0.3371  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.2367  decode.d7.loss_mask: 0.3365  decode.d7.loss_dice: 0.2167  decode.d8.loss_cls: 0.2053  decode.d8.loss_mask: 0.3357  decode.d8.loss_dice: 0.2326
09/30 11:39:55 - mmengine - INFO - Iter(train) [ 21750/320000]  base_lr: 9.3862e-05 lr: 9.3862e-06  eta: 1 day, 11:50:53  time: 0.4342  data_time: 0.0093  memory: 5161  grad_norm: 55.9970  loss: 7.3156  decode.loss_cls: 0.0791  decode.loss_mask: 0.3524  decode.loss_dice: 0.2136  decode.d0.loss_cls: 1.0399  decode.d0.loss_mask: 0.2941  decode.d0.loss_dice: 0.2323  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.3545  decode.d1.loss_dice: 0.2132  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.3612  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.3534  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.3589  decode.d4.loss_dice: 0.2132  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.3555  decode.d5.loss_dice: 0.2110  decode.d6.loss_cls: 0.0670  decode.d6.loss_mask: 0.3516  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.0744  decode.d7.loss_mask: 0.3558  decode.d7.loss_dice: 0.2254  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.3549  decode.d8.loss_dice: 0.2149
09/30 11:40:16 - mmengine - INFO - Iter(train) [ 21800/320000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 1 day, 11:50:32  time: 0.4344  data_time: 0.0093  memory: 5147  grad_norm: 77.5487  loss: 5.3700  decode.loss_cls: 0.0942  decode.loss_mask: 0.2127  decode.loss_dice: 0.1479  decode.d0.loss_cls: 0.8199  decode.d0.loss_mask: 0.2141  decode.d0.loss_dice: 0.1526  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.2167  decode.d1.loss_dice: 0.1486  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 0.2126  decode.d2.loss_dice: 0.1465  decode.d3.loss_cls: 0.0930  decode.d3.loss_mask: 0.2130  decode.d3.loss_dice: 0.1460  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.1494  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.2097  decode.d5.loss_dice: 0.1475  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.1489  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 0.2111  decode.d7.loss_dice: 0.1456  decode.d8.loss_cls: 0.1200  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.1466
09/30 11:40:38 - mmengine - INFO - Iter(train) [ 21850/320000]  base_lr: 9.3833e-05 lr: 9.3833e-06  eta: 1 day, 11:50:11  time: 0.4330  data_time: 0.0093  memory: 5160  grad_norm: 54.3700  loss: 8.6662  decode.loss_cls: 0.1962  decode.loss_mask: 0.2626  decode.loss_dice: 0.2625  decode.d0.loss_cls: 0.9894  decode.d0.loss_mask: 0.2803  decode.d0.loss_dice: 0.2668  decode.d1.loss_cls: 0.2838  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.2493  decode.d2.loss_cls: 0.2969  decode.d2.loss_mask: 0.3343  decode.d2.loss_dice: 0.2623  decode.d3.loss_cls: 0.3207  decode.d3.loss_mask: 0.2606  decode.d3.loss_dice: 0.2507  decode.d4.loss_cls: 0.2679  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.2393  decode.d5.loss_cls: 0.2777  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.2529  decode.d6.loss_cls: 0.2331  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.1998  decode.d7.loss_mask: 0.3421  decode.d7.loss_dice: 0.2645  decode.d8.loss_cls: 0.1475  decode.d8.loss_mask: 0.3355  decode.d8.loss_dice: 0.2672
09/30 11:41:00 - mmengine - INFO - Iter(train) [ 21900/320000]  base_lr: 9.3819e-05 lr: 9.3819e-06  eta: 1 day, 11:49:50  time: 0.4332  data_time: 0.0092  memory: 5146  grad_norm: 72.0296  loss: 7.2294  decode.loss_cls: 0.1435  decode.loss_mask: 0.2561  decode.loss_dice: 0.1847  decode.d0.loss_cls: 0.9517  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.1986  decode.d1.loss_mask: 0.2666  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.2045  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.1808  decode.d3.loss_cls: 0.2033  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.2319  decode.d4.loss_cls: 0.2156  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2238  decode.d5.loss_cls: 0.1837  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.2130  decode.d6.loss_cls: 0.2199  decode.d6.loss_mask: 0.2486  decode.d6.loss_dice: 0.1854  decode.d7.loss_cls: 0.2067  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.1810  decode.d8.loss_cls: 0.1569  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.1932
09/30 11:41:22 - mmengine - INFO - Iter(train) [ 21950/320000]  base_lr: 9.3805e-05 lr: 9.3805e-06  eta: 1 day, 11:49:30  time: 0.4338  data_time: 0.0090  memory: 5145  grad_norm: 76.9655  loss: 6.8328  decode.loss_cls: 0.1007  decode.loss_mask: 0.2124  decode.loss_dice: 0.2225  decode.d0.loss_cls: 1.1438  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2570  decode.d1.loss_cls: 0.2055  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.2059  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 0.2246  decode.d2.loss_dice: 0.2296  decode.d3.loss_cls: 0.0971  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.2036  decode.d4.loss_cls: 0.1095  decode.d4.loss_mask: 0.2198  decode.d4.loss_dice: 0.2179  decode.d5.loss_cls: 0.1204  decode.d5.loss_mask: 0.2187  decode.d5.loss_dice: 0.2489  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.2180  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.1575  decode.d8.loss_mask: 0.2173  decode.d8.loss_dice: 0.2562
09/30 11:41:43 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:41:43 - mmengine - INFO - Iter(train) [ 22000/320000]  base_lr: 9.3791e-05 lr: 9.3791e-06  eta: 1 day, 11:49:09  time: 0.4343  data_time: 0.0093  memory: 5161  grad_norm: 70.3655  loss: 5.9270  decode.loss_cls: 0.0878  decode.loss_mask: 0.2284  decode.loss_dice: 0.1910  decode.d0.loss_cls: 0.7623  decode.d0.loss_mask: 0.2384  decode.d0.loss_dice: 0.2315  decode.d1.loss_cls: 0.1145  decode.d1.loss_mask: 0.2328  decode.d1.loss_dice: 0.2005  decode.d2.loss_cls: 0.0849  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0806  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.1966  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2150  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.2042  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.2277  decode.d6.loss_dice: 0.1909  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.0931  decode.d8.loss_mask: 0.2342  decode.d8.loss_dice: 0.2492
09/30 11:42:05 - mmengine - INFO - Iter(train) [ 22050/320000]  base_lr: 9.3777e-05 lr: 9.3777e-06  eta: 1 day, 11:48:49  time: 0.4344  data_time: 0.0093  memory: 5180  grad_norm: 50.4717  loss: 7.9038  decode.loss_cls: 0.1659  decode.loss_mask: 0.3022  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.9167  decode.d0.loss_mask: 0.3150  decode.d0.loss_dice: 0.2550  decode.d1.loss_cls: 0.2095  decode.d1.loss_mask: 0.3022  decode.d1.loss_dice: 0.2219  decode.d2.loss_cls: 0.1499  decode.d2.loss_mask: 0.3039  decode.d2.loss_dice: 0.2522  decode.d3.loss_cls: 0.1448  decode.d3.loss_mask: 0.3045  decode.d3.loss_dice: 0.2481  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.2714  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.3039  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.1372  decode.d6.loss_mask: 0.3027  decode.d6.loss_dice: 0.2491  decode.d7.loss_cls: 0.1621  decode.d7.loss_mask: 0.3028  decode.d7.loss_dice: 0.2520  decode.d8.loss_cls: 0.1754  decode.d8.loss_mask: 0.3007  decode.d8.loss_dice: 0.2439
09/30 11:42:27 - mmengine - INFO - Iter(train) [ 22100/320000]  base_lr: 9.3763e-05 lr: 9.3763e-06  eta: 1 day, 11:48:27  time: 0.4334  data_time: 0.0091  memory: 5147  grad_norm: 164.8983  loss: 10.7692  decode.loss_cls: 0.4187  decode.loss_mask: 0.2996  decode.loss_dice: 0.3349  decode.d0.loss_cls: 1.0906  decode.d0.loss_mask: 0.3055  decode.d0.loss_dice: 0.2977  decode.d1.loss_cls: 0.4237  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.2912  decode.d2.loss_cls: 0.4281  decode.d2.loss_mask: 0.2998  decode.d2.loss_dice: 0.2752  decode.d3.loss_cls: 0.3996  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.2746  decode.d4.loss_cls: 0.3415  decode.d4.loss_mask: 0.2972  decode.d4.loss_dice: 0.3211  decode.d5.loss_cls: 0.3967  decode.d5.loss_mask: 0.3027  decode.d5.loss_dice: 0.3161  decode.d6.loss_cls: 0.4275  decode.d6.loss_mask: 0.2962  decode.d6.loss_dice: 0.3319  decode.d7.loss_cls: 0.3824  decode.d7.loss_mask: 0.2961  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.3963  decode.d8.loss_mask: 0.2971  decode.d8.loss_dice: 0.3221
09/30 11:42:48 - mmengine - INFO - Iter(train) [ 22150/320000]  base_lr: 9.3748e-05 lr: 9.3748e-06  eta: 1 day, 11:48:07  time: 0.4341  data_time: 0.0094  memory: 5180  grad_norm: 195.8955  loss: 7.9668  decode.loss_cls: 0.1469  decode.loss_mask: 0.4078  decode.loss_dice: 0.2639  decode.d0.loss_cls: 0.7509  decode.d0.loss_mask: 0.3661  decode.d0.loss_dice: 0.2574  decode.d1.loss_cls: 0.1527  decode.d1.loss_mask: 0.3332  decode.d1.loss_dice: 0.2138  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.4213  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.2154  decode.d3.loss_mask: 0.3409  decode.d3.loss_dice: 0.2391  decode.d4.loss_cls: 0.1255  decode.d4.loss_mask: 0.3374  decode.d4.loss_dice: 0.2162  decode.d5.loss_cls: 0.1175  decode.d5.loss_mask: 0.3656  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.1381  decode.d6.loss_mask: 0.3444  decode.d6.loss_dice: 0.2278  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.3324  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.1440  decode.d8.loss_mask: 0.3347  decode.d8.loss_dice: 0.2269
09/30 11:43:10 - mmengine - INFO - Iter(train) [ 22200/320000]  base_lr: 9.3734e-05 lr: 9.3734e-06  eta: 1 day, 11:47:46  time: 0.4340  data_time: 0.0091  memory: 5161  grad_norm: 87.6034  loss: 7.5605  decode.loss_cls: 0.1462  decode.loss_mask: 0.2933  decode.loss_dice: 0.2660  decode.d0.loss_cls: 0.9037  decode.d0.loss_mask: 0.2773  decode.d0.loss_dice: 0.2651  decode.d1.loss_cls: 0.1574  decode.d1.loss_mask: 0.2833  decode.d1.loss_dice: 0.2592  decode.d2.loss_cls: 0.1398  decode.d2.loss_mask: 0.2860  decode.d2.loss_dice: 0.2620  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2820  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.0989  decode.d4.loss_mask: 0.2814  decode.d4.loss_dice: 0.2577  decode.d5.loss_cls: 0.1243  decode.d5.loss_mask: 0.2854  decode.d5.loss_dice: 0.2569  decode.d6.loss_cls: 0.1407  decode.d6.loss_mask: 0.2989  decode.d6.loss_dice: 0.2589  decode.d7.loss_cls: 0.1574  decode.d7.loss_mask: 0.3010  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.1619  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2402
09/30 11:43:32 - mmengine - INFO - Iter(train) [ 22250/320000]  base_lr: 9.3720e-05 lr: 9.3720e-06  eta: 1 day, 11:47:25  time: 0.4338  data_time: 0.0094  memory: 5161  grad_norm: 131.2329  loss: 9.8997  decode.loss_cls: 0.1987  decode.loss_mask: 0.3720  decode.loss_dice: 0.3352  decode.d0.loss_cls: 0.8748  decode.d0.loss_mask: 0.3695  decode.d0.loss_dice: 0.3259  decode.d1.loss_cls: 0.2441  decode.d1.loss_mask: 0.3691  decode.d1.loss_dice: 0.3360  decode.d2.loss_cls: 0.1907  decode.d2.loss_mask: 0.3679  decode.d2.loss_dice: 0.3394  decode.d3.loss_cls: 0.2408  decode.d3.loss_mask: 0.3650  decode.d3.loss_dice: 0.3280  decode.d4.loss_cls: 0.2432  decode.d4.loss_mask: 0.3646  decode.d4.loss_dice: 0.3179  decode.d5.loss_cls: 0.2436  decode.d5.loss_mask: 0.3660  decode.d5.loss_dice: 0.3153  decode.d6.loss_cls: 0.2656  decode.d6.loss_mask: 0.3677  decode.d6.loss_dice: 0.3283  decode.d7.loss_cls: 0.2314  decode.d7.loss_mask: 0.3639  decode.d7.loss_dice: 0.2995  decode.d8.loss_cls: 0.1883  decode.d8.loss_mask: 0.3728  decode.d8.loss_dice: 0.3742
09/30 11:43:53 - mmengine - INFO - Iter(train) [ 22300/320000]  base_lr: 9.3706e-05 lr: 9.3706e-06  eta: 1 day, 11:47:05  time: 0.4349  data_time: 0.0092  memory: 5158  grad_norm: 53.0000  loss: 8.2074  decode.loss_cls: 0.2049  decode.loss_mask: 0.2312  decode.loss_dice: 0.2867  decode.d0.loss_cls: 1.1130  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.2941  decode.d1.loss_cls: 0.1932  decode.d1.loss_mask: 0.2330  decode.d1.loss_dice: 0.2876  decode.d2.loss_cls: 0.1963  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.2018  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2983  decode.d4.loss_cls: 0.1636  decode.d4.loss_mask: 0.2553  decode.d4.loss_dice: 0.3024  decode.d5.loss_cls: 0.1678  decode.d5.loss_mask: 0.2386  decode.d5.loss_dice: 0.2807  decode.d6.loss_cls: 0.1970  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.3051  decode.d7.loss_cls: 0.2037  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.3026  decode.d8.loss_cls: 0.1976  decode.d8.loss_mask: 0.2412  decode.d8.loss_dice: 0.3098
09/30 11:44:15 - mmengine - INFO - Iter(train) [ 22350/320000]  base_lr: 9.3692e-05 lr: 9.3692e-06  eta: 1 day, 11:46:44  time: 0.4337  data_time: 0.0092  memory: 5145  grad_norm: 108.7042  loss: 7.3572  decode.loss_cls: 0.2964  decode.loss_mask: 0.2252  decode.loss_dice: 0.1846  decode.d0.loss_cls: 0.9066  decode.d0.loss_mask: 0.2191  decode.d0.loss_dice: 0.1934  decode.d1.loss_cls: 0.2374  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.1943  decode.d2.loss_cls: 0.2297  decode.d2.loss_mask: 0.2161  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.2841  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.1656  decode.d4.loss_cls: 0.2917  decode.d4.loss_mask: 0.2165  decode.d4.loss_dice: 0.1745  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.1918  decode.d6.loss_cls: 0.2767  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.1710  decode.d7.loss_cls: 0.2590  decode.d7.loss_mask: 0.2488  decode.d7.loss_dice: 0.1843  decode.d8.loss_cls: 0.2539  decode.d8.loss_mask: 0.2187  decode.d8.loss_dice: 0.1920
09/30 11:44:37 - mmengine - INFO - Iter(train) [ 22400/320000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 1 day, 11:46:23  time: 0.4332  data_time: 0.0090  memory: 5180  grad_norm: 57.3027  loss: 6.5760  decode.loss_cls: 0.1691  decode.loss_mask: 0.2005  decode.loss_dice: 0.2012  decode.d0.loss_cls: 1.0784  decode.d0.loss_mask: 0.2076  decode.d0.loss_dice: 0.2006  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.2020  decode.d1.loss_dice: 0.1936  decode.d2.loss_cls: 0.1363  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.2079  decode.d3.loss_cls: 0.1577  decode.d3.loss_mask: 0.2015  decode.d3.loss_dice: 0.2068  decode.d4.loss_cls: 0.1547  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.1542  decode.d5.loss_mask: 0.2027  decode.d5.loss_dice: 0.1985  decode.d6.loss_cls: 0.1617  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.2054  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 0.2048  decode.d7.loss_dice: 0.1978  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 0.2032  decode.d8.loss_dice: 0.2041
09/30 11:44:59 - mmengine - INFO - Iter(train) [ 22450/320000]  base_lr: 9.3663e-05 lr: 9.3663e-06  eta: 1 day, 11:46:02  time: 0.4344  data_time: 0.0092  memory: 5160  grad_norm: 77.3114  loss: 7.6317  decode.loss_cls: 0.0995  decode.loss_mask: 0.3266  decode.loss_dice: 0.2376  decode.d0.loss_cls: 0.8910  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.2418  decode.d1.loss_cls: 0.1819  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.2361  decode.d2.loss_cls: 0.1722  decode.d2.loss_mask: 0.3258  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.3193  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.3198  decode.d4.loss_dice: 0.2558  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.3134  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.1158  decode.d6.loss_mask: 0.3164  decode.d6.loss_dice: 0.2335  decode.d7.loss_cls: 0.1142  decode.d7.loss_mask: 0.3168  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.1061  decode.d8.loss_mask: 0.3218  decode.d8.loss_dice: 0.2407
09/30 11:45:20 - mmengine - INFO - Iter(train) [ 22500/320000]  base_lr: 9.3649e-05 lr: 9.3649e-06  eta: 1 day, 11:45:41  time: 0.4330  data_time: 0.0088  memory: 5147  grad_norm: 65.1291  loss: 7.0129  decode.loss_cls: 0.1627  decode.loss_mask: 0.2411  decode.loss_dice: 0.2022  decode.d0.loss_cls: 1.0540  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.2119  decode.d1.loss_cls: 0.2319  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.1979  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.1973  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.1917  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 0.2460  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.1971  decode.d6.loss_cls: 0.1628  decode.d6.loss_mask: 0.2453  decode.d6.loss_dice: 0.1889  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 0.2424  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.1572  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.1948
09/30 11:45:42 - mmengine - INFO - Iter(train) [ 22550/320000]  base_lr: 9.3635e-05 lr: 9.3635e-06  eta: 1 day, 11:45:20  time: 0.4339  data_time: 0.0091  memory: 5160  grad_norm: 136.9594  loss: 6.8541  decode.loss_cls: 0.0593  decode.loss_mask: 0.2868  decode.loss_dice: 0.2470  decode.d0.loss_cls: 0.7737  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.0718  decode.d1.loss_mask: 0.2965  decode.d1.loss_dice: 0.2668  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.2534  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.2585  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.2495  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.2878  decode.d7.loss_dice: 0.2426  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.2552
09/30 11:46:04 - mmengine - INFO - Iter(train) [ 22600/320000]  base_lr: 9.3621e-05 lr: 9.3621e-06  eta: 1 day, 11:44:59  time: 0.4342  data_time: 0.0093  memory: 5180  grad_norm: 71.5942  loss: 7.1020  decode.loss_cls: 0.1035  decode.loss_mask: 0.2664  decode.loss_dice: 0.2683  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.2480  decode.d1.loss_cls: 0.1424  decode.d1.loss_mask: 0.2656  decode.d1.loss_dice: 0.2624  decode.d2.loss_cls: 0.0677  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.2843  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 0.2687  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.1222  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.2807  decode.d5.loss_cls: 0.0955  decode.d5.loss_mask: 0.2581  decode.d5.loss_dice: 0.2683  decode.d6.loss_cls: 0.1155  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2739  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.2650  decode.d7.loss_dice: 0.2705  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.2645  decode.d8.loss_dice: 0.2685
09/30 11:46:25 - mmengine - INFO - Iter(train) [ 22650/320000]  base_lr: 9.3607e-05 lr: 9.3607e-06  eta: 1 day, 11:44:38  time: 0.4342  data_time: 0.0093  memory: 5161  grad_norm: 78.0820  loss: 8.5862  decode.loss_cls: 0.2558  decode.loss_mask: 0.2617  decode.loss_dice: 0.2590  decode.d0.loss_cls: 1.1252  decode.d0.loss_mask: 0.2603  decode.d0.loss_dice: 0.2779  decode.d1.loss_cls: 0.3153  decode.d1.loss_mask: 0.2655  decode.d1.loss_dice: 0.2682  decode.d2.loss_cls: 0.2578  decode.d2.loss_mask: 0.2531  decode.d2.loss_dice: 0.2541  decode.d3.loss_cls: 0.2484  decode.d3.loss_mask: 0.2596  decode.d3.loss_dice: 0.2427  decode.d4.loss_cls: 0.2563  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.2461  decode.d5.loss_cls: 0.2497  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.2545  decode.d6.loss_mask: 0.2595  decode.d6.loss_dice: 0.2373  decode.d7.loss_cls: 0.2548  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.2075  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.2648
09/30 11:46:47 - mmengine - INFO - Iter(train) [ 22700/320000]  base_lr: 9.3593e-05 lr: 9.3593e-06  eta: 1 day, 11:44:20  time: 0.4529  data_time: 0.0093  memory: 5180  grad_norm: 49.7111  loss: 6.3517  decode.loss_cls: 0.0413  decode.loss_mask: 0.2957  decode.loss_dice: 0.2028  decode.d0.loss_cls: 0.9112  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.1079  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.1945  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.2890  decode.d2.loss_dice: 0.1963  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.3004  decode.d3.loss_dice: 0.2026  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.2961  decode.d5.loss_dice: 0.1895  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.2932  decode.d6.loss_dice: 0.2051  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.2928  decode.d8.loss_dice: 0.2088
09/30 11:47:09 - mmengine - INFO - Iter(train) [ 22750/320000]  base_lr: 9.3578e-05 lr: 9.3578e-06  eta: 1 day, 11:43:59  time: 0.4331  data_time: 0.0091  memory: 5161  grad_norm: 45.4135  loss: 5.8744  decode.loss_cls: 0.0108  decode.loss_mask: 0.3000  decode.loss_dice: 0.1976  decode.d0.loss_cls: 0.7518  decode.d0.loss_mask: 0.3069  decode.d0.loss_dice: 0.2005  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.3025  decode.d1.loss_dice: 0.1957  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.3026  decode.d2.loss_dice: 0.2020  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.3026  decode.d3.loss_dice: 0.1962  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.1978  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.2000  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.2985  decode.d6.loss_dice: 0.1985  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.3024  decode.d7.loss_dice: 0.2021  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.3010  decode.d8.loss_dice: 0.1958
09/30 11:47:31 - mmengine - INFO - Iter(train) [ 22800/320000]  base_lr: 9.3564e-05 lr: 9.3564e-06  eta: 1 day, 11:43:38  time: 0.4344  data_time: 0.0093  memory: 5161  grad_norm: 117.1901  loss: 7.9763  decode.loss_cls: 0.1668  decode.loss_mask: 0.3074  decode.loss_dice: 0.2485  decode.d0.loss_cls: 0.7730  decode.d0.loss_mask: 0.3079  decode.d0.loss_dice: 0.2578  decode.d1.loss_cls: 0.1859  decode.d1.loss_mask: 0.3114  decode.d1.loss_dice: 0.2735  decode.d2.loss_cls: 0.1661  decode.d2.loss_mask: 0.3100  decode.d2.loss_dice: 0.2490  decode.d3.loss_cls: 0.1723  decode.d3.loss_mask: 0.3012  decode.d3.loss_dice: 0.2522  decode.d4.loss_cls: 0.1962  decode.d4.loss_mask: 0.3087  decode.d4.loss_dice: 0.2490  decode.d5.loss_cls: 0.1911  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.2543  decode.d6.loss_cls: 0.1858  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.2694  decode.d7.loss_cls: 0.1592  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.2488  decode.d8.loss_cls: 0.1591  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.2498
09/30 11:47:52 - mmengine - INFO - Iter(train) [ 22850/320000]  base_lr: 9.3550e-05 lr: 9.3550e-06  eta: 1 day, 11:43:17  time: 0.4332  data_time: 0.0091  memory: 5180  grad_norm: 64.2398  loss: 6.1001  decode.loss_cls: 0.0650  decode.loss_mask: 0.2767  decode.loss_dice: 0.1873  decode.d0.loss_cls: 0.7703  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.1974  decode.d1.loss_cls: 0.1852  decode.d1.loss_mask: 0.2678  decode.d1.loss_dice: 0.1970  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.2738  decode.d2.loss_dice: 0.2034  decode.d3.loss_cls: 0.0423  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.1956  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.1948  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.2777  decode.d5.loss_dice: 0.1992  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.2726  decode.d6.loss_dice: 0.1915  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2006  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.1983
09/30 11:48:14 - mmengine - INFO - Iter(train) [ 22900/320000]  base_lr: 9.3536e-05 lr: 9.3536e-06  eta: 1 day, 11:42:57  time: 0.4352  data_time: 0.0093  memory: 5146  grad_norm: 137.3351  loss: 9.9724  decode.loss_cls: 0.1404  decode.loss_mask: 0.3683  decode.loss_dice: 0.3688  decode.d0.loss_cls: 0.9661  decode.d0.loss_mask: 0.3666  decode.d0.loss_dice: 0.3989  decode.d1.loss_cls: 0.2949  decode.d1.loss_mask: 0.3635  decode.d1.loss_dice: 0.3805  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 0.3620  decode.d2.loss_dice: 0.3969  decode.d3.loss_cls: 0.1804  decode.d3.loss_mask: 0.3585  decode.d3.loss_dice: 0.3976  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.3636  decode.d4.loss_dice: 0.3731  decode.d5.loss_cls: 0.1409  decode.d5.loss_mask: 0.3709  decode.d5.loss_dice: 0.4093  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.3756  decode.d6.loss_dice: 0.4085  decode.d7.loss_cls: 0.1165  decode.d7.loss_mask: 0.3771  decode.d7.loss_dice: 0.4184  decode.d8.loss_cls: 0.0991  decode.d8.loss_mask: 0.3744  decode.d8.loss_dice: 0.4187
09/30 11:48:36 - mmengine - INFO - Iter(train) [ 22950/320000]  base_lr: 9.3522e-05 lr: 9.3522e-06  eta: 1 day, 11:42:36  time: 0.4343  data_time: 0.0093  memory: 5160  grad_norm: 29.1437  loss: 5.7320  decode.loss_cls: 0.0708  decode.loss_mask: 0.2301  decode.loss_dice: 0.1869  decode.d0.loss_cls: 0.8314  decode.d0.loss_mask: 0.2301  decode.d0.loss_dice: 0.1875  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.1888  decode.d2.loss_cls: 0.1333  decode.d2.loss_mask: 0.2273  decode.d2.loss_dice: 0.1973  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2249  decode.d3.loss_dice: 0.1854  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.1934  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.2273  decode.d6.loss_dice: 0.1914  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.2315  decode.d7.loss_dice: 0.1834  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.1862
09/30 11:48:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:48:57 - mmengine - INFO - Iter(train) [ 23000/320000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 1 day, 11:42:15  time: 0.4346  data_time: 0.0094  memory: 5147  grad_norm: 77.5512  loss: 8.8391  decode.loss_cls: 0.2424  decode.loss_mask: 0.3101  decode.loss_dice: 0.2495  decode.d0.loss_cls: 0.9982  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.3434  decode.d1.loss_mask: 0.3067  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.3145  decode.d2.loss_mask: 0.3251  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.2674  decode.d3.loss_mask: 0.3094  decode.d3.loss_dice: 0.2444  decode.d4.loss_cls: 0.2560  decode.d4.loss_mask: 0.2919  decode.d4.loss_dice: 0.2535  decode.d5.loss_cls: 0.2519  decode.d5.loss_mask: 0.2846  decode.d5.loss_dice: 0.2390  decode.d6.loss_cls: 0.2869  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2549  decode.d7.loss_mask: 0.3002  decode.d7.loss_dice: 0.2429  decode.d8.loss_cls: 0.2367  decode.d8.loss_mask: 0.2938  decode.d8.loss_dice: 0.2491
09/30 11:49:19 - mmengine - INFO - Iter(train) [ 23050/320000]  base_lr: 9.3493e-05 lr: 9.3493e-06  eta: 1 day, 11:41:55  time: 0.4345  data_time: 0.0093  memory: 5132  grad_norm: 206.5790  loss: 7.9294  decode.loss_cls: 0.2059  decode.loss_mask: 0.2701  decode.loss_dice: 0.2536  decode.d0.loss_cls: 0.8973  decode.d0.loss_mask: 0.2834  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.2612  decode.d1.loss_mask: 0.2613  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.2477  decode.d2.loss_mask: 0.2752  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.2364  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 0.2708  decode.d4.loss_dice: 0.2309  decode.d5.loss_cls: 0.1985  decode.d5.loss_mask: 0.2709  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1932  decode.d6.loss_mask: 0.2735  decode.d6.loss_dice: 0.2220  decode.d7.loss_cls: 0.1823  decode.d7.loss_mask: 0.2759  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.2159  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2303
09/30 11:49:41 - mmengine - INFO - Iter(train) [ 23100/320000]  base_lr: 9.3479e-05 lr: 9.3479e-06  eta: 1 day, 11:41:34  time: 0.4339  data_time: 0.0092  memory: 5160  grad_norm: 157.9363  loss: 6.0070  decode.loss_cls: 0.1304  decode.loss_mask: 0.2009  decode.loss_dice: 0.2009  decode.d0.loss_cls: 0.9851  decode.d0.loss_mask: 0.2043  decode.d0.loss_dice: 0.2153  decode.d1.loss_cls: 0.1217  decode.d1.loss_mask: 0.2035  decode.d1.loss_dice: 0.2442  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.2040  decode.d2.loss_dice: 0.2361  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.2031  decode.d3.loss_dice: 0.2231  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.2031  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.1265  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.2137  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.2023  decode.d7.loss_dice: 0.2236  decode.d8.loss_cls: 0.0844  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.2185
09/30 11:50:03 - mmengine - INFO - Iter(train) [ 23150/320000]  base_lr: 9.3465e-05 lr: 9.3465e-06  eta: 1 day, 11:41:13  time: 0.4347  data_time: 0.0093  memory: 5161  grad_norm: 123.1670  loss: 6.9985  decode.loss_cls: 0.0833  decode.loss_mask: 0.3205  decode.loss_dice: 0.2048  decode.d0.loss_cls: 0.8606  decode.d0.loss_mask: 0.3192  decode.d0.loss_dice: 0.2211  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 0.3231  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.3191  decode.d2.loss_dice: 0.2106  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.3299  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.3223  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.3270  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 0.3228  decode.d6.loss_dice: 0.2035  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.2039  decode.d8.loss_cls: 0.0854  decode.d8.loss_mask: 0.3226  decode.d8.loss_dice: 0.2053
09/30 11:50:24 - mmengine - INFO - Iter(train) [ 23200/320000]  base_lr: 9.3451e-05 lr: 9.3451e-06  eta: 1 day, 11:40:53  time: 0.4335  data_time: 0.0092  memory: 5160  grad_norm: 105.6339  loss: 10.8189  decode.loss_cls: 0.2960  decode.loss_mask: 0.3947  decode.loss_dice: 0.2639  decode.d0.loss_cls: 1.0312  decode.d0.loss_mask: 0.4510  decode.d0.loss_dice: 0.2834  decode.d1.loss_cls: 0.3951  decode.d1.loss_mask: 0.4032  decode.d1.loss_dice: 0.2842  decode.d2.loss_cls: 0.4136  decode.d2.loss_mask: 0.3844  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.3565  decode.d3.loss_mask: 0.3880  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.3578  decode.d4.loss_mask: 0.3921  decode.d4.loss_dice: 0.2783  decode.d5.loss_cls: 0.3220  decode.d5.loss_mask: 0.3973  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.3354  decode.d6.loss_mask: 0.3984  decode.d6.loss_dice: 0.2637  decode.d7.loss_cls: 0.3350  decode.d7.loss_mask: 0.3976  decode.d7.loss_dice: 0.2628  decode.d8.loss_cls: 0.2863  decode.d8.loss_mask: 0.3942  decode.d8.loss_dice: 0.2618
09/30 11:50:46 - mmengine - INFO - Iter(train) [ 23250/320000]  base_lr: 9.3437e-05 lr: 9.3437e-06  eta: 1 day, 11:40:32  time: 0.4348  data_time: 0.0091  memory: 5161  grad_norm: 60.5824  loss: 7.2071  decode.loss_cls: 0.0932  decode.loss_mask: 0.2647  decode.loss_dice: 0.2267  decode.d0.loss_cls: 1.0052  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.2373  decode.d1.loss_cls: 0.2130  decode.d1.loss_mask: 0.2663  decode.d1.loss_dice: 0.2277  decode.d2.loss_cls: 0.1610  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.2287  decode.d3.loss_cls: 0.1212  decode.d3.loss_mask: 0.2607  decode.d3.loss_dice: 0.2303  decode.d4.loss_cls: 0.1059  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.2435  decode.d5.loss_cls: 0.1390  decode.d5.loss_mask: 0.2700  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.2654  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.1346  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.2304  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.2559
09/30 11:51:08 - mmengine - INFO - Iter(train) [ 23300/320000]  base_lr: 9.3423e-05 lr: 9.3423e-06  eta: 1 day, 11:40:11  time: 0.4342  data_time: 0.0093  memory: 5147  grad_norm: 249.1414  loss: 7.3147  decode.loss_cls: 0.1304  decode.loss_mask: 0.2732  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.7479  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.2690  decode.d1.loss_cls: 0.1376  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.1611  decode.d2.loss_mask: 0.2704  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 0.2711  decode.d3.loss_dice: 0.2538  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 0.2724  decode.d4.loss_dice: 0.2389  decode.d5.loss_cls: 0.1635  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.1723  decode.d6.loss_mask: 0.2758  decode.d6.loss_dice: 0.2449  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.2720  decode.d7.loss_dice: 0.2398  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.2474
09/30 11:51:29 - mmengine - INFO - Iter(train) [ 23350/320000]  base_lr: 9.3408e-05 lr: 9.3408e-06  eta: 1 day, 11:39:50  time: 0.4350  data_time: 0.0095  memory: 5145  grad_norm: 38.7105  loss: 6.6611  decode.loss_cls: 0.1142  decode.loss_mask: 0.2397  decode.loss_dice: 0.2225  decode.d0.loss_cls: 0.9592  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.2334  decode.d1.loss_cls: 0.1413  decode.d1.loss_mask: 0.2433  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.0983  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2329  decode.d3.loss_cls: 0.1106  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.2265  decode.d4.loss_cls: 0.1018  decode.d4.loss_mask: 0.2395  decode.d4.loss_dice: 0.2182  decode.d5.loss_cls: 0.0909  decode.d5.loss_mask: 0.2363  decode.d5.loss_dice: 0.2296  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.2360  decode.d7.loss_cls: 0.1061  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2343  decode.d8.loss_cls: 0.1101  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2305
09/30 11:51:51 - mmengine - INFO - Iter(train) [ 23400/320000]  base_lr: 9.3394e-05 lr: 9.3394e-06  eta: 1 day, 11:39:30  time: 0.4334  data_time: 0.0093  memory: 5160  grad_norm: 94.7678  loss: 7.8897  decode.loss_cls: 0.1368  decode.loss_mask: 0.3132  decode.loss_dice: 0.2134  decode.d0.loss_cls: 0.9550  decode.d0.loss_mask: 0.3438  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.1978  decode.d1.loss_mask: 0.3075  decode.d1.loss_dice: 0.2293  decode.d2.loss_cls: 0.1525  decode.d2.loss_mask: 0.3136  decode.d2.loss_dice: 0.2183  decode.d3.loss_cls: 0.1258  decode.d3.loss_mask: 0.3150  decode.d3.loss_dice: 0.2189  decode.d4.loss_cls: 0.1970  decode.d4.loss_mask: 0.3184  decode.d4.loss_dice: 0.2285  decode.d5.loss_cls: 0.1748  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.2428  decode.d6.loss_cls: 0.1660  decode.d6.loss_mask: 0.3135  decode.d6.loss_dice: 0.2263  decode.d7.loss_cls: 0.1584  decode.d7.loss_mask: 0.3091  decode.d7.loss_dice: 0.2231  decode.d8.loss_cls: 0.1573  decode.d8.loss_mask: 0.3138  decode.d8.loss_dice: 0.2332
09/30 11:52:13 - mmengine - INFO - Iter(train) [ 23450/320000]  base_lr: 9.3380e-05 lr: 9.3380e-06  eta: 1 day, 11:39:09  time: 0.4344  data_time: 0.0094  memory: 5161  grad_norm: 58.9413  loss: 7.8752  decode.loss_cls: 0.1039  decode.loss_mask: 0.2867  decode.loss_dice: 0.2754  decode.d0.loss_cls: 0.9791  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.2869  decode.d1.loss_cls: 0.1649  decode.d1.loss_mask: 0.2961  decode.d1.loss_dice: 0.2684  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2903  decode.d2.loss_dice: 0.2626  decode.d3.loss_cls: 0.1417  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.2802  decode.d4.loss_cls: 0.1884  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.2723  decode.d5.loss_cls: 0.1309  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.2690  decode.d6.loss_cls: 0.1952  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.2694  decode.d7.loss_cls: 0.1024  decode.d7.loss_mask: 0.2904  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.0938  decode.d8.loss_mask: 0.2889  decode.d8.loss_dice: 0.2785
09/30 11:52:35 - mmengine - INFO - Iter(train) [ 23500/320000]  base_lr: 9.3366e-05 lr: 9.3366e-06  eta: 1 day, 11:38:48  time: 0.4341  data_time: 0.0094  memory: 5161  grad_norm: 137.2769  loss: 8.6914  decode.loss_cls: 0.2455  decode.loss_mask: 0.2676  decode.loss_dice: 0.2152  decode.d0.loss_cls: 1.0484  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.2312  decode.d1.loss_cls: 0.3169  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2068  decode.d2.loss_cls: 0.2522  decode.d2.loss_mask: 0.3351  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.2808  decode.d3.loss_mask: 0.3200  decode.d3.loss_dice: 0.2249  decode.d4.loss_cls: 0.2782  decode.d4.loss_mask: 0.3261  decode.d4.loss_dice: 0.1895  decode.d5.loss_cls: 0.2600  decode.d5.loss_mask: 0.3265  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.2618  decode.d6.loss_mask: 0.3273  decode.d6.loss_dice: 0.2233  decode.d7.loss_cls: 0.2314  decode.d7.loss_mask: 0.3386  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.2127  decode.d8.loss_mask: 0.3530  decode.d8.loss_dice: 0.2635
09/30 11:52:56 - mmengine - INFO - Iter(train) [ 23550/320000]  base_lr: 9.3352e-05 lr: 9.3352e-06  eta: 1 day, 11:38:27  time: 0.4340  data_time: 0.0092  memory: 5160  grad_norm: 52.3502  loss: 5.7773  decode.loss_cls: 0.1474  decode.loss_mask: 0.2049  decode.loss_dice: 0.1663  decode.d0.loss_cls: 0.8656  decode.d0.loss_mask: 0.2070  decode.d0.loss_dice: 0.1690  decode.d1.loss_cls: 0.1229  decode.d1.loss_mask: 0.2076  decode.d1.loss_dice: 0.1667  decode.d2.loss_cls: 0.1216  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.1682  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 0.2054  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.1304  decode.d4.loss_mask: 0.2024  decode.d4.loss_dice: 0.1648  decode.d5.loss_cls: 0.1467  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.1682  decode.d6.loss_cls: 0.1305  decode.d6.loss_mask: 0.2058  decode.d6.loss_dice: 0.1676  decode.d7.loss_cls: 0.1361  decode.d7.loss_mask: 0.2062  decode.d7.loss_dice: 0.1668  decode.d8.loss_cls: 0.1480  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.1646
09/30 11:53:18 - mmengine - INFO - Iter(train) [ 23600/320000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 1 day, 11:38:07  time: 0.4343  data_time: 0.0092  memory: 5161  grad_norm: 26.0954  loss: 5.9773  decode.loss_cls: 0.1638  decode.loss_mask: 0.2031  decode.loss_dice: 0.1546  decode.d0.loss_cls: 1.0788  decode.d0.loss_mask: 0.2050  decode.d0.loss_dice: 0.1689  decode.d1.loss_cls: 0.1421  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.1574  decode.d2.loss_cls: 0.1208  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1530  decode.d3.loss_cls: 0.1413  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.1587  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 0.2088  decode.d4.loss_dice: 0.1602  decode.d5.loss_cls: 0.1383  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.1559  decode.d6.loss_cls: 0.1655  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.1697  decode.d7.loss_cls: 0.1397  decode.d7.loss_mask: 0.1988  decode.d7.loss_dice: 0.1569  decode.d8.loss_cls: 0.1500  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.1560
09/30 11:53:40 - mmengine - INFO - Iter(train) [ 23650/320000]  base_lr: 9.3323e-05 lr: 9.3323e-06  eta: 1 day, 11:37:46  time: 0.4336  data_time: 0.0092  memory: 5180  grad_norm: 124.1914  loss: 7.8678  decode.loss_cls: 0.2282  decode.loss_mask: 0.2484  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.9921  decode.d0.loss_mask: 0.2475  decode.d0.loss_dice: 0.2270  decode.d1.loss_cls: 0.2610  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.2103  decode.d2.loss_cls: 0.2599  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.2121  decode.d3.loss_mask: 0.2584  decode.d3.loss_dice: 0.2063  decode.d4.loss_cls: 0.2376  decode.d4.loss_mask: 0.2560  decode.d4.loss_dice: 0.2203  decode.d5.loss_cls: 0.2058  decode.d5.loss_mask: 0.2542  decode.d5.loss_dice: 0.2162  decode.d6.loss_cls: 0.2389  decode.d6.loss_mask: 0.2568  decode.d6.loss_dice: 0.2118  decode.d7.loss_cls: 0.2733  decode.d7.loss_mask: 0.2550  decode.d7.loss_dice: 0.2255  decode.d8.loss_cls: 0.2694  decode.d8.loss_mask: 0.2519  decode.d8.loss_dice: 0.2057
09/30 11:54:01 - mmengine - INFO - Iter(train) [ 23700/320000]  base_lr: 9.3309e-05 lr: 9.3309e-06  eta: 1 day, 11:37:25  time: 0.4342  data_time: 0.0092  memory: 5147  grad_norm: 85.6697  loss: 7.4178  decode.loss_cls: 0.1853  decode.loss_mask: 0.2459  decode.loss_dice: 0.2011  decode.d0.loss_cls: 0.8463  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.2251  decode.d1.loss_cls: 0.2184  decode.d1.loss_mask: 0.2463  decode.d1.loss_dice: 0.1822  decode.d2.loss_cls: 0.2194  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2108  decode.d3.loss_cls: 0.1786  decode.d3.loss_mask: 0.2512  decode.d3.loss_dice: 0.1813  decode.d4.loss_cls: 0.2354  decode.d4.loss_mask: 0.2821  decode.d4.loss_dice: 0.2178  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.2442  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.2129  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.2203  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.2219  decode.d8.loss_cls: 0.2091  decode.d8.loss_mask: 0.2795  decode.d8.loss_dice: 0.2171
09/30 11:54:23 - mmengine - INFO - Iter(train) [ 23750/320000]  base_lr: 9.3295e-05 lr: 9.3295e-06  eta: 1 day, 11:37:04  time: 0.4336  data_time: 0.0093  memory: 5180  grad_norm: 35.7979  loss: 6.5267  decode.loss_cls: 0.1477  decode.loss_mask: 0.2516  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.8751  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.1751  decode.d1.loss_cls: 0.1440  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.1753  decode.d2.loss_cls: 0.1953  decode.d2.loss_mask: 0.2429  decode.d2.loss_dice: 0.1642  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.2437  decode.d3.loss_dice: 0.1687  decode.d4.loss_cls: 0.1563  decode.d4.loss_mask: 0.2506  decode.d4.loss_dice: 0.1852  decode.d5.loss_cls: 0.1457  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.1831  decode.d6.loss_cls: 0.1397  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.1779  decode.d7.loss_cls: 0.1645  decode.d7.loss_mask: 0.2496  decode.d7.loss_dice: 0.1824  decode.d8.loss_cls: 0.1349  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.1800
09/30 11:54:45 - mmengine - INFO - Iter(train) [ 23800/320000]  base_lr: 9.3281e-05 lr: 9.3281e-06  eta: 1 day, 11:36:44  time: 0.4360  data_time: 0.0095  memory: 5146  grad_norm: 76.9905  loss: 7.5870  decode.loss_cls: 0.1547  decode.loss_mask: 0.3057  decode.loss_dice: 0.2136  decode.d0.loss_cls: 0.8953  decode.d0.loss_mask: 0.3136  decode.d0.loss_dice: 0.2303  decode.d1.loss_cls: 0.2169  decode.d1.loss_mask: 0.3065  decode.d1.loss_dice: 0.2013  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 0.3089  decode.d2.loss_dice: 0.2023  decode.d3.loss_cls: 0.1585  decode.d3.loss_mask: 0.3052  decode.d3.loss_dice: 0.1994  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.2995  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.1378  decode.d5.loss_mask: 0.3053  decode.d5.loss_dice: 0.2044  decode.d6.loss_cls: 0.1458  decode.d6.loss_mask: 0.3072  decode.d6.loss_dice: 0.2086  decode.d7.loss_cls: 0.1907  decode.d7.loss_mask: 0.3029  decode.d7.loss_dice: 0.2094  decode.d8.loss_cls: 0.1763  decode.d8.loss_mask: 0.3055  decode.d8.loss_dice: 0.2108
09/30 11:55:07 - mmengine - INFO - Iter(train) [ 23850/320000]  base_lr: 9.3267e-05 lr: 9.3267e-06  eta: 1 day, 11:36:23  time: 0.4342  data_time: 0.0096  memory: 5160  grad_norm: 97.6993  loss: 7.2682  decode.loss_cls: 0.1730  decode.loss_mask: 0.2574  decode.loss_dice: 0.1821  decode.d0.loss_cls: 0.8207  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.2016  decode.d1.loss_cls: 0.3853  decode.d1.loss_mask: 0.2619  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.1863  decode.d3.loss_cls: 0.1782  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.1916  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.1835  decode.d5.loss_cls: 0.2675  decode.d5.loss_mask: 0.2588  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.1993  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.1832  decode.d7.loss_cls: 0.1637  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.1793  decode.d8.loss_cls: 0.1629  decode.d8.loss_mask: 0.2634  decode.d8.loss_dice: 0.1905
09/30 11:55:28 - mmengine - INFO - Iter(train) [ 23900/320000]  base_lr: 9.3253e-05 lr: 9.3253e-06  eta: 1 day, 11:36:02  time: 0.4341  data_time: 0.0091  memory: 5180  grad_norm: 51.3504  loss: 5.4362  decode.loss_cls: 0.0422  decode.loss_mask: 0.2079  decode.loss_dice: 0.1945  decode.d0.loss_cls: 0.8337  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.2007  decode.d1.loss_cls: 0.1135  decode.d1.loss_mask: 0.2075  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0902  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 0.2055  decode.d3.loss_dice: 0.2013  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.2097  decode.d4.loss_dice: 0.1904  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.1879  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.1923  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.2083  decode.d7.loss_dice: 0.1890  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.2059  decode.d8.loss_dice: 0.1843
09/30 11:55:50 - mmengine - INFO - Iter(train) [ 23950/320000]  base_lr: 9.3238e-05 lr: 9.3238e-06  eta: 1 day, 11:35:41  time: 0.4343  data_time: 0.0094  memory: 5161  grad_norm: 70.2387  loss: 9.3480  decode.loss_cls: 0.3178  decode.loss_mask: 0.2962  decode.loss_dice: 0.3069  decode.d0.loss_cls: 0.8695  decode.d0.loss_mask: 0.3011  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.3290  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.2456  decode.d2.loss_cls: 0.3561  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.2428  decode.d3.loss_mask: 0.2846  decode.d3.loss_dice: 0.2709  decode.d4.loss_cls: 0.2130  decode.d4.loss_mask: 0.3441  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.2852  decode.d5.loss_mask: 0.2972  decode.d5.loss_dice: 0.2876  decode.d6.loss_cls: 0.3016  decode.d6.loss_mask: 0.2934  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.2679  decode.d7.loss_mask: 0.3043  decode.d7.loss_dice: 0.3119  decode.d8.loss_cls: 0.3213  decode.d8.loss_mask: 0.2990  decode.d8.loss_dice: 0.2886
09/30 11:56:12 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 11:56:12 - mmengine - INFO - Iter(train) [ 24000/320000]  base_lr: 9.3224e-05 lr: 9.3224e-06  eta: 1 day, 11:35:21  time: 0.4334  data_time: 0.0090  memory: 5160  grad_norm: 96.4160  loss: 7.8360  decode.loss_cls: 0.0668  decode.loss_mask: 0.3902  decode.loss_dice: 0.2299  decode.d0.loss_cls: 1.0409  decode.d0.loss_mask: 0.2858  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.1756  decode.d1.loss_mask: 0.2911  decode.d1.loss_dice: 0.2041  decode.d2.loss_cls: 0.2150  decode.d2.loss_mask: 0.3136  decode.d2.loss_dice: 0.2225  decode.d3.loss_cls: 0.1806  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.2226  decode.d4.loss_cls: 0.1021  decode.d4.loss_mask: 0.4368  decode.d4.loss_dice: 0.2761  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.3734  decode.d5.loss_dice: 0.2261  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.3586  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.3035  decode.d7.loss_dice: 0.2081  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.3792  decode.d8.loss_dice: 0.2302
09/30 11:56:33 - mmengine - INFO - Iter(train) [ 24050/320000]  base_lr: 9.3210e-05 lr: 9.3210e-06  eta: 1 day, 11:35:00  time: 0.4346  data_time: 0.0092  memory: 5161  grad_norm: 94.2333  loss: 7.4740  decode.loss_cls: 0.0733  decode.loss_mask: 0.3129  decode.loss_dice: 0.2777  decode.d0.loss_cls: 0.8925  decode.d0.loss_mask: 0.3472  decode.d0.loss_dice: 0.2753  decode.d1.loss_cls: 0.0979  decode.d1.loss_mask: 0.3218  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.3171  decode.d2.loss_dice: 0.2696  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.3191  decode.d3.loss_dice: 0.2842  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 0.3146  decode.d4.loss_dice: 0.2651  decode.d5.loss_cls: 0.0896  decode.d5.loss_mask: 0.3183  decode.d5.loss_dice: 0.2582  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.3147  decode.d6.loss_dice: 0.2746  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.3131  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.3155  decode.d8.loss_dice: 0.2742
09/30 11:56:55 - mmengine - INFO - Iter(train) [ 24100/320000]  base_lr: 9.3196e-05 lr: 9.3196e-06  eta: 1 day, 11:34:39  time: 0.4341  data_time: 0.0094  memory: 5160  grad_norm: 85.4870  loss: 6.1139  decode.loss_cls: 0.0905  decode.loss_mask: 0.2684  decode.loss_dice: 0.1808  decode.d0.loss_cls: 0.8184  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.1829  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.2506  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.2488  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0799  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.1819  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.2682  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.1066  decode.d6.loss_mask: 0.2431  decode.d6.loss_dice: 0.1799  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 0.2357  decode.d7.loss_dice: 0.1759  decode.d8.loss_cls: 0.1041  decode.d8.loss_mask: 0.2409  decode.d8.loss_dice: 0.1817
09/30 11:57:17 - mmengine - INFO - Iter(train) [ 24150/320000]  base_lr: 9.3182e-05 lr: 9.3182e-06  eta: 1 day, 11:34:18  time: 0.4337  data_time: 0.0094  memory: 5180  grad_norm: 55.1688  loss: 7.0699  decode.loss_cls: 0.0869  decode.loss_mask: 0.2961  decode.loss_dice: 0.2483  decode.d0.loss_cls: 0.8905  decode.d0.loss_mask: 0.3077  decode.d0.loss_dice: 0.2649  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.2977  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.2968  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.2908  decode.d3.loss_dice: 0.2378  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.2962  decode.d4.loss_dice: 0.2390  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.2961  decode.d5.loss_dice: 0.2475  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.3059  decode.d6.loss_dice: 0.2621  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.3128  decode.d7.loss_dice: 0.2597  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.2922  decode.d8.loss_dice: 0.2418
09/30 11:57:39 - mmengine - INFO - Iter(train) [ 24200/320000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 1 day, 11:33:57  time: 0.4340  data_time: 0.0093  memory: 5146  grad_norm: 65.6848  loss: 7.0461  decode.loss_cls: 0.1469  decode.loss_mask: 0.2250  decode.loss_dice: 0.2038  decode.d0.loss_cls: 0.9692  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.1883  decode.d1.loss_cls: 0.2508  decode.d1.loss_mask: 0.2269  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.2352  decode.d2.loss_mask: 0.2261  decode.d2.loss_dice: 0.1952  decode.d3.loss_cls: 0.2233  decode.d3.loss_mask: 0.2257  decode.d3.loss_dice: 0.1842  decode.d4.loss_cls: 0.2167  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.1995  decode.d5.loss_cls: 0.2515  decode.d5.loss_mask: 0.2279  decode.d5.loss_dice: 0.1965  decode.d6.loss_cls: 0.2092  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1797  decode.d7.loss_cls: 0.1688  decode.d7.loss_mask: 0.2295  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.1737  decode.d8.loss_mask: 0.2298  decode.d8.loss_dice: 0.1926
09/30 11:58:00 - mmengine - INFO - Iter(train) [ 24250/320000]  base_lr: 9.3153e-05 lr: 9.3153e-06  eta: 1 day, 11:33:36  time: 0.4342  data_time: 0.0094  memory: 5147  grad_norm: 66.0308  loss: 7.6242  decode.loss_cls: 0.1279  decode.loss_mask: 0.3097  decode.loss_dice: 0.2004  decode.d0.loss_cls: 1.0353  decode.d0.loss_mask: 0.3146  decode.d0.loss_dice: 0.2014  decode.d1.loss_cls: 0.1700  decode.d1.loss_mask: 0.3065  decode.d1.loss_dice: 0.1965  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.3297  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.1867  decode.d3.loss_mask: 0.3323  decode.d3.loss_dice: 0.2230  decode.d4.loss_cls: 0.1496  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.1858  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.2042  decode.d6.loss_cls: 0.1396  decode.d6.loss_mask: 0.3032  decode.d6.loss_dice: 0.2016  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.3256  decode.d7.loss_dice: 0.2248  decode.d8.loss_cls: 0.1356  decode.d8.loss_mask: 0.3077  decode.d8.loss_dice: 0.2053
09/30 11:58:22 - mmengine - INFO - Iter(train) [ 24300/320000]  base_lr: 9.3139e-05 lr: 9.3139e-06  eta: 1 day, 11:33:15  time: 0.4333  data_time: 0.0092  memory: 5180  grad_norm: 58.8623  loss: 7.9294  decode.loss_cls: 0.1870  decode.loss_mask: 0.2634  decode.loss_dice: 0.2334  decode.d0.loss_cls: 0.9550  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.2802  decode.d1.loss_cls: 0.2836  decode.d1.loss_mask: 0.2583  decode.d1.loss_dice: 0.2269  decode.d2.loss_cls: 0.2058  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.2240  decode.d3.loss_cls: 0.2403  decode.d3.loss_mask: 0.2686  decode.d3.loss_dice: 0.2263  decode.d4.loss_cls: 0.2339  decode.d4.loss_mask: 0.2638  decode.d4.loss_dice: 0.2244  decode.d5.loss_cls: 0.2032  decode.d5.loss_mask: 0.2635  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.2394  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.2214  decode.d7.loss_cls: 0.1871  decode.d7.loss_mask: 0.2599  decode.d7.loss_dice: 0.2409  decode.d8.loss_cls: 0.2161  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.2323
09/30 11:58:44 - mmengine - INFO - Iter(train) [ 24350/320000]  base_lr: 9.3125e-05 lr: 9.3125e-06  eta: 1 day, 11:32:57  time: 0.4531  data_time: 0.0094  memory: 5180  grad_norm: 35.3405  loss: 6.5269  decode.loss_cls: 0.0881  decode.loss_mask: 0.2555  decode.loss_dice: 0.2177  decode.d0.loss_cls: 0.8866  decode.d0.loss_mask: 0.2626  decode.d0.loss_dice: 0.2315  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.2192  decode.d2.loss_cls: 0.0991  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.2181  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.2603  decode.d3.loss_dice: 0.2201  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.2581  decode.d4.loss_dice: 0.2232  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.2573  decode.d5.loss_dice: 0.2251  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.2548  decode.d6.loss_dice: 0.2172  decode.d7.loss_cls: 0.1028  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.2196  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.2553  decode.d8.loss_dice: 0.2246
09/30 11:59:06 - mmengine - INFO - Iter(train) [ 24400/320000]  base_lr: 9.3111e-05 lr: 9.3111e-06  eta: 1 day, 11:32:35  time: 0.4331  data_time: 0.0094  memory: 5161  grad_norm: 32.8593  loss: 5.7240  decode.loss_cls: 0.0209  decode.loss_mask: 0.2609  decode.loss_dice: 0.1931  decode.d0.loss_cls: 0.9000  decode.d0.loss_mask: 0.2662  decode.d0.loss_dice: 0.2068  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.1951  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.1906  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.1962  decode.d4.loss_cls: 0.0292  decode.d4.loss_mask: 0.2572  decode.d4.loss_dice: 0.1918  decode.d5.loss_cls: 0.0326  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.1906  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.1906  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.1945  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.2567  decode.d8.loss_dice: 0.1915
09/30 11:59:27 - mmengine - INFO - Iter(train) [ 24450/320000]  base_lr: 9.3097e-05 lr: 9.3097e-06  eta: 1 day, 11:32:15  time: 0.4335  data_time: 0.0093  memory: 5160  grad_norm: 113.0069  loss: 7.5440  decode.loss_cls: 0.0978  decode.loss_mask: 0.3168  decode.loss_dice: 0.2513  decode.d0.loss_cls: 0.9806  decode.d0.loss_mask: 0.2458  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.2091  decode.d1.loss_mask: 0.2526  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.1181  decode.d2.loss_mask: 0.3150  decode.d2.loss_dice: 0.2606  decode.d3.loss_cls: 0.1399  decode.d3.loss_mask: 0.3260  decode.d3.loss_dice: 0.2826  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.3160  decode.d4.loss_dice: 0.2596  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.2562  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.3097  decode.d6.loss_dice: 0.2663  decode.d7.loss_cls: 0.0942  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.3169  decode.d8.loss_dice: 0.2586
09/30 11:59:49 - mmengine - INFO - Iter(train) [ 24500/320000]  base_lr: 9.3082e-05 lr: 9.3082e-06  eta: 1 day, 11:31:54  time: 0.4340  data_time: 0.0094  memory: 5180  grad_norm: 488.8425  loss: 12.4144  decode.loss_cls: 0.2194  decode.loss_mask: 0.5988  decode.loss_dice: 0.3262  decode.d0.loss_cls: 1.2056  decode.d0.loss_mask: 0.4184  decode.d0.loss_dice: 0.3419  decode.d1.loss_cls: 0.2527  decode.d1.loss_mask: 0.7015  decode.d1.loss_dice: 0.2987  decode.d2.loss_cls: 0.2871  decode.d2.loss_mask: 0.5480  decode.d2.loss_dice: 0.2814  decode.d3.loss_cls: 0.2979  decode.d3.loss_mask: 0.5120  decode.d3.loss_dice: 0.3185  decode.d4.loss_cls: 0.3307  decode.d4.loss_mask: 0.5547  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.2749  decode.d5.loss_mask: 0.5377  decode.d5.loss_dice: 0.3016  decode.d6.loss_cls: 0.3253  decode.d6.loss_mask: 0.5599  decode.d6.loss_dice: 0.3198  decode.d7.loss_cls: 0.2885  decode.d7.loss_mask: 0.5582  decode.d7.loss_dice: 0.3302  decode.d8.loss_cls: 0.3613  decode.d8.loss_mask: 0.4422  decode.d8.loss_dice: 0.3313
09/30 12:00:11 - mmengine - INFO - Iter(train) [ 24550/320000]  base_lr: 9.3068e-05 lr: 9.3068e-06  eta: 1 day, 11:31:33  time: 0.4346  data_time: 0.0091  memory: 5180  grad_norm: 159.5320  loss: 8.1146  decode.loss_cls: 0.2487  decode.loss_mask: 0.1969  decode.loss_dice: 0.2474  decode.d0.loss_cls: 0.9463  decode.d0.loss_mask: 0.2079  decode.d0.loss_dice: 0.2878  decode.d1.loss_cls: 0.3639  decode.d1.loss_mask: 0.1937  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.3361  decode.d2.loss_mask: 0.1959  decode.d2.loss_dice: 0.2263  decode.d3.loss_cls: 0.2941  decode.d3.loss_mask: 0.2104  decode.d3.loss_dice: 0.2620  decode.d4.loss_cls: 0.2991  decode.d4.loss_mask: 0.2031  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.2488  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.2669  decode.d6.loss_cls: 0.2478  decode.d6.loss_mask: 0.2003  decode.d6.loss_dice: 0.2612  decode.d7.loss_cls: 0.2638  decode.d7.loss_mask: 0.2027  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.2555  decode.d8.loss_mask: 0.2024  decode.d8.loss_dice: 0.3084
09/30 12:00:32 - mmengine - INFO - Iter(train) [ 24600/320000]  base_lr: 9.3054e-05 lr: 9.3054e-06  eta: 1 day, 11:31:12  time: 0.4328  data_time: 0.0093  memory: 5161  grad_norm: 45.5654  loss: 6.2331  decode.loss_cls: 0.0348  decode.loss_mask: 0.2566  decode.loss_dice: 0.2116  decode.d0.loss_cls: 0.7985  decode.d0.loss_mask: 0.2698  decode.d0.loss_dice: 0.2591  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.1979  decode.d2.loss_cls: 0.1012  decode.d2.loss_mask: 0.2593  decode.d2.loss_dice: 0.2056  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.2571  decode.d3.loss_dice: 0.2078  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.2079  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2066  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.2150  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.2591  decode.d7.loss_dice: 0.2038  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.2582  decode.d8.loss_dice: 0.2068
09/30 12:00:54 - mmengine - INFO - Iter(train) [ 24650/320000]  base_lr: 9.3040e-05 lr: 9.3040e-06  eta: 1 day, 11:30:51  time: 0.4335  data_time: 0.0091  memory: 5160  grad_norm: 153.6069  loss: 7.6693  decode.loss_cls: 0.1781  decode.loss_mask: 0.2586  decode.loss_dice: 0.2490  decode.d0.loss_cls: 0.9807  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.2296  decode.d1.loss_cls: 0.2219  decode.d1.loss_mask: 0.2332  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.2631  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.2378  decode.d3.loss_cls: 0.2233  decode.d3.loss_mask: 0.2483  decode.d3.loss_dice: 0.2380  decode.d4.loss_cls: 0.2022  decode.d4.loss_mask: 0.2525  decode.d4.loss_dice: 0.2330  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 0.2558  decode.d5.loss_dice: 0.2172  decode.d6.loss_cls: 0.1737  decode.d6.loss_mask: 0.2588  decode.d6.loss_dice: 0.2487  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.2448  decode.d8.loss_cls: 0.1893  decode.d8.loss_mask: 0.2635  decode.d8.loss_dice: 0.2436
09/30 12:01:16 - mmengine - INFO - Iter(train) [ 24700/320000]  base_lr: 9.3026e-05 lr: 9.3026e-06  eta: 1 day, 11:30:29  time: 0.4335  data_time: 0.0092  memory: 5180  grad_norm: 57.4889  loss: 6.8235  decode.loss_cls: 0.0681  decode.loss_mask: 0.3033  decode.loss_dice: 0.2334  decode.d0.loss_cls: 0.7613  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.2303  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.3088  decode.d1.loss_dice: 0.2331  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.3009  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.3019  decode.d3.loss_dice: 0.2320  decode.d4.loss_cls: 0.0705  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.2284  decode.d5.loss_cls: 0.0663  decode.d5.loss_mask: 0.3027  decode.d5.loss_dice: 0.2260  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.3034  decode.d6.loss_dice: 0.2352  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.3038  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.3057  decode.d8.loss_dice: 0.2326
09/30 12:01:38 - mmengine - INFO - Iter(train) [ 24750/320000]  base_lr: 9.3012e-05 lr: 9.3012e-06  eta: 1 day, 11:30:09  time: 0.4346  data_time: 0.0095  memory: 5180  grad_norm: 83.9616  loss: 6.3121  decode.loss_cls: 0.1778  decode.loss_mask: 0.2077  decode.loss_dice: 0.1757  decode.d0.loss_cls: 0.8201  decode.d0.loss_mask: 0.2220  decode.d0.loss_dice: 0.1917  decode.d1.loss_cls: 0.1526  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.1908  decode.d2.loss_cls: 0.1522  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.1946  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.1923  decode.d4.loss_cls: 0.1605  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1813  decode.d5.loss_cls: 0.1604  decode.d5.loss_mask: 0.2084  decode.d5.loss_dice: 0.1790  decode.d6.loss_cls: 0.2100  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.1823  decode.d7.loss_cls: 0.1784  decode.d7.loss_mask: 0.2108  decode.d7.loss_dice: 0.1809  decode.d8.loss_cls: 0.1879  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.1793
09/30 12:01:59 - mmengine - INFO - Iter(train) [ 24800/320000]  base_lr: 9.2997e-05 lr: 9.2997e-06  eta: 1 day, 11:29:48  time: 0.4347  data_time: 0.0095  memory: 5161  grad_norm: 58.2480  loss: 6.4841  decode.loss_cls: 0.1205  decode.loss_mask: 0.2355  decode.loss_dice: 0.1939  decode.d0.loss_cls: 1.0175  decode.d0.loss_mask: 0.2355  decode.d0.loss_dice: 0.1937  decode.d1.loss_cls: 0.1151  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.1361  decode.d2.loss_mask: 0.2362  decode.d2.loss_dice: 0.1942  decode.d3.loss_cls: 0.1406  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.1949  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.1934  decode.d5.loss_cls: 0.1027  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.1972  decode.d6.loss_cls: 0.1263  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2006  decode.d7.loss_cls: 0.1505  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.1928  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.2376  decode.d8.loss_dice: 0.1875
09/30 12:02:21 - mmengine - INFO - Iter(train) [ 24850/320000]  base_lr: 9.2983e-05 lr: 9.2983e-06  eta: 1 day, 11:29:27  time: 0.4345  data_time: 0.0094  memory: 5161  grad_norm: 44.9693  loss: 6.0809  decode.loss_cls: 0.1219  decode.loss_mask: 0.2332  decode.loss_dice: 0.1719  decode.d0.loss_cls: 0.8602  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.1984  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 0.2358  decode.d1.loss_dice: 0.1756  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.1024  decode.d3.loss_mask: 0.2381  decode.d3.loss_dice: 0.1786  decode.d4.loss_cls: 0.1103  decode.d4.loss_mask: 0.2366  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.1033  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.1820  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 0.2399  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.1122  decode.d8.loss_mask: 0.2383  decode.d8.loss_dice: 0.1792
09/30 12:02:43 - mmengine - INFO - Iter(train) [ 24900/320000]  base_lr: 9.2969e-05 lr: 9.2969e-06  eta: 1 day, 11:29:06  time: 0.4336  data_time: 0.0091  memory: 5161  grad_norm: 71.8825  loss: 6.7831  decode.loss_cls: 0.1114  decode.loss_mask: 0.2737  decode.loss_dice: 0.2083  decode.d0.loss_cls: 0.8397  decode.d0.loss_mask: 0.2819  decode.d0.loss_dice: 0.2388  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.2771  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.2739  decode.d2.loss_dice: 0.2281  decode.d3.loss_cls: 0.1092  decode.d3.loss_mask: 0.2787  decode.d3.loss_dice: 0.2409  decode.d4.loss_cls: 0.1078  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.2378  decode.d5.loss_cls: 0.1106  decode.d5.loss_mask: 0.2756  decode.d5.loss_dice: 0.2179  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.2732  decode.d6.loss_dice: 0.2325  decode.d7.loss_cls: 0.1144  decode.d7.loss_mask: 0.2755  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.1272  decode.d8.loss_mask: 0.2764  decode.d8.loss_dice: 0.2355
09/30 12:03:04 - mmengine - INFO - Iter(train) [ 24950/320000]  base_lr: 9.2955e-05 lr: 9.2955e-06  eta: 1 day, 11:28:45  time: 0.4340  data_time: 0.0094  memory: 5147  grad_norm: 14.5515  loss: 4.6508  decode.loss_cls: 0.0183  decode.loss_mask: 0.2118  decode.loss_dice: 0.1538  decode.d0.loss_cls: 0.7552  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.1575  decode.d1.loss_cls: 0.0286  decode.d1.loss_mask: 0.2133  decode.d1.loss_dice: 0.1576  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.2131  decode.d2.loss_dice: 0.1586  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.2135  decode.d3.loss_dice: 0.1583  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.2139  decode.d4.loss_dice: 0.1622  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.2134  decode.d5.loss_dice: 0.1614  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.1558  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.2134  decode.d7.loss_dice: 0.1565  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.1607
09/30 12:03:26 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:03:26 - mmengine - INFO - Iter(train) [ 25000/320000]  base_lr: 9.2941e-05 lr: 9.2941e-06  eta: 1 day, 11:28:24  time: 0.4335  data_time: 0.0095  memory: 5161  grad_norm: 124.0904  loss: 11.7718  decode.loss_cls: 0.3450  decode.loss_mask: 0.3766  decode.loss_dice: 0.3502  decode.d0.loss_cls: 0.9835  decode.d0.loss_mask: 0.3732  decode.d0.loss_dice: 0.3875  decode.d1.loss_cls: 0.4075  decode.d1.loss_mask: 0.3798  decode.d1.loss_dice: 0.3575  decode.d2.loss_cls: 0.3313  decode.d2.loss_mask: 0.3600  decode.d2.loss_dice: 0.3580  decode.d3.loss_cls: 0.3945  decode.d3.loss_mask: 0.3764  decode.d3.loss_dice: 0.3602  decode.d4.loss_cls: 0.4087  decode.d4.loss_mask: 0.4279  decode.d4.loss_dice: 0.3411  decode.d5.loss_cls: 0.3687  decode.d5.loss_mask: 0.4038  decode.d5.loss_dice: 0.3835  decode.d6.loss_cls: 0.3608  decode.d6.loss_mask: 0.3943  decode.d6.loss_dice: 0.3561  decode.d7.loss_cls: 0.3499  decode.d7.loss_mask: 0.4225  decode.d7.loss_dice: 0.3695  decode.d8.loss_cls: 0.3109  decode.d8.loss_mask: 0.3715  decode.d8.loss_dice: 0.3613
09/30 12:03:48 - mmengine - INFO - Iter(train) [ 25050/320000]  base_lr: 9.2927e-05 lr: 9.2927e-06  eta: 1 day, 11:28:03  time: 0.4337  data_time: 0.0093  memory: 5147  grad_norm: 456.2076  loss: 9.7155  decode.loss_cls: 0.1194  decode.loss_mask: 0.4302  decode.loss_dice: 0.3243  decode.d0.loss_cls: 1.0732  decode.d0.loss_mask: 0.3774  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.2752  decode.d1.loss_mask: 0.3500  decode.d1.loss_dice: 0.3219  decode.d2.loss_cls: 0.2458  decode.d2.loss_mask: 0.3334  decode.d2.loss_dice: 0.3065  decode.d3.loss_cls: 0.1839  decode.d3.loss_mask: 0.3363  decode.d3.loss_dice: 0.3320  decode.d4.loss_cls: 0.1956  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.3398  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 0.3437  decode.d5.loss_dice: 0.3278  decode.d6.loss_cls: 0.1867  decode.d6.loss_mask: 0.3317  decode.d6.loss_dice: 0.2947  decode.d7.loss_cls: 0.2129  decode.d7.loss_mask: 0.3339  decode.d7.loss_dice: 0.3249  decode.d8.loss_cls: 0.2312  decode.d8.loss_mask: 0.3623  decode.d8.loss_dice: 0.3577
09/30 12:04:09 - mmengine - INFO - Iter(train) [ 25100/320000]  base_lr: 9.2912e-05 lr: 9.2912e-06  eta: 1 day, 11:27:42  time: 0.4338  data_time: 0.0093  memory: 5180  grad_norm: 50.9050  loss: 5.6785  decode.loss_cls: 0.0844  decode.loss_mask: 0.2225  decode.loss_dice: 0.1808  decode.d0.loss_cls: 0.9040  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.1876  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 0.2147  decode.d1.loss_dice: 0.1758  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.1733  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.2192  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.1773  decode.d6.loss_cls: 0.0966  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.1725  decode.d7.loss_cls: 0.0832  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.1719  decode.d8.loss_cls: 0.0878  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.1816
09/30 12:04:31 - mmengine - INFO - Iter(train) [ 25150/320000]  base_lr: 9.2898e-05 lr: 9.2898e-06  eta: 1 day, 11:27:21  time: 0.4333  data_time: 0.0091  memory: 5180  grad_norm: 39.9197  loss: 5.3463  decode.loss_cls: 0.0518  decode.loss_mask: 0.1842  decode.loss_dice: 0.1655  decode.d0.loss_cls: 1.0457  decode.d0.loss_mask: 0.1909  decode.d0.loss_dice: 0.1710  decode.d1.loss_cls: 0.1609  decode.d1.loss_mask: 0.1845  decode.d1.loss_dice: 0.1806  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 0.1862  decode.d2.loss_dice: 0.1666  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.1869  decode.d3.loss_dice: 0.1658  decode.d4.loss_cls: 0.0691  decode.d4.loss_mask: 0.1899  decode.d4.loss_dice: 0.1803  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.1869  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.1892  decode.d6.loss_dice: 0.1676  decode.d7.loss_cls: 0.1182  decode.d7.loss_mask: 0.1874  decode.d7.loss_dice: 0.1617  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.1837  decode.d8.loss_dice: 0.1692
09/30 12:04:53 - mmengine - INFO - Iter(train) [ 25200/320000]  base_lr: 9.2884e-05 lr: 9.2884e-06  eta: 1 day, 11:26:59  time: 0.4334  data_time: 0.0092  memory: 5161  grad_norm: 161.6418  loss: 9.5731  decode.loss_cls: 0.1093  decode.loss_mask: 0.4476  decode.loss_dice: 0.2980  decode.d0.loss_cls: 0.8846  decode.d0.loss_mask: 0.4568  decode.d0.loss_dice: 0.2895  decode.d1.loss_cls: 0.2415  decode.d1.loss_mask: 0.3858  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.2001  decode.d2.loss_mask: 0.3953  decode.d2.loss_dice: 0.2785  decode.d3.loss_cls: 0.2047  decode.d3.loss_mask: 0.3853  decode.d3.loss_dice: 0.2868  decode.d4.loss_cls: 0.2199  decode.d4.loss_mask: 0.3951  decode.d4.loss_dice: 0.2787  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 0.4423  decode.d5.loss_dice: 0.2970  decode.d6.loss_cls: 0.2195  decode.d6.loss_mask: 0.3847  decode.d6.loss_dice: 0.2860  decode.d7.loss_cls: 0.2032  decode.d7.loss_mask: 0.3890  decode.d7.loss_dice: 0.2787  decode.d8.loss_cls: 0.2231  decode.d8.loss_mask: 0.3934  decode.d8.loss_dice: 0.2716
09/30 12:05:15 - mmengine - INFO - Iter(train) [ 25250/320000]  base_lr: 9.2870e-05 lr: 9.2870e-06  eta: 1 day, 11:26:39  time: 0.4341  data_time: 0.0093  memory: 5160  grad_norm: 142.4101  loss: 9.1271  decode.loss_cls: 0.2563  decode.loss_mask: 0.3153  decode.loss_dice: 0.2754  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.3139  decode.d1.loss_cls: 0.3297  decode.d1.loss_mask: 0.3137  decode.d1.loss_dice: 0.2935  decode.d2.loss_cls: 0.2321  decode.d2.loss_mask: 0.2933  decode.d2.loss_dice: 0.2992  decode.d3.loss_cls: 0.2416  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.2987  decode.d4.loss_cls: 0.2312  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 0.3358  decode.d5.loss_mask: 0.2997  decode.d5.loss_dice: 0.2892  decode.d6.loss_cls: 0.2331  decode.d6.loss_mask: 0.3280  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.2449  decode.d7.loss_mask: 0.3176  decode.d7.loss_dice: 0.2807  decode.d8.loss_cls: 0.2249  decode.d8.loss_mask: 0.3118  decode.d8.loss_dice: 0.2649
09/30 12:05:36 - mmengine - INFO - Iter(train) [ 25300/320000]  base_lr: 9.2856e-05 lr: 9.2856e-06  eta: 1 day, 11:26:18  time: 0.4337  data_time: 0.0090  memory: 5161  grad_norm: 34.5315  loss: 6.6895  decode.loss_cls: 0.2148  decode.loss_mask: 0.2101  decode.loss_dice: 0.2013  decode.d0.loss_cls: 1.0081  decode.d0.loss_mask: 0.1832  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.2545  decode.d1.loss_mask: 0.1830  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.2238  decode.d2.loss_mask: 0.1843  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.1762  decode.d3.loss_mask: 0.1829  decode.d3.loss_dice: 0.1826  decode.d4.loss_cls: 0.1755  decode.d4.loss_mask: 0.1824  decode.d4.loss_dice: 0.1777  decode.d5.loss_cls: 0.2248  decode.d5.loss_mask: 0.1887  decode.d5.loss_dice: 0.2193  decode.d6.loss_cls: 0.1844  decode.d6.loss_mask: 0.1848  decode.d6.loss_dice: 0.1738  decode.d7.loss_cls: 0.2107  decode.d7.loss_mask: 0.1831  decode.d7.loss_dice: 0.1707  decode.d8.loss_cls: 0.2472  decode.d8.loss_mask: 0.1966  decode.d8.loss_dice: 0.1933
09/30 12:05:58 - mmengine - INFO - Iter(train) [ 25350/320000]  base_lr: 9.2841e-05 lr: 9.2841e-06  eta: 1 day, 11:25:57  time: 0.4333  data_time: 0.0093  memory: 5147  grad_norm: 120.0852  loss: 7.4032  decode.loss_cls: 0.1408  decode.loss_mask: 0.2629  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.9384  decode.d0.loss_mask: 0.2793  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.2006  decode.d1.loss_mask: 0.2617  decode.d1.loss_dice: 0.2112  decode.d2.loss_cls: 0.1355  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.2275  decode.d3.loss_cls: 0.1248  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2352  decode.d4.loss_cls: 0.1561  decode.d4.loss_mask: 0.2563  decode.d4.loss_dice: 0.2312  decode.d5.loss_cls: 0.1752  decode.d5.loss_mask: 0.2563  decode.d5.loss_dice: 0.2129  decode.d6.loss_cls: 0.2153  decode.d6.loss_mask: 0.2615  decode.d6.loss_dice: 0.2159  decode.d7.loss_cls: 0.2410  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.2313  decode.d8.loss_cls: 0.1815  decode.d8.loss_mask: 0.2600  decode.d8.loss_dice: 0.2229
09/30 12:06:20 - mmengine - INFO - Iter(train) [ 25400/320000]  base_lr: 9.2827e-05 lr: 9.2827e-06  eta: 1 day, 11:25:36  time: 0.4333  data_time: 0.0090  memory: 5161  grad_norm: 60.6474  loss: 5.4643  decode.loss_cls: 0.1040  decode.loss_mask: 0.1828  decode.loss_dice: 0.1507  decode.d0.loss_cls: 0.8883  decode.d0.loss_mask: 0.1843  decode.d0.loss_dice: 0.1510  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.1870  decode.d1.loss_dice: 0.1766  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.1807  decode.d2.loss_dice: 0.1521  decode.d3.loss_cls: 0.1409  decode.d3.loss_mask: 0.1960  decode.d3.loss_dice: 0.1727  decode.d4.loss_cls: 0.1104  decode.d4.loss_mask: 0.1925  decode.d4.loss_dice: 0.1775  decode.d5.loss_cls: 0.1317  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.1863  decode.d6.loss_cls: 0.1532  decode.d6.loss_mask: 0.1867  decode.d6.loss_dice: 0.1511  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.1810  decode.d7.loss_dice: 0.1520  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.1644
09/30 12:06:41 - mmengine - INFO - Iter(train) [ 25450/320000]  base_lr: 9.2813e-05 lr: 9.2813e-06  eta: 1 day, 11:25:14  time: 0.4337  data_time: 0.0092  memory: 5161  grad_norm: 54.6875  loss: 7.4041  decode.loss_cls: 0.1218  decode.loss_mask: 0.3193  decode.loss_dice: 0.2326  decode.d0.loss_cls: 0.6544  decode.d0.loss_mask: 0.4382  decode.d0.loss_dice: 0.2403  decode.d1.loss_cls: 0.1056  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.2493  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.3270  decode.d2.loss_dice: 0.2438  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.4194  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.1105  decode.d4.loss_mask: 0.3116  decode.d4.loss_dice: 0.2158  decode.d5.loss_cls: 0.0348  decode.d5.loss_mask: 0.4211  decode.d5.loss_dice: 0.2254  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.4207  decode.d6.loss_dice: 0.2298  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.4259  decode.d7.loss_dice: 0.2191  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 0.3125  decode.d8.loss_dice: 0.2373
09/30 12:07:03 - mmengine - INFO - Iter(train) [ 25500/320000]  base_lr: 9.2799e-05 lr: 9.2799e-06  eta: 1 day, 11:24:53  time: 0.4339  data_time: 0.0090  memory: 5160  grad_norm: 79.0376  loss: 6.5432  decode.loss_cls: 0.1123  decode.loss_mask: 0.2447  decode.loss_dice: 0.2158  decode.d0.loss_cls: 0.7840  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2411  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.2445  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.1392  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2221  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2185  decode.d4.loss_cls: 0.1189  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.2180  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.2054  decode.d6.loss_cls: 0.1098  decode.d6.loss_mask: 0.2483  decode.d6.loss_dice: 0.2361  decode.d7.loss_cls: 0.1298  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2356  decode.d8.loss_cls: 0.1140  decode.d8.loss_mask: 0.2447  decode.d8.loss_dice: 0.2259
09/30 12:07:25 - mmengine - INFO - Iter(train) [ 25550/320000]  base_lr: 9.2785e-05 lr: 9.2785e-06  eta: 1 day, 11:24:31  time: 0.4331  data_time: 0.0089  memory: 5180  grad_norm: 27.4044  loss: 5.8730  decode.loss_cls: 0.0241  decode.loss_mask: 0.2737  decode.loss_dice: 0.2003  decode.d0.loss_cls: 0.8169  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.2081  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.2732  decode.d1.loss_dice: 0.2013  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.2732  decode.d3.loss_dice: 0.1921  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.2757  decode.d4.loss_dice: 0.1960  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.2774  decode.d5.loss_dice: 0.1978  decode.d6.loss_cls: 0.0229  decode.d6.loss_mask: 0.2730  decode.d6.loss_dice: 0.2026  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.2709  decode.d7.loss_dice: 0.1974  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.2065
09/30 12:07:46 - mmengine - INFO - Iter(train) [ 25600/320000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 1 day, 11:24:10  time: 0.4331  data_time: 0.0089  memory: 5180  grad_norm: 64.5755  loss: 8.5269  decode.loss_cls: 0.2350  decode.loss_mask: 0.2777  decode.loss_dice: 0.2451  decode.d0.loss_cls: 1.0884  decode.d0.loss_mask: 0.2782  decode.d0.loss_dice: 0.2697  decode.d1.loss_cls: 0.2863  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.2487  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.2827  decode.d2.loss_dice: 0.2464  decode.d3.loss_cls: 0.2262  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2466  decode.d4.loss_cls: 0.2111  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.2386  decode.d5.loss_cls: 0.2061  decode.d5.loss_mask: 0.2810  decode.d5.loss_dice: 0.2541  decode.d6.loss_cls: 0.2237  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.2625  decode.d7.loss_cls: 0.2593  decode.d7.loss_mask: 0.2710  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.2506  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.2421
09/30 12:08:08 - mmengine - INFO - Iter(train) [ 25650/320000]  base_lr: 9.2756e-05 lr: 9.2756e-06  eta: 1 day, 11:23:49  time: 0.4336  data_time: 0.0089  memory: 5161  grad_norm: 85.5497  loss: 6.9715  decode.loss_cls: 0.1610  decode.loss_mask: 0.2264  decode.loss_dice: 0.2338  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.2430  decode.d1.loss_cls: 0.1858  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.2379  decode.d2.loss_cls: 0.1901  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.2399  decode.d3.loss_cls: 0.1471  decode.d3.loss_mask: 0.2235  decode.d3.loss_dice: 0.2367  decode.d4.loss_cls: 0.1443  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.2383  decode.d5.loss_cls: 0.1396  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2335  decode.d6.loss_cls: 0.1540  decode.d6.loss_mask: 0.2260  decode.d6.loss_dice: 0.2370  decode.d7.loss_cls: 0.1405  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.2389  decode.d8.loss_cls: 0.1393  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2425
09/30 12:08:30 - mmengine - INFO - Iter(train) [ 25700/320000]  base_lr: 9.2742e-05 lr: 9.2742e-06  eta: 1 day, 11:23:28  time: 0.4336  data_time: 0.0091  memory: 5161  grad_norm: 136.4342  loss: 5.9590  decode.loss_cls: 0.0305  decode.loss_mask: 0.2844  decode.loss_dice: 0.1982  decode.d0.loss_cls: 0.7646  decode.d0.loss_mask: 0.2974  decode.d0.loss_dice: 0.2049  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.2916  decode.d2.loss_dice: 0.1972  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2864  decode.d3.loss_dice: 0.2005  decode.d4.loss_cls: 0.0277  decode.d4.loss_mask: 0.2889  decode.d4.loss_dice: 0.2012  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.2874  decode.d5.loss_dice: 0.1997  decode.d6.loss_cls: 0.0377  decode.d6.loss_mask: 0.2888  decode.d6.loss_dice: 0.2068  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.2010  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.2886  decode.d8.loss_dice: 0.2004
09/30 12:08:51 - mmengine - INFO - Iter(train) [ 25750/320000]  base_lr: 9.2728e-05 lr: 9.2728e-06  eta: 1 day, 11:23:06  time: 0.4341  data_time: 0.0093  memory: 5180  grad_norm: 70.3584  loss: 7.5891  decode.loss_cls: 0.1279  decode.loss_mask: 0.2384  decode.loss_dice: 0.2152  decode.d0.loss_cls: 1.1183  decode.d0.loss_mask: 0.2377  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2135  decode.d2.loss_cls: 0.2351  decode.d2.loss_mask: 0.2480  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.1695  decode.d3.loss_mask: 0.2435  decode.d3.loss_dice: 0.2275  decode.d4.loss_cls: 0.1579  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.2577  decode.d5.loss_cls: 0.2464  decode.d5.loss_mask: 0.2362  decode.d5.loss_dice: 0.2177  decode.d6.loss_cls: 0.1892  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2272  decode.d7.loss_cls: 0.1863  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.1780  decode.d8.loss_mask: 0.2372  decode.d8.loss_dice: 0.2084
09/30 12:09:13 - mmengine - INFO - Iter(train) [ 25800/320000]  base_lr: 9.2714e-05 lr: 9.2714e-06  eta: 1 day, 11:22:45  time: 0.4340  data_time: 0.0093  memory: 5160  grad_norm: 29.5970  loss: 6.2639  decode.loss_cls: 0.0658  decode.loss_mask: 0.2355  decode.loss_dice: 0.2418  decode.d0.loss_cls: 0.9103  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.2359  decode.d1.loss_dice: 0.2134  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2194  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.2415  decode.d3.loss_dice: 0.2295  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.2424  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.0893  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 0.2429  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.2235  decode.d8.loss_cls: 0.1024  decode.d8.loss_mask: 0.2381  decode.d8.loss_dice: 0.2159
09/30 12:09:35 - mmengine - INFO - Iter(train) [ 25850/320000]  base_lr: 9.2700e-05 lr: 9.2700e-06  eta: 1 day, 11:22:25  time: 0.4338  data_time: 0.0092  memory: 5160  grad_norm: 199.8549  loss: 10.7506  decode.loss_cls: 0.3755  decode.loss_mask: 0.3574  decode.loss_dice: 0.2407  decode.d0.loss_cls: 1.0440  decode.d0.loss_mask: 0.2711  decode.d0.loss_dice: 0.2720  decode.d1.loss_cls: 0.4541  decode.d1.loss_mask: 0.3101  decode.d1.loss_dice: 0.2627  decode.d2.loss_cls: 0.4655  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.2913  decode.d3.loss_cls: 0.4020  decode.d3.loss_mask: 0.3311  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.4533  decode.d4.loss_mask: 0.3749  decode.d4.loss_dice: 0.2780  decode.d5.loss_cls: 0.4116  decode.d5.loss_mask: 0.3958  decode.d5.loss_dice: 0.2680  decode.d6.loss_cls: 0.3847  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.3642  decode.d7.loss_mask: 0.3475  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.3825  decode.d8.loss_mask: 0.2827  decode.d8.loss_dice: 0.2940
09/30 12:09:57 - mmengine - INFO - Iter(train) [ 25900/320000]  base_lr: 9.2685e-05 lr: 9.2685e-06  eta: 1 day, 11:22:04  time: 0.4345  data_time: 0.0093  memory: 5161  grad_norm: 114.5739  loss: 9.7322  decode.loss_cls: 0.1931  decode.loss_mask: 0.4825  decode.loss_dice: 0.3862  decode.d0.loss_cls: 0.8837  decode.d0.loss_mask: 0.2867  decode.d0.loss_dice: 0.3496  decode.d1.loss_cls: 0.3340  decode.d1.loss_mask: 0.2963  decode.d1.loss_dice: 0.3324  decode.d2.loss_cls: 0.2691  decode.d2.loss_mask: 0.2789  decode.d2.loss_dice: 0.2963  decode.d3.loss_cls: 0.2692  decode.d3.loss_mask: 0.2788  decode.d3.loss_dice: 0.2815  decode.d4.loss_cls: 0.2073  decode.d4.loss_mask: 0.2806  decode.d4.loss_dice: 0.2678  decode.d5.loss_cls: 0.2620  decode.d5.loss_mask: 0.2785  decode.d5.loss_dice: 0.2757  decode.d6.loss_cls: 0.2842  decode.d6.loss_mask: 0.2835  decode.d6.loss_dice: 0.3074  decode.d7.loss_cls: 0.2490  decode.d7.loss_mask: 0.3405  decode.d7.loss_dice: 0.3612  decode.d8.loss_cls: 0.1957  decode.d8.loss_mask: 0.5600  decode.d8.loss_dice: 0.3604
09/30 12:10:18 - mmengine - INFO - Iter(train) [ 25950/320000]  base_lr: 9.2671e-05 lr: 9.2671e-06  eta: 1 day, 11:21:43  time: 0.4343  data_time: 0.0093  memory: 5180  grad_norm: 73.5322  loss: 5.2033  decode.loss_cls: 0.0569  decode.loss_mask: 0.2217  decode.loss_dice: 0.1643  decode.d0.loss_cls: 0.7439  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1638  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.1596  decode.d2.loss_cls: 0.0429  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.1594  decode.d3.loss_cls: 0.0480  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.1637  decode.d4.loss_cls: 0.1029  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.1933  decode.d5.loss_cls: 0.0744  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.1712  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.2252  decode.d6.loss_dice: 0.1766  decode.d7.loss_cls: 0.0395  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.1691  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1630
09/30 12:10:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:10:40 - mmengine - INFO - Iter(train) [ 26000/320000]  base_lr: 9.2657e-05 lr: 9.2657e-06  eta: 1 day, 11:21:22  time: 0.4350  data_time: 0.0095  memory: 5161  grad_norm: 273.3179  loss: 10.9678  decode.loss_cls: 0.2288  decode.loss_mask: 0.3862  decode.loss_dice: 0.3235  decode.d0.loss_cls: 1.1323  decode.d0.loss_mask: 0.3437  decode.d0.loss_dice: 0.2878  decode.d1.loss_cls: 0.4036  decode.d1.loss_mask: 0.3574  decode.d1.loss_dice: 0.2933  decode.d2.loss_cls: 0.3462  decode.d2.loss_mask: 0.3408  decode.d2.loss_dice: 0.2669  decode.d3.loss_cls: 0.3178  decode.d3.loss_mask: 0.3770  decode.d3.loss_dice: 0.3192  decode.d4.loss_cls: 0.3480  decode.d4.loss_mask: 0.4279  decode.d4.loss_dice: 0.3244  decode.d5.loss_cls: 0.3268  decode.d5.loss_mask: 0.4102  decode.d5.loss_dice: 0.3390  decode.d6.loss_cls: 0.3002  decode.d6.loss_mask: 0.4137  decode.d6.loss_dice: 0.3342  decode.d7.loss_cls: 0.2965  decode.d7.loss_mask: 0.4304  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 0.2439  decode.d8.loss_mask: 0.3726  decode.d8.loss_dice: 0.3322
09/30 12:11:02 - mmengine - INFO - Iter(train) [ 26050/320000]  base_lr: 9.2643e-05 lr: 9.2643e-06  eta: 1 day, 11:21:03  time: 0.4331  data_time: 0.0091  memory: 5161  grad_norm: 38.4943  loss: 5.1914  decode.loss_cls: 0.0273  decode.loss_mask: 0.2114  decode.loss_dice: 0.1801  decode.d0.loss_cls: 0.9153  decode.d0.loss_mask: 0.2244  decode.d0.loss_dice: 0.1907  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.1741  decode.d2.loss_cls: 0.0342  decode.d2.loss_mask: 0.2149  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.2109  decode.d3.loss_dice: 0.1774  decode.d4.loss_cls: 0.0484  decode.d4.loss_mask: 0.2123  decode.d4.loss_dice: 0.1820  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.1804  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.2127  decode.d6.loss_dice: 0.1792  decode.d7.loss_cls: 0.0284  decode.d7.loss_mask: 0.2105  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0300  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.1800
09/30 12:11:24 - mmengine - INFO - Iter(train) [ 26100/320000]  base_lr: 9.2629e-05 lr: 9.2629e-06  eta: 1 day, 11:20:42  time: 0.4344  data_time: 0.0096  memory: 5160  grad_norm: 127.5802  loss: 8.5662  decode.loss_cls: 0.1326  decode.loss_mask: 0.3728  decode.loss_dice: 0.2313  decode.d0.loss_cls: 1.0338  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.2105  decode.d1.loss_cls: 0.2838  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.2167  decode.d2.loss_cls: 0.2725  decode.d2.loss_mask: 0.3241  decode.d2.loss_dice: 0.2183  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 0.3667  decode.d3.loss_dice: 0.2319  decode.d4.loss_cls: 0.1400  decode.d4.loss_mask: 0.4092  decode.d4.loss_dice: 0.2434  decode.d5.loss_cls: 0.1770  decode.d5.loss_mask: 0.3821  decode.d5.loss_dice: 0.2368  decode.d6.loss_cls: 0.1690  decode.d6.loss_mask: 0.3804  decode.d6.loss_dice: 0.2419  decode.d7.loss_cls: 0.1850  decode.d7.loss_mask: 0.3309  decode.d7.loss_dice: 0.2177  decode.d8.loss_cls: 0.2024  decode.d8.loss_mask: 0.3289  decode.d8.loss_dice: 0.2204
09/30 12:11:45 - mmengine - INFO - Iter(train) [ 26150/320000]  base_lr: 9.2615e-05 lr: 9.2615e-06  eta: 1 day, 11:20:21  time: 0.4335  data_time: 0.0092  memory: 5161  grad_norm: 107.7383  loss: 7.4994  decode.loss_cls: 0.1575  decode.loss_mask: 0.2833  decode.loss_dice: 0.2317  decode.d0.loss_cls: 0.9975  decode.d0.loss_mask: 0.2975  decode.d0.loss_dice: 0.2149  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.2789  decode.d1.loss_dice: 0.2087  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.2872  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.4835  decode.d3.loss_dice: 0.2337  decode.d4.loss_cls: 0.0991  decode.d4.loss_mask: 0.3584  decode.d4.loss_dice: 0.2257  decode.d5.loss_cls: 0.1217  decode.d5.loss_mask: 0.3902  decode.d5.loss_dice: 0.2261  decode.d6.loss_cls: 0.0946  decode.d6.loss_mask: 0.3395  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.2266  decode.d8.loss_cls: 0.1229  decode.d8.loss_mask: 0.2902  decode.d8.loss_dice: 0.2141
09/30 12:12:07 - mmengine - INFO - Iter(train) [ 26200/320000]  base_lr: 9.2600e-05 lr: 9.2600e-06  eta: 1 day, 11:20:00  time: 0.4340  data_time: 0.0093  memory: 5161  grad_norm: 78.6238  loss: 7.3839  decode.loss_cls: 0.1310  decode.loss_mask: 0.2472  decode.loss_dice: 0.2826  decode.d0.loss_cls: 0.8168  decode.d0.loss_mask: 0.2694  decode.d0.loss_dice: 0.2663  decode.d1.loss_cls: 0.2177  decode.d1.loss_mask: 0.2479  decode.d1.loss_dice: 0.2831  decode.d2.loss_cls: 0.2044  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.1711  decode.d3.loss_mask: 0.2496  decode.d3.loss_dice: 0.2593  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 0.2470  decode.d4.loss_dice: 0.2686  decode.d5.loss_cls: 0.1687  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2586  decode.d6.loss_cls: 0.1609  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.1404  decode.d7.loss_mask: 0.2491  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 0.2441  decode.d8.loss_dice: 0.2582
09/30 12:12:29 - mmengine - INFO - Iter(train) [ 26250/320000]  base_lr: 9.2586e-05 lr: 9.2586e-06  eta: 1 day, 11:19:39  time: 0.4344  data_time: 0.0092  memory: 5180  grad_norm: 96.7827  loss: 8.5653  decode.loss_cls: 0.1629  decode.loss_mask: 0.2736  decode.loss_dice: 0.2359  decode.d0.loss_cls: 1.0239  decode.d0.loss_mask: 0.2940  decode.d0.loss_dice: 0.2568  decode.d1.loss_cls: 0.3677  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.2317  decode.d2.loss_cls: 0.2920  decode.d2.loss_mask: 0.2756  decode.d2.loss_dice: 0.2358  decode.d3.loss_cls: 0.2623  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.2299  decode.d4.loss_cls: 0.3481  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.2450  decode.d5.loss_cls: 0.3230  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.2617  decode.d6.loss_cls: 0.1801  decode.d6.loss_mask: 0.2817  decode.d6.loss_dice: 0.2568  decode.d7.loss_cls: 0.2432  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.2336  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.2763  decode.d8.loss_dice: 0.2305
09/30 12:12:50 - mmengine - INFO - Iter(train) [ 26300/320000]  base_lr: 9.2572e-05 lr: 9.2572e-06  eta: 1 day, 11:19:18  time: 0.4332  data_time: 0.0093  memory: 5161  grad_norm: 528.3010  loss: 10.2077  decode.loss_cls: 0.1784  decode.loss_mask: 0.3464  decode.loss_dice: 0.3598  decode.d0.loss_cls: 0.8495  decode.d0.loss_mask: 0.3629  decode.d0.loss_dice: 0.3764  decode.d1.loss_cls: 0.3015  decode.d1.loss_mask: 0.3518  decode.d1.loss_dice: 0.3783  decode.d2.loss_cls: 0.1930  decode.d2.loss_mask: 0.3436  decode.d2.loss_dice: 0.3495  decode.d3.loss_cls: 0.2652  decode.d3.loss_mask: 0.3396  decode.d3.loss_dice: 0.3573  decode.d4.loss_cls: 0.2685  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.4020  decode.d5.loss_cls: 0.2425  decode.d5.loss_mask: 0.4239  decode.d5.loss_dice: 0.4290  decode.d6.loss_cls: 0.2287  decode.d6.loss_mask: 0.3444  decode.d6.loss_dice: 0.3664  decode.d7.loss_cls: 0.2030  decode.d7.loss_mask: 0.3463  decode.d7.loss_dice: 0.3666  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.3470  decode.d8.loss_dice: 0.3522
09/30 12:13:12 - mmengine - INFO - Iter(train) [ 26350/320000]  base_lr: 9.2558e-05 lr: 9.2558e-06  eta: 1 day, 11:18:57  time: 0.4347  data_time: 0.0094  memory: 5160  grad_norm: 80.7510  loss: 8.3804  decode.loss_cls: 0.1259  decode.loss_mask: 0.3223  decode.loss_dice: 0.2751  decode.d0.loss_cls: 1.0079  decode.d0.loss_mask: 0.3267  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.2043  decode.d1.loss_mask: 0.3179  decode.d1.loss_dice: 0.2393  decode.d2.loss_cls: 0.2126  decode.d2.loss_mask: 0.3160  decode.d2.loss_dice: 0.2417  decode.d3.loss_cls: 0.1904  decode.d3.loss_mask: 0.3191  decode.d3.loss_dice: 0.2630  decode.d4.loss_cls: 0.1762  decode.d4.loss_mask: 0.3168  decode.d4.loss_dice: 0.2669  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 0.3188  decode.d5.loss_dice: 0.2754  decode.d6.loss_cls: 0.1849  decode.d6.loss_mask: 0.3162  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.1746  decode.d7.loss_mask: 0.3206  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 0.3202  decode.d8.loss_dice: 0.2654
09/30 12:13:34 - mmengine - INFO - Iter(train) [ 26400/320000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 1 day, 11:18:37  time: 0.4353  data_time: 0.0092  memory: 5160  grad_norm: 32.1767  loss: 4.6768  decode.loss_cls: 0.0227  decode.loss_mask: 0.1717  decode.loss_dice: 0.1753  decode.d0.loss_cls: 0.9764  decode.d0.loss_mask: 0.1744  decode.d0.loss_dice: 0.1760  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.1722  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.1700  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.1701  decode.d3.loss_dice: 0.1792  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.1703  decode.d4.loss_dice: 0.1770  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.1708  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.1718  decode.d6.loss_dice: 0.1703  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.1700  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.1710  decode.d8.loss_dice: 0.1801
09/30 12:13:56 - mmengine - INFO - Iter(train) [ 26450/320000]  base_lr: 9.2529e-05 lr: 9.2529e-06  eta: 1 day, 11:18:16  time: 0.4347  data_time: 0.0092  memory: 5180  grad_norm: 38.8834  loss: 7.0785  decode.loss_cls: 0.1735  decode.loss_mask: 0.2525  decode.loss_dice: 0.2041  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.2230  decode.d1.loss_cls: 0.1685  decode.d1.loss_mask: 0.2457  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.2133  decode.d2.loss_mask: 0.2502  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 0.2566  decode.d3.loss_dice: 0.2325  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.1710  decode.d5.loss_mask: 0.2509  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.1537  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.2059  decode.d7.loss_cls: 0.1728  decode.d7.loss_mask: 0.2548  decode.d7.loss_dice: 0.2126  decode.d8.loss_cls: 0.1671  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.2048
09/30 12:14:17 - mmengine - INFO - Iter(train) [ 26500/320000]  base_lr: 9.2515e-05 lr: 9.2515e-06  eta: 1 day, 11:17:55  time: 0.4340  data_time: 0.0091  memory: 5160  grad_norm: 93.0774  loss: 10.2333  decode.loss_cls: 0.3413  decode.loss_mask: 0.4124  decode.loss_dice: 0.3353  decode.d0.loss_cls: 1.0345  decode.d0.loss_mask: 0.2482  decode.d0.loss_dice: 0.2956  decode.d1.loss_cls: 0.3904  decode.d1.loss_mask: 0.2463  decode.d1.loss_dice: 0.3115  decode.d2.loss_cls: 0.3093  decode.d2.loss_mask: 0.2441  decode.d2.loss_dice: 0.3078  decode.d3.loss_cls: 0.3645  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.3305  decode.d4.loss_cls: 0.3528  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.3429  decode.d5.loss_cls: 0.2883  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.3322  decode.d6.loss_cls: 0.3410  decode.d6.loss_mask: 0.2874  decode.d6.loss_dice: 0.3476  decode.d7.loss_cls: 0.3330  decode.d7.loss_mask: 0.2651  decode.d7.loss_dice: 0.3413  decode.d8.loss_cls: 0.3478  decode.d8.loss_mask: 0.4045  decode.d8.loss_dice: 0.3209
09/30 12:14:39 - mmengine - INFO - Iter(train) [ 26550/320000]  base_lr: 9.2501e-05 lr: 9.2501e-06  eta: 1 day, 11:17:34  time: 0.4344  data_time: 0.0092  memory: 5147  grad_norm: 40.3337  loss: 5.8621  decode.loss_cls: 0.0562  decode.loss_mask: 0.2266  decode.loss_dice: 0.2072  decode.d0.loss_cls: 0.8403  decode.d0.loss_mask: 0.2356  decode.d0.loss_dice: 0.2041  decode.d1.loss_cls: 0.0824  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.0924  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.2099  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.0657  decode.d4.loss_mask: 0.2306  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.2219  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.2250  decode.d6.loss_dice: 0.2184  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.2294  decode.d7.loss_dice: 0.2190  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2203
09/30 12:15:01 - mmengine - INFO - Iter(train) [ 26600/320000]  base_lr: 9.2487e-05 lr: 9.2487e-06  eta: 1 day, 11:17:13  time: 0.4333  data_time: 0.0090  memory: 5180  grad_norm: 86.7664  loss: 8.6066  decode.loss_cls: 0.2122  decode.loss_mask: 0.2879  decode.loss_dice: 0.2945  decode.d0.loss_cls: 0.8733  decode.d0.loss_mask: 0.3056  decode.d0.loss_dice: 0.2859  decode.d1.loss_cls: 0.2142  decode.d1.loss_mask: 0.2920  decode.d1.loss_dice: 0.2927  decode.d2.loss_cls: 0.1925  decode.d2.loss_mask: 0.2943  decode.d2.loss_dice: 0.2873  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.1827  decode.d4.loss_mask: 0.2914  decode.d4.loss_dice: 0.2776  decode.d5.loss_cls: 0.2183  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.2900  decode.d6.loss_cls: 0.2293  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.2864  decode.d7.loss_cls: 0.2533  decode.d7.loss_mask: 0.2929  decode.d7.loss_dice: 0.2968  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.2916  decode.d8.loss_dice: 0.2905
09/30 12:15:22 - mmengine - INFO - Iter(train) [ 26650/320000]  base_lr: 9.2473e-05 lr: 9.2473e-06  eta: 1 day, 11:16:51  time: 0.4336  data_time: 0.0092  memory: 5147  grad_norm: 283.7912  loss: 10.3021  decode.loss_cls: 0.2175  decode.loss_mask: 0.3920  decode.loss_dice: 0.2606  decode.d0.loss_cls: 1.0002  decode.d0.loss_mask: 0.4023  decode.d0.loss_dice: 0.2719  decode.d1.loss_cls: 0.3042  decode.d1.loss_mask: 0.3725  decode.d1.loss_dice: 0.2626  decode.d2.loss_cls: 0.2752  decode.d2.loss_mask: 0.4617  decode.d2.loss_dice: 0.2546  decode.d3.loss_cls: 0.2924  decode.d3.loss_mask: 0.4635  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.2041  decode.d4.loss_mask: 0.4854  decode.d4.loss_dice: 0.2584  decode.d5.loss_cls: 0.2951  decode.d5.loss_mask: 0.4091  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.3095  decode.d6.loss_mask: 0.3898  decode.d6.loss_dice: 0.2626  decode.d7.loss_cls: 0.3980  decode.d7.loss_mask: 0.3644  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.1793  decode.d8.loss_mask: 0.5023  decode.d8.loss_dice: 0.2571
09/30 12:15:44 - mmengine - INFO - Iter(train) [ 26700/320000]  base_lr: 9.2459e-05 lr: 9.2459e-06  eta: 1 day, 11:16:30  time: 0.4328  data_time: 0.0089  memory: 5161  grad_norm: 55.6011  loss: 7.1677  decode.loss_cls: 0.1765  decode.loss_mask: 0.2275  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.9342  decode.d0.loss_mask: 0.2262  decode.d0.loss_dice: 0.2335  decode.d1.loss_cls: 0.1796  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.2119  decode.d2.loss_cls: 0.2682  decode.d2.loss_mask: 0.2223  decode.d2.loss_dice: 0.2276  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 0.2247  decode.d4.loss_dice: 0.2095  decode.d5.loss_cls: 0.1928  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.1729  decode.d6.loss_mask: 0.2266  decode.d6.loss_dice: 0.2134  decode.d7.loss_cls: 0.2004  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.2140  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.2205
09/30 12:16:06 - mmengine - INFO - Iter(train) [ 26750/320000]  base_lr: 9.2444e-05 lr: 9.2444e-06  eta: 1 day, 11:16:08  time: 0.4321  data_time: 0.0090  memory: 5180  grad_norm: 84.9385  loss: 6.4798  decode.loss_cls: 0.1206  decode.loss_mask: 0.2251  decode.loss_dice: 0.2366  decode.d0.loss_cls: 0.9555  decode.d0.loss_mask: 0.2255  decode.d0.loss_dice: 0.2563  decode.d1.loss_cls: 0.1056  decode.d1.loss_mask: 0.2280  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.2396  decode.d3.loss_cls: 0.0990  decode.d3.loss_mask: 0.2229  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.0896  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.2355  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.2198  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 0.2204  decode.d8.loss_dice: 0.2243
09/30 12:16:27 - mmengine - INFO - Iter(train) [ 26800/320000]  base_lr: 9.2430e-05 lr: 9.2430e-06  eta: 1 day, 11:15:47  time: 0.4336  data_time: 0.0093  memory: 5180  grad_norm: 87.8884  loss: 7.0621  decode.loss_cls: 0.1129  decode.loss_mask: 0.2581  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.9430  decode.d0.loss_mask: 0.2768  decode.d0.loss_dice: 0.2799  decode.d1.loss_cls: 0.0868  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.1040  decode.d2.loss_mask: 0.2561  decode.d2.loss_dice: 0.2663  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.2621  decode.d4.loss_dice: 0.2601  decode.d5.loss_cls: 0.1042  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.2532  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2589  decode.d6.loss_dice: 0.2418  decode.d7.loss_cls: 0.1030  decode.d7.loss_mask: 0.2605  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.2569  decode.d8.loss_dice: 0.2521
09/30 12:16:49 - mmengine - INFO - Iter(train) [ 26850/320000]  base_lr: 9.2416e-05 lr: 9.2416e-06  eta: 1 day, 11:15:26  time: 0.4349  data_time: 0.0093  memory: 5180  grad_norm: 66.0059  loss: 8.3692  decode.loss_cls: 0.1619  decode.loss_mask: 0.3901  decode.loss_dice: 0.2309  decode.d0.loss_cls: 0.9377  decode.d0.loss_mask: 0.3927  decode.d0.loss_dice: 0.2297  decode.d1.loss_cls: 0.1750  decode.d1.loss_mask: 0.3896  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.1594  decode.d2.loss_mask: 0.3971  decode.d2.loss_dice: 0.2326  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 0.3895  decode.d3.loss_dice: 0.2097  decode.d4.loss_cls: 0.1248  decode.d4.loss_mask: 0.3907  decode.d4.loss_dice: 0.2363  decode.d5.loss_cls: 0.1194  decode.d5.loss_mask: 0.3880  decode.d5.loss_dice: 0.2280  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.3917  decode.d6.loss_dice: 0.2504  decode.d7.loss_cls: 0.0902  decode.d7.loss_mask: 0.3929  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 0.3923  decode.d8.loss_dice: 0.2371
09/30 12:17:11 - mmengine - INFO - Iter(train) [ 26900/320000]  base_lr: 9.2402e-05 lr: 9.2402e-06  eta: 1 day, 11:15:05  time: 0.4340  data_time: 0.0091  memory: 5147  grad_norm: 96.4540  loss: 7.4393  decode.loss_cls: 0.2219  decode.loss_mask: 0.2481  decode.loss_dice: 0.2151  decode.d0.loss_cls: 1.1222  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.1968  decode.d1.loss_cls: 0.2318  decode.d1.loss_mask: 0.2688  decode.d1.loss_dice: 0.2353  decode.d2.loss_cls: 0.2580  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.1896  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.2153  decode.d4.loss_cls: 0.1883  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.1758  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 0.2519  decode.d5.loss_dice: 0.1862  decode.d6.loss_cls: 0.1897  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2035  decode.d7.loss_cls: 0.1607  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.1893  decode.d8.loss_cls: 0.2055  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.1814
09/30 12:17:33 - mmengine - INFO - Iter(train) [ 26950/320000]  base_lr: 9.2388e-05 lr: 9.2388e-06  eta: 1 day, 11:14:44  time: 0.4337  data_time: 0.0090  memory: 5180  grad_norm: 76.4575  loss: 5.9694  decode.loss_cls: 0.0689  decode.loss_mask: 0.2406  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.9558  decode.d0.loss_mask: 0.2454  decode.d0.loss_dice: 0.2119  decode.d1.loss_cls: 0.0718  decode.d1.loss_mask: 0.2404  decode.d1.loss_dice: 0.2028  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.2405  decode.d2.loss_dice: 0.2001  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.1993  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.1991  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2004  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.2413  decode.d6.loss_dice: 0.1995  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.2417  decode.d7.loss_dice: 0.1976  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.1967
09/30 12:17:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:17:54 - mmengine - INFO - Iter(train) [ 27000/320000]  base_lr: 9.2373e-05 lr: 9.2373e-06  eta: 1 day, 11:14:23  time: 0.4343  data_time: 0.0091  memory: 5180  grad_norm: 46.4599  loss: 5.4643  decode.loss_cls: 0.1229  decode.loss_mask: 0.1964  decode.loss_dice: 0.1869  decode.d0.loss_cls: 0.8785  decode.d0.loss_mask: 0.2024  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.1979  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.1982  decode.d3.loss_dice: 0.2052  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.2074  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.1970  decode.d5.loss_dice: 0.1998  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.2001  decode.d6.loss_dice: 0.2006  decode.d7.loss_cls: 0.0819  decode.d7.loss_mask: 0.2009  decode.d7.loss_dice: 0.2038  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.1946
09/30 12:18:16 - mmengine - INFO - Iter(train) [ 27050/320000]  base_lr: 9.2359e-05 lr: 9.2359e-06  eta: 1 day, 11:14:02  time: 0.4332  data_time: 0.0091  memory: 5161  grad_norm: 359.0318  loss: 7.8074  decode.loss_cls: 0.2226  decode.loss_mask: 0.2644  decode.loss_dice: 0.2002  decode.d0.loss_cls: 0.8276  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.1985  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 0.2707  decode.d1.loss_dice: 0.1902  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 0.3066  decode.d2.loss_dice: 0.1974  decode.d3.loss_cls: 0.2700  decode.d3.loss_mask: 0.3082  decode.d3.loss_dice: 0.1975  decode.d4.loss_cls: 0.2643  decode.d4.loss_mask: 0.2978  decode.d4.loss_dice: 0.1919  decode.d5.loss_cls: 0.2666  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.1956  decode.d6.loss_cls: 0.2440  decode.d6.loss_mask: 0.2694  decode.d6.loss_dice: 0.1939  decode.d7.loss_cls: 0.2579  decode.d7.loss_mask: 0.2723  decode.d7.loss_dice: 0.1926  decode.d8.loss_cls: 0.2352  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.1983
09/30 12:18:38 - mmengine - INFO - Iter(train) [ 27100/320000]  base_lr: 9.2345e-05 lr: 9.2345e-06  eta: 1 day, 11:13:41  time: 0.4347  data_time: 0.0092  memory: 5180  grad_norm: 32.2171  loss: 6.3729  decode.loss_cls: 0.1090  decode.loss_mask: 0.2388  decode.loss_dice: 0.2346  decode.d0.loss_cls: 0.9117  decode.d0.loss_mask: 0.2474  decode.d0.loss_dice: 0.2210  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.2397  decode.d1.loss_dice: 0.2093  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2265  decode.d3.loss_cls: 0.0872  decode.d3.loss_mask: 0.2404  decode.d3.loss_dice: 0.2223  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2337  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.2401  decode.d6.loss_dice: 0.2256  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.1044  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2142
09/30 12:18:59 - mmengine - INFO - Iter(train) [ 27150/320000]  base_lr: 9.2331e-05 lr: 9.2331e-06  eta: 1 day, 11:13:20  time: 0.4325  data_time: 0.0088  memory: 5147  grad_norm: 141.6704  loss: 10.0246  decode.loss_cls: 0.2322  decode.loss_mask: 0.3882  decode.loss_dice: 0.3486  decode.d0.loss_cls: 0.9780  decode.d0.loss_mask: 0.2581  decode.d0.loss_dice: 0.3613  decode.d1.loss_cls: 0.2283  decode.d1.loss_mask: 0.3539  decode.d1.loss_dice: 0.3280  decode.d2.loss_cls: 0.2704  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.3358  decode.d3.loss_cls: 0.2434  decode.d3.loss_mask: 0.3525  decode.d3.loss_dice: 0.3610  decode.d4.loss_cls: 0.3494  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.2874  decode.d5.loss_mask: 0.3763  decode.d5.loss_dice: 0.3590  decode.d6.loss_cls: 0.1951  decode.d6.loss_mask: 0.3489  decode.d6.loss_dice: 0.3334  decode.d7.loss_cls: 0.1960  decode.d7.loss_mask: 0.3447  decode.d7.loss_dice: 0.3282  decode.d8.loss_cls: 0.2229  decode.d8.loss_mask: 0.3890  decode.d8.loss_dice: 0.3309
09/30 12:19:21 - mmengine - INFO - Iter(train) [ 27200/320000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 1 day, 11:12:59  time: 0.4334  data_time: 0.0090  memory: 5160  grad_norm: 114.2304  loss: 6.8581  decode.loss_cls: 0.0858  decode.loss_mask: 0.2859  decode.loss_dice: 0.2347  decode.d0.loss_cls: 0.8205  decode.d0.loss_mask: 0.2895  decode.d0.loss_dice: 0.2279  decode.d1.loss_cls: 0.0719  decode.d1.loss_mask: 0.2913  decode.d1.loss_dice: 0.2254  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.2341  decode.d3.loss_cls: 0.1688  decode.d3.loss_mask: 0.2803  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.2897  decode.d4.loss_dice: 0.2328  decode.d5.loss_cls: 0.0940  decode.d5.loss_mask: 0.2848  decode.d5.loss_dice: 0.2371  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.2280  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.2918  decode.d7.loss_dice: 0.2301  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.2299
09/30 12:19:43 - mmengine - INFO - Iter(train) [ 27250/320000]  base_lr: 9.2302e-05 lr: 9.2302e-06  eta: 1 day, 11:12:37  time: 0.4333  data_time: 0.0091  memory: 5161  grad_norm: 89.2630  loss: 7.6596  decode.loss_cls: 0.1707  decode.loss_mask: 0.2698  decode.loss_dice: 0.2435  decode.d0.loss_cls: 0.8365  decode.d0.loss_mask: 0.2777  decode.d0.loss_dice: 0.2803  decode.d1.loss_cls: 0.2008  decode.d1.loss_mask: 0.2749  decode.d1.loss_dice: 0.2581  decode.d2.loss_cls: 0.1468  decode.d2.loss_mask: 0.2746  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.1758  decode.d3.loss_mask: 0.2720  decode.d3.loss_dice: 0.2540  decode.d4.loss_cls: 0.1553  decode.d4.loss_mask: 0.2713  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.1387  decode.d5.loss_mask: 0.2724  decode.d5.loss_dice: 0.2604  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 0.2711  decode.d6.loss_dice: 0.2749  decode.d7.loss_cls: 0.2199  decode.d7.loss_mask: 0.2723  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 0.2712  decode.d8.loss_dice: 0.2657
09/30 12:20:04 - mmengine - INFO - Iter(train) [ 27300/320000]  base_lr: 9.2288e-05 lr: 9.2288e-06  eta: 1 day, 11:12:16  time: 0.4331  data_time: 0.0089  memory: 5180  grad_norm: 89.5399  loss: 6.4585  decode.loss_cls: 0.0946  decode.loss_mask: 0.2434  decode.loss_dice: 0.2159  decode.d0.loss_cls: 0.8026  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.2470  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2298  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.2492  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.2446  decode.d3.loss_dice: 0.2322  decode.d4.loss_cls: 0.0960  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.2244  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.2550  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2344  decode.d7.loss_cls: 0.0873  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2304  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.2481  decode.d8.loss_dice: 0.2321
09/30 12:20:26 - mmengine - INFO - Iter(train) [ 27350/320000]  base_lr: 9.2274e-05 lr: 9.2274e-06  eta: 1 day, 11:11:54  time: 0.4335  data_time: 0.0091  memory: 5145  grad_norm: 100.6795  loss: 9.3448  decode.loss_cls: 0.3951  decode.loss_mask: 0.2775  decode.loss_dice: 0.2343  decode.d0.loss_cls: 1.0321  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.3856  decode.d1.loss_mask: 0.2762  decode.d1.loss_dice: 0.2365  decode.d2.loss_cls: 0.2975  decode.d2.loss_mask: 0.2854  decode.d2.loss_dice: 0.2337  decode.d3.loss_cls: 0.3384  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.2329  decode.d4.loss_cls: 0.3412  decode.d4.loss_mask: 0.2728  decode.d4.loss_dice: 0.2243  decode.d5.loss_cls: 0.3906  decode.d5.loss_mask: 0.2731  decode.d5.loss_dice: 0.2355  decode.d6.loss_cls: 0.3824  decode.d6.loss_mask: 0.2720  decode.d6.loss_dice: 0.2289  decode.d7.loss_cls: 0.3665  decode.d7.loss_mask: 0.2707  decode.d7.loss_dice: 0.2282  decode.d8.loss_cls: 0.3390  decode.d8.loss_mask: 0.2774  decode.d8.loss_dice: 0.2243
09/30 12:20:48 - mmengine - INFO - Iter(train) [ 27400/320000]  base_lr: 9.2260e-05 lr: 9.2260e-06  eta: 1 day, 11:11:33  time: 0.4340  data_time: 0.0090  memory: 5160  grad_norm: 54.7526  loss: 5.9339  decode.loss_cls: 0.0843  decode.loss_mask: 0.2290  decode.loss_dice: 0.2195  decode.d0.loss_cls: 0.7668  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.2187  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2261  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.2141  decode.d3.loss_cls: 0.1111  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2238  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.2304  decode.d4.loss_dice: 0.2377  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.2219  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.2316  decode.d7.loss_dice: 0.2111  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.2082
09/30 12:21:10 - mmengine - INFO - Iter(train) [ 27450/320000]  base_lr: 9.2246e-05 lr: 9.2246e-06  eta: 1 day, 11:11:12  time: 0.4343  data_time: 0.0095  memory: 5147  grad_norm: 117.2318  loss: 8.2527  decode.loss_cls: 0.1568  decode.loss_mask: 0.3692  decode.loss_dice: 0.2240  decode.d0.loss_cls: 0.9309  decode.d0.loss_mask: 0.3504  decode.d0.loss_dice: 0.2113  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.3511  decode.d1.loss_dice: 0.2101  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 0.3788  decode.d2.loss_dice: 0.2291  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 0.3719  decode.d3.loss_dice: 0.2212  decode.d4.loss_cls: 0.1556  decode.d4.loss_mask: 0.3727  decode.d4.loss_dice: 0.2223  decode.d5.loss_cls: 0.1396  decode.d5.loss_mask: 0.3756  decode.d5.loss_dice: 0.2229  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 0.3681  decode.d6.loss_dice: 0.2232  decode.d7.loss_cls: 0.1342  decode.d7.loss_mask: 0.3605  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.1597  decode.d8.loss_mask: 0.3572  decode.d8.loss_dice: 0.2218
09/30 12:21:31 - mmengine - INFO - Iter(train) [ 27500/320000]  base_lr: 9.2232e-05 lr: 9.2232e-06  eta: 1 day, 11:10:51  time: 0.4333  data_time: 0.0092  memory: 5145  grad_norm: 115.3214  loss: 6.8509  decode.loss_cls: 0.1643  decode.loss_mask: 0.2708  decode.loss_dice: 0.2392  decode.d0.loss_cls: 1.0409  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2396  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.2798  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.0804  decode.d2.loss_mask: 0.2535  decode.d2.loss_dice: 0.2315  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.2351  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.2440  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.2345  decode.d6.loss_cls: 0.0829  decode.d6.loss_mask: 0.2625  decode.d6.loss_dice: 0.2245  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.2722  decode.d7.loss_dice: 0.2327  decode.d8.loss_cls: 0.0996  decode.d8.loss_mask: 0.2669  decode.d8.loss_dice: 0.2256
09/30 12:21:53 - mmengine - INFO - Iter(train) [ 27550/320000]  base_lr: 9.2217e-05 lr: 9.2217e-06  eta: 1 day, 11:10:30  time: 0.4342  data_time: 0.0091  memory: 5160  grad_norm: 73.8067  loss: 8.5009  decode.loss_cls: 0.3362  decode.loss_mask: 0.2404  decode.loss_dice: 0.2023  decode.d0.loss_cls: 0.9603  decode.d0.loss_mask: 0.2361  decode.d0.loss_dice: 0.2075  decode.d1.loss_cls: 0.3065  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.2050  decode.d2.loss_cls: 0.3009  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.1980  decode.d3.loss_cls: 0.3534  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.2073  decode.d4.loss_cls: 0.3410  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2101  decode.d5.loss_cls: 0.3640  decode.d5.loss_mask: 0.2349  decode.d5.loss_dice: 0.1995  decode.d6.loss_cls: 0.3594  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.2066  decode.d7.loss_cls: 0.3880  decode.d7.loss_mask: 0.2400  decode.d7.loss_dice: 0.2072  decode.d8.loss_cls: 0.3666  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2117
09/30 12:22:15 - mmengine - INFO - Iter(train) [ 27600/320000]  base_lr: 9.2203e-05 lr: 9.2203e-06  eta: 1 day, 11:10:08  time: 0.4332  data_time: 0.0088  memory: 5132  grad_norm: 35.8992  loss: 6.4205  decode.loss_cls: 0.0490  decode.loss_mask: 0.2668  decode.loss_dice: 0.2386  decode.d0.loss_cls: 0.8142  decode.d0.loss_mask: 0.2719  decode.d0.loss_dice: 0.2623  decode.d1.loss_cls: 0.0868  decode.d1.loss_mask: 0.2661  decode.d1.loss_dice: 0.2397  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2379  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.2691  decode.d3.loss_dice: 0.2399  decode.d4.loss_cls: 0.0415  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.2663  decode.d5.loss_dice: 0.2349  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.2433  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.2644  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.2678  decode.d8.loss_dice: 0.2437
09/30 12:22:36 - mmengine - INFO - Iter(train) [ 27650/320000]  base_lr: 9.2189e-05 lr: 9.2189e-06  eta: 1 day, 11:09:47  time: 0.4338  data_time: 0.0088  memory: 5180  grad_norm: 68.7354  loss: 6.6053  decode.loss_cls: 0.0683  decode.loss_mask: 0.2151  decode.loss_dice: 0.2355  decode.d0.loss_cls: 0.9225  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.2437  decode.d1.loss_cls: 0.1911  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.2531  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.1593  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.1325  decode.d4.loss_mask: 0.2167  decode.d4.loss_dice: 0.2375  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.2083  decode.d5.loss_dice: 0.2679  decode.d6.loss_cls: 0.1066  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.2626  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.2149  decode.d7.loss_dice: 0.2561  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.2186  decode.d8.loss_dice: 0.2437
09/30 12:22:58 - mmengine - INFO - Iter(train) [ 27700/320000]  base_lr: 9.2175e-05 lr: 9.2175e-06  eta: 1 day, 11:09:27  time: 0.4331  data_time: 0.0089  memory: 5161  grad_norm: 78.8969  loss: 7.5261  decode.loss_cls: 0.1411  decode.loss_mask: 0.2356  decode.loss_dice: 0.2296  decode.d0.loss_cls: 1.0164  decode.d0.loss_mask: 0.2430  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.2128  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.2365  decode.d2.loss_cls: 0.1734  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.2349  decode.d3.loss_cls: 0.1772  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2297  decode.d4.loss_cls: 0.1931  decode.d4.loss_mask: 0.2351  decode.d4.loss_dice: 0.2444  decode.d5.loss_cls: 0.2168  decode.d5.loss_mask: 0.2301  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.2490  decode.d6.loss_mask: 0.2306  decode.d6.loss_dice: 0.2251  decode.d7.loss_cls: 0.2458  decode.d7.loss_mask: 0.2320  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.1929  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.2199
09/30 12:23:20 - mmengine - INFO - Iter(train) [ 27750/320000]  base_lr: 9.2161e-05 lr: 9.2161e-06  eta: 1 day, 11:09:06  time: 0.4354  data_time: 0.0094  memory: 5160  grad_norm: 92.5834  loss: 7.4937  decode.loss_cls: 0.1268  decode.loss_mask: 0.2980  decode.loss_dice: 0.2264  decode.d0.loss_cls: 1.1102  decode.d0.loss_mask: 0.2778  decode.d0.loss_dice: 0.2015  decode.d1.loss_cls: 0.2595  decode.d1.loss_mask: 0.2774  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.1785  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.1208  decode.d3.loss_mask: 0.2711  decode.d3.loss_dice: 0.2146  decode.d4.loss_cls: 0.1287  decode.d4.loss_mask: 0.2708  decode.d4.loss_dice: 0.2156  decode.d5.loss_cls: 0.1080  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.2375  decode.d6.loss_cls: 0.1524  decode.d6.loss_mask: 0.2983  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.1438  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.1251  decode.d8.loss_mask: 0.2948  decode.d8.loss_dice: 0.2283
09/30 12:23:42 - mmengine - INFO - Iter(train) [ 27800/320000]  base_lr: 9.2146e-05 lr: 9.2146e-06  eta: 1 day, 11:08:45  time: 0.4330  data_time: 0.0090  memory: 5161  grad_norm: 32.5121  loss: 5.3308  decode.loss_cls: 0.0193  decode.loss_mask: 0.2458  decode.loss_dice: 0.1766  decode.d0.loss_cls: 0.8556  decode.d0.loss_mask: 0.2490  decode.d0.loss_dice: 0.1814  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.1746  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.1724  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.2495  decode.d3.loss_dice: 0.1741  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.2510  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 0.2488  decode.d6.loss_dice: 0.1761  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.2444  decode.d8.loss_dice: 0.1739
09/30 12:24:03 - mmengine - INFO - Iter(train) [ 27850/320000]  base_lr: 9.2132e-05 lr: 9.2132e-06  eta: 1 day, 11:08:23  time: 0.4339  data_time: 0.0091  memory: 5146  grad_norm: 86.6663  loss: 8.3637  decode.loss_cls: 0.2317  decode.loss_mask: 0.2933  decode.loss_dice: 0.2476  decode.d0.loss_cls: 0.9432  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.2079  decode.d1.loss_mask: 0.2972  decode.d1.loss_dice: 0.2420  decode.d2.loss_cls: 0.2382  decode.d2.loss_mask: 0.2945  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.2419  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.2057  decode.d4.loss_mask: 0.2979  decode.d4.loss_dice: 0.2395  decode.d5.loss_cls: 0.2272  decode.d5.loss_mask: 0.2869  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.2071  decode.d6.loss_mask: 0.2975  decode.d6.loss_dice: 0.2730  decode.d7.loss_cls: 0.2303  decode.d7.loss_mask: 0.2961  decode.d7.loss_dice: 0.2524  decode.d8.loss_cls: 0.2181  decode.d8.loss_mask: 0.3055  decode.d8.loss_dice: 0.2441
09/30 12:24:25 - mmengine - INFO - Iter(train) [ 27900/320000]  base_lr: 9.2118e-05 lr: 9.2118e-06  eta: 1 day, 11:08:02  time: 0.4328  data_time: 0.0091  memory: 5193  grad_norm: 58.8001  loss: 9.9100  decode.loss_cls: 0.3127  decode.loss_mask: 0.3181  decode.loss_dice: 0.3324  decode.d0.loss_cls: 0.8745  decode.d0.loss_mask: 0.3020  decode.d0.loss_dice: 0.3550  decode.d1.loss_cls: 0.2692  decode.d1.loss_mask: 0.2822  decode.d1.loss_dice: 0.3216  decode.d2.loss_cls: 0.3624  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.3123  decode.d3.loss_cls: 0.3111  decode.d3.loss_mask: 0.2859  decode.d3.loss_dice: 0.2896  decode.d4.loss_cls: 0.3241  decode.d4.loss_mask: 0.3111  decode.d4.loss_dice: 0.2930  decode.d5.loss_cls: 0.3131  decode.d5.loss_mask: 0.3484  decode.d5.loss_dice: 0.3022  decode.d6.loss_cls: 0.3297  decode.d6.loss_mask: 0.3369  decode.d6.loss_dice: 0.3278  decode.d7.loss_cls: 0.2966  decode.d7.loss_mask: 0.3076  decode.d7.loss_dice: 0.3125  decode.d8.loss_cls: 0.3158  decode.d8.loss_mask: 0.2773  decode.d8.loss_dice: 0.3092
09/30 12:24:47 - mmengine - INFO - Iter(train) [ 27950/320000]  base_lr: 9.2104e-05 lr: 9.2104e-06  eta: 1 day, 11:07:41  time: 0.4333  data_time: 0.0091  memory: 5180  grad_norm: 94.3156  loss: 7.5684  decode.loss_cls: 0.1816  decode.loss_mask: 0.2850  decode.loss_dice: 0.2497  decode.d0.loss_cls: 0.8466  decode.d0.loss_mask: 0.2633  decode.d0.loss_dice: 0.2053  decode.d1.loss_cls: 0.1342  decode.d1.loss_mask: 0.2727  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.1448  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.1410  decode.d4.loss_mask: 0.3869  decode.d4.loss_dice: 0.2621  decode.d5.loss_cls: 0.1998  decode.d5.loss_mask: 0.2899  decode.d5.loss_dice: 0.2554  decode.d6.loss_cls: 0.0951  decode.d6.loss_mask: 0.3567  decode.d6.loss_dice: 0.2530  decode.d7.loss_cls: 0.1675  decode.d7.loss_mask: 0.2761  decode.d7.loss_dice: 0.2304  decode.d8.loss_cls: 0.1693  decode.d8.loss_mask: 0.3405  decode.d8.loss_dice: 0.2458
09/30 12:25:08 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:25:08 - mmengine - INFO - Iter(train) [ 28000/320000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 1 day, 11:07:20  time: 0.4351  data_time: 0.0093  memory: 5160  grad_norm: 84.6581  loss: 10.3583  decode.loss_cls: 0.2710  decode.loss_mask: 0.3081  decode.loss_dice: 0.3231  decode.d0.loss_cls: 1.1611  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.3533  decode.d1.loss_cls: 0.3908  decode.d1.loss_mask: 0.2896  decode.d1.loss_dice: 0.3373  decode.d2.loss_cls: 0.3470  decode.d2.loss_mask: 0.2770  decode.d2.loss_dice: 0.3216  decode.d3.loss_cls: 0.2790  decode.d3.loss_mask: 0.3030  decode.d3.loss_dice: 0.3350  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 0.3052  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.2889  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.3635  decode.d6.loss_cls: 0.3030  decode.d6.loss_mask: 0.2883  decode.d6.loss_dice: 0.3513  decode.d7.loss_cls: 0.3750  decode.d7.loss_mask: 0.2740  decode.d7.loss_dice: 0.3357  decode.d8.loss_cls: 0.3774  decode.d8.loss_mask: 0.2716  decode.d8.loss_dice: 0.3528
09/30 12:25:30 - mmengine - INFO - Iter(train) [ 28050/320000]  base_lr: 9.2075e-05 lr: 9.2075e-06  eta: 1 day, 11:06:59  time: 0.4335  data_time: 0.0094  memory: 5161  grad_norm: 268.8423  loss: 9.8493  decode.loss_cls: 0.1816  decode.loss_mask: 0.4157  decode.loss_dice: 0.2705  decode.d0.loss_cls: 1.0728  decode.d0.loss_mask: 0.4229  decode.d0.loss_dice: 0.2653  decode.d1.loss_cls: 0.3138  decode.d1.loss_mask: 0.3592  decode.d1.loss_dice: 0.3095  decode.d2.loss_cls: 0.2880  decode.d2.loss_mask: 0.3560  decode.d2.loss_dice: 0.3242  decode.d3.loss_cls: 0.2230  decode.d3.loss_mask: 0.3599  decode.d3.loss_dice: 0.2926  decode.d4.loss_cls: 0.1671  decode.d4.loss_mask: 0.4141  decode.d4.loss_dice: 0.2757  decode.d5.loss_cls: 0.2249  decode.d5.loss_mask: 0.4160  decode.d5.loss_dice: 0.2776  decode.d6.loss_cls: 0.1784  decode.d6.loss_mask: 0.4098  decode.d6.loss_dice: 0.2654  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 0.4160  decode.d7.loss_dice: 0.2801  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.4187  decode.d8.loss_dice: 0.2773
09/30 12:25:52 - mmengine - INFO - Iter(train) [ 28100/320000]  base_lr: 9.2061e-05 lr: 9.2061e-06  eta: 1 day, 11:06:37  time: 0.4338  data_time: 0.0092  memory: 5161  grad_norm: 25.2595  loss: 5.2367  decode.loss_cls: 0.0178  decode.loss_mask: 0.2084  decode.loss_dice: 0.1920  decode.d0.loss_cls: 0.9545  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.2031  decode.d1.loss_cls: 0.0224  decode.d1.loss_mask: 0.2100  decode.d1.loss_dice: 0.2011  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.2098  decode.d3.loss_dice: 0.1970  decode.d4.loss_cls: 0.0295  decode.d4.loss_mask: 0.2097  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.1922  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.2041  decode.d6.loss_dice: 0.1933  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.1871  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.2063  decode.d8.loss_dice: 0.1907
09/30 12:26:13 - mmengine - INFO - Iter(train) [ 28150/320000]  base_lr: 9.2047e-05 lr: 9.2047e-06  eta: 1 day, 11:06:16  time: 0.4342  data_time: 0.0094  memory: 5161  grad_norm: 129.6586  loss: 8.0065  decode.loss_cls: 0.1434  decode.loss_mask: 0.3009  decode.loss_dice: 0.2433  decode.d0.loss_cls: 0.9332  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.2343  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.2203  decode.d2.loss_cls: 0.1628  decode.d2.loss_mask: 0.3142  decode.d2.loss_dice: 0.2393  decode.d3.loss_cls: 0.2648  decode.d3.loss_mask: 0.3042  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.1623  decode.d4.loss_mask: 0.3156  decode.d4.loss_dice: 0.2572  decode.d5.loss_cls: 0.1577  decode.d5.loss_mask: 0.3436  decode.d5.loss_dice: 0.2761  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 0.3140  decode.d6.loss_dice: 0.2502  decode.d7.loss_cls: 0.1809  decode.d7.loss_mask: 0.3145  decode.d7.loss_dice: 0.2371  decode.d8.loss_cls: 0.1595  decode.d8.loss_mask: 0.2996  decode.d8.loss_dice: 0.2575
09/30 12:26:35 - mmengine - INFO - Iter(train) [ 28200/320000]  base_lr: 9.2033e-05 lr: 9.2033e-06  eta: 1 day, 11:05:55  time: 0.4349  data_time: 0.0093  memory: 5180  grad_norm: 29.2815  loss: 5.6301  decode.loss_cls: 0.1132  decode.loss_mask: 0.2065  decode.loss_dice: 0.1730  decode.d0.loss_cls: 0.9379  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.1300  decode.d1.loss_mask: 0.2050  decode.d1.loss_dice: 0.1710  decode.d2.loss_cls: 0.0962  decode.d2.loss_mask: 0.2058  decode.d2.loss_dice: 0.1743  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.1773  decode.d4.loss_cls: 0.0962  decode.d4.loss_mask: 0.2052  decode.d4.loss_dice: 0.1722  decode.d5.loss_cls: 0.0913  decode.d5.loss_mask: 0.2037  decode.d5.loss_dice: 0.1697  decode.d6.loss_cls: 0.0985  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.1708  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.1693  decode.d8.loss_cls: 0.1086  decode.d8.loss_mask: 0.2041  decode.d8.loss_dice: 0.1719
09/30 12:26:57 - mmengine - INFO - Iter(train) [ 28250/320000]  base_lr: 9.2019e-05 lr: 9.2019e-06  eta: 1 day, 11:05:34  time: 0.4331  data_time: 0.0095  memory: 5161  grad_norm: 46.4513  loss: 5.9326  decode.loss_cls: 0.1159  decode.loss_mask: 0.2447  decode.loss_dice: 0.1863  decode.d0.loss_cls: 0.8076  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.2438  decode.d1.loss_dice: 0.1896  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.1842  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.2481  decode.d3.loss_dice: 0.1838  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.2485  decode.d4.loss_dice: 0.1826  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.1856  decode.d6.loss_cls: 0.1095  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.2457  decode.d7.loss_dice: 0.1824  decode.d8.loss_cls: 0.1306  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.1909
09/30 12:27:19 - mmengine - INFO - Iter(train) [ 28300/320000]  base_lr: 9.2004e-05 lr: 9.2004e-06  eta: 1 day, 11:05:13  time: 0.4342  data_time: 0.0093  memory: 5160  grad_norm: 169.5251  loss: 7.3876  decode.loss_cls: 0.1245  decode.loss_mask: 0.3067  decode.loss_dice: 0.2331  decode.d0.loss_cls: 0.9022  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.2258  decode.d1.loss_cls: 0.0827  decode.d1.loss_mask: 0.3930  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.0902  decode.d2.loss_mask: 0.2861  decode.d2.loss_dice: 0.2199  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.2889  decode.d3.loss_dice: 0.2224  decode.d4.loss_cls: 0.1301  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.2263  decode.d5.loss_cls: 0.1213  decode.d5.loss_mask: 0.2941  decode.d5.loss_dice: 0.2223  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 0.3255  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.1128  decode.d7.loss_mask: 0.3277  decode.d7.loss_dice: 0.2288  decode.d8.loss_cls: 0.1034  decode.d8.loss_mask: 0.4007  decode.d8.loss_dice: 0.2403
09/30 12:27:40 - mmengine - INFO - Iter(train) [ 28350/320000]  base_lr: 9.1990e-05 lr: 9.1990e-06  eta: 1 day, 11:04:52  time: 0.4341  data_time: 0.0093  memory: 5193  grad_norm: 78.6472  loss: 9.3558  decode.loss_cls: 0.3329  decode.loss_mask: 0.2489  decode.loss_dice: 0.3091  decode.d0.loss_cls: 0.9174  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.3333  decode.d1.loss_cls: 0.5154  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.3106  decode.d2.loss_cls: 0.4011  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.2547  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.3354  decode.d4.loss_cls: 0.2321  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.3007  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 0.2514  decode.d5.loss_dice: 0.3081  decode.d6.loss_cls: 0.2043  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.3208  decode.d7.loss_cls: 0.2466  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.3097  decode.d8.loss_cls: 0.3489  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.3305
09/30 12:28:02 - mmengine - INFO - Iter(train) [ 28400/320000]  base_lr: 9.1976e-05 lr: 9.1976e-06  eta: 1 day, 11:04:31  time: 0.4339  data_time: 0.0091  memory: 5161  grad_norm: 31.3388  loss: 5.1939  decode.loss_cls: 0.0684  decode.loss_mask: 0.2486  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.7464  decode.d0.loss_mask: 0.2510  decode.d0.loss_dice: 0.1720  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.1651  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.2436  decode.d2.loss_dice: 0.1677  decode.d3.loss_cls: 0.0156  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.1654  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.2471  decode.d4.loss_dice: 0.1687  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.2473  decode.d5.loss_dice: 0.1667  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.2491  decode.d6.loss_dice: 0.1695  decode.d7.loss_cls: 0.0125  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.1693  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.2483  decode.d8.loss_dice: 0.1715
09/30 12:28:24 - mmengine - INFO - Iter(train) [ 28450/320000]  base_lr: 9.1962e-05 lr: 9.1962e-06  eta: 1 day, 11:04:09  time: 0.4339  data_time: 0.0094  memory: 5158  grad_norm: 125.2369  loss: 7.2878  decode.loss_cls: 0.1983  decode.loss_mask: 0.2399  decode.loss_dice: 0.1872  decode.d0.loss_cls: 0.9988  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.2327  decode.d1.loss_mask: 0.2361  decode.d1.loss_dice: 0.1862  decode.d2.loss_cls: 0.2283  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.1855  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.1918  decode.d4.loss_cls: 0.2166  decode.d4.loss_mask: 0.2388  decode.d4.loss_dice: 0.1829  decode.d5.loss_cls: 0.2316  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.2084  decode.d6.loss_mask: 0.2390  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 0.3452  decode.d7.loss_dice: 0.2043  decode.d8.loss_cls: 0.1876  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.1911
09/30 12:28:45 - mmengine - INFO - Iter(train) [ 28500/320000]  base_lr: 9.1948e-05 lr: 9.1948e-06  eta: 1 day, 11:03:48  time: 0.4351  data_time: 0.0094  memory: 5161  grad_norm: 45.7633  loss: 6.8503  decode.loss_cls: 0.1246  decode.loss_mask: 0.2492  decode.loss_dice: 0.2194  decode.d0.loss_cls: 0.9355  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.1905  decode.d1.loss_mask: 0.2516  decode.d1.loss_dice: 0.2155  decode.d2.loss_cls: 0.1410  decode.d2.loss_mask: 0.2454  decode.d2.loss_dice: 0.2080  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.1937  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.2071  decode.d5.loss_cls: 0.1537  decode.d5.loss_mask: 0.2483  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.0793  decode.d6.loss_mask: 0.2472  decode.d6.loss_dice: 0.2119  decode.d7.loss_cls: 0.1048  decode.d7.loss_mask: 0.2489  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.2258
09/30 12:29:07 - mmengine - INFO - Iter(train) [ 28550/320000]  base_lr: 9.1934e-05 lr: 9.1934e-06  eta: 1 day, 11:03:28  time: 0.4336  data_time: 0.0094  memory: 5180  grad_norm: 152.5528  loss: 6.2145  decode.loss_cls: 0.1539  decode.loss_mask: 0.2561  decode.loss_dice: 0.1841  decode.d0.loss_cls: 0.8124  decode.d0.loss_mask: 0.2573  decode.d0.loss_dice: 0.1883  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.2593  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.2012  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.1973  decode.d5.loss_cls: 0.0870  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.2053  decode.d6.loss_cls: 0.1833  decode.d6.loss_mask: 0.2565  decode.d6.loss_dice: 0.1924  decode.d7.loss_cls: 0.1355  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.1886  decode.d8.loss_cls: 0.1349  decode.d8.loss_mask: 0.2557  decode.d8.loss_dice: 0.1911
09/30 12:29:29 - mmengine - INFO - Iter(train) [ 28600/320000]  base_lr: 9.1919e-05 lr: 9.1919e-06  eta: 1 day, 11:03:07  time: 0.4342  data_time: 0.0094  memory: 5145  grad_norm: 75.2543  loss: 6.9939  decode.loss_cls: 0.0662  decode.loss_mask: 0.3224  decode.loss_dice: 0.2038  decode.d0.loss_cls: 1.0027  decode.d0.loss_mask: 0.3349  decode.d0.loss_dice: 0.2243  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.3303  decode.d1.loss_dice: 0.2100  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.3235  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.3205  decode.d3.loss_dice: 0.2044  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.3207  decode.d4.loss_dice: 0.2054  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.3281  decode.d5.loss_dice: 0.2039  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.2021  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.3234  decode.d7.loss_dice: 0.2019  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.3214  decode.d8.loss_dice: 0.2043
09/30 12:29:51 - mmengine - INFO - Iter(train) [ 28650/320000]  base_lr: 9.1905e-05 lr: 9.1905e-06  eta: 1 day, 11:02:46  time: 0.4345  data_time: 0.0094  memory: 5147  grad_norm: 92.6988  loss: 5.6844  decode.loss_cls: 0.2008  decode.loss_mask: 0.2167  decode.loss_dice: 0.1878  decode.d0.loss_cls: 0.8637  decode.d0.loss_mask: 0.2263  decode.d0.loss_dice: 0.1891  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.2185  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.0490  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.1905  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.2220  decode.d3.loss_dice: 0.1940  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.2186  decode.d4.loss_dice: 0.1881  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.1925  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.1894  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.1871  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1885
09/30 12:30:12 - mmengine - INFO - Iter(train) [ 28700/320000]  base_lr: 9.1891e-05 lr: 9.1891e-06  eta: 1 day, 11:02:25  time: 0.4356  data_time: 0.0096  memory: 5180  grad_norm: 78.7569  loss: 7.5779  decode.loss_cls: 0.0500  decode.loss_mask: 0.3083  decode.loss_dice: 0.2780  decode.d0.loss_cls: 0.7540  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.2521  decode.d1.loss_cls: 0.1794  decode.d1.loss_mask: 0.3125  decode.d1.loss_dice: 0.2567  decode.d2.loss_cls: 0.1920  decode.d2.loss_mask: 0.3113  decode.d2.loss_dice: 0.2624  decode.d3.loss_cls: 0.1702  decode.d3.loss_mask: 0.3140  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.1075  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.2603  decode.d5.loss_cls: 0.1266  decode.d5.loss_mask: 0.3127  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.1088  decode.d6.loss_mask: 0.3103  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.0969  decode.d7.loss_mask: 0.3101  decode.d7.loss_dice: 0.2534  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.3069  decode.d8.loss_dice: 0.2549
09/30 12:30:34 - mmengine - INFO - Iter(train) [ 28750/320000]  base_lr: 9.1877e-05 lr: 9.1877e-06  eta: 1 day, 11:02:04  time: 0.4344  data_time: 0.0093  memory: 5146  grad_norm: 72.5208  loss: 8.3753  decode.loss_cls: 0.0934  decode.loss_mask: 0.3557  decode.loss_dice: 0.2684  decode.d0.loss_cls: 0.8424  decode.d0.loss_mask: 0.3624  decode.d0.loss_dice: 0.2846  decode.d1.loss_cls: 0.1780  decode.d1.loss_mask: 0.3657  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.1981  decode.d2.loss_mask: 0.3552  decode.d2.loss_dice: 0.2678  decode.d3.loss_cls: 0.1275  decode.d3.loss_mask: 0.3511  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.1103  decode.d4.loss_mask: 0.3494  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.1090  decode.d5.loss_mask: 0.3534  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.1128  decode.d6.loss_mask: 0.3517  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.1879  decode.d7.loss_mask: 0.3565  decode.d7.loss_dice: 0.2589  decode.d8.loss_cls: 0.1532  decode.d8.loss_mask: 0.3563  decode.d8.loss_dice: 0.2775
09/30 12:30:56 - mmengine - INFO - Iter(train) [ 28800/320000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 1 day, 11:01:43  time: 0.4343  data_time: 0.0092  memory: 5180  grad_norm: 38.7106  loss: 7.2727  decode.loss_cls: 0.0762  decode.loss_mask: 0.2853  decode.loss_dice: 0.2630  decode.d0.loss_cls: 0.7957  decode.d0.loss_mask: 0.2937  decode.d0.loss_dice: 0.2602  decode.d1.loss_cls: 0.1248  decode.d1.loss_mask: 0.2846  decode.d1.loss_dice: 0.2623  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 0.2900  decode.d2.loss_dice: 0.2549  decode.d3.loss_cls: 0.0914  decode.d3.loss_mask: 0.2865  decode.d3.loss_dice: 0.2591  decode.d4.loss_cls: 0.1377  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.2583  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.2588  decode.d6.loss_cls: 0.1526  decode.d6.loss_mask: 0.2842  decode.d6.loss_dice: 0.2668  decode.d7.loss_cls: 0.1333  decode.d7.loss_mask: 0.2820  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.0815  decode.d8.loss_mask: 0.2874  decode.d8.loss_dice: 0.2707
09/30 12:31:18 - mmengine - INFO - Iter(train) [ 28850/320000]  base_lr: 9.1848e-05 lr: 9.1848e-06  eta: 1 day, 11:01:23  time: 0.4344  data_time: 0.0093  memory: 5161  grad_norm: 57.4704  loss: 8.4325  decode.loss_cls: 0.1784  decode.loss_mask: 0.2587  decode.loss_dice: 0.3287  decode.d0.loss_cls: 0.8634  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.3041  decode.d1.loss_cls: 0.1384  decode.d1.loss_mask: 0.2599  decode.d1.loss_dice: 0.3108  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 0.2568  decode.d2.loss_dice: 0.2683  decode.d3.loss_cls: 0.1987  decode.d3.loss_mask: 0.2596  decode.d3.loss_dice: 0.2941  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2951  decode.d5.loss_cls: 0.2753  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2698  decode.d6.loss_cls: 0.2986  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2984  decode.d7.loss_cls: 0.3026  decode.d7.loss_mask: 0.2590  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.2637  decode.d8.loss_mask: 0.2580  decode.d8.loss_dice: 0.2943
09/30 12:31:39 - mmengine - INFO - Iter(train) [ 28900/320000]  base_lr: 9.1834e-05 lr: 9.1834e-06  eta: 1 day, 11:01:02  time: 0.4353  data_time: 0.0095  memory: 5147  grad_norm: 68.0465  loss: 7.4579  decode.loss_cls: 0.1335  decode.loss_mask: 0.2579  decode.loss_dice: 0.2231  decode.d0.loss_cls: 1.0981  decode.d0.loss_mask: 0.2690  decode.d0.loss_dice: 0.2315  decode.d1.loss_cls: 0.2427  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.2100  decode.d2.loss_cls: 0.1933  decode.d2.loss_mask: 0.2581  decode.d2.loss_dice: 0.2023  decode.d3.loss_cls: 0.1554  decode.d3.loss_mask: 0.2649  decode.d3.loss_dice: 0.2437  decode.d4.loss_cls: 0.1851  decode.d4.loss_mask: 0.2638  decode.d4.loss_dice: 0.2334  decode.d5.loss_cls: 0.1672  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.1440  decode.d6.loss_mask: 0.2656  decode.d6.loss_dice: 0.2481  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.2282  decode.d8.loss_cls: 0.1255  decode.d8.loss_mask: 0.2566  decode.d8.loss_dice: 0.2172
09/30 12:32:01 - mmengine - INFO - Iter(train) [ 28950/320000]  base_lr: 9.1820e-05 lr: 9.1820e-06  eta: 1 day, 11:00:41  time: 0.4357  data_time: 0.0096  memory: 5160  grad_norm: 136.5296  loss: 7.3260  decode.loss_cls: 0.1399  decode.loss_mask: 0.2793  decode.loss_dice: 0.2309  decode.d0.loss_cls: 0.9264  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.2397  decode.d1.loss_cls: 0.1317  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.2136  decode.d2.loss_cls: 0.1776  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.2334  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 0.2898  decode.d3.loss_dice: 0.2500  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 0.2825  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.1374  decode.d5.loss_mask: 0.2845  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.1388  decode.d6.loss_mask: 0.2894  decode.d6.loss_dice: 0.2316  decode.d7.loss_cls: 0.1332  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.2267  decode.d8.loss_cls: 0.1481  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.2230
09/30 12:32:23 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:32:23 - mmengine - INFO - Iter(train) [ 29000/320000]  base_lr: 9.1806e-05 lr: 9.1806e-06  eta: 1 day, 11:00:21  time: 0.4348  data_time: 0.0093  memory: 5161  grad_norm: 40.5757  loss: 6.0138  decode.loss_cls: 0.1108  decode.loss_mask: 0.2266  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.7537  decode.d0.loss_mask: 0.2230  decode.d0.loss_dice: 0.2115  decode.d1.loss_cls: 0.1331  decode.d1.loss_mask: 0.2218  decode.d1.loss_dice: 0.1906  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.1990  decode.d3.loss_cls: 0.1122  decode.d3.loss_mask: 0.2241  decode.d3.loss_dice: 0.2101  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.2089  decode.d5.loss_cls: 0.0972  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.2062  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.2061  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.2098  decode.d8.loss_cls: 0.0989  decode.d8.loss_mask: 0.2221  decode.d8.loss_dice: 0.2088
09/30 12:32:45 - mmengine - INFO - Iter(train) [ 29050/320000]  base_lr: 9.1792e-05 lr: 9.1792e-06  eta: 1 day, 11:00:00  time: 0.4339  data_time: 0.0094  memory: 5161  grad_norm: 25.3371  loss: 5.1767  decode.loss_cls: 0.0454  decode.loss_mask: 0.2147  decode.loss_dice: 0.1724  decode.d0.loss_cls: 0.9029  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.1869  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.1676  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.1752  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.2144  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.2105  decode.d4.loss_dice: 0.1688  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.2131  decode.d5.loss_dice: 0.1729  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.2097  decode.d6.loss_dice: 0.1697  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.2124  decode.d7.loss_dice: 0.1739  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.2143  decode.d8.loss_dice: 0.1750
09/30 12:33:06 - mmengine - INFO - Iter(train) [ 29100/320000]  base_lr: 9.1777e-05 lr: 9.1777e-06  eta: 1 day, 10:59:39  time: 0.4355  data_time: 0.0094  memory: 5160  grad_norm: 36.6944  loss: 5.6675  decode.loss_cls: 0.0527  decode.loss_mask: 0.2156  decode.loss_dice: 0.1723  decode.d0.loss_cls: 1.2096  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.1892  decode.d1.loss_cls: 0.0880  decode.d1.loss_mask: 0.2213  decode.d1.loss_dice: 0.1809  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.1796  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.1707  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.1718  decode.d5.loss_cls: 0.0390  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.1740  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.2163  decode.d7.loss_dice: 0.1903  decode.d8.loss_cls: 0.0806  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.1777
09/30 12:33:28 - mmengine - INFO - Iter(train) [ 29150/320000]  base_lr: 9.1763e-05 lr: 9.1763e-06  eta: 1 day, 10:59:18  time: 0.4349  data_time: 0.0092  memory: 5161  grad_norm: 91.6264  loss: 9.5952  decode.loss_cls: 0.3620  decode.loss_mask: 0.2277  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.9404  decode.d0.loss_mask: 0.2967  decode.d0.loss_dice: 0.3239  decode.d1.loss_cls: 0.3379  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.2731  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.2810  decode.d3.loss_cls: 0.2300  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.3264  decode.d4.loss_cls: 0.2817  decode.d4.loss_mask: 0.2941  decode.d4.loss_dice: 0.3055  decode.d5.loss_cls: 0.3158  decode.d5.loss_mask: 0.2926  decode.d5.loss_dice: 0.2789  decode.d6.loss_cls: 0.3162  decode.d6.loss_mask: 0.2932  decode.d6.loss_dice: 0.3073  decode.d7.loss_cls: 0.2966  decode.d7.loss_mask: 0.2913  decode.d7.loss_dice: 0.3150  decode.d8.loss_cls: 0.4194  decode.d8.loss_mask: 0.2261  decode.d8.loss_dice: 0.2785
09/30 12:33:50 - mmengine - INFO - Iter(train) [ 29200/320000]  base_lr: 9.1749e-05 lr: 9.1749e-06  eta: 1 day, 10:58:57  time: 0.4339  data_time: 0.0091  memory: 5161  grad_norm: 44.1196  loss: 7.4256  decode.loss_cls: 0.0681  decode.loss_mask: 0.2874  decode.loss_dice: 0.2828  decode.d0.loss_cls: 0.8604  decode.d0.loss_mask: 0.2947  decode.d0.loss_dice: 0.2965  decode.d1.loss_cls: 0.1077  decode.d1.loss_mask: 0.2893  decode.d1.loss_dice: 0.2736  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.2820  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.2865  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.1016  decode.d4.loss_mask: 0.2897  decode.d4.loss_dice: 0.2781  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.2794  decode.d6.loss_cls: 0.1208  decode.d6.loss_mask: 0.2857  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.2805  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.2891  decode.d8.loss_dice: 0.2788
09/30 12:34:11 - mmengine - INFO - Iter(train) [ 29250/320000]  base_lr: 9.1735e-05 lr: 9.1735e-06  eta: 1 day, 10:58:37  time: 0.4344  data_time: 0.0092  memory: 5160  grad_norm: 57.8380  loss: 7.2068  decode.loss_cls: 0.2270  decode.loss_mask: 0.2041  decode.loss_dice: 0.1821  decode.d0.loss_cls: 0.9546  decode.d0.loss_mask: 0.2103  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.3288  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.3190  decode.d2.loss_mask: 0.2045  decode.d2.loss_dice: 0.1918  decode.d3.loss_cls: 0.3072  decode.d3.loss_mask: 0.2054  decode.d3.loss_dice: 0.1878  decode.d4.loss_cls: 0.2318  decode.d4.loss_mask: 0.2072  decode.d4.loss_dice: 0.1872  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 0.2067  decode.d5.loss_dice: 0.1827  decode.d6.loss_cls: 0.2629  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.2019  decode.d8.loss_mask: 0.2025  decode.d8.loss_dice: 0.1804
09/30 12:34:33 - mmengine - INFO - Iter(train) [ 29300/320000]  base_lr: 9.1721e-05 lr: 9.1721e-06  eta: 1 day, 10:58:16  time: 0.4340  data_time: 0.0091  memory: 5146  grad_norm: 184.6121  loss: 7.2250  decode.loss_cls: 0.1472  decode.loss_mask: 0.2511  decode.loss_dice: 0.2131  decode.d0.loss_cls: 0.8093  decode.d0.loss_mask: 0.2579  decode.d0.loss_dice: 0.2129  decode.d1.loss_cls: 0.2232  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.2513  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.1868  decode.d4.loss_mask: 0.2572  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.2533  decode.d5.loss_dice: 0.2224  decode.d6.loss_cls: 0.1814  decode.d6.loss_mask: 0.2532  decode.d6.loss_dice: 0.2251  decode.d7.loss_cls: 0.1892  decode.d7.loss_mask: 0.2465  decode.d7.loss_dice: 0.2093  decode.d8.loss_cls: 0.1438  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2145
09/30 12:34:55 - mmengine - INFO - Iter(train) [ 29350/320000]  base_lr: 9.1706e-05 lr: 9.1706e-06  eta: 1 day, 10:57:57  time: 0.4341  data_time: 0.0091  memory: 5161  grad_norm: 157.2799  loss: 7.8622  decode.loss_cls: 0.1529  decode.loss_mask: 0.2560  decode.loss_dice: 0.2467  decode.d0.loss_cls: 0.8877  decode.d0.loss_mask: 0.2717  decode.d0.loss_dice: 0.2651  decode.d1.loss_cls: 0.2168  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.2786  decode.d2.loss_cls: 0.2198  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2538  decode.d3.loss_cls: 0.1805  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.2116  decode.d4.loss_mask: 0.2583  decode.d4.loss_dice: 0.2443  decode.d5.loss_cls: 0.1864  decode.d5.loss_mask: 0.2551  decode.d5.loss_dice: 0.2492  decode.d6.loss_cls: 0.1752  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.2572  decode.d7.loss_mask: 0.2520  decode.d7.loss_dice: 0.2509  decode.d8.loss_cls: 0.1676  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.2407
09/30 12:35:17 - mmengine - INFO - Iter(train) [ 29400/320000]  base_lr: 9.1692e-05 lr: 9.1692e-06  eta: 1 day, 10:57:36  time: 0.4357  data_time: 0.0093  memory: 5147  grad_norm: 84.4036  loss: 7.2257  decode.loss_cls: 0.2705  decode.loss_mask: 0.1927  decode.loss_dice: 0.2186  decode.d0.loss_cls: 1.0057  decode.d0.loss_mask: 0.2014  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.2381  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.2028  decode.d2.loss_cls: 0.2126  decode.d2.loss_mask: 0.1933  decode.d2.loss_dice: 0.2071  decode.d3.loss_cls: 0.2534  decode.d3.loss_mask: 0.1911  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.2495  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.2144  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 0.1915  decode.d5.loss_dice: 0.2287  decode.d6.loss_cls: 0.1922  decode.d6.loss_mask: 0.1910  decode.d6.loss_dice: 0.2205  decode.d7.loss_cls: 0.2298  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.2382  decode.d8.loss_cls: 0.2443  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.2070
09/30 12:35:39 - mmengine - INFO - Iter(train) [ 29450/320000]  base_lr: 9.1678e-05 lr: 9.1678e-06  eta: 1 day, 10:57:15  time: 0.4351  data_time: 0.0092  memory: 5161  grad_norm: 21.6975  loss: 4.8691  decode.loss_cls: 0.0654  decode.loss_mask: 0.2044  decode.loss_dice: 0.1407  decode.d0.loss_cls: 0.9192  decode.d0.loss_mask: 0.2024  decode.d0.loss_dice: 0.1457  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.2025  decode.d1.loss_dice: 0.1422  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.2036  decode.d2.loss_dice: 0.1389  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.1376  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1426  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.2019  decode.d5.loss_dice: 0.1400  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.1457  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.2029  decode.d7.loss_dice: 0.1393  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.2052  decode.d8.loss_dice: 0.1396
09/30 12:36:00 - mmengine - INFO - Iter(train) [ 29500/320000]  base_lr: 9.1664e-05 lr: 9.1664e-06  eta: 1 day, 10:56:54  time: 0.4338  data_time: 0.0090  memory: 5146  grad_norm: 44.3749  loss: 7.6139  decode.loss_cls: 0.1528  decode.loss_mask: 0.2343  decode.loss_dice: 0.2564  decode.d0.loss_cls: 1.0040  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2583  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.2042  decode.d1.loss_dice: 0.2667  decode.d2.loss_cls: 0.1804  decode.d2.loss_mask: 0.2635  decode.d2.loss_dice: 0.2831  decode.d3.loss_cls: 0.1916  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.2770  decode.d4.loss_cls: 0.1555  decode.d4.loss_mask: 0.2547  decode.d4.loss_dice: 0.2611  decode.d5.loss_cls: 0.1821  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2599  decode.d6.loss_cls: 0.1823  decode.d6.loss_mask: 0.2521  decode.d6.loss_dice: 0.2595  decode.d7.loss_cls: 0.2006  decode.d7.loss_mask: 0.2101  decode.d7.loss_dice: 0.2854  decode.d8.loss_cls: 0.1682  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2898
09/30 12:36:22 - mmengine - INFO - Iter(train) [ 29550/320000]  base_lr: 9.1650e-05 lr: 9.1650e-06  eta: 1 day, 10:56:33  time: 0.4370  data_time: 0.0094  memory: 5160  grad_norm: 117.0132  loss: 6.2940  decode.loss_cls: 0.0670  decode.loss_mask: 0.2183  decode.loss_dice: 0.2185  decode.d0.loss_cls: 1.0520  decode.d0.loss_mask: 0.2172  decode.d0.loss_dice: 0.2023  decode.d1.loss_cls: 0.1655  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.2091  decode.d2.loss_cls: 0.1232  decode.d2.loss_mask: 0.2134  decode.d2.loss_dice: 0.2067  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.2093  decode.d4.loss_cls: 0.1386  decode.d4.loss_mask: 0.2177  decode.d4.loss_dice: 0.1922  decode.d5.loss_cls: 0.1006  decode.d5.loss_mask: 0.2209  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.1043  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.2089  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.2136  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.2225
09/30 12:36:44 - mmengine - INFO - Iter(train) [ 29600/320000]  base_lr: 9.1635e-05 lr: 9.1635e-06  eta: 1 day, 10:56:12  time: 0.4357  data_time: 0.0092  memory: 5180  grad_norm: 103.1074  loss: 5.7176  decode.loss_cls: 0.0948  decode.loss_mask: 0.2241  decode.loss_dice: 0.1774  decode.d0.loss_cls: 0.8553  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.2108  decode.d1.loss_cls: 0.0968  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.1839  decode.d2.loss_cls: 0.0664  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.1754  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2241  decode.d3.loss_dice: 0.1759  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.1816  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.1798  decode.d6.loss_cls: 0.0831  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.1792  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.1777  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.2337  decode.d8.loss_dice: 0.1882
09/30 12:37:06 - mmengine - INFO - Iter(train) [ 29650/320000]  base_lr: 9.1621e-05 lr: 9.1621e-06  eta: 1 day, 10:55:52  time: 0.4350  data_time: 0.0093  memory: 5160  grad_norm: 97.4199  loss: 7.2395  decode.loss_cls: 0.1074  decode.loss_mask: 0.2637  decode.loss_dice: 0.2494  decode.d0.loss_cls: 0.7676  decode.d0.loss_mask: 0.2627  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 0.2650  decode.d1.loss_dice: 0.2526  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 0.2612  decode.d2.loss_dice: 0.2522  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 0.2641  decode.d3.loss_dice: 0.2458  decode.d4.loss_cls: 0.1339  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.2662  decode.d5.loss_cls: 0.1126  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.1298  decode.d6.loss_mask: 0.3088  decode.d6.loss_dice: 0.2850  decode.d7.loss_cls: 0.1321  decode.d7.loss_mask: 0.2897  decode.d7.loss_dice: 0.2668  decode.d8.loss_cls: 0.1182  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.2446
09/30 12:37:27 - mmengine - INFO - Iter(train) [ 29700/320000]  base_lr: 9.1607e-05 lr: 9.1607e-06  eta: 1 day, 10:55:31  time: 0.4353  data_time: 0.0093  memory: 5180  grad_norm: 29.4530  loss: 4.9647  decode.loss_cls: 0.0392  decode.loss_mask: 0.2052  decode.loss_dice: 0.1802  decode.d0.loss_cls: 0.8470  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.1876  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.2051  decode.d1.loss_dice: 0.1778  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.2033  decode.d2.loss_dice: 0.1783  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.2069  decode.d3.loss_dice: 0.1895  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.2038  decode.d4.loss_dice: 0.1844  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.2052  decode.d5.loss_dice: 0.1808  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.2052  decode.d6.loss_dice: 0.1809  decode.d7.loss_cls: 0.0223  decode.d7.loss_mask: 0.2044  decode.d7.loss_dice: 0.1764  decode.d8.loss_cls: 0.0252  decode.d8.loss_mask: 0.2060  decode.d8.loss_dice: 0.1828
09/30 12:37:49 - mmengine - INFO - Iter(train) [ 29750/320000]  base_lr: 9.1593e-05 lr: 9.1593e-06  eta: 1 day, 10:55:10  time: 0.4345  data_time: 0.0091  memory: 5160  grad_norm: 32.6649  loss: 7.0379  decode.loss_cls: 0.1272  decode.loss_mask: 0.2270  decode.loss_dice: 0.2258  decode.d0.loss_cls: 0.8053  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.2712  decode.d1.loss_cls: 0.1430  decode.d1.loss_mask: 0.2273  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.1703  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.2552  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 0.2252  decode.d3.loss_dice: 0.2410  decode.d4.loss_cls: 0.1889  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2596  decode.d5.loss_cls: 0.1867  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.2328  decode.d6.loss_cls: 0.1668  decode.d6.loss_mask: 0.2258  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.1482  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.2490  decode.d8.loss_cls: 0.2147  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.2261
09/30 12:38:11 - mmengine - INFO - Iter(train) [ 29800/320000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 1 day, 10:54:49  time: 0.4348  data_time: 0.0091  memory: 5180  grad_norm: 42.5453  loss: 4.7299  decode.loss_cls: 0.0159  decode.loss_mask: 0.1927  decode.loss_dice: 0.1711  decode.d0.loss_cls: 0.8916  decode.d0.loss_mask: 0.1984  decode.d0.loss_dice: 0.1846  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.1954  decode.d1.loss_dice: 0.1719  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.1964  decode.d2.loss_dice: 0.1727  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.1742  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.1941  decode.d4.loss_dice: 0.1736  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.1944  decode.d5.loss_dice: 0.1711  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.1936  decode.d6.loss_dice: 0.1720  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.1945  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.1951  decode.d8.loss_dice: 0.1730
09/30 12:38:33 - mmengine - INFO - Iter(train) [ 29850/320000]  base_lr: 9.1564e-05 lr: 9.1564e-06  eta: 1 day, 10:54:28  time: 0.4349  data_time: 0.0091  memory: 5161  grad_norm: 74.5036  loss: 7.8237  decode.loss_cls: 0.1386  decode.loss_mask: 0.3288  decode.loss_dice: 0.2381  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.3287  decode.d0.loss_dice: 0.2451  decode.d1.loss_cls: 0.1376  decode.d1.loss_mask: 0.3286  decode.d1.loss_dice: 0.2444  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 0.3271  decode.d2.loss_dice: 0.2509  decode.d3.loss_cls: 0.1386  decode.d3.loss_mask: 0.3292  decode.d3.loss_dice: 0.2449  decode.d4.loss_cls: 0.1593  decode.d4.loss_mask: 0.3336  decode.d4.loss_dice: 0.2534  decode.d5.loss_cls: 0.1346  decode.d5.loss_mask: 0.3273  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.1513  decode.d6.loss_mask: 0.3269  decode.d6.loss_dice: 0.2352  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 0.3282  decode.d7.loss_dice: 0.2464  decode.d8.loss_cls: 0.1564  decode.d8.loss_mask: 0.3265  decode.d8.loss_dice: 0.2383
09/30 12:38:54 - mmengine - INFO - Iter(train) [ 29900/320000]  base_lr: 9.1550e-05 lr: 9.1550e-06  eta: 1 day, 10:54:08  time: 0.4342  data_time: 0.0089  memory: 5180  grad_norm: 76.3129  loss: 5.4724  decode.loss_cls: 0.0296  decode.loss_mask: 0.2007  decode.loss_dice: 0.2006  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.2299  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.2033  decode.d1.loss_dice: 0.1995  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.2006  decode.d2.loss_dice: 0.1838  decode.d3.loss_cls: 0.1158  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.1966  decode.d4.loss_cls: 0.0670  decode.d4.loss_mask: 0.2004  decode.d4.loss_dice: 0.2152  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.1980  decode.d5.loss_dice: 0.2009  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.2078  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.1972  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0293  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.2042
09/30 12:39:16 - mmengine - INFO - Iter(train) [ 29950/320000]  base_lr: 9.1536e-05 lr: 9.1536e-06  eta: 1 day, 10:53:47  time: 0.4354  data_time: 0.0093  memory: 5180  grad_norm: 120.4031  loss: 10.5593  decode.loss_cls: 0.3580  decode.loss_mask: 0.3174  decode.loss_dice: 0.2462  decode.d0.loss_cls: 1.0809  decode.d0.loss_mask: 0.3258  decode.d0.loss_dice: 0.2795  decode.d1.loss_cls: 0.4790  decode.d1.loss_mask: 0.3206  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.3993  decode.d2.loss_mask: 0.3190  decode.d2.loss_dice: 0.2728  decode.d3.loss_cls: 0.4100  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.4252  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.2652  decode.d5.loss_cls: 0.3835  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.2745  decode.d6.loss_cls: 0.3449  decode.d6.loss_mask: 0.3205  decode.d6.loss_dice: 0.2764  decode.d7.loss_cls: 0.3434  decode.d7.loss_mask: 0.3936  decode.d7.loss_dice: 0.2631  decode.d8.loss_cls: 0.3972  decode.d8.loss_mask: 0.3093  decode.d8.loss_dice: 0.2689
09/30 12:39:38 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:39:38 - mmengine - INFO - Iter(train) [ 30000/320000]  base_lr: 9.1522e-05 lr: 9.1522e-06  eta: 1 day, 10:53:26  time: 0.4346  data_time: 0.0091  memory: 5161  grad_norm: 53.2988  loss: 5.5467  decode.loss_cls: 0.0445  decode.loss_mask: 0.2449  decode.loss_dice: 0.1819  decode.d0.loss_cls: 0.8627  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.2468  decode.d1.loss_dice: 0.1803  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.2446  decode.d2.loss_dice: 0.1770  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.1727  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.1800  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.1762  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.2452  decode.d7.loss_dice: 0.1790  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.1796
09/30 12:40:00 - mmengine - INFO - Iter(train) [ 30050/320000]  base_lr: 9.1508e-05 lr: 9.1508e-06  eta: 1 day, 10:53:05  time: 0.4350  data_time: 0.0091  memory: 5161  grad_norm: 93.1274  loss: 7.0218  decode.loss_cls: 0.1419  decode.loss_mask: 0.2814  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.8855  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.2426  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.2816  decode.d1.loss_dice: 0.2300  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.2311  decode.d3.loss_cls: 0.0864  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.2811  decode.d4.loss_dice: 0.2211  decode.d5.loss_cls: 0.1432  decode.d5.loss_mask: 0.2840  decode.d5.loss_dice: 0.2238  decode.d6.loss_cls: 0.1333  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.1447  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.2229  decode.d8.loss_cls: 0.1318  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.2211
09/30 12:40:21 - mmengine - INFO - Iter(train) [ 30100/320000]  base_lr: 9.1493e-05 lr: 9.1493e-06  eta: 1 day, 10:52:44  time: 0.4336  data_time: 0.0089  memory: 5161  grad_norm: 120.8216  loss: 9.4976  decode.loss_cls: 0.1760  decode.loss_mask: 0.3271  decode.loss_dice: 0.3787  decode.d0.loss_cls: 1.1618  decode.d0.loss_mask: 0.2870  decode.d0.loss_dice: 0.3282  decode.d1.loss_cls: 0.2588  decode.d1.loss_mask: 0.2997  decode.d1.loss_dice: 0.3519  decode.d2.loss_cls: 0.1923  decode.d2.loss_mask: 0.2766  decode.d2.loss_dice: 0.3359  decode.d3.loss_cls: 0.1666  decode.d3.loss_mask: 0.2836  decode.d3.loss_dice: 0.3299  decode.d4.loss_cls: 0.2018  decode.d4.loss_mask: 0.2878  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 0.1971  decode.d5.loss_mask: 0.3239  decode.d5.loss_dice: 0.3600  decode.d6.loss_cls: 0.2204  decode.d6.loss_mask: 0.3165  decode.d6.loss_dice: 0.3674  decode.d7.loss_cls: 0.2015  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.3612  decode.d8.loss_cls: 0.2200  decode.d8.loss_mask: 0.2806  decode.d8.loss_dice: 0.3699
09/30 12:40:43 - mmengine - INFO - Iter(train) [ 30150/320000]  base_lr: 9.1479e-05 lr: 9.1479e-06  eta: 1 day, 10:52:23  time: 0.4343  data_time: 0.0088  memory: 5161  grad_norm: 56.4010  loss: 6.4065  decode.loss_cls: 0.1154  decode.loss_mask: 0.2437  decode.loss_dice: 0.1985  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.1994  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.1422  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.1915  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.2430  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.1873  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.2409  decode.d5.loss_dice: 0.2286  decode.d6.loss_cls: 0.1409  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2161  decode.d7.loss_cls: 0.1211  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.1743  decode.d8.loss_cls: 0.1205  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.2075
09/30 12:41:05 - mmengine - INFO - Iter(train) [ 30200/320000]  base_lr: 9.1465e-05 lr: 9.1465e-06  eta: 1 day, 10:52:02  time: 0.4349  data_time: 0.0091  memory: 5160  grad_norm: 48.8601  loss: 6.4718  decode.loss_cls: 0.1865  decode.loss_mask: 0.2427  decode.loss_dice: 0.1951  decode.d0.loss_cls: 0.8630  decode.d0.loss_mask: 0.2354  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.2367  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.1801  decode.d2.loss_cls: 0.2068  decode.d2.loss_mask: 0.2286  decode.d2.loss_dice: 0.1896  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 0.2340  decode.d3.loss_dice: 0.1912  decode.d4.loss_cls: 0.1564  decode.d4.loss_mask: 0.2314  decode.d4.loss_dice: 0.1869  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1905  decode.d6.loss_cls: 0.0986  decode.d6.loss_mask: 0.2328  decode.d6.loss_dice: 0.2006  decode.d7.loss_cls: 0.0910  decode.d7.loss_mask: 0.2316  decode.d7.loss_dice: 0.1923  decode.d8.loss_cls: 0.0887  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.1860
09/30 12:41:26 - mmengine - INFO - Iter(train) [ 30250/320000]  base_lr: 9.1451e-05 lr: 9.1451e-06  eta: 1 day, 10:51:41  time: 0.4339  data_time: 0.0093  memory: 5180  grad_norm: 31.5302  loss: 5.6990  decode.loss_cls: 0.0469  decode.loss_mask: 0.2499  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.8753  decode.d0.loss_mask: 0.2451  decode.d0.loss_dice: 0.1802  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.1721  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.2472  decode.d2.loss_dice: 0.1722  decode.d3.loss_cls: 0.1159  decode.d3.loss_mask: 0.2360  decode.d3.loss_dice: 0.1811  decode.d4.loss_cls: 0.1243  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.1762  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.1762  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.1753  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.1748  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.2465  decode.d8.loss_dice: 0.1745
09/30 12:41:48 - mmengine - INFO - Iter(train) [ 30300/320000]  base_lr: 9.1437e-05 lr: 9.1437e-06  eta: 1 day, 10:51:20  time: 0.4348  data_time: 0.0089  memory: 5180  grad_norm: 25.9423  loss: 5.5285  decode.loss_cls: 0.0316  decode.loss_mask: 0.2289  decode.loss_dice: 0.1965  decode.d0.loss_cls: 0.8928  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.2143  decode.d1.loss_cls: 0.0946  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.1944  decode.d2.loss_cls: 0.0274  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.2007  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.1975  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.1926  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.1918  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.2239  decode.d6.loss_dice: 0.1940  decode.d7.loss_cls: 0.0237  decode.d7.loss_mask: 0.2282  decode.d7.loss_dice: 0.1901  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.1979
09/30 12:42:10 - mmengine - INFO - Iter(train) [ 30350/320000]  base_lr: 9.1422e-05 lr: 9.1422e-06  eta: 1 day, 10:50:59  time: 0.4336  data_time: 0.0090  memory: 5161  grad_norm: 22.9851  loss: 5.1899  decode.loss_cls: 0.0188  decode.loss_mask: 0.2139  decode.loss_dice: 0.1916  decode.d0.loss_cls: 0.7720  decode.d0.loss_mask: 0.2233  decode.d0.loss_dice: 0.2012  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.2154  decode.d1.loss_dice: 0.2079  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.1961  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.2163  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.2149  decode.d4.loss_dice: 0.1929  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.2161  decode.d5.loss_dice: 0.2179  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.2146  decode.d7.loss_dice: 0.1837  decode.d8.loss_cls: 0.0328  decode.d8.loss_mask: 0.2156  decode.d8.loss_dice: 0.2036
09/30 12:42:32 - mmengine - INFO - Iter(train) [ 30400/320000]  base_lr: 9.1408e-05 lr: 9.1408e-06  eta: 1 day, 10:50:37  time: 0.4346  data_time: 0.0091  memory: 5146  grad_norm: 41.4244  loss: 6.7503  decode.loss_cls: 0.0914  decode.loss_mask: 0.2732  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.8884  decode.d0.loss_mask: 0.2840  decode.d0.loss_dice: 0.2462  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.2400  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.2731  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.2740  decode.d3.loss_dice: 0.2363  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2716  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.0946  decode.d6.loss_mask: 0.2698  decode.d6.loss_dice: 0.2143  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.2690  decode.d7.loss_dice: 0.1997  decode.d8.loss_cls: 0.1772  decode.d8.loss_mask: 0.2702  decode.d8.loss_dice: 0.2259
09/30 12:42:53 - mmengine - INFO - Iter(train) [ 30450/320000]  base_lr: 9.1394e-05 lr: 9.1394e-06  eta: 1 day, 10:50:16  time: 0.4348  data_time: 0.0091  memory: 5161  grad_norm: 49.7579  loss: 7.6655  decode.loss_cls: 0.0920  decode.loss_mask: 0.2549  decode.loss_dice: 0.2784  decode.d0.loss_cls: 0.7842  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.2633  decode.d1.loss_cls: 0.2400  decode.d1.loss_mask: 0.2525  decode.d1.loss_dice: 0.2695  decode.d2.loss_cls: 0.1180  decode.d2.loss_mask: 0.2577  decode.d2.loss_dice: 0.2891  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.2341  decode.d4.loss_cls: 0.2305  decode.d4.loss_mask: 0.2537  decode.d4.loss_dice: 0.2582  decode.d5.loss_cls: 0.2052  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.2622  decode.d6.loss_cls: 0.2090  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1952  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.2686  decode.d8.loss_cls: 0.2086  decode.d8.loss_mask: 0.2517  decode.d8.loss_dice: 0.2550
09/30 12:43:15 - mmengine - INFO - Iter(train) [ 30500/320000]  base_lr: 9.1380e-05 lr: 9.1380e-06  eta: 1 day, 10:49:55  time: 0.4346  data_time: 0.0093  memory: 5180  grad_norm: 82.8340  loss: 7.3410  decode.loss_cls: 0.0768  decode.loss_mask: 0.3139  decode.loss_dice: 0.2446  decode.d0.loss_cls: 0.8796  decode.d0.loss_mask: 0.3249  decode.d0.loss_dice: 0.2354  decode.d1.loss_cls: 0.0891  decode.d1.loss_mask: 0.3163  decode.d1.loss_dice: 0.2359  decode.d2.loss_cls: 0.1179  decode.d2.loss_mask: 0.3145  decode.d2.loss_dice: 0.2293  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.3203  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.2119  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.3203  decode.d5.loss_dice: 0.2339  decode.d6.loss_cls: 0.1090  decode.d6.loss_mask: 0.3192  decode.d6.loss_dice: 0.2457  decode.d7.loss_cls: 0.1299  decode.d7.loss_mask: 0.3203  decode.d7.loss_dice: 0.2343  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 0.3179  decode.d8.loss_dice: 0.2351
09/30 12:43:37 - mmengine - INFO - Iter(train) [ 30550/320000]  base_lr: 9.1366e-05 lr: 9.1366e-06  eta: 1 day, 10:49:34  time: 0.4342  data_time: 0.0092  memory: 5161  grad_norm: 116.0773  loss: 6.7209  decode.loss_cls: 0.0765  decode.loss_mask: 0.2553  decode.loss_dice: 0.2756  decode.d0.loss_cls: 0.7792  decode.d0.loss_mask: 0.2542  decode.d0.loss_dice: 0.2658  decode.d1.loss_cls: 0.1009  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.1076  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2496  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.2604  decode.d5.loss_dice: 0.2792  decode.d6.loss_cls: 0.0743  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.0932  decode.d7.loss_mask: 0.2470  decode.d7.loss_dice: 0.2689  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.2462  decode.d8.loss_dice: 0.2767
09/30 12:43:59 - mmengine - INFO - Iter(train) [ 30600/320000]  base_lr: 9.1351e-05 lr: 9.1351e-06  eta: 1 day, 10:49:13  time: 0.4348  data_time: 0.0094  memory: 5147  grad_norm: 294.5107  loss: 8.8694  decode.loss_cls: 0.1354  decode.loss_mask: 0.3248  decode.loss_dice: 0.3079  decode.d0.loss_cls: 1.1370  decode.d0.loss_mask: 0.3259  decode.d0.loss_dice: 0.3091  decode.d1.loss_cls: 0.2195  decode.d1.loss_mask: 0.3047  decode.d1.loss_dice: 0.3023  decode.d2.loss_cls: 0.1810  decode.d2.loss_mask: 0.3146  decode.d2.loss_dice: 0.2850  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 0.3011  decode.d3.loss_dice: 0.2756  decode.d4.loss_cls: 0.2120  decode.d4.loss_mask: 0.3161  decode.d4.loss_dice: 0.3177  decode.d5.loss_cls: 0.1414  decode.d5.loss_mask: 0.3071  decode.d5.loss_dice: 0.3364  decode.d6.loss_cls: 0.2061  decode.d6.loss_mask: 0.2931  decode.d6.loss_dice: 0.2950  decode.d7.loss_cls: 0.1358  decode.d7.loss_mask: 0.3099  decode.d7.loss_dice: 0.3161  decode.d8.loss_cls: 0.0848  decode.d8.loss_mask: 0.3355  decode.d8.loss_dice: 0.3253
09/30 12:44:20 - mmengine - INFO - Iter(train) [ 30650/320000]  base_lr: 9.1337e-05 lr: 9.1337e-06  eta: 1 day, 10:48:52  time: 0.4346  data_time: 0.0094  memory: 5161  grad_norm: 43.9780  loss: 5.9888  decode.loss_cls: 0.0343  decode.loss_mask: 0.3025  decode.loss_dice: 0.2004  decode.d0.loss_cls: 0.8253  decode.d0.loss_mask: 0.2949  decode.d0.loss_dice: 0.2082  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.2095  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.3043  decode.d2.loss_dice: 0.2063  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2980  decode.d3.loss_dice: 0.1986  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2996  decode.d4.loss_dice: 0.1997  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.2050  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.3009  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.3036  decode.d8.loss_dice: 0.1927
09/30 12:44:42 - mmengine - INFO - Iter(train) [ 30700/320000]  base_lr: 9.1323e-05 lr: 9.1323e-06  eta: 1 day, 10:48:31  time: 0.4346  data_time: 0.0094  memory: 5180  grad_norm: 51.1475  loss: 6.2483  decode.loss_cls: 0.1499  decode.loss_mask: 0.1936  decode.loss_dice: 0.1709  decode.d0.loss_cls: 0.9087  decode.d0.loss_mask: 0.2026  decode.d0.loss_dice: 0.2118  decode.d1.loss_cls: 0.2002  decode.d1.loss_mask: 0.1947  decode.d1.loss_dice: 0.1934  decode.d2.loss_cls: 0.2248  decode.d2.loss_mask: 0.1930  decode.d2.loss_dice: 0.1868  decode.d3.loss_cls: 0.1594  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.1822  decode.d4.loss_cls: 0.1646  decode.d4.loss_mask: 0.1950  decode.d4.loss_dice: 0.2066  decode.d5.loss_cls: 0.1421  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.1749  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 0.1941  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.1540  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.1857  decode.d8.loss_cls: 0.1487  decode.d8.loss_mask: 0.1938  decode.d8.loss_dice: 0.1915
09/30 12:45:04 - mmengine - INFO - Iter(train) [ 30750/320000]  base_lr: 9.1309e-05 lr: 9.1309e-06  eta: 1 day, 10:48:10  time: 0.4347  data_time: 0.0094  memory: 5161  grad_norm: 128.4453  loss: 6.4491  decode.loss_cls: 0.2092  decode.loss_mask: 0.1794  decode.loss_dice: 0.1849  decode.d0.loss_cls: 1.0580  decode.d0.loss_mask: 0.1794  decode.d0.loss_dice: 0.2019  decode.d1.loss_cls: 0.2036  decode.d1.loss_mask: 0.1902  decode.d1.loss_dice: 0.2031  decode.d2.loss_cls: 0.1455  decode.d2.loss_mask: 0.1877  decode.d2.loss_dice: 0.1917  decode.d3.loss_cls: 0.1543  decode.d3.loss_mask: 0.1795  decode.d3.loss_dice: 0.1936  decode.d4.loss_cls: 0.1521  decode.d4.loss_mask: 0.1814  decode.d4.loss_dice: 0.1832  decode.d5.loss_cls: 0.2112  decode.d5.loss_mask: 0.1881  decode.d5.loss_dice: 0.2019  decode.d6.loss_cls: 0.1633  decode.d6.loss_mask: 0.1835  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.1759  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.1819  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 0.1780  decode.d8.loss_dice: 0.2029
09/30 12:45:25 - mmengine - INFO - Iter(train) [ 30800/320000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 1 day, 10:47:49  time: 0.4339  data_time: 0.0093  memory: 5160  grad_norm: 15.4964  loss: 5.1061  decode.loss_cls: 0.0137  decode.loss_mask: 0.2247  decode.loss_dice: 0.1821  decode.d0.loss_cls: 0.8335  decode.d0.loss_mask: 0.2306  decode.d0.loss_dice: 0.1936  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.1867  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.2265  decode.d2.loss_dice: 0.1882  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.2258  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.1858  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.2257  decode.d6.loss_dice: 0.1857  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.1831  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.1833
09/30 12:45:47 - mmengine - INFO - Iter(train) [ 30850/320000]  base_lr: 9.1280e-05 lr: 9.1280e-06  eta: 1 day, 10:47:28  time: 0.4343  data_time: 0.0093  memory: 5160  grad_norm: 65.5746  loss: 6.9445  decode.loss_cls: 0.1151  decode.loss_mask: 0.2306  decode.loss_dice: 0.2731  decode.d0.loss_cls: 0.9405  decode.d0.loss_mask: 0.2434  decode.d0.loss_dice: 0.3042  decode.d1.loss_cls: 0.1011  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.2657  decode.d2.loss_cls: 0.1440  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.2413  decode.d3.loss_cls: 0.1099  decode.d3.loss_mask: 0.2284  decode.d3.loss_dice: 0.2563  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2525  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.1260  decode.d6.loss_mask: 0.2295  decode.d6.loss_dice: 0.2760  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.2307  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.1252  decode.d8.loss_mask: 0.2310  decode.d8.loss_dice: 0.2494
09/30 12:46:09 - mmengine - INFO - Iter(train) [ 30900/320000]  base_lr: 9.1266e-05 lr: 9.1266e-06  eta: 1 day, 10:47:07  time: 0.4367  data_time: 0.0097  memory: 5161  grad_norm: 84.9864  loss: 11.3980  decode.loss_cls: 0.3003  decode.loss_mask: 0.3637  decode.loss_dice: 0.3419  decode.d0.loss_cls: 1.1089  decode.d0.loss_mask: 0.3539  decode.d0.loss_dice: 0.3743  decode.d1.loss_cls: 0.3403  decode.d1.loss_mask: 0.4012  decode.d1.loss_dice: 0.3905  decode.d2.loss_cls: 0.3699  decode.d2.loss_mask: 0.3665  decode.d2.loss_dice: 0.3553  decode.d3.loss_cls: 0.3142  decode.d3.loss_mask: 0.3593  decode.d3.loss_dice: 0.3514  decode.d4.loss_cls: 0.3782  decode.d4.loss_mask: 0.3750  decode.d4.loss_dice: 0.3742  decode.d5.loss_cls: 0.3431  decode.d5.loss_mask: 0.3665  decode.d5.loss_dice: 0.3613  decode.d6.loss_cls: 0.3031  decode.d6.loss_mask: 0.3951  decode.d6.loss_dice: 0.3557  decode.d7.loss_cls: 0.3051  decode.d7.loss_mask: 0.3610  decode.d7.loss_dice: 0.3565  decode.d8.loss_cls: 0.3263  decode.d8.loss_mask: 0.3504  decode.d8.loss_dice: 0.3553
09/30 12:46:31 - mmengine - INFO - Iter(train) [ 30950/320000]  base_lr: 9.1252e-05 lr: 9.1252e-06  eta: 1 day, 10:46:46  time: 0.4359  data_time: 0.0096  memory: 5147  grad_norm: 136.2952  loss: 9.6342  decode.loss_cls: 0.1399  decode.loss_mask: 0.3822  decode.loss_dice: 0.3113  decode.d0.loss_cls: 0.9488  decode.d0.loss_mask: 0.3941  decode.d0.loss_dice: 0.3357  decode.d1.loss_cls: 0.1950  decode.d1.loss_mask: 0.3855  decode.d1.loss_dice: 0.3276  decode.d2.loss_cls: 0.1805  decode.d2.loss_mask: 0.3856  decode.d2.loss_dice: 0.3091  decode.d3.loss_cls: 0.2424  decode.d3.loss_mask: 0.3809  decode.d3.loss_dice: 0.3149  decode.d4.loss_cls: 0.2474  decode.d4.loss_mask: 0.3824  decode.d4.loss_dice: 0.3182  decode.d5.loss_cls: 0.2326  decode.d5.loss_mask: 0.3838  decode.d5.loss_dice: 0.3121  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 0.3821  decode.d6.loss_dice: 0.3204  decode.d7.loss_cls: 0.1528  decode.d7.loss_mask: 0.3741  decode.d7.loss_dice: 0.2880  decode.d8.loss_cls: 0.1501  decode.d8.loss_mask: 0.3772  decode.d8.loss_dice: 0.2988
09/30 12:46:53 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:46:53 - mmengine - INFO - Iter(train) [ 31000/320000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 1 day, 10:46:27  time: 0.4350  data_time: 0.0094  memory: 5161  grad_norm: 65.9310  loss: 6.3260  decode.loss_cls: 0.1315  decode.loss_mask: 0.2224  decode.loss_dice: 0.2203  decode.d0.loss_cls: 0.8963  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.0998  decode.d1.loss_mask: 0.2205  decode.d1.loss_dice: 0.2155  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2179  decode.d3.loss_cls: 0.0955  decode.d3.loss_mask: 0.2222  decode.d3.loss_dice: 0.2301  decode.d4.loss_cls: 0.0962  decode.d4.loss_mask: 0.2282  decode.d4.loss_dice: 0.2230  decode.d5.loss_cls: 0.1099  decode.d5.loss_mask: 0.2311  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.1229  decode.d6.loss_mask: 0.2228  decode.d6.loss_dice: 0.2189  decode.d7.loss_cls: 0.1330  decode.d7.loss_mask: 0.2261  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.2170
09/30 12:47:14 - mmengine - INFO - Iter(train) [ 31050/320000]  base_lr: 9.1223e-05 lr: 9.1223e-06  eta: 1 day, 10:46:07  time: 0.4350  data_time: 0.0092  memory: 5161  grad_norm: 18.2819  loss: 5.0141  decode.loss_cls: 0.0301  decode.loss_mask: 0.2176  decode.loss_dice: 0.1673  decode.d0.loss_cls: 0.9052  decode.d0.loss_mask: 0.2211  decode.d0.loss_dice: 0.1696  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 0.2147  decode.d1.loss_dice: 0.1700  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.2159  decode.d2.loss_dice: 0.1686  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2142  decode.d3.loss_dice: 0.1688  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.1713  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.2145  decode.d5.loss_dice: 0.1691  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.2136  decode.d6.loss_dice: 0.1714  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.2148  decode.d7.loss_dice: 0.1719  decode.d8.loss_cls: 0.0328  decode.d8.loss_mask: 0.2157  decode.d8.loss_dice: 0.1699
09/30 12:47:36 - mmengine - INFO - Iter(train) [ 31100/320000]  base_lr: 9.1209e-05 lr: 9.1209e-06  eta: 1 day, 10:45:46  time: 0.4362  data_time: 0.0095  memory: 5180  grad_norm: 51.2535  loss: 7.1607  decode.loss_cls: 0.0834  decode.loss_mask: 0.2342  decode.loss_dice: 0.2628  decode.d0.loss_cls: 1.1367  decode.d0.loss_mask: 0.2408  decode.d0.loss_dice: 0.2536  decode.d1.loss_cls: 0.0890  decode.d1.loss_mask: 0.2503  decode.d1.loss_dice: 0.2452  decode.d2.loss_cls: 0.1536  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2767  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.2644  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.2720  decode.d6.loss_cls: 0.1469  decode.d6.loss_mask: 0.2375  decode.d6.loss_dice: 0.2772  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.2495  decode.d8.loss_cls: 0.1303  decode.d8.loss_mask: 0.2390  decode.d8.loss_dice: 0.2732
09/30 12:47:58 - mmengine - INFO - Iter(train) [ 31150/320000]  base_lr: 9.1195e-05 lr: 9.1195e-06  eta: 1 day, 10:45:25  time: 0.4355  data_time: 0.0094  memory: 5161  grad_norm: 45.3424  loss: 5.8276  decode.loss_cls: 0.0360  decode.loss_mask: 0.2295  decode.loss_dice: 0.1991  decode.d0.loss_cls: 1.0150  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2125  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.1984  decode.d3.loss_cls: 0.0815  decode.d3.loss_mask: 0.2405  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0461  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.1971  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.1914  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.2180  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.2425  decode.d7.loss_dice: 0.2009  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.1799
09/30 12:48:20 - mmengine - INFO - Iter(train) [ 31200/320000]  base_lr: 9.1181e-05 lr: 9.1181e-06  eta: 1 day, 10:45:04  time: 0.4351  data_time: 0.0094  memory: 5147  grad_norm: 53.4131  loss: 6.1686  decode.loss_cls: 0.0785  decode.loss_mask: 0.2658  decode.loss_dice: 0.2076  decode.d0.loss_cls: 0.7894  decode.d0.loss_mask: 0.2677  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.1123  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.1978  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.2607  decode.d2.loss_dice: 0.1942  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.2086  decode.d4.loss_cls: 0.1003  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2011  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.2072  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2001  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.1933  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.2588  decode.d8.loss_dice: 0.1911
09/30 12:48:41 - mmengine - INFO - Iter(train) [ 31250/320000]  base_lr: 9.1167e-05 lr: 9.1167e-06  eta: 1 day, 10:44:44  time: 0.4351  data_time: 0.0095  memory: 5180  grad_norm: 82.2594  loss: 8.4039  decode.loss_cls: 0.1521  decode.loss_mask: 0.3473  decode.loss_dice: 0.2843  decode.d0.loss_cls: 1.0297  decode.d0.loss_mask: 0.3405  decode.d0.loss_dice: 0.3025  decode.d1.loss_cls: 0.2076  decode.d1.loss_mask: 0.3259  decode.d1.loss_dice: 0.2545  decode.d2.loss_cls: 0.1120  decode.d2.loss_mask: 0.3546  decode.d2.loss_dice: 0.3095  decode.d3.loss_cls: 0.1421  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.2671  decode.d4.loss_cls: 0.1222  decode.d4.loss_mask: 0.3299  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.1417  decode.d5.loss_mask: 0.3173  decode.d5.loss_dice: 0.2682  decode.d6.loss_cls: 0.1089  decode.d6.loss_mask: 0.3175  decode.d6.loss_dice: 0.2610  decode.d7.loss_cls: 0.1219  decode.d7.loss_mask: 0.3257  decode.d7.loss_dice: 0.2780  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.3290  decode.d8.loss_dice: 0.2810
09/30 12:49:03 - mmengine - INFO - Iter(train) [ 31300/320000]  base_lr: 9.1152e-05 lr: 9.1152e-06  eta: 1 day, 10:44:23  time: 0.4346  data_time: 0.0096  memory: 5160  grad_norm: 99.1632  loss: 6.8045  decode.loss_cls: 0.0431  decode.loss_mask: 0.2881  decode.loss_dice: 0.2559  decode.d0.loss_cls: 0.7845  decode.d0.loss_mask: 0.2940  decode.d0.loss_dice: 0.2699  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.2450  decode.d2.loss_cls: 0.1051  decode.d2.loss_mask: 0.2903  decode.d2.loss_dice: 0.2408  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.2883  decode.d3.loss_dice: 0.2387  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.2393  decode.d5.loss_cls: 0.0809  decode.d5.loss_mask: 0.2925  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.2912  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.2910  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.2914  decode.d8.loss_dice: 0.2480
09/30 12:49:25 - mmengine - INFO - Iter(train) [ 31350/320000]  base_lr: 9.1138e-05 lr: 9.1138e-06  eta: 1 day, 10:44:02  time: 0.4359  data_time: 0.0094  memory: 5161  grad_norm: 23.0051  loss: 5.3450  decode.loss_cls: 0.0456  decode.loss_mask: 0.2225  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.8339  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.1597  decode.d1.loss_cls: 0.1278  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.1646  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.1802  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.1699  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.1649  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.1650  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.2222  decode.d6.loss_dice: 0.1717  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.2191  decode.d7.loss_dice: 0.1662  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1680
09/30 12:49:47 - mmengine - INFO - Iter(train) [ 31400/320000]  base_lr: 9.1124e-05 lr: 9.1124e-06  eta: 1 day, 10:43:41  time: 0.4356  data_time: 0.0093  memory: 5161  grad_norm: 287.3340  loss: 8.4130  decode.loss_cls: 0.1058  decode.loss_mask: 0.3146  decode.loss_dice: 0.2567  decode.d0.loss_cls: 1.0823  decode.d0.loss_mask: 0.3174  decode.d0.loss_dice: 0.2612  decode.d1.loss_cls: 0.2512  decode.d1.loss_mask: 0.3004  decode.d1.loss_dice: 0.2364  decode.d2.loss_cls: 0.1897  decode.d2.loss_mask: 0.3355  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.1900  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.2311  decode.d4.loss_cls: 0.1359  decode.d4.loss_mask: 0.3226  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.2335  decode.d5.loss_mask: 0.3363  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.2046  decode.d6.loss_mask: 0.3202  decode.d6.loss_dice: 0.2519  decode.d7.loss_cls: 0.1814  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.2591  decode.d8.loss_cls: 0.1141  decode.d8.loss_mask: 0.3508  decode.d8.loss_dice: 0.2845
09/30 12:50:08 - mmengine - INFO - Iter(train) [ 31450/320000]  base_lr: 9.1110e-05 lr: 9.1110e-06  eta: 1 day, 10:43:20  time: 0.4349  data_time: 0.0095  memory: 5180  grad_norm: 85.9233  loss: 5.9357  decode.loss_cls: 0.1307  decode.loss_mask: 0.1811  decode.loss_dice: 0.1847  decode.d0.loss_cls: 0.8787  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1972  decode.d1.loss_cls: 0.1776  decode.d1.loss_mask: 0.1854  decode.d1.loss_dice: 0.1910  decode.d2.loss_cls: 0.1841  decode.d2.loss_mask: 0.1818  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.1752  decode.d3.loss_mask: 0.1826  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 0.1828  decode.d4.loss_dice: 0.1782  decode.d5.loss_cls: 0.1479  decode.d5.loss_mask: 0.1834  decode.d5.loss_dice: 0.1558  decode.d6.loss_cls: 0.1459  decode.d6.loss_mask: 0.1844  decode.d6.loss_dice: 0.1924  decode.d7.loss_cls: 0.1688  decode.d7.loss_mask: 0.1846  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.1130  decode.d8.loss_mask: 0.1833  decode.d8.loss_dice: 0.1846
09/30 12:50:30 - mmengine - INFO - Iter(train) [ 31500/320000]  base_lr: 9.1096e-05 lr: 9.1096e-06  eta: 1 day, 10:43:00  time: 0.4360  data_time: 0.0096  memory: 5161  grad_norm: 60.7622  loss: 5.2596  decode.loss_cls: 0.1223  decode.loss_mask: 0.1927  decode.loss_dice: 0.1700  decode.d0.loss_cls: 1.0282  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.1644  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.1967  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.1558  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.1920  decode.d3.loss_dice: 0.1611  decode.d4.loss_cls: 0.1139  decode.d4.loss_mask: 0.1904  decode.d4.loss_dice: 0.1559  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.1977  decode.d5.loss_dice: 0.1654  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.1645  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 0.1886  decode.d7.loss_dice: 0.1555  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.1884  decode.d8.loss_dice: 0.1562
09/30 12:50:52 - mmengine - INFO - Iter(train) [ 31550/320000]  base_lr: 9.1081e-05 lr: 9.1081e-06  eta: 1 day, 10:42:39  time: 0.4354  data_time: 0.0094  memory: 5180  grad_norm: 54.4973  loss: 6.5809  decode.loss_cls: 0.0508  decode.loss_mask: 0.2826  decode.loss_dice: 0.2122  decode.d0.loss_cls: 0.8110  decode.d0.loss_mask: 0.2890  decode.d0.loss_dice: 0.2345  decode.d1.loss_cls: 0.0818  decode.d1.loss_mask: 0.2907  decode.d1.loss_dice: 0.2343  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.2764  decode.d2.loss_dice: 0.2106  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 0.2783  decode.d3.loss_dice: 0.2141  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.2182  decode.d5.loss_cls: 0.0732  decode.d5.loss_mask: 0.2786  decode.d5.loss_dice: 0.2156  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.2835  decode.d6.loss_dice: 0.2213  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.2223  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.2171
09/30 12:51:14 - mmengine - INFO - Iter(train) [ 31600/320000]  base_lr: 9.1067e-05 lr: 9.1067e-06  eta: 1 day, 10:42:18  time: 0.4344  data_time: 0.0095  memory: 5180  grad_norm: 34.5655  loss: 5.1617  decode.loss_cls: 0.0143  decode.loss_mask: 0.2399  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.8239  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.1858  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.2446  decode.d1.loss_dice: 0.1795  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.1808  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.2391  decode.d3.loss_dice: 0.1809  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.1835  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2416  decode.d5.loss_dice: 0.1846  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.1803  decode.d7.loss_cls: 0.0195  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.1831
09/30 12:51:35 - mmengine - INFO - Iter(train) [ 31650/320000]  base_lr: 9.1053e-05 lr: 9.1053e-06  eta: 1 day, 10:41:57  time: 0.4343  data_time: 0.0092  memory: 5161  grad_norm: 94.7633  loss: 8.0186  decode.loss_cls: 0.0900  decode.loss_mask: 0.4341  decode.loss_dice: 0.2336  decode.d0.loss_cls: 0.8847  decode.d0.loss_mask: 0.2905  decode.d0.loss_dice: 0.2363  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 0.3622  decode.d1.loss_dice: 0.2415  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 0.2860  decode.d2.loss_dice: 0.2230  decode.d3.loss_cls: 0.1435  decode.d3.loss_mask: 0.3856  decode.d3.loss_dice: 0.2221  decode.d4.loss_cls: 0.1738  decode.d4.loss_mask: 0.3887  decode.d4.loss_dice: 0.2250  decode.d5.loss_cls: 0.1449  decode.d5.loss_mask: 0.3410  decode.d5.loss_dice: 0.2268  decode.d6.loss_cls: 0.1155  decode.d6.loss_mask: 0.3508  decode.d6.loss_dice: 0.2290  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.3513  decode.d7.loss_dice: 0.2353  decode.d8.loss_cls: 0.1157  decode.d8.loss_mask: 0.3676  decode.d8.loss_dice: 0.2330
09/30 12:51:57 - mmengine - INFO - Iter(train) [ 31700/320000]  base_lr: 9.1039e-05 lr: 9.1039e-06  eta: 1 day, 10:41:36  time: 0.4347  data_time: 0.0096  memory: 5147  grad_norm: 102.4402  loss: 9.7198  decode.loss_cls: 0.2312  decode.loss_mask: 0.4051  decode.loss_dice: 0.3433  decode.d0.loss_cls: 0.7294  decode.d0.loss_mask: 0.4158  decode.d0.loss_dice: 0.3401  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.3951  decode.d1.loss_dice: 0.3196  decode.d2.loss_cls: 0.1436  decode.d2.loss_mask: 0.3871  decode.d2.loss_dice: 0.3392  decode.d3.loss_cls: 0.1588  decode.d3.loss_mask: 0.3866  decode.d3.loss_dice: 0.3403  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.3874  decode.d4.loss_dice: 0.3263  decode.d5.loss_cls: 0.1930  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.3302  decode.d6.loss_cls: 0.1778  decode.d6.loss_mask: 0.4004  decode.d6.loss_dice: 0.3429  decode.d7.loss_cls: 0.1827  decode.d7.loss_mask: 0.3998  decode.d7.loss_dice: 0.3480  decode.d8.loss_cls: 0.2543  decode.d8.loss_mask: 0.3989  decode.d8.loss_dice: 0.3550
09/30 12:52:19 - mmengine - INFO - Iter(train) [ 31750/320000]  base_lr: 9.1025e-05 lr: 9.1025e-06  eta: 1 day, 10:41:16  time: 0.4359  data_time: 0.0098  memory: 5161  grad_norm: 40.6115  loss: 8.2261  decode.loss_cls: 0.1835  decode.loss_mask: 0.3054  decode.loss_dice: 0.2569  decode.d0.loss_cls: 0.9393  decode.d0.loss_mask: 0.2794  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.1703  decode.d1.loss_mask: 0.3153  decode.d1.loss_dice: 0.2568  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.3430  decode.d2.loss_dice: 0.2410  decode.d3.loss_cls: 0.1638  decode.d3.loss_mask: 0.3155  decode.d3.loss_dice: 0.2595  decode.d4.loss_cls: 0.1658  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.2715  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.3114  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.1905  decode.d6.loss_mask: 0.3847  decode.d6.loss_dice: 0.2642  decode.d7.loss_cls: 0.1988  decode.d7.loss_mask: 0.3775  decode.d7.loss_dice: 0.2628  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.2351
09/30 12:52:41 - mmengine - INFO - Iter(train) [ 31800/320000]  base_lr: 9.1010e-05 lr: 9.1010e-06  eta: 1 day, 10:40:55  time: 0.4363  data_time: 0.0095  memory: 5147  grad_norm: 101.5409  loss: 9.9711  decode.loss_cls: 0.3367  decode.loss_mask: 0.2581  decode.loss_dice: 0.3045  decode.d0.loss_cls: 1.0891  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.2898  decode.d1.loss_cls: 0.3928  decode.d1.loss_mask: 0.2578  decode.d1.loss_dice: 0.3116  decode.d2.loss_cls: 0.4041  decode.d2.loss_mask: 0.2526  decode.d2.loss_dice: 0.3222  decode.d3.loss_cls: 0.4260  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.3264  decode.d4.loss_cls: 0.3270  decode.d4.loss_mask: 0.2596  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 0.3306  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2834  decode.d6.loss_cls: 0.3672  decode.d6.loss_mask: 0.2537  decode.d6.loss_dice: 0.3029  decode.d7.loss_cls: 0.3251  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.3321  decode.d8.loss_mask: 0.2553  decode.d8.loss_dice: 0.3274
09/30 12:53:03 - mmengine - INFO - Iter(train) [ 31850/320000]  base_lr: 9.0996e-05 lr: 9.0996e-06  eta: 1 day, 10:40:35  time: 0.4354  data_time: 0.0097  memory: 5180  grad_norm: 47.4014  loss: 6.4734  decode.loss_cls: 0.0539  decode.loss_mask: 0.2851  decode.loss_dice: 0.2194  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.2169  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.2880  decode.d1.loss_dice: 0.2234  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.2171  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.2178  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.2850  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.2214  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.2836  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.2889  decode.d8.loss_dice: 0.2235
09/30 12:53:24 - mmengine - INFO - Iter(train) [ 31900/320000]  base_lr: 9.0982e-05 lr: 9.0982e-06  eta: 1 day, 10:40:14  time: 0.4356  data_time: 0.0093  memory: 5160  grad_norm: 78.8576  loss: 9.2444  decode.loss_cls: 0.2860  decode.loss_mask: 0.2589  decode.loss_dice: 0.3024  decode.d0.loss_cls: 1.1958  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.4142  decode.d1.loss_mask: 0.2537  decode.d1.loss_dice: 0.2982  decode.d2.loss_cls: 0.2721  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.3082  decode.d3.loss_cls: 0.2235  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.2871  decode.d4.loss_cls: 0.2910  decode.d4.loss_mask: 0.2445  decode.d4.loss_dice: 0.2777  decode.d5.loss_cls: 0.3149  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.2600  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2916  decode.d7.loss_cls: 0.3252  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.2627  decode.d8.loss_cls: 0.2855  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.2970
09/30 12:53:46 - mmengine - INFO - Iter(train) [ 31950/320000]  base_lr: 9.0968e-05 lr: 9.0968e-06  eta: 1 day, 10:39:53  time: 0.4356  data_time: 0.0094  memory: 5161  grad_norm: 18.9709  loss: 5.0967  decode.loss_cls: 0.0733  decode.loss_mask: 0.1789  decode.loss_dice: 0.2073  decode.d0.loss_cls: 0.8376  decode.d0.loss_mask: 0.1792  decode.d0.loss_dice: 0.2037  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.1772  decode.d1.loss_dice: 0.1861  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.1788  decode.d2.loss_dice: 0.2038  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.1773  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.1753  decode.d4.loss_dice: 0.1912  decode.d5.loss_cls: 0.0573  decode.d5.loss_mask: 0.1787  decode.d5.loss_dice: 0.2039  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.1781  decode.d6.loss_dice: 0.2076  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.1772  decode.d7.loss_dice: 0.1615  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.1756  decode.d8.loss_dice: 0.2007
09/30 12:54:08 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 12:54:08 - mmengine - INFO - Iter(train) [ 32000/320000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 1 day, 10:39:33  time: 0.4363  data_time: 0.0096  memory: 5160  grad_norm: 51.9535  loss: 9.1701  decode.loss_cls: 0.2438  decode.loss_mask: 0.2449  decode.loss_dice: 0.3835  decode.d0.loss_cls: 1.0508  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.3617  decode.d1.loss_cls: 0.2690  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.3681  decode.d2.loss_cls: 0.2768  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.3332  decode.d3.loss_cls: 0.2088  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.3732  decode.d4.loss_cls: 0.2008  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.3501  decode.d5.loss_cls: 0.1935  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.3839  decode.d6.loss_cls: 0.2139  decode.d6.loss_mask: 0.2450  decode.d6.loss_dice: 0.3630  decode.d7.loss_cls: 0.1850  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.3378  decode.d8.loss_cls: 0.2474  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.3724
09/30 12:54:30 - mmengine - INFO - Iter(train) [ 32050/320000]  base_lr: 9.0939e-05 lr: 9.0939e-06  eta: 1 day, 10:39:12  time: 0.4358  data_time: 0.0095  memory: 5180  grad_norm: 187.4378  loss: 6.0385  decode.loss_cls: 0.0694  decode.loss_mask: 0.2506  decode.loss_dice: 0.2063  decode.d0.loss_cls: 0.9746  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.1994  decode.d1.loss_cls: 0.1538  decode.d1.loss_mask: 0.2170  decode.d1.loss_dice: 0.1895  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.2188  decode.d2.loss_dice: 0.1814  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.2277  decode.d3.loss_dice: 0.1962  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1853  decode.d5.loss_cls: 0.0746  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2050  decode.d6.loss_cls: 0.0789  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.1888  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.2440  decode.d7.loss_dice: 0.2047  decode.d8.loss_cls: 0.1014  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2020
09/30 12:54:51 - mmengine - INFO - Iter(train) [ 32100/320000]  base_lr: 9.0925e-05 lr: 9.0925e-06  eta: 1 day, 10:38:51  time: 0.4349  data_time: 0.0093  memory: 5161  grad_norm: 129.1486  loss: 5.5467  decode.loss_cls: 0.0752  decode.loss_mask: 0.2279  decode.loss_dice: 0.1922  decode.d0.loss_cls: 0.7435  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.1963  decode.d1.loss_cls: 0.1309  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.1872  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.2289  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.1848  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.2300  decode.d4.loss_dice: 0.1887  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.2318  decode.d5.loss_dice: 0.1858  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.1834  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1911
09/30 12:55:13 - mmengine - INFO - Iter(train) [ 32150/320000]  base_lr: 9.0911e-05 lr: 9.0911e-06  eta: 1 day, 10:38:31  time: 0.4350  data_time: 0.0096  memory: 5180  grad_norm: 36.9950  loss: 6.0182  decode.loss_cls: 0.0610  decode.loss_mask: 0.2525  decode.loss_dice: 0.2012  decode.d0.loss_cls: 0.8304  decode.d0.loss_mask: 0.2542  decode.d0.loss_dice: 0.2182  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.2544  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.1930  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.2544  decode.d4.loss_dice: 0.2003  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.2496  decode.d5.loss_dice: 0.1917  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.2505  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.2574  decode.d7.loss_dice: 0.2119  decode.d8.loss_cls: 0.0715  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.2097
09/30 12:55:35 - mmengine - INFO - Iter(train) [ 32200/320000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 1 day, 10:38:10  time: 0.4365  data_time: 0.0096  memory: 5161  grad_norm: 30.8001  loss: 5.7909  decode.loss_cls: 0.0779  decode.loss_mask: 0.2411  decode.loss_dice: 0.1904  decode.d0.loss_cls: 0.8289  decode.d0.loss_mask: 0.2561  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.1805  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.2458  decode.d2.loss_dice: 0.1869  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.2441  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.1829  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.2410  decode.d5.loss_dice: 0.1787  decode.d6.loss_cls: 0.0709  decode.d6.loss_mask: 0.2415  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.1808  decode.d8.loss_cls: 0.0712  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.1859
09/30 12:55:57 - mmengine - INFO - Iter(train) [ 32250/320000]  base_lr: 9.0882e-05 lr: 9.0882e-06  eta: 1 day, 10:37:50  time: 0.4359  data_time: 0.0095  memory: 5180  grad_norm: 215.9425  loss: 7.1852  decode.loss_cls: 0.0622  decode.loss_mask: 0.3369  decode.loss_dice: 0.2385  decode.d0.loss_cls: 0.7283  decode.d0.loss_mask: 0.3377  decode.d0.loss_dice: 0.2623  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.3376  decode.d1.loss_dice: 0.2303  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.3408  decode.d2.loss_dice: 0.2278  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.3239  decode.d3.loss_dice: 0.2281  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.3419  decode.d4.loss_dice: 0.2346  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.2197  decode.d6.loss_cls: 0.1178  decode.d6.loss_mask: 0.3313  decode.d6.loss_dice: 0.2426  decode.d7.loss_cls: 0.1061  decode.d7.loss_mask: 0.3312  decode.d7.loss_dice: 0.2306  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.3301  decode.d8.loss_dice: 0.2336
09/30 12:56:19 - mmengine - INFO - Iter(train) [ 32300/320000]  base_lr: 9.0868e-05 lr: 9.0868e-06  eta: 1 day, 10:37:29  time: 0.4355  data_time: 0.0094  memory: 5161  grad_norm: 37.3753  loss: 5.8324  decode.loss_cls: 0.1598  decode.loss_mask: 0.2026  decode.loss_dice: 0.1501  decode.d0.loss_cls: 0.8186  decode.d0.loss_mask: 0.2130  decode.d0.loss_dice: 0.1474  decode.d1.loss_cls: 0.2311  decode.d1.loss_mask: 0.2090  decode.d1.loss_dice: 0.1422  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.1434  decode.d3.loss_cls: 0.1807  decode.d3.loss_mask: 0.2052  decode.d3.loss_dice: 0.1484  decode.d4.loss_cls: 0.1392  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.1439  decode.d5.loss_cls: 0.1384  decode.d5.loss_mask: 0.2067  decode.d5.loss_dice: 0.1438  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 0.2060  decode.d6.loss_dice: 0.1470  decode.d7.loss_cls: 0.1408  decode.d7.loss_mask: 0.2083  decode.d7.loss_dice: 0.1467  decode.d8.loss_cls: 0.1635  decode.d8.loss_mask: 0.2053  decode.d8.loss_dice: 0.1497
09/30 12:56:40 - mmengine - INFO - Iter(train) [ 32350/320000]  base_lr: 9.0854e-05 lr: 9.0854e-06  eta: 1 day, 10:37:09  time: 0.4353  data_time: 0.0094  memory: 5161  grad_norm: 60.4776  loss: 6.1497  decode.loss_cls: 0.1576  decode.loss_mask: 0.2031  decode.loss_dice: 0.1898  decode.d0.loss_cls: 0.9567  decode.d0.loss_mask: 0.2030  decode.d0.loss_dice: 0.1948  decode.d1.loss_cls: 0.1506  decode.d1.loss_mask: 0.1960  decode.d1.loss_dice: 0.1842  decode.d2.loss_cls: 0.1515  decode.d2.loss_mask: 0.1956  decode.d2.loss_dice: 0.1758  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.1977  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.1658  decode.d4.loss_mask: 0.1990  decode.d4.loss_dice: 0.1792  decode.d5.loss_cls: 0.1378  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.1819  decode.d6.loss_cls: 0.2012  decode.d6.loss_mask: 0.1976  decode.d6.loss_dice: 0.1747  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 0.2033  decode.d7.loss_dice: 0.1816  decode.d8.loss_cls: 0.1248  decode.d8.loss_mask: 0.2027  decode.d8.loss_dice: 0.1834
09/30 12:57:02 - mmengine - INFO - Iter(train) [ 32400/320000]  base_lr: 9.0840e-05 lr: 9.0840e-06  eta: 1 day, 10:36:48  time: 0.4345  data_time: 0.0095  memory: 5180  grad_norm: 81.9601  loss: 6.2796  decode.loss_cls: 0.1393  decode.loss_mask: 0.2426  decode.loss_dice: 0.1886  decode.d0.loss_cls: 0.9392  decode.d0.loss_mask: 0.2650  decode.d0.loss_dice: 0.2064  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.1710  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.1056  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0984  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.1801  decode.d5.loss_cls: 0.0995  decode.d5.loss_mask: 0.2437  decode.d5.loss_dice: 0.1739  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.1655  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.1149  decode.d8.loss_mask: 0.2434  decode.d8.loss_dice: 0.1750
09/30 12:57:24 - mmengine - INFO - Iter(train) [ 32450/320000]  base_lr: 9.0826e-05 lr: 9.0826e-06  eta: 1 day, 10:36:27  time: 0.4354  data_time: 0.0096  memory: 5180  grad_norm: 50.6336  loss: 7.4758  decode.loss_cls: 0.0799  decode.loss_mask: 0.3076  decode.loss_dice: 0.2508  decode.d0.loss_cls: 0.8914  decode.d0.loss_mask: 0.3002  decode.d0.loss_dice: 0.2481  decode.d1.loss_cls: 0.1561  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.2607  decode.d2.loss_cls: 0.1071  decode.d2.loss_mask: 0.3095  decode.d2.loss_dice: 0.2526  decode.d3.loss_cls: 0.1307  decode.d3.loss_mask: 0.3066  decode.d3.loss_dice: 0.2458  decode.d4.loss_cls: 0.1235  decode.d4.loss_mask: 0.3054  decode.d4.loss_dice: 0.2428  decode.d5.loss_cls: 0.1330  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.0849  decode.d6.loss_mask: 0.3045  decode.d6.loss_dice: 0.2354  decode.d7.loss_cls: 0.1258  decode.d7.loss_mask: 0.3045  decode.d7.loss_dice: 0.2412  decode.d8.loss_cls: 0.1110  decode.d8.loss_mask: 0.3070  decode.d8.loss_dice: 0.2484
09/30 12:57:46 - mmengine - INFO - Iter(train) [ 32500/320000]  base_lr: 9.0811e-05 lr: 9.0811e-06  eta: 1 day, 10:36:07  time: 0.4359  data_time: 0.0096  memory: 5147  grad_norm: 74.6838  loss: 4.9635  decode.loss_cls: 0.0150  decode.loss_mask: 0.2260  decode.loss_dice: 0.1708  decode.d0.loss_cls: 0.7824  decode.d0.loss_mask: 0.2255  decode.d0.loss_dice: 0.1855  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.2224  decode.d1.loss_dice: 0.1723  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.1752  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.2226  decode.d3.loss_dice: 0.1755  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.1776  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.2209  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.1729  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.2221  decode.d7.loss_dice: 0.1761  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.1739
09/30 12:58:08 - mmengine - INFO - Iter(train) [ 32550/320000]  base_lr: 9.0797e-05 lr: 9.0797e-06  eta: 1 day, 10:35:46  time: 0.4360  data_time: 0.0096  memory: 5180  grad_norm: 80.2348  loss: 6.4338  decode.loss_cls: 0.1476  decode.loss_mask: 0.2484  decode.loss_dice: 0.1750  decode.d0.loss_cls: 0.8987  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.1895  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2540  decode.d1.loss_dice: 0.1867  decode.d2.loss_cls: 0.1572  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.1900  decode.d3.loss_cls: 0.1523  decode.d3.loss_mask: 0.2548  decode.d3.loss_dice: 0.1830  decode.d4.loss_cls: 0.1331  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.1830  decode.d5.loss_cls: 0.1107  decode.d5.loss_mask: 0.2533  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.1775  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.2524  decode.d7.loss_dice: 0.1851  decode.d8.loss_cls: 0.1080  decode.d8.loss_mask: 0.2507  decode.d8.loss_dice: 0.1797
09/30 12:58:29 - mmengine - INFO - Iter(train) [ 32600/320000]  base_lr: 9.0783e-05 lr: 9.0783e-06  eta: 1 day, 10:35:25  time: 0.4353  data_time: 0.0096  memory: 5180  grad_norm: 63.7577  loss: 5.6098  decode.loss_cls: 0.0996  decode.loss_mask: 0.2176  decode.loss_dice: 0.1634  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.1755  decode.d1.loss_cls: 0.1678  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.1703  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 0.2091  decode.d2.loss_dice: 0.1581  decode.d3.loss_cls: 0.1315  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.1651  decode.d4.loss_cls: 0.0956  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.1625  decode.d5.loss_cls: 0.0885  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.1573  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.2178  decode.d6.loss_dice: 0.1655  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2141  decode.d7.loss_dice: 0.1640  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.2195  decode.d8.loss_dice: 0.1746
09/30 12:58:51 - mmengine - INFO - Iter(train) [ 32650/320000]  base_lr: 9.0769e-05 lr: 9.0769e-06  eta: 1 day, 10:35:06  time: 0.4357  data_time: 0.0096  memory: 5161  grad_norm: 65.3198  loss: 7.9446  decode.loss_cls: 0.1664  decode.loss_mask: 0.3338  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.9692  decode.d0.loss_mask: 0.2781  decode.d0.loss_dice: 0.2093  decode.d1.loss_cls: 0.1814  decode.d1.loss_mask: 0.3465  decode.d1.loss_dice: 0.2052  decode.d2.loss_cls: 0.1897  decode.d2.loss_mask: 0.3365  decode.d2.loss_dice: 0.2042  decode.d3.loss_cls: 0.1739  decode.d3.loss_mask: 0.3485  decode.d3.loss_dice: 0.2114  decode.d4.loss_cls: 0.1654  decode.d4.loss_mask: 0.3273  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.3470  decode.d5.loss_dice: 0.2027  decode.d6.loss_cls: 0.1758  decode.d6.loss_mask: 0.3475  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.1846  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.2136  decode.d8.loss_cls: 0.1622  decode.d8.loss_mask: 0.3313  decode.d8.loss_dice: 0.1982
09/30 12:59:13 - mmengine - INFO - Iter(train) [ 32700/320000]  base_lr: 9.0755e-05 lr: 9.0755e-06  eta: 1 day, 10:34:46  time: 0.4364  data_time: 0.0095  memory: 5180  grad_norm: 28.5994  loss: 6.2458  decode.loss_cls: 0.0659  decode.loss_mask: 0.2612  decode.loss_dice: 0.1866  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2210  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.2644  decode.d1.loss_dice: 0.1991  decode.d2.loss_cls: 0.0800  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.2065  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2615  decode.d3.loss_dice: 0.2162  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.2674  decode.d4.loss_dice: 0.2208  decode.d5.loss_cls: 0.0785  decode.d5.loss_mask: 0.2647  decode.d5.loss_dice: 0.2075  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.2646  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.2089  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2114
09/30 12:59:35 - mmengine - INFO - Iter(train) [ 32750/320000]  base_lr: 9.0740e-05 lr: 9.0740e-06  eta: 1 day, 10:34:25  time: 0.4346  data_time: 0.0093  memory: 5160  grad_norm: 78.9527  loss: 8.6223  decode.loss_cls: 0.2568  decode.loss_mask: 0.2384  decode.loss_dice: 0.3025  decode.d0.loss_cls: 0.9140  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.3405  decode.d1.loss_cls: 0.2615  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.3175  decode.d2.loss_cls: 0.2448  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.2137  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.2973  decode.d4.loss_cls: 0.2310  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2981  decode.d5.loss_cls: 0.2549  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.2968  decode.d6.loss_cls: 0.2406  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.3122  decode.d7.loss_cls: 0.2734  decode.d7.loss_mask: 0.3249  decode.d7.loss_dice: 0.3054  decode.d8.loss_cls: 0.2469  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.2933
09/30 12:59:57 - mmengine - INFO - Iter(train) [ 32800/320000]  base_lr: 9.0726e-05 lr: 9.0726e-06  eta: 1 day, 10:34:04  time: 0.4353  data_time: 0.0095  memory: 5147  grad_norm: 31.4721  loss: 5.8536  decode.loss_cls: 0.0737  decode.loss_mask: 0.1988  decode.loss_dice: 0.2190  decode.d0.loss_cls: 0.7749  decode.d0.loss_mask: 0.2016  decode.d0.loss_dice: 0.1910  decode.d1.loss_cls: 0.1746  decode.d1.loss_mask: 0.2007  decode.d1.loss_dice: 0.1988  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.2002  decode.d2.loss_dice: 0.2183  decode.d3.loss_cls: 0.1031  decode.d3.loss_mask: 0.1997  decode.d3.loss_dice: 0.2137  decode.d4.loss_cls: 0.1473  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.2061  decode.d5.loss_cls: 0.1221  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.2106  decode.d6.loss_cls: 0.0953  decode.d6.loss_mask: 0.2024  decode.d6.loss_dice: 0.2160  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.2109  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.1999  decode.d8.loss_dice: 0.2074
09/30 13:00:18 - mmengine - INFO - Iter(train) [ 32850/320000]  base_lr: 9.0712e-05 lr: 9.0712e-06  eta: 1 day, 10:33:43  time: 0.4360  data_time: 0.0092  memory: 5161  grad_norm: 74.8830  loss: 7.2586  decode.loss_cls: 0.1220  decode.loss_mask: 0.2765  decode.loss_dice: 0.2362  decode.d0.loss_cls: 0.9734  decode.d0.loss_mask: 0.2654  decode.d0.loss_dice: 0.2298  decode.d1.loss_cls: 0.1775  decode.d1.loss_mask: 0.2732  decode.d1.loss_dice: 0.2374  decode.d2.loss_cls: 0.1564  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.2257  decode.d3.loss_cls: 0.1259  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.2215  decode.d4.loss_cls: 0.1468  decode.d4.loss_mask: 0.2807  decode.d4.loss_dice: 0.2247  decode.d5.loss_cls: 0.1482  decode.d5.loss_mask: 0.2717  decode.d5.loss_dice: 0.2233  decode.d6.loss_cls: 0.1347  decode.d6.loss_mask: 0.2703  decode.d6.loss_dice: 0.2238  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.3525  decode.d7.loss_dice: 0.2297  decode.d8.loss_cls: 0.1327  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.2231
09/30 13:00:40 - mmengine - INFO - Iter(train) [ 32900/320000]  base_lr: 9.0698e-05 lr: 9.0698e-06  eta: 1 day, 10:33:23  time: 0.4361  data_time: 0.0096  memory: 5161  grad_norm: 26.9437  loss: 5.0574  decode.loss_cls: 0.0654  decode.loss_mask: 0.1852  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.8885  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.1935  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.1829  decode.d1.loss_dice: 0.1824  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.1862  decode.d2.loss_dice: 0.1801  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.1871  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.0657  decode.d4.loss_mask: 0.1835  decode.d4.loss_dice: 0.1422  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.1890  decode.d5.loss_dice: 0.1501  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.1891  decode.d6.loss_dice: 0.1525  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.1868  decode.d7.loss_dice: 0.1738  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.1777
09/30 13:01:02 - mmengine - INFO - Iter(train) [ 32950/320000]  base_lr: 9.0683e-05 lr: 9.0683e-06  eta: 1 day, 10:33:02  time: 0.4354  data_time: 0.0095  memory: 5161  grad_norm: 56.2479  loss: 5.5173  decode.loss_cls: 0.0145  decode.loss_mask: 0.2381  decode.loss_dice: 0.1846  decode.d0.loss_cls: 0.9719  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.1855  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.0981  decode.d2.loss_mask: 0.2360  decode.d2.loss_dice: 0.1823  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.2335  decode.d3.loss_dice: 0.1893  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.2006  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.1875  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.2365  decode.d6.loss_dice: 0.1831  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.2400  decode.d7.loss_dice: 0.1867  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.1864
09/30 13:01:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:01:24 - mmengine - INFO - Iter(train) [ 33000/320000]  base_lr: 9.0669e-05 lr: 9.0669e-06  eta: 1 day, 10:32:41  time: 0.4351  data_time: 0.0095  memory: 5161  grad_norm: 150.3849  loss: 9.9684  decode.loss_cls: 0.3442  decode.loss_mask: 0.2557  decode.loss_dice: 0.3186  decode.d0.loss_cls: 1.1340  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.3667  decode.d1.loss_cls: 0.3416  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.3452  decode.d2.loss_cls: 0.3543  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.3576  decode.d3.loss_cls: 0.2954  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.3579  decode.d4.loss_cls: 0.2860  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.3472  decode.d5.loss_cls: 0.2980  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.3615  decode.d6.loss_cls: 0.2679  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.3507  decode.d7.loss_cls: 0.2596  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.3462  decode.d8.loss_cls: 0.2813  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.3395
09/30 13:01:46 - mmengine - INFO - Iter(train) [ 33050/320000]  base_lr: 9.0655e-05 lr: 9.0655e-06  eta: 1 day, 10:32:20  time: 0.4349  data_time: 0.0094  memory: 5160  grad_norm: 29.9290  loss: 5.9755  decode.loss_cls: 0.0325  decode.loss_mask: 0.2971  decode.loss_dice: 0.1908  decode.d0.loss_cls: 0.8546  decode.d0.loss_mask: 0.3015  decode.d0.loss_dice: 0.2018  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.2958  decode.d1.loss_dice: 0.1943  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.1946  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.2977  decode.d3.loss_dice: 0.1914  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.1902  decode.d5.loss_cls: 0.0199  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.1945  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2966  decode.d6.loss_dice: 0.1925  decode.d7.loss_cls: 0.0259  decode.d7.loss_mask: 0.2989  decode.d7.loss_dice: 0.1930  decode.d8.loss_cls: 0.0318  decode.d8.loss_mask: 0.2977  decode.d8.loss_dice: 0.1968
09/30 13:02:07 - mmengine - INFO - Iter(train) [ 33100/320000]  base_lr: 9.0641e-05 lr: 9.0641e-06  eta: 1 day, 10:32:00  time: 0.4360  data_time: 0.0095  memory: 5161  grad_norm: 62.7201  loss: 5.6743  decode.loss_cls: 0.0150  decode.loss_mask: 0.2458  decode.loss_dice: 0.2163  decode.d0.loss_cls: 0.7929  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.2151  decode.d1.loss_cls: 0.0296  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.2200  decode.d2.loss_cls: 0.0318  decode.d2.loss_mask: 0.2496  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2177  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.2430  decode.d5.loss_dice: 0.2148  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.2499  decode.d6.loss_dice: 0.2123  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.2466  decode.d7.loss_dice: 0.2230  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.2478  decode.d8.loss_dice: 0.2300
09/30 13:02:29 - mmengine - INFO - Iter(train) [ 33150/320000]  base_lr: 9.0627e-05 lr: 9.0627e-06  eta: 1 day, 10:31:39  time: 0.4355  data_time: 0.0096  memory: 5161  grad_norm: 54.0381  loss: 5.5802  decode.loss_cls: 0.0940  decode.loss_mask: 0.2119  decode.loss_dice: 0.1749  decode.d0.loss_cls: 0.8393  decode.d0.loss_mask: 0.2242  decode.d0.loss_dice: 0.1995  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.1769  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.2150  decode.d2.loss_dice: 0.1775  decode.d3.loss_cls: 0.0750  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.1801  decode.d4.loss_cls: 0.0854  decode.d4.loss_mask: 0.2163  decode.d4.loss_dice: 0.1807  decode.d5.loss_cls: 0.0916  decode.d5.loss_mask: 0.2172  decode.d5.loss_dice: 0.1824  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.2147  decode.d6.loss_dice: 0.1999  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.1911  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.2161  decode.d8.loss_dice: 0.1801
09/30 13:02:51 - mmengine - INFO - Iter(train) [ 33200/320000]  base_lr: 9.0612e-05 lr: 9.0612e-06  eta: 1 day, 10:31:18  time: 0.4346  data_time: 0.0094  memory: 5147  grad_norm: 230.9159  loss: 11.9041  decode.loss_cls: 0.3930  decode.loss_mask: 0.3021  decode.loss_dice: 0.3471  decode.d0.loss_cls: 1.1020  decode.d0.loss_mask: 0.3281  decode.d0.loss_dice: 0.3348  decode.d1.loss_cls: 0.5485  decode.d1.loss_mask: 0.3050  decode.d1.loss_dice: 0.3371  decode.d2.loss_cls: 0.4631  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.3363  decode.d3.loss_cls: 0.3871  decode.d3.loss_mask: 0.3318  decode.d3.loss_dice: 0.3421  decode.d4.loss_cls: 0.4680  decode.d4.loss_mask: 0.3150  decode.d4.loss_dice: 0.3496  decode.d5.loss_cls: 0.4144  decode.d5.loss_mask: 0.3824  decode.d5.loss_dice: 0.3554  decode.d6.loss_cls: 0.4698  decode.d6.loss_mask: 0.3390  decode.d6.loss_dice: 0.3673  decode.d7.loss_cls: 0.4088  decode.d7.loss_mask: 0.3496  decode.d7.loss_dice: 0.3419  decode.d8.loss_cls: 0.3676  decode.d8.loss_mask: 0.4689  decode.d8.loss_dice: 0.3277
09/30 13:03:13 - mmengine - INFO - Iter(train) [ 33250/320000]  base_lr: 9.0598e-05 lr: 9.0598e-06  eta: 1 day, 10:30:57  time: 0.4347  data_time: 0.0091  memory: 5161  grad_norm: 49.4100  loss: 6.7628  decode.loss_cls: 0.1096  decode.loss_mask: 0.2217  decode.loss_dice: 0.2554  decode.d0.loss_cls: 0.8599  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.2464  decode.d1.loss_cls: 0.1304  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.1629  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2507  decode.d3.loss_cls: 0.1800  decode.d3.loss_mask: 0.2224  decode.d3.loss_dice: 0.2654  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 0.2222  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2505  decode.d6.loss_cls: 0.1195  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.2584  decode.d7.loss_cls: 0.1185  decode.d7.loss_mask: 0.2210  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.0915  decode.d8.loss_mask: 0.2209  decode.d8.loss_dice: 0.2624
09/30 13:03:34 - mmengine - INFO - Iter(train) [ 33300/320000]  base_lr: 9.0584e-05 lr: 9.0584e-06  eta: 1 day, 10:30:35  time: 0.4344  data_time: 0.0089  memory: 5147  grad_norm: 31.2630  loss: 5.8002  decode.loss_cls: 0.0465  decode.loss_mask: 0.2183  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.8014  decode.d0.loss_mask: 0.2228  decode.d0.loss_dice: 0.2408  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.2196  decode.d1.loss_dice: 0.2368  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.2170  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.2198  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.2192  decode.d5.loss_dice: 0.2342  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2171  decode.d6.loss_dice: 0.2251  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.2200  decode.d7.loss_dice: 0.2306  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.2183  decode.d8.loss_dice: 0.2314
09/30 13:03:56 - mmengine - INFO - Iter(train) [ 33350/320000]  base_lr: 9.0570e-05 lr: 9.0570e-06  eta: 1 day, 10:30:14  time: 0.4358  data_time: 0.0095  memory: 5147  grad_norm: 53.0658  loss: 6.8475  decode.loss_cls: 0.1768  decode.loss_mask: 0.2428  decode.loss_dice: 0.2075  decode.d0.loss_cls: 1.0574  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.2088  decode.d1.loss_cls: 0.2025  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.1968  decode.d2.loss_cls: 0.1630  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.1909  decode.d3.loss_cls: 0.1239  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2007  decode.d4.loss_cls: 0.1318  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.1906  decode.d5.loss_cls: 0.1277  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 0.2460  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.1540  decode.d7.loss_mask: 0.2461  decode.d7.loss_dice: 0.2095  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.2416  decode.d8.loss_dice: 0.2068
09/30 13:04:18 - mmengine - INFO - Iter(train) [ 33400/320000]  base_lr: 9.0555e-05 lr: 9.0555e-06  eta: 1 day, 10:29:53  time: 0.4345  data_time: 0.0091  memory: 5161  grad_norm: 38.4688  loss: 6.4002  decode.loss_cls: 0.0433  decode.loss_mask: 0.2479  decode.loss_dice: 0.2151  decode.d0.loss_cls: 0.9064  decode.d0.loss_mask: 0.2499  decode.d0.loss_dice: 0.2280  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2341  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2223  decode.d3.loss_cls: 0.1323  decode.d3.loss_mask: 0.2479  decode.d3.loss_dice: 0.2191  decode.d4.loss_cls: 0.0955  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.2325  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.2500  decode.d5.loss_dice: 0.2327  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.2524  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.2496  decode.d7.loss_dice: 0.2108  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2212
09/30 13:04:40 - mmengine - INFO - Iter(train) [ 33450/320000]  base_lr: 9.0541e-05 lr: 9.0541e-06  eta: 1 day, 10:29:32  time: 0.4342  data_time: 0.0093  memory: 5145  grad_norm: 110.7212  loss: 6.8335  decode.loss_cls: 0.1471  decode.loss_mask: 0.3083  decode.loss_dice: 0.1711  decode.d0.loss_cls: 0.9071  decode.d0.loss_mask: 0.3204  decode.d0.loss_dice: 0.1877  decode.d1.loss_cls: 0.1164  decode.d1.loss_mask: 0.3120  decode.d1.loss_dice: 0.1708  decode.d2.loss_cls: 0.1001  decode.d2.loss_mask: 0.3066  decode.d2.loss_dice: 0.1710  decode.d3.loss_cls: 0.0964  decode.d3.loss_mask: 0.3021  decode.d3.loss_dice: 0.1800  decode.d4.loss_cls: 0.1546  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.1033  decode.d5.loss_mask: 0.3049  decode.d5.loss_dice: 0.1711  decode.d6.loss_cls: 0.1288  decode.d6.loss_mask: 0.3026  decode.d6.loss_dice: 0.1767  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.3027  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.3026  decode.d8.loss_dice: 0.1761
09/30 13:05:01 - mmengine - INFO - Iter(train) [ 33500/320000]  base_lr: 9.0527e-05 lr: 9.0527e-06  eta: 1 day, 10:29:11  time: 0.4349  data_time: 0.0094  memory: 5146  grad_norm: 95.0577  loss: 5.9974  decode.loss_cls: 0.1290  decode.loss_mask: 0.1938  decode.loss_dice: 0.1854  decode.d0.loss_cls: 1.0024  decode.d0.loss_mask: 0.2010  decode.d0.loss_dice: 0.1952  decode.d1.loss_cls: 0.2338  decode.d1.loss_mask: 0.1964  decode.d1.loss_dice: 0.1806  decode.d2.loss_cls: 0.1198  decode.d2.loss_mask: 0.1964  decode.d2.loss_dice: 0.1837  decode.d3.loss_cls: 0.1421  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.1803  decode.d4.loss_cls: 0.1026  decode.d4.loss_mask: 0.1954  decode.d4.loss_dice: 0.1833  decode.d5.loss_cls: 0.1155  decode.d5.loss_mask: 0.1963  decode.d5.loss_dice: 0.1902  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.1975  decode.d6.loss_dice: 0.1913  decode.d7.loss_cls: 0.1099  decode.d7.loss_mask: 0.1959  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.1100  decode.d8.loss_mask: 0.1944  decode.d8.loss_dice: 0.1811
09/30 13:05:23 - mmengine - INFO - Iter(train) [ 33550/320000]  base_lr: 9.0513e-05 lr: 9.0513e-06  eta: 1 day, 10:28:50  time: 0.4348  data_time: 0.0093  memory: 5145  grad_norm: 49.4096  loss: 8.9759  decode.loss_cls: 0.2336  decode.loss_mask: 0.2747  decode.loss_dice: 0.2842  decode.d0.loss_cls: 1.1546  decode.d0.loss_mask: 0.2903  decode.d0.loss_dice: 0.3051  decode.d1.loss_cls: 0.3011  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2835  decode.d2.loss_cls: 0.2066  decode.d2.loss_mask: 0.2823  decode.d2.loss_dice: 0.2599  decode.d3.loss_cls: 0.2605  decode.d3.loss_mask: 0.2822  decode.d3.loss_dice: 0.2885  decode.d4.loss_cls: 0.2555  decode.d4.loss_mask: 0.2780  decode.d4.loss_dice: 0.2674  decode.d5.loss_cls: 0.2266  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.2811  decode.d6.loss_cls: 0.2364  decode.d6.loss_mask: 0.2806  decode.d6.loss_dice: 0.2978  decode.d7.loss_cls: 0.2421  decode.d7.loss_mask: 0.2738  decode.d7.loss_dice: 0.2869  decode.d8.loss_cls: 0.2271  decode.d8.loss_mask: 0.2767  decode.d8.loss_dice: 0.2764
09/30 13:05:45 - mmengine - INFO - Iter(train) [ 33600/320000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 1 day, 10:28:30  time: 0.4356  data_time: 0.0097  memory: 5160  grad_norm: 30.4297  loss: 5.5667  decode.loss_cls: 0.0529  decode.loss_mask: 0.2028  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.9395  decode.d0.loss_mask: 0.2033  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.0894  decode.d1.loss_mask: 0.2059  decode.d1.loss_dice: 0.1929  decode.d2.loss_cls: 0.0631  decode.d2.loss_mask: 0.2035  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.0931  decode.d3.loss_mask: 0.2057  decode.d3.loss_dice: 0.2137  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.1909  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.2038  decode.d5.loss_dice: 0.1955  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.2035  decode.d7.loss_dice: 0.1863  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2006
09/30 13:06:07 - mmengine - INFO - Iter(train) [ 33650/320000]  base_lr: 9.0484e-05 lr: 9.0484e-06  eta: 1 day, 10:28:09  time: 0.4351  data_time: 0.0095  memory: 5180  grad_norm: 46.4627  loss: 5.9150  decode.loss_cls: 0.1050  decode.loss_mask: 0.2354  decode.loss_dice: 0.1835  decode.d0.loss_cls: 0.8343  decode.d0.loss_mask: 0.2140  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 0.2099  decode.d1.loss_dice: 0.1720  decode.d2.loss_cls: 0.0966  decode.d2.loss_mask: 0.2081  decode.d2.loss_dice: 0.1702  decode.d3.loss_cls: 0.1065  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.1755  decode.d4.loss_cls: 0.1120  decode.d4.loss_mask: 0.2076  decode.d4.loss_dice: 0.1728  decode.d5.loss_cls: 0.1766  decode.d5.loss_mask: 0.2030  decode.d5.loss_dice: 0.1730  decode.d6.loss_cls: 0.1561  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.1741  decode.d7.loss_cls: 0.1904  decode.d7.loss_mask: 0.2068  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.1135  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.1852
09/30 13:06:28 - mmengine - INFO - Iter(train) [ 33700/320000]  base_lr: 9.0470e-05 lr: 9.0470e-06  eta: 1 day, 10:27:48  time: 0.4349  data_time: 0.0095  memory: 5132  grad_norm: 67.4461  loss: 7.7668  decode.loss_cls: 0.0929  decode.loss_mask: 0.3481  decode.loss_dice: 0.2064  decode.d0.loss_cls: 0.9333  decode.d0.loss_mask: 0.3549  decode.d0.loss_dice: 0.2016  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 0.3469  decode.d1.loss_dice: 0.2011  decode.d2.loss_cls: 0.1797  decode.d2.loss_mask: 0.3448  decode.d2.loss_dice: 0.1970  decode.d3.loss_cls: 0.1733  decode.d3.loss_mask: 0.3518  decode.d3.loss_dice: 0.2107  decode.d4.loss_cls: 0.1950  decode.d4.loss_mask: 0.3438  decode.d4.loss_dice: 0.1999  decode.d5.loss_cls: 0.1883  decode.d5.loss_mask: 0.3474  decode.d5.loss_dice: 0.1965  decode.d6.loss_cls: 0.1775  decode.d6.loss_mask: 0.3487  decode.d6.loss_dice: 0.2069  decode.d7.loss_cls: 0.1253  decode.d7.loss_mask: 0.3461  decode.d7.loss_dice: 0.2065  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 0.3439  decode.d8.loss_dice: 0.2042
09/30 13:06:50 - mmengine - INFO - Iter(train) [ 33750/320000]  base_lr: 9.0456e-05 lr: 9.0456e-06  eta: 1 day, 10:27:27  time: 0.4347  data_time: 0.0093  memory: 5160  grad_norm: 27.4809  loss: 5.7889  decode.loss_cls: 0.0114  decode.loss_mask: 0.2688  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.8862  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.2133  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.2661  decode.d1.loss_dice: 0.2006  decode.d2.loss_cls: 0.0227  decode.d2.loss_mask: 0.2697  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.2694  decode.d3.loss_dice: 0.2008  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.1990  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.1998  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.2018  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.1984  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.2699  decode.d8.loss_dice: 0.1948
09/30 13:07:12 - mmengine - INFO - Iter(train) [ 33800/320000]  base_lr: 9.0442e-05 lr: 9.0442e-06  eta: 1 day, 10:27:06  time: 0.4350  data_time: 0.0094  memory: 5146  grad_norm: 193.3969  loss: 6.6802  decode.loss_cls: 0.0615  decode.loss_mask: 0.2883  decode.loss_dice: 0.2169  decode.d0.loss_cls: 0.7506  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.2346  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.2860  decode.d1.loss_dice: 0.2194  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.2907  decode.d2.loss_dice: 0.2279  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.2891  decode.d3.loss_dice: 0.2162  decode.d4.loss_cls: 0.1121  decode.d4.loss_mask: 0.2916  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.1256  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.2261  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.2937  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.1140  decode.d7.loss_mask: 0.2927  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.2173
09/30 13:07:34 - mmengine - INFO - Iter(train) [ 33850/320000]  base_lr: 9.0428e-05 lr: 9.0428e-06  eta: 1 day, 10:26:45  time: 0.4346  data_time: 0.0095  memory: 5161  grad_norm: 82.7422  loss: 7.3957  decode.loss_cls: 0.1182  decode.loss_mask: 0.2937  decode.loss_dice: 0.2204  decode.d0.loss_cls: 0.9374  decode.d0.loss_mask: 0.2985  decode.d0.loss_dice: 0.2277  decode.d1.loss_cls: 0.1530  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.2421  decode.d2.loss_cls: 0.1326  decode.d2.loss_mask: 0.3110  decode.d2.loss_dice: 0.2367  decode.d3.loss_cls: 0.1637  decode.d3.loss_mask: 0.3051  decode.d3.loss_dice: 0.2456  decode.d4.loss_cls: 0.1385  decode.d4.loss_mask: 0.3049  decode.d4.loss_dice: 0.2334  decode.d5.loss_cls: 0.1298  decode.d5.loss_mask: 0.2955  decode.d5.loss_dice: 0.2296  decode.d6.loss_cls: 0.0819  decode.d6.loss_mask: 0.3030  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.3104  decode.d7.loss_dice: 0.2218  decode.d8.loss_cls: 0.1158  decode.d8.loss_mask: 0.2932  decode.d8.loss_dice: 0.2376
09/30 13:07:55 - mmengine - INFO - Iter(train) [ 33900/320000]  base_lr: 9.0413e-05 lr: 9.0413e-06  eta: 1 day, 10:26:24  time: 0.4358  data_time: 0.0095  memory: 5146  grad_norm: 25.3482  loss: 5.3142  decode.loss_cls: 0.0054  decode.loss_mask: 0.2734  decode.loss_dice: 0.1875  decode.d0.loss_cls: 0.6437  decode.d0.loss_mask: 0.2765  decode.d0.loss_dice: 0.1889  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.2737  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.2725  decode.d2.loss_dice: 0.1887  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.2729  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.2716  decode.d4.loss_dice: 0.1858  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.1852  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.1865  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.2754  decode.d7.loss_dice: 0.1847  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2744  decode.d8.loss_dice: 0.1846
09/30 13:08:17 - mmengine - INFO - Iter(train) [ 33950/320000]  base_lr: 9.0399e-05 lr: 9.0399e-06  eta: 1 day, 10:26:04  time: 0.4354  data_time: 0.0092  memory: 5161  grad_norm: 60.7316  loss: 8.0685  decode.loss_cls: 0.2225  decode.loss_mask: 0.2373  decode.loss_dice: 0.2394  decode.d0.loss_cls: 1.0437  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.3301  decode.d1.loss_mask: 0.2407  decode.d1.loss_dice: 0.2476  decode.d2.loss_cls: 0.3008  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.2615  decode.d3.loss_cls: 0.2548  decode.d3.loss_mask: 0.2399  decode.d3.loss_dice: 0.2477  decode.d4.loss_cls: 0.2392  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.2597  decode.d5.loss_mask: 0.2327  decode.d5.loss_dice: 0.2453  decode.d6.loss_cls: 0.2001  decode.d6.loss_mask: 0.2388  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.1809  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.1504  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.2517
09/30 13:08:39 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:08:39 - mmengine - INFO - Iter(train) [ 34000/320000]  base_lr: 9.0385e-05 lr: 9.0385e-06  eta: 1 day, 10:25:43  time: 0.4357  data_time: 0.0093  memory: 5146  grad_norm: 81.6955  loss: 6.0196  decode.loss_cls: 0.0856  decode.loss_mask: 0.2110  decode.loss_dice: 0.2244  decode.d0.loss_cls: 0.8897  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2417  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.2128  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.2235  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.2196  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.1204  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.2129  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.2216  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 0.2129  decode.d6.loss_dice: 0.2244  decode.d7.loss_cls: 0.1014  decode.d7.loss_mask: 0.2101  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.2127  decode.d8.loss_dice: 0.2145
09/30 13:09:01 - mmengine - INFO - Iter(train) [ 34050/320000]  base_lr: 9.0371e-05 lr: 9.0371e-06  eta: 1 day, 10:25:23  time: 0.4374  data_time: 0.0095  memory: 5146  grad_norm: 48.4670  loss: 8.3035  decode.loss_cls: 0.1232  decode.loss_mask: 0.2920  decode.loss_dice: 0.2166  decode.d0.loss_cls: 0.9291  decode.d0.loss_mask: 0.2991  decode.d0.loss_dice: 0.2236  decode.d1.loss_cls: 0.2970  decode.d1.loss_mask: 0.2971  decode.d1.loss_dice: 0.2297  decode.d2.loss_cls: 0.1814  decode.d2.loss_mask: 0.3985  decode.d2.loss_dice: 0.2152  decode.d3.loss_cls: 0.1560  decode.d3.loss_mask: 0.4183  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.1576  decode.d4.loss_mask: 0.4163  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.4238  decode.d5.loss_dice: 0.2304  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.4268  decode.d6.loss_dice: 0.2306  decode.d7.loss_cls: 0.0945  decode.d7.loss_mask: 0.4240  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.0852  decode.d8.loss_mask: 0.4244  decode.d8.loss_dice: 0.2327
09/30 13:09:23 - mmengine - INFO - Iter(train) [ 34100/320000]  base_lr: 9.0356e-05 lr: 9.0356e-06  eta: 1 day, 10:25:02  time: 0.4356  data_time: 0.0095  memory: 5180  grad_norm: 53.2308  loss: 6.7561  decode.loss_cls: 0.0817  decode.loss_mask: 0.2494  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.9956  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2358  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2612  decode.d1.loss_dice: 0.2277  decode.d2.loss_cls: 0.1063  decode.d2.loss_mask: 0.2504  decode.d2.loss_dice: 0.2189  decode.d3.loss_cls: 0.0994  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2170  decode.d5.loss_cls: 0.1724  decode.d5.loss_mask: 0.2441  decode.d5.loss_dice: 0.2055  decode.d6.loss_cls: 0.0968  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.1310  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.2199  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.2401
09/30 13:09:44 - mmengine - INFO - Iter(train) [ 34150/320000]  base_lr: 9.0342e-05 lr: 9.0342e-06  eta: 1 day, 10:24:41  time: 0.4342  data_time: 0.0094  memory: 5146  grad_norm: 230.6157  loss: 7.1606  decode.loss_cls: 0.1548  decode.loss_mask: 0.2361  decode.loss_dice: 0.2535  decode.d0.loss_cls: 0.9384  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.2364  decode.d1.loss_cls: 0.1977  decode.d1.loss_mask: 0.2357  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.1835  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.1186  decode.d3.loss_mask: 0.2373  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.2408  decode.d4.loss_dice: 0.2364  decode.d5.loss_cls: 0.1468  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.1653  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2188  decode.d7.loss_cls: 0.1778  decode.d7.loss_mask: 0.2321  decode.d7.loss_dice: 0.2426  decode.d8.loss_cls: 0.1511  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.2434
09/30 13:10:06 - mmengine - INFO - Iter(train) [ 34200/320000]  base_lr: 9.0328e-05 lr: 9.0328e-06  eta: 1 day, 10:24:20  time: 0.4356  data_time: 0.0094  memory: 5180  grad_norm: 33.8314  loss: 3.9276  decode.loss_cls: 0.0146  decode.loss_mask: 0.1547  decode.loss_dice: 0.1397  decode.d0.loss_cls: 0.7919  decode.d0.loss_mask: 0.1576  decode.d0.loss_dice: 0.1391  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.1584  decode.d1.loss_dice: 0.1445  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.1566  decode.d2.loss_dice: 0.1409  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.1550  decode.d3.loss_dice: 0.1370  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.1563  decode.d4.loss_dice: 0.1402  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.1577  decode.d5.loss_dice: 0.1401  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.1566  decode.d6.loss_dice: 0.1393  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.1554  decode.d7.loss_dice: 0.1386  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.1552  decode.d8.loss_dice: 0.1379
09/30 13:10:28 - mmengine - INFO - Iter(train) [ 34250/320000]  base_lr: 9.0314e-05 lr: 9.0314e-06  eta: 1 day, 10:23:59  time: 0.4350  data_time: 0.0096  memory: 5146  grad_norm: 36.2937  loss: 6.8341  decode.loss_cls: 0.1235  decode.loss_mask: 0.2865  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.9361  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.2050  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.2833  decode.d1.loss_dice: 0.2080  decode.d2.loss_cls: 0.1002  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.1034  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.2056  decode.d4.loss_cls: 0.1140  decode.d4.loss_mask: 0.2787  decode.d4.loss_dice: 0.2098  decode.d5.loss_cls: 0.1303  decode.d5.loss_mask: 0.2840  decode.d5.loss_dice: 0.2127  decode.d6.loss_cls: 0.1480  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.2040  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.2859  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.1139  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.2161
09/30 13:10:50 - mmengine - INFO - Iter(train) [ 34300/320000]  base_lr: 9.0300e-05 lr: 9.0300e-06  eta: 1 day, 10:23:40  time: 0.4345  data_time: 0.0095  memory: 5179  grad_norm: 54.8993  loss: 6.5511  decode.loss_cls: 0.0626  decode.loss_mask: 0.2586  decode.loss_dice: 0.2652  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 0.2609  decode.d0.loss_dice: 0.2734  decode.d1.loss_cls: 0.1096  decode.d1.loss_mask: 0.2602  decode.d1.loss_dice: 0.2681  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 0.2572  decode.d2.loss_dice: 0.2531  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.2606  decode.d3.loss_dice: 0.2537  decode.d4.loss_cls: 0.0530  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2726  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.2744  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.2592  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.0371  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.2601  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.2574  decode.d8.loss_dice: 0.2874
09/30 13:11:12 - mmengine - INFO - Iter(train) [ 34350/320000]  base_lr: 9.0285e-05 lr: 9.0285e-06  eta: 1 day, 10:23:19  time: 0.4344  data_time: 0.0093  memory: 5180  grad_norm: 64.4511  loss: 6.4955  decode.loss_cls: 0.0734  decode.loss_mask: 0.2492  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.9344  decode.d0.loss_mask: 0.2535  decode.d0.loss_dice: 0.2270  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.2557  decode.d1.loss_dice: 0.2048  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.2112  decode.d3.loss_cls: 0.1345  decode.d3.loss_mask: 0.2503  decode.d3.loss_dice: 0.2204  decode.d4.loss_cls: 0.1298  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.2256  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2017  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 0.2504  decode.d6.loss_dice: 0.2160  decode.d7.loss_cls: 0.0881  decode.d7.loss_mask: 0.2473  decode.d7.loss_dice: 0.2030  decode.d8.loss_cls: 0.1109  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2082
09/30 13:11:33 - mmengine - INFO - Iter(train) [ 34400/320000]  base_lr: 9.0271e-05 lr: 9.0271e-06  eta: 1 day, 10:22:58  time: 0.4349  data_time: 0.0094  memory: 5147  grad_norm: 57.7581  loss: 6.3080  decode.loss_cls: 0.1295  decode.loss_mask: 0.2270  decode.loss_dice: 0.1815  decode.d0.loss_cls: 0.7442  decode.d0.loss_mask: 0.2332  decode.d0.loss_dice: 0.2225  decode.d1.loss_cls: 0.1494  decode.d1.loss_mask: 0.2286  decode.d1.loss_dice: 0.2186  decode.d2.loss_cls: 0.1627  decode.d2.loss_mask: 0.2279  decode.d2.loss_dice: 0.1746  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.2241  decode.d3.loss_dice: 0.1968  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 0.2235  decode.d4.loss_dice: 0.1950  decode.d5.loss_cls: 0.1586  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1883  decode.d6.loss_cls: 0.1676  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.1751  decode.d7.loss_cls: 0.1349  decode.d7.loss_mask: 0.2257  decode.d7.loss_dice: 0.1852  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 0.2205  decode.d8.loss_dice: 0.1845
09/30 13:11:55 - mmengine - INFO - Iter(train) [ 34450/320000]  base_lr: 9.0257e-05 lr: 9.0257e-06  eta: 1 day, 10:22:37  time: 0.4352  data_time: 0.0093  memory: 5180  grad_norm: 63.5868  loss: 4.8627  decode.loss_cls: 0.0510  decode.loss_mask: 0.1938  decode.loss_dice: 0.1514  decode.d0.loss_cls: 0.8360  decode.d0.loss_mask: 0.1934  decode.d0.loss_dice: 0.1543  decode.d1.loss_cls: 0.0338  decode.d1.loss_mask: 0.1942  decode.d1.loss_dice: 0.1551  decode.d2.loss_cls: 0.0293  decode.d2.loss_mask: 0.1977  decode.d2.loss_dice: 0.1645  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.1975  decode.d3.loss_dice: 0.1524  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.1584  decode.d5.loss_cls: 0.0681  decode.d5.loss_mask: 0.1981  decode.d5.loss_dice: 0.1522  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.1934  decode.d6.loss_dice: 0.1536  decode.d7.loss_cls: 0.1077  decode.d7.loss_mask: 0.1930  decode.d7.loss_dice: 0.1514  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.1978  decode.d8.loss_dice: 0.1565
09/30 13:12:17 - mmengine - INFO - Iter(train) [ 34500/320000]  base_lr: 9.0243e-05 lr: 9.0243e-06  eta: 1 day, 10:22:16  time: 0.4366  data_time: 0.0096  memory: 5161  grad_norm: 62.5559  loss: 6.8142  decode.loss_cls: 0.2151  decode.loss_mask: 0.2290  decode.loss_dice: 0.2031  decode.d0.loss_cls: 0.7949  decode.d0.loss_mask: 0.2316  decode.d0.loss_dice: 0.2322  decode.d1.loss_cls: 0.1391  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.1229  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.2037  decode.d3.loss_cls: 0.1579  decode.d3.loss_mask: 0.2276  decode.d3.loss_dice: 0.2036  decode.d4.loss_cls: 0.1412  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.1889  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.2039  decode.d6.loss_cls: 0.2168  decode.d6.loss_mask: 0.2294  decode.d6.loss_dice: 0.2018  decode.d7.loss_cls: 0.2238  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.2068  decode.d8.loss_cls: 0.2450  decode.d8.loss_mask: 0.2286  decode.d8.loss_dice: 0.2057
09/30 13:12:39 - mmengine - INFO - Iter(train) [ 34550/320000]  base_lr: 9.0228e-05 lr: 9.0228e-06  eta: 1 day, 10:21:55  time: 0.4350  data_time: 0.0095  memory: 5161  grad_norm: 61.0506  loss: 7.1694  decode.loss_cls: 0.1454  decode.loss_mask: 0.2523  decode.loss_dice: 0.2077  decode.d0.loss_cls: 1.0386  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.2439  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.2537  decode.d1.loss_dice: 0.2137  decode.d2.loss_cls: 0.1515  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.1626  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.2053  decode.d4.loss_cls: 0.1782  decode.d4.loss_mask: 0.2498  decode.d4.loss_dice: 0.2095  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 0.2533  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.1540  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2070  decode.d7.loss_cls: 0.1508  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.1913  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.2265
09/30 13:13:00 - mmengine - INFO - Iter(train) [ 34600/320000]  base_lr: 9.0214e-05 lr: 9.0214e-06  eta: 1 day, 10:21:34  time: 0.4346  data_time: 0.0094  memory: 5147  grad_norm: 53.0985  loss: 5.5117  decode.loss_cls: 0.0972  decode.loss_mask: 0.1840  decode.loss_dice: 0.1659  decode.d0.loss_cls: 0.8886  decode.d0.loss_mask: 0.1891  decode.d0.loss_dice: 0.1662  decode.d1.loss_cls: 0.1581  decode.d1.loss_mask: 0.1852  decode.d1.loss_dice: 0.1655  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.1883  decode.d2.loss_dice: 0.1841  decode.d3.loss_cls: 0.1008  decode.d3.loss_mask: 0.1923  decode.d3.loss_dice: 0.1809  decode.d4.loss_cls: 0.1167  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.1755  decode.d5.loss_cls: 0.1249  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.0963  decode.d6.loss_mask: 0.1953  decode.d6.loss_dice: 0.1789  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.1702  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.1882  decode.d8.loss_dice: 0.1701
09/30 13:13:22 - mmengine - INFO - Iter(train) [ 34650/320000]  base_lr: 9.0200e-05 lr: 9.0200e-06  eta: 1 day, 10:21:13  time: 0.4348  data_time: 0.0093  memory: 5180  grad_norm: 61.1315  loss: 6.9732  decode.loss_cls: 0.2093  decode.loss_mask: 0.2226  decode.loss_dice: 0.2333  decode.d0.loss_cls: 0.8898  decode.d0.loss_mask: 0.2282  decode.d0.loss_dice: 0.2088  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.1729  decode.d2.loss_cls: 0.2031  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.1983  decode.d3.loss_cls: 0.1423  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.2368  decode.d4.loss_cls: 0.2049  decode.d4.loss_mask: 0.2221  decode.d4.loss_dice: 0.1920  decode.d5.loss_cls: 0.1750  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.1960  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.2189  decode.d7.loss_cls: 0.2111  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.2214  decode.d8.loss_cls: 0.1868  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.2069
09/30 13:13:44 - mmengine - INFO - Iter(train) [ 34700/320000]  base_lr: 9.0186e-05 lr: 9.0186e-06  eta: 1 day, 10:20:52  time: 0.4346  data_time: 0.0094  memory: 5146  grad_norm: 82.0128  loss: 6.6353  decode.loss_cls: 0.1752  decode.loss_mask: 0.2309  decode.loss_dice: 0.1854  decode.d0.loss_cls: 0.8242  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.1832  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2319  decode.d2.loss_cls: 0.1690  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.1919  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 0.2301  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.1741  decode.d4.loss_mask: 0.2306  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.1563  decode.d5.loss_mask: 0.2324  decode.d5.loss_dice: 0.2065  decode.d6.loss_cls: 0.1326  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.1308  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2018  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2161
09/30 13:14:06 - mmengine - INFO - Iter(train) [ 34750/320000]  base_lr: 9.0172e-05 lr: 9.0172e-06  eta: 1 day, 10:20:31  time: 0.4347  data_time: 0.0095  memory: 5161  grad_norm: 107.9991  loss: 7.3431  decode.loss_cls: 0.2285  decode.loss_mask: 0.2298  decode.loss_dice: 0.2503  decode.d0.loss_cls: 0.8230  decode.d0.loss_mask: 0.2292  decode.d0.loss_dice: 0.2691  decode.d1.loss_cls: 0.2011  decode.d1.loss_mask: 0.2321  decode.d1.loss_dice: 0.2434  decode.d2.loss_cls: 0.1959  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2355  decode.d3.loss_cls: 0.1711  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.1819  decode.d4.loss_mask: 0.2308  decode.d4.loss_dice: 0.2461  decode.d5.loss_cls: 0.2096  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2430  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.2307  decode.d6.loss_dice: 0.2470  decode.d7.loss_cls: 0.1787  decode.d7.loss_mask: 0.2357  decode.d7.loss_dice: 0.2537  decode.d8.loss_cls: 0.1905  decode.d8.loss_mask: 0.2298  decode.d8.loss_dice: 0.2473
09/30 13:14:28 - mmengine - INFO - Iter(train) [ 34800/320000]  base_lr: 9.0157e-05 lr: 9.0157e-06  eta: 1 day, 10:20:11  time: 0.4350  data_time: 0.0095  memory: 5160  grad_norm: 28.8745  loss: 5.1206  decode.loss_cls: 0.0629  decode.loss_mask: 0.2041  decode.loss_dice: 0.1673  decode.d0.loss_cls: 0.8107  decode.d0.loss_mask: 0.2146  decode.d0.loss_dice: 0.1752  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.1716  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.2071  decode.d2.loss_dice: 0.1708  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.2076  decode.d3.loss_dice: 0.1690  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.2067  decode.d4.loss_dice: 0.1741  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.1712  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 0.2066  decode.d6.loss_dice: 0.1715  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.2038  decode.d7.loss_dice: 0.1659  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.1721
09/30 13:14:49 - mmengine - INFO - Iter(train) [ 34850/320000]  base_lr: 9.0143e-05 lr: 9.0143e-06  eta: 1 day, 10:19:50  time: 0.4354  data_time: 0.0094  memory: 5180  grad_norm: 108.5925  loss: 5.8943  decode.loss_cls: 0.0578  decode.loss_mask: 0.2628  decode.loss_dice: 0.1980  decode.d0.loss_cls: 0.8549  decode.d0.loss_mask: 0.2752  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.2030  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.2649  decode.d2.loss_dice: 0.2001  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2019  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2033  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.2061  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.2641  decode.d6.loss_dice: 0.2088  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.2599  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2030
09/30 13:15:11 - mmengine - INFO - Iter(train) [ 34900/320000]  base_lr: 9.0129e-05 lr: 9.0129e-06  eta: 1 day, 10:19:29  time: 0.4356  data_time: 0.0093  memory: 5161  grad_norm: 17.9124  loss: 5.1373  decode.loss_cls: 0.1025  decode.loss_mask: 0.1533  decode.loss_dice: 0.1801  decode.d0.loss_cls: 0.9274  decode.d0.loss_mask: 0.1523  decode.d0.loss_dice: 0.1643  decode.d1.loss_cls: 0.1394  decode.d1.loss_mask: 0.1519  decode.d1.loss_dice: 0.1588  decode.d2.loss_cls: 0.1200  decode.d2.loss_mask: 0.1511  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.1413  decode.d3.loss_mask: 0.1505  decode.d3.loss_dice: 0.1643  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.1499  decode.d4.loss_dice: 0.1832  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.1518  decode.d5.loss_dice: 0.1941  decode.d6.loss_cls: 0.0769  decode.d6.loss_mask: 0.1494  decode.d6.loss_dice: 0.1547  decode.d7.loss_cls: 0.0711  decode.d7.loss_mask: 0.1497  decode.d7.loss_dice: 0.1661  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 0.1491  decode.d8.loss_dice: 0.1599
09/30 13:15:33 - mmengine - INFO - Iter(train) [ 34950/320000]  base_lr: 9.0115e-05 lr: 9.0115e-06  eta: 1 day, 10:19:08  time: 0.4362  data_time: 0.0094  memory: 5180  grad_norm: 165.5916  loss: 8.1662  decode.loss_cls: 0.1333  decode.loss_mask: 0.3267  decode.loss_dice: 0.2388  decode.d0.loss_cls: 0.9251  decode.d0.loss_mask: 0.3129  decode.d0.loss_dice: 0.2443  decode.d1.loss_cls: 0.1855  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.2727  decode.d2.loss_mask: 0.2972  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.2339  decode.d3.loss_mask: 0.2996  decode.d3.loss_dice: 0.2162  decode.d4.loss_cls: 0.2410  decode.d4.loss_mask: 0.2959  decode.d4.loss_dice: 0.2296  decode.d5.loss_cls: 0.2115  decode.d5.loss_mask: 0.2992  decode.d5.loss_dice: 0.2204  decode.d6.loss_cls: 0.1959  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.2167  decode.d7.loss_cls: 0.2077  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.2258  decode.d8.loss_cls: 0.1767  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.2393
09/30 13:15:55 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:15:55 - mmengine - INFO - Iter(train) [ 35000/320000]  base_lr: 9.0100e-05 lr: 9.0100e-06  eta: 1 day, 10:18:47  time: 0.4355  data_time: 0.0094  memory: 5147  grad_norm: 114.1248  loss: 8.2030  decode.loss_cls: 0.2057  decode.loss_mask: 0.2849  decode.loss_dice: 0.2138  decode.d0.loss_cls: 0.8548  decode.d0.loss_mask: 0.3729  decode.d0.loss_dice: 0.2655  decode.d1.loss_cls: 0.1963  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.2369  decode.d2.loss_cls: 0.1779  decode.d2.loss_mask: 0.2815  decode.d2.loss_dice: 0.2135  decode.d3.loss_cls: 0.2051  decode.d3.loss_mask: 0.2859  decode.d3.loss_dice: 0.2080  decode.d4.loss_cls: 0.2227  decode.d4.loss_mask: 0.2827  decode.d4.loss_dice: 0.2105  decode.d5.loss_cls: 0.2357  decode.d5.loss_mask: 0.3577  decode.d5.loss_dice: 0.2672  decode.d6.loss_cls: 0.2257  decode.d6.loss_mask: 0.3221  decode.d6.loss_dice: 0.2539  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 0.3162  decode.d7.loss_dice: 0.2627  decode.d8.loss_cls: 0.2198  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.2233
09/30 13:16:16 - mmengine - INFO - Iter(train) [ 35050/320000]  base_lr: 9.0086e-05 lr: 9.0086e-06  eta: 1 day, 10:18:27  time: 0.4357  data_time: 0.0095  memory: 5160  grad_norm: 70.4416  loss: 8.8216  decode.loss_cls: 0.1365  decode.loss_mask: 0.2789  decode.loss_dice: 0.3518  decode.d0.loss_cls: 0.9036  decode.d0.loss_mask: 0.2757  decode.d0.loss_dice: 0.3461  decode.d1.loss_cls: 0.3587  decode.d1.loss_mask: 0.2772  decode.d1.loss_dice: 0.3459  decode.d2.loss_cls: 0.1558  decode.d2.loss_mask: 0.2747  decode.d2.loss_dice: 0.3612  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.1801  decode.d4.loss_mask: 0.2851  decode.d4.loss_dice: 0.3672  decode.d5.loss_cls: 0.1528  decode.d5.loss_mask: 0.2771  decode.d5.loss_dice: 0.3282  decode.d6.loss_cls: 0.1632  decode.d6.loss_mask: 0.2749  decode.d6.loss_dice: 0.3597  decode.d7.loss_cls: 0.1785  decode.d7.loss_mask: 0.2800  decode.d7.loss_dice: 0.3690  decode.d8.loss_cls: 0.1658  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.3530
09/30 13:16:38 - mmengine - INFO - Iter(train) [ 35100/320000]  base_lr: 9.0072e-05 lr: 9.0072e-06  eta: 1 day, 10:18:06  time: 0.4357  data_time: 0.0096  memory: 5161  grad_norm: 94.1357  loss: 6.5473  decode.loss_cls: 0.0752  decode.loss_mask: 0.2361  decode.loss_dice: 0.2761  decode.d0.loss_cls: 1.0190  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2240  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.2368  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.2193  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.2371  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2712  decode.d6.loss_cls: 0.1589  decode.d6.loss_mask: 0.2100  decode.d6.loss_dice: 0.2210  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.2713  decode.d8.loss_cls: 0.1350  decode.d8.loss_mask: 0.2102  decode.d8.loss_dice: 0.2222
09/30 13:17:00 - mmengine - INFO - Iter(train) [ 35150/320000]  base_lr: 9.0058e-05 lr: 9.0058e-06  eta: 1 day, 10:17:46  time: 0.4354  data_time: 0.0095  memory: 5160  grad_norm: 38.1020  loss: 6.9519  decode.loss_cls: 0.0548  decode.loss_mask: 0.3544  decode.loss_dice: 0.2279  decode.d0.loss_cls: 0.6783  decode.d0.loss_mask: 0.3625  decode.d0.loss_dice: 0.2313  decode.d1.loss_cls: 0.0820  decode.d1.loss_mask: 0.3524  decode.d1.loss_dice: 0.2181  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.3556  decode.d2.loss_dice: 0.2214  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.3609  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.3525  decode.d4.loss_dice: 0.2224  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.3541  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.3548  decode.d6.loss_dice: 0.2307  decode.d7.loss_cls: 0.0430  decode.d7.loss_mask: 0.3571  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.3560  decode.d8.loss_dice: 0.2141
09/30 13:17:22 - mmengine - INFO - Iter(train) [ 35200/320000]  base_lr: 9.0043e-05 lr: 9.0043e-06  eta: 1 day, 10:17:25  time: 0.4365  data_time: 0.0098  memory: 5147  grad_norm: 86.7020  loss: 6.1403  decode.loss_cls: 0.0689  decode.loss_mask: 0.2141  decode.loss_dice: 0.2177  decode.d0.loss_cls: 0.8682  decode.d0.loss_mask: 0.2478  decode.d0.loss_dice: 0.2435  decode.d1.loss_cls: 0.1194  decode.d1.loss_mask: 0.2183  decode.d1.loss_dice: 0.2306  decode.d2.loss_cls: 0.1167  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.1941  decode.d3.loss_cls: 0.1101  decode.d3.loss_mask: 0.2181  decode.d3.loss_dice: 0.2544  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2600  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.2101  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.2184  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.2175  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.2144  decode.d8.loss_dice: 0.2279
09/30 13:17:44 - mmengine - INFO - Iter(train) [ 35250/320000]  base_lr: 9.0029e-05 lr: 9.0029e-06  eta: 1 day, 10:17:04  time: 0.4354  data_time: 0.0096  memory: 5160  grad_norm: 74.4012  loss: 7.4800  decode.loss_cls: 0.2258  decode.loss_mask: 0.2730  decode.loss_dice: 0.2032  decode.d0.loss_cls: 0.8003  decode.d0.loss_mask: 0.2801  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.1555  decode.d1.loss_mask: 0.2731  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.1561  decode.d2.loss_mask: 0.2730  decode.d2.loss_dice: 0.2064  decode.d3.loss_cls: 0.2017  decode.d3.loss_mask: 0.2732  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.2128  decode.d4.loss_mask: 0.2698  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.2677  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.1899  decode.d6.loss_cls: 0.2346  decode.d6.loss_mask: 0.2741  decode.d6.loss_dice: 0.2025  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.2342  decode.d8.loss_mask: 0.2733  decode.d8.loss_dice: 0.1977
09/30 13:18:05 - mmengine - INFO - Iter(train) [ 35300/320000]  base_lr: 9.0015e-05 lr: 9.0015e-06  eta: 1 day, 10:16:43  time: 0.4361  data_time: 0.0095  memory: 5161  grad_norm: 19.2754  loss: 4.3837  decode.loss_cls: 0.0043  decode.loss_mask: 0.1806  decode.loss_dice: 0.1603  decode.d0.loss_cls: 0.8686  decode.d0.loss_mask: 0.1839  decode.d0.loss_dice: 0.1755  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.1794  decode.d1.loss_dice: 0.1666  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.1816  decode.d2.loss_dice: 0.1637  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.1827  decode.d3.loss_dice: 0.1638  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.1643  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.1817  decode.d5.loss_dice: 0.1650  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1829  decode.d6.loss_dice: 0.1681  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.1807  decode.d7.loss_dice: 0.1681  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.1802  decode.d8.loss_dice: 0.1655
09/30 13:18:27 - mmengine - INFO - Iter(train) [ 35350/320000]  base_lr: 9.0001e-05 lr: 9.0001e-06  eta: 1 day, 10:16:23  time: 0.4362  data_time: 0.0096  memory: 5161  grad_norm: 45.4877  loss: 7.0447  decode.loss_cls: 0.0794  decode.loss_mask: 0.2424  decode.loss_dice: 0.2554  decode.d0.loss_cls: 1.1019  decode.d0.loss_mask: 0.2453  decode.d0.loss_dice: 0.2404  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.2427  decode.d1.loss_dice: 0.2319  decode.d2.loss_cls: 0.1257  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2392  decode.d3.loss_cls: 0.1204  decode.d3.loss_mask: 0.2401  decode.d3.loss_dice: 0.2324  decode.d4.loss_cls: 0.1709  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.2497  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.2478  decode.d5.loss_dice: 0.2430  decode.d6.loss_cls: 0.1208  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2416  decode.d7.loss_cls: 0.1264  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.2494  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2227
09/30 13:18:49 - mmengine - INFO - Iter(train) [ 35400/320000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 1 day, 10:16:02  time: 0.4362  data_time: 0.0095  memory: 5147  grad_norm: 47.7583  loss: 6.5104  decode.loss_cls: 0.1128  decode.loss_mask: 0.2490  decode.loss_dice: 0.2169  decode.d0.loss_cls: 0.7838  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2328  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.2263  decode.d2.loss_cls: 0.1125  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2261  decode.d3.loss_cls: 0.1189  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.1999  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.1438  decode.d5.loss_mask: 0.2513  decode.d5.loss_dice: 0.2095  decode.d6.loss_cls: 0.1209  decode.d6.loss_mask: 0.2538  decode.d6.loss_dice: 0.2060  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2106  decode.d8.loss_cls: 0.1463  decode.d8.loss_mask: 0.2514  decode.d8.loss_dice: 0.2005
09/30 13:19:11 - mmengine - INFO - Iter(train) [ 35450/320000]  base_lr: 8.9972e-05 lr: 8.9972e-06  eta: 1 day, 10:15:41  time: 0.4355  data_time: 0.0093  memory: 5161  grad_norm: 30.7059  loss: 6.4713  decode.loss_cls: 0.0934  decode.loss_mask: 0.2457  decode.loss_dice: 0.2059  decode.d0.loss_cls: 0.9123  decode.d0.loss_mask: 0.2460  decode.d0.loss_dice: 0.2120  decode.d1.loss_cls: 0.1499  decode.d1.loss_mask: 0.2431  decode.d1.loss_dice: 0.2009  decode.d2.loss_cls: 0.1118  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.2065  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.2421  decode.d3.loss_dice: 0.2111  decode.d4.loss_cls: 0.1722  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.1062  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2081  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.2110  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.2436  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.1081  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2113
09/30 13:19:33 - mmengine - INFO - Iter(train) [ 35500/320000]  base_lr: 8.9958e-05 lr: 8.9958e-06  eta: 1 day, 10:15:21  time: 0.4367  data_time: 0.0091  memory: 5160  grad_norm: 101.9951  loss: 11.0640  decode.loss_cls: 0.2291  decode.loss_mask: 0.3841  decode.loss_dice: 0.3769  decode.d0.loss_cls: 1.1307  decode.d0.loss_mask: 0.3037  decode.d0.loss_dice: 0.3934  decode.d1.loss_cls: 0.4322  decode.d1.loss_mask: 0.3250  decode.d1.loss_dice: 0.3585  decode.d2.loss_cls: 0.3083  decode.d2.loss_mask: 0.3212  decode.d2.loss_dice: 0.3567  decode.d3.loss_cls: 0.3139  decode.d3.loss_mask: 0.3348  decode.d3.loss_dice: 0.3261  decode.d4.loss_cls: 0.3498  decode.d4.loss_mask: 0.3230  decode.d4.loss_dice: 0.3783  decode.d5.loss_cls: 0.2168  decode.d5.loss_mask: 0.3357  decode.d5.loss_dice: 0.3427  decode.d6.loss_cls: 0.3350  decode.d6.loss_mask: 0.3409  decode.d6.loss_dice: 0.3463  decode.d7.loss_cls: 0.3220  decode.d7.loss_mask: 0.3481  decode.d7.loss_dice: 0.3681  decode.d8.loss_cls: 0.3284  decode.d8.loss_mask: 0.4730  decode.d8.loss_dice: 0.3614
09/30 13:19:54 - mmengine - INFO - Iter(train) [ 35550/320000]  base_lr: 8.9944e-05 lr: 8.9944e-06  eta: 1 day, 10:15:00  time: 0.4350  data_time: 0.0093  memory: 5160  grad_norm: 58.6047  loss: 7.4982  decode.loss_cls: 0.0742  decode.loss_mask: 0.3268  decode.loss_dice: 0.2462  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 0.3315  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.1086  decode.d1.loss_mask: 0.3271  decode.d1.loss_dice: 0.2508  decode.d2.loss_cls: 0.1091  decode.d2.loss_mask: 0.3197  decode.d2.loss_dice: 0.2450  decode.d3.loss_cls: 0.0847  decode.d3.loss_mask: 0.3262  decode.d3.loss_dice: 0.2503  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.3325  decode.d4.loss_dice: 0.2499  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 0.3272  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.3231  decode.d6.loss_dice: 0.2601  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.3342  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.3286  decode.d8.loss_dice: 0.2810
09/30 13:20:16 - mmengine - INFO - Iter(train) [ 35600/320000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 1 day, 10:14:38  time: 0.4345  data_time: 0.0090  memory: 5179  grad_norm: 49.4918  loss: 4.5812  decode.loss_cls: 0.0437  decode.loss_mask: 0.1785  decode.loss_dice: 0.1481  decode.d0.loss_cls: 0.8036  decode.d0.loss_mask: 0.1758  decode.d0.loss_dice: 0.1528  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.1758  decode.d1.loss_dice: 0.1508  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.1767  decode.d2.loss_dice: 0.1513  decode.d3.loss_cls: 0.0318  decode.d3.loss_mask: 0.1777  decode.d3.loss_dice: 0.1533  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.1775  decode.d4.loss_dice: 0.1517  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.1766  decode.d5.loss_dice: 0.1470  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.1780  decode.d6.loss_dice: 0.1458  decode.d7.loss_cls: 0.0774  decode.d7.loss_mask: 0.1770  decode.d7.loss_dice: 0.1475  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 0.1765  decode.d8.loss_dice: 0.1490
09/30 13:20:38 - mmengine - INFO - Iter(train) [ 35650/320000]  base_lr: 8.9915e-05 lr: 8.9915e-06  eta: 1 day, 10:14:17  time: 0.4350  data_time: 0.0093  memory: 5180  grad_norm: 28.2795  loss: 5.3733  decode.loss_cls: 0.0087  decode.loss_mask: 0.2469  decode.loss_dice: 0.2013  decode.d0.loss_cls: 0.7994  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2054  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.2024  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.1960  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.2469  decode.d3.loss_dice: 0.1949  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.2442  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2486  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.2475  decode.d6.loss_dice: 0.1954  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.2009  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.2490  decode.d8.loss_dice: 0.2006
09/30 13:21:00 - mmengine - INFO - Iter(train) [ 35700/320000]  base_lr: 8.9901e-05 lr: 8.9901e-06  eta: 1 day, 10:13:57  time: 0.4357  data_time: 0.0093  memory: 5161  grad_norm: 68.2942  loss: 8.1656  decode.loss_cls: 0.1667  decode.loss_mask: 0.2870  decode.loss_dice: 0.2470  decode.d0.loss_cls: 0.9535  decode.d0.loss_mask: 0.2879  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.2429  decode.d1.loss_mask: 0.2928  decode.d1.loss_dice: 0.2419  decode.d2.loss_cls: 0.2137  decode.d2.loss_mask: 0.2925  decode.d2.loss_dice: 0.2453  decode.d3.loss_cls: 0.2015  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.2600  decode.d4.loss_cls: 0.1808  decode.d4.loss_mask: 0.3031  decode.d4.loss_dice: 0.2775  decode.d5.loss_cls: 0.1791  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.2960  decode.d6.loss_cls: 0.1783  decode.d6.loss_mask: 0.2951  decode.d6.loss_dice: 0.2636  decode.d7.loss_cls: 0.1519  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.2692  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.2225
09/30 13:21:21 - mmengine - INFO - Iter(train) [ 35750/320000]  base_lr: 8.9887e-05 lr: 8.9887e-06  eta: 1 day, 10:13:35  time: 0.4344  data_time: 0.0091  memory: 5160  grad_norm: 59.7302  loss: 6.7744  decode.loss_cls: 0.1069  decode.loss_mask: 0.2779  decode.loss_dice: 0.2095  decode.d0.loss_cls: 0.9621  decode.d0.loss_mask: 0.2934  decode.d0.loss_dice: 0.2297  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.2391  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.0722  decode.d3.loss_mask: 0.2836  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 0.2827  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.0900  decode.d5.loss_mask: 0.2815  decode.d5.loss_dice: 0.2195  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.2778  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.2791  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.2826  decode.d8.loss_dice: 0.2145
09/30 13:21:43 - mmengine - INFO - Iter(train) [ 35800/320000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 1 day, 10:13:14  time: 0.4348  data_time: 0.0090  memory: 5160  grad_norm: 28.4859  loss: 5.6602  decode.loss_cls: 0.0861  decode.loss_mask: 0.1965  decode.loss_dice: 0.1801  decode.d0.loss_cls: 0.8027  decode.d0.loss_mask: 0.1995  decode.d0.loss_dice: 0.1818  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.1937  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.1285  decode.d2.loss_mask: 0.1960  decode.d2.loss_dice: 0.1879  decode.d3.loss_cls: 0.1237  decode.d3.loss_mask: 0.1953  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.1117  decode.d4.loss_mask: 0.1967  decode.d4.loss_dice: 0.1940  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.1943  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.1332  decode.d6.loss_mask: 0.1972  decode.d6.loss_dice: 0.1812  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 0.1928  decode.d7.loss_dice: 0.1905  decode.d8.loss_cls: 0.1446  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.1848
09/30 13:22:05 - mmengine - INFO - Iter(train) [ 35850/320000]  base_lr: 8.9858e-05 lr: 8.9858e-06  eta: 1 day, 10:12:53  time: 0.4360  data_time: 0.0094  memory: 5161  grad_norm: 54.5404  loss: 6.8900  decode.loss_cls: 0.1195  decode.loss_mask: 0.2233  decode.loss_dice: 0.2207  decode.d0.loss_cls: 0.9613  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.2387  decode.d1.loss_cls: 0.2005  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2217  decode.d2.loss_cls: 0.1656  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.1488  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.2344  decode.d4.loss_cls: 0.1731  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.2415  decode.d5.loss_cls: 0.1616  decode.d5.loss_mask: 0.2227  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.1631  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.1633  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.0986  decode.d8.loss_mask: 0.2223  decode.d8.loss_dice: 0.2365
09/30 13:22:27 - mmengine - INFO - Iter(train) [ 35900/320000]  base_lr: 8.9844e-05 lr: 8.9844e-06  eta: 1 day, 10:12:32  time: 0.4342  data_time: 0.0096  memory: 5161  grad_norm: 99.7731  loss: 6.7481  decode.loss_cls: 0.0301  decode.loss_mask: 0.3176  decode.loss_dice: 0.2165  decode.d0.loss_cls: 0.9322  decode.d0.loss_mask: 0.3298  decode.d0.loss_dice: 0.2205  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.3368  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.3241  decode.d2.loss_dice: 0.2210  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.3250  decode.d3.loss_dice: 0.2197  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.3246  decode.d4.loss_dice: 0.2255  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.3188  decode.d6.loss_dice: 0.2226  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.3213  decode.d7.loss_dice: 0.2179  decode.d8.loss_cls: 0.0287  decode.d8.loss_mask: 0.3194  decode.d8.loss_dice: 0.2167
09/30 13:22:49 - mmengine - INFO - Iter(train) [ 35950/320000]  base_lr: 8.9830e-05 lr: 8.9830e-06  eta: 1 day, 10:12:13  time: 0.4354  data_time: 0.0092  memory: 5161  grad_norm: 93.5843  loss: 9.8200  decode.loss_cls: 0.3084  decode.loss_mask: 0.3190  decode.loss_dice: 0.3182  decode.d0.loss_cls: 0.9374  decode.d0.loss_mask: 0.3433  decode.d0.loss_dice: 0.3034  decode.d1.loss_cls: 0.2710  decode.d1.loss_mask: 0.3200  decode.d1.loss_dice: 0.2846  decode.d2.loss_cls: 0.2765  decode.d2.loss_mask: 0.3257  decode.d2.loss_dice: 0.2783  decode.d3.loss_cls: 0.3140  decode.d3.loss_mask: 0.3231  decode.d3.loss_dice: 0.2833  decode.d4.loss_cls: 0.2751  decode.d4.loss_mask: 0.3189  decode.d4.loss_dice: 0.3023  decode.d5.loss_cls: 0.3184  decode.d5.loss_mask: 0.3260  decode.d5.loss_dice: 0.2929  decode.d6.loss_cls: 0.2850  decode.d6.loss_mask: 0.3435  decode.d6.loss_dice: 0.3077  decode.d7.loss_cls: 0.2887  decode.d7.loss_mask: 0.3194  decode.d7.loss_dice: 0.2908  decode.d8.loss_cls: 0.3318  decode.d8.loss_mask: 0.3101  decode.d8.loss_dice: 0.3032
09/30 13:23:10 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:23:10 - mmengine - INFO - Iter(train) [ 36000/320000]  base_lr: 8.9816e-05 lr: 8.9816e-06  eta: 1 day, 10:11:51  time: 0.4349  data_time: 0.0094  memory: 5161  grad_norm: 39.2115  loss: 6.4937  decode.loss_cls: 0.0130  decode.loss_mask: 0.3000  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.8516  decode.d0.loss_mask: 0.2927  decode.d0.loss_dice: 0.2299  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.2950  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.2964  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.0250  decode.d3.loss_mask: 0.2976  decode.d3.loss_dice: 0.2290  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.2978  decode.d4.loss_dice: 0.2373  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.2975  decode.d5.loss_dice: 0.2389  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.2302  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.2352  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.2365
09/30 13:23:32 - mmengine - INFO - Iter(train) [ 36050/320000]  base_lr: 8.9802e-05 lr: 8.9802e-06  eta: 1 day, 10:11:30  time: 0.4334  data_time: 0.0093  memory: 5147  grad_norm: 289.7644  loss: 6.8639  decode.loss_cls: 0.0889  decode.loss_mask: 0.3798  decode.loss_dice: 0.2434  decode.d0.loss_cls: 0.9927  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2396  decode.d1.loss_cls: 0.2499  decode.d1.loss_mask: 0.2266  decode.d1.loss_dice: 0.2101  decode.d2.loss_cls: 0.1478  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.2171  decode.d3.loss_cls: 0.0943  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.2409  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.2274  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2439  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.2295  decode.d7.loss_cls: 0.1217  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2280  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.2507  decode.d8.loss_dice: 0.2686
09/30 13:23:54 - mmengine - INFO - Iter(train) [ 36100/320000]  base_lr: 8.9787e-05 lr: 8.9787e-06  eta: 1 day, 10:11:09  time: 0.4345  data_time: 0.0092  memory: 5180  grad_norm: 26.8722  loss: 5.1947  decode.loss_cls: 0.0082  decode.loss_mask: 0.2183  decode.loss_dice: 0.1667  decode.d0.loss_cls: 0.8844  decode.d0.loss_mask: 0.2126  decode.d0.loss_dice: 0.1828  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.2230  decode.d1.loss_dice: 0.1685  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.2158  decode.d2.loss_dice: 0.1675  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.1685  decode.d5.loss_cls: 0.0553  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.1750  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.2175  decode.d6.loss_dice: 0.1736  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.2212  decode.d7.loss_dice: 0.1704  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.1718
09/30 13:24:16 - mmengine - INFO - Iter(train) [ 36150/320000]  base_lr: 8.9773e-05 lr: 8.9773e-06  eta: 1 day, 10:10:48  time: 0.4343  data_time: 0.0091  memory: 5160  grad_norm: 84.2300  loss: 8.8782  decode.loss_cls: 0.1911  decode.loss_mask: 0.2944  decode.loss_dice: 0.2500  decode.d0.loss_cls: 0.9380  decode.d0.loss_mask: 0.2590  decode.d0.loss_dice: 0.2383  decode.d1.loss_cls: 0.2507  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.2589  decode.d2.loss_cls: 0.2307  decode.d2.loss_mask: 0.3229  decode.d2.loss_dice: 0.2417  decode.d3.loss_cls: 0.2562  decode.d3.loss_mask: 0.3319  decode.d3.loss_dice: 0.2443  decode.d4.loss_cls: 0.2546  decode.d4.loss_mask: 0.3971  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.4125  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.2380  decode.d6.loss_mask: 0.3385  decode.d6.loss_dice: 0.2329  decode.d7.loss_cls: 0.2524  decode.d7.loss_mask: 0.3354  decode.d7.loss_dice: 0.2559  decode.d8.loss_cls: 0.2538  decode.d8.loss_mask: 0.3532  decode.d8.loss_dice: 0.2438
09/30 13:24:37 - mmengine - INFO - Iter(train) [ 36200/320000]  base_lr: 8.9759e-05 lr: 8.9759e-06  eta: 1 day, 10:10:27  time: 0.4351  data_time: 0.0093  memory: 5180  grad_norm: 51.7293  loss: 7.3442  decode.loss_cls: 0.2033  decode.loss_mask: 0.2562  decode.loss_dice: 0.2728  decode.d0.loss_cls: 0.7964  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.2552  decode.d1.loss_cls: 0.1373  decode.d1.loss_mask: 0.2574  decode.d1.loss_dice: 0.2804  decode.d2.loss_cls: 0.1693  decode.d2.loss_mask: 0.2604  decode.d2.loss_dice: 0.2315  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.2503  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.2538  decode.d6.loss_cls: 0.1815  decode.d6.loss_mask: 0.2568  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 0.2594  decode.d7.loss_dice: 0.2691  decode.d8.loss_cls: 0.1577  decode.d8.loss_mask: 0.2594  decode.d8.loss_dice: 0.2621
09/30 13:24:59 - mmengine - INFO - Iter(train) [ 36250/320000]  base_lr: 8.9745e-05 lr: 8.9745e-06  eta: 1 day, 10:10:05  time: 0.4345  data_time: 0.0092  memory: 5180  grad_norm: 71.2429  loss: 6.1520  decode.loss_cls: 0.1328  decode.loss_mask: 0.2030  decode.loss_dice: 0.1986  decode.d0.loss_cls: 0.8194  decode.d0.loss_mask: 0.2269  decode.d0.loss_dice: 0.2148  decode.d1.loss_cls: 0.1800  decode.d1.loss_mask: 0.2035  decode.d1.loss_dice: 0.1886  decode.d2.loss_cls: 0.1427  decode.d2.loss_mask: 0.2072  decode.d2.loss_dice: 0.2156  decode.d3.loss_cls: 0.1391  decode.d3.loss_mask: 0.2010  decode.d3.loss_dice: 0.2082  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.2024  decode.d4.loss_dice: 0.2070  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.2124  decode.d6.loss_cls: 0.1010  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.2362  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.2050  decode.d8.loss_dice: 0.2133
09/30 13:25:21 - mmengine - INFO - Iter(train) [ 36300/320000]  base_lr: 8.9730e-05 lr: 8.9730e-06  eta: 1 day, 10:09:44  time: 0.4352  data_time: 0.0091  memory: 5161  grad_norm: 74.5145  loss: 7.2842  decode.loss_cls: 0.1008  decode.loss_mask: 0.2920  decode.loss_dice: 0.2424  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 0.2955  decode.d0.loss_dice: 0.2707  decode.d1.loss_cls: 0.1362  decode.d1.loss_mask: 0.2941  decode.d1.loss_dice: 0.2423  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.2351  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.2926  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.1259  decode.d4.loss_mask: 0.2941  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.1336  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.2364  decode.d6.loss_cls: 0.1263  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.2395  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 0.2922  decode.d7.loss_dice: 0.2417  decode.d8.loss_cls: 0.1138  decode.d8.loss_mask: 0.2917  decode.d8.loss_dice: 0.2340
09/30 13:25:43 - mmengine - INFO - Iter(train) [ 36350/320000]  base_lr: 8.9716e-05 lr: 8.9716e-06  eta: 1 day, 10:09:23  time: 0.4350  data_time: 0.0094  memory: 5180  grad_norm: 80.8673  loss: 5.8408  decode.loss_cls: 0.0452  decode.loss_mask: 0.2340  decode.loss_dice: 0.1865  decode.d0.loss_cls: 0.9716  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.1928  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 0.2352  decode.d1.loss_dice: 0.1840  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.2383  decode.d2.loss_dice: 0.1880  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.2364  decode.d3.loss_dice: 0.1893  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.2302  decode.d4.loss_dice: 0.1794  decode.d5.loss_cls: 0.1187  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1884  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0455  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.1832
09/30 13:26:04 - mmengine - INFO - Iter(train) [ 36400/320000]  base_lr: 8.9702e-05 lr: 8.9702e-06  eta: 1 day, 10:09:02  time: 0.4340  data_time: 0.0090  memory: 5161  grad_norm: 72.6061  loss: 7.4447  decode.loss_cls: 0.2029  decode.loss_mask: 0.2576  decode.loss_dice: 0.1951  decode.d0.loss_cls: 0.8858  decode.d0.loss_mask: 0.2701  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.1713  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.2084  decode.d2.loss_cls: 0.2054  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.2134  decode.d3.loss_cls: 0.1996  decode.d3.loss_mask: 0.2649  decode.d3.loss_dice: 0.2086  decode.d4.loss_cls: 0.1741  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2082  decode.d5.loss_cls: 0.2067  decode.d5.loss_mask: 0.2590  decode.d5.loss_dice: 0.2381  decode.d6.loss_cls: 0.2571  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.1997  decode.d7.loss_cls: 0.1559  decode.d7.loss_mask: 0.2602  decode.d7.loss_dice: 0.2274  decode.d8.loss_cls: 0.1970  decode.d8.loss_mask: 0.2587  decode.d8.loss_dice: 0.1956
09/30 13:26:26 - mmengine - INFO - Iter(train) [ 36450/320000]  base_lr: 8.9688e-05 lr: 8.9688e-06  eta: 1 day, 10:08:41  time: 0.4352  data_time: 0.0094  memory: 5145  grad_norm: 112.6302  loss: 7.3567  decode.loss_cls: 0.2627  decode.loss_mask: 0.2524  decode.loss_dice: 0.1749  decode.d0.loss_cls: 0.8076  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.1879  decode.d1.loss_cls: 0.2155  decode.d1.loss_mask: 0.2560  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.2298  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.1793  decode.d3.loss_cls: 0.2502  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.1732  decode.d4.loss_cls: 0.2047  decode.d4.loss_mask: 0.2526  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.2608  decode.d5.loss_mask: 0.2564  decode.d5.loss_dice: 0.1762  decode.d6.loss_cls: 0.2685  decode.d6.loss_mask: 0.2536  decode.d6.loss_dice: 0.1734  decode.d7.loss_cls: 0.2387  decode.d7.loss_mask: 0.2584  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.2802  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.1793
09/30 13:26:48 - mmengine - INFO - Iter(train) [ 36500/320000]  base_lr: 8.9673e-05 lr: 8.9673e-06  eta: 1 day, 10:08:19  time: 0.4341  data_time: 0.0093  memory: 5160  grad_norm: 62.9867  loss: 6.7326  decode.loss_cls: 0.1203  decode.loss_mask: 0.2818  decode.loss_dice: 0.1969  decode.d0.loss_cls: 1.0411  decode.d0.loss_mask: 0.2793  decode.d0.loss_dice: 0.1967  decode.d1.loss_cls: 0.1111  decode.d1.loss_mask: 0.2806  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.1331  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.1853  decode.d3.loss_cls: 0.0885  decode.d3.loss_mask: 0.2799  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.2807  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.1080  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.1926  decode.d6.loss_cls: 0.0788  decode.d6.loss_mask: 0.2873  decode.d6.loss_dice: 0.2159  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.2841  decode.d7.loss_dice: 0.2025  decode.d8.loss_cls: 0.1122  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.1977
09/30 13:27:10 - mmengine - INFO - Iter(train) [ 36550/320000]  base_lr: 8.9659e-05 lr: 8.9659e-06  eta: 1 day, 10:07:58  time: 0.4348  data_time: 0.0093  memory: 5161  grad_norm: 30.2997  loss: 6.2949  decode.loss_cls: 0.0630  decode.loss_mask: 0.2410  decode.loss_dice: 0.2257  decode.d0.loss_cls: 0.8503  decode.d0.loss_mask: 0.2447  decode.d0.loss_dice: 0.2473  decode.d1.loss_cls: 0.1173  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2271  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.0697  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.2429  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.2138  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.2170  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2235
09/30 13:27:31 - mmengine - INFO - Iter(train) [ 36600/320000]  base_lr: 8.9645e-05 lr: 8.9645e-06  eta: 1 day, 10:07:37  time: 0.4347  data_time: 0.0092  memory: 5180  grad_norm: 68.0872  loss: 6.6596  decode.loss_cls: 0.1607  decode.loss_mask: 0.2100  decode.loss_dice: 0.2142  decode.d0.loss_cls: 0.9530  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.2323  decode.d1.loss_cls: 0.1721  decode.d1.loss_mask: 0.2036  decode.d1.loss_dice: 0.1941  decode.d2.loss_cls: 0.1572  decode.d2.loss_mask: 0.2269  decode.d2.loss_dice: 0.2184  decode.d3.loss_cls: 0.1345  decode.d3.loss_mask: 0.2159  decode.d3.loss_dice: 0.1997  decode.d4.loss_cls: 0.1446  decode.d4.loss_mask: 0.2044  decode.d4.loss_dice: 0.1964  decode.d5.loss_cls: 0.1488  decode.d5.loss_mask: 0.2035  decode.d5.loss_dice: 0.2280  decode.d6.loss_cls: 0.1719  decode.d6.loss_mask: 0.2191  decode.d6.loss_dice: 0.2365  decode.d7.loss_cls: 0.1631  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.2299  decode.d8.loss_cls: 0.1538  decode.d8.loss_mask: 0.2050  decode.d8.loss_dice: 0.2118
09/30 13:27:53 - mmengine - INFO - Iter(train) [ 36650/320000]  base_lr: 8.9631e-05 lr: 8.9631e-06  eta: 1 day, 10:07:16  time: 0.4355  data_time: 0.0094  memory: 5180  grad_norm: 37.1546  loss: 6.9835  decode.loss_cls: 0.0732  decode.loss_mask: 0.2960  decode.loss_dice: 0.2372  decode.d0.loss_cls: 0.8591  decode.d0.loss_mask: 0.3139  decode.d0.loss_dice: 0.2621  decode.d1.loss_cls: 0.0985  decode.d1.loss_mask: 0.2985  decode.d1.loss_dice: 0.2633  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.3022  decode.d2.loss_dice: 0.2496  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.3025  decode.d3.loss_dice: 0.2451  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.3010  decode.d4.loss_dice: 0.2407  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2970  decode.d5.loss_dice: 0.2423  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 0.2941  decode.d6.loss_dice: 0.2377  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.2997  decode.d7.loss_dice: 0.2380  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.2972  decode.d8.loss_dice: 0.2532
09/30 13:28:15 - mmengine - INFO - Iter(train) [ 36700/320000]  base_lr: 8.9617e-05 lr: 8.9617e-06  eta: 1 day, 10:06:55  time: 0.4361  data_time: 0.0096  memory: 5147  grad_norm: 67.8754  loss: 5.2213  decode.loss_cls: 0.0230  decode.loss_mask: 0.2576  decode.loss_dice: 0.1707  decode.d0.loss_cls: 0.7524  decode.d0.loss_mask: 0.2634  decode.d0.loss_dice: 0.1733  decode.d1.loss_cls: 0.0167  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.1705  decode.d2.loss_cls: 0.0134  decode.d2.loss_mask: 0.2508  decode.d2.loss_dice: 0.1696  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.2535  decode.d4.loss_dice: 0.1682  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.2561  decode.d5.loss_dice: 0.1684  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.2540  decode.d6.loss_dice: 0.1694  decode.d7.loss_cls: 0.0411  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.2553  decode.d8.loss_dice: 0.1715
09/30 13:28:37 - mmengine - INFO - Iter(train) [ 36750/320000]  base_lr: 8.9602e-05 lr: 8.9602e-06  eta: 1 day, 10:06:35  time: 0.4371  data_time: 0.0097  memory: 5147  grad_norm: 35.7814  loss: 5.4516  decode.loss_cls: 0.0557  decode.loss_mask: 0.2515  decode.loss_dice: 0.1959  decode.d0.loss_cls: 0.7213  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.2020  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.2516  decode.d1.loss_dice: 0.1903  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.2518  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0267  decode.d3.loss_mask: 0.2534  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.1995  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.2540  decode.d5.loss_dice: 0.1881  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.1901  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.2540  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.2538  decode.d8.loss_dice: 0.1926
09/30 13:28:58 - mmengine - INFO - Iter(train) [ 36800/320000]  base_lr: 8.9588e-05 lr: 8.9588e-06  eta: 1 day, 10:06:14  time: 0.4352  data_time: 0.0095  memory: 5160  grad_norm: 97.7279  loss: 7.3200  decode.loss_cls: 0.1750  decode.loss_mask: 0.2519  decode.loss_dice: 0.1963  decode.d0.loss_cls: 1.0482  decode.d0.loss_mask: 0.2569  decode.d0.loss_dice: 0.2039  decode.d1.loss_cls: 0.1503  decode.d1.loss_mask: 0.2638  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.1188  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.2023  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.1872  decode.d4.loss_cls: 0.1889  decode.d4.loss_mask: 0.2788  decode.d4.loss_dice: 0.2443  decode.d5.loss_cls: 0.1411  decode.d5.loss_mask: 0.3933  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 0.2568  decode.d6.loss_dice: 0.2286  decode.d7.loss_cls: 0.1641  decode.d7.loss_mask: 0.2529  decode.d7.loss_dice: 0.2040  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.2550  decode.d8.loss_dice: 0.2117
09/30 13:29:20 - mmengine - INFO - Iter(train) [ 36850/320000]  base_lr: 8.9574e-05 lr: 8.9574e-06  eta: 1 day, 10:05:52  time: 0.4339  data_time: 0.0092  memory: 5180  grad_norm: 62.1608  loss: 7.5279  decode.loss_cls: 0.2649  decode.loss_mask: 0.2629  decode.loss_dice: 0.2353  decode.d0.loss_cls: 0.8011  decode.d0.loss_mask: 0.2677  decode.d0.loss_dice: 0.2204  decode.d1.loss_cls: 0.1769  decode.d1.loss_mask: 0.2705  decode.d1.loss_dice: 0.2152  decode.d2.loss_cls: 0.1512  decode.d2.loss_mask: 0.2733  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.1143  decode.d3.loss_mask: 0.2623  decode.d3.loss_dice: 0.2011  decode.d4.loss_cls: 0.2190  decode.d4.loss_mask: 0.2625  decode.d4.loss_dice: 0.2166  decode.d5.loss_cls: 0.2118  decode.d5.loss_mask: 0.2737  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.1955  decode.d6.loss_mask: 0.2684  decode.d6.loss_dice: 0.2439  decode.d7.loss_cls: 0.2042  decode.d7.loss_mask: 0.2710  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.2692  decode.d8.loss_mask: 0.2820  decode.d8.loss_dice: 0.2266
09/30 13:29:42 - mmengine - INFO - Iter(train) [ 36900/320000]  base_lr: 8.9560e-05 lr: 8.9560e-06  eta: 1 day, 10:05:31  time: 0.4354  data_time: 0.0093  memory: 5161  grad_norm: 60.0073  loss: 5.8052  decode.loss_cls: 0.0882  decode.loss_mask: 0.2114  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.8995  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.1950  decode.d1.loss_cls: 0.1547  decode.d1.loss_mask: 0.2111  decode.d1.loss_dice: 0.1893  decode.d2.loss_cls: 0.1289  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.1848  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.2110  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 0.2095  decode.d4.loss_dice: 0.1865  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1830  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.0960  decode.d8.loss_mask: 0.2113  decode.d8.loss_dice: 0.1858
09/30 13:30:04 - mmengine - INFO - Iter(train) [ 36950/320000]  base_lr: 8.9545e-05 lr: 8.9545e-06  eta: 1 day, 10:05:10  time: 0.4345  data_time: 0.0093  memory: 5161  grad_norm: 107.5151  loss: 6.7941  decode.loss_cls: 0.1440  decode.loss_mask: 0.2636  decode.loss_dice: 0.1995  decode.d0.loss_cls: 0.9076  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.1935  decode.d1.loss_mask: 0.2680  decode.d1.loss_dice: 0.2182  decode.d2.loss_cls: 0.1195  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2008  decode.d3.loss_cls: 0.1197  decode.d3.loss_mask: 0.2647  decode.d3.loss_dice: 0.2002  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.2680  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.2732  decode.d5.loss_dice: 0.2204  decode.d6.loss_cls: 0.1092  decode.d6.loss_mask: 0.2714  decode.d6.loss_dice: 0.2013  decode.d7.loss_cls: 0.1146  decode.d7.loss_mask: 0.2721  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.1339  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.2119
09/30 13:30:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:30:25 - mmengine - INFO - Iter(train) [ 37000/320000]  base_lr: 8.9531e-05 lr: 8.9531e-06  eta: 1 day, 10:04:49  time: 0.4364  data_time: 0.0095  memory: 5180  grad_norm: 26.3300  loss: 4.6745  decode.loss_cls: 0.0057  decode.loss_mask: 0.2086  decode.loss_dice: 0.1606  decode.d0.loss_cls: 0.8142  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.1733  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.2113  decode.d1.loss_dice: 0.1672  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.2086  decode.d2.loss_dice: 0.1660  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.2096  decode.d3.loss_dice: 0.1678  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2100  decode.d4.loss_dice: 0.1701  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.2118  decode.d5.loss_dice: 0.1676  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.1655  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.1639  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.2096  decode.d8.loss_dice: 0.1662
09/30 13:30:47 - mmengine - INFO - Iter(train) [ 37050/320000]  base_lr: 8.9517e-05 lr: 8.9517e-06  eta: 1 day, 10:04:28  time: 0.4362  data_time: 0.0094  memory: 5161  grad_norm: 32.4437  loss: 6.5054  decode.loss_cls: 0.1096  decode.loss_mask: 0.2289  decode.loss_dice: 0.2449  decode.d0.loss_cls: 0.8836  decode.d0.loss_mask: 0.2313  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.2173  decode.d2.loss_cls: 0.0910  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.1110  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.2431  decode.d4.loss_cls: 0.1237  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.2289  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.1107  decode.d6.loss_mask: 0.2341  decode.d6.loss_dice: 0.2435  decode.d7.loss_cls: 0.1062  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.1037  decode.d8.loss_mask: 0.2309  decode.d8.loss_dice: 0.2354
09/30 13:31:09 - mmengine - INFO - Iter(train) [ 37100/320000]  base_lr: 8.9503e-05 lr: 8.9503e-06  eta: 1 day, 10:04:07  time: 0.4360  data_time: 0.0094  memory: 5161  grad_norm: 41.6928  loss: 6.7396  decode.loss_cls: 0.1453  decode.loss_mask: 0.2272  decode.loss_dice: 0.2497  decode.d0.loss_cls: 0.8137  decode.d0.loss_mask: 0.2319  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.1528  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2598  decode.d2.loss_cls: 0.1451  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.1048  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.2318  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.2247  decode.d4.loss_dice: 0.2514  decode.d5.loss_cls: 0.1155  decode.d5.loss_mask: 0.2288  decode.d5.loss_dice: 0.2500  decode.d6.loss_cls: 0.1386  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.1023  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.2538
09/30 13:31:31 - mmengine - INFO - Iter(train) [ 37150/320000]  base_lr: 8.9488e-05 lr: 8.9488e-06  eta: 1 day, 10:03:46  time: 0.4360  data_time: 0.0094  memory: 5147  grad_norm: 71.7805  loss: 5.4360  decode.loss_cls: 0.0927  decode.loss_mask: 0.2089  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.8971  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.1878  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.2104  decode.d1.loss_dice: 0.1744  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1780  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.1726  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.2122  decode.d4.loss_dice: 0.1744  decode.d5.loss_cls: 0.0803  decode.d5.loss_mask: 0.2125  decode.d5.loss_dice: 0.1758  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.1757  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.2119  decode.d7.loss_dice: 0.1760  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 0.2110  decode.d8.loss_dice: 0.1807
09/30 13:31:53 - mmengine - INFO - Iter(train) [ 37200/320000]  base_lr: 8.9474e-05 lr: 8.9474e-06  eta: 1 day, 10:03:26  time: 0.4372  data_time: 0.0093  memory: 5161  grad_norm: 48.9954  loss: 7.8011  decode.loss_cls: 0.1585  decode.loss_mask: 0.2311  decode.loss_dice: 0.2905  decode.d0.loss_cls: 0.8643  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.3137  decode.d1.loss_cls: 0.1247  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.2905  decode.d2.loss_cls: 0.2121  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.2937  decode.d3.loss_cls: 0.2262  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.2922  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.2324  decode.d4.loss_dice: 0.3045  decode.d5.loss_cls: 0.2081  decode.d5.loss_mask: 0.2307  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.2274  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2827  decode.d7.loss_cls: 0.1761  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2705  decode.d8.loss_cls: 0.1585  decode.d8.loss_mask: 0.2342  decode.d8.loss_dice: 0.2869
09/30 13:32:14 - mmengine - INFO - Iter(train) [ 37250/320000]  base_lr: 8.9460e-05 lr: 8.9460e-06  eta: 1 day, 10:03:05  time: 0.4356  data_time: 0.0093  memory: 5146  grad_norm: 60.0869  loss: 5.7255  decode.loss_cls: 0.0639  decode.loss_mask: 0.2085  decode.loss_dice: 0.2151  decode.d0.loss_cls: 0.9445  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.2034  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.2063  decode.d1.loss_dice: 0.2298  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.2057  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.0806  decode.d3.loss_mask: 0.2067  decode.d3.loss_dice: 0.1840  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.2078  decode.d4.loss_dice: 0.1758  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.2061  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.1000  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.1683  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.2077  decode.d7.loss_dice: 0.1730  decode.d8.loss_cls: 0.0925  decode.d8.loss_mask: 0.2077  decode.d8.loss_dice: 0.1822
09/30 13:32:36 - mmengine - INFO - Iter(train) [ 37300/320000]  base_lr: 8.9446e-05 lr: 8.9446e-06  eta: 1 day, 10:02:44  time: 0.4351  data_time: 0.0092  memory: 5160  grad_norm: 112.0989  loss: 6.6621  decode.loss_cls: 0.1918  decode.loss_mask: 0.2151  decode.loss_dice: 0.1927  decode.d0.loss_cls: 0.9858  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.2146  decode.d1.loss_cls: 0.2598  decode.d1.loss_mask: 0.2179  decode.d1.loss_dice: 0.2045  decode.d2.loss_cls: 0.1479  decode.d2.loss_mask: 0.2144  decode.d2.loss_dice: 0.2120  decode.d3.loss_cls: 0.1777  decode.d3.loss_mask: 0.2174  decode.d3.loss_dice: 0.2146  decode.d4.loss_cls: 0.1301  decode.d4.loss_mask: 0.2177  decode.d4.loss_dice: 0.2124  decode.d5.loss_cls: 0.1550  decode.d5.loss_mask: 0.2143  decode.d5.loss_dice: 0.2100  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.1667  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.2082  decode.d8.loss_cls: 0.1094  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.2007
09/30 13:32:58 - mmengine - INFO - Iter(train) [ 37350/320000]  base_lr: 8.9431e-05 lr: 8.9431e-06  eta: 1 day, 10:02:23  time: 0.4349  data_time: 0.0094  memory: 5161  grad_norm: 191.5071  loss: 10.8402  decode.loss_cls: 0.2153  decode.loss_mask: 0.3852  decode.loss_dice: 0.3447  decode.d0.loss_cls: 1.2193  decode.d0.loss_mask: 0.3510  decode.d0.loss_dice: 0.3671  decode.d1.loss_cls: 0.2861  decode.d1.loss_mask: 0.3872  decode.d1.loss_dice: 0.3398  decode.d2.loss_cls: 0.3150  decode.d2.loss_mask: 0.3490  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.2604  decode.d3.loss_mask: 0.4316  decode.d3.loss_dice: 0.3769  decode.d4.loss_cls: 0.2207  decode.d4.loss_mask: 0.4750  decode.d4.loss_dice: 0.3485  decode.d5.loss_cls: 0.1533  decode.d5.loss_mask: 0.5681  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.3680  decode.d6.loss_dice: 0.3451  decode.d7.loss_cls: 0.2462  decode.d7.loss_mask: 0.3504  decode.d7.loss_dice: 0.3505  decode.d8.loss_cls: 0.2160  decode.d8.loss_mask: 0.3921  decode.d8.loss_dice: 0.3112
09/30 13:33:20 - mmengine - INFO - Iter(train) [ 37400/320000]  base_lr: 8.9417e-05 lr: 8.9417e-06  eta: 1 day, 10:02:02  time: 0.4343  data_time: 0.0092  memory: 5147  grad_norm: 324.1139  loss: 8.2201  decode.loss_cls: 0.0815  decode.loss_mask: 0.2917  decode.loss_dice: 0.2981  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.2571  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.2931  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.2808  decode.d3.loss_dice: 0.3010  decode.d4.loss_cls: 0.1161  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.3279  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.2889  decode.d5.loss_dice: 0.3254  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.4536  decode.d6.loss_dice: 0.3376  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.5677  decode.d7.loss_dice: 0.3289  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.5465  decode.d8.loss_dice: 0.3527
09/30 13:33:41 - mmengine - INFO - Iter(train) [ 37450/320000]  base_lr: 8.9403e-05 lr: 8.9403e-06  eta: 1 day, 10:01:41  time: 0.4354  data_time: 0.0094  memory: 5147  grad_norm: 37.3223  loss: 4.8916  decode.loss_cls: 0.0286  decode.loss_mask: 0.1936  decode.loss_dice: 0.1679  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.2022  decode.d0.loss_dice: 0.1757  decode.d1.loss_cls: 0.0484  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.1950  decode.d2.loss_dice: 0.1752  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.1738  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.1966  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.1981  decode.d5.loss_dice: 0.1763  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.1719  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.1776  decode.d8.loss_cls: 0.0272  decode.d8.loss_mask: 0.1959  decode.d8.loss_dice: 0.1688
09/30 13:34:03 - mmengine - INFO - Iter(train) [ 37500/320000]  base_lr: 8.9389e-05 lr: 8.9389e-06  eta: 1 day, 10:01:20  time: 0.4349  data_time: 0.0093  memory: 5146  grad_norm: 24.6487  loss: 5.6130  decode.loss_cls: 0.0970  decode.loss_mask: 0.2139  decode.loss_dice: 0.2130  decode.d0.loss_cls: 0.7321  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.2131  decode.d1.loss_dice: 0.2074  decode.d2.loss_cls: 0.0870  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2048  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.1558  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.2136  decode.d4.loss_dice: 0.1950  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.2131  decode.d5.loss_dice: 0.2098  decode.d6.loss_cls: 0.0760  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.2049  decode.d7.loss_cls: 0.0881  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.2109  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.2112
09/30 13:34:25 - mmengine - INFO - Iter(train) [ 37550/320000]  base_lr: 8.9375e-05 lr: 8.9375e-06  eta: 1 day, 10:00:59  time: 0.4346  data_time: 0.0092  memory: 5180  grad_norm: 100.3394  loss: 5.4228  decode.loss_cls: 0.0458  decode.loss_mask: 0.2085  decode.loss_dice: 0.2076  decode.d0.loss_cls: 0.7530  decode.d0.loss_mask: 0.2088  decode.d0.loss_dice: 0.2178  decode.d1.loss_cls: 0.0389  decode.d1.loss_mask: 0.2070  decode.d1.loss_dice: 0.2112  decode.d2.loss_cls: 0.0311  decode.d2.loss_mask: 0.2075  decode.d2.loss_dice: 0.2025  decode.d3.loss_cls: 0.0310  decode.d3.loss_mask: 0.2063  decode.d3.loss_dice: 0.2084  decode.d4.loss_cls: 0.1214  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.2007  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0678  decode.d6.loss_mask: 0.2092  decode.d6.loss_dice: 0.2035  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.2133  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.2115  decode.d8.loss_dice: 0.2114
09/30 13:34:47 - mmengine - INFO - Iter(train) [ 37600/320000]  base_lr: 8.9360e-05 lr: 8.9360e-06  eta: 1 day, 10:00:39  time: 0.4351  data_time: 0.0092  memory: 5147  grad_norm: 93.7739  loss: 9.9649  decode.loss_cls: 0.2077  decode.loss_mask: 0.3759  decode.loss_dice: 0.2310  decode.d0.loss_cls: 1.1169  decode.d0.loss_mask: 0.3060  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.3328  decode.d1.loss_mask: 0.3605  decode.d1.loss_dice: 0.2528  decode.d2.loss_cls: 0.3011  decode.d2.loss_mask: 0.3865  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.2223  decode.d3.loss_mask: 0.5079  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.2882  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.2545  decode.d5.loss_mask: 0.4724  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.2417  decode.d6.loss_mask: 0.4073  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.1905  decode.d7.loss_mask: 0.5211  decode.d7.loss_dice: 0.2407  decode.d8.loss_cls: 0.1827  decode.d8.loss_mask: 0.5297  decode.d8.loss_dice: 0.2353
09/30 13:35:09 - mmengine - INFO - Iter(train) [ 37650/320000]  base_lr: 8.9346e-05 lr: 8.9346e-06  eta: 1 day, 10:00:18  time: 0.4353  data_time: 0.0092  memory: 5160  grad_norm: 23.9281  loss: 5.7312  decode.loss_cls: 0.0608  decode.loss_mask: 0.2522  decode.loss_dice: 0.1983  decode.d0.loss_cls: 0.8945  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.1956  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.2555  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.2496  decode.d2.loss_dice: 0.2003  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.2040  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.1916  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.2540  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.2054  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.2554  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.2499  decode.d8.loss_dice: 0.2034
09/30 13:35:31 - mmengine - INFO - Iter(train) [ 37700/320000]  base_lr: 8.9332e-05 lr: 8.9332e-06  eta: 1 day, 9:59:57  time: 0.4350  data_time: 0.0092  memory: 5160  grad_norm: 70.7115  loss: 8.0862  decode.loss_cls: 0.2821  decode.loss_mask: 0.2533  decode.loss_dice: 0.2279  decode.d0.loss_cls: 1.0001  decode.d0.loss_mask: 0.2536  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.2658  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2158  decode.d2.loss_cls: 0.2822  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.2604  decode.d3.loss_mask: 0.2663  decode.d3.loss_dice: 0.2245  decode.d4.loss_cls: 0.2654  decode.d4.loss_mask: 0.2625  decode.d4.loss_dice: 0.2235  decode.d5.loss_cls: 0.2349  decode.d5.loss_mask: 0.2736  decode.d5.loss_dice: 0.2175  decode.d6.loss_cls: 0.2094  decode.d6.loss_mask: 0.2685  decode.d6.loss_dice: 0.2212  decode.d7.loss_cls: 0.1867  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.2918  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.2151
09/30 13:35:52 - mmengine - INFO - Iter(train) [ 37750/320000]  base_lr: 8.9318e-05 lr: 8.9318e-06  eta: 1 day, 9:59:36  time: 0.4352  data_time: 0.0091  memory: 5180  grad_norm: 79.0209  loss: 6.0363  decode.loss_cls: 0.0717  decode.loss_mask: 0.2256  decode.loss_dice: 0.1976  decode.d0.loss_cls: 0.8338  decode.d0.loss_mask: 0.2357  decode.d0.loss_dice: 0.2048  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.2104  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.1953  decode.d3.loss_cls: 0.1204  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.1988  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.1163  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2046  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.1943  decode.d7.loss_cls: 0.1304  decode.d7.loss_mask: 0.2255  decode.d7.loss_dice: 0.1935  decode.d8.loss_cls: 0.0845  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.1998
09/30 13:36:14 - mmengine - INFO - Iter(train) [ 37800/320000]  base_lr: 8.9303e-05 lr: 8.9303e-06  eta: 1 day, 9:59:15  time: 0.4350  data_time: 0.0093  memory: 5180  grad_norm: 37.6667  loss: 5.5831  decode.loss_cls: 0.0679  decode.loss_mask: 0.2335  decode.loss_dice: 0.2002  decode.d0.loss_cls: 0.7480  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.2051  decode.d1.loss_cls: 0.0496  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.1977  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.2010  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.2323  decode.d4.loss_dice: 0.2010  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.2367  decode.d5.loss_dice: 0.1963  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.1988  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2026
09/30 13:36:36 - mmengine - INFO - Iter(train) [ 37850/320000]  base_lr: 8.9289e-05 lr: 8.9289e-06  eta: 1 day, 9:58:54  time: 0.4356  data_time: 0.0094  memory: 5160  grad_norm: 21.3855  loss: 5.4069  decode.loss_cls: 0.0198  decode.loss_mask: 0.2637  decode.loss_dice: 0.1761  decode.d0.loss_cls: 0.8372  decode.d0.loss_mask: 0.2718  decode.d0.loss_dice: 0.1791  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.2647  decode.d1.loss_dice: 0.1815  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.2664  decode.d2.loss_dice: 0.1761  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.1754  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.2672  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.1750  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2651  decode.d7.loss_dice: 0.1778  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.1812
09/30 13:36:58 - mmengine - INFO - Iter(train) [ 37900/320000]  base_lr: 8.9275e-05 lr: 8.9275e-06  eta: 1 day, 9:58:33  time: 0.4343  data_time: 0.0094  memory: 5160  grad_norm: 125.4472  loss: 8.4860  decode.loss_cls: 0.1548  decode.loss_mask: 0.3473  decode.loss_dice: 0.2605  decode.d0.loss_cls: 0.8833  decode.d0.loss_mask: 0.3674  decode.d0.loss_dice: 0.2645  decode.d1.loss_cls: 0.1912  decode.d1.loss_mask: 0.3129  decode.d1.loss_dice: 0.2489  decode.d2.loss_cls: 0.1704  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.1570  decode.d3.loss_mask: 0.3766  decode.d3.loss_dice: 0.2944  decode.d4.loss_cls: 0.1938  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.2750  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 0.3321  decode.d5.loss_dice: 0.2513  decode.d6.loss_cls: 0.1524  decode.d6.loss_mask: 0.3824  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.1814  decode.d7.loss_mask: 0.3392  decode.d7.loss_dice: 0.2692  decode.d8.loss_cls: 0.1559  decode.d8.loss_mask: 0.3511  decode.d8.loss_dice: 0.2750
09/30 13:37:19 - mmengine - INFO - Iter(train) [ 37950/320000]  base_lr: 8.9261e-05 lr: 8.9261e-06  eta: 1 day, 9:58:12  time: 0.4354  data_time: 0.0092  memory: 5180  grad_norm: 68.8897  loss: 6.3693  decode.loss_cls: 0.0776  decode.loss_mask: 0.2609  decode.loss_dice: 0.1762  decode.d0.loss_cls: 1.0575  decode.d0.loss_mask: 0.2735  decode.d0.loss_dice: 0.1760  decode.d1.loss_cls: 0.1524  decode.d1.loss_mask: 0.2660  decode.d1.loss_dice: 0.1773  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.0955  decode.d3.loss_mask: 0.2609  decode.d3.loss_dice: 0.1702  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.2599  decode.d4.loss_dice: 0.1733  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.1783  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.2628  decode.d6.loss_dice: 0.1756  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 0.2613  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.2631  decode.d8.loss_dice: 0.1771
09/30 13:37:41 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:37:41 - mmengine - INFO - Iter(train) [ 38000/320000]  base_lr: 8.9246e-05 lr: 8.9246e-06  eta: 1 day, 9:57:51  time: 0.4360  data_time: 0.0094  memory: 5146  grad_norm: 192.9550  loss: 6.8431  decode.loss_cls: 0.1709  decode.loss_mask: 0.2592  decode.loss_dice: 0.2068  decode.d0.loss_cls: 0.8703  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.2045  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 0.2467  decode.d1.loss_dice: 0.1819  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.2518  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.1761  decode.d3.loss_mask: 0.2501  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.1408  decode.d4.loss_mask: 0.2537  decode.d4.loss_dice: 0.1920  decode.d5.loss_cls: 0.1488  decode.d5.loss_mask: 0.2887  decode.d5.loss_dice: 0.2027  decode.d6.loss_cls: 0.1687  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.2007  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.1930  decode.d8.loss_cls: 0.1631  decode.d8.loss_mask: 0.2583  decode.d8.loss_dice: 0.2036
09/30 13:38:03 - mmengine - INFO - Iter(train) [ 38050/320000]  base_lr: 8.9232e-05 lr: 8.9232e-06  eta: 1 day, 9:57:30  time: 0.4355  data_time: 0.0094  memory: 5161  grad_norm: 116.1924  loss: 7.9032  decode.loss_cls: 0.1147  decode.loss_mask: 0.3230  decode.loss_dice: 0.2484  decode.d0.loss_cls: 0.8638  decode.d0.loss_mask: 0.3023  decode.d0.loss_dice: 0.2328  decode.d1.loss_cls: 0.2189  decode.d1.loss_mask: 0.2982  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.1471  decode.d2.loss_mask: 0.3266  decode.d2.loss_dice: 0.2308  decode.d3.loss_cls: 0.1243  decode.d3.loss_mask: 0.3275  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.3206  decode.d4.loss_dice: 0.2301  decode.d5.loss_cls: 0.1479  decode.d5.loss_mask: 0.3179  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.1588  decode.d6.loss_mask: 0.3091  decode.d6.loss_dice: 0.2587  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 0.3237  decode.d7.loss_dice: 0.2737  decode.d8.loss_cls: 0.1829  decode.d8.loss_mask: 0.3144  decode.d8.loss_dice: 0.2424
09/30 13:38:25 - mmengine - INFO - Iter(train) [ 38100/320000]  base_lr: 8.9218e-05 lr: 8.9218e-06  eta: 1 day, 9:57:09  time: 0.4356  data_time: 0.0094  memory: 5160  grad_norm: 86.7389  loss: 8.2362  decode.loss_cls: 0.1721  decode.loss_mask: 0.3316  decode.loss_dice: 0.2464  decode.d0.loss_cls: 0.9300  decode.d0.loss_mask: 0.3422  decode.d0.loss_dice: 0.2796  decode.d1.loss_cls: 0.1713  decode.d1.loss_mask: 0.3351  decode.d1.loss_dice: 0.2587  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 0.3364  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 0.3355  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1666  decode.d4.loss_mask: 0.3371  decode.d4.loss_dice: 0.2830  decode.d5.loss_cls: 0.1343  decode.d5.loss_mask: 0.3452  decode.d5.loss_dice: 0.2559  decode.d6.loss_cls: 0.1691  decode.d6.loss_mask: 0.3338  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.1610  decode.d7.loss_mask: 0.3385  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.1437  decode.d8.loss_mask: 0.3359  decode.d8.loss_dice: 0.2502
09/30 13:38:46 - mmengine - INFO - Iter(train) [ 38150/320000]  base_lr: 8.9204e-05 lr: 8.9204e-06  eta: 1 day, 9:56:48  time: 0.4347  data_time: 0.0093  memory: 5161  grad_norm: 61.5982  loss: 8.1446  decode.loss_cls: 0.1730  decode.loss_mask: 0.2651  decode.loss_dice: 0.2815  decode.d0.loss_cls: 0.8089  decode.d0.loss_mask: 0.2880  decode.d0.loss_dice: 0.2830  decode.d1.loss_cls: 0.3224  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.2999  decode.d2.loss_cls: 0.2935  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.2648  decode.d3.loss_cls: 0.2142  decode.d3.loss_mask: 0.2654  decode.d3.loss_dice: 0.2776  decode.d4.loss_cls: 0.1882  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.2617  decode.d5.loss_cls: 0.1816  decode.d5.loss_mask: 0.2676  decode.d5.loss_dice: 0.2840  decode.d6.loss_cls: 0.1716  decode.d6.loss_mask: 0.2611  decode.d6.loss_dice: 0.2736  decode.d7.loss_cls: 0.1712  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1778  decode.d8.loss_mask: 0.2649  decode.d8.loss_dice: 0.2635
09/30 13:39:08 - mmengine - INFO - Iter(train) [ 38200/320000]  base_lr: 8.9189e-05 lr: 8.9189e-06  eta: 1 day, 9:56:27  time: 0.4349  data_time: 0.0093  memory: 5161  grad_norm: 43.0776  loss: 5.5671  decode.loss_cls: 0.0274  decode.loss_mask: 0.2599  decode.loss_dice: 0.1885  decode.d0.loss_cls: 0.7836  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.1828  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.1884  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.1809  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.2630  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.0657  decode.d4.loss_mask: 0.2592  decode.d4.loss_dice: 0.1833  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.2615  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.2578  decode.d6.loss_dice: 0.1867  decode.d7.loss_cls: 0.0223  decode.d7.loss_mask: 0.2613  decode.d7.loss_dice: 0.1871  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.1877
09/30 13:39:30 - mmengine - INFO - Iter(train) [ 38250/320000]  base_lr: 8.9175e-05 lr: 8.9175e-06  eta: 1 day, 9:56:06  time: 0.4351  data_time: 0.0093  memory: 5147  grad_norm: 26.5875  loss: 4.7746  decode.loss_cls: 0.0081  decode.loss_mask: 0.2169  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.7196  decode.d0.loss_mask: 0.2179  decode.d0.loss_dice: 0.1753  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.2189  decode.d2.loss_dice: 0.1789  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.1786  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.2134  decode.d4.loss_dice: 0.1789  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.2178  decode.d6.loss_dice: 0.1783  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2166  decode.d8.loss_dice: 0.1758
09/30 13:39:52 - mmengine - INFO - Iter(train) [ 38300/320000]  base_lr: 8.9161e-05 lr: 8.9161e-06  eta: 1 day, 9:55:44  time: 0.4349  data_time: 0.0092  memory: 5145  grad_norm: 100.3165  loss: 7.7779  decode.loss_cls: 0.1491  decode.loss_mask: 0.2867  decode.loss_dice: 0.2597  decode.d0.loss_cls: 0.9094  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.1165  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.2346  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.2911  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.1429  decode.d3.loss_mask: 0.2908  decode.d3.loss_dice: 0.2761  decode.d4.loss_cls: 0.1414  decode.d4.loss_mask: 0.2959  decode.d4.loss_dice: 0.2811  decode.d5.loss_cls: 0.1559  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.1503  decode.d6.loss_mask: 0.2811  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.1520  decode.d7.loss_mask: 0.2812  decode.d7.loss_dice: 0.2740  decode.d8.loss_cls: 0.1432  decode.d8.loss_mask: 0.2868  decode.d8.loss_dice: 0.2723
09/30 13:40:14 - mmengine - INFO - Iter(train) [ 38350/320000]  base_lr: 8.9147e-05 lr: 8.9147e-06  eta: 1 day, 9:55:23  time: 0.4350  data_time: 0.0095  memory: 5180  grad_norm: 57.4998  loss: 5.2393  decode.loss_cls: 0.0671  decode.loss_mask: 0.2110  decode.loss_dice: 0.1754  decode.d0.loss_cls: 0.8061  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.1730  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1740  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.1768  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.2140  decode.d3.loss_dice: 0.1742  decode.d4.loss_cls: 0.0552  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.1775  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1715  decode.d6.loss_cls: 0.0711  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.1696  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.2150  decode.d7.loss_dice: 0.1816  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.1744
09/30 13:40:35 - mmengine - INFO - Iter(train) [ 38400/320000]  base_lr: 8.9132e-05 lr: 8.9132e-06  eta: 1 day, 9:55:02  time: 0.4341  data_time: 0.0093  memory: 5147  grad_norm: 60.8065  loss: 7.7194  decode.loss_cls: 0.1911  decode.loss_mask: 0.2997  decode.loss_dice: 0.2315  decode.d0.loss_cls: 0.9340  decode.d0.loss_mask: 0.2963  decode.d0.loss_dice: 0.2168  decode.d1.loss_cls: 0.1967  decode.d1.loss_mask: 0.2990  decode.d1.loss_dice: 0.2162  decode.d2.loss_cls: 0.2097  decode.d2.loss_mask: 0.2976  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.1760  decode.d3.loss_mask: 0.2976  decode.d3.loss_dice: 0.2450  decode.d4.loss_cls: 0.1466  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.2142  decode.d5.loss_cls: 0.1549  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.2181  decode.d6.loss_cls: 0.1791  decode.d6.loss_mask: 0.2990  decode.d6.loss_dice: 0.2118  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 0.3023  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.1557  decode.d8.loss_mask: 0.2987  decode.d8.loss_dice: 0.2230
09/30 13:40:57 - mmengine - INFO - Iter(train) [ 38450/320000]  base_lr: 8.9118e-05 lr: 8.9118e-06  eta: 1 day, 9:54:42  time: 0.4353  data_time: 0.0094  memory: 5146  grad_norm: 38.7144  loss: 7.0225  decode.loss_cls: 0.1216  decode.loss_mask: 0.2685  decode.loss_dice: 0.2345  decode.d0.loss_cls: 0.8661  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.2304  decode.d1.loss_cls: 0.1363  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.2217  decode.d2.loss_cls: 0.1715  decode.d2.loss_mask: 0.2627  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.1422  decode.d3.loss_mask: 0.2665  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.1596  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.2279  decode.d5.loss_cls: 0.0988  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.2662  decode.d6.loss_dice: 0.2534  decode.d7.loss_cls: 0.1030  decode.d7.loss_mask: 0.2695  decode.d7.loss_dice: 0.2308  decode.d8.loss_cls: 0.1317  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2106
09/30 13:41:19 - mmengine - INFO - Iter(train) [ 38500/320000]  base_lr: 8.9104e-05 lr: 8.9104e-06  eta: 1 day, 9:54:21  time: 0.4354  data_time: 0.0094  memory: 5147  grad_norm: 50.9859  loss: 7.0980  decode.loss_cls: 0.2201  decode.loss_mask: 0.2524  decode.loss_dice: 0.2039  decode.d0.loss_cls: 0.9039  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.2767  decode.d1.loss_cls: 0.1544  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 0.2499  decode.d2.loss_dice: 0.2086  decode.d3.loss_cls: 0.1458  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2318  decode.d4.loss_cls: 0.1684  decode.d4.loss_mask: 0.2494  decode.d4.loss_dice: 0.2100  decode.d5.loss_cls: 0.1578  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.1393  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.2268  decode.d7.loss_cls: 0.1162  decode.d7.loss_mask: 0.2498  decode.d7.loss_dice: 0.2456  decode.d8.loss_cls: 0.1530  decode.d8.loss_mask: 0.2472  decode.d8.loss_dice: 0.2422
09/30 13:41:41 - mmengine - INFO - Iter(train) [ 38550/320000]  base_lr: 8.9090e-05 lr: 8.9090e-06  eta: 1 day, 9:54:00  time: 0.4374  data_time: 0.0098  memory: 5161  grad_norm: 42.6001  loss: 5.2020  decode.loss_cls: 0.0665  decode.loss_mask: 0.2338  decode.loss_dice: 0.1705  decode.d0.loss_cls: 0.9114  decode.d0.loss_mask: 0.2345  decode.d0.loss_dice: 0.1851  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.1780  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.1799  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.2341  decode.d3.loss_dice: 0.1846  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.2346  decode.d6.loss_dice: 0.1692  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.1736  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.2345  decode.d8.loss_dice: 0.1750
09/30 13:42:02 - mmengine - INFO - Iter(train) [ 38600/320000]  base_lr: 8.9075e-05 lr: 8.9075e-06  eta: 1 day, 9:53:39  time: 0.4353  data_time: 0.0096  memory: 5160  grad_norm: 205.9107  loss: 8.4470  decode.loss_cls: 0.1176  decode.loss_mask: 0.3510  decode.loss_dice: 0.2791  decode.d0.loss_cls: 0.8958  decode.d0.loss_mask: 0.3407  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.2330  decode.d1.loss_mask: 0.3494  decode.d1.loss_dice: 0.2862  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 0.3425  decode.d2.loss_dice: 0.2889  decode.d3.loss_cls: 0.1732  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.2762  decode.d4.loss_cls: 0.1610  decode.d4.loss_mask: 0.3391  decode.d4.loss_dice: 0.2794  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.3477  decode.d5.loss_dice: 0.2773  decode.d6.loss_cls: 0.0946  decode.d6.loss_mask: 0.3534  decode.d6.loss_dice: 0.2787  decode.d7.loss_cls: 0.1116  decode.d7.loss_mask: 0.3504  decode.d7.loss_dice: 0.2776  decode.d8.loss_cls: 0.1134  decode.d8.loss_mask: 0.3468  decode.d8.loss_dice: 0.2751
09/30 13:42:24 - mmengine - INFO - Iter(train) [ 38650/320000]  base_lr: 8.9061e-05 lr: 8.9061e-06  eta: 1 day, 9:53:18  time: 0.4354  data_time: 0.0097  memory: 5147  grad_norm: 71.3401  loss: 7.9600  decode.loss_cls: 0.1505  decode.loss_mask: 0.3034  decode.loss_dice: 0.2523  decode.d0.loss_cls: 1.0826  decode.d0.loss_mask: 0.3196  decode.d0.loss_dice: 0.2905  decode.d1.loss_cls: 0.1244  decode.d1.loss_mask: 0.2978  decode.d1.loss_dice: 0.2883  decode.d2.loss_cls: 0.1867  decode.d2.loss_mask: 0.2981  decode.d2.loss_dice: 0.2712  decode.d3.loss_cls: 0.1220  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.2813  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.2742  decode.d5.loss_cls: 0.1236  decode.d5.loss_mask: 0.3016  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.1321  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.2580  decode.d7.loss_cls: 0.0910  decode.d7.loss_mask: 0.2981  decode.d7.loss_dice: 0.2701  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.3009  decode.d8.loss_dice: 0.2672
09/30 13:42:46 - mmengine - INFO - Iter(train) [ 38700/320000]  base_lr: 8.9047e-05 lr: 8.9047e-06  eta: 1 day, 9:52:57  time: 0.4357  data_time: 0.0095  memory: 5180  grad_norm: 81.3415  loss: 7.0097  decode.loss_cls: 0.1417  decode.loss_mask: 0.2518  decode.loss_dice: 0.2683  decode.d0.loss_cls: 0.8698  decode.d0.loss_mask: 0.2460  decode.d0.loss_dice: 0.2629  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 0.2433  decode.d1.loss_dice: 0.2407  decode.d2.loss_cls: 0.1551  decode.d2.loss_mask: 0.2430  decode.d2.loss_dice: 0.2469  decode.d3.loss_cls: 0.1246  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.2398  decode.d4.loss_dice: 0.2590  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 0.2452  decode.d5.loss_dice: 0.2745  decode.d6.loss_cls: 0.1166  decode.d6.loss_mask: 0.2439  decode.d6.loss_dice: 0.2543  decode.d7.loss_cls: 0.1230  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.1383  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.2538
09/30 13:43:08 - mmengine - INFO - Iter(train) [ 38750/320000]  base_lr: 8.9033e-05 lr: 8.9033e-06  eta: 1 day, 9:52:36  time: 0.4357  data_time: 0.0095  memory: 5160  grad_norm: 40.6866  loss: 5.9035  decode.loss_cls: 0.1658  decode.loss_mask: 0.2031  decode.loss_dice: 0.1614  decode.d0.loss_cls: 0.9281  decode.d0.loss_mask: 0.1977  decode.d0.loss_dice: 0.1714  decode.d1.loss_cls: 0.1190  decode.d1.loss_mask: 0.2054  decode.d1.loss_dice: 0.1650  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1597  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.1610  decode.d4.loss_cls: 0.1602  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.1618  decode.d5.loss_cls: 0.1361  decode.d5.loss_mask: 0.2102  decode.d5.loss_dice: 0.1625  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.1627  decode.d7.loss_cls: 0.1604  decode.d7.loss_mask: 0.2028  decode.d7.loss_dice: 0.1618  decode.d8.loss_cls: 0.1293  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.1617
09/30 13:43:30 - mmengine - INFO - Iter(train) [ 38800/320000]  base_lr: 8.9018e-05 lr: 8.9018e-06  eta: 1 day, 9:52:15  time: 0.4353  data_time: 0.0095  memory: 5145  grad_norm: 37.1969  loss: 5.7185  decode.loss_cls: 0.0897  decode.loss_mask: 0.2108  decode.loss_dice: 0.2194  decode.d0.loss_cls: 0.8224  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.1170  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.2092  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.2097  decode.d2.loss_dice: 0.2073  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.2084  decode.d3.loss_dice: 0.2153  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.2158  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.2160  decode.d6.loss_cls: 0.0726  decode.d6.loss_mask: 0.2074  decode.d6.loss_dice: 0.2040  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.2105  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0851  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.2117
09/30 13:43:51 - mmengine - INFO - Iter(train) [ 38850/320000]  base_lr: 8.9004e-05 lr: 8.9004e-06  eta: 1 day, 9:51:54  time: 0.4351  data_time: 0.0095  memory: 5161  grad_norm: 57.1901  loss: 9.0837  decode.loss_cls: 0.1912  decode.loss_mask: 0.3384  decode.loss_dice: 0.2619  decode.d0.loss_cls: 0.9475  decode.d0.loss_mask: 0.3540  decode.d0.loss_dice: 0.2637  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.3619  decode.d1.loss_dice: 0.2810  decode.d2.loss_cls: 0.1751  decode.d2.loss_mask: 0.3687  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.1598  decode.d3.loss_mask: 0.3566  decode.d3.loss_dice: 0.2691  decode.d4.loss_cls: 0.1732  decode.d4.loss_mask: 0.3389  decode.d4.loss_dice: 0.2772  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 0.4174  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.1668  decode.d6.loss_mask: 0.5350  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.1660  decode.d7.loss_mask: 0.4817  decode.d7.loss_dice: 0.2735  decode.d8.loss_cls: 0.1914  decode.d8.loss_mask: 0.3316  decode.d8.loss_dice: 0.2524
09/30 13:44:13 - mmengine - INFO - Iter(train) [ 38900/320000]  base_lr: 8.8990e-05 lr: 8.8990e-06  eta: 1 day, 9:51:32  time: 0.4347  data_time: 0.0092  memory: 5161  grad_norm: 58.8073  loss: 6.9020  decode.loss_cls: 0.1427  decode.loss_mask: 0.2408  decode.loss_dice: 0.2625  decode.d0.loss_cls: 0.7843  decode.d0.loss_mask: 0.2467  decode.d0.loss_dice: 0.2632  decode.d1.loss_cls: 0.1155  decode.d1.loss_mask: 0.2467  decode.d1.loss_dice: 0.2634  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.2469  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.1182  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.2518  decode.d4.loss_cls: 0.1047  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.2477  decode.d5.loss_cls: 0.1088  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.2626  decode.d6.loss_cls: 0.1265  decode.d6.loss_mask: 0.2418  decode.d6.loss_dice: 0.2630  decode.d7.loss_cls: 0.1394  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.1358  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.2481
09/30 13:44:35 - mmengine - INFO - Iter(train) [ 38950/320000]  base_lr: 8.8976e-05 lr: 8.8976e-06  eta: 1 day, 9:51:11  time: 0.4352  data_time: 0.0093  memory: 5180  grad_norm: 34.7758  loss: 4.8369  decode.loss_cls: 0.0076  decode.loss_mask: 0.2231  decode.loss_dice: 0.1700  decode.d0.loss_cls: 0.8321  decode.d0.loss_mask: 0.2254  decode.d0.loss_dice: 0.1683  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.1696  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2192  decode.d2.loss_dice: 0.1658  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.2269  decode.d3.loss_dice: 0.1710  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.1729  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.2220  decode.d5.loss_dice: 0.1655  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.1662  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.1723  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.1732
09/30 13:44:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:44:57 - mmengine - INFO - Iter(train) [ 39000/320000]  base_lr: 8.8961e-05 lr: 8.8961e-06  eta: 1 day, 9:50:51  time: 0.4366  data_time: 0.0095  memory: 5180  grad_norm: 29.1657  loss: 5.9061  decode.loss_cls: 0.1349  decode.loss_mask: 0.2069  decode.loss_dice: 0.1583  decode.d0.loss_cls: 0.7371  decode.d0.loss_mask: 0.2105  decode.d0.loss_dice: 0.1608  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.1516  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 0.2060  decode.d2.loss_dice: 0.1627  decode.d3.loss_cls: 0.1819  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1532  decode.d4.loss_cls: 0.1874  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1541  decode.d5.loss_cls: 0.2132  decode.d5.loss_mask: 0.2057  decode.d5.loss_dice: 0.1572  decode.d6.loss_cls: 0.1969  decode.d6.loss_mask: 0.2077  decode.d6.loss_dice: 0.1540  decode.d7.loss_cls: 0.1513  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.1554  decode.d8.loss_cls: 0.1583  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.1543
09/30 13:45:18 - mmengine - INFO - Iter(train) [ 39050/320000]  base_lr: 8.8947e-05 lr: 8.8947e-06  eta: 1 day, 9:50:30  time: 0.4358  data_time: 0.0095  memory: 5147  grad_norm: 58.1979  loss: 7.9164  decode.loss_cls: 0.1680  decode.loss_mask: 0.2770  decode.loss_dice: 0.2486  decode.d0.loss_cls: 1.0214  decode.d0.loss_mask: 0.2857  decode.d0.loss_dice: 0.2765  decode.d1.loss_cls: 0.1991  decode.d1.loss_mask: 0.2820  decode.d1.loss_dice: 0.2595  decode.d2.loss_cls: 0.2073  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.2448  decode.d3.loss_cls: 0.1868  decode.d3.loss_mask: 0.2805  decode.d3.loss_dice: 0.2132  decode.d4.loss_cls: 0.1792  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.2553  decode.d5.loss_cls: 0.1753  decode.d5.loss_mask: 0.2781  decode.d5.loss_dice: 0.2660  decode.d6.loss_cls: 0.1343  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.2829  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.2787  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.1725  decode.d8.loss_mask: 0.2831  decode.d8.loss_dice: 0.2351
09/30 13:45:40 - mmengine - INFO - Iter(train) [ 39100/320000]  base_lr: 8.8933e-05 lr: 8.8933e-06  eta: 1 day, 9:50:09  time: 0.4351  data_time: 0.0095  memory: 5160  grad_norm: 53.9834  loss: 7.6881  decode.loss_cls: 0.1684  decode.loss_mask: 0.2543  decode.loss_dice: 0.2754  decode.d0.loss_cls: 1.1815  decode.d0.loss_mask: 0.2237  decode.d0.loss_dice: 0.2269  decode.d1.loss_cls: 0.2347  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.2400  decode.d2.loss_cls: 0.1972  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2131  decode.d4.loss_cls: 0.1982  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.2601  decode.d5.loss_cls: 0.1662  decode.d5.loss_mask: 0.2271  decode.d5.loss_dice: 0.2549  decode.d6.loss_cls: 0.1520  decode.d6.loss_mask: 0.2470  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.1329  decode.d7.loss_mask: 0.2927  decode.d7.loss_dice: 0.2717  decode.d8.loss_cls: 0.1591  decode.d8.loss_mask: 0.2440  decode.d8.loss_dice: 0.2742
09/30 13:46:02 - mmengine - INFO - Iter(train) [ 39150/320000]  base_lr: 8.8919e-05 lr: 8.8919e-06  eta: 1 day, 9:49:48  time: 0.4354  data_time: 0.0093  memory: 5146  grad_norm: 60.2392  loss: 6.6781  decode.loss_cls: 0.1284  decode.loss_mask: 0.1959  decode.loss_dice: 0.2677  decode.d0.loss_cls: 0.8031  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2768  decode.d1.loss_cls: 0.1576  decode.d1.loss_mask: 0.1963  decode.d1.loss_dice: 0.2462  decode.d2.loss_cls: 0.1500  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.2639  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 0.1942  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.1820  decode.d5.loss_mask: 0.1969  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.1630  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.2772  decode.d7.loss_cls: 0.1235  decode.d7.loss_mask: 0.1943  decode.d7.loss_dice: 0.2576  decode.d8.loss_cls: 0.1483  decode.d8.loss_mask: 0.1915  decode.d8.loss_dice: 0.2633
09/30 13:46:24 - mmengine - INFO - Iter(train) [ 39200/320000]  base_lr: 8.8904e-05 lr: 8.8904e-06  eta: 1 day, 9:49:27  time: 0.4356  data_time: 0.0096  memory: 5161  grad_norm: 135.2601  loss: 9.2540  decode.loss_cls: 0.1419  decode.loss_mask: 0.3802  decode.loss_dice: 0.3134  decode.d0.loss_cls: 0.8947  decode.d0.loss_mask: 0.2517  decode.d0.loss_dice: 0.3110  decode.d1.loss_cls: 0.3023  decode.d1.loss_mask: 0.2453  decode.d1.loss_dice: 0.3121  decode.d2.loss_cls: 0.2623  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.2939  decode.d3.loss_cls: 0.1534  decode.d3.loss_mask: 0.3939  decode.d3.loss_dice: 0.3370  decode.d4.loss_cls: 0.2053  decode.d4.loss_mask: 0.3966  decode.d4.loss_dice: 0.3463  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 0.3879  decode.d5.loss_dice: 0.3025  decode.d6.loss_cls: 0.1619  decode.d6.loss_mask: 0.3839  decode.d6.loss_dice: 0.3211  decode.d7.loss_cls: 0.1441  decode.d7.loss_mask: 0.3927  decode.d7.loss_dice: 0.3334  decode.d8.loss_cls: 0.1487  decode.d8.loss_mask: 0.3915  decode.d8.loss_dice: 0.3352
09/30 13:46:46 - mmengine - INFO - Iter(train) [ 39250/320000]  base_lr: 8.8890e-05 lr: 8.8890e-06  eta: 1 day, 9:49:07  time: 0.4352  data_time: 0.0095  memory: 5180  grad_norm: 20.6351  loss: 5.4047  decode.loss_cls: 0.0550  decode.loss_mask: 0.2041  decode.loss_dice: 0.1968  decode.d0.loss_cls: 0.9202  decode.d0.loss_mask: 0.2031  decode.d0.loss_dice: 0.1919  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.1838  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.2027  decode.d2.loss_dice: 0.1819  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.1995  decode.d3.loss_dice: 0.1903  decode.d4.loss_cls: 0.0670  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0756  decode.d5.loss_mask: 0.2046  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.1887  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.2031  decode.d7.loss_dice: 0.1810  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.1844
09/30 13:47:08 - mmengine - INFO - Iter(train) [ 39300/320000]  base_lr: 8.8876e-05 lr: 8.8876e-06  eta: 1 day, 9:48:46  time: 0.4347  data_time: 0.0095  memory: 5160  grad_norm: 80.2566  loss: 6.8443  decode.loss_cls: 0.1181  decode.loss_mask: 0.2532  decode.loss_dice: 0.2480  decode.d0.loss_cls: 0.9726  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.2344  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.2428  decode.d2.loss_cls: 0.1125  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.2445  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.2541  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2607  decode.d5.loss_cls: 0.0802  decode.d5.loss_mask: 0.2568  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.1154  decode.d6.loss_mask: 0.2537  decode.d6.loss_dice: 0.2582  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.2486  decode.d8.loss_cls: 0.1450  decode.d8.loss_mask: 0.2458  decode.d8.loss_dice: 0.2330
09/30 13:47:29 - mmengine - INFO - Iter(train) [ 39350/320000]  base_lr: 8.8862e-05 lr: 8.8862e-06  eta: 1 day, 9:48:25  time: 0.4359  data_time: 0.0095  memory: 5147  grad_norm: 157.6536  loss: 8.4486  decode.loss_cls: 0.2185  decode.loss_mask: 0.2460  decode.loss_dice: 0.2734  decode.d0.loss_cls: 1.1543  decode.d0.loss_mask: 0.2350  decode.d0.loss_dice: 0.2277  decode.d1.loss_cls: 0.2774  decode.d1.loss_mask: 0.2573  decode.d1.loss_dice: 0.2835  decode.d2.loss_cls: 0.1811  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2732  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.1918  decode.d4.loss_mask: 0.2785  decode.d4.loss_dice: 0.3077  decode.d5.loss_cls: 0.1517  decode.d5.loss_mask: 0.2610  decode.d5.loss_dice: 0.2928  decode.d6.loss_cls: 0.2417  decode.d6.loss_mask: 0.2749  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.3325  decode.d7.loss_mask: 0.2352  decode.d7.loss_dice: 0.2500  decode.d8.loss_cls: 0.2128  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.2852
09/30 13:47:51 - mmengine - INFO - Iter(train) [ 39400/320000]  base_lr: 8.8847e-05 lr: 8.8847e-06  eta: 1 day, 9:48:04  time: 0.4360  data_time: 0.0095  memory: 5161  grad_norm: 121.8599  loss: 6.8648  decode.loss_cls: 0.0830  decode.loss_mask: 0.2663  decode.loss_dice: 0.2704  decode.d0.loss_cls: 0.8679  decode.d0.loss_mask: 0.2688  decode.d0.loss_dice: 0.2101  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.2662  decode.d1.loss_dice: 0.2337  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.2723  decode.d2.loss_dice: 0.2637  decode.d3.loss_cls: 0.0949  decode.d3.loss_mask: 0.2798  decode.d3.loss_dice: 0.2786  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.2642  decode.d4.loss_dice: 0.2669  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.2658  decode.d5.loss_dice: 0.2554  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.2671  decode.d6.loss_dice: 0.2554  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.2713  decode.d7.loss_dice: 0.2619  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.2638  decode.d8.loss_dice: 0.2613
09/30 13:48:13 - mmengine - INFO - Iter(train) [ 39450/320000]  base_lr: 8.8833e-05 lr: 8.8833e-06  eta: 1 day, 9:47:43  time: 0.4363  data_time: 0.0096  memory: 5160  grad_norm: 151.3981  loss: 7.8145  decode.loss_cls: 0.1502  decode.loss_mask: 0.4010  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.8320  decode.d0.loss_mask: 0.4199  decode.d0.loss_dice: 0.2497  decode.d1.loss_cls: 0.1141  decode.d1.loss_mask: 0.3929  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.4027  decode.d2.loss_dice: 0.2349  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.3985  decode.d3.loss_dice: 0.2340  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.4091  decode.d4.loss_dice: 0.2298  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.4113  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.3907  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.3842  decode.d7.loss_dice: 0.2246  decode.d8.loss_cls: 0.1425  decode.d8.loss_mask: 0.3880  decode.d8.loss_dice: 0.2298
09/30 13:48:35 - mmengine - INFO - Iter(train) [ 39500/320000]  base_lr: 8.8819e-05 lr: 8.8819e-06  eta: 1 day, 9:47:22  time: 0.4365  data_time: 0.0096  memory: 5145  grad_norm: 110.0975  loss: 9.0965  decode.loss_cls: 0.1709  decode.loss_mask: 0.3881  decode.loss_dice: 0.2762  decode.d0.loss_cls: 0.9668  decode.d0.loss_mask: 0.3803  decode.d0.loss_dice: 0.2933  decode.d1.loss_cls: 0.1676  decode.d1.loss_mask: 0.3884  decode.d1.loss_dice: 0.2704  decode.d2.loss_cls: 0.1099  decode.d2.loss_mask: 0.4307  decode.d2.loss_dice: 0.2819  decode.d3.loss_cls: 0.2063  decode.d3.loss_mask: 0.3616  decode.d3.loss_dice: 0.2666  decode.d4.loss_cls: 0.1987  decode.d4.loss_mask: 0.3940  decode.d4.loss_dice: 0.2809  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.3953  decode.d5.loss_dice: 0.2825  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.3841  decode.d6.loss_dice: 0.2853  decode.d7.loss_cls: 0.1463  decode.d7.loss_mask: 0.3852  decode.d7.loss_dice: 0.2825  decode.d8.loss_cls: 0.1554  decode.d8.loss_mask: 0.3907  decode.d8.loss_dice: 0.2737
09/30 13:48:57 - mmengine - INFO - Iter(train) [ 39550/320000]  base_lr: 8.8805e-05 lr: 8.8805e-06  eta: 1 day, 9:47:02  time: 0.4366  data_time: 0.0096  memory: 5180  grad_norm: 33.9775  loss: 6.1413  decode.loss_cls: 0.1048  decode.loss_mask: 0.1884  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.8813  decode.d0.loss_mask: 0.1740  decode.d0.loss_dice: 0.2344  decode.d1.loss_cls: 0.1437  decode.d1.loss_mask: 0.1770  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.1461  decode.d2.loss_mask: 0.1856  decode.d2.loss_dice: 0.2090  decode.d3.loss_cls: 0.1443  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.2190  decode.d4.loss_cls: 0.1425  decode.d4.loss_mask: 0.1770  decode.d4.loss_dice: 0.2346  decode.d5.loss_cls: 0.1548  decode.d5.loss_mask: 0.1792  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.1266  decode.d6.loss_mask: 0.1769  decode.d6.loss_dice: 0.2285  decode.d7.loss_cls: 0.1127  decode.d7.loss_mask: 0.1862  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.1024  decode.d8.loss_mask: 0.1867  decode.d8.loss_dice: 0.2371
09/30 13:49:18 - mmengine - INFO - Iter(train) [ 39600/320000]  base_lr: 8.8790e-05 lr: 8.8790e-06  eta: 1 day, 9:46:41  time: 0.4367  data_time: 0.0097  memory: 5161  grad_norm: 56.1539  loss: 7.4272  decode.loss_cls: 0.1464  decode.loss_mask: 0.2448  decode.loss_dice: 0.2656  decode.d0.loss_cls: 0.9018  decode.d0.loss_mask: 0.2505  decode.d0.loss_dice: 0.2751  decode.d1.loss_cls: 0.2030  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.2609  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 0.2443  decode.d2.loss_dice: 0.2672  decode.d3.loss_cls: 0.1500  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.2760  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.2451  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2590  decode.d6.loss_cls: 0.1489  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.2679  decode.d7.loss_cls: 0.1758  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.2854  decode.d8.loss_cls: 0.1680  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.2634
09/30 13:49:40 - mmengine - INFO - Iter(train) [ 39650/320000]  base_lr: 8.8776e-05 lr: 8.8776e-06  eta: 1 day, 9:46:20  time: 0.4368  data_time: 0.0097  memory: 5161  grad_norm: 20.9603  loss: 5.9913  decode.loss_cls: 0.0570  decode.loss_mask: 0.2021  decode.loss_dice: 0.2435  decode.d0.loss_cls: 0.8956  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.2316  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.2050  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.1041  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.2210  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.2060  decode.d4.loss_dice: 0.2059  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.2047  decode.d6.loss_dice: 0.2153  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.2210  decode.d8.loss_cls: 0.1090  decode.d8.loss_mask: 0.2046  decode.d8.loss_dice: 0.2066
09/30 13:50:02 - mmengine - INFO - Iter(train) [ 39700/320000]  base_lr: 8.8762e-05 lr: 8.8762e-06  eta: 1 day, 9:45:59  time: 0.4356  data_time: 0.0096  memory: 5160  grad_norm: 89.7487  loss: 8.0886  decode.loss_cls: 0.1450  decode.loss_mask: 0.2919  decode.loss_dice: 0.2278  decode.d0.loss_cls: 0.9152  decode.d0.loss_mask: 0.2813  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.2443  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.2195  decode.d2.loss_cls: 0.3030  decode.d2.loss_mask: 0.2809  decode.d2.loss_dice: 0.2319  decode.d3.loss_cls: 0.2432  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.2431  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.2254  decode.d5.loss_cls: 0.2010  decode.d5.loss_mask: 0.2931  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.2373  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.2435  decode.d7.loss_cls: 0.2005  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.2360  decode.d8.loss_cls: 0.1577  decode.d8.loss_mask: 0.2864  decode.d8.loss_dice: 0.2266
09/30 13:50:24 - mmengine - INFO - Iter(train) [ 39750/320000]  base_lr: 8.8748e-05 lr: 8.8748e-06  eta: 1 day, 9:45:38  time: 0.4365  data_time: 0.0096  memory: 5161  grad_norm: 84.6351  loss: 8.3060  decode.loss_cls: 0.1496  decode.loss_mask: 0.2863  decode.loss_dice: 0.2746  decode.d0.loss_cls: 1.0071  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.2339  decode.d1.loss_cls: 0.2529  decode.d1.loss_mask: 0.2855  decode.d1.loss_dice: 0.2742  decode.d2.loss_cls: 0.2310  decode.d2.loss_mask: 0.2781  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.2356  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.2417  decode.d4.loss_cls: 0.2090  decode.d4.loss_mask: 0.2831  decode.d4.loss_dice: 0.2418  decode.d5.loss_cls: 0.2100  decode.d5.loss_mask: 0.2850  decode.d5.loss_dice: 0.2609  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.2737  decode.d7.loss_cls: 0.1871  decode.d7.loss_mask: 0.2880  decode.d7.loss_dice: 0.2643  decode.d8.loss_cls: 0.1621  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.2624
09/30 13:50:46 - mmengine - INFO - Iter(train) [ 39800/320000]  base_lr: 8.8733e-05 lr: 8.8733e-06  eta: 1 day, 9:45:18  time: 0.4368  data_time: 0.0098  memory: 5161  grad_norm: 67.0197  loss: 6.8533  decode.loss_cls: 0.0693  decode.loss_mask: 0.2538  decode.loss_dice: 0.2527  decode.d0.loss_cls: 0.8877  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.2522  decode.d1.loss_cls: 0.1118  decode.d1.loss_mask: 0.2527  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.1231  decode.d2.loss_mask: 0.2580  decode.d2.loss_dice: 0.2949  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2476  decode.d4.loss_cls: 0.1096  decode.d4.loss_mask: 0.2551  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.0757  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.2640  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2579  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.2557  decode.d8.loss_dice: 0.2596
09/30 13:51:07 - mmengine - INFO - Iter(train) [ 39850/320000]  base_lr: 8.8719e-05 lr: 8.8719e-06  eta: 1 day, 9:44:57  time: 0.4366  data_time: 0.0098  memory: 5160  grad_norm: 117.9414  loss: 7.7020  decode.loss_cls: 0.0914  decode.loss_mask: 0.3362  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.9288  decode.d0.loss_mask: 0.3232  decode.d0.loss_dice: 0.2045  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.3206  decode.d1.loss_dice: 0.2359  decode.d2.loss_cls: 0.0297  decode.d2.loss_mask: 0.4658  decode.d2.loss_dice: 0.2444  decode.d3.loss_cls: 0.1441  decode.d3.loss_mask: 0.3390  decode.d3.loss_dice: 0.2087  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.3202  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.4679  decode.d5.loss_dice: 0.2255  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.4641  decode.d6.loss_dice: 0.2189  decode.d7.loss_cls: 0.0312  decode.d7.loss_mask: 0.4607  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.4722  decode.d8.loss_dice: 0.2259
09/30 13:51:29 - mmengine - INFO - Iter(train) [ 39900/320000]  base_lr: 8.8705e-05 lr: 8.8705e-06  eta: 1 day, 9:44:36  time: 0.4362  data_time: 0.0095  memory: 5161  grad_norm: 60.2531  loss: 7.1949  decode.loss_cls: 0.2021  decode.loss_mask: 0.2015  decode.loss_dice: 0.1862  decode.d0.loss_cls: 1.0286  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.2073  decode.d1.loss_cls: 0.2409  decode.d1.loss_mask: 0.2039  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.2647  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1976  decode.d3.loss_cls: 0.2470  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.1900  decode.d4.loss_cls: 0.2418  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.1912  decode.d5.loss_cls: 0.2819  decode.d5.loss_mask: 0.2029  decode.d5.loss_dice: 0.1889  decode.d6.loss_cls: 0.2330  decode.d6.loss_mask: 0.2007  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.2832  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.1840  decode.d8.loss_cls: 0.2411  decode.d8.loss_mask: 0.2020  decode.d8.loss_dice: 0.1871
09/30 13:51:51 - mmengine - INFO - Iter(train) [ 39950/320000]  base_lr: 8.8691e-05 lr: 8.8691e-06  eta: 1 day, 9:44:15  time: 0.4352  data_time: 0.0092  memory: 5161  grad_norm: 49.5056  loss: 6.4883  decode.loss_cls: 0.2030  decode.loss_mask: 0.2092  decode.loss_dice: 0.1651  decode.d0.loss_cls: 1.0363  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.1529  decode.d1.loss_cls: 0.2162  decode.d1.loss_mask: 0.2049  decode.d1.loss_dice: 0.1601  decode.d2.loss_cls: 0.2419  decode.d2.loss_mask: 0.2059  decode.d2.loss_dice: 0.1565  decode.d3.loss_cls: 0.2131  decode.d3.loss_mask: 0.2041  decode.d3.loss_dice: 0.1577  decode.d4.loss_cls: 0.1367  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.1902  decode.d5.loss_cls: 0.1695  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.1772  decode.d6.loss_cls: 0.1743  decode.d6.loss_mask: 0.2081  decode.d6.loss_dice: 0.1729  decode.d7.loss_cls: 0.1618  decode.d7.loss_mask: 0.2087  decode.d7.loss_dice: 0.1763  decode.d8.loss_cls: 0.1713  decode.d8.loss_mask: 0.2071  decode.d8.loss_dice: 0.1750
09/30 13:52:13 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 13:52:13 - mmengine - INFO - Iter(train) [ 40000/320000]  base_lr: 8.8676e-05 lr: 8.8676e-06  eta: 1 day, 9:43:54  time: 0.4362  data_time: 0.0097  memory: 5161  grad_norm: 116.0363  loss: 9.0620  decode.loss_cls: 0.1811  decode.loss_mask: 0.3599  decode.loss_dice: 0.2796  decode.d0.loss_cls: 0.8890  decode.d0.loss_mask: 0.3679  decode.d0.loss_dice: 0.2788  decode.d1.loss_cls: 0.2211  decode.d1.loss_mask: 0.3618  decode.d1.loss_dice: 0.2781  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.3572  decode.d2.loss_dice: 0.2787  decode.d3.loss_cls: 0.2337  decode.d3.loss_mask: 0.3505  decode.d3.loss_dice: 0.2894  decode.d4.loss_cls: 0.2361  decode.d4.loss_mask: 0.3603  decode.d4.loss_dice: 0.2925  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.3564  decode.d5.loss_dice: 0.2856  decode.d6.loss_cls: 0.1997  decode.d6.loss_mask: 0.3535  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 0.3571  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.1896  decode.d8.loss_mask: 0.3601  decode.d8.loss_dice: 0.2735
09/30 13:52:13 - mmengine - INFO - Saving checkpoint at 40000 iterations
09/30 13:52:28 - mmengine - INFO - Iter(val) [ 50/206]    eta: 0:00:41  time: 0.1771  data_time: 0.0045  memory: 9555  
09/30 13:52:37 - mmengine - INFO - Iter(val) [100/206]    eta: 0:00:23  time: 0.1771  data_time: 0.0044  memory: 2998  
09/30 13:52:46 - mmengine - INFO - Iter(val) [150/206]    eta: 0:00:11  time: 0.1775  data_time: 0.0045  memory: 2998  
09/30 13:52:55 - mmengine - INFO - Iter(val) [200/206]    eta: 0:00:01  time: 0.1759  data_time: 0.0039  memory: 2998  
09/30 13:52:56 - mmengine - INFO - per class results:
09/30 13:52:56 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|      background     | 98.87 | 99.25 |
|   beetroot-poriyal  |  98.0 | 99.19 |
|        bhindi       |  44.9 | 46.11 |
| capsicum-green-peas | 96.43 | 98.46 |
|     dosakay-dal     | 71.05 | 79.88 |
|    dosakaya-curry   | 95.29 | 97.99 |
|    jaipuri-sabji    | 97.57 |  98.7 |
|  ladiesfinger-curry | 97.52 | 99.36 |
|    lobiya-masala    | 96.06 |  99.1 |
|        pongal       | 95.17 | 97.48 |
|    pumpkin-gravy    | 76.83 | 77.67 |
|     pumpkin-dry     | 94.52 | 96.55 |
|     rajma-masala    | 97.98 | 98.97 |
|      tomato-dal     | 85.29 | 86.53 |
|     turai-moong     | 82.46 | 99.19 |
|     turai-tomato    | 83.58 | 85.42 |
|    beerakay-curry   | 97.16 | 98.75 |
|   cabbage-poriyal   | 97.15 | 98.74 |
|    capsicum-gravy   | 97.53 | 99.17 |
|     chana-masala    | 96.28 | 97.77 |
|      chow-chow      | 97.08 | 98.45 |
|       chutney       | 95.07 |  98.0 |
|      curd-rice      | 94.17 | 97.57 |
|         dal         | 93.91 | 98.39 |
|      dal-tadka      | 96.95 | 98.95 |
|        daliya       | 97.95 |  99.2 |
|     daliya-upma     | 96.73 | 98.95 |
|     donda-curry     | 97.35 | 98.34 |
|    dosakaya-gravy   | 95.72 | 98.14 |
|      egg-white      | 91.54 | 95.82 |
|         idly        | 96.96 | 98.79 |
|       khichdi       |  95.1 | 98.98 |
| ladies-finger-gravy | 90.59 | 99.01 |
|      methi-dal      | 97.43 | 99.04 |
|  mixed-veg-poriyal  | 93.88 | 96.72 |
|   palak-soya-curry  | 96.63 | 98.36 |
|     paneer-gravy    | 97.25 | 98.26 |
|         poha        | 96.01 | 97.23 |
|    pumpkin-masala   | 88.06 | 98.45 |
|    raw-banana-dry   | 96.48 | 97.74 |
|         rice        | 94.99 | 98.66 |
|         roti        | 95.72 | 98.98 |
|        sambar       | 97.09 | 98.92 |
|    snakegourd-dry   | 96.14 | 98.57 |
|   snakeguard-curry  |  97.8 | 98.91 |
|      soya-gravy     | 91.15 |  98.4 |
|   thotakura-pappu   | 95.38 | 98.98 |
|         upma        | 16.32 | 98.95 |
|       uttapam       |  0.0  |  0.0  |
+---------------------+-------+-------+
09/30 13:52:56 - mmengine - INFO - Iter(val) [206/206]    aAcc: 98.8100  mIoU: 89.5700  mAcc: 94.0600  data_time: 0.0067  time: 0.1987
09/30 13:52:57 - mmengine - INFO - The best checkpoint with 89.5700 mIoU at 40000 iter is saved to best_mIoU_iter_40000.pth.
09/30 13:53:24 - mmengine - INFO - Iter(train) [ 40050/320000]  base_lr: 8.8662e-05 lr: 8.8662e-06  eta: 1 day, 9:44:14  time: 0.4324  data_time: 0.0090  memory: 5145  grad_norm: 56.8491  loss: 5.8556  decode.loss_cls: 0.0777  decode.loss_mask: 0.2098  decode.loss_dice: 0.1937  decode.d0.loss_cls: 0.9357  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.1931  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.2136  decode.d1.loss_dice: 0.1930  decode.d2.loss_cls: 0.1283  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.1994  decode.d3.loss_cls: 0.1115  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.1952  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.2094  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.0980  decode.d5.loss_mask: 0.2074  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.2068  decode.d6.loss_dice: 0.1899  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.2055  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.2071  decode.d8.loss_dice: 0.2199
09/30 13:53:45 - mmengine - INFO - Iter(train) [ 40100/320000]  base_lr: 8.8648e-05 lr: 8.8648e-06  eta: 1 day, 9:43:52  time: 0.4336  data_time: 0.0090  memory: 5129  grad_norm: 26.1723  loss: 5.5690  decode.loss_cls: 0.0279  decode.loss_mask: 0.2282  decode.loss_dice: 0.1955  decode.d0.loss_cls: 0.9172  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.0397  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.1992  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.2275  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2119  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.2036  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.2228  decode.d6.loss_dice: 0.2015  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.1959  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.2250  decode.d8.loss_dice: 0.2035
09/30 13:54:07 - mmengine - INFO - Iter(train) [ 40150/320000]  base_lr: 8.8634e-05 lr: 8.8634e-06  eta: 1 day, 9:43:31  time: 0.4329  data_time: 0.0090  memory: 5129  grad_norm: 87.0231  loss: 6.5332  decode.loss_cls: 0.1455  decode.loss_mask: 0.2389  decode.loss_dice: 0.2193  decode.d0.loss_cls: 0.8466  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.2285  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2303  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2271  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 0.2456  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.2476  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.2336  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2334  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2437  decode.d8.loss_dice: 0.2341
09/30 13:54:29 - mmengine - INFO - Iter(train) [ 40200/320000]  base_lr: 8.8619e-05 lr: 8.8619e-06  eta: 1 day, 9:43:09  time: 0.4333  data_time: 0.0093  memory: 5120  grad_norm: 59.2052  loss: 6.8382  decode.loss_cls: 0.1644  decode.loss_mask: 0.2735  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.8497  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.2442  decode.d1.loss_cls: 0.1085  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.1072  decode.d2.loss_mask: 0.2744  decode.d2.loss_dice: 0.2178  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.2759  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.2775  decode.d4.loss_dice: 0.2090  decode.d5.loss_cls: 0.1392  decode.d5.loss_mask: 0.2716  decode.d5.loss_dice: 0.2165  decode.d6.loss_cls: 0.0910  decode.d6.loss_mask: 0.2771  decode.d6.loss_dice: 0.2136  decode.d7.loss_cls: 0.1159  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2225  decode.d8.loss_cls: 0.1264  decode.d8.loss_mask: 0.2722  decode.d8.loss_dice: 0.2219
09/30 13:54:50 - mmengine - INFO - Iter(train) [ 40250/320000]  base_lr: 8.8605e-05 lr: 8.8605e-06  eta: 1 day, 9:42:47  time: 0.4345  data_time: 0.0091  memory: 5129  grad_norm: 35.1544  loss: 6.4315  decode.loss_cls: 0.0415  decode.loss_mask: 0.2497  decode.loss_dice: 0.2400  decode.d0.loss_cls: 0.8465  decode.d0.loss_mask: 0.2534  decode.d0.loss_dice: 0.2311  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.2552  decode.d1.loss_dice: 0.2592  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.2629  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2483  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2474  decode.d5.loss_cls: 0.1336  decode.d5.loss_mask: 0.2500  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.0981  decode.d7.loss_mask: 0.2495  decode.d7.loss_dice: 0.2611  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.2502  decode.d8.loss_dice: 0.2517
09/30 13:55:12 - mmengine - INFO - Iter(train) [ 40300/320000]  base_lr: 8.8591e-05 lr: 8.8591e-06  eta: 1 day, 9:42:26  time: 0.4325  data_time: 0.0089  memory: 5130  grad_norm: 134.8116  loss: 7.9809  decode.loss_cls: 0.1885  decode.loss_mask: 0.2569  decode.loss_dice: 0.1999  decode.d0.loss_cls: 1.0444  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.2159  decode.d1.loss_cls: 0.2029  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.1890  decode.d2.loss_cls: 0.2090  decode.d2.loss_mask: 0.4041  decode.d2.loss_dice: 0.2115  decode.d3.loss_cls: 0.1963  decode.d3.loss_mask: 0.3154  decode.d3.loss_dice: 0.2097  decode.d4.loss_cls: 0.2253  decode.d4.loss_mask: 0.4048  decode.d4.loss_dice: 0.2093  decode.d5.loss_cls: 0.2142  decode.d5.loss_mask: 0.2586  decode.d5.loss_dice: 0.1993  decode.d6.loss_cls: 0.2512  decode.d6.loss_mask: 0.2549  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.2163  decode.d7.loss_mask: 0.2579  decode.d7.loss_dice: 0.1933  decode.d8.loss_cls: 0.2438  decode.d8.loss_mask: 0.2732  decode.d8.loss_dice: 0.2227
09/30 13:55:34 - mmengine - INFO - Iter(train) [ 40350/320000]  base_lr: 8.8577e-05 lr: 8.8577e-06  eta: 1 day, 9:42:04  time: 0.4340  data_time: 0.0091  memory: 5129  grad_norm: 53.1844  loss: 8.2001  decode.loss_cls: 0.2737  decode.loss_mask: 0.3350  decode.loss_dice: 0.2556  decode.d0.loss_cls: 0.9628  decode.d0.loss_mask: 0.2669  decode.d0.loss_dice: 0.2663  decode.d1.loss_cls: 0.2504  decode.d1.loss_mask: 0.2559  decode.d1.loss_dice: 0.2180  decode.d2.loss_cls: 0.2242  decode.d2.loss_mask: 0.2604  decode.d2.loss_dice: 0.2314  decode.d3.loss_cls: 0.2135  decode.d3.loss_mask: 0.2437  decode.d3.loss_dice: 0.2238  decode.d4.loss_cls: 0.2320  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2230  decode.d5.loss_cls: 0.2391  decode.d5.loss_mask: 0.2605  decode.d5.loss_dice: 0.2137  decode.d6.loss_cls: 0.2290  decode.d6.loss_mask: 0.2957  decode.d6.loss_dice: 0.2385  decode.d7.loss_cls: 0.2698  decode.d7.loss_mask: 0.2626  decode.d7.loss_dice: 0.2398  decode.d8.loss_cls: 0.2412  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.2439
09/30 13:55:55 - mmengine - INFO - Iter(train) [ 40400/320000]  base_lr: 8.8562e-05 lr: 8.8562e-06  eta: 1 day, 9:41:42  time: 0.4353  data_time: 0.0092  memory: 5129  grad_norm: 90.8980  loss: 5.6679  decode.loss_cls: 0.0868  decode.loss_mask: 0.2135  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.8368  decode.d0.loss_mask: 0.2146  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.1894  decode.d2.loss_cls: 0.1068  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.1833  decode.d3.loss_cls: 0.1001  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.1852  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.2156  decode.d4.loss_dice: 0.1805  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.2119  decode.d5.loss_dice: 0.1795  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.2132  decode.d6.loss_dice: 0.1822  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.1791  decode.d8.loss_cls: 0.1003  decode.d8.loss_mask: 0.2144  decode.d8.loss_dice: 0.1809
09/30 13:56:17 - mmengine - INFO - Iter(train) [ 40450/320000]  base_lr: 8.8548e-05 lr: 8.8548e-06  eta: 1 day, 9:41:21  time: 0.4361  data_time: 0.0095  memory: 5145  grad_norm: 32.4178  loss: 5.1318  decode.loss_cls: 0.0967  decode.loss_mask: 0.1847  decode.loss_dice: 0.1675  decode.d0.loss_cls: 0.7136  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.1746  decode.d2.loss_cls: 0.1039  decode.d2.loss_mask: 0.1855  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.1773  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.1855  decode.d4.loss_dice: 0.1638  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.1830  decode.d5.loss_dice: 0.1611  decode.d6.loss_cls: 0.0926  decode.d6.loss_mask: 0.1834  decode.d6.loss_dice: 0.1620  decode.d7.loss_cls: 0.0994  decode.d7.loss_mask: 0.1836  decode.d7.loss_dice: 0.1741  decode.d8.loss_cls: 0.0973  decode.d8.loss_mask: 0.1843  decode.d8.loss_dice: 0.1756
09/30 13:56:39 - mmengine - INFO - Iter(train) [ 40500/320000]  base_lr: 8.8534e-05 lr: 8.8534e-06  eta: 1 day, 9:41:00  time: 0.4350  data_time: 0.0095  memory: 5129  grad_norm: 30.4030  loss: 5.8990  decode.loss_cls: 0.1525  decode.loss_mask: 0.1987  decode.loss_dice: 0.2047  decode.d0.loss_cls: 0.8978  decode.d0.loss_mask: 0.2083  decode.d0.loss_dice: 0.2181  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 0.2053  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.2065  decode.d2.loss_dice: 0.2200  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.2139  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.2023  decode.d4.loss_dice: 0.2061  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.2035  decode.d5.loss_dice: 0.2054  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.2052  decode.d6.loss_dice: 0.2076  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.2142  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.2046  decode.d8.loss_dice: 0.2071
09/30 13:57:01 - mmengine - INFO - Iter(train) [ 40550/320000]  base_lr: 8.8520e-05 lr: 8.8520e-06  eta: 1 day, 9:40:39  time: 0.4349  data_time: 0.0092  memory: 5120  grad_norm: 79.0683  loss: 6.5548  decode.loss_cls: 0.0745  decode.loss_mask: 0.2581  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.9117  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.2395  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.2625  decode.d1.loss_dice: 0.2693  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.2632  decode.d2.loss_dice: 0.2516  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 0.2675  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.0281  decode.d4.loss_mask: 0.2618  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.0366  decode.d5.loss_mask: 0.2687  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.1132  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.2333  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.2618  decode.d8.loss_dice: 0.2426
09/30 13:57:23 - mmengine - INFO - Iter(train) [ 40600/320000]  base_lr: 8.8505e-05 lr: 8.8505e-06  eta: 1 day, 9:40:19  time: 0.4531  data_time: 0.0094  memory: 5129  grad_norm: 37.6230  loss: 5.6904  decode.loss_cls: 0.1025  decode.loss_mask: 0.1842  decode.loss_dice: 0.2102  decode.d0.loss_cls: 1.0391  decode.d0.loss_mask: 0.1874  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.1841  decode.d1.loss_dice: 0.1644  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.1826  decode.d3.loss_dice: 0.2075  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.1816  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.2012  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 0.1863  decode.d6.loss_dice: 0.2101  decode.d7.loss_cls: 0.1110  decode.d7.loss_mask: 0.1819  decode.d7.loss_dice: 0.2005  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.1835  decode.d8.loss_dice: 0.2027
09/30 13:57:44 - mmengine - INFO - Iter(train) [ 40650/320000]  base_lr: 8.8491e-05 lr: 8.8491e-06  eta: 1 day, 9:39:58  time: 0.4355  data_time: 0.0094  memory: 5145  grad_norm: 47.9950  loss: 5.9848  decode.loss_cls: 0.1036  decode.loss_mask: 0.2165  decode.loss_dice: 0.1917  decode.d0.loss_cls: 0.8712  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.2031  decode.d1.loss_cls: 0.1378  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.1836  decode.d2.loss_cls: 0.1113  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.1880  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.2167  decode.d3.loss_dice: 0.1923  decode.d4.loss_cls: 0.1153  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.1944  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.1879  decode.d6.loss_cls: 0.1194  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.2137  decode.d7.loss_dice: 0.1840  decode.d8.loss_cls: 0.1105  decode.d8.loss_mask: 0.2165  decode.d8.loss_dice: 0.1930
09/30 13:58:06 - mmengine - INFO - Iter(train) [ 40700/320000]  base_lr: 8.8477e-05 lr: 8.8477e-06  eta: 1 day, 9:39:37  time: 0.4364  data_time: 0.0095  memory: 5129  grad_norm: 28.2057  loss: 6.2614  decode.loss_cls: 0.0600  decode.loss_mask: 0.2697  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.9114  decode.d0.loss_mask: 0.2086  decode.d0.loss_dice: 0.2302  decode.d1.loss_cls: 0.1321  decode.d1.loss_mask: 0.2010  decode.d1.loss_dice: 0.2019  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.2677  decode.d2.loss_dice: 0.2124  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.2706  decode.d3.loss_dice: 0.2149  decode.d4.loss_cls: 0.1252  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.1271  decode.d5.loss_mask: 0.2086  decode.d5.loss_dice: 0.2104  decode.d6.loss_cls: 0.1129  decode.d6.loss_mask: 0.2067  decode.d6.loss_dice: 0.2009  decode.d7.loss_cls: 0.1300  decode.d7.loss_mask: 0.2056  decode.d7.loss_dice: 0.2049  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.2023  decode.d8.loss_dice: 0.1987
09/30 13:58:28 - mmengine - INFO - Iter(train) [ 40750/320000]  base_lr: 8.8463e-05 lr: 8.8463e-06  eta: 1 day, 9:39:16  time: 0.4375  data_time: 0.0092  memory: 5129  grad_norm: 94.3620  loss: 12.6965  decode.loss_cls: 0.3326  decode.loss_mask: 0.3795  decode.loss_dice: 0.3507  decode.d0.loss_cls: 0.9908  decode.d0.loss_mask: 0.4182  decode.d0.loss_dice: 0.3709  decode.d1.loss_cls: 0.4228  decode.d1.loss_mask: 0.4069  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.2635  decode.d2.loss_mask: 0.5725  decode.d2.loss_dice: 0.3419  decode.d3.loss_cls: 0.2945  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.3290  decode.d4.loss_cls: 0.2435  decode.d4.loss_mask: 0.8206  decode.d4.loss_dice: 0.3522  decode.d5.loss_cls: 0.2333  decode.d5.loss_mask: 0.7741  decode.d5.loss_dice: 0.3434  decode.d6.loss_cls: 0.2517  decode.d6.loss_mask: 0.7630  decode.d6.loss_dice: 0.3512  decode.d7.loss_cls: 0.3901  decode.d7.loss_mask: 0.3824  decode.d7.loss_dice: 0.3594  decode.d8.loss_cls: 0.3385  decode.d8.loss_mask: 0.5244  decode.d8.loss_dice: 0.3565
09/30 13:58:50 - mmengine - INFO - Iter(train) [ 40800/320000]  base_lr: 8.8448e-05 lr: 8.8448e-06  eta: 1 day, 9:38:54  time: 0.4338  data_time: 0.0090  memory: 5145  grad_norm: 81.5435  loss: 6.2950  decode.loss_cls: 0.0998  decode.loss_mask: 0.2657  decode.loss_dice: 0.1783  decode.d0.loss_cls: 0.9296  decode.d0.loss_mask: 0.2731  decode.d0.loss_dice: 0.1982  decode.d1.loss_cls: 0.1233  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.1735  decode.d2.loss_cls: 0.0894  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.1770  decode.d3.loss_cls: 0.0934  decode.d3.loss_mask: 0.2591  decode.d3.loss_dice: 0.1687  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.2618  decode.d4.loss_dice: 0.1734  decode.d5.loss_cls: 0.0960  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.1815  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0832  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.0906  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.1723
09/30 13:59:11 - mmengine - INFO - Iter(train) [ 40850/320000]  base_lr: 8.8434e-05 lr: 8.8434e-06  eta: 1 day, 9:38:33  time: 0.4343  data_time: 0.0094  memory: 5120  grad_norm: 64.8339  loss: 7.3898  decode.loss_cls: 0.0654  decode.loss_mask: 0.3082  decode.loss_dice: 0.2684  decode.d0.loss_cls: 0.8634  decode.d0.loss_mask: 0.3112  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.0762  decode.d1.loss_mask: 0.3155  decode.d1.loss_dice: 0.2851  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.3105  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.1010  decode.d3.loss_mask: 0.3087  decode.d3.loss_dice: 0.2704  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.3088  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.3153  decode.d5.loss_dice: 0.2747  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.3148  decode.d6.loss_dice: 0.2697  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.3082  decode.d7.loss_dice: 0.2649  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.3152  decode.d8.loss_dice: 0.2789
09/30 13:59:33 - mmengine - INFO - Iter(train) [ 40900/320000]  base_lr: 8.8420e-05 lr: 8.8420e-06  eta: 1 day, 9:38:11  time: 0.4340  data_time: 0.0090  memory: 5130  grad_norm: 37.0146  loss: 6.7956  decode.loss_cls: 0.1226  decode.loss_mask: 0.1869  decode.loss_dice: 0.2795  decode.d0.loss_cls: 0.9376  decode.d0.loss_mask: 0.1894  decode.d0.loss_dice: 0.2910  decode.d1.loss_cls: 0.1555  decode.d1.loss_mask: 0.1859  decode.d1.loss_dice: 0.2850  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 0.1833  decode.d2.loss_dice: 0.2849  decode.d3.loss_cls: 0.1142  decode.d3.loss_mask: 0.1868  decode.d3.loss_dice: 0.2983  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.1943  decode.d4.loss_dice: 0.2842  decode.d5.loss_cls: 0.1162  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.2876  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.1816  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.1829  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.1305  decode.d8.loss_mask: 0.1879  decode.d8.loss_dice: 0.2848
09/30 13:59:55 - mmengine - INFO - Iter(train) [ 40950/320000]  base_lr: 8.8406e-05 lr: 8.8406e-06  eta: 1 day, 9:37:49  time: 0.4337  data_time: 0.0092  memory: 5129  grad_norm: 40.4669  loss: 5.6267  decode.loss_cls: 0.0131  decode.loss_mask: 0.2885  decode.loss_dice: 0.1949  decode.d0.loss_cls: 0.6221  decode.d0.loss_mask: 0.2940  decode.d0.loss_dice: 0.1909  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.1894  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.2880  decode.d2.loss_dice: 0.1934  decode.d3.loss_cls: 0.0250  decode.d3.loss_mask: 0.2900  decode.d3.loss_dice: 0.1957  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.2924  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 0.2845  decode.d5.loss_dice: 0.1903  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.2901  decode.d6.loss_dice: 0.1925  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.1901  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.1902
09/30 14:00:17 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:00:17 - mmengine - INFO - Iter(train) [ 41000/320000]  base_lr: 8.8391e-05 lr: 8.8391e-06  eta: 1 day, 9:37:27  time: 0.4340  data_time: 0.0090  memory: 5120  grad_norm: 69.8817  loss: 6.0318  decode.loss_cls: 0.1159  decode.loss_mask: 0.2717  decode.loss_dice: 0.1773  decode.d0.loss_cls: 0.7115  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.1836  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.2738  decode.d1.loss_dice: 0.1776  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.1815  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.2709  decode.d5.loss_dice: 0.1751  decode.d6.loss_cls: 0.1119  decode.d6.loss_mask: 0.2675  decode.d6.loss_dice: 0.1818  decode.d7.loss_cls: 0.1164  decode.d7.loss_mask: 0.2683  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.2704  decode.d8.loss_dice: 0.1741
09/30 14:00:38 - mmengine - INFO - Iter(train) [ 41050/320000]  base_lr: 8.8377e-05 lr: 8.8377e-06  eta: 1 day, 9:37:06  time: 0.4351  data_time: 0.0091  memory: 5129  grad_norm: 24.6466  loss: 6.0184  decode.loss_cls: 0.0125  decode.loss_mask: 0.2914  decode.loss_dice: 0.2178  decode.d0.loss_cls: 0.8030  decode.d0.loss_mask: 0.2982  decode.d0.loss_dice: 0.2190  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.2957  decode.d1.loss_dice: 0.2098  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.2921  decode.d2.loss_dice: 0.2174  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.2923  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.2980  decode.d4.loss_dice: 0.2129  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.2164  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2943  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0099  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.2244  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.2915  decode.d8.loss_dice: 0.2101
09/30 14:01:00 - mmengine - INFO - Iter(train) [ 41100/320000]  base_lr: 8.8363e-05 lr: 8.8363e-06  eta: 1 day, 9:36:44  time: 0.4336  data_time: 0.0091  memory: 5129  grad_norm: 85.8360  loss: 5.7745  decode.loss_cls: 0.0848  decode.loss_mask: 0.2295  decode.loss_dice: 0.1993  decode.d0.loss_cls: 0.9509  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.1913  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.2461  decode.d1.loss_dice: 0.2176  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2245  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.2277  decode.d3.loss_dice: 0.2059  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.2059  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.2230  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.2365  decode.d6.loss_dice: 0.2245  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.2003
09/30 14:01:22 - mmengine - INFO - Iter(train) [ 41150/320000]  base_lr: 8.8349e-05 lr: 8.8349e-06  eta: 1 day, 9:36:23  time: 0.4338  data_time: 0.0090  memory: 5145  grad_norm: 44.7332  loss: 6.6823  decode.loss_cls: 0.1698  decode.loss_mask: 0.2237  decode.loss_dice: 0.2261  decode.d0.loss_cls: 0.8479  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2093  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.2122  decode.d2.loss_cls: 0.0890  decode.d2.loss_mask: 0.6574  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.1452  decode.d3.loss_mask: 0.2183  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.1226  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.2028  decode.d5.loss_cls: 0.1170  decode.d5.loss_mask: 0.2238  decode.d5.loss_dice: 0.2114  decode.d6.loss_cls: 0.0981  decode.d6.loss_mask: 0.2255  decode.d6.loss_dice: 0.2097  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.1991  decode.d8.loss_cls: 0.0925  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.2132
09/30 14:01:43 - mmengine - INFO - Iter(train) [ 41200/320000]  base_lr: 8.8334e-05 lr: 8.8334e-06  eta: 1 day, 9:36:01  time: 0.4346  data_time: 0.0093  memory: 5120  grad_norm: 31.1686  loss: 5.3679  decode.loss_cls: 0.0655  decode.loss_mask: 0.2184  decode.loss_dice: 0.1613  decode.d0.loss_cls: 0.9922  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.1717  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.1598  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.2111  decode.d2.loss_dice: 0.1601  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.1632  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.2134  decode.d4.loss_dice: 0.1628  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.2136  decode.d5.loss_dice: 0.1619  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.1651  decode.d8.loss_cls: 0.1184  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.1651
09/30 14:02:05 - mmengine - INFO - Iter(train) [ 41250/320000]  base_lr: 8.8320e-05 lr: 8.8320e-06  eta: 1 day, 9:35:39  time: 0.4345  data_time: 0.0093  memory: 5145  grad_norm: 33.0587  loss: 7.3864  decode.loss_cls: 0.1246  decode.loss_mask: 0.2322  decode.loss_dice: 0.3059  decode.d0.loss_cls: 0.8174  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.3110  decode.d1.loss_cls: 0.2417  decode.d1.loss_mask: 0.2273  decode.d1.loss_dice: 0.3104  decode.d2.loss_cls: 0.1190  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.3179  decode.d3.loss_cls: 0.1245  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.3000  decode.d4.loss_cls: 0.1266  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.3064  decode.d5.loss_cls: 0.1245  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.3056  decode.d6.loss_cls: 0.1132  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.3080  decode.d7.loss_cls: 0.1016  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.3164  decode.d8.loss_cls: 0.1217  decode.d8.loss_mask: 0.2235  decode.d8.loss_dice: 0.3191
09/30 14:02:27 - mmengine - INFO - Iter(train) [ 41300/320000]  base_lr: 8.8306e-05 lr: 8.8306e-06  eta: 1 day, 9:35:18  time: 0.4334  data_time: 0.0092  memory: 5145  grad_norm: 93.7625  loss: 8.2683  decode.loss_cls: 0.1936  decode.loss_mask: 0.3014  decode.loss_dice: 0.2417  decode.d0.loss_cls: 0.9337  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.2417  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 0.3066  decode.d1.loss_dice: 0.2507  decode.d2.loss_cls: 0.1644  decode.d2.loss_mask: 0.2985  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 0.3042  decode.d3.loss_dice: 0.2488  decode.d4.loss_cls: 0.2230  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.2530  decode.d5.loss_mask: 0.3000  decode.d5.loss_dice: 0.2579  decode.d6.loss_cls: 0.2200  decode.d6.loss_mask: 0.3028  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.2382  decode.d7.loss_mask: 0.3019  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.1799  decode.d8.loss_mask: 0.3010  decode.d8.loss_dice: 0.2587
09/30 14:02:49 - mmengine - INFO - Iter(train) [ 41350/320000]  base_lr: 8.8292e-05 lr: 8.8292e-06  eta: 1 day, 9:34:56  time: 0.4340  data_time: 0.0091  memory: 5129  grad_norm: 45.6992  loss: 7.2872  decode.loss_cls: 0.1601  decode.loss_mask: 0.2991  decode.loss_dice: 0.1974  decode.d0.loss_cls: 0.9335  decode.d0.loss_mask: 0.2970  decode.d0.loss_dice: 0.2059  decode.d1.loss_cls: 0.1931  decode.d1.loss_mask: 0.3000  decode.d1.loss_dice: 0.2008  decode.d2.loss_cls: 0.1335  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.2058  decode.d3.loss_cls: 0.1777  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.1920  decode.d4.loss_mask: 0.2930  decode.d4.loss_dice: 0.2005  decode.d5.loss_cls: 0.1359  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.2352  decode.d6.loss_cls: 0.1069  decode.d6.loss_mask: 0.2948  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 0.2930  decode.d7.loss_dice: 0.2081  decode.d8.loss_cls: 0.1167  decode.d8.loss_mask: 0.2889  decode.d8.loss_dice: 0.2042
09/30 14:03:10 - mmengine - INFO - Iter(train) [ 41400/320000]  base_lr: 8.8277e-05 lr: 8.8277e-06  eta: 1 day, 9:34:34  time: 0.4339  data_time: 0.0092  memory: 5145  grad_norm: 75.2208  loss: 7.7261  decode.loss_cls: 0.0292  decode.loss_mask: 0.4447  decode.loss_dice: 0.2232  decode.d0.loss_cls: 0.8294  decode.d0.loss_mask: 0.3689  decode.d0.loss_dice: 0.2138  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.3761  decode.d1.loss_dice: 0.2363  decode.d2.loss_cls: 0.1268  decode.d2.loss_mask: 0.3671  decode.d2.loss_dice: 0.2101  decode.d3.loss_cls: 0.1186  decode.d3.loss_mask: 0.3846  decode.d3.loss_dice: 0.2182  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.0331  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 0.2279  decode.d6.loss_cls: 0.0996  decode.d6.loss_mask: 0.3641  decode.d6.loss_dice: 0.2104  decode.d7.loss_cls: 0.1057  decode.d7.loss_mask: 0.3610  decode.d7.loss_dice: 0.2148  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 0.3791  decode.d8.loss_dice: 0.2196
09/30 14:03:32 - mmengine - INFO - Iter(train) [ 41450/320000]  base_lr: 8.8263e-05 lr: 8.8263e-06  eta: 1 day, 9:34:13  time: 0.4337  data_time: 0.0093  memory: 5120  grad_norm: 56.3040  loss: 8.9912  decode.loss_cls: 0.1926  decode.loss_mask: 0.2806  decode.loss_dice: 0.2956  decode.d0.loss_cls: 1.1292  decode.d0.loss_mask: 0.2834  decode.d0.loss_dice: 0.3021  decode.d1.loss_cls: 0.2444  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.3604  decode.d2.loss_cls: 0.2193  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.1773  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.3004  decode.d4.loss_cls: 0.2104  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.3420  decode.d5.loss_cls: 0.1835  decode.d5.loss_mask: 0.2808  decode.d5.loss_dice: 0.3217  decode.d6.loss_cls: 0.2382  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.2925  decode.d7.loss_cls: 0.2318  decode.d7.loss_mask: 0.2798  decode.d7.loss_dice: 0.2963  decode.d8.loss_cls: 0.2372  decode.d8.loss_mask: 0.2800  decode.d8.loss_dice: 0.3173
09/30 14:03:54 - mmengine - INFO - Iter(train) [ 41500/320000]  base_lr: 8.8249e-05 lr: 8.8249e-06  eta: 1 day, 9:33:51  time: 0.4339  data_time: 0.0091  memory: 5129  grad_norm: 38.1952  loss: 6.2061  decode.loss_cls: 0.0785  decode.loss_mask: 0.2213  decode.loss_dice: 0.2283  decode.d0.loss_cls: 0.8804  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.2537  decode.d1.loss_cls: 0.1116  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.2579  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.2232  decode.d2.loss_dice: 0.2474  decode.d3.loss_cls: 0.1093  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.2625  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.2447  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.2207  decode.d6.loss_dice: 0.2392  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.2328  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.2237  decode.d8.loss_dice: 0.2376
09/30 14:04:15 - mmengine - INFO - Iter(train) [ 41550/320000]  base_lr: 8.8235e-05 lr: 8.8235e-06  eta: 1 day, 9:33:29  time: 0.4338  data_time: 0.0092  memory: 5129  grad_norm: 42.5632  loss: 5.9993  decode.loss_cls: 0.0209  decode.loss_mask: 0.2489  decode.loss_dice: 0.2156  decode.d0.loss_cls: 0.9361  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.2283  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.2537  decode.d1.loss_dice: 0.2278  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.2221  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.2513  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.2523  decode.d4.loss_dice: 0.2293  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2580  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2229  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.2290  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.2259
09/30 14:04:37 - mmengine - INFO - Iter(train) [ 41600/320000]  base_lr: 8.8220e-05 lr: 8.8220e-06  eta: 1 day, 9:33:08  time: 0.4342  data_time: 0.0092  memory: 5145  grad_norm: 59.7792  loss: 6.9415  decode.loss_cls: 0.1063  decode.loss_mask: 0.2914  decode.loss_dice: 0.2134  decode.d0.loss_cls: 0.8149  decode.d0.loss_mask: 0.2974  decode.d0.loss_dice: 0.2108  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 0.2928  decode.d1.loss_dice: 0.2041  decode.d2.loss_cls: 0.1114  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.1216  decode.d3.loss_mask: 0.2884  decode.d3.loss_dice: 0.2138  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.2163  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.2131  decode.d6.loss_cls: 0.1503  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.2034  decode.d7.loss_cls: 0.1078  decode.d7.loss_mask: 0.2919  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.1375  decode.d8.loss_mask: 0.2925  decode.d8.loss_dice: 0.2020
09/30 14:04:59 - mmengine - INFO - Iter(train) [ 41650/320000]  base_lr: 8.8206e-05 lr: 8.8206e-06  eta: 1 day, 9:32:46  time: 0.4342  data_time: 0.0090  memory: 5129  grad_norm: 106.1490  loss: 5.6307  decode.loss_cls: 0.0750  decode.loss_mask: 0.2280  decode.loss_dice: 0.1725  decode.d0.loss_cls: 0.8509  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.1990  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.1774  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.1806  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.1804  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.1741  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.1785  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.1779  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.1749  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.2286  decode.d8.loss_dice: 0.1807
09/30 14:05:20 - mmengine - INFO - Iter(train) [ 41700/320000]  base_lr: 8.8192e-05 lr: 8.8192e-06  eta: 1 day, 9:32:25  time: 0.4355  data_time: 0.0095  memory: 5129  grad_norm: 27.4994  loss: 5.0207  decode.loss_cls: 0.0278  decode.loss_mask: 0.2168  decode.loss_dice: 0.1773  decode.d0.loss_cls: 0.7646  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.1857  decode.d1.loss_cls: 0.0278  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.1827  decode.d2.loss_cls: 0.0284  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.1803  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.2178  decode.d3.loss_dice: 0.1748  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1764  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.1795  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.2157  decode.d7.loss_dice: 0.1803  decode.d8.loss_cls: 0.0280  decode.d8.loss_mask: 0.2156  decode.d8.loss_dice: 0.1762
09/30 14:05:42 - mmengine - INFO - Iter(train) [ 41750/320000]  base_lr: 8.8178e-05 lr: 8.8178e-06  eta: 1 day, 9:32:04  time: 0.4337  data_time: 0.0090  memory: 5145  grad_norm: 34.0037  loss: 7.0870  decode.loss_cls: 0.1055  decode.loss_mask: 0.3034  decode.loss_dice: 0.2007  decode.d0.loss_cls: 0.9022  decode.d0.loss_mask: 0.2666  decode.d0.loss_dice: 0.2078  decode.d1.loss_cls: 0.1499  decode.d1.loss_mask: 0.2916  decode.d1.loss_dice: 0.2086  decode.d2.loss_cls: 0.1474  decode.d2.loss_mask: 0.2881  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.1984  decode.d3.loss_mask: 0.2586  decode.d3.loss_dice: 0.2059  decode.d4.loss_cls: 0.1493  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.1865  decode.d5.loss_mask: 0.2499  decode.d5.loss_dice: 0.1970  decode.d6.loss_cls: 0.1660  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.2020  decode.d7.loss_cls: 0.1811  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.2028  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.2058
09/30 14:06:04 - mmengine - INFO - Iter(train) [ 41800/320000]  base_lr: 8.8163e-05 lr: 8.8163e-06  eta: 1 day, 9:31:42  time: 0.4355  data_time: 0.0091  memory: 5129  grad_norm: 76.9730  loss: 7.4190  decode.loss_cls: 0.1009  decode.loss_mask: 0.2705  decode.loss_dice: 0.3068  decode.d0.loss_cls: 0.8976  decode.d0.loss_mask: 0.2482  decode.d0.loss_dice: 0.3176  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 0.2493  decode.d1.loss_dice: 0.2890  decode.d2.loss_cls: 0.1205  decode.d2.loss_mask: 0.2562  decode.d2.loss_dice: 0.2940  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.3084  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.2982  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.3133  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.3036  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.2710  decode.d8.loss_dice: 0.3053
09/30 14:06:26 - mmengine - INFO - Iter(train) [ 41850/320000]  base_lr: 8.8149e-05 lr: 8.8149e-06  eta: 1 day, 9:31:21  time: 0.4348  data_time: 0.0093  memory: 5129  grad_norm: 47.5531  loss: 5.6061  decode.loss_cls: 0.0591  decode.loss_mask: 0.2478  decode.loss_dice: 0.1854  decode.d0.loss_cls: 0.6609  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.1824  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.2472  decode.d1.loss_dice: 0.1818  decode.d2.loss_cls: 0.0858  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.1859  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.1821  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.1850  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.2491  decode.d6.loss_dice: 0.1797  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.2497  decode.d7.loss_dice: 0.1805  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.1800
09/30 14:06:47 - mmengine - INFO - Iter(train) [ 41900/320000]  base_lr: 8.8135e-05 lr: 8.8135e-06  eta: 1 day, 9:30:59  time: 0.4343  data_time: 0.0090  memory: 5145  grad_norm: 24.8353  loss: 4.9645  decode.loss_cls: 0.0882  decode.loss_mask: 0.1914  decode.loss_dice: 0.1722  decode.d0.loss_cls: 0.7976  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.1933  decode.d1.loss_cls: 0.0338  decode.d1.loss_mask: 0.1975  decode.d1.loss_dice: 0.1868  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.1962  decode.d3.loss_dice: 0.1783  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0373  decode.d5.loss_mask: 0.1956  decode.d5.loss_dice: 0.1747  decode.d6.loss_cls: 0.0428  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.1955  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.1810
09/30 14:07:09 - mmengine - INFO - Iter(train) [ 41950/320000]  base_lr: 8.8120e-05 lr: 8.8120e-06  eta: 1 day, 9:30:38  time: 0.4345  data_time: 0.0093  memory: 5129  grad_norm: 190.7849  loss: 6.5368  decode.loss_cls: 0.0369  decode.loss_mask: 0.2695  decode.loss_dice: 0.1991  decode.d0.loss_cls: 0.9556  decode.d0.loss_mask: 0.2631  decode.d0.loss_dice: 0.1935  decode.d1.loss_cls: 0.0832  decode.d1.loss_mask: 0.3183  decode.d1.loss_dice: 0.2068  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.2964  decode.d2.loss_dice: 0.2031  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.2015  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 0.2843  decode.d4.loss_dice: 0.2022  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.2731  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.2029  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.2008  decode.d8.loss_cls: 0.1237  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.1954
09/30 14:07:31 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:07:31 - mmengine - INFO - Iter(train) [ 42000/320000]  base_lr: 8.8106e-05 lr: 8.8106e-06  eta: 1 day, 9:30:17  time: 0.4351  data_time: 0.0093  memory: 5145  grad_norm: 59.0886  loss: 7.7561  decode.loss_cls: 0.0772  decode.loss_mask: 0.3658  decode.loss_dice: 0.2533  decode.d0.loss_cls: 0.8932  decode.d0.loss_mask: 0.3730  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.3613  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.3665  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.3710  decode.d3.loss_dice: 0.2534  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.3633  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.3667  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.3702  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.3641  decode.d7.loss_dice: 0.2496  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 0.3651  decode.d8.loss_dice: 0.2530
09/30 14:07:53 - mmengine - INFO - Iter(train) [ 42050/320000]  base_lr: 8.8092e-05 lr: 8.8092e-06  eta: 1 day, 9:29:55  time: 0.4353  data_time: 0.0093  memory: 5129  grad_norm: 52.8727  loss: 5.7265  decode.loss_cls: 0.0161  decode.loss_mask: 0.2487  decode.loss_dice: 0.2155  decode.d0.loss_cls: 0.7888  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2335  decode.d1.loss_cls: 0.0465  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2328  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.2425  decode.d3.loss_dice: 0.2256  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.2456  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.2190  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.2466  decode.d7.loss_dice: 0.2240  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2222
09/30 14:08:14 - mmengine - INFO - Iter(train) [ 42100/320000]  base_lr: 8.8078e-05 lr: 8.8078e-06  eta: 1 day, 9:29:34  time: 0.4343  data_time: 0.0092  memory: 5129  grad_norm: 62.2648  loss: 6.5922  decode.loss_cls: 0.1688  decode.loss_mask: 0.2182  decode.loss_dice: 0.1854  decode.d0.loss_cls: 1.1321  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.1935  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 0.2309  decode.d1.loss_dice: 0.2107  decode.d2.loss_cls: 0.1352  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.1875  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.1920  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.2201  decode.d4.loss_dice: 0.1954  decode.d5.loss_cls: 0.1866  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.1922  decode.d6.loss_cls: 0.1468  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.1960  decode.d7.loss_cls: 0.1387  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.1927  decode.d8.loss_cls: 0.1256  decode.d8.loss_mask: 0.2156  decode.d8.loss_dice: 0.1904
09/30 14:08:36 - mmengine - INFO - Iter(train) [ 42150/320000]  base_lr: 8.8063e-05 lr: 8.8063e-06  eta: 1 day, 9:29:12  time: 0.4352  data_time: 0.0095  memory: 5129  grad_norm: 72.7416  loss: 6.5115  decode.loss_cls: 0.1582  decode.loss_mask: 0.2277  decode.loss_dice: 0.1947  decode.d0.loss_cls: 0.9929  decode.d0.loss_mask: 0.2175  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.1242  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.1768  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.2053  decode.d3.loss_cls: 0.1903  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.1859  decode.d4.loss_cls: 0.1629  decode.d4.loss_mask: 0.2276  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.1616  decode.d5.loss_mask: 0.2193  decode.d5.loss_dice: 0.1883  decode.d6.loss_cls: 0.1613  decode.d6.loss_mask: 0.2252  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.1534  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.1537  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.1926
09/30 14:08:58 - mmengine - INFO - Iter(train) [ 42200/320000]  base_lr: 8.8049e-05 lr: 8.8049e-06  eta: 1 day, 9:28:51  time: 0.4340  data_time: 0.0091  memory: 5129  grad_norm: 70.5209  loss: 7.4969  decode.loss_cls: 0.1334  decode.loss_mask: 0.2055  decode.loss_dice: 0.2558  decode.d0.loss_cls: 1.0403  decode.d0.loss_mask: 0.2028  decode.d0.loss_dice: 0.2879  decode.d1.loss_cls: 0.1897  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.2855  decode.d2.loss_cls: 0.2109  decode.d2.loss_mask: 0.2072  decode.d2.loss_dice: 0.2969  decode.d3.loss_cls: 0.1897  decode.d3.loss_mask: 0.2017  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.1957  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2771  decode.d5.loss_cls: 0.1896  decode.d5.loss_mask: 0.2037  decode.d5.loss_dice: 0.2924  decode.d6.loss_cls: 0.1803  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.2721  decode.d7.loss_cls: 0.1578  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.2845  decode.d8.loss_cls: 0.1471  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2827
09/30 14:09:20 - mmengine - INFO - Iter(train) [ 42250/320000]  base_lr: 8.8035e-05 lr: 8.8035e-06  eta: 1 day, 9:28:31  time: 0.4539  data_time: 0.0094  memory: 5129  grad_norm: 143.6088  loss: 9.0580  decode.loss_cls: 0.2319  decode.loss_mask: 0.3890  decode.loss_dice: 0.3056  decode.d0.loss_cls: 1.0242  decode.d0.loss_mask: 0.2937  decode.d0.loss_dice: 0.3031  decode.d1.loss_cls: 0.1667  decode.d1.loss_mask: 0.3294  decode.d1.loss_dice: 0.2567  decode.d2.loss_cls: 0.1667  decode.d2.loss_mask: 0.3381  decode.d2.loss_dice: 0.2623  decode.d3.loss_cls: 0.2077  decode.d3.loss_mask: 0.3246  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.2232  decode.d4.loss_mask: 0.3163  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.2469  decode.d5.loss_mask: 0.3463  decode.d5.loss_dice: 0.2609  decode.d6.loss_cls: 0.2179  decode.d6.loss_mask: 0.3819  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.2163  decode.d7.loss_mask: 0.3450  decode.d7.loss_dice: 0.2675  decode.d8.loss_cls: 0.2000  decode.d8.loss_mask: 0.3676  decode.d8.loss_dice: 0.2745
09/30 14:09:42 - mmengine - INFO - Iter(train) [ 42300/320000]  base_lr: 8.8021e-05 lr: 8.8021e-06  eta: 1 day, 9:28:10  time: 0.4358  data_time: 0.0093  memory: 5145  grad_norm: 51.9455  loss: 6.3811  decode.loss_cls: 0.0518  decode.loss_mask: 0.2448  decode.loss_dice: 0.2379  decode.d0.loss_cls: 0.8077  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.2457  decode.d1.loss_cls: 0.1355  decode.d1.loss_mask: 0.2481  decode.d1.loss_dice: 0.2320  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.2517  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2391  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.2517  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.2397  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.2541  decode.d7.loss_dice: 0.2342  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2433
09/30 14:10:03 - mmengine - INFO - Iter(train) [ 42350/320000]  base_lr: 8.8006e-05 lr: 8.8006e-06  eta: 1 day, 9:27:48  time: 0.4347  data_time: 0.0095  memory: 5145  grad_norm: 69.5453  loss: 6.6521  decode.loss_cls: 0.1002  decode.loss_mask: 0.3232  decode.loss_dice: 0.1990  decode.d0.loss_cls: 0.6931  decode.d0.loss_mask: 0.3307  decode.d0.loss_dice: 0.2039  decode.d1.loss_cls: 0.0288  decode.d1.loss_mask: 0.3196  decode.d1.loss_dice: 0.2041  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.3194  decode.d2.loss_dice: 0.2012  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.3258  decode.d3.loss_dice: 0.2048  decode.d4.loss_cls: 0.0896  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.0995  decode.d5.loss_mask: 0.3241  decode.d5.loss_dice: 0.2017  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.3216  decode.d6.loss_dice: 0.2021  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.3220  decode.d7.loss_dice: 0.2012  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.3232  decode.d8.loss_dice: 0.1951
09/30 14:10:25 - mmengine - INFO - Iter(train) [ 42400/320000]  base_lr: 8.7992e-05 lr: 8.7992e-06  eta: 1 day, 9:27:27  time: 0.4353  data_time: 0.0093  memory: 5129  grad_norm: 26.8580  loss: 5.3373  decode.loss_cls: 0.0925  decode.loss_mask: 0.1933  decode.loss_dice: 0.1704  decode.d0.loss_cls: 0.8554  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.1256  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.1592  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.1944  decode.d2.loss_dice: 0.1841  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.1895  decode.d3.loss_dice: 0.1533  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 0.1908  decode.d4.loss_dice: 0.1549  decode.d5.loss_cls: 0.1153  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.1563  decode.d6.loss_cls: 0.0948  decode.d6.loss_mask: 0.1924  decode.d6.loss_dice: 0.1579  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.1917  decode.d7.loss_dice: 0.1629  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.1917  decode.d8.loss_dice: 0.1645
09/30 14:10:47 - mmengine - INFO - Iter(train) [ 42450/320000]  base_lr: 8.7978e-05 lr: 8.7978e-06  eta: 1 day, 9:27:06  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 141.1149  loss: 8.0399  decode.loss_cls: 0.2202  decode.loss_mask: 0.2204  decode.loss_dice: 0.2828  decode.d0.loss_cls: 0.9200  decode.d0.loss_mask: 0.2301  decode.d0.loss_dice: 0.2942  decode.d1.loss_cls: 0.2608  decode.d1.loss_mask: 0.2163  decode.d1.loss_dice: 0.2662  decode.d2.loss_cls: 0.2602  decode.d2.loss_mask: 0.2215  decode.d2.loss_dice: 0.2622  decode.d3.loss_cls: 0.2653  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.2633  decode.d4.loss_cls: 0.2771  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2710  decode.d5.loss_cls: 0.2579  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.2209  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.2605  decode.d7.loss_cls: 0.2374  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.2342  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.2503
09/30 14:11:09 - mmengine - INFO - Iter(train) [ 42500/320000]  base_lr: 8.7964e-05 lr: 8.7964e-06  eta: 1 day, 9:26:45  time: 0.4353  data_time: 0.0096  memory: 5129  grad_norm: 133.1545  loss: 6.3976  decode.loss_cls: 0.0873  decode.loss_mask: 0.2633  decode.loss_dice: 0.2073  decode.d0.loss_cls: 0.8263  decode.d0.loss_mask: 0.2633  decode.d0.loss_dice: 0.2120  decode.d1.loss_cls: 0.0719  decode.d1.loss_mask: 0.2604  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.2615  decode.d2.loss_dice: 0.2234  decode.d3.loss_cls: 0.0917  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.2189  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2147  decode.d5.loss_cls: 0.0949  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.2042  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.1234  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.2610  decode.d8.loss_dice: 0.1965
09/30 14:11:31 - mmengine - INFO - Iter(train) [ 42550/320000]  base_lr: 8.7949e-05 lr: 8.7949e-06  eta: 1 day, 9:26:24  time: 0.4336  data_time: 0.0093  memory: 5129  grad_norm: 105.8943  loss: 6.0905  decode.loss_cls: 0.0482  decode.loss_mask: 0.2367  decode.loss_dice: 0.2177  decode.d0.loss_cls: 0.8625  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.2162  decode.d2.loss_cls: 0.1198  decode.d2.loss_mask: 0.2317  decode.d2.loss_dice: 0.2135  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2060  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.2325  decode.d4.loss_dice: 0.1947  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2160  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 0.2348  decode.d8.loss_dice: 0.2048
09/30 14:11:52 - mmengine - INFO - Iter(train) [ 42600/320000]  base_lr: 8.7935e-05 lr: 8.7935e-06  eta: 1 day, 9:26:02  time: 0.4354  data_time: 0.0093  memory: 5145  grad_norm: 125.4320  loss: 9.8731  decode.loss_cls: 0.3505  decode.loss_mask: 0.2465  decode.loss_dice: 0.3138  decode.d0.loss_cls: 1.0310  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.3020  decode.d1.loss_cls: 0.3757  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.3108  decode.d2.loss_cls: 0.3842  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.2986  decode.d3.loss_cls: 0.4008  decode.d3.loss_mask: 0.2462  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 0.3914  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.3072  decode.d5.loss_cls: 0.3974  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.2992  decode.d6.loss_cls: 0.3436  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.2900  decode.d7.loss_cls: 0.3414  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.3054  decode.d8.loss_cls: 0.3671  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.2999
09/30 14:12:14 - mmengine - INFO - Iter(train) [ 42650/320000]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 1 day, 9:25:41  time: 0.4352  data_time: 0.0094  memory: 5129  grad_norm: 120.2449  loss: 8.1112  decode.loss_cls: 0.1287  decode.loss_mask: 0.3430  decode.loss_dice: 0.2548  decode.d0.loss_cls: 1.0332  decode.d0.loss_mask: 0.3365  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.1384  decode.d1.loss_mask: 0.3390  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.1528  decode.d2.loss_mask: 0.3547  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.3388  decode.d3.loss_dice: 0.2356  decode.d4.loss_cls: 0.1200  decode.d4.loss_mask: 0.3411  decode.d4.loss_dice: 0.2417  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.3472  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.1339  decode.d6.loss_mask: 0.3356  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.1287  decode.d7.loss_mask: 0.3316  decode.d7.loss_dice: 0.2397  decode.d8.loss_cls: 0.1458  decode.d8.loss_mask: 0.3393  decode.d8.loss_dice: 0.2532
09/30 14:12:36 - mmengine - INFO - Iter(train) [ 42700/320000]  base_lr: 8.7907e-05 lr: 8.7907e-06  eta: 1 day, 9:25:20  time: 0.4350  data_time: 0.0091  memory: 5145  grad_norm: 34.6705  loss: 5.9117  decode.loss_cls: 0.0419  decode.loss_mask: 0.2528  decode.loss_dice: 0.2079  decode.d0.loss_cls: 0.8975  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.2540  decode.d1.loss_dice: 0.2090  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.2531  decode.d2.loss_dice: 0.2062  decode.d3.loss_cls: 0.0470  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.2034  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.2096  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.2514  decode.d5.loss_dice: 0.2017  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2034  decode.d7.loss_cls: 0.0484  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.2514  decode.d8.loss_dice: 0.2068
09/30 14:12:58 - mmengine - INFO - Iter(train) [ 42750/320000]  base_lr: 8.7892e-05 lr: 8.7892e-06  eta: 1 day, 9:24:59  time: 0.4350  data_time: 0.0093  memory: 5145  grad_norm: 36.4305  loss: 6.2517  decode.loss_cls: 0.0767  decode.loss_mask: 0.2070  decode.loss_dice: 0.1992  decode.d0.loss_cls: 1.1114  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.2132  decode.d1.loss_cls: 0.1494  decode.d1.loss_mask: 0.2079  decode.d1.loss_dice: 0.2299  decode.d2.loss_cls: 0.0684  decode.d2.loss_mask: 0.2081  decode.d2.loss_dice: 0.2232  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.1991  decode.d4.loss_cls: 0.1167  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.2157  decode.d5.loss_cls: 0.1295  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.2041  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.2230  decode.d7.loss_cls: 0.1231  decode.d7.loss_mask: 0.2067  decode.d7.loss_dice: 0.2074  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.2080  decode.d8.loss_dice: 0.1881
09/30 14:13:19 - mmengine - INFO - Iter(train) [ 42800/320000]  base_lr: 8.7878e-05 lr: 8.7878e-06  eta: 1 day, 9:24:37  time: 0.4354  data_time: 0.0095  memory: 5145  grad_norm: 32.3223  loss: 6.0758  decode.loss_cls: 0.0539  decode.loss_mask: 0.2763  decode.loss_dice: 0.1893  decode.d0.loss_cls: 0.7372  decode.d0.loss_mask: 0.2857  decode.d0.loss_dice: 0.1892  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.2772  decode.d1.loss_dice: 0.1848  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.2791  decode.d4.loss_dice: 0.1860  decode.d5.loss_cls: 0.0584  decode.d5.loss_mask: 0.2790  decode.d5.loss_dice: 0.1912  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.2789  decode.d6.loss_dice: 0.1879  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.2774  decode.d7.loss_dice: 0.1907  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.2775  decode.d8.loss_dice: 0.1915
09/30 14:13:41 - mmengine - INFO - Iter(train) [ 42850/320000]  base_lr: 8.7864e-05 lr: 8.7864e-06  eta: 1 day, 9:24:16  time: 0.4350  data_time: 0.0092  memory: 5145  grad_norm: 32.7812  loss: 5.3729  decode.loss_cls: 0.0202  decode.loss_mask: 0.2183  decode.loss_dice: 0.1838  decode.d0.loss_cls: 0.9284  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.1803  decode.d1.loss_cls: 0.0777  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.2215  decode.d2.loss_dice: 0.1859  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.1767  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.1830  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.2168  decode.d5.loss_dice: 0.1856  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.2181  decode.d6.loss_dice: 0.1814  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.2133  decode.d7.loss_dice: 0.1785  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.2167  decode.d8.loss_dice: 0.1868
09/30 14:14:03 - mmengine - INFO - Iter(train) [ 42900/320000]  base_lr: 8.7849e-05 lr: 8.7849e-06  eta: 1 day, 9:23:55  time: 0.4348  data_time: 0.0093  memory: 5120  grad_norm: 99.8693  loss: 5.9348  decode.loss_cls: 0.1087  decode.loss_mask: 0.2094  decode.loss_dice: 0.2113  decode.d0.loss_cls: 0.8386  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2089  decode.d1.loss_cls: 0.1065  decode.d1.loss_mask: 0.2099  decode.d1.loss_dice: 0.1978  decode.d2.loss_cls: 0.0905  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.2019  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.1934  decode.d4.loss_cls: 0.1008  decode.d4.loss_mask: 0.2112  decode.d4.loss_dice: 0.1963  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.2127  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 0.2127  decode.d6.loss_dice: 0.2099  decode.d7.loss_cls: 0.1505  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.1816  decode.d8.loss_cls: 0.1096  decode.d8.loss_mask: 0.2096  decode.d8.loss_dice: 0.2078
09/30 14:14:25 - mmengine - INFO - Iter(train) [ 42950/320000]  base_lr: 8.7835e-05 lr: 8.7835e-06  eta: 1 day, 9:23:33  time: 0.4335  data_time: 0.0091  memory: 5145  grad_norm: 33.2203  loss: 6.1462  decode.loss_cls: 0.1593  decode.loss_mask: 0.1875  decode.loss_dice: 0.1784  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.2096  decode.d1.loss_cls: 0.2003  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.1755  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.1779  decode.d3.loss_mask: 0.1922  decode.d3.loss_dice: 0.2004  decode.d4.loss_cls: 0.1636  decode.d4.loss_mask: 0.1927  decode.d4.loss_dice: 0.2007  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.1967  decode.d5.loss_dice: 0.2058  decode.d6.loss_cls: 0.1583  decode.d6.loss_mask: 0.1900  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 0.1873  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.1737  decode.d8.loss_mask: 0.1904  decode.d8.loss_dice: 0.1824
09/30 14:14:46 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:14:46 - mmengine - INFO - Iter(train) [ 43000/320000]  base_lr: 8.7821e-05 lr: 8.7821e-06  eta: 1 day, 9:23:12  time: 0.4355  data_time: 0.0093  memory: 5129  grad_norm: 131.9105  loss: 5.9866  decode.loss_cls: 0.1304  decode.loss_mask: 0.2130  decode.loss_dice: 0.1882  decode.d0.loss_cls: 0.8576  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.1895  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.0896  decode.d2.loss_mask: 0.2092  decode.d2.loss_dice: 0.1948  decode.d3.loss_cls: 0.1106  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.1296  decode.d4.loss_mask: 0.2122  decode.d4.loss_dice: 0.1906  decode.d5.loss_cls: 0.1273  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.1974  decode.d6.loss_cls: 0.1420  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.1900  decode.d7.loss_cls: 0.1466  decode.d7.loss_mask: 0.2132  decode.d7.loss_dice: 0.1982  decode.d8.loss_cls: 0.0977  decode.d8.loss_mask: 0.2093  decode.d8.loss_dice: 0.1876
09/30 14:15:08 - mmengine - INFO - Iter(train) [ 43050/320000]  base_lr: 8.7807e-05 lr: 8.7807e-06  eta: 1 day, 9:22:51  time: 0.4366  data_time: 0.0095  memory: 5129  grad_norm: 45.2917  loss: 5.8712  decode.loss_cls: 0.0348  decode.loss_mask: 0.2439  decode.loss_dice: 0.1927  decode.d0.loss_cls: 0.9845  decode.d0.loss_mask: 0.2458  decode.d0.loss_dice: 0.1973  decode.d1.loss_cls: 0.1629  decode.d1.loss_mask: 0.2408  decode.d1.loss_dice: 0.1834  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.1901  decode.d3.loss_cls: 0.0328  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.1917  decode.d4.loss_cls: 0.0835  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.2565  decode.d5.loss_dice: 0.2029  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.1912  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.2464  decode.d8.loss_dice: 0.1880
09/30 14:15:30 - mmengine - INFO - Iter(train) [ 43100/320000]  base_lr: 8.7792e-05 lr: 8.7792e-06  eta: 1 day, 9:22:29  time: 0.4347  data_time: 0.0090  memory: 5129  grad_norm: 28.8189  loss: 4.9313  decode.loss_cls: 0.0304  decode.loss_mask: 0.2080  decode.loss_dice: 0.1688  decode.d0.loss_cls: 0.8778  decode.d0.loss_mask: 0.2040  decode.d0.loss_dice: 0.1669  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.2048  decode.d1.loss_dice: 0.1647  decode.d2.loss_cls: 0.0206  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.1664  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.1667  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.2058  decode.d4.loss_dice: 0.1706  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.2058  decode.d5.loss_dice: 0.1671  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.1722  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.1710  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.1724
09/30 14:15:52 - mmengine - INFO - Iter(train) [ 43150/320000]  base_lr: 8.7778e-05 lr: 8.7778e-06  eta: 1 day, 9:22:08  time: 0.4339  data_time: 0.0091  memory: 5129  grad_norm: 41.0104  loss: 7.1331  decode.loss_cls: 0.2223  decode.loss_mask: 0.1971  decode.loss_dice: 0.2389  decode.d0.loss_cls: 0.9781  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.2277  decode.d1.loss_cls: 0.1890  decode.d1.loss_mask: 0.1974  decode.d1.loss_dice: 0.2186  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 0.2000  decode.d2.loss_dice: 0.2403  decode.d3.loss_cls: 0.1875  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.2451  decode.d4.loss_cls: 0.2285  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.2361  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.2316  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.2119  decode.d6.loss_dice: 0.2249  decode.d7.loss_cls: 0.1963  decode.d7.loss_mask: 0.1971  decode.d7.loss_dice: 0.2384  decode.d8.loss_cls: 0.1632  decode.d8.loss_mask: 0.1948  decode.d8.loss_dice: 0.2244
09/30 14:16:13 - mmengine - INFO - Iter(train) [ 43200/320000]  base_lr: 8.7764e-05 lr: 8.7764e-06  eta: 1 day, 9:21:47  time: 0.4351  data_time: 0.0092  memory: 5120  grad_norm: 36.0419  loss: 4.9873  decode.loss_cls: 0.0764  decode.loss_mask: 0.1869  decode.loss_dice: 0.1950  decode.d0.loss_cls: 0.7663  decode.d0.loss_mask: 0.1833  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.1864  decode.d2.loss_dice: 0.1845  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.1851  decode.d3.loss_dice: 0.1791  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.1849  decode.d4.loss_dice: 0.1923  decode.d5.loss_cls: 0.0883  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1910  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.1859  decode.d6.loss_dice: 0.1808  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.1848  decode.d7.loss_dice: 0.1810  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 0.1869  decode.d8.loss_dice: 0.1800
09/30 14:16:35 - mmengine - INFO - Iter(train) [ 43250/320000]  base_lr: 8.7750e-05 lr: 8.7750e-06  eta: 1 day, 9:21:26  time: 0.4374  data_time: 0.0093  memory: 5145  grad_norm: 35.6545  loss: 7.4773  decode.loss_cls: 0.0979  decode.loss_mask: 0.2639  decode.loss_dice: 0.2755  decode.d0.loss_cls: 0.8712  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.2499  decode.d1.loss_cls: 0.1389  decode.d1.loss_mask: 0.2675  decode.d1.loss_dice: 0.2696  decode.d2.loss_cls: 0.1519  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.2755  decode.d3.loss_cls: 0.1983  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.2828  decode.d4.loss_cls: 0.1184  decode.d4.loss_mask: 0.2679  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.1184  decode.d5.loss_mask: 0.2663  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.1202  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.2852  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 0.2658  decode.d7.loss_dice: 0.2860  decode.d8.loss_cls: 0.1225  decode.d8.loss_mask: 0.2631  decode.d8.loss_dice: 0.2775
09/30 14:16:57 - mmengine - INFO - Iter(train) [ 43300/320000]  base_lr: 8.7735e-05 lr: 8.7735e-06  eta: 1 day, 9:21:04  time: 0.4346  data_time: 0.0093  memory: 5145  grad_norm: 24.0061  loss: 5.6226  decode.loss_cls: 0.0395  decode.loss_mask: 0.2624  decode.loss_dice: 0.1941  decode.d0.loss_cls: 0.7740  decode.d0.loss_mask: 0.2600  decode.d0.loss_dice: 0.1949  decode.d1.loss_cls: 0.0389  decode.d1.loss_mask: 0.2601  decode.d1.loss_dice: 0.1950  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.2609  decode.d2.loss_dice: 0.1902  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.1872  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.0342  decode.d5.loss_mask: 0.2606  decode.d5.loss_dice: 0.1919  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.1937  decode.d7.loss_cls: 0.0404  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.1951  decode.d8.loss_cls: 0.0362  decode.d8.loss_mask: 0.2606  decode.d8.loss_dice: 0.1940
09/30 14:17:19 - mmengine - INFO - Iter(train) [ 43350/320000]  base_lr: 8.7721e-05 lr: 8.7721e-06  eta: 1 day, 9:20:43  time: 0.4344  data_time: 0.0092  memory: 5145  grad_norm: 56.3023  loss: 7.0967  decode.loss_cls: 0.0654  decode.loss_mask: 0.2836  decode.loss_dice: 0.2600  decode.d0.loss_cls: 0.9334  decode.d0.loss_mask: 0.2906  decode.d0.loss_dice: 0.2572  decode.d1.loss_cls: 0.0808  decode.d1.loss_mask: 0.2941  decode.d1.loss_dice: 0.2359  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.2500  decode.d3.loss_cls: 0.1041  decode.d3.loss_mask: 0.2834  decode.d3.loss_dice: 0.2569  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2885  decode.d5.loss_dice: 0.2598  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.2839  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.1046  decode.d7.loss_mask: 0.2856  decode.d7.loss_dice: 0.2495  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2845  decode.d8.loss_dice: 0.2555
09/30 14:17:40 - mmengine - INFO - Iter(train) [ 43400/320000]  base_lr: 8.7707e-05 lr: 8.7707e-06  eta: 1 day, 9:20:22  time: 0.4347  data_time: 0.0091  memory: 5129  grad_norm: 90.8405  loss: 7.4970  decode.loss_cls: 0.1979  decode.loss_mask: 0.2487  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.6805  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2338  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2311  decode.d2.loss_cls: 0.2603  decode.d2.loss_mask: 0.2443  decode.d2.loss_dice: 0.2299  decode.d3.loss_cls: 0.2497  decode.d3.loss_mask: 0.2443  decode.d3.loss_dice: 0.2296  decode.d4.loss_cls: 0.2457  decode.d4.loss_mask: 0.2460  decode.d4.loss_dice: 0.2291  decode.d5.loss_cls: 0.2262  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2276  decode.d6.loss_cls: 0.2091  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.2159  decode.d7.loss_mask: 0.2439  decode.d7.loss_dice: 0.2275  decode.d8.loss_cls: 0.2134  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.2239
09/30 14:18:02 - mmengine - INFO - Iter(train) [ 43450/320000]  base_lr: 8.7693e-05 lr: 8.7693e-06  eta: 1 day, 9:20:00  time: 0.4344  data_time: 0.0090  memory: 5129  grad_norm: 27.1597  loss: 5.6750  decode.loss_cls: 0.0306  decode.loss_mask: 0.2343  decode.loss_dice: 0.2147  decode.d0.loss_cls: 0.8214  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.2273  decode.d1.loss_cls: 0.0221  decode.d1.loss_mask: 0.2324  decode.d1.loss_dice: 0.2150  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2179  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.2151  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.2193  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2561  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.2141  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.2324  decode.d7.loss_dice: 0.2137  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.2311  decode.d8.loss_dice: 0.2174
09/30 14:18:24 - mmengine - INFO - Iter(train) [ 43500/320000]  base_lr: 8.7678e-05 lr: 8.7678e-06  eta: 1 day, 9:19:39  time: 0.4337  data_time: 0.0091  memory: 5145  grad_norm: 341.9168  loss: 6.8832  decode.loss_cls: 0.1493  decode.loss_mask: 0.2560  decode.loss_dice: 0.2344  decode.d0.loss_cls: 0.9425  decode.d0.loss_mask: 0.2619  decode.d0.loss_dice: 0.2370  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.2303  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 0.2711  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.1750  decode.d3.loss_mask: 0.2590  decode.d3.loss_dice: 0.2159  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.2588  decode.d4.loss_dice: 0.2119  decode.d5.loss_cls: 0.1233  decode.d5.loss_mask: 0.2653  decode.d5.loss_dice: 0.2119  decode.d6.loss_cls: 0.0966  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2264  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2359  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.2333
09/30 14:18:46 - mmengine - INFO - Iter(train) [ 43550/320000]  base_lr: 8.7664e-05 lr: 8.7664e-06  eta: 1 day, 9:19:17  time: 0.4346  data_time: 0.0092  memory: 5129  grad_norm: 41.0306  loss: 5.1708  decode.loss_cls: 0.0281  decode.loss_mask: 0.2459  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.6929  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.1891  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.2496  decode.d1.loss_dice: 0.1956  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.1796  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.1781  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.1704  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.1835  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.2495  decode.d6.loss_dice: 0.1781  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.1769  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.2458  decode.d8.loss_dice: 0.1803
09/30 14:19:07 - mmengine - INFO - Iter(train) [ 43600/320000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 1 day, 9:18:56  time: 0.4338  data_time: 0.0091  memory: 5145  grad_norm: 74.0557  loss: 6.1751  decode.loss_cls: 0.0686  decode.loss_mask: 0.2459  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.8572  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2204  decode.d1.loss_cls: 0.1130  decode.d1.loss_mask: 0.2328  decode.d1.loss_dice: 0.2187  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2191  decode.d3.loss_cls: 0.0800  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2121  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.2238  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.2374  decode.d5.loss_dice: 0.2348  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.2426  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.2220  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.2483  decode.d8.loss_dice: 0.2261
09/30 14:19:29 - mmengine - INFO - Iter(train) [ 43650/320000]  base_lr: 8.7635e-05 lr: 8.7635e-06  eta: 1 day, 9:18:34  time: 0.4339  data_time: 0.0091  memory: 5129  grad_norm: 98.6039  loss: 7.4199  decode.loss_cls: 0.2880  decode.loss_mask: 0.2544  decode.loss_dice: 0.2087  decode.d0.loss_cls: 0.8506  decode.d0.loss_mask: 0.2572  decode.d0.loss_dice: 0.2184  decode.d1.loss_cls: 0.1842  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2142  decode.d2.loss_cls: 0.2019  decode.d2.loss_mask: 0.2558  decode.d2.loss_dice: 0.2054  decode.d3.loss_cls: 0.1713  decode.d3.loss_mask: 0.2564  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.1874  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.2062  decode.d5.loss_cls: 0.2081  decode.d5.loss_mask: 0.2547  decode.d5.loss_dice: 0.2194  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.2067  decode.d7.loss_cls: 0.2229  decode.d7.loss_mask: 0.2579  decode.d7.loss_dice: 0.2113  decode.d8.loss_cls: 0.2482  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.2083
09/30 14:19:51 - mmengine - INFO - Iter(train) [ 43700/320000]  base_lr: 8.7621e-05 lr: 8.7621e-06  eta: 1 day, 9:18:13  time: 0.4347  data_time: 0.0092  memory: 5129  grad_norm: 43.1080  loss: 5.7883  decode.loss_cls: 0.1276  decode.loss_mask: 0.1745  decode.loss_dice: 0.2128  decode.d0.loss_cls: 0.8165  decode.d0.loss_mask: 0.1768  decode.d0.loss_dice: 0.2210  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 0.1721  decode.d1.loss_dice: 0.2143  decode.d2.loss_cls: 0.1267  decode.d2.loss_mask: 0.1734  decode.d2.loss_dice: 0.2238  decode.d3.loss_cls: 0.1415  decode.d3.loss_mask: 0.1743  decode.d3.loss_dice: 0.2131  decode.d4.loss_cls: 0.1223  decode.d4.loss_mask: 0.1748  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.1211  decode.d5.loss_mask: 0.1755  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.1155  decode.d6.loss_mask: 0.1754  decode.d6.loss_dice: 0.2028  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.1728  decode.d7.loss_dice: 0.2142  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 0.1728  decode.d8.loss_dice: 0.2143
09/30 14:20:13 - mmengine - INFO - Iter(train) [ 43750/320000]  base_lr: 8.7607e-05 lr: 8.7607e-06  eta: 1 day, 9:17:51  time: 0.4347  data_time: 0.0095  memory: 5145  grad_norm: 42.2841  loss: 6.4934  decode.loss_cls: 0.0258  decode.loss_mask: 0.3352  decode.loss_dice: 0.2151  decode.d0.loss_cls: 0.8781  decode.d0.loss_mask: 0.3354  decode.d0.loss_dice: 0.2142  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.2243  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.3316  decode.d2.loss_dice: 0.2184  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.3312  decode.d3.loss_dice: 0.2176  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.3298  decode.d4.loss_dice: 0.2139  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.3313  decode.d5.loss_dice: 0.2145  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.3377  decode.d6.loss_dice: 0.2109  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.2111  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.3342  decode.d8.loss_dice: 0.2138
09/30 14:20:34 - mmengine - INFO - Iter(train) [ 43800/320000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 1 day, 9:17:30  time: 0.4361  data_time: 0.0095  memory: 5129  grad_norm: 117.6089  loss: 7.7883  decode.loss_cls: 0.3051  decode.loss_mask: 0.2374  decode.loss_dice: 0.1951  decode.d0.loss_cls: 1.0018  decode.d0.loss_mask: 0.2412  decode.d0.loss_dice: 0.1907  decode.d1.loss_cls: 0.1805  decode.d1.loss_mask: 0.2396  decode.d1.loss_dice: 0.1928  decode.d2.loss_cls: 0.2132  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.1907  decode.d3.loss_cls: 0.2830  decode.d3.loss_mask: 0.2355  decode.d3.loss_dice: 0.1846  decode.d4.loss_cls: 0.3450  decode.d4.loss_mask: 0.2431  decode.d4.loss_dice: 0.1941  decode.d5.loss_cls: 0.3138  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.1882  decode.d6.loss_cls: 0.2907  decode.d6.loss_mask: 0.2378  decode.d6.loss_dice: 0.1841  decode.d7.loss_cls: 0.2983  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.2805  decode.d8.loss_mask: 0.2371  decode.d8.loss_dice: 0.1850
09/30 14:20:56 - mmengine - INFO - Iter(train) [ 43850/320000]  base_lr: 8.7578e-05 lr: 8.7578e-06  eta: 1 day, 9:17:09  time: 0.4349  data_time: 0.0093  memory: 5129  grad_norm: 37.6989  loss: 5.0046  decode.loss_cls: 0.0145  decode.loss_mask: 0.2209  decode.loss_dice: 0.1715  decode.d0.loss_cls: 0.8523  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.1770  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.1809  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.1848  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.2230  decode.d3.loss_dice: 0.1787  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.1792  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.2220  decode.d5.loss_dice: 0.1770  decode.d6.loss_cls: 0.0096  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.1799  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.2246  decode.d8.loss_dice: 0.1839
09/30 14:21:18 - mmengine - INFO - Iter(train) [ 43900/320000]  base_lr: 8.7564e-05 lr: 8.7564e-06  eta: 1 day, 9:16:49  time: 0.4525  data_time: 0.0095  memory: 5145  grad_norm: 40.6247  loss: 6.5724  decode.loss_cls: 0.0728  decode.loss_mask: 0.2407  decode.loss_dice: 0.2536  decode.d0.loss_cls: 0.9756  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2728  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.2403  decode.d1.loss_dice: 0.2235  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.1965  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.2437  decode.d3.loss_dice: 0.2395  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.2408  decode.d4.loss_dice: 0.2481  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.1036  decode.d6.loss_mask: 0.2415  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.2391  decode.d7.loss_dice: 0.2342  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2286
09/30 14:21:40 - mmengine - INFO - Iter(train) [ 43950/320000]  base_lr: 8.7550e-05 lr: 8.7550e-06  eta: 1 day, 9:16:28  time: 0.4357  data_time: 0.0096  memory: 5145  grad_norm: 64.3441  loss: 5.5734  decode.loss_cls: 0.0158  decode.loss_mask: 0.2799  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.8418  decode.d0.loss_mask: 0.2651  decode.d0.loss_dice: 0.1879  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.2686  decode.d1.loss_dice: 0.1886  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.2731  decode.d2.loss_dice: 0.1945  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2693  decode.d3.loss_dice: 0.1962  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.2680  decode.d4.loss_dice: 0.1954  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.2588  decode.d5.loss_dice: 0.1869  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.2645  decode.d6.loss_dice: 0.1929  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.1974
09/30 14:22:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:22:02 - mmengine - INFO - Iter(train) [ 44000/320000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 1 day, 9:16:07  time: 0.4362  data_time: 0.0096  memory: 5145  grad_norm: 43.1961  loss: 6.6016  decode.loss_cls: 0.1422  decode.loss_mask: 0.2324  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.8992  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.2260  decode.d1.loss_cls: 0.1608  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.2108  decode.d2.loss_cls: 0.1458  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.2196  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 0.2245  decode.d3.loss_dice: 0.2084  decode.d4.loss_cls: 0.1256  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.2040  decode.d5.loss_cls: 0.1436  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.2132  decode.d6.loss_cls: 0.1337  decode.d6.loss_mask: 0.2240  decode.d6.loss_dice: 0.2031  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.3268  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.3221  decode.d8.loss_dice: 0.2200
09/30 14:22:24 - mmengine - INFO - Iter(train) [ 44050/320000]  base_lr: 8.7521e-05 lr: 8.7521e-06  eta: 1 day, 9:15:45  time: 0.4361  data_time: 0.0097  memory: 5129  grad_norm: 124.8469  loss: 5.8858  decode.loss_cls: 0.0246  decode.loss_mask: 0.2333  decode.loss_dice: 0.2137  decode.d0.loss_cls: 1.0029  decode.d0.loss_mask: 0.2343  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2244  decode.d2.loss_cls: 0.0353  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.2370  decode.d4.loss_dice: 0.2165  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.2128  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.2382  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2109  decode.d8.loss_cls: 0.0316  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.2124
09/30 14:22:45 - mmengine - INFO - Iter(train) [ 44100/320000]  base_lr: 8.7507e-05 lr: 8.7507e-06  eta: 1 day, 9:15:24  time: 0.4362  data_time: 0.0097  memory: 5145  grad_norm: 76.0580  loss: 7.0434  decode.loss_cls: 0.1803  decode.loss_mask: 0.2388  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.8818  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.2245  decode.d1.loss_cls: 0.1726  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2167  decode.d2.loss_cls: 0.1757  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2167  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.2141  decode.d4.loss_cls: 0.1579  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.1672  decode.d5.loss_mask: 0.2403  decode.d5.loss_dice: 0.2417  decode.d6.loss_cls: 0.1694  decode.d6.loss_mask: 0.2365  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.1676  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.2106  decode.d8.loss_cls: 0.1678  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2563
09/30 14:23:07 - mmengine - INFO - Iter(train) [ 44150/320000]  base_lr: 8.7493e-05 lr: 8.7493e-06  eta: 1 day, 9:15:03  time: 0.4360  data_time: 0.0095  memory: 5129  grad_norm: 33.4793  loss: 5.8871  decode.loss_cls: 0.1081  decode.loss_mask: 0.2121  decode.loss_dice: 0.1946  decode.d0.loss_cls: 0.8699  decode.d0.loss_mask: 0.2188  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.1973  decode.d2.loss_cls: 0.1402  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.1834  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.2128  decode.d3.loss_dice: 0.2061  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.2090  decode.d4.loss_dice: 0.1963  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.1985  decode.d7.loss_cls: 0.0912  decode.d7.loss_mask: 0.2130  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.1894
09/30 14:23:29 - mmengine - INFO - Iter(train) [ 44200/320000]  base_lr: 8.7478e-05 lr: 8.7478e-06  eta: 1 day, 9:14:42  time: 0.4353  data_time: 0.0096  memory: 5129  grad_norm: 92.4351  loss: 6.6975  decode.loss_cls: 0.1223  decode.loss_mask: 0.2283  decode.loss_dice: 0.2008  decode.d0.loss_cls: 1.1187  decode.d0.loss_mask: 0.2508  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.1849  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.2013  decode.d2.loss_cls: 0.1510  decode.d2.loss_mask: 0.2372  decode.d2.loss_dice: 0.1916  decode.d3.loss_cls: 0.1123  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.1908  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.1796  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.1907  decode.d6.loss_cls: 0.1376  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1887  decode.d7.loss_cls: 0.1353  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.1916  decode.d8.loss_cls: 0.1258  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.1903
09/30 14:23:51 - mmengine - INFO - Iter(train) [ 44250/320000]  base_lr: 8.7464e-05 lr: 8.7464e-06  eta: 1 day, 9:14:21  time: 0.4359  data_time: 0.0095  memory: 5145  grad_norm: 47.8291  loss: 6.7037  decode.loss_cls: 0.1305  decode.loss_mask: 0.2101  decode.loss_dice: 0.2644  decode.d0.loss_cls: 0.8819  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.3059  decode.d1.loss_cls: 0.1349  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.2419  decode.d3.loss_cls: 0.1162  decode.d3.loss_mask: 0.2135  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.2161  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.2788  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.1515  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 0.2134  decode.d8.loss_dice: 0.2483
09/30 14:24:13 - mmengine - INFO - Iter(train) [ 44300/320000]  base_lr: 8.7450e-05 lr: 8.7450e-06  eta: 1 day, 9:14:00  time: 0.4351  data_time: 0.0093  memory: 5129  grad_norm: 15.3950  loss: 4.9793  decode.loss_cls: 0.0450  decode.loss_mask: 0.2143  decode.loss_dice: 0.1582  decode.d0.loss_cls: 0.8721  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.1500  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.2200  decode.d1.loss_dice: 0.1509  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.1528  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.1572  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.2199  decode.d4.loss_dice: 0.1526  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.1557  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.1518  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.1538  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.1580
09/30 14:24:34 - mmengine - INFO - Iter(train) [ 44350/320000]  base_lr: 8.7436e-05 lr: 8.7436e-06  eta: 1 day, 9:13:39  time: 0.4360  data_time: 0.0093  memory: 5129  grad_norm: 44.5995  loss: 6.6402  decode.loss_cls: 0.1139  decode.loss_mask: 0.2620  decode.loss_dice: 0.2121  decode.d0.loss_cls: 0.8855  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.2572  decode.d1.loss_cls: 0.1415  decode.d1.loss_mask: 0.2641  decode.d1.loss_dice: 0.2215  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.2295  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.0699  decode.d4.loss_mask: 0.2624  decode.d4.loss_dice: 0.2229  decode.d5.loss_cls: 0.1030  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.2075  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.2124  decode.d7.loss_cls: 0.1209  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.2098  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.2065
09/30 14:24:56 - mmengine - INFO - Iter(train) [ 44400/320000]  base_lr: 8.7421e-05 lr: 8.7421e-06  eta: 1 day, 9:13:18  time: 0.4364  data_time: 0.0097  memory: 5129  grad_norm: 31.3234  loss: 5.5559  decode.loss_cls: 0.0604  decode.loss_mask: 0.2365  decode.loss_dice: 0.1894  decode.d0.loss_cls: 0.6833  decode.d0.loss_mask: 0.2455  decode.d0.loss_dice: 0.2019  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.2397  decode.d1.loss_dice: 0.1845  decode.d2.loss_cls: 0.0840  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.1971  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.1824  decode.d5.loss_cls: 0.0553  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.2391  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.2364  decode.d7.loss_dice: 0.2086  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.1926
09/30 14:25:18 - mmengine - INFO - Iter(train) [ 44450/320000]  base_lr: 8.7407e-05 lr: 8.7407e-06  eta: 1 day, 9:12:57  time: 0.4365  data_time: 0.0095  memory: 5145  grad_norm: 49.8495  loss: 4.7792  decode.loss_cls: 0.0187  decode.loss_mask: 0.2198  decode.loss_dice: 0.1663  decode.d0.loss_cls: 0.7463  decode.d0.loss_mask: 0.2255  decode.d0.loss_dice: 0.1669  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.1588  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.2213  decode.d3.loss_dice: 0.1595  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.2210  decode.d4.loss_dice: 0.1599  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.2188  decode.d5.loss_dice: 0.1627  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.1616  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.1646  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.2178  decode.d8.loss_dice: 0.1625
09/30 14:25:40 - mmengine - INFO - Iter(train) [ 44500/320000]  base_lr: 8.7393e-05 lr: 8.7393e-06  eta: 1 day, 9:12:36  time: 0.4371  data_time: 0.0095  memory: 5120  grad_norm: 58.0872  loss: 8.0654  decode.loss_cls: 0.1973  decode.loss_mask: 0.2185  decode.loss_dice: 0.2886  decode.d0.loss_cls: 0.9561  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.3062  decode.d1.loss_cls: 0.2351  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.2829  decode.d2.loss_cls: 0.2136  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.2191  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.3095  decode.d4.loss_cls: 0.2230  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.3044  decode.d5.loss_cls: 0.2340  decode.d5.loss_mask: 0.2176  decode.d5.loss_dice: 0.3008  decode.d6.loss_cls: 0.2078  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.3173  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.2788  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.2179  decode.d8.loss_dice: 0.3027
09/30 14:26:02 - mmengine - INFO - Iter(train) [ 44550/320000]  base_lr: 8.7379e-05 lr: 8.7379e-06  eta: 1 day, 9:12:15  time: 0.4359  data_time: 0.0094  memory: 5145  grad_norm: 46.2489  loss: 5.7961  decode.loss_cls: 0.0708  decode.loss_mask: 0.1869  decode.loss_dice: 0.1924  decode.d0.loss_cls: 0.8911  decode.d0.loss_mask: 0.1893  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.3191  decode.d1.loss_mask: 0.1902  decode.d1.loss_dice: 0.1925  decode.d2.loss_cls: 0.1192  decode.d2.loss_mask: 0.1877  decode.d2.loss_dice: 0.1963  decode.d3.loss_cls: 0.1017  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.1996  decode.d4.loss_cls: 0.0958  decode.d4.loss_mask: 0.1898  decode.d4.loss_dice: 0.1937  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 0.1871  decode.d5.loss_dice: 0.1995  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.1921  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.1978  decode.d8.loss_cls: 0.0686  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.1952
09/30 14:26:23 - mmengine - INFO - Iter(train) [ 44600/320000]  base_lr: 8.7364e-05 lr: 8.7364e-06  eta: 1 day, 9:11:54  time: 0.4352  data_time: 0.0094  memory: 5129  grad_norm: 58.7833  loss: 5.1901  decode.loss_cls: 0.0819  decode.loss_mask: 0.1991  decode.loss_dice: 0.1730  decode.d0.loss_cls: 0.7518  decode.d0.loss_mask: 0.2004  decode.d0.loss_dice: 0.1600  decode.d1.loss_cls: 0.0977  decode.d1.loss_mask: 0.2014  decode.d1.loss_dice: 0.1680  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.1625  decode.d3.loss_cls: 0.0827  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.1644  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.1990  decode.d4.loss_dice: 0.1680  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.2013  decode.d5.loss_dice: 0.1552  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 0.2005  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.1615  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.1680
09/30 14:26:45 - mmengine - INFO - Iter(train) [ 44650/320000]  base_lr: 8.7350e-05 lr: 8.7350e-06  eta: 1 day, 9:11:33  time: 0.4341  data_time: 0.0092  memory: 5120  grad_norm: 31.5757  loss: 9.0213  decode.loss_cls: 0.1874  decode.loss_mask: 0.3297  decode.loss_dice: 0.2875  decode.d0.loss_cls: 0.8927  decode.d0.loss_mask: 0.3051  decode.d0.loss_dice: 0.2987  decode.d1.loss_cls: 0.1734  decode.d1.loss_mask: 0.2978  decode.d1.loss_dice: 0.3058  decode.d2.loss_cls: 0.1770  decode.d2.loss_mask: 0.3634  decode.d2.loss_dice: 0.2853  decode.d3.loss_cls: 0.1753  decode.d3.loss_mask: 0.3967  decode.d3.loss_dice: 0.2832  decode.d4.loss_cls: 0.1933  decode.d4.loss_mask: 0.3663  decode.d4.loss_dice: 0.2993  decode.d5.loss_cls: 0.1836  decode.d5.loss_mask: 0.3737  decode.d5.loss_dice: 0.2922  decode.d6.loss_cls: 0.1668  decode.d6.loss_mask: 0.4898  decode.d6.loss_dice: 0.2900  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 0.3628  decode.d7.loss_dice: 0.2878  decode.d8.loss_cls: 0.1766  decode.d8.loss_mask: 0.3166  decode.d8.loss_dice: 0.2892
09/30 14:27:07 - mmengine - INFO - Iter(train) [ 44700/320000]  base_lr: 8.7336e-05 lr: 8.7336e-06  eta: 1 day, 9:11:12  time: 0.4356  data_time: 0.0092  memory: 5129  grad_norm: 93.5841  loss: 7.2267  decode.loss_cls: 0.0798  decode.loss_mask: 0.2819  decode.loss_dice: 0.2674  decode.d0.loss_cls: 0.9446  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.2767  decode.d1.loss_cls: 0.1236  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.2920  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.2567  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.3280  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.2588  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.2797  decode.d6.loss_dice: 0.2655  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.2828  decode.d7.loss_dice: 0.2453  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.3037  decode.d8.loss_dice: 0.2594
09/30 14:27:29 - mmengine - INFO - Iter(train) [ 44750/320000]  base_lr: 8.7321e-05 lr: 8.7321e-06  eta: 1 day, 9:10:50  time: 0.4368  data_time: 0.0095  memory: 5145  grad_norm: 98.7738  loss: 6.3928  decode.loss_cls: 0.0267  decode.loss_mask: 0.2866  decode.loss_dice: 0.2366  decode.d0.loss_cls: 0.7473  decode.d0.loss_mask: 0.2954  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.2879  decode.d1.loss_dice: 0.2576  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.2546  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.2878  decode.d4.loss_dice: 0.2361  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.2421  decode.d6.loss_cls: 0.0385  decode.d6.loss_mask: 0.2852  decode.d6.loss_dice: 0.2419  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.2878  decode.d7.loss_dice: 0.2377  decode.d8.loss_cls: 0.0230  decode.d8.loss_mask: 0.2860  decode.d8.loss_dice: 0.2374
09/30 14:27:51 - mmengine - INFO - Iter(train) [ 44800/320000]  base_lr: 8.7307e-05 lr: 8.7307e-06  eta: 1 day, 9:10:29  time: 0.4356  data_time: 0.0094  memory: 5145  grad_norm: 67.4683  loss: 9.0779  decode.loss_cls: 0.2188  decode.loss_mask: 0.3674  decode.loss_dice: 0.2121  decode.d0.loss_cls: 1.0156  decode.d0.loss_mask: 0.2808  decode.d0.loss_dice: 0.2237  decode.d1.loss_cls: 0.2898  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.2162  decode.d2.loss_cls: 0.2608  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.2186  decode.d3.loss_cls: 0.2537  decode.d3.loss_mask: 0.3527  decode.d3.loss_dice: 0.2076  decode.d4.loss_cls: 0.2978  decode.d4.loss_mask: 0.3400  decode.d4.loss_dice: 0.2036  decode.d5.loss_cls: 0.3619  decode.d5.loss_mask: 0.3519  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.3136  decode.d6.loss_mask: 0.3651  decode.d6.loss_dice: 0.2069  decode.d7.loss_cls: 0.3639  decode.d7.loss_mask: 0.3589  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.2564  decode.d8.loss_mask: 0.3583  decode.d8.loss_dice: 0.2045
09/30 14:28:12 - mmengine - INFO - Iter(train) [ 44850/320000]  base_lr: 8.7293e-05 lr: 8.7293e-06  eta: 1 day, 9:10:07  time: 0.4353  data_time: 0.0092  memory: 5129  grad_norm: 98.6202  loss: 7.1606  decode.loss_cls: 0.0746  decode.loss_mask: 0.2826  decode.loss_dice: 0.2345  decode.d0.loss_cls: 0.9130  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.2447  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.2264  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.2870  decode.d2.loss_dice: 0.2384  decode.d3.loss_cls: 0.1171  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.2321  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2851  decode.d4.loss_dice: 0.2243  decode.d5.loss_cls: 0.1009  decode.d5.loss_mask: 0.2847  decode.d5.loss_dice: 0.2209  decode.d6.loss_cls: 0.1403  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.1823  decode.d7.loss_mask: 0.2846  decode.d7.loss_dice: 0.2228  decode.d8.loss_cls: 0.1494  decode.d8.loss_mask: 0.2846  decode.d8.loss_dice: 0.2555
09/30 14:28:34 - mmengine - INFO - Iter(train) [ 44900/320000]  base_lr: 8.7279e-05 lr: 8.7279e-06  eta: 1 day, 9:09:46  time: 0.4331  data_time: 0.0091  memory: 5145  grad_norm: 205.9696  loss: 7.8845  decode.loss_cls: 0.1434  decode.loss_mask: 0.2936  decode.loss_dice: 0.2216  decode.d0.loss_cls: 0.9640  decode.d0.loss_mask: 0.2817  decode.d0.loss_dice: 0.2120  decode.d1.loss_cls: 0.2045  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.2269  decode.d2.loss_cls: 0.1521  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.2343  decode.d3.loss_cls: 0.1642  decode.d3.loss_mask: 0.3588  decode.d3.loss_dice: 0.2317  decode.d4.loss_cls: 0.1641  decode.d4.loss_mask: 0.3172  decode.d4.loss_dice: 0.2100  decode.d5.loss_cls: 0.1869  decode.d5.loss_mask: 0.3934  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.1755  decode.d6.loss_mask: 0.2950  decode.d6.loss_dice: 0.2206  decode.d7.loss_cls: 0.1674  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.2248  decode.d8.loss_cls: 0.1641  decode.d8.loss_mask: 0.3306  decode.d8.loss_dice: 0.2232
09/30 14:28:56 - mmengine - INFO - Iter(train) [ 44950/320000]  base_lr: 8.7264e-05 lr: 8.7264e-06  eta: 1 day, 9:09:24  time: 0.4338  data_time: 0.0091  memory: 5145  grad_norm: 35.1368  loss: 6.3621  decode.loss_cls: 0.1520  decode.loss_mask: 0.2172  decode.loss_dice: 0.1894  decode.d0.loss_cls: 0.8996  decode.d0.loss_mask: 0.2245  decode.d0.loss_dice: 0.2259  decode.d1.loss_cls: 0.1315  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.1147  decode.d2.loss_mask: 0.2157  decode.d2.loss_dice: 0.2129  decode.d3.loss_cls: 0.1244  decode.d3.loss_mask: 0.2135  decode.d3.loss_dice: 0.2082  decode.d4.loss_cls: 0.0986  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.0878  decode.d5.loss_mask: 0.2178  decode.d5.loss_dice: 0.2159  decode.d6.loss_cls: 0.1224  decode.d6.loss_mask: 0.2172  decode.d6.loss_dice: 0.2243  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.1998  decode.d8.loss_cls: 0.1572  decode.d8.loss_mask: 0.2167  decode.d8.loss_dice: 0.2099
09/30 14:29:17 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:29:17 - mmengine - INFO - Iter(train) [ 45000/320000]  base_lr: 8.7250e-05 lr: 8.7250e-06  eta: 1 day, 9:09:03  time: 0.4346  data_time: 0.0091  memory: 5129  grad_norm: 33.9709  loss: 5.9870  decode.loss_cls: 0.0368  decode.loss_mask: 0.2822  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.7918  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.2796  decode.d1.loss_dice: 0.1932  decode.d2.loss_cls: 0.0950  decode.d2.loss_mask: 0.2765  decode.d2.loss_dice: 0.1912  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.2757  decode.d3.loss_dice: 0.1942  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.0315  decode.d5.loss_mask: 0.2784  decode.d5.loss_dice: 0.2025  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2050  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.1966  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.1944
09/30 14:29:39 - mmengine - INFO - Iter(train) [ 45050/320000]  base_lr: 8.7236e-05 lr: 8.7236e-06  eta: 1 day, 9:08:41  time: 0.4337  data_time: 0.0090  memory: 5129  grad_norm: 97.6215  loss: 7.8428  decode.loss_cls: 0.1419  decode.loss_mask: 0.2449  decode.loss_dice: 0.2703  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.3098  decode.d1.loss_cls: 0.3050  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.2662  decode.d2.loss_cls: 0.2531  decode.d2.loss_mask: 0.2389  decode.d2.loss_dice: 0.2641  decode.d3.loss_cls: 0.1401  decode.d3.loss_mask: 0.2599  decode.d3.loss_dice: 0.2743  decode.d4.loss_cls: 0.1576  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.3050  decode.d5.loss_cls: 0.2434  decode.d5.loss_mask: 0.2520  decode.d5.loss_dice: 0.2782  decode.d6.loss_cls: 0.1539  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2609  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.2419  decode.d7.loss_dice: 0.3061  decode.d8.loss_cls: 0.1628  decode.d8.loss_mask: 0.2429  decode.d8.loss_dice: 0.2781
09/30 14:30:01 - mmengine - INFO - Iter(train) [ 45100/320000]  base_lr: 8.7221e-05 lr: 8.7221e-06  eta: 1 day, 9:08:19  time: 0.4359  data_time: 0.0094  memory: 5129  grad_norm: 39.4907  loss: 5.9692  decode.loss_cls: 0.0053  decode.loss_mask: 0.3030  decode.loss_dice: 0.2071  decode.d0.loss_cls: 0.7588  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.2040  decode.d1.loss_cls: 0.0313  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.3039  decode.d2.loss_dice: 0.2102  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.3047  decode.d3.loss_dice: 0.2136  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.2995  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.3023  decode.d6.loss_dice: 0.2069  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.2991  decode.d7.loss_dice: 0.2095  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.3045  decode.d8.loss_dice: 0.2102
09/30 14:30:23 - mmengine - INFO - Iter(train) [ 45150/320000]  base_lr: 8.7207e-05 lr: 8.7207e-06  eta: 1 day, 9:07:58  time: 0.4341  data_time: 0.0093  memory: 5129  grad_norm: 44.2814  loss: 6.2424  decode.loss_cls: 0.0578  decode.loss_mask: 0.2781  decode.loss_dice: 0.2273  decode.d0.loss_cls: 0.7248  decode.d0.loss_mask: 0.2787  decode.d0.loss_dice: 0.2420  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.2778  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.2766  decode.d2.loss_dice: 0.2323  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.2376  decode.d4.loss_cls: 0.0241  decode.d4.loss_mask: 0.2791  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.2407  decode.d6.loss_cls: 0.0385  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.2282  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.2779  decode.d7.loss_dice: 0.2335  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.2803  decode.d8.loss_dice: 0.2420
09/30 14:30:44 - mmengine - INFO - Iter(train) [ 45200/320000]  base_lr: 8.7193e-05 lr: 8.7193e-06  eta: 1 day, 9:07:37  time: 0.4340  data_time: 0.0091  memory: 5145  grad_norm: 127.7503  loss: 7.2852  decode.loss_cls: 0.1315  decode.loss_mask: 0.2737  decode.loss_dice: 0.2373  decode.d0.loss_cls: 0.9474  decode.d0.loss_mask: 0.2895  decode.d0.loss_dice: 0.2467  decode.d1.loss_cls: 0.1658  decode.d1.loss_mask: 0.2713  decode.d1.loss_dice: 0.2472  decode.d2.loss_cls: 0.1105  decode.d2.loss_mask: 0.2854  decode.d2.loss_dice: 0.2493  decode.d3.loss_cls: 0.0899  decode.d3.loss_mask: 0.2790  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1158  decode.d4.loss_mask: 0.2747  decode.d4.loss_dice: 0.2465  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.2753  decode.d5.loss_dice: 0.2406  decode.d6.loss_cls: 0.1523  decode.d6.loss_mask: 0.2713  decode.d6.loss_dice: 0.2430  decode.d7.loss_cls: 0.1400  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2453  decode.d8.loss_cls: 0.1254  decode.d8.loss_mask: 0.2780  decode.d8.loss_dice: 0.2504
09/30 14:31:06 - mmengine - INFO - Iter(train) [ 45250/320000]  base_lr: 8.7179e-05 lr: 8.7179e-06  eta: 1 day, 9:07:16  time: 0.4363  data_time: 0.0096  memory: 5145  grad_norm: 107.4466  loss: 8.2315  decode.loss_cls: 0.1470  decode.loss_mask: 0.3167  decode.loss_dice: 0.2401  decode.d0.loss_cls: 0.9588  decode.d0.loss_mask: 0.3389  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.1455  decode.d1.loss_mask: 0.3204  decode.d1.loss_dice: 0.2508  decode.d2.loss_cls: 0.1494  decode.d2.loss_mask: 0.3089  decode.d2.loss_dice: 0.2666  decode.d3.loss_cls: 0.1555  decode.d3.loss_mask: 0.3485  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.3470  decode.d4.loss_dice: 0.2454  decode.d5.loss_cls: 0.1491  decode.d5.loss_mask: 0.3951  decode.d5.loss_dice: 0.2550  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.4079  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.3916  decode.d7.loss_dice: 0.2241  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.4493  decode.d8.loss_dice: 0.2539
09/30 14:31:28 - mmengine - INFO - Iter(train) [ 45300/320000]  base_lr: 8.7164e-05 lr: 8.7164e-06  eta: 1 day, 9:06:54  time: 0.4353  data_time: 0.0094  memory: 5129  grad_norm: 30.2562  loss: 6.1057  decode.loss_cls: 0.1305  decode.loss_mask: 0.2292  decode.loss_dice: 0.1689  decode.d0.loss_cls: 0.9725  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.1803  decode.d2.loss_cls: 0.0753  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.1910  decode.d3.loss_cls: 0.1184  decode.d3.loss_mask: 0.2317  decode.d3.loss_dice: 0.1742  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.2306  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.1299  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.1749  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.2336  decode.d6.loss_dice: 0.1755  decode.d7.loss_cls: 0.1024  decode.d7.loss_mask: 0.2328  decode.d7.loss_dice: 0.1877  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.1752
09/30 14:31:50 - mmengine - INFO - Iter(train) [ 45350/320000]  base_lr: 8.7150e-05 lr: 8.7150e-06  eta: 1 day, 9:06:33  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 60.1200  loss: 7.1905  decode.loss_cls: 0.1243  decode.loss_mask: 0.2193  decode.loss_dice: 0.2655  decode.d0.loss_cls: 0.8973  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.2383  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.2611  decode.d2.loss_cls: 0.1913  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.2717  decode.d3.loss_cls: 0.1685  decode.d3.loss_mask: 0.2174  decode.d3.loss_dice: 0.2567  decode.d4.loss_cls: 0.1504  decode.d4.loss_mask: 0.2187  decode.d4.loss_dice: 0.2605  decode.d5.loss_cls: 0.1372  decode.d5.loss_mask: 0.2236  decode.d5.loss_dice: 0.2666  decode.d6.loss_cls: 0.1568  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.2589  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.2620  decode.d8.loss_cls: 0.1794  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.2679
09/30 14:32:12 - mmengine - INFO - Iter(train) [ 45400/320000]  base_lr: 8.7136e-05 lr: 8.7136e-06  eta: 1 day, 9:06:12  time: 0.4354  data_time: 0.0094  memory: 5145  grad_norm: 43.6885  loss: 5.4854  decode.loss_cls: 0.0757  decode.loss_mask: 0.2155  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.8182  decode.d0.loss_mask: 0.2236  decode.d0.loss_dice: 0.1896  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.1936  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.1932  decode.d4.loss_cls: 0.0412  decode.d4.loss_mask: 0.2201  decode.d4.loss_dice: 0.1911  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.1875  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.2190  decode.d6.loss_dice: 0.1886  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.2182  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.2169  decode.d8.loss_dice: 0.1874
09/30 14:32:33 - mmengine - INFO - Iter(train) [ 45450/320000]  base_lr: 8.7122e-05 lr: 8.7122e-06  eta: 1 day, 9:05:51  time: 0.4351  data_time: 0.0096  memory: 5145  grad_norm: 32.4091  loss: 6.1594  decode.loss_cls: 0.0825  decode.loss_mask: 0.2777  decode.loss_dice: 0.1863  decode.d0.loss_cls: 0.8184  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.1769  decode.d1.loss_cls: 0.1160  decode.d1.loss_mask: 0.2664  decode.d1.loss_dice: 0.1749  decode.d2.loss_cls: 0.1084  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.1717  decode.d4.loss_cls: 0.0536  decode.d4.loss_mask: 0.2644  decode.d4.loss_dice: 0.1703  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.1880  decode.d6.loss_cls: 0.1625  decode.d6.loss_mask: 0.2549  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.1638  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.1776  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.2673  decode.d8.loss_dice: 0.1729
09/30 14:32:55 - mmengine - INFO - Iter(train) [ 45500/320000]  base_lr: 8.7107e-05 lr: 8.7107e-06  eta: 1 day, 9:05:30  time: 0.4368  data_time: 0.0097  memory: 5120  grad_norm: 78.1550  loss: 7.0501  decode.loss_cls: 0.1027  decode.loss_mask: 0.2257  decode.loss_dice: 0.2671  decode.d0.loss_cls: 0.9018  decode.d0.loss_mask: 0.2202  decode.d0.loss_dice: 0.3033  decode.d1.loss_cls: 0.2573  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.2545  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2569  decode.d3.loss_cls: 0.1143  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.2668  decode.d4.loss_cls: 0.1651  decode.d4.loss_mask: 0.2224  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.2245  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.2239  decode.d6.loss_dice: 0.2635  decode.d7.loss_cls: 0.1119  decode.d7.loss_mask: 0.2248  decode.d7.loss_dice: 0.2710  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 0.2273  decode.d8.loss_dice: 0.2781
09/30 14:33:17 - mmengine - INFO - Iter(train) [ 45550/320000]  base_lr: 8.7093e-05 lr: 8.7093e-06  eta: 1 day, 9:05:10  time: 0.4533  data_time: 0.0095  memory: 5120  grad_norm: 54.7181  loss: 5.6758  decode.loss_cls: 0.0408  decode.loss_mask: 0.2155  decode.loss_dice: 0.2027  decode.d0.loss_cls: 0.8201  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.2007  decode.d1.loss_cls: 0.1051  decode.d1.loss_mask: 0.2164  decode.d1.loss_dice: 0.2004  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.2158  decode.d2.loss_dice: 0.1979  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.2075  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1980  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.2134  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.1154  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.1943
09/30 14:33:39 - mmengine - INFO - Iter(train) [ 45600/320000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 1 day, 9:04:49  time: 0.4358  data_time: 0.0096  memory: 5129  grad_norm: 34.5034  loss: 6.2039  decode.loss_cls: 0.0466  decode.loss_mask: 0.2933  decode.loss_dice: 0.2008  decode.d0.loss_cls: 0.8389  decode.d0.loss_mask: 0.2999  decode.d0.loss_dice: 0.2066  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.3000  decode.d1.loss_dice: 0.2033  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.2977  decode.d2.loss_dice: 0.2007  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.2910  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.2900  decode.d5.loss_dice: 0.1941  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.2013  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.2082
09/30 14:34:01 - mmengine - INFO - Iter(train) [ 45650/320000]  base_lr: 8.7064e-05 lr: 8.7064e-06  eta: 1 day, 9:04:28  time: 0.4354  data_time: 0.0096  memory: 5120  grad_norm: 80.3485  loss: 8.4787  decode.loss_cls: 0.2578  decode.loss_mask: 0.2550  decode.loss_dice: 0.2637  decode.d0.loss_cls: 0.9945  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.2946  decode.d1.loss_cls: 0.3218  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.2628  decode.d2.loss_cls: 0.2597  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.2731  decode.d3.loss_cls: 0.2212  decode.d3.loss_mask: 0.2590  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.2395  decode.d4.loss_mask: 0.2561  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.2453  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.2650  decode.d6.loss_cls: 0.2406  decode.d6.loss_mask: 0.2582  decode.d6.loss_dice: 0.2662  decode.d7.loss_cls: 0.1782  decode.d7.loss_mask: 0.2575  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.2309  decode.d8.loss_mask: 0.2572  decode.d8.loss_dice: 0.2750
09/30 14:34:23 - mmengine - INFO - Iter(train) [ 45700/320000]  base_lr: 8.7050e-05 lr: 8.7050e-06  eta: 1 day, 9:04:07  time: 0.4356  data_time: 0.0095  memory: 5145  grad_norm: 25.5951  loss: 5.5022  decode.loss_cls: 0.0777  decode.loss_mask: 0.2192  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.7641  decode.d0.loss_mask: 0.2348  decode.d0.loss_dice: 0.2059  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.2067  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2157  decode.d2.loss_dice: 0.2094  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.1942  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.2047  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.2184  decode.d6.loss_dice: 0.2133  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.2000  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.2185  decode.d8.loss_dice: 0.2109
09/30 14:34:44 - mmengine - INFO - Iter(train) [ 45750/320000]  base_lr: 8.7036e-05 lr: 8.7036e-06  eta: 1 day, 9:03:46  time: 0.4364  data_time: 0.0096  memory: 5120  grad_norm: 70.8259  loss: 7.4988  decode.loss_cls: 0.2589  decode.loss_mask: 0.2131  decode.loss_dice: 0.2344  decode.d0.loss_cls: 0.8146  decode.d0.loss_mask: 0.2137  decode.d0.loss_dice: 0.2624  decode.d1.loss_cls: 0.2494  decode.d1.loss_mask: 0.2156  decode.d1.loss_dice: 0.2470  decode.d2.loss_cls: 0.2642  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.2491  decode.d3.loss_cls: 0.2048  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.2495  decode.d4.loss_cls: 0.2194  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.2535  decode.d5.loss_cls: 0.2057  decode.d5.loss_mask: 0.2159  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.2317  decode.d6.loss_mask: 0.2140  decode.d6.loss_dice: 0.2347  decode.d7.loss_cls: 0.2153  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.2385  decode.d8.loss_cls: 0.2438  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2513
09/30 14:35:06 - mmengine - INFO - Iter(train) [ 45800/320000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 1 day, 9:03:24  time: 0.4355  data_time: 0.0095  memory: 5129  grad_norm: 143.0340  loss: 6.8143  decode.loss_cls: 0.1227  decode.loss_mask: 0.2327  decode.loss_dice: 0.2602  decode.d0.loss_cls: 0.8465  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.2550  decode.d1.loss_cls: 0.1438  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2661  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.2340  decode.d3.loss_dice: 0.2767  decode.d4.loss_cls: 0.1186  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.2684  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.2612  decode.d6.loss_cls: 0.1018  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.2520  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2468  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2577
09/30 14:35:28 - mmengine - INFO - Iter(train) [ 45850/320000]  base_lr: 8.7007e-05 lr: 8.7007e-06  eta: 1 day, 9:03:03  time: 0.4360  data_time: 0.0096  memory: 5145  grad_norm: 63.2480  loss: 7.5331  decode.loss_cls: 0.1447  decode.loss_mask: 0.2770  decode.loss_dice: 0.2502  decode.d0.loss_cls: 0.8891  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.2528  decode.d1.loss_cls: 0.1573  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.2355  decode.d2.loss_cls: 0.1902  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.2448  decode.d3.loss_cls: 0.1469  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.2610  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 0.2780  decode.d4.loss_dice: 0.2482  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.2816  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.1556  decode.d6.loss_mask: 0.2792  decode.d6.loss_dice: 0.2527  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.2777  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.2345
09/30 14:35:50 - mmengine - INFO - Iter(train) [ 45900/320000]  base_lr: 8.6993e-05 lr: 8.6993e-06  eta: 1 day, 9:02:42  time: 0.4364  data_time: 0.0095  memory: 5120  grad_norm: 96.3858  loss: 5.5886  decode.loss_cls: 0.0691  decode.loss_mask: 0.2528  decode.loss_dice: 0.1925  decode.d0.loss_cls: 0.7986  decode.d0.loss_mask: 0.2515  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.2130  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.2091  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.1966  decode.d4.loss_cls: 0.0171  decode.d4.loss_mask: 0.2545  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.2569  decode.d5.loss_dice: 0.2020  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.2107  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.2041  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.1902
09/30 14:36:12 - mmengine - INFO - Iter(train) [ 45950/320000]  base_lr: 8.6979e-05 lr: 8.6979e-06  eta: 1 day, 9:02:21  time: 0.4364  data_time: 0.0097  memory: 5129  grad_norm: 33.9091  loss: 5.5913  decode.loss_cls: 0.0925  decode.loss_mask: 0.2212  decode.loss_dice: 0.1866  decode.d0.loss_cls: 0.6993  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.1866  decode.d1.loss_cls: 0.1014  decode.d1.loss_mask: 0.2238  decode.d1.loss_dice: 0.1839  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.1869  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.0792  decode.d4.loss_mask: 0.2230  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.0810  decode.d5.loss_mask: 0.2217  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.1833  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.1862  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.1850
09/30 14:36:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:36:33 - mmengine - INFO - Iter(train) [ 46000/320000]  base_lr: 8.6964e-05 lr: 8.6964e-06  eta: 1 day, 9:02:00  time: 0.4362  data_time: 0.0096  memory: 5120  grad_norm: 58.0983  loss: 7.3744  decode.loss_cls: 0.1727  decode.loss_mask: 0.2474  decode.loss_dice: 0.2238  decode.d0.loss_cls: 0.9235  decode.d0.loss_mask: 0.2440  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.2136  decode.d1.loss_mask: 0.2663  decode.d1.loss_dice: 0.2408  decode.d2.loss_cls: 0.1330  decode.d2.loss_mask: 0.2803  decode.d2.loss_dice: 0.2242  decode.d3.loss_cls: 0.1629  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.2393  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 0.3355  decode.d4.loss_dice: 0.2272  decode.d5.loss_cls: 0.1493  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.1696  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 0.2511  decode.d7.loss_dice: 0.2214  decode.d8.loss_cls: 0.1829  decode.d8.loss_mask: 0.2430  decode.d8.loss_dice: 0.2173
09/30 14:36:55 - mmengine - INFO - Iter(train) [ 46050/320000]  base_lr: 8.6950e-05 lr: 8.6950e-06  eta: 1 day, 9:01:39  time: 0.4359  data_time: 0.0095  memory: 5129  grad_norm: 42.6712  loss: 6.0711  decode.loss_cls: 0.1264  decode.loss_mask: 0.2092  decode.loss_dice: 0.2215  decode.d0.loss_cls: 0.7419  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.1691  decode.d1.loss_mask: 0.2092  decode.d1.loss_dice: 0.2148  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.2100  decode.d2.loss_dice: 0.2016  decode.d3.loss_cls: 0.1194  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.1106  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.1916  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 0.2109  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.1271  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.1944  decode.d7.loss_cls: 0.1206  decode.d7.loss_mask: 0.2088  decode.d7.loss_dice: 0.2172  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2076
09/30 14:37:17 - mmengine - INFO - Iter(train) [ 46100/320000]  base_lr: 8.6936e-05 lr: 8.6936e-06  eta: 1 day, 9:01:18  time: 0.4365  data_time: 0.0095  memory: 5145  grad_norm: 35.6162  loss: 8.4426  decode.loss_cls: 0.1738  decode.loss_mask: 0.3368  decode.loss_dice: 0.2934  decode.d0.loss_cls: 0.7672  decode.d0.loss_mask: 0.4242  decode.d0.loss_dice: 0.3194  decode.d1.loss_cls: 0.1789  decode.d1.loss_mask: 0.3259  decode.d1.loss_dice: 0.2886  decode.d2.loss_cls: 0.1009  decode.d2.loss_mask: 0.3787  decode.d2.loss_dice: 0.3014  decode.d3.loss_cls: 0.1594  decode.d3.loss_mask: 0.3389  decode.d3.loss_dice: 0.2906  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.4196  decode.d4.loss_dice: 0.2942  decode.d5.loss_cls: 0.1405  decode.d5.loss_mask: 0.3535  decode.d5.loss_dice: 0.2883  decode.d6.loss_cls: 0.0931  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.2945  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.3961  decode.d7.loss_dice: 0.2905  decode.d8.loss_cls: 0.1615  decode.d8.loss_mask: 0.3340  decode.d8.loss_dice: 0.2892
09/30 14:37:39 - mmengine - INFO - Iter(train) [ 46150/320000]  base_lr: 8.6922e-05 lr: 8.6922e-06  eta: 1 day, 9:00:57  time: 0.4354  data_time: 0.0095  memory: 5129  grad_norm: 36.9545  loss: 5.2396  decode.loss_cls: 0.0143  decode.loss_mask: 0.2338  decode.loss_dice: 0.1865  decode.d0.loss_cls: 0.8206  decode.d0.loss_mask: 0.2391  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.1915  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.2335  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.2367  decode.d3.loss_dice: 0.1896  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.2379  decode.d4.loss_dice: 0.1904  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.2372  decode.d5.loss_dice: 0.1902  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1938  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.1917  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.1874
09/30 14:38:01 - mmengine - INFO - Iter(train) [ 46200/320000]  base_lr: 8.6907e-05 lr: 8.6907e-06  eta: 1 day, 9:00:36  time: 0.4360  data_time: 0.0095  memory: 5145  grad_norm: 32.3897  loss: 4.9209  decode.loss_cls: 0.0122  decode.loss_mask: 0.2230  decode.loss_dice: 0.1715  decode.d0.loss_cls: 0.8194  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.2231  decode.d1.loss_dice: 0.1701  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.2223  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.2235  decode.d3.loss_dice: 0.1709  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.1772  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2253  decode.d5.loss_dice: 0.1797  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.2214  decode.d6.loss_dice: 0.1755  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.1754  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.1700
09/30 14:38:23 - mmengine - INFO - Iter(train) [ 46250/320000]  base_lr: 8.6893e-05 lr: 8.6893e-06  eta: 1 day, 9:00:15  time: 0.4371  data_time: 0.0097  memory: 5129  grad_norm: 45.7318  loss: 5.9684  decode.loss_cls: 0.0257  decode.loss_mask: 0.2446  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.8798  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.2273  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.2188  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2253  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.2494  decode.d3.loss_dice: 0.2411  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.2498  decode.d4.loss_dice: 0.2431  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.2464  decode.d5.loss_dice: 0.2443  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.2499  decode.d6.loss_dice: 0.2369  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.2469  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.0279  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2441
09/30 14:38:44 - mmengine - INFO - Iter(train) [ 46300/320000]  base_lr: 8.6879e-05 lr: 8.6879e-06  eta: 1 day, 8:59:53  time: 0.4366  data_time: 0.0097  memory: 5129  grad_norm: 75.6716  loss: 7.2879  decode.loss_cls: 0.1703  decode.loss_mask: 0.2821  decode.loss_dice: 0.2198  decode.d0.loss_cls: 0.8611  decode.d0.loss_mask: 0.2871  decode.d0.loss_dice: 0.2307  decode.d1.loss_cls: 0.2112  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.2258  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.2204  decode.d3.loss_cls: 0.1286  decode.d3.loss_mask: 0.2801  decode.d3.loss_dice: 0.2243  decode.d4.loss_cls: 0.1446  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.2270  decode.d5.loss_cls: 0.1541  decode.d5.loss_mask: 0.2848  decode.d5.loss_dice: 0.2286  decode.d6.loss_cls: 0.1368  decode.d6.loss_mask: 0.2821  decode.d6.loss_dice: 0.2290  decode.d7.loss_cls: 0.1199  decode.d7.loss_mask: 0.2843  decode.d7.loss_dice: 0.2077  decode.d8.loss_cls: 0.1519  decode.d8.loss_mask: 0.2835  decode.d8.loss_dice: 0.2208
09/30 14:39:06 - mmengine - INFO - Iter(train) [ 46350/320000]  base_lr: 8.6864e-05 lr: 8.6864e-06  eta: 1 day, 8:59:32  time: 0.4367  data_time: 0.0097  memory: 5145  grad_norm: 47.1416  loss: 7.1178  decode.loss_cls: 0.1656  decode.loss_mask: 0.3345  decode.loss_dice: 0.2208  decode.d0.loss_cls: 0.9492  decode.d0.loss_mask: 0.2565  decode.d0.loss_dice: 0.2039  decode.d1.loss_cls: 0.1579  decode.d1.loss_mask: 0.2521  decode.d1.loss_dice: 0.1898  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 0.2722  decode.d2.loss_dice: 0.2149  decode.d3.loss_cls: 0.1726  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.2141  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 0.2540  decode.d4.loss_dice: 0.2056  decode.d5.loss_cls: 0.1466  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2011  decode.d6.loss_cls: 0.1552  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.1994  decode.d7.loss_cls: 0.1561  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.1977  decode.d8.loss_cls: 0.1608  decode.d8.loss_mask: 0.3151  decode.d8.loss_dice: 0.2080
09/30 14:39:28 - mmengine - INFO - Iter(train) [ 46400/320000]  base_lr: 8.6850e-05 lr: 8.6850e-06  eta: 1 day, 8:59:11  time: 0.4353  data_time: 0.0095  memory: 5145  grad_norm: 54.2387  loss: 8.2359  decode.loss_cls: 0.2520  decode.loss_mask: 0.2260  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.9304  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2693  decode.d1.loss_cls: 0.2927  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2682  decode.d2.loss_cls: 0.2655  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.2683  decode.d3.loss_mask: 0.2267  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.2925  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.2638  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.2486  decode.d6.loss_cls: 0.2618  decode.d6.loss_mask: 0.2272  decode.d6.loss_dice: 0.2455  decode.d7.loss_cls: 0.2625  decode.d7.loss_mask: 0.2242  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.3205  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.2877
09/30 14:39:50 - mmengine - INFO - Iter(train) [ 46450/320000]  base_lr: 8.6836e-05 lr: 8.6836e-06  eta: 1 day, 8:58:50  time: 0.4354  data_time: 0.0094  memory: 5145  grad_norm: 25.0857  loss: 5.8790  decode.loss_cls: 0.0575  decode.loss_mask: 0.2664  decode.loss_dice: 0.1950  decode.d0.loss_cls: 0.7481  decode.d0.loss_mask: 0.2736  decode.d0.loss_dice: 0.1919  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.2680  decode.d1.loss_dice: 0.1922  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.2705  decode.d3.loss_dice: 0.1950  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.1989  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.1929  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.2683  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.0498  decode.d7.loss_mask: 0.2665  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.2694  decode.d8.loss_dice: 0.1956
09/30 14:40:12 - mmengine - INFO - Iter(train) [ 46500/320000]  base_lr: 8.6822e-05 lr: 8.6822e-06  eta: 1 day, 8:58:29  time: 0.4351  data_time: 0.0095  memory: 5129  grad_norm: 55.7552  loss: 6.1000  decode.loss_cls: 0.1194  decode.loss_mask: 0.2412  decode.loss_dice: 0.2108  decode.d0.loss_cls: 0.8816  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.1756  decode.d1.loss_cls: 0.0871  decode.d1.loss_mask: 0.2426  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.2387  decode.d2.loss_dice: 0.1819  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.1833  decode.d4.loss_cls: 0.1167  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.1898  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.2409  decode.d5.loss_dice: 0.1866  decode.d6.loss_cls: 0.1436  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.1824  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.2420  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.2095
09/30 14:40:33 - mmengine - INFO - Iter(train) [ 46550/320000]  base_lr: 8.6807e-05 lr: 8.6807e-06  eta: 1 day, 8:58:08  time: 0.4357  data_time: 0.0096  memory: 5129  grad_norm: 30.1627  loss: 5.8536  decode.loss_cls: 0.0693  decode.loss_mask: 0.2619  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.7814  decode.d0.loss_mask: 0.2655  decode.d0.loss_dice: 0.1808  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.1834  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.1796  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.1822  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.2619  decode.d5.loss_dice: 0.1837  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.2563  decode.d6.loss_dice: 0.1812  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.1767  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.2586  decode.d8.loss_dice: 0.1806
09/30 14:40:55 - mmengine - INFO - Iter(train) [ 46600/320000]  base_lr: 8.6793e-05 lr: 8.6793e-06  eta: 1 day, 8:57:47  time: 0.4364  data_time: 0.0096  memory: 5120  grad_norm: 36.2157  loss: 4.8525  decode.loss_cls: 0.0095  decode.loss_mask: 0.2300  decode.loss_dice: 0.1635  decode.d0.loss_cls: 0.8272  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.1621  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.1614  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.1657  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.2319  decode.d3.loss_dice: 0.1653  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.1640  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.1651  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.2274  decode.d7.loss_dice: 0.1647  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.1634
09/30 14:41:17 - mmengine - INFO - Iter(train) [ 46650/320000]  base_lr: 8.6779e-05 lr: 8.6779e-06  eta: 1 day, 8:57:25  time: 0.4356  data_time: 0.0094  memory: 5129  grad_norm: 23.2033  loss: 5.5627  decode.loss_cls: 0.0939  decode.loss_mask: 0.1935  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.7655  decode.d0.loss_mask: 0.2007  decode.d0.loss_dice: 0.2283  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 0.1948  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.1949  decode.d2.loss_dice: 0.1851  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.1944  decode.d3.loss_dice: 0.1913  decode.d4.loss_cls: 0.0850  decode.d4.loss_mask: 0.1940  decode.d4.loss_dice: 0.1920  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.1962  decode.d5.loss_dice: 0.2013  decode.d6.loss_cls: 0.0952  decode.d6.loss_mask: 0.1968  decode.d6.loss_dice: 0.2126  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.2021  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.1922
09/30 14:41:39 - mmengine - INFO - Iter(train) [ 46700/320000]  base_lr: 8.6764e-05 lr: 8.6764e-06  eta: 1 day, 8:57:04  time: 0.4367  data_time: 0.0095  memory: 5120  grad_norm: 64.6159  loss: 6.5148  decode.loss_cls: 0.1295  decode.loss_mask: 0.2016  decode.loss_dice: 0.2344  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 0.2114  decode.d0.loss_dice: 0.2426  decode.d1.loss_cls: 0.1575  decode.d1.loss_mask: 0.2058  decode.d1.loss_dice: 0.2395  decode.d2.loss_cls: 0.1345  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.1591  decode.d3.loss_mask: 0.2050  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 0.2062  decode.d4.loss_dice: 0.2504  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.2054  decode.d6.loss_dice: 0.2454  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.2112  decode.d7.loss_dice: 0.2526  decode.d8.loss_cls: 0.1466  decode.d8.loss_mask: 0.2032  decode.d8.loss_dice: 0.2438
09/30 14:42:01 - mmengine - INFO - Iter(train) [ 46750/320000]  base_lr: 8.6750e-05 lr: 8.6750e-06  eta: 1 day, 8:56:43  time: 0.4358  data_time: 0.0095  memory: 5129  grad_norm: 160.0062  loss: 7.6192  decode.loss_cls: 0.1714  decode.loss_mask: 0.2736  decode.loss_dice: 0.2341  decode.d0.loss_cls: 0.9092  decode.d0.loss_mask: 0.2813  decode.d0.loss_dice: 0.2325  decode.d1.loss_cls: 0.2076  decode.d1.loss_mask: 0.2873  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.2074  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2045  decode.d3.loss_cls: 0.1288  decode.d3.loss_mask: 0.2698  decode.d3.loss_dice: 0.2361  decode.d4.loss_cls: 0.1670  decode.d4.loss_mask: 0.2722  decode.d4.loss_dice: 0.2389  decode.d5.loss_cls: 0.2057  decode.d5.loss_mask: 0.2715  decode.d5.loss_dice: 0.2327  decode.d6.loss_cls: 0.1758  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.2351  decode.d7.loss_cls: 0.1722  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.1749  decode.d8.loss_mask: 0.2773  decode.d8.loss_dice: 0.2185
09/30 14:42:22 - mmengine - INFO - Iter(train) [ 46800/320000]  base_lr: 8.6736e-05 lr: 8.6736e-06  eta: 1 day, 8:56:22  time: 0.4354  data_time: 0.0096  memory: 5120  grad_norm: 184.4034  loss: 9.1087  decode.loss_cls: 0.1524  decode.loss_mask: 0.3005  decode.loss_dice: 0.3179  decode.d0.loss_cls: 0.9582  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3166  decode.d1.loss_cls: 0.3153  decode.d1.loss_mask: 0.2992  decode.d1.loss_dice: 0.3168  decode.d2.loss_cls: 0.2779  decode.d2.loss_mask: 0.3133  decode.d2.loss_dice: 0.3167  decode.d3.loss_cls: 0.2215  decode.d3.loss_mask: 0.3030  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.2467  decode.d4.loss_mask: 0.2982  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.2448  decode.d5.loss_mask: 0.3015  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.1710  decode.d6.loss_mask: 0.2998  decode.d6.loss_dice: 0.3143  decode.d7.loss_cls: 0.1693  decode.d7.loss_mask: 0.3045  decode.d7.loss_dice: 0.3279  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.3029  decode.d8.loss_dice: 0.3279
09/30 14:42:44 - mmengine - INFO - Iter(train) [ 46850/320000]  base_lr: 8.6722e-05 lr: 8.6722e-06  eta: 1 day, 8:56:01  time: 0.4357  data_time: 0.0095  memory: 5129  grad_norm: 57.9676  loss: 6.6498  decode.loss_cls: 0.0337  decode.loss_mask: 0.2755  decode.loss_dice: 0.2325  decode.d0.loss_cls: 0.9365  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.2008  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.1295  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.1358  decode.d3.loss_mask: 0.2374  decode.d3.loss_dice: 0.2317  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.2291  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.2322  decode.d6.loss_cls: 0.1055  decode.d6.loss_mask: 0.2447  decode.d6.loss_dice: 0.2360  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.2542  decode.d7.loss_dice: 0.2331  decode.d8.loss_cls: 0.0426  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.2329
09/30 14:43:06 - mmengine - INFO - Iter(train) [ 46900/320000]  base_lr: 8.6707e-05 lr: 8.6707e-06  eta: 1 day, 8:55:40  time: 0.4352  data_time: 0.0092  memory: 5145  grad_norm: 33.8851  loss: 6.8682  decode.loss_cls: 0.1333  decode.loss_mask: 0.2218  decode.loss_dice: 0.2484  decode.d0.loss_cls: 0.9035  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2540  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.2325  decode.d2.loss_cls: 0.1238  decode.d2.loss_mask: 0.2203  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 0.2236  decode.d3.loss_dice: 0.2536  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.2428  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2426  decode.d6.loss_cls: 0.1675  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.1247  decode.d7.loss_mask: 0.2194  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.2279
09/30 14:43:28 - mmengine - INFO - Iter(train) [ 46950/320000]  base_lr: 8.6693e-05 lr: 8.6693e-06  eta: 1 day, 8:55:18  time: 0.4347  data_time: 0.0093  memory: 5120  grad_norm: 45.9218  loss: 9.3985  decode.loss_cls: 0.2366  decode.loss_mask: 0.2847  decode.loss_dice: 0.2402  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.2693  decode.d0.loss_dice: 0.2630  decode.d1.loss_cls: 0.3348  decode.d1.loss_mask: 0.3004  decode.d1.loss_dice: 0.2683  decode.d2.loss_cls: 0.2088  decode.d2.loss_mask: 0.3259  decode.d2.loss_dice: 0.2605  decode.d3.loss_cls: 0.1115  decode.d3.loss_mask: 0.5938  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.5935  decode.d4.loss_dice: 0.2479  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.5417  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.0858  decode.d6.loss_mask: 0.5796  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.0920  decode.d7.loss_mask: 0.5846  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.1088  decode.d8.loss_mask: 0.5622  decode.d8.loss_dice: 0.2459
09/30 14:43:49 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:43:49 - mmengine - INFO - Iter(train) [ 47000/320000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 1 day, 8:54:57  time: 0.4370  data_time: 0.0094  memory: 5129  grad_norm: 36.7278  loss: 5.9729  decode.loss_cls: 0.0065  decode.loss_mask: 0.2651  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.9676  decode.d0.loss_mask: 0.2655  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.2167  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.2604  decode.d2.loss_dice: 0.2123  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.2614  decode.d3.loss_dice: 0.2147  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2167  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.2622  decode.d5.loss_dice: 0.2185  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.2605  decode.d6.loss_dice: 0.2192  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.2605  decode.d7.loss_dice: 0.2240  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.2601  decode.d8.loss_dice: 0.2272
09/30 14:44:11 - mmengine - INFO - Iter(train) [ 47050/320000]  base_lr: 8.6664e-05 lr: 8.6664e-06  eta: 1 day, 8:54:36  time: 0.4350  data_time: 0.0093  memory: 5129  grad_norm: 65.8570  loss: 8.2784  decode.loss_cls: 0.1286  decode.loss_mask: 0.3150  decode.loss_dice: 0.2998  decode.d0.loss_cls: 0.8005  decode.d0.loss_mask: 0.3154  decode.d0.loss_dice: 0.3167  decode.d1.loss_cls: 0.2893  decode.d1.loss_mask: 0.3079  decode.d1.loss_dice: 0.2920  decode.d2.loss_cls: 0.2401  decode.d2.loss_mask: 0.3151  decode.d2.loss_dice: 0.2913  decode.d3.loss_cls: 0.1950  decode.d3.loss_mask: 0.2443  decode.d3.loss_dice: 0.3188  decode.d4.loss_cls: 0.1614  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.3356  decode.d5.loss_cls: 0.1664  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.3021  decode.d6.loss_cls: 0.1582  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2913  decode.d7.loss_cls: 0.1396  decode.d7.loss_mask: 0.3111  decode.d7.loss_dice: 0.2973  decode.d8.loss_cls: 0.1668  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2857
09/30 14:44:33 - mmengine - INFO - Iter(train) [ 47100/320000]  base_lr: 8.6650e-05 lr: 8.6650e-06  eta: 1 day, 8:54:14  time: 0.4359  data_time: 0.0093  memory: 5146  grad_norm: 90.6317  loss: 8.2969  decode.loss_cls: 0.1136  decode.loss_mask: 0.2986  decode.loss_dice: 0.3081  decode.d0.loss_cls: 0.8807  decode.d0.loss_mask: 0.3001  decode.d0.loss_dice: 0.3379  decode.d1.loss_cls: 0.1324  decode.d1.loss_mask: 0.2990  decode.d1.loss_dice: 0.2907  decode.d2.loss_cls: 0.1383  decode.d2.loss_mask: 0.2989  decode.d2.loss_dice: 0.2878  decode.d3.loss_cls: 0.1746  decode.d3.loss_mask: 0.3054  decode.d3.loss_dice: 0.3207  decode.d4.loss_cls: 0.1500  decode.d4.loss_mask: 0.3094  decode.d4.loss_dice: 0.3332  decode.d5.loss_cls: 0.2024  decode.d5.loss_mask: 0.2976  decode.d5.loss_dice: 0.2984  decode.d6.loss_cls: 0.1688  decode.d6.loss_mask: 0.2968  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.1608  decode.d7.loss_mask: 0.2991  decode.d7.loss_dice: 0.2756  decode.d8.loss_cls: 0.1478  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.2887
09/30 14:44:55 - mmengine - INFO - Iter(train) [ 47150/320000]  base_lr: 8.6636e-05 lr: 8.6636e-06  eta: 1 day, 8:53:53  time: 0.4350  data_time: 0.0094  memory: 5145  grad_norm: 110.9750  loss: 5.9449  decode.loss_cls: 0.0459  decode.loss_mask: 0.2784  decode.loss_dice: 0.2002  decode.d0.loss_cls: 0.8390  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.1964  decode.d1.loss_cls: 0.1403  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.1932  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.2815  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.2190  decode.d4.loss_dice: 0.1899  decode.d5.loss_cls: 0.0962  decode.d5.loss_mask: 0.2163  decode.d5.loss_dice: 0.1854  decode.d6.loss_cls: 0.0302  decode.d6.loss_mask: 0.2728  decode.d6.loss_dice: 0.1981  decode.d7.loss_cls: 0.1146  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.2027
09/30 14:45:17 - mmengine - INFO - Iter(train) [ 47200/320000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 1 day, 8:53:32  time: 0.4504  data_time: 0.0094  memory: 5120  grad_norm: 41.2605  loss: 6.4747  decode.loss_cls: 0.1041  decode.loss_mask: 0.2404  decode.loss_dice: 0.2277  decode.d0.loss_cls: 0.8363  decode.d0.loss_mask: 0.2473  decode.d0.loss_dice: 0.2195  decode.d1.loss_cls: 0.1378  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2258  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2256  decode.d3.loss_cls: 0.0892  decode.d3.loss_mask: 0.2453  decode.d3.loss_dice: 0.2255  decode.d4.loss_cls: 0.1030  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.2304  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.2305  decode.d6.loss_cls: 0.1167  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.2238  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2348  decode.d8.loss_cls: 0.1216  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2279
09/30 14:45:38 - mmengine - INFO - Iter(train) [ 47250/320000]  base_lr: 8.6607e-05 lr: 8.6607e-06  eta: 1 day, 8:53:11  time: 0.4341  data_time: 0.0090  memory: 5129  grad_norm: 84.1999  loss: 9.0291  decode.loss_cls: 0.1966  decode.loss_mask: 0.2932  decode.loss_dice: 0.2244  decode.d0.loss_cls: 0.8947  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.2266  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.4145  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.4251  decode.d2.loss_dice: 0.2594  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 0.4210  decode.d3.loss_dice: 0.2536  decode.d4.loss_cls: 0.0887  decode.d4.loss_mask: 0.4351  decode.d4.loss_dice: 0.2521  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.7904  decode.d5.loss_dice: 0.2651  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.4056  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.1671  decode.d7.loss_mask: 0.4204  decode.d7.loss_dice: 0.2622  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.7728  decode.d8.loss_dice: 0.2592
09/30 14:46:00 - mmengine - INFO - Iter(train) [ 47300/320000]  base_lr: 8.6593e-05 lr: 8.6593e-06  eta: 1 day, 8:52:50  time: 0.4362  data_time: 0.0094  memory: 5129  grad_norm: 46.2753  loss: 5.5915  decode.loss_cls: 0.0403  decode.loss_mask: 0.2569  decode.loss_dice: 0.1934  decode.d0.loss_cls: 0.6905  decode.d0.loss_mask: 0.2751  decode.d0.loss_dice: 0.2188  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.2548  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.1960  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.1958  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.2590  decode.d4.loss_dice: 0.2169  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.2108  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.2527  decode.d6.loss_dice: 0.2038  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.2550  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.2559  decode.d8.loss_dice: 0.1922
09/30 14:46:22 - mmengine - INFO - Iter(train) [ 47350/320000]  base_lr: 8.6579e-05 lr: 8.6579e-06  eta: 1 day, 8:52:29  time: 0.4360  data_time: 0.0093  memory: 5129  grad_norm: 90.7660  loss: 6.2557  decode.loss_cls: 0.0808  decode.loss_mask: 0.2742  decode.loss_dice: 0.1879  decode.d0.loss_cls: 0.9246  decode.d0.loss_mask: 0.2876  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.2778  decode.d1.loss_dice: 0.1870  decode.d2.loss_cls: 0.0874  decode.d2.loss_mask: 0.2719  decode.d2.loss_dice: 0.1857  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.1946  decode.d4.loss_cls: 0.0888  decode.d4.loss_mask: 0.2733  decode.d4.loss_dice: 0.1870  decode.d5.loss_cls: 0.0835  decode.d5.loss_mask: 0.2748  decode.d5.loss_dice: 0.1777  decode.d6.loss_cls: 0.0769  decode.d6.loss_mask: 0.2710  decode.d6.loss_dice: 0.1832  decode.d7.loss_cls: 0.0832  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.1774  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.1726
09/30 14:46:44 - mmengine - INFO - Iter(train) [ 47400/320000]  base_lr: 8.6564e-05 lr: 8.6564e-06  eta: 1 day, 8:52:07  time: 0.4359  data_time: 0.0095  memory: 5129  grad_norm: 66.0081  loss: 5.6571  decode.loss_cls: 0.0815  decode.loss_mask: 0.2248  decode.loss_dice: 0.1645  decode.d0.loss_cls: 0.8171  decode.d0.loss_mask: 0.2327  decode.d0.loss_dice: 0.1745  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.2490  decode.d1.loss_dice: 0.1884  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.2487  decode.d2.loss_dice: 0.1821  decode.d3.loss_cls: 0.0328  decode.d3.loss_mask: 0.2872  decode.d3.loss_dice: 0.1754  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2219  decode.d4.loss_dice: 0.1614  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.2362  decode.d5.loss_dice: 0.1742  decode.d6.loss_cls: 0.1109  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1692  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.2180  decode.d7.loss_dice: 0.1642  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.1674
09/30 14:47:06 - mmengine - INFO - Iter(train) [ 47450/320000]  base_lr: 8.6550e-05 lr: 8.6550e-06  eta: 1 day, 8:51:46  time: 0.4352  data_time: 0.0091  memory: 5129  grad_norm: 46.8113  loss: 6.3372  decode.loss_cls: 0.0800  decode.loss_mask: 0.2416  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.8567  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2090  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 0.2396  decode.d1.loss_dice: 0.1915  decode.d2.loss_cls: 0.1566  decode.d2.loss_mask: 0.2395  decode.d2.loss_dice: 0.2011  decode.d3.loss_cls: 0.1034  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 0.2375  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.0998  decode.d6.loss_mask: 0.2382  decode.d6.loss_dice: 0.1946  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.2403  decode.d7.loss_dice: 0.1942  decode.d8.loss_cls: 0.1977  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.1927
09/30 14:47:27 - mmengine - INFO - Iter(train) [ 47500/320000]  base_lr: 8.6536e-05 lr: 8.6536e-06  eta: 1 day, 8:51:25  time: 0.4353  data_time: 0.0092  memory: 5120  grad_norm: 55.3161  loss: 5.3006  decode.loss_cls: 0.0735  decode.loss_mask: 0.2137  decode.loss_dice: 0.1813  decode.d0.loss_cls: 0.7525  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.1936  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.2143  decode.d1.loss_dice: 0.1798  decode.d2.loss_cls: 0.0857  decode.d2.loss_mask: 0.2166  decode.d2.loss_dice: 0.1726  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.1849  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.2132  decode.d4.loss_dice: 0.1662  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.2137  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.1732  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.2147  decode.d7.loss_dice: 0.1661  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.1708
09/30 14:47:49 - mmengine - INFO - Iter(train) [ 47550/320000]  base_lr: 8.6522e-05 lr: 8.6522e-06  eta: 1 day, 8:51:03  time: 0.4361  data_time: 0.0093  memory: 5129  grad_norm: 130.9853  loss: 9.8909  decode.loss_cls: 0.2623  decode.loss_mask: 0.2935  decode.loss_dice: 0.3081  decode.d0.loss_cls: 1.1212  decode.d0.loss_mask: 0.3057  decode.d0.loss_dice: 0.3158  decode.d1.loss_cls: 0.3139  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.2967  decode.d2.loss_cls: 0.2545  decode.d2.loss_mask: 0.3022  decode.d2.loss_dice: 0.2977  decode.d3.loss_cls: 0.2803  decode.d3.loss_mask: 0.3019  decode.d3.loss_dice: 0.3194  decode.d4.loss_cls: 0.3293  decode.d4.loss_mask: 0.3179  decode.d4.loss_dice: 0.3101  decode.d5.loss_cls: 0.3072  decode.d5.loss_mask: 0.3066  decode.d5.loss_dice: 0.3035  decode.d6.loss_cls: 0.3207  decode.d6.loss_mask: 0.3131  decode.d6.loss_dice: 0.2970  decode.d7.loss_cls: 0.2669  decode.d7.loss_mask: 0.3102  decode.d7.loss_dice: 0.2946  decode.d8.loss_cls: 0.3081  decode.d8.loss_mask: 0.2986  decode.d8.loss_dice: 0.3169
09/30 14:48:11 - mmengine - INFO - Iter(train) [ 47600/320000]  base_lr: 8.6507e-05 lr: 8.6507e-06  eta: 1 day, 8:50:42  time: 0.4370  data_time: 0.0096  memory: 5145  grad_norm: 26.0199  loss: 5.9667  decode.loss_cls: 0.1017  decode.loss_mask: 0.2422  decode.loss_dice: 0.1586  decode.d0.loss_cls: 1.0168  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.1643  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.1542  decode.d2.loss_cls: 0.1131  decode.d2.loss_mask: 0.2412  decode.d2.loss_dice: 0.1577  decode.d3.loss_cls: 0.1103  decode.d3.loss_mask: 0.2335  decode.d3.loss_dice: 0.1552  decode.d4.loss_cls: 0.1234  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.1532  decode.d5.loss_cls: 0.1262  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.1590  decode.d6.loss_cls: 0.1059  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.1552  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.1484  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.1554
09/30 14:48:33 - mmengine - INFO - Iter(train) [ 47650/320000]  base_lr: 8.6493e-05 lr: 8.6493e-06  eta: 1 day, 8:50:21  time: 0.4359  data_time: 0.0094  memory: 5145  grad_norm: 96.1226  loss: 5.9721  decode.loss_cls: 0.0690  decode.loss_mask: 0.2229  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.8264  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2320  decode.d1.loss_cls: 0.1095  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.2273  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2299  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.0573  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.2397  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.2235  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2343  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.2344  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.2338
09/30 14:48:55 - mmengine - INFO - Iter(train) [ 47700/320000]  base_lr: 8.6479e-05 lr: 8.6479e-06  eta: 1 day, 8:50:00  time: 0.4377  data_time: 0.0095  memory: 5129  grad_norm: 53.7769  loss: 6.5413  decode.loss_cls: 0.0407  decode.loss_mask: 0.3081  decode.loss_dice: 0.2145  decode.d0.loss_cls: 0.8718  decode.d0.loss_mask: 0.2637  decode.d0.loss_dice: 0.2019  decode.d1.loss_cls: 0.1468  decode.d1.loss_mask: 0.2612  decode.d1.loss_dice: 0.2055  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.3180  decode.d2.loss_dice: 0.2085  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.3089  decode.d3.loss_dice: 0.2163  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.3107  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 0.3089  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.2048  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.2175  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.3112  decode.d8.loss_dice: 0.2118
09/30 14:49:16 - mmengine - INFO - Iter(train) [ 47750/320000]  base_lr: 8.6464e-05 lr: 8.6464e-06  eta: 1 day, 8:49:39  time: 0.4366  data_time: 0.0094  memory: 5145  grad_norm: 169.1078  loss: 8.6284  decode.loss_cls: 0.1944  decode.loss_mask: 0.3378  decode.loss_dice: 0.2837  decode.d0.loss_cls: 0.9608  decode.d0.loss_mask: 0.3337  decode.d0.loss_dice: 0.2723  decode.d1.loss_cls: 0.2045  decode.d1.loss_mask: 0.3574  decode.d1.loss_dice: 0.2887  decode.d2.loss_cls: 0.1246  decode.d2.loss_mask: 0.3278  decode.d2.loss_dice: 0.2772  decode.d3.loss_cls: 0.1166  decode.d3.loss_mask: 0.3245  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 0.3710  decode.d4.loss_dice: 0.2999  decode.d5.loss_cls: 0.1412  decode.d5.loss_mask: 0.3465  decode.d5.loss_dice: 0.3005  decode.d6.loss_cls: 0.1592  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.2849  decode.d7.loss_cls: 0.1763  decode.d7.loss_mask: 0.3296  decode.d7.loss_dice: 0.2995  decode.d8.loss_cls: 0.1925  decode.d8.loss_mask: 0.3295  decode.d8.loss_dice: 0.2768
09/30 14:49:38 - mmengine - INFO - Iter(train) [ 47800/320000]  base_lr: 8.6450e-05 lr: 8.6450e-06  eta: 1 day, 8:49:18  time: 0.4361  data_time: 0.0095  memory: 5130  grad_norm: 59.2331  loss: 6.6004  decode.loss_cls: 0.0840  decode.loss_mask: 0.2270  decode.loss_dice: 0.2783  decode.d0.loss_cls: 0.7888  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2577  decode.d1.loss_cls: 0.1482  decode.d1.loss_mask: 0.2269  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.0831  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.2651  decode.d3.loss_cls: 0.1178  decode.d3.loss_mask: 0.2277  decode.d3.loss_dice: 0.2700  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 0.2264  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.2675  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.0920  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.0855  decode.d8.loss_mask: 0.2275  decode.d8.loss_dice: 0.2789
09/30 14:50:00 - mmengine - INFO - Iter(train) [ 47850/320000]  base_lr: 8.6436e-05 lr: 8.6436e-06  eta: 1 day, 8:48:56  time: 0.4361  data_time: 0.0094  memory: 5120  grad_norm: 68.2473  loss: 7.5562  decode.loss_cls: 0.1762  decode.loss_mask: 0.2227  decode.loss_dice: 0.2481  decode.d0.loss_cls: 0.9797  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.2494  decode.d1.loss_cls: 0.2040  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2276  decode.d2.loss_cls: 0.1618  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.3079  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2976  decode.d4.loss_cls: 0.1998  decode.d4.loss_mask: 0.2307  decode.d4.loss_dice: 0.2955  decode.d5.loss_cls: 0.1951  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.2486  decode.d6.loss_cls: 0.1930  decode.d6.loss_mask: 0.2225  decode.d6.loss_dice: 0.2870  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 0.2210  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.1814  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.2355
09/30 14:50:22 - mmengine - INFO - Iter(train) [ 47900/320000]  base_lr: 8.6422e-05 lr: 8.6422e-06  eta: 1 day, 8:48:35  time: 0.4357  data_time: 0.0093  memory: 5129  grad_norm: 138.0740  loss: 6.9100  decode.loss_cls: 0.0781  decode.loss_mask: 0.2577  decode.loss_dice: 0.2359  decode.d0.loss_cls: 0.9739  decode.d0.loss_mask: 0.2622  decode.d0.loss_dice: 0.2303  decode.d1.loss_cls: 0.1472  decode.d1.loss_mask: 0.2595  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.1459  decode.d2.loss_mask: 0.2548  decode.d2.loss_dice: 0.2361  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 0.2574  decode.d3.loss_dice: 0.2358  decode.d4.loss_cls: 0.1153  decode.d4.loss_mask: 0.2542  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.1048  decode.d5.loss_mask: 0.2545  decode.d5.loss_dice: 0.2424  decode.d6.loss_cls: 0.0894  decode.d6.loss_mask: 0.2610  decode.d6.loss_dice: 0.2525  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.2560  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.2612  decode.d8.loss_dice: 0.2330
09/30 14:50:44 - mmengine - INFO - Iter(train) [ 47950/320000]  base_lr: 8.6407e-05 lr: 8.6407e-06  eta: 1 day, 8:48:14  time: 0.4354  data_time: 0.0096  memory: 5130  grad_norm: 69.0068  loss: 7.2425  decode.loss_cls: 0.0592  decode.loss_mask: 0.2900  decode.loss_dice: 0.2402  decode.d0.loss_cls: 0.9075  decode.d0.loss_mask: 0.2989  decode.d0.loss_dice: 0.2480  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.2611  decode.d2.loss_cls: 0.1101  decode.d2.loss_mask: 0.2921  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.2622  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.2448  decode.d5.loss_cls: 0.1047  decode.d5.loss_mask: 0.2869  decode.d5.loss_dice: 0.2587  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.2876  decode.d6.loss_dice: 0.2388  decode.d7.loss_cls: 0.0862  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.2572  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.2870  decode.d8.loss_dice: 0.2490
09/30 14:51:05 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:51:05 - mmengine - INFO - Iter(train) [ 48000/320000]  base_lr: 8.6393e-05 lr: 8.6393e-06  eta: 1 day, 8:47:53  time: 0.4360  data_time: 0.0095  memory: 5120  grad_norm: 37.2305  loss: 7.6484  decode.loss_cls: 0.1759  decode.loss_mask: 0.2139  decode.loss_dice: 0.2850  decode.d0.loss_cls: 0.9057  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.3085  decode.d1.loss_cls: 0.2469  decode.d1.loss_mask: 0.2187  decode.d1.loss_dice: 0.2797  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2597  decode.d3.loss_cls: 0.1950  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.2955  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.2995  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.2904  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.2800  decode.d7.loss_cls: 0.1276  decode.d7.loss_mask: 0.2794  decode.d7.loss_dice: 0.2790  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.2722
09/30 14:51:27 - mmengine - INFO - Iter(train) [ 48050/320000]  base_lr: 8.6379e-05 lr: 8.6379e-06  eta: 1 day, 8:47:32  time: 0.4357  data_time: 0.0096  memory: 5145  grad_norm: 64.3789  loss: 5.8262  decode.loss_cls: 0.0590  decode.loss_mask: 0.2566  decode.loss_dice: 0.1958  decode.d0.loss_cls: 0.8021  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.1998  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.2559  decode.d1.loss_dice: 0.1978  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.2569  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.2134  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.2034  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.2070  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.2563  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 0.2575  decode.d7.loss_dice: 0.2071  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.2051
09/30 14:51:49 - mmengine - INFO - Iter(train) [ 48100/320000]  base_lr: 8.6364e-05 lr: 8.6364e-06  eta: 1 day, 8:47:11  time: 0.4360  data_time: 0.0097  memory: 5129  grad_norm: 73.0240  loss: 6.6334  decode.loss_cls: 0.0418  decode.loss_mask: 0.2841  decode.loss_dice: 0.2287  decode.d0.loss_cls: 0.9442  decode.d0.loss_mask: 0.2841  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.1415  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.2556  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.2844  decode.d2.loss_dice: 0.2271  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.2253  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.2196  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.2814  decode.d5.loss_dice: 0.2415  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.2792  decode.d6.loss_dice: 0.2466  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.2777  decode.d7.loss_dice: 0.2227  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.2490
09/30 14:52:11 - mmengine - INFO - Iter(train) [ 48150/320000]  base_lr: 8.6350e-05 lr: 8.6350e-06  eta: 1 day, 8:46:49  time: 0.4355  data_time: 0.0095  memory: 5145  grad_norm: 192.3431  loss: 6.9297  decode.loss_cls: 0.1364  decode.loss_mask: 0.2724  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 0.2829  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.0816  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.2149  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.2919  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.2742  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.1613  decode.d5.loss_mask: 0.2834  decode.d5.loss_dice: 0.2141  decode.d6.loss_cls: 0.1288  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0901  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.1458  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.2156
09/30 14:52:33 - mmengine - INFO - Iter(train) [ 48200/320000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 1 day, 8:46:28  time: 0.4358  data_time: 0.0096  memory: 5129  grad_norm: 50.7458  loss: 8.1254  decode.loss_cls: 0.2050  decode.loss_mask: 0.2759  decode.loss_dice: 0.2709  decode.d0.loss_cls: 0.8123  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.2673  decode.d1.loss_cls: 0.2007  decode.d1.loss_mask: 0.2727  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.1771  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.1760  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.2814  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 0.2743  decode.d4.loss_dice: 0.2789  decode.d5.loss_cls: 0.2056  decode.d5.loss_mask: 0.2777  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 0.2809  decode.d6.loss_dice: 0.2784  decode.d7.loss_cls: 0.2051  decode.d7.loss_mask: 0.2777  decode.d7.loss_dice: 0.2819  decode.d8.loss_cls: 0.2271  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2698
09/30 14:52:54 - mmengine - INFO - Iter(train) [ 48250/320000]  base_lr: 8.6321e-05 lr: 8.6321e-06  eta: 1 day, 8:46:07  time: 0.4361  data_time: 0.0095  memory: 5145  grad_norm: 28.9469  loss: 5.5787  decode.loss_cls: 0.0410  decode.loss_mask: 0.1902  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.9728  decode.d0.loss_mask: 0.1840  decode.d0.loss_dice: 0.2271  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.1885  decode.d1.loss_dice: 0.2165  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.1887  decode.d2.loss_dice: 0.2334  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.1852  decode.d3.loss_dice: 0.2197  decode.d4.loss_cls: 0.0392  decode.d4.loss_mask: 0.1874  decode.d4.loss_dice: 0.2055  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.1903  decode.d5.loss_dice: 0.2212  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.1914  decode.d6.loss_dice: 0.2255  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.1928  decode.d7.loss_dice: 0.2287  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.1916  decode.d8.loss_dice: 0.2351
09/30 14:53:16 - mmengine - INFO - Iter(train) [ 48300/320000]  base_lr: 8.6307e-05 lr: 8.6307e-06  eta: 1 day, 8:45:46  time: 0.4359  data_time: 0.0097  memory: 5120  grad_norm: 75.4734  loss: 5.5300  decode.loss_cls: 0.0499  decode.loss_mask: 0.2506  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.8279  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.1706  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.2513  decode.d1.loss_dice: 0.1809  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.2521  decode.d2.loss_dice: 0.1817  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.2497  decode.d3.loss_dice: 0.1769  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.1707  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.2559  decode.d5.loss_dice: 0.1746  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.2510  decode.d6.loss_dice: 0.1714  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.1754  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.2458  decode.d8.loss_dice: 0.1788
09/30 14:53:38 - mmengine - INFO - Iter(train) [ 48350/320000]  base_lr: 8.6293e-05 lr: 8.6293e-06  eta: 1 day, 8:45:25  time: 0.4367  data_time: 0.0096  memory: 5120  grad_norm: 47.0092  loss: 6.1093  decode.loss_cls: 0.0591  decode.loss_mask: 0.2843  decode.loss_dice: 0.1907  decode.d0.loss_cls: 0.8500  decode.d0.loss_mask: 0.2937  decode.d0.loss_dice: 0.1999  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.1937  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.2811  decode.d2.loss_dice: 0.1941  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.1976  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.2788  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.2807  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.2830  decode.d7.loss_dice: 0.1939  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.2799  decode.d8.loss_dice: 0.1927
09/30 14:54:00 - mmengine - INFO - Iter(train) [ 48400/320000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 1 day, 8:45:04  time: 0.4365  data_time: 0.0094  memory: 5129  grad_norm: 85.5048  loss: 6.5095  decode.loss_cls: 0.0915  decode.loss_mask: 0.2831  decode.loss_dice: 0.1919  decode.d0.loss_cls: 0.7955  decode.d0.loss_mask: 0.2833  decode.d0.loss_dice: 0.1821  decode.d1.loss_cls: 0.1584  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.1787  decode.d2.loss_cls: 0.1068  decode.d2.loss_mask: 0.2863  decode.d2.loss_dice: 0.1764  decode.d3.loss_cls: 0.1636  decode.d3.loss_mask: 0.2836  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.2824  decode.d4.loss_dice: 0.1757  decode.d5.loss_cls: 0.1190  decode.d5.loss_mask: 0.2858  decode.d5.loss_dice: 0.1821  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.2836  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.0972  decode.d7.loss_mask: 0.2844  decode.d7.loss_dice: 0.1703  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.2879  decode.d8.loss_dice: 0.1767
09/30 14:54:22 - mmengine - INFO - Iter(train) [ 48450/320000]  base_lr: 8.6264e-05 lr: 8.6264e-06  eta: 1 day, 8:44:42  time: 0.4363  data_time: 0.0097  memory: 5129  grad_norm: 14.6753  loss: 4.6730  decode.loss_cls: 0.0021  decode.loss_mask: 0.2245  decode.loss_dice: 0.1750  decode.d0.loss_cls: 0.6700  decode.d0.loss_mask: 0.2250  decode.d0.loss_dice: 0.1837  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.2214  decode.d1.loss_dice: 0.1766  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.1708  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.1751  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.2197  decode.d4.loss_dice: 0.1702  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.1732  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2243  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.1752
09/30 14:54:43 - mmengine - INFO - Iter(train) [ 48500/320000]  base_lr: 8.6250e-05 lr: 8.6250e-06  eta: 1 day, 8:44:21  time: 0.4356  data_time: 0.0095  memory: 5129  grad_norm: 47.4309  loss: 7.0362  decode.loss_cls: 0.1645  decode.loss_mask: 0.1991  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.9342  decode.d0.loss_mask: 0.2025  decode.d0.loss_dice: 0.2591  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.2402  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.2477  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 0.1991  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.1613  decode.d4.loss_mask: 0.2006  decode.d4.loss_dice: 0.2465  decode.d5.loss_cls: 0.2094  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.1603  decode.d6.loss_mask: 0.2011  decode.d6.loss_dice: 0.2381  decode.d7.loss_cls: 0.1571  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.1710  decode.d8.loss_mask: 0.2010  decode.d8.loss_dice: 0.2596
09/30 14:55:05 - mmengine - INFO - Iter(train) [ 48550/320000]  base_lr: 8.6236e-05 lr: 8.6236e-06  eta: 1 day, 8:44:00  time: 0.4359  data_time: 0.0095  memory: 5120  grad_norm: 40.1743  loss: 5.5614  decode.loss_cls: 0.0711  decode.loss_mask: 0.2088  decode.loss_dice: 0.1845  decode.d0.loss_cls: 0.9064  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.1155  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.1881  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.2081  decode.d5.loss_dice: 0.1790  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.2106  decode.d6.loss_dice: 0.1840  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.2086  decode.d7.loss_dice: 0.1873  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.1890
09/30 14:55:27 - mmengine - INFO - Iter(train) [ 48600/320000]  base_lr: 8.6221e-05 lr: 8.6221e-06  eta: 1 day, 8:43:39  time: 0.4379  data_time: 0.0096  memory: 5129  grad_norm: 81.9573  loss: 6.7353  decode.loss_cls: 0.1588  decode.loss_mask: 0.1996  decode.loss_dice: 0.2249  decode.d0.loss_cls: 0.9796  decode.d0.loss_mask: 0.2044  decode.d0.loss_dice: 0.2755  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 0.2009  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.1371  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.2714  decode.d3.loss_cls: 0.1376  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.1187  decode.d4.loss_mask: 0.2077  decode.d4.loss_dice: 0.2507  decode.d5.loss_cls: 0.1319  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.1292  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.2442
09/30 14:55:49 - mmengine - INFO - Iter(train) [ 48650/320000]  base_lr: 8.6207e-05 lr: 8.6207e-06  eta: 1 day, 8:43:18  time: 0.4349  data_time: 0.0095  memory: 5129  grad_norm: 31.3166  loss: 5.0415  decode.loss_cls: 0.0216  decode.loss_mask: 0.2096  decode.loss_dice: 0.1847  decode.d0.loss_cls: 0.9149  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.2010  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.2252  decode.d1.loss_dice: 0.1879  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.2056  decode.d2.loss_dice: 0.1777  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.2090  decode.d3.loss_dice: 0.1794  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.2097  decode.d4.loss_dice: 0.1754  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 0.2065  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.1739  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 0.2041  decode.d7.loss_dice: 0.1765  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.2083  decode.d8.loss_dice: 0.1824
09/30 14:56:11 - mmengine - INFO - Iter(train) [ 48700/320000]  base_lr: 8.6193e-05 lr: 8.6193e-06  eta: 1 day, 8:42:57  time: 0.4353  data_time: 0.0094  memory: 5129  grad_norm: 140.2090  loss: 8.4476  decode.loss_cls: 0.1629  decode.loss_mask: 0.3471  decode.loss_dice: 0.2334  decode.d0.loss_cls: 1.0280  decode.d0.loss_mask: 0.3066  decode.d0.loss_dice: 0.2358  decode.d1.loss_cls: 0.1907  decode.d1.loss_mask: 0.3307  decode.d1.loss_dice: 0.2430  decode.d2.loss_cls: 0.1926  decode.d2.loss_mask: 0.4571  decode.d2.loss_dice: 0.2330  decode.d3.loss_cls: 0.1997  decode.d3.loss_mask: 0.3580  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.0991  decode.d4.loss_mask: 0.4740  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.4782  decode.d5.loss_dice: 0.2226  decode.d6.loss_cls: 0.1378  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.2343  decode.d7.loss_cls: 0.1415  decode.d7.loss_mask: 0.3487  decode.d7.loss_dice: 0.2448  decode.d8.loss_cls: 0.1100  decode.d8.loss_mask: 0.3378  decode.d8.loss_dice: 0.2267
09/30 14:56:33 - mmengine - INFO - Iter(train) [ 48750/320000]  base_lr: 8.6179e-05 lr: 8.6179e-06  eta: 1 day, 8:42:36  time: 0.4350  data_time: 0.0095  memory: 5120  grad_norm: 41.1565  loss: 5.0395  decode.loss_cls: 0.0910  decode.loss_mask: 0.1679  decode.loss_dice: 0.1516  decode.d0.loss_cls: 0.9158  decode.d0.loss_mask: 0.1704  decode.d0.loss_dice: 0.1511  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 0.1685  decode.d1.loss_dice: 0.1498  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.1676  decode.d2.loss_dice: 0.1513  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.1700  decode.d3.loss_dice: 0.1568  decode.d4.loss_cls: 0.1016  decode.d4.loss_mask: 0.1688  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 0.1699  decode.d5.loss_dice: 0.1558  decode.d6.loss_cls: 0.1115  decode.d6.loss_mask: 0.1676  decode.d6.loss_dice: 0.1513  decode.d7.loss_cls: 0.1138  decode.d7.loss_mask: 0.1665  decode.d7.loss_dice: 0.1523  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.1679  decode.d8.loss_dice: 0.1510
09/30 14:56:54 - mmengine - INFO - Iter(train) [ 48800/320000]  base_lr: 8.6164e-05 lr: 8.6164e-06  eta: 1 day, 8:42:14  time: 0.4348  data_time: 0.0095  memory: 5129  grad_norm: 64.7401  loss: 6.2631  decode.loss_cls: 0.0730  decode.loss_mask: 0.2416  decode.loss_dice: 0.2219  decode.d0.loss_cls: 0.8184  decode.d0.loss_mask: 0.2472  decode.d0.loss_dice: 0.2194  decode.d1.loss_cls: 0.1584  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.2070  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.2434  decode.d2.loss_dice: 0.2167  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2242  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.2260  decode.d5.loss_cls: 0.0979  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.2230  decode.d6.loss_cls: 0.0943  decode.d6.loss_mask: 0.2418  decode.d6.loss_dice: 0.2041  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.2398  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.2458  decode.d8.loss_dice: 0.2110
09/30 14:57:16 - mmengine - INFO - Iter(train) [ 48850/320000]  base_lr: 8.6150e-05 lr: 8.6150e-06  eta: 1 day, 8:41:53  time: 0.4362  data_time: 0.0095  memory: 5120  grad_norm: 27.2792  loss: 5.0920  decode.loss_cls: 0.0919  decode.loss_mask: 0.1548  decode.loss_dice: 0.1569  decode.d0.loss_cls: 0.9871  decode.d0.loss_mask: 0.1576  decode.d0.loss_dice: 0.1666  decode.d1.loss_cls: 0.1877  decode.d1.loss_mask: 0.1547  decode.d1.loss_dice: 0.1515  decode.d2.loss_cls: 0.1043  decode.d2.loss_mask: 0.1553  decode.d2.loss_dice: 0.1599  decode.d3.loss_cls: 0.0950  decode.d3.loss_mask: 0.1565  decode.d3.loss_dice: 0.1587  decode.d4.loss_cls: 0.0870  decode.d4.loss_mask: 0.1578  decode.d4.loss_dice: 0.1545  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.1761  decode.d5.loss_dice: 0.1695  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.1567  decode.d6.loss_dice: 0.1574  decode.d7.loss_cls: 0.0966  decode.d7.loss_mask: 0.1602  decode.d7.loss_dice: 0.1571  decode.d8.loss_cls: 0.1020  decode.d8.loss_mask: 0.1553  decode.d8.loss_dice: 0.1617
09/30 14:57:38 - mmengine - INFO - Iter(train) [ 48900/320000]  base_lr: 8.6136e-05 lr: 8.6136e-06  eta: 1 day, 8:41:33  time: 0.4353  data_time: 0.0093  memory: 5129  grad_norm: 38.7229  loss: 6.9411  decode.loss_cls: 0.1284  decode.loss_mask: 0.3216  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.9027  decode.d0.loss_mask: 0.3059  decode.d0.loss_dice: 0.1928  decode.d1.loss_cls: 0.1401  decode.d1.loss_mask: 0.2900  decode.d1.loss_dice: 0.1866  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.3001  decode.d2.loss_dice: 0.1900  decode.d3.loss_cls: 0.1301  decode.d3.loss_mask: 0.2875  decode.d3.loss_dice: 0.1805  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.3275  decode.d4.loss_dice: 0.1837  decode.d5.loss_cls: 0.1433  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.1779  decode.d6.loss_cls: 0.1261  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.1790  decode.d7.loss_cls: 0.1381  decode.d7.loss_mask: 0.2921  decode.d7.loss_dice: 0.1997  decode.d8.loss_cls: 0.1321  decode.d8.loss_mask: 0.3046  decode.d8.loss_dice: 0.1822
09/30 14:58:00 - mmengine - INFO - Iter(train) [ 48950/320000]  base_lr: 8.6121e-05 lr: 8.6121e-06  eta: 1 day, 8:41:12  time: 0.4361  data_time: 0.0095  memory: 5120  grad_norm: 30.2947  loss: 6.5838  decode.loss_cls: 0.0829  decode.loss_mask: 0.2100  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.9486  decode.d0.loss_mask: 0.2150  decode.d0.loss_dice: 0.2818  decode.d1.loss_cls: 0.1233  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.2667  decode.d3.loss_cls: 0.0875  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.2578  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.2657  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.2140  decode.d5.loss_dice: 0.2864  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.2096  decode.d6.loss_dice: 0.2447  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.2148  decode.d7.loss_dice: 0.2649  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.2091  decode.d8.loss_dice: 0.2693
09/30 14:58:22 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 14:58:22 - mmengine - INFO - Iter(train) [ 49000/320000]  base_lr: 8.6107e-05 lr: 8.6107e-06  eta: 1 day, 8:40:51  time: 0.4350  data_time: 0.0094  memory: 5145  grad_norm: 57.9567  loss: 5.2826  decode.loss_cls: 0.0607  decode.loss_mask: 0.2250  decode.loss_dice: 0.1702  decode.d0.loss_cls: 0.6938  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.1768  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1706  decode.d2.loss_cls: 0.0995  decode.d2.loss_mask: 0.2222  decode.d2.loss_dice: 0.1691  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.1717  decode.d4.loss_cls: 0.0903  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.2203  decode.d5.loss_dice: 0.1687  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.1707  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.1695  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.2234  decode.d8.loss_dice: 0.1661
09/30 14:58:44 - mmengine - INFO - Iter(train) [ 49050/320000]  base_lr: 8.6093e-05 lr: 8.6093e-06  eta: 1 day, 8:40:30  time: 0.4365  data_time: 0.0097  memory: 5145  grad_norm: 113.1203  loss: 8.4263  decode.loss_cls: 0.2062  decode.loss_mask: 0.2838  decode.loss_dice: 0.2894  decode.d0.loss_cls: 1.1978  decode.d0.loss_mask: 0.2837  decode.d0.loss_dice: 0.2821  decode.d1.loss_cls: 0.2619  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.2502  decode.d2.loss_cls: 0.2829  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.2410  decode.d3.loss_cls: 0.1974  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2524  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 0.2562  decode.d4.loss_dice: 0.2541  decode.d5.loss_cls: 0.2128  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.2447  decode.d6.loss_cls: 0.2133  decode.d6.loss_mask: 0.2946  decode.d6.loss_dice: 0.2504  decode.d7.loss_cls: 0.1457  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.2457  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 0.2766  decode.d8.loss_dice: 0.2606
09/30 14:59:05 - mmengine - INFO - Iter(train) [ 49100/320000]  base_lr: 8.6078e-05 lr: 8.6078e-06  eta: 1 day, 8:40:08  time: 0.4371  data_time: 0.0096  memory: 5129  grad_norm: 26.2732  loss: 5.8474  decode.loss_cls: 0.0166  decode.loss_mask: 0.2558  decode.loss_dice: 0.2210  decode.d0.loss_cls: 0.8046  decode.d0.loss_mask: 0.2669  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.2195  decode.d2.loss_cls: 0.0384  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.2254  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.2273  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2248  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2173  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.2193  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.2604  decode.d8.loss_dice: 0.2197
09/30 14:59:27 - mmengine - INFO - Iter(train) [ 49150/320000]  base_lr: 8.6064e-05 lr: 8.6064e-06  eta: 1 day, 8:39:47  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 87.7129  loss: 6.7227  decode.loss_cls: 0.1982  decode.loss_mask: 0.2253  decode.loss_dice: 0.1973  decode.d0.loss_cls: 1.0041  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.2025  decode.d1.loss_cls: 0.1482  decode.d1.loss_mask: 0.2397  decode.d1.loss_dice: 0.2132  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.2375  decode.d2.loss_dice: 0.2161  decode.d3.loss_cls: 0.1279  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2106  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.2098  decode.d5.loss_cls: 0.1296  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.1984  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.2210  decode.d7.loss_cls: 0.1367  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.2167  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.2111
09/30 14:59:49 - mmengine - INFO - Iter(train) [ 49200/320000]  base_lr: 8.6050e-05 lr: 8.6050e-06  eta: 1 day, 8:39:26  time: 0.4369  data_time: 0.0096  memory: 5129  grad_norm: 129.7117  loss: 8.6146  decode.loss_cls: 0.2383  decode.loss_mask: 0.3247  decode.loss_dice: 0.2350  decode.d0.loss_cls: 0.8476  decode.d0.loss_mask: 0.3315  decode.d0.loss_dice: 0.2469  decode.d1.loss_cls: 0.1428  decode.d1.loss_mask: 0.3366  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.1668  decode.d2.loss_mask: 0.3294  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.2135  decode.d3.loss_mask: 0.3222  decode.d3.loss_dice: 0.2370  decode.d4.loss_cls: 0.2674  decode.d4.loss_mask: 0.3413  decode.d4.loss_dice: 0.2447  decode.d5.loss_cls: 0.3060  decode.d5.loss_mask: 0.3197  decode.d5.loss_dice: 0.2328  decode.d6.loss_cls: 0.2607  decode.d6.loss_mask: 0.3267  decode.d6.loss_dice: 0.2394  decode.d7.loss_cls: 0.2592  decode.d7.loss_mask: 0.3255  decode.d7.loss_dice: 0.2361  decode.d8.loss_cls: 0.2346  decode.d8.loss_mask: 0.3284  decode.d8.loss_dice: 0.2334
09/30 15:00:11 - mmengine - INFO - Iter(train) [ 49250/320000]  base_lr: 8.6036e-05 lr: 8.6036e-06  eta: 1 day, 8:39:05  time: 0.4374  data_time: 0.0095  memory: 5129  grad_norm: 145.7785  loss: 7.5936  decode.loss_cls: 0.3042  decode.loss_mask: 0.1818  decode.loss_dice: 0.2607  decode.d0.loss_cls: 1.0307  decode.d0.loss_mask: 0.1813  decode.d0.loss_dice: 0.2649  decode.d1.loss_cls: 0.2444  decode.d1.loss_mask: 0.1794  decode.d1.loss_dice: 0.2430  decode.d2.loss_cls: 0.2279  decode.d2.loss_mask: 0.1776  decode.d2.loss_dice: 0.2430  decode.d3.loss_cls: 0.2619  decode.d3.loss_mask: 0.1779  decode.d3.loss_dice: 0.2238  decode.d4.loss_cls: 0.2218  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.2249  decode.d5.loss_mask: 0.1811  decode.d5.loss_dice: 0.2501  decode.d6.loss_cls: 0.2410  decode.d6.loss_mask: 0.1798  decode.d6.loss_dice: 0.2557  decode.d7.loss_cls: 0.2539  decode.d7.loss_mask: 0.1821  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.2808  decode.d8.loss_mask: 0.1764  decode.d8.loss_dice: 0.2375
09/30 15:00:33 - mmengine - INFO - Iter(train) [ 49300/320000]  base_lr: 8.6021e-05 lr: 8.6021e-06  eta: 1 day, 8:38:44  time: 0.4359  data_time: 0.0096  memory: 5129  grad_norm: 80.9365  loss: 6.4779  decode.loss_cls: 0.1598  decode.loss_mask: 0.2154  decode.loss_dice: 0.2163  decode.d0.loss_cls: 0.8694  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.2039  decode.d1.loss_cls: 0.1498  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.1494  decode.d2.loss_mask: 0.2153  decode.d2.loss_dice: 0.2033  decode.d3.loss_cls: 0.1602  decode.d3.loss_mask: 0.2122  decode.d3.loss_dice: 0.1957  decode.d4.loss_cls: 0.1647  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.2022  decode.d5.loss_cls: 0.1458  decode.d5.loss_mask: 0.2192  decode.d5.loss_dice: 0.2095  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 0.2157  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.1508  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.1558  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.1997
09/30 15:00:54 - mmengine - INFO - Iter(train) [ 49350/320000]  base_lr: 8.6007e-05 lr: 8.6007e-06  eta: 1 day, 8:38:23  time: 0.4365  data_time: 0.0095  memory: 5129  grad_norm: 47.3187  loss: 5.3813  decode.loss_cls: 0.0752  decode.loss_mask: 0.1828  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.9931  decode.d0.loss_mask: 0.1851  decode.d0.loss_dice: 0.1766  decode.d1.loss_cls: 0.0982  decode.d1.loss_mask: 0.1824  decode.d1.loss_dice: 0.2138  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.1842  decode.d2.loss_dice: 0.1780  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.1820  decode.d3.loss_dice: 0.1849  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.1812  decode.d4.loss_dice: 0.1786  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 0.1798  decode.d5.loss_dice: 0.1757  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.1821  decode.d6.loss_dice: 0.1840  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.1706  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.1817  decode.d8.loss_dice: 0.1835
09/30 15:01:16 - mmengine - INFO - Iter(train) [ 49400/320000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 1 day, 8:38:02  time: 0.4359  data_time: 0.0094  memory: 5145  grad_norm: 27.5246  loss: 4.5994  decode.loss_cls: 0.0427  decode.loss_mask: 0.1754  decode.loss_dice: 0.1557  decode.d0.loss_cls: 0.8493  decode.d0.loss_mask: 0.1810  decode.d0.loss_dice: 0.1618  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.1759  decode.d1.loss_dice: 0.1572  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.1787  decode.d2.loss_dice: 0.1659  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.1773  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.0513  decode.d4.loss_mask: 0.1751  decode.d4.loss_dice: 0.1581  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.1785  decode.d5.loss_dice: 0.1542  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.1750  decode.d6.loss_dice: 0.1622  decode.d7.loss_cls: 0.0454  decode.d7.loss_mask: 0.1754  decode.d7.loss_dice: 0.1505  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.1759  decode.d8.loss_dice: 0.1547
09/30 15:01:38 - mmengine - INFO - Iter(train) [ 49450/320000]  base_lr: 8.5978e-05 lr: 8.5978e-06  eta: 1 day, 8:37:40  time: 0.4360  data_time: 0.0095  memory: 5145  grad_norm: 141.5187  loss: 9.3458  decode.loss_cls: 0.1136  decode.loss_mask: 0.4244  decode.loss_dice: 0.3253  decode.d0.loss_cls: 0.8060  decode.d0.loss_mask: 0.4357  decode.d0.loss_dice: 0.3078  decode.d1.loss_cls: 0.1239  decode.d1.loss_mask: 0.4368  decode.d1.loss_dice: 0.3287  decode.d2.loss_cls: 0.1130  decode.d2.loss_mask: 0.4326  decode.d2.loss_dice: 0.3239  decode.d3.loss_cls: 0.1065  decode.d3.loss_mask: 0.4246  decode.d3.loss_dice: 0.3305  decode.d4.loss_cls: 0.1388  decode.d4.loss_mask: 0.4222  decode.d4.loss_dice: 0.3238  decode.d5.loss_cls: 0.1311  decode.d5.loss_mask: 0.4286  decode.d5.loss_dice: 0.3315  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.4159  decode.d6.loss_dice: 0.3232  decode.d7.loss_cls: 0.1262  decode.d7.loss_mask: 0.4200  decode.d7.loss_dice: 0.3267  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.4198  decode.d8.loss_dice: 0.3233
09/30 15:02:00 - mmengine - INFO - Iter(train) [ 49500/320000]  base_lr: 8.5964e-05 lr: 8.5964e-06  eta: 1 day, 8:37:19  time: 0.4362  data_time: 0.0096  memory: 5129  grad_norm: 61.8128  loss: 6.8495  decode.loss_cls: 0.0534  decode.loss_mask: 0.2742  decode.loss_dice: 0.2704  decode.d0.loss_cls: 0.8516  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.2580  decode.d1.loss_cls: 0.0998  decode.d1.loss_mask: 0.2749  decode.d1.loss_dice: 0.2702  decode.d2.loss_cls: 0.0994  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.2606  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.2776  decode.d4.loss_dice: 0.2698  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.2717  decode.d5.loss_dice: 0.2577  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.2710  decode.d6.loss_dice: 0.2626  decode.d7.loss_cls: 0.0544  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.2602  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.2554
09/30 15:02:22 - mmengine - INFO - Iter(train) [ 49550/320000]  base_lr: 8.5950e-05 lr: 8.5950e-06  eta: 1 day, 8:36:58  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 101.4165  loss: 9.2219  decode.loss_cls: 0.1356  decode.loss_mask: 0.3183  decode.loss_dice: 0.3511  decode.d0.loss_cls: 1.0703  decode.d0.loss_mask: 0.3116  decode.d0.loss_dice: 0.3350  decode.d1.loss_cls: 0.2546  decode.d1.loss_mask: 0.3058  decode.d1.loss_dice: 0.3414  decode.d2.loss_cls: 0.1476  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.3387  decode.d3.loss_cls: 0.2244  decode.d3.loss_mask: 0.3115  decode.d3.loss_dice: 0.3623  decode.d4.loss_cls: 0.1509  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.3775  decode.d5.loss_cls: 0.1324  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.3467  decode.d6.loss_cls: 0.1464  decode.d6.loss_mask: 0.3128  decode.d6.loss_dice: 0.3545  decode.d7.loss_cls: 0.1563  decode.d7.loss_mask: 0.3057  decode.d7.loss_dice: 0.3477  decode.d8.loss_cls: 0.1811  decode.d8.loss_mask: 0.3099  decode.d8.loss_dice: 0.3505
09/30 15:02:44 - mmengine - INFO - Iter(train) [ 49600/320000]  base_lr: 8.5935e-05 lr: 8.5935e-06  eta: 1 day, 8:36:37  time: 0.4357  data_time: 0.0094  memory: 5129  grad_norm: 63.9207  loss: 6.8295  decode.loss_cls: 0.0848  decode.loss_mask: 0.3135  decode.loss_dice: 0.2339  decode.d0.loss_cls: 0.7737  decode.d0.loss_mask: 0.3114  decode.d0.loss_dice: 0.2401  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.3106  decode.d1.loss_dice: 0.2351  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.3054  decode.d2.loss_dice: 0.2358  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.3082  decode.d3.loss_dice: 0.2370  decode.d4.loss_cls: 0.0401  decode.d4.loss_mask: 0.3106  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.3137  decode.d5.loss_dice: 0.2421  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.3199  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.0792  decode.d7.loss_mask: 0.3186  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.3075  decode.d8.loss_dice: 0.2398
09/30 15:03:05 - mmengine - INFO - Iter(train) [ 49650/320000]  base_lr: 8.5921e-05 lr: 8.5921e-06  eta: 1 day, 8:36:16  time: 0.4371  data_time: 0.0096  memory: 5145  grad_norm: 73.1794  loss: 5.9232  decode.loss_cls: 0.0798  decode.loss_mask: 0.2375  decode.loss_dice: 0.2152  decode.d0.loss_cls: 0.8331  decode.d0.loss_mask: 0.2467  decode.d0.loss_dice: 0.2176  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.2213  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2224  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.2413  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.2420  decode.d4.loss_dice: 0.2196  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.2403  decode.d5.loss_dice: 0.2151  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.2386  decode.d6.loss_dice: 0.2209  decode.d7.loss_cls: 0.1015  decode.d7.loss_mask: 0.2392  decode.d7.loss_dice: 0.2178  decode.d8.loss_cls: 0.0455  decode.d8.loss_mask: 0.2421  decode.d8.loss_dice: 0.2239
09/30 15:03:27 - mmengine - INFO - Iter(train) [ 49700/320000]  base_lr: 8.5907e-05 lr: 8.5907e-06  eta: 1 day, 8:35:55  time: 0.4365  data_time: 0.0095  memory: 5120  grad_norm: 56.8272  loss: 6.2503  decode.loss_cls: 0.0845  decode.loss_mask: 0.2226  decode.loss_dice: 0.1853  decode.d0.loss_cls: 0.8983  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2104  decode.d2.loss_cls: 0.1468  decode.d2.loss_mask: 0.2253  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 0.2213  decode.d3.loss_dice: 0.1857  decode.d4.loss_cls: 0.1788  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.1999  decode.d5.loss_cls: 0.1454  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.1883  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.1890  decode.d7.loss_cls: 0.0935  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.1922  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.1929
09/30 15:03:49 - mmengine - INFO - Iter(train) [ 49750/320000]  base_lr: 8.5893e-05 lr: 8.5893e-06  eta: 1 day, 8:35:34  time: 0.4364  data_time: 0.0097  memory: 5145  grad_norm: 169.2050  loss: 10.5748  decode.loss_cls: 0.3193  decode.loss_mask: 0.3783  decode.loss_dice: 0.3406  decode.d0.loss_cls: 1.0409  decode.d0.loss_mask: 0.3961  decode.d0.loss_dice: 0.3123  decode.d1.loss_cls: 0.2664  decode.d1.loss_mask: 0.3687  decode.d1.loss_dice: 0.3252  decode.d2.loss_cls: 0.2545  decode.d2.loss_mask: 0.4774  decode.d2.loss_dice: 0.3487  decode.d3.loss_cls: 0.2970  decode.d3.loss_mask: 0.3817  decode.d3.loss_dice: 0.3047  decode.d4.loss_cls: 0.3005  decode.d4.loss_mask: 0.3834  decode.d4.loss_dice: 0.2993  decode.d5.loss_cls: 0.2528  decode.d5.loss_mask: 0.3715  decode.d5.loss_dice: 0.2896  decode.d6.loss_cls: 0.2421  decode.d6.loss_mask: 0.3838  decode.d6.loss_dice: 0.3346  decode.d7.loss_cls: 0.2903  decode.d7.loss_mask: 0.3544  decode.d7.loss_dice: 0.3136  decode.d8.loss_cls: 0.2492  decode.d8.loss_mask: 0.3907  decode.d8.loss_dice: 0.3074
09/30 15:04:11 - mmengine - INFO - Iter(train) [ 49800/320000]  base_lr: 8.5878e-05 lr: 8.5878e-06  eta: 1 day, 8:35:13  time: 0.4373  data_time: 0.0095  memory: 5145  grad_norm: 51.3279  loss: 5.4460  decode.loss_cls: 0.0069  decode.loss_mask: 0.2301  decode.loss_dice: 0.2173  decode.d0.loss_cls: 0.8342  decode.d0.loss_mask: 0.2318  decode.d0.loss_dice: 0.2214  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.2280  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.2308  decode.d2.loss_dice: 0.2249  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.2127  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.2154  decode.d5.loss_cls: 0.0154  decode.d5.loss_mask: 0.2322  decode.d5.loss_dice: 0.2274  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2294  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2187  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.2236
09/30 15:04:33 - mmengine - INFO - Iter(train) [ 49850/320000]  base_lr: 8.5864e-05 lr: 8.5864e-06  eta: 1 day, 8:34:51  time: 0.4357  data_time: 0.0095  memory: 5129  grad_norm: 32.7224  loss: 6.9865  decode.loss_cls: 0.2042  decode.loss_mask: 0.2252  decode.loss_dice: 0.2145  decode.d0.loss_cls: 0.9664  decode.d0.loss_mask: 0.2244  decode.d0.loss_dice: 0.1993  decode.d1.loss_cls: 0.2106  decode.d1.loss_mask: 0.2281  decode.d1.loss_dice: 0.2088  decode.d2.loss_cls: 0.2087  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2128  decode.d3.loss_cls: 0.1782  decode.d3.loss_mask: 0.2246  decode.d3.loss_dice: 0.2081  decode.d4.loss_cls: 0.2189  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.1882  decode.d5.loss_cls: 0.1731  decode.d5.loss_mask: 0.2251  decode.d5.loss_dice: 0.1951  decode.d6.loss_cls: 0.1900  decode.d6.loss_mask: 0.2243  decode.d6.loss_dice: 0.1669  decode.d7.loss_cls: 0.1925  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.2127  decode.d8.loss_cls: 0.1788  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.2077
09/30 15:04:54 - mmengine - INFO - Iter(train) [ 49900/320000]  base_lr: 8.5850e-05 lr: 8.5850e-06  eta: 1 day, 8:34:30  time: 0.4360  data_time: 0.0095  memory: 5120  grad_norm: 56.0830  loss: 5.7692  decode.loss_cls: 0.0628  decode.loss_mask: 0.2529  decode.loss_dice: 0.1931  decode.d0.loss_cls: 0.8169  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.1794  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.2576  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.0523  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.1872  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.2584  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.2565  decode.d5.loss_dice: 0.1915  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.2592  decode.d6.loss_dice: 0.1908  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.1905  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.1919
09/30 15:05:16 - mmengine - INFO - Iter(train) [ 49950/320000]  base_lr: 8.5835e-05 lr: 8.5835e-06  eta: 1 day, 8:34:09  time: 0.4378  data_time: 0.0096  memory: 5129  grad_norm: 121.5447  loss: 8.1611  decode.loss_cls: 0.1610  decode.loss_mask: 0.2915  decode.loss_dice: 0.2832  decode.d0.loss_cls: 0.8481  decode.d0.loss_mask: 0.2930  decode.d0.loss_dice: 0.2796  decode.d1.loss_cls: 0.1224  decode.d1.loss_mask: 0.2917  decode.d1.loss_dice: 0.2862  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 0.2890  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.2274  decode.d3.loss_mask: 0.2926  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.1692  decode.d4.loss_mask: 0.2908  decode.d4.loss_dice: 0.2737  decode.d5.loss_cls: 0.1810  decode.d5.loss_mask: 0.2897  decode.d5.loss_dice: 0.2725  decode.d6.loss_cls: 0.2067  decode.d6.loss_mask: 0.2887  decode.d6.loss_dice: 0.2691  decode.d7.loss_cls: 0.1902  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.2737  decode.d8.loss_cls: 0.1839  decode.d8.loss_mask: 0.2897  decode.d8.loss_dice: 0.2844
09/30 15:05:38 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:05:38 - mmengine - INFO - Iter(train) [ 50000/320000]  base_lr: 8.5821e-05 lr: 8.5821e-06  eta: 1 day, 8:33:49  time: 0.4365  data_time: 0.0094  memory: 5145  grad_norm: 34.8629  loss: 5.9776  decode.loss_cls: 0.0549  decode.loss_mask: 0.2053  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.9066  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.2319  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.2069  decode.d1.loss_dice: 0.2471  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.2444  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.2462  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.2091  decode.d4.loss_dice: 0.2453  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.2046  decode.d5.loss_dice: 0.2422  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.2049  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2073  decode.d8.loss_dice: 0.2494
09/30 15:06:00 - mmengine - INFO - Iter(train) [ 50050/320000]  base_lr: 8.5807e-05 lr: 8.5807e-06  eta: 1 day, 8:33:27  time: 0.4359  data_time: 0.0093  memory: 5120  grad_norm: 124.1867  loss: 5.3638  decode.loss_cls: 0.0449  decode.loss_mask: 0.2255  decode.loss_dice: 0.1821  decode.d0.loss_cls: 0.8505  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0415  decode.d1.loss_mask: 0.2185  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.1900  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.1900  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.1811  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.2205  decode.d5.loss_dice: 0.1822  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.1823  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.2222  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.2235  decode.d8.loss_dice: 0.1843
09/30 15:06:22 - mmengine - INFO - Iter(train) [ 50100/320000]  base_lr: 8.5792e-05 lr: 8.5792e-06  eta: 1 day, 8:33:06  time: 0.4356  data_time: 0.0095  memory: 5119  grad_norm: 79.1136  loss: 8.6531  decode.loss_cls: 0.1602  decode.loss_mask: 0.3824  decode.loss_dice: 0.2523  decode.d0.loss_cls: 0.7577  decode.d0.loss_mask: 0.2680  decode.d0.loss_dice: 0.2446  decode.d1.loss_cls: 0.2788  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.2342  decode.d2.loss_cls: 0.1629  decode.d2.loss_mask: 0.5020  decode.d2.loss_dice: 0.2426  decode.d3.loss_cls: 0.2143  decode.d3.loss_mask: 0.3401  decode.d3.loss_dice: 0.2736  decode.d4.loss_cls: 0.1146  decode.d4.loss_mask: 0.4990  decode.d4.loss_dice: 0.2381  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.5057  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.2116  decode.d6.loss_mask: 0.3329  decode.d6.loss_dice: 0.2590  decode.d7.loss_cls: 0.2652  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2500  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 0.3961  decode.d8.loss_dice: 0.2444
09/30 15:06:44 - mmengine - INFO - Iter(train) [ 50150/320000]  base_lr: 8.5778e-05 lr: 8.5778e-06  eta: 1 day, 8:32:45  time: 0.4349  data_time: 0.0094  memory: 5129  grad_norm: 19.0372  loss: 5.1906  decode.loss_cls: 0.0047  decode.loss_mask: 0.2417  decode.loss_dice: 0.1881  decode.d0.loss_cls: 0.8123  decode.d0.loss_mask: 0.2479  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.1969  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.1870  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.2427  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.1867  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2430  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.1888
09/30 15:07:06 - mmengine - INFO - Iter(train) [ 50200/320000]  base_lr: 8.5764e-05 lr: 8.5764e-06  eta: 1 day, 8:32:24  time: 0.4376  data_time: 0.0096  memory: 5145  grad_norm: 17.6010  loss: 4.1883  decode.loss_cls: 0.0031  decode.loss_mask: 0.1783  decode.loss_dice: 0.1499  decode.d0.loss_cls: 0.8688  decode.d0.loss_mask: 0.1817  decode.d0.loss_dice: 0.1601  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.1787  decode.d1.loss_dice: 0.1512  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.1493  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1775  decode.d3.loss_dice: 0.1527  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.1797  decode.d4.loss_dice: 0.1466  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.1774  decode.d5.loss_dice: 0.1456  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.1782  decode.d6.loss_dice: 0.1543  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.1797  decode.d7.loss_dice: 0.1508  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.1765  decode.d8.loss_dice: 0.1423
09/30 15:07:27 - mmengine - INFO - Iter(train) [ 50250/320000]  base_lr: 8.5749e-05 lr: 8.5749e-06  eta: 1 day, 8:32:03  time: 0.4369  data_time: 0.0096  memory: 5129  grad_norm: 62.6944  loss: 6.8458  decode.loss_cls: 0.1222  decode.loss_mask: 0.2324  decode.loss_dice: 0.2295  decode.d0.loss_cls: 0.8756  decode.d0.loss_mask: 0.2387  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.1720  decode.d1.loss_mask: 0.2301  decode.d1.loss_dice: 0.2421  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.2305  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.1314  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.2414  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 0.2336  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.1267  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.2604  decode.d6.loss_cls: 0.1483  decode.d6.loss_mask: 0.2336  decode.d6.loss_dice: 0.2461  decode.d7.loss_cls: 0.1538  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.1116  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.2340
09/30 15:07:49 - mmengine - INFO - Iter(train) [ 50300/320000]  base_lr: 8.5735e-05 lr: 8.5735e-06  eta: 1 day, 8:31:42  time: 0.4356  data_time: 0.0094  memory: 5129  grad_norm: 83.3686  loss: 6.8415  decode.loss_cls: 0.0733  decode.loss_mask: 0.2783  decode.loss_dice: 0.2272  decode.d0.loss_cls: 0.9288  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.2183  decode.d1.loss_cls: 0.0813  decode.d1.loss_mask: 0.2811  decode.d1.loss_dice: 0.2314  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.2325  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.2820  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.2256  decode.d5.loss_cls: 0.1016  decode.d5.loss_mask: 0.2848  decode.d5.loss_dice: 0.2711  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.2758  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.1101  decode.d7.loss_mask: 0.2822  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.2787  decode.d8.loss_dice: 0.2278
09/30 15:08:11 - mmengine - INFO - Iter(train) [ 50350/320000]  base_lr: 8.5721e-05 lr: 8.5721e-06  eta: 1 day, 8:31:21  time: 0.4355  data_time: 0.0092  memory: 5129  grad_norm: 91.5735  loss: 7.3509  decode.loss_cls: 0.2430  decode.loss_mask: 0.2374  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.8984  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2517  decode.d1.loss_cls: 0.2051  decode.d1.loss_mask: 0.2411  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.1676  decode.d2.loss_mask: 0.2428  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.1712  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2256  decode.d4.loss_cls: 0.1612  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2359  decode.d5.loss_cls: 0.1660  decode.d5.loss_mask: 0.2389  decode.d5.loss_dice: 0.2286  decode.d6.loss_cls: 0.1701  decode.d6.loss_mask: 0.2381  decode.d6.loss_dice: 0.2369  decode.d7.loss_cls: 0.1679  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.2176  decode.d8.loss_mask: 0.2416  decode.d8.loss_dice: 0.2356
09/30 15:08:33 - mmengine - INFO - Iter(train) [ 50400/320000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 1 day, 8:31:00  time: 0.4348  data_time: 0.0093  memory: 5159  grad_norm: 67.8905  loss: 7.3959  decode.loss_cls: 0.1354  decode.loss_mask: 0.2806  decode.loss_dice: 0.2269  decode.d0.loss_cls: 0.9322  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.2236  decode.d1.loss_cls: 0.2206  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.2083  decode.d2.loss_cls: 0.2347  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2234  decode.d3.loss_cls: 0.1510  decode.d3.loss_mask: 0.2796  decode.d3.loss_dice: 0.2211  decode.d4.loss_cls: 0.1624  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.1609  decode.d5.loss_mask: 0.2805  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.1721  decode.d6.loss_mask: 0.2807  decode.d6.loss_dice: 0.2187  decode.d7.loss_cls: 0.1595  decode.d7.loss_mask: 0.2855  decode.d7.loss_dice: 0.2271  decode.d8.loss_cls: 0.1315  decode.d8.loss_mask: 0.2824  decode.d8.loss_dice: 0.2214
09/30 15:08:55 - mmengine - INFO - Iter(train) [ 50450/320000]  base_lr: 8.5692e-05 lr: 8.5692e-06  eta: 1 day, 8:30:38  time: 0.4343  data_time: 0.0091  memory: 5129  grad_norm: 49.4883  loss: 6.1259  decode.loss_cls: 0.0429  decode.loss_mask: 0.2956  decode.loss_dice: 0.1978  decode.d0.loss_cls: 0.8576  decode.d0.loss_mask: 0.3073  decode.d0.loss_dice: 0.2117  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.2981  decode.d2.loss_dice: 0.2007  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.1955  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.1952  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.2934  decode.d6.loss_dice: 0.1960  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.2955  decode.d8.loss_dice: 0.1990
09/30 15:09:16 - mmengine - INFO - Iter(train) [ 50500/320000]  base_lr: 8.5678e-05 lr: 8.5678e-06  eta: 1 day, 8:30:17  time: 0.4358  data_time: 0.0095  memory: 5129  grad_norm: 82.0052  loss: 6.5431  decode.loss_cls: 0.2218  decode.loss_mask: 0.1919  decode.loss_dice: 0.1981  decode.d0.loss_cls: 0.8022  decode.d0.loss_mask: 0.1952  decode.d0.loss_dice: 0.2447  decode.d1.loss_cls: 0.2288  decode.d1.loss_mask: 0.1905  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.1843  decode.d2.loss_mask: 0.1924  decode.d2.loss_dice: 0.2362  decode.d3.loss_cls: 0.1972  decode.d3.loss_mask: 0.1899  decode.d3.loss_dice: 0.2010  decode.d4.loss_cls: 0.1576  decode.d4.loss_mask: 0.1934  decode.d4.loss_dice: 0.1942  decode.d5.loss_cls: 0.1585  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.1790  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 0.1898  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.2199  decode.d7.loss_mask: 0.1906  decode.d7.loss_dice: 0.1943  decode.d8.loss_cls: 0.2200  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.1978
09/30 15:09:38 - mmengine - INFO - Iter(train) [ 50550/320000]  base_lr: 8.5664e-05 lr: 8.5664e-06  eta: 1 day, 8:29:57  time: 0.4353  data_time: 0.0094  memory: 5145  grad_norm: 30.4404  loss: 5.5962  decode.loss_cls: 0.0179  decode.loss_mask: 0.2624  decode.loss_dice: 0.1994  decode.d0.loss_cls: 0.8049  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.2031  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.2642  decode.d1.loss_dice: 0.2041  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2084  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.2644  decode.d3.loss_dice: 0.1999  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.2620  decode.d4.loss_dice: 0.1942  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.2631  decode.d5.loss_dice: 0.1999  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.2641  decode.d6.loss_dice: 0.1981  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2632  decode.d7.loss_dice: 0.2008  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.1961
09/30 15:10:00 - mmengine - INFO - Iter(train) [ 50600/320000]  base_lr: 8.5649e-05 lr: 8.5649e-06  eta: 1 day, 8:29:35  time: 0.4352  data_time: 0.0091  memory: 5129  grad_norm: 27.8265  loss: 6.1276  decode.loss_cls: 0.1418  decode.loss_mask: 0.2284  decode.loss_dice: 0.1756  decode.d0.loss_cls: 0.9506  decode.d0.loss_mask: 0.2264  decode.d0.loss_dice: 0.1823  decode.d1.loss_cls: 0.1153  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.1815  decode.d2.loss_cls: 0.0921  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.1813  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.2303  decode.d3.loss_dice: 0.1806  decode.d4.loss_cls: 0.1214  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.1372  decode.d5.loss_mask: 0.2256  decode.d5.loss_dice: 0.1781  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.1814  decode.d7.loss_cls: 0.1406  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.1747  decode.d8.loss_cls: 0.1382  decode.d8.loss_mask: 0.2275  decode.d8.loss_dice: 0.1769
09/30 15:10:22 - mmengine - INFO - Iter(train) [ 50650/320000]  base_lr: 8.5635e-05 lr: 8.5635e-06  eta: 1 day, 8:29:14  time: 0.4360  data_time: 0.0094  memory: 5119  grad_norm: 29.9651  loss: 5.8976  decode.loss_cls: 0.0130  decode.loss_mask: 0.3197  decode.loss_dice: 0.1877  decode.d0.loss_cls: 0.6894  decode.d0.loss_mask: 0.3381  decode.d0.loss_dice: 0.1859  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.3272  decode.d1.loss_dice: 0.1818  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.3232  decode.d2.loss_dice: 0.1842  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.3227  decode.d3.loss_dice: 0.1825  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.3176  decode.d4.loss_dice: 0.1854  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.3221  decode.d5.loss_dice: 0.1829  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.3173  decode.d6.loss_dice: 0.1857  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.3229  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.3243  decode.d8.loss_dice: 0.1892
09/30 15:10:44 - mmengine - INFO - Iter(train) [ 50700/320000]  base_lr: 8.5621e-05 lr: 8.5621e-06  eta: 1 day, 8:28:53  time: 0.4349  data_time: 0.0093  memory: 5145  grad_norm: 17.9141  loss: 4.4890  decode.loss_cls: 0.0120  decode.loss_mask: 0.2087  decode.loss_dice: 0.1507  decode.d0.loss_cls: 0.7727  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.1520  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.1507  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.2089  decode.d2.loss_dice: 0.1511  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.2084  decode.d3.loss_dice: 0.1498  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.2090  decode.d4.loss_dice: 0.1503  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.2077  decode.d5.loss_dice: 0.1510  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.1488  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.1504  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1511
09/30 15:11:06 - mmengine - INFO - Iter(train) [ 50750/320000]  base_lr: 8.5606e-05 lr: 8.5606e-06  eta: 1 day, 8:28:31  time: 0.4359  data_time: 0.0093  memory: 5129  grad_norm: 22.3939  loss: 5.8078  decode.loss_cls: 0.0816  decode.loss_mask: 0.2241  decode.loss_dice: 0.1868  decode.d0.loss_cls: 0.8677  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.1960  decode.d1.loss_cls: 0.0888  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.1869  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.3574  decode.d3.loss_dice: 0.1995  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.2255  decode.d5.loss_dice: 0.1850  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.2345  decode.d6.loss_dice: 0.1919  decode.d7.loss_cls: 0.1003  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.1890  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.2237  decode.d8.loss_dice: 0.1865
09/30 15:11:27 - mmengine - INFO - Iter(train) [ 50800/320000]  base_lr: 8.5592e-05 lr: 8.5592e-06  eta: 1 day, 8:28:10  time: 0.4350  data_time: 0.0092  memory: 5129  grad_norm: 146.4185  loss: 6.3854  decode.loss_cls: 0.1034  decode.loss_mask: 0.2197  decode.loss_dice: 0.2323  decode.d0.loss_cls: 0.8706  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.2320  decode.d1.loss_cls: 0.1614  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.2426  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.2588  decode.d3.loss_cls: 0.1021  decode.d3.loss_mask: 0.2187  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.1019  decode.d4.loss_mask: 0.2206  decode.d4.loss_dice: 0.2580  decode.d5.loss_cls: 0.0949  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.2311  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2425
09/30 15:11:49 - mmengine - INFO - Iter(train) [ 50850/320000]  base_lr: 8.5578e-05 lr: 8.5578e-06  eta: 1 day, 8:27:49  time: 0.4348  data_time: 0.0092  memory: 5129  grad_norm: 81.8491  loss: 5.4864  decode.loss_cls: 0.0695  decode.loss_mask: 0.1875  decode.loss_dice: 0.2229  decode.d0.loss_cls: 0.7396  decode.d0.loss_mask: 0.1906  decode.d0.loss_dice: 0.2306  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.1892  decode.d1.loss_dice: 0.2209  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.1873  decode.d2.loss_dice: 0.2204  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.1862  decode.d3.loss_dice: 0.2062  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.0806  decode.d5.loss_mask: 0.1870  decode.d5.loss_dice: 0.2262  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.1883  decode.d6.loss_dice: 0.2031  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.1844  decode.d7.loss_dice: 0.2151  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.1876  decode.d8.loss_dice: 0.2161
09/30 15:12:11 - mmengine - INFO - Iter(train) [ 50900/320000]  base_lr: 8.5564e-05 lr: 8.5564e-06  eta: 1 day, 8:27:27  time: 0.4352  data_time: 0.0092  memory: 5145  grad_norm: 53.2485  loss: 5.9137  decode.loss_cls: 0.1086  decode.loss_mask: 0.2135  decode.loss_dice: 0.2052  decode.d0.loss_cls: 0.8146  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2123  decode.d1.loss_cls: 0.1134  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.2160  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.2174  decode.d2.loss_dice: 0.2214  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.2186  decode.d4.loss_dice: 0.2202  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.2188  decode.d6.loss_dice: 0.2055  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.2174  decode.d7.loss_dice: 0.1945  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.2173  decode.d8.loss_dice: 0.2070
09/30 15:12:33 - mmengine - INFO - Iter(train) [ 50950/320000]  base_lr: 8.5549e-05 lr: 8.5549e-06  eta: 1 day, 8:27:06  time: 0.4362  data_time: 0.0094  memory: 5145  grad_norm: 29.5885  loss: 6.5675  decode.loss_cls: 0.0928  decode.loss_mask: 0.2627  decode.loss_dice: 0.1964  decode.d0.loss_cls: 0.8637  decode.d0.loss_mask: 0.2693  decode.d0.loss_dice: 0.2291  decode.d1.loss_cls: 0.1715  decode.d1.loss_mask: 0.2664  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.1283  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2008  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.2655  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.2675  decode.d4.loss_dice: 0.2096  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 0.2681  decode.d5.loss_dice: 0.1998  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.2660  decode.d6.loss_dice: 0.2031  decode.d7.loss_cls: 0.1123  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.2659  decode.d8.loss_dice: 0.2122
09/30 15:12:55 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:12:55 - mmengine - INFO - Iter(train) [ 51000/320000]  base_lr: 8.5535e-05 lr: 8.5535e-06  eta: 1 day, 8:26:45  time: 0.4352  data_time: 0.0093  memory: 5145  grad_norm: 27.7599  loss: 5.4633  decode.loss_cls: 0.0614  decode.loss_mask: 0.2097  decode.loss_dice: 0.2152  decode.d0.loss_cls: 0.8007  decode.d0.loss_mask: 0.2109  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.2150  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.2208  decode.d3.loss_cls: 0.0320  decode.d3.loss_mask: 0.2117  decode.d3.loss_dice: 0.2178  decode.d4.loss_cls: 0.0855  decode.d4.loss_mask: 0.2094  decode.d4.loss_dice: 0.1894  decode.d5.loss_cls: 0.0333  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.2142  decode.d6.loss_cls: 0.0251  decode.d6.loss_mask: 0.2126  decode.d6.loss_dice: 0.2192  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.2119  decode.d7.loss_dice: 0.2044  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.2115
09/30 15:13:16 - mmengine - INFO - Iter(train) [ 51050/320000]  base_lr: 8.5521e-05 lr: 8.5521e-06  eta: 1 day, 8:26:23  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 40.1911  loss: 6.5635  decode.loss_cls: 0.1527  decode.loss_mask: 0.2473  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.8507  decode.d0.loss_mask: 0.2475  decode.d0.loss_dice: 0.2034  decode.d1.loss_cls: 0.1399  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2011  decode.d2.loss_cls: 0.1404  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2006  decode.d3.loss_cls: 0.1364  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.2013  decode.d4.loss_cls: 0.1550  decode.d4.loss_mask: 0.2415  decode.d4.loss_dice: 0.2075  decode.d5.loss_cls: 0.1340  decode.d5.loss_mask: 0.2420  decode.d5.loss_dice: 0.2001  decode.d6.loss_cls: 0.1283  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.1981  decode.d7.loss_cls: 0.1329  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.2002  decode.d8.loss_cls: 0.1350  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.1954
09/30 15:13:38 - mmengine - INFO - Iter(train) [ 51100/320000]  base_lr: 8.5506e-05 lr: 8.5506e-06  eta: 1 day, 8:26:02  time: 0.4361  data_time: 0.0096  memory: 5145  grad_norm: 108.0290  loss: 6.4953  decode.loss_cls: 0.0683  decode.loss_mask: 0.2483  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.8308  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.2442  decode.d1.loss_cls: 0.1080  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2357  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.2492  decode.d2.loss_dice: 0.2766  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.2485  decode.d3.loss_dice: 0.2371  decode.d4.loss_cls: 0.0894  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.2280  decode.d5.loss_cls: 0.1030  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2171  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2287  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.2486  decode.d7.loss_dice: 0.2371  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.2587
09/30 15:14:00 - mmengine - INFO - Iter(train) [ 51150/320000]  base_lr: 8.5492e-05 lr: 8.5492e-06  eta: 1 day, 8:25:41  time: 0.4364  data_time: 0.0095  memory: 5129  grad_norm: 70.7955  loss: 6.7885  decode.loss_cls: 0.0721  decode.loss_mask: 0.2791  decode.loss_dice: 0.2257  decode.d0.loss_cls: 0.9646  decode.d0.loss_mask: 0.2827  decode.d0.loss_dice: 0.2260  decode.d1.loss_cls: 0.1278  decode.d1.loss_mask: 0.2814  decode.d1.loss_dice: 0.2320  decode.d2.loss_cls: 0.1133  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.2266  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.2235  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.2738  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2241  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.2212  decode.d7.loss_cls: 0.0653  decode.d7.loss_mask: 0.2769  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.1055  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2326
09/30 15:14:22 - mmengine - INFO - Iter(train) [ 51200/320000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 1 day, 8:25:20  time: 0.4359  data_time: 0.0092  memory: 5120  grad_norm: 44.5617  loss: 5.8743  decode.loss_cls: 0.0977  decode.loss_mask: 0.2108  decode.loss_dice: 0.2100  decode.d0.loss_cls: 0.7475  decode.d0.loss_mask: 0.2149  decode.d0.loss_dice: 0.2155  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.2107  decode.d1.loss_dice: 0.2034  decode.d2.loss_cls: 0.1219  decode.d2.loss_mask: 0.2093  decode.d2.loss_dice: 0.2174  decode.d3.loss_cls: 0.0967  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.2266  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.2103  decode.d4.loss_dice: 0.2100  decode.d5.loss_cls: 0.1030  decode.d5.loss_mask: 0.2104  decode.d5.loss_dice: 0.2057  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.1153  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.1989  decode.d8.loss_cls: 0.1161  decode.d8.loss_mask: 0.2115  decode.d8.loss_dice: 0.1971
09/30 15:14:43 - mmengine - INFO - Iter(train) [ 51250/320000]  base_lr: 8.5463e-05 lr: 8.5463e-06  eta: 1 day, 8:24:58  time: 0.4350  data_time: 0.0094  memory: 5120  grad_norm: 65.8017  loss: 7.4546  decode.loss_cls: 0.0863  decode.loss_mask: 0.3138  decode.loss_dice: 0.2503  decode.d0.loss_cls: 0.8384  decode.d0.loss_mask: 0.3160  decode.d0.loss_dice: 0.2191  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.3091  decode.d1.loss_dice: 0.2390  decode.d2.loss_cls: 0.1579  decode.d2.loss_mask: 0.3039  decode.d2.loss_dice: 0.2418  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.3105  decode.d3.loss_dice: 0.2636  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 0.3118  decode.d4.loss_dice: 0.2360  decode.d5.loss_cls: 0.1131  decode.d5.loss_mask: 0.3146  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.1140  decode.d6.loss_mask: 0.3149  decode.d6.loss_dice: 0.2474  decode.d7.loss_cls: 0.1098  decode.d7.loss_mask: 0.3131  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.1069  decode.d8.loss_mask: 0.3104  decode.d8.loss_dice: 0.2341
09/30 15:15:05 - mmengine - INFO - Iter(train) [ 51300/320000]  base_lr: 8.5449e-05 lr: 8.5449e-06  eta: 1 day, 8:24:37  time: 0.4367  data_time: 0.0095  memory: 5145  grad_norm: 52.9611  loss: 7.7967  decode.loss_cls: 0.1888  decode.loss_mask: 0.2889  decode.loss_dice: 0.2161  decode.d0.loss_cls: 0.9526  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.2326  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.1960  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.3552  decode.d2.loss_dice: 0.1997  decode.d3.loss_cls: 0.1575  decode.d3.loss_mask: 0.3591  decode.d3.loss_dice: 0.2101  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.4151  decode.d4.loss_dice: 0.2155  decode.d5.loss_cls: 0.2263  decode.d5.loss_mask: 0.2623  decode.d5.loss_dice: 0.2041  decode.d6.loss_cls: 0.2054  decode.d6.loss_mask: 0.2846  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.1513  decode.d7.loss_mask: 0.3397  decode.d7.loss_dice: 0.2069  decode.d8.loss_cls: 0.1988  decode.d8.loss_mask: 0.2774  decode.d8.loss_dice: 0.2385
09/30 15:15:27 - mmengine - INFO - Iter(train) [ 51350/320000]  base_lr: 8.5435e-05 lr: 8.5435e-06  eta: 1 day, 8:24:16  time: 0.4361  data_time: 0.0097  memory: 5129  grad_norm: 97.3649  loss: 8.7305  decode.loss_cls: 0.2319  decode.loss_mask: 0.2469  decode.loss_dice: 0.2662  decode.d0.loss_cls: 1.2253  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.2829  decode.d1.loss_cls: 0.3477  decode.d1.loss_mask: 0.2458  decode.d1.loss_dice: 0.2214  decode.d2.loss_cls: 0.2354  decode.d2.loss_mask: 0.2439  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.2313  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.2865  decode.d4.loss_cls: 0.2277  decode.d4.loss_mask: 0.3398  decode.d4.loss_dice: 0.3216  decode.d5.loss_cls: 0.1908  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.3154  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.2528  decode.d6.loss_dice: 0.3030  decode.d7.loss_cls: 0.2141  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.3123  decode.d8.loss_cls: 0.2037  decode.d8.loss_mask: 0.2517  decode.d8.loss_dice: 0.2803
09/30 15:15:49 - mmengine - INFO - Iter(train) [ 51400/320000]  base_lr: 8.5420e-05 lr: 8.5420e-06  eta: 1 day, 8:23:54  time: 0.4354  data_time: 0.0095  memory: 5145  grad_norm: 39.4471  loss: 5.8974  decode.loss_cls: 0.0406  decode.loss_mask: 0.2750  decode.loss_dice: 0.2055  decode.d0.loss_cls: 0.8050  decode.d0.loss_mask: 0.2790  decode.d0.loss_dice: 0.2114  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.2799  decode.d1.loss_dice: 0.2152  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.2788  decode.d2.loss_dice: 0.2124  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.2806  decode.d3.loss_dice: 0.2065  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.2761  decode.d4.loss_dice: 0.2064  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.2783  decode.d5.loss_dice: 0.2077  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.2766  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.2104  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.1980
09/30 15:16:11 - mmengine - INFO - Iter(train) [ 51450/320000]  base_lr: 8.5406e-05 lr: 8.5406e-06  eta: 1 day, 8:23:33  time: 0.4347  data_time: 0.0094  memory: 5129  grad_norm: 74.5533  loss: 6.0364  decode.loss_cls: 0.0523  decode.loss_mask: 0.2416  decode.loss_dice: 0.1795  decode.d0.loss_cls: 0.9001  decode.d0.loss_mask: 0.2437  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 0.2502  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.1200  decode.d2.loss_mask: 0.2422  decode.d2.loss_dice: 0.1847  decode.d3.loss_cls: 0.1157  decode.d3.loss_mask: 0.2426  decode.d3.loss_dice: 0.1875  decode.d4.loss_cls: 0.1085  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.1831  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.1898  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.2404  decode.d6.loss_dice: 0.1968  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.1905  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.2419  decode.d8.loss_dice: 0.1783
09/30 15:16:32 - mmengine - INFO - Iter(train) [ 51500/320000]  base_lr: 8.5392e-05 lr: 8.5392e-06  eta: 1 day, 8:23:11  time: 0.4345  data_time: 0.0093  memory: 5120  grad_norm: 48.6944  loss: 6.2815  decode.loss_cls: 0.1471  decode.loss_mask: 0.2071  decode.loss_dice: 0.1906  decode.d0.loss_cls: 0.7438  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2010  decode.d1.loss_cls: 0.1702  decode.d1.loss_mask: 0.2074  decode.d1.loss_dice: 0.2065  decode.d2.loss_cls: 0.0950  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.1049  decode.d3.loss_mask: 0.2053  decode.d3.loss_dice: 0.1915  decode.d4.loss_cls: 0.1331  decode.d4.loss_mask: 0.2083  decode.d4.loss_dice: 0.1946  decode.d5.loss_cls: 0.1232  decode.d5.loss_mask: 0.2090  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.2248  decode.d6.loss_mask: 0.2042  decode.d6.loss_dice: 0.2083  decode.d7.loss_cls: 0.2349  decode.d7.loss_mask: 0.2072  decode.d7.loss_dice: 0.2178  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.2090
09/30 15:16:54 - mmengine - INFO - Iter(train) [ 51550/320000]  base_lr: 8.5377e-05 lr: 8.5377e-06  eta: 1 day, 8:22:50  time: 0.4347  data_time: 0.0092  memory: 5145  grad_norm: 12.4133  loss: 3.9984  decode.loss_cls: 0.0034  decode.loss_mask: 0.1628  decode.loss_dice: 0.1503  decode.d0.loss_cls: 0.8657  decode.d0.loss_mask: 0.1601  decode.d0.loss_dice: 0.1460  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.1667  decode.d1.loss_dice: 0.1484  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.1642  decode.d2.loss_dice: 0.1471  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.1652  decode.d3.loss_dice: 0.1490  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.1582  decode.d4.loss_dice: 0.1460  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1638  decode.d5.loss_dice: 0.1481  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.1613  decode.d6.loss_dice: 0.1457  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.1632  decode.d7.loss_dice: 0.1470  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.1623  decode.d8.loss_dice: 0.1472
09/30 15:17:16 - mmengine - INFO - Iter(train) [ 51600/320000]  base_lr: 8.5363e-05 lr: 8.5363e-06  eta: 1 day, 8:22:29  time: 0.4356  data_time: 0.0095  memory: 5129  grad_norm: 70.1779  loss: 5.6772  decode.loss_cls: 0.0626  decode.loss_mask: 0.2064  decode.loss_dice: 0.1820  decode.d0.loss_cls: 0.8958  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.1831  decode.d1.loss_cls: 0.1433  decode.d1.loss_mask: 0.2067  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.0939  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.1957  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1925  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.1952  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.2124  decode.d5.loss_dice: 0.1937  decode.d6.loss_cls: 0.1185  decode.d6.loss_mask: 0.2085  decode.d6.loss_dice: 0.1810  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.2040  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.2084  decode.d8.loss_dice: 0.1864
09/30 15:17:38 - mmengine - INFO - Iter(train) [ 51650/320000]  base_lr: 8.5349e-05 lr: 8.5349e-06  eta: 1 day, 8:22:08  time: 0.4357  data_time: 0.0093  memory: 5129  grad_norm: 62.4430  loss: 7.6959  decode.loss_cls: 0.0827  decode.loss_mask: 0.3085  decode.loss_dice: 0.2690  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.2912  decode.d1.loss_cls: 0.3053  decode.d1.loss_mask: 0.2753  decode.d1.loss_dice: 0.2485  decode.d2.loss_cls: 0.1518  decode.d2.loss_mask: 0.2962  decode.d2.loss_dice: 0.2490  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.1558  decode.d4.loss_mask: 0.2792  decode.d4.loss_dice: 0.2488  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.2391  decode.d6.loss_cls: 0.1413  decode.d6.loss_mask: 0.2795  decode.d6.loss_dice: 0.2579  decode.d7.loss_cls: 0.1483  decode.d7.loss_mask: 0.2756  decode.d7.loss_dice: 0.2590  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 0.3000  decode.d8.loss_dice: 0.2537
09/30 15:18:00 - mmengine - INFO - Iter(train) [ 51700/320000]  base_lr: 8.5335e-05 lr: 8.5335e-06  eta: 1 day, 8:21:46  time: 0.4356  data_time: 0.0093  memory: 5146  grad_norm: 55.7490  loss: 6.9335  decode.loss_cls: 0.1003  decode.loss_mask: 0.2953  decode.loss_dice: 0.2094  decode.d0.loss_cls: 0.9561  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.1882  decode.d1.loss_mask: 0.3008  decode.d1.loss_dice: 0.2013  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.3027  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.2086  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.3007  decode.d4.loss_dice: 0.2107  decode.d5.loss_cls: 0.1621  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.2035  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.2954  decode.d6.loss_dice: 0.2066  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.2128  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.2981  decode.d8.loss_dice: 0.2103
09/30 15:18:21 - mmengine - INFO - Iter(train) [ 51750/320000]  base_lr: 8.5320e-05 lr: 8.5320e-06  eta: 1 day, 8:21:25  time: 0.4352  data_time: 0.0092  memory: 5145  grad_norm: 41.5076  loss: 4.6731  decode.loss_cls: 0.0403  decode.loss_mask: 0.1657  decode.loss_dice: 0.1723  decode.d0.loss_cls: 0.8507  decode.d0.loss_mask: 0.1702  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.1660  decode.d1.loss_dice: 0.1839  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.1686  decode.d2.loss_dice: 0.1779  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.1644  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0226  decode.d4.loss_mask: 0.1644  decode.d4.loss_dice: 0.1777  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.1667  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.1644  decode.d6.loss_dice: 0.1786  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.1651  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.1659  decode.d8.loss_dice: 0.1888
09/30 15:18:43 - mmengine - INFO - Iter(train) [ 51800/320000]  base_lr: 8.5306e-05 lr: 8.5306e-06  eta: 1 day, 8:21:04  time: 0.4353  data_time: 0.0093  memory: 5129  grad_norm: 54.8560  loss: 4.8364  decode.loss_cls: 0.0072  decode.loss_mask: 0.2117  decode.loss_dice: 0.1784  decode.d0.loss_cls: 0.7448  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.1817  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.1825  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.2133  decode.d3.loss_dice: 0.1865  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.2216  decode.d4.loss_dice: 0.1919  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.2149  decode.d5.loss_dice: 0.1855  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.2127  decode.d6.loss_dice: 0.1831  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.2173  decode.d7.loss_dice: 0.1888  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.1870
09/30 15:19:05 - mmengine - INFO - Iter(train) [ 51850/320000]  base_lr: 8.5292e-05 lr: 8.5292e-06  eta: 1 day, 8:20:42  time: 0.4358  data_time: 0.0096  memory: 5129  grad_norm: 45.2778  loss: 6.3659  decode.loss_cls: 0.0924  decode.loss_mask: 0.2110  decode.loss_dice: 0.2472  decode.d0.loss_cls: 0.7939  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.2703  decode.d1.loss_cls: 0.1313  decode.d1.loss_mask: 0.2225  decode.d1.loss_dice: 0.2585  decode.d2.loss_cls: 0.1053  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.2492  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 0.2117  decode.d3.loss_dice: 0.2502  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.2201  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.1191  decode.d5.loss_mask: 0.2121  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.2116  decode.d6.loss_dice: 0.2464  decode.d7.loss_cls: 0.0958  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.2571  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.2602
09/30 15:19:27 - mmengine - INFO - Iter(train) [ 51900/320000]  base_lr: 8.5277e-05 lr: 8.5277e-06  eta: 1 day, 8:20:21  time: 0.4361  data_time: 0.0097  memory: 5145  grad_norm: 51.7375  loss: 5.8642  decode.loss_cls: 0.0988  decode.loss_mask: 0.2266  decode.loss_dice: 0.1678  decode.d0.loss_cls: 0.8895  decode.d0.loss_mask: 0.2307  decode.d0.loss_dice: 0.1739  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 0.2293  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.1335  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.1098  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.1702  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.1687  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.1776  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 0.2279  decode.d6.loss_dice: 0.1697  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 0.2253  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0903  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.1708
09/30 15:19:49 - mmengine - INFO - Iter(train) [ 51950/320000]  base_lr: 8.5263e-05 lr: 8.5263e-06  eta: 1 day, 8:20:00  time: 0.4355  data_time: 0.0097  memory: 5129  grad_norm: 43.3507  loss: 7.3484  decode.loss_cls: 0.1189  decode.loss_mask: 0.2811  decode.loss_dice: 0.2543  decode.d0.loss_cls: 0.7952  decode.d0.loss_mask: 0.2838  decode.d0.loss_dice: 0.2525  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.2846  decode.d1.loss_dice: 0.2617  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.2555  decode.d3.loss_cls: 0.1208  decode.d3.loss_mask: 0.2836  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.1305  decode.d4.loss_mask: 0.2791  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.1208  decode.d5.loss_mask: 0.2769  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.1428  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.2546  decode.d7.loss_cls: 0.1368  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.1467  decode.d8.loss_mask: 0.2764  decode.d8.loss_dice: 0.2570
09/30 15:20:10 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:20:10 - mmengine - INFO - Iter(train) [ 52000/320000]  base_lr: 8.5249e-05 lr: 8.5249e-06  eta: 1 day, 8:19:39  time: 0.4362  data_time: 0.0096  memory: 5120  grad_norm: 34.0707  loss: 5.7657  decode.loss_cls: 0.0875  decode.loss_mask: 0.1909  decode.loss_dice: 0.2314  decode.d0.loss_cls: 0.8456  decode.d0.loss_mask: 0.1928  decode.d0.loss_dice: 0.2137  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.1936  decode.d1.loss_dice: 0.2324  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.1932  decode.d2.loss_dice: 0.2119  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.1894  decode.d3.loss_dice: 0.2173  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.1914  decode.d4.loss_dice: 0.2296  decode.d5.loss_cls: 0.0886  decode.d5.loss_mask: 0.1926  decode.d5.loss_dice: 0.2198  decode.d6.loss_cls: 0.0886  decode.d6.loss_mask: 0.1924  decode.d6.loss_dice: 0.2312  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.1897  decode.d7.loss_dice: 0.2321  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 0.1898  decode.d8.loss_dice: 0.2145
09/30 15:20:32 - mmengine - INFO - Iter(train) [ 52050/320000]  base_lr: 8.5234e-05 lr: 8.5234e-06  eta: 1 day, 8:19:17  time: 0.4366  data_time: 0.0096  memory: 5129  grad_norm: 51.2389  loss: 7.7105  decode.loss_cls: 0.2092  decode.loss_mask: 0.2510  decode.loss_dice: 0.2467  decode.d0.loss_cls: 0.8900  decode.d0.loss_mask: 0.2565  decode.d0.loss_dice: 0.2464  decode.d1.loss_cls: 0.2167  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.2430  decode.d2.loss_cls: 0.2075  decode.d2.loss_mask: 0.2496  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.1842  decode.d3.loss_mask: 0.2611  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.1847  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2454  decode.d5.loss_cls: 0.1862  decode.d5.loss_mask: 0.2613  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.1843  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.2494  decode.d7.loss_cls: 0.1866  decode.d7.loss_mask: 0.2468  decode.d7.loss_dice: 0.2532  decode.d8.loss_cls: 0.1696  decode.d8.loss_mask: 0.2890  decode.d8.loss_dice: 0.2677
09/30 15:20:54 - mmengine - INFO - Iter(train) [ 52100/320000]  base_lr: 8.5220e-05 lr: 8.5220e-06  eta: 1 day, 8:18:56  time: 0.4369  data_time: 0.0097  memory: 5145  grad_norm: 55.5788  loss: 8.3144  decode.loss_cls: 0.2581  decode.loss_mask: 0.3178  decode.loss_dice: 0.2196  decode.d0.loss_cls: 0.8442  decode.d0.loss_mask: 0.3210  decode.d0.loss_dice: 0.2392  decode.d1.loss_cls: 0.2145  decode.d1.loss_mask: 0.3204  decode.d1.loss_dice: 0.2232  decode.d2.loss_cls: 0.2623  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.2478  decode.d3.loss_mask: 0.3204  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.2165  decode.d4.loss_mask: 0.3178  decode.d4.loss_dice: 0.2140  decode.d5.loss_cls: 0.2329  decode.d5.loss_mask: 0.3175  decode.d5.loss_dice: 0.2136  decode.d6.loss_cls: 0.2177  decode.d6.loss_mask: 0.3162  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.2278  decode.d7.loss_mask: 0.3188  decode.d7.loss_dice: 0.2124  decode.d8.loss_cls: 0.2106  decode.d8.loss_mask: 0.3191  decode.d8.loss_dice: 0.2057
09/30 15:21:16 - mmengine - INFO - Iter(train) [ 52150/320000]  base_lr: 8.5206e-05 lr: 8.5206e-06  eta: 1 day, 8:18:35  time: 0.4368  data_time: 0.0096  memory: 5129  grad_norm: 85.5052  loss: 7.0759  decode.loss_cls: 0.0448  decode.loss_mask: 0.2525  decode.loss_dice: 0.2676  decode.d0.loss_cls: 1.0429  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.1145  decode.d1.loss_mask: 0.2497  decode.d1.loss_dice: 0.2591  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 0.2516  decode.d2.loss_dice: 0.2799  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.2559  decode.d3.loss_dice: 0.2688  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.2525  decode.d4.loss_dice: 0.2722  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.2590  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 0.2533  decode.d6.loss_dice: 0.2757  decode.d7.loss_cls: 0.0951  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.2473  decode.d8.loss_dice: 0.2616
09/30 15:21:38 - mmengine - INFO - Iter(train) [ 52200/320000]  base_lr: 8.5191e-05 lr: 8.5191e-06  eta: 1 day, 8:18:15  time: 0.4353  data_time: 0.0095  memory: 5129  grad_norm: 61.9942  loss: 6.4956  decode.loss_cls: 0.1464  decode.loss_mask: 0.2186  decode.loss_dice: 0.2093  decode.d0.loss_cls: 0.8597  decode.d0.loss_mask: 0.2223  decode.d0.loss_dice: 0.2142  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 0.2217  decode.d1.loss_dice: 0.2349  decode.d2.loss_cls: 0.1114  decode.d2.loss_mask: 0.2200  decode.d2.loss_dice: 0.2161  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.2232  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.2205  decode.d4.loss_dice: 0.2210  decode.d5.loss_cls: 0.1449  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.2093  decode.d6.loss_cls: 0.1559  decode.d6.loss_mask: 0.2159  decode.d6.loss_dice: 0.2096  decode.d7.loss_cls: 0.1823  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.2017  decode.d8.loss_cls: 0.1637  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.2157
09/30 15:22:00 - mmengine - INFO - Iter(train) [ 52250/320000]  base_lr: 8.5177e-05 lr: 8.5177e-06  eta: 1 day, 8:17:53  time: 0.4356  data_time: 0.0094  memory: 5129  grad_norm: 36.9628  loss: 5.5622  decode.loss_cls: 0.1263  decode.loss_mask: 0.1828  decode.loss_dice: 0.1714  decode.d0.loss_cls: 1.0119  decode.d0.loss_mask: 0.1893  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.1325  decode.d1.loss_mask: 0.1832  decode.d1.loss_dice: 0.1610  decode.d2.loss_cls: 0.1066  decode.d2.loss_mask: 0.1847  decode.d2.loss_dice: 0.1720  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.1824  decode.d3.loss_dice: 0.1672  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.1849  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.1826  decode.d5.loss_dice: 0.1624  decode.d6.loss_cls: 0.1216  decode.d6.loss_mask: 0.1848  decode.d6.loss_dice: 0.1621  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.1825  decode.d7.loss_dice: 0.1680  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1672
09/30 15:22:22 - mmengine - INFO - Iter(train) [ 52300/320000]  base_lr: 8.5163e-05 lr: 8.5163e-06  eta: 1 day, 8:17:32  time: 0.4358  data_time: 0.0097  memory: 5129  grad_norm: 74.3242  loss: 6.6340  decode.loss_cls: 0.0902  decode.loss_mask: 0.2677  decode.loss_dice: 0.2416  decode.d0.loss_cls: 0.8210  decode.d0.loss_mask: 0.2694  decode.d0.loss_dice: 0.2384  decode.d1.loss_cls: 0.1096  decode.d1.loss_mask: 0.2696  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.2700  decode.d2.loss_dice: 0.2246  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.2688  decode.d3.loss_dice: 0.2269  decode.d4.loss_cls: 0.1043  decode.d4.loss_mask: 0.2689  decode.d4.loss_dice: 0.2246  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.2267  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 0.2664  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.2680  decode.d7.loss_dice: 0.2288  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.2411
09/30 15:22:43 - mmengine - INFO - Iter(train) [ 52350/320000]  base_lr: 8.5148e-05 lr: 8.5148e-06  eta: 1 day, 8:17:11  time: 0.4394  data_time: 0.0098  memory: 5129  grad_norm: 86.8769  loss: 7.7581  decode.loss_cls: 0.0651  decode.loss_mask: 0.2902  decode.loss_dice: 0.3085  decode.d0.loss_cls: 0.9944  decode.d0.loss_mask: 0.2991  decode.d0.loss_dice: 0.3092  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 0.2901  decode.d1.loss_dice: 0.3233  decode.d2.loss_cls: 0.0580  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.3122  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.2906  decode.d3.loss_dice: 0.3093  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.3216  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.2897  decode.d5.loss_dice: 0.3194  decode.d6.loss_cls: 0.0925  decode.d6.loss_mask: 0.2921  decode.d6.loss_dice: 0.3104  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.3360  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.2875  decode.d8.loss_dice: 0.3602
09/30 15:23:05 - mmengine - INFO - Iter(train) [ 52400/320000]  base_lr: 8.5134e-05 lr: 8.5134e-06  eta: 1 day, 8:16:51  time: 0.4382  data_time: 0.0095  memory: 5129  grad_norm: 61.1412  loss: 6.6531  decode.loss_cls: 0.0588  decode.loss_mask: 0.2290  decode.loss_dice: 0.2686  decode.d0.loss_cls: 1.0103  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.2617  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 0.2262  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.3015  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.2625  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.2249  decode.d5.loss_dice: 0.2504  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2552  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.2257  decode.d7.loss_dice: 0.2365  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.2305  decode.d8.loss_dice: 0.2635
09/30 15:23:27 - mmengine - INFO - Iter(train) [ 52450/320000]  base_lr: 8.5120e-05 lr: 8.5120e-06  eta: 1 day, 8:16:30  time: 0.4378  data_time: 0.0096  memory: 5130  grad_norm: 26.0963  loss: 5.0772  decode.loss_cls: 0.0429  decode.loss_mask: 0.2051  decode.loss_dice: 0.1719  decode.d0.loss_cls: 0.9696  decode.d0.loss_mask: 0.2059  decode.d0.loss_dice: 0.1666  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.2032  decode.d1.loss_dice: 0.1690  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.2007  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.1652  decode.d5.loss_cls: 0.0453  decode.d5.loss_mask: 0.2020  decode.d5.loss_dice: 0.1659  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.1996  decode.d6.loss_dice: 0.1653  decode.d7.loss_cls: 0.0419  decode.d7.loss_mask: 0.2041  decode.d7.loss_dice: 0.1693  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1734
09/30 15:23:49 - mmengine - INFO - Iter(train) [ 52500/320000]  base_lr: 8.5106e-05 lr: 8.5106e-06  eta: 1 day, 8:16:09  time: 0.4379  data_time: 0.0099  memory: 5145  grad_norm: 29.6132  loss: 5.9100  decode.loss_cls: 0.0949  decode.loss_mask: 0.2211  decode.loss_dice: 0.1841  decode.d0.loss_cls: 0.9281  decode.d0.loss_mask: 0.2222  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.1908  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.2167  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.1059  decode.d4.loss_mask: 0.2197  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.1083  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.1937  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.1893  decode.d7.loss_cls: 0.0942  decode.d7.loss_mask: 0.2180  decode.d7.loss_dice: 0.1891  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.1898
09/30 15:24:11 - mmengine - INFO - Iter(train) [ 52550/320000]  base_lr: 8.5091e-05 lr: 8.5091e-06  eta: 1 day, 8:15:48  time: 0.4383  data_time: 0.0095  memory: 5129  grad_norm: 27.7496  loss: 5.4870  decode.loss_cls: 0.0817  decode.loss_mask: 0.2138  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.8235  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.1755  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.2167  decode.d1.loss_dice: 0.1859  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.2176  decode.d2.loss_dice: 0.1882  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.1845  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.2155  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2155  decode.d6.loss_dice: 0.1831  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.2141  decode.d7.loss_dice: 0.1861  decode.d8.loss_cls: 0.1289  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.1856
09/30 15:24:33 - mmengine - INFO - Iter(train) [ 52600/320000]  base_lr: 8.5077e-05 lr: 8.5077e-06  eta: 1 day, 8:15:28  time: 0.4387  data_time: 0.0097  memory: 5120  grad_norm: 42.9472  loss: 6.9839  decode.loss_cls: 0.1728  decode.loss_mask: 0.2358  decode.loss_dice: 0.2458  decode.d0.loss_cls: 0.8217  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2728  decode.d1.loss_cls: 0.1194  decode.d1.loss_mask: 0.2355  decode.d1.loss_dice: 0.2635  decode.d2.loss_cls: 0.1189  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.2768  decode.d3.loss_cls: 0.1825  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1410  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.2335  decode.d5.loss_cls: 0.1397  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2145  decode.d6.loss_cls: 0.1526  decode.d6.loss_mask: 0.2391  decode.d6.loss_dice: 0.2101  decode.d7.loss_cls: 0.1741  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2344  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2552
09/30 15:24:55 - mmengine - INFO - Iter(train) [ 52650/320000]  base_lr: 8.5063e-05 lr: 8.5063e-06  eta: 1 day, 8:15:07  time: 0.4361  data_time: 0.0096  memory: 5145  grad_norm: 32.4253  loss: 5.4070  decode.loss_cls: 0.0049  decode.loss_mask: 0.2470  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.7191  decode.d0.loss_mask: 0.2632  decode.d0.loss_dice: 0.2196  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.2438  decode.d1.loss_dice: 0.2132  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2184  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.2482  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.2481  decode.d6.loss_dice: 0.2185  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.2469  decode.d7.loss_dice: 0.2135  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2150
09/30 15:25:17 - mmengine - INFO - Iter(train) [ 52700/320000]  base_lr: 8.5048e-05 lr: 8.5048e-06  eta: 1 day, 8:14:46  time: 0.4371  data_time: 0.0097  memory: 5145  grad_norm: 52.1414  loss: 5.6967  decode.loss_cls: 0.1056  decode.loss_mask: 0.1913  decode.loss_dice: 0.2067  decode.d0.loss_cls: 0.7622  decode.d0.loss_mask: 0.1989  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.1359  decode.d1.loss_mask: 0.2001  decode.d1.loss_dice: 0.1834  decode.d2.loss_cls: 0.0898  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.2074  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 0.1923  decode.d3.loss_dice: 0.1766  decode.d4.loss_cls: 0.1334  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.1789  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 0.1918  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.1058  decode.d6.loss_mask: 0.1919  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 0.1925  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.2008
09/30 15:25:39 - mmengine - INFO - Iter(train) [ 52750/320000]  base_lr: 8.5034e-05 lr: 8.5034e-06  eta: 1 day, 8:14:25  time: 0.4367  data_time: 0.0096  memory: 5129  grad_norm: 101.7792  loss: 6.9850  decode.loss_cls: 0.1013  decode.loss_mask: 0.2582  decode.loss_dice: 0.2522  decode.d0.loss_cls: 0.8550  decode.d0.loss_mask: 0.2364  decode.d0.loss_dice: 0.1962  decode.d1.loss_cls: 0.2449  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.2163  decode.d2.loss_cls: 0.1306  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.2314  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.3339  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.3132  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.3134  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.1140  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.2464  decode.d7.loss_cls: 0.1348  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.2434  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.2662  decode.d8.loss_dice: 0.2460
09/30 15:26:00 - mmengine - INFO - Iter(train) [ 52800/320000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 1 day, 8:14:04  time: 0.4361  data_time: 0.0094  memory: 5120  grad_norm: 186.7608  loss: 8.3053  decode.loss_cls: 0.1244  decode.loss_mask: 0.2962  decode.loss_dice: 0.2947  decode.d0.loss_cls: 0.9661  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.3182  decode.d1.loss_cls: 0.1760  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.2105  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.3041  decode.d3.loss_cls: 0.1840  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.2761  decode.d4.loss_cls: 0.1978  decode.d4.loss_mask: 0.2952  decode.d4.loss_dice: 0.3115  decode.d5.loss_cls: 0.1090  decode.d5.loss_mask: 0.2975  decode.d5.loss_dice: 0.3088  decode.d6.loss_cls: 0.1288  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.2989  decode.d7.loss_cls: 0.1343  decode.d7.loss_mask: 0.2985  decode.d7.loss_dice: 0.2821  decode.d8.loss_cls: 0.1251  decode.d8.loss_mask: 0.2929  decode.d8.loss_dice: 0.3044
09/30 15:26:22 - mmengine - INFO - Iter(train) [ 52850/320000]  base_lr: 8.5005e-05 lr: 8.5005e-06  eta: 1 day, 8:13:42  time: 0.4365  data_time: 0.0097  memory: 5120  grad_norm: 28.5129  loss: 5.6860  decode.loss_cls: 0.0970  decode.loss_mask: 0.2318  decode.loss_dice: 0.1656  decode.d0.loss_cls: 0.8081  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.1688  decode.d1.loss_cls: 0.0933  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.1613  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.2308  decode.d2.loss_dice: 0.1639  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2292  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.0909  decode.d4.loss_mask: 0.2284  decode.d4.loss_dice: 0.1659  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.1632  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.1758  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.2112  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.1624
09/30 15:26:44 - mmengine - INFO - Iter(train) [ 52900/320000]  base_lr: 8.4991e-05 lr: 8.4991e-06  eta: 1 day, 8:13:21  time: 0.4368  data_time: 0.0096  memory: 5119  grad_norm: 81.4496  loss: 6.1732  decode.loss_cls: 0.0694  decode.loss_mask: 0.2444  decode.loss_dice: 0.2005  decode.d0.loss_cls: 0.9001  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.2165  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.2462  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.2453  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.2616  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.2480  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2357  decode.d7.loss_cls: 0.0560  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.2463  decode.d8.loss_dice: 0.2193
09/30 15:27:06 - mmengine - INFO - Iter(train) [ 52950/320000]  base_lr: 8.4977e-05 lr: 8.4977e-06  eta: 1 day, 8:13:00  time: 0.4372  data_time: 0.0097  memory: 5129  grad_norm: 37.7580  loss: 4.6016  decode.loss_cls: 0.0054  decode.loss_mask: 0.1949  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.8526  decode.d0.loss_mask: 0.1995  decode.d0.loss_dice: 0.1864  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.1954  decode.d1.loss_dice: 0.1753  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.1926  decode.d2.loss_dice: 0.1697  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.1755  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.1925  decode.d4.loss_dice: 0.1793  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.1914  decode.d5.loss_dice: 0.1721  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.1948  decode.d6.loss_dice: 0.1789  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.1904  decode.d7.loss_dice: 0.1743  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.1756
09/30 15:27:28 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:27:28 - mmengine - INFO - Iter(train) [ 53000/320000]  base_lr: 8.4962e-05 lr: 8.4962e-06  eta: 1 day, 8:12:39  time: 0.4383  data_time: 0.0098  memory: 5145  grad_norm: 21.9795  loss: 5.3208  decode.loss_cls: 0.0160  decode.loss_mask: 0.2664  decode.loss_dice: 0.1771  decode.d0.loss_cls: 0.7638  decode.d0.loss_mask: 0.2818  decode.d0.loss_dice: 0.1674  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.2686  decode.d1.loss_dice: 0.1727  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.1707  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.1733  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.1728  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2641  decode.d6.loss_dice: 0.1808  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.2615  decode.d7.loss_dice: 0.1809  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.2669  decode.d8.loss_dice: 0.1745
09/30 15:27:50 - mmengine - INFO - Iter(train) [ 53050/320000]  base_lr: 8.4948e-05 lr: 8.4948e-06  eta: 1 day, 8:12:18  time: 0.4363  data_time: 0.0097  memory: 5129  grad_norm: 40.3637  loss: 5.3134  decode.loss_cls: 0.0204  decode.loss_mask: 0.2232  decode.loss_dice: 0.1965  decode.d0.loss_cls: 0.8126  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.0313  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.2090  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.2112  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.2082  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.2193  decode.d4.loss_dice: 0.2104  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.2036  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2097  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.2125  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.2055
09/30 15:28:11 - mmengine - INFO - Iter(train) [ 53100/320000]  base_lr: 8.4934e-05 lr: 8.4934e-06  eta: 1 day, 8:11:57  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 63.4580  loss: 5.8877  decode.loss_cls: 0.0330  decode.loss_mask: 0.2320  decode.loss_dice: 0.2158  decode.d0.loss_cls: 0.8808  decode.d0.loss_mask: 0.2380  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.2087  decode.d2.loss_cls: 0.1093  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.0414  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.2474  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.2298  decode.d5.loss_dice: 0.2229  decode.d6.loss_cls: 0.0326  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.2145  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2215  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.2313  decode.d8.loss_dice: 0.2201
09/30 15:28:33 - mmengine - INFO - Iter(train) [ 53150/320000]  base_lr: 8.4919e-05 lr: 8.4919e-06  eta: 1 day, 8:11:36  time: 0.4356  data_time: 0.0094  memory: 5129  grad_norm: 123.2748  loss: 6.4607  decode.loss_cls: 0.0650  decode.loss_mask: 0.2795  decode.loss_dice: 0.1908  decode.d0.loss_cls: 1.1707  decode.d0.loss_mask: 0.2878  decode.d0.loss_dice: 0.1942  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.2054  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.1924  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.1905  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.1893  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.2770  decode.d5.loss_dice: 0.1858  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.2784  decode.d6.loss_dice: 0.2007  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 0.2807  decode.d7.loss_dice: 0.1997  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.2800  decode.d8.loss_dice: 0.1889
09/30 15:28:55 - mmengine - INFO - Iter(train) [ 53200/320000]  base_lr: 8.4905e-05 lr: 8.4905e-06  eta: 1 day, 8:11:15  time: 0.4357  data_time: 0.0095  memory: 5145  grad_norm: 82.1879  loss: 7.8738  decode.loss_cls: 0.1782  decode.loss_mask: 0.2438  decode.loss_dice: 0.2593  decode.d0.loss_cls: 0.9179  decode.d0.loss_mask: 0.3734  decode.d0.loss_dice: 0.2867  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.3637  decode.d1.loss_dice: 0.3169  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.3655  decode.d2.loss_dice: 0.3040  decode.d3.loss_cls: 0.1874  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.2472  decode.d5.loss_cls: 0.2162  decode.d5.loss_mask: 0.2474  decode.d5.loss_dice: 0.2524  decode.d6.loss_cls: 0.1802  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2648  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.2468  decode.d8.loss_cls: 0.1636  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2595
09/30 15:29:17 - mmengine - INFO - Iter(train) [ 53250/320000]  base_lr: 8.4891e-05 lr: 8.4891e-06  eta: 1 day, 8:10:53  time: 0.4349  data_time: 0.0094  memory: 5129  grad_norm: 46.6157  loss: 6.0807  decode.loss_cls: 0.0777  decode.loss_mask: 0.2226  decode.loss_dice: 0.2191  decode.d0.loss_cls: 0.8977  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.2149  decode.d2.loss_cls: 0.1307  decode.d2.loss_mask: 0.2214  decode.d2.loss_dice: 0.2064  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.2239  decode.d3.loss_dice: 0.2159  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.2285  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.2211  decode.d5.loss_dice: 0.2195  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.2152  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.2130  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.2242  decode.d8.loss_dice: 0.2251
09/30 15:29:39 - mmengine - INFO - Iter(train) [ 53300/320000]  base_lr: 8.4876e-05 lr: 8.4876e-06  eta: 1 day, 8:10:32  time: 0.4360  data_time: 0.0096  memory: 5129  grad_norm: 27.8828  loss: 4.9290  decode.loss_cls: 0.0436  decode.loss_mask: 0.2020  decode.loss_dice: 0.1647  decode.d0.loss_cls: 0.8199  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.1839  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.1852  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.1782  decode.d3.loss_cls: 0.0250  decode.d3.loss_mask: 0.1973  decode.d3.loss_dice: 0.1845  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.1752  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.2006  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.1650  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.2007  decode.d8.loss_dice: 0.1712
09/30 15:30:01 - mmengine - INFO - Iter(train) [ 53350/320000]  base_lr: 8.4862e-05 lr: 8.4862e-06  eta: 1 day, 8:10:11  time: 0.4362  data_time: 0.0098  memory: 5129  grad_norm: 68.3712  loss: 6.5945  decode.loss_cls: 0.0236  decode.loss_mask: 0.3067  decode.loss_dice: 0.2344  decode.d0.loss_cls: 0.7359  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.2346  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.3070  decode.d2.loss_dice: 0.2375  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.3124  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.3159  decode.d4.loss_dice: 0.2517  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.3086  decode.d5.loss_dice: 0.2442  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 0.3073  decode.d6.loss_dice: 0.2551  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 0.3124  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.3119  decode.d8.loss_dice: 0.2435
09/30 15:30:22 - mmengine - INFO - Iter(train) [ 53400/320000]  base_lr: 8.4848e-05 lr: 8.4848e-06  eta: 1 day, 8:09:50  time: 0.4367  data_time: 0.0094  memory: 5146  grad_norm: 53.4473  loss: 5.9304  decode.loss_cls: 0.0719  decode.loss_mask: 0.1980  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.8629  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.2329  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 0.1953  decode.d1.loss_dice: 0.2071  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.1984  decode.d2.loss_dice: 0.2049  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.2307  decode.d4.loss_cls: 0.1101  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.2145  decode.d5.loss_cls: 0.0942  decode.d5.loss_mask: 0.1982  decode.d5.loss_dice: 0.2006  decode.d6.loss_cls: 0.1454  decode.d6.loss_mask: 0.1959  decode.d6.loss_dice: 0.2147  decode.d7.loss_cls: 0.1188  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.2244  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.2211
09/30 15:30:44 - mmengine - INFO - Iter(train) [ 53450/320000]  base_lr: 8.4833e-05 lr: 8.4833e-06  eta: 1 day, 8:09:29  time: 0.4373  data_time: 0.0097  memory: 5129  grad_norm: 57.3350  loss: 6.3522  decode.loss_cls: 0.0874  decode.loss_mask: 0.2390  decode.loss_dice: 0.2450  decode.d0.loss_cls: 0.8681  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.2587  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.1091  decode.d2.loss_mask: 0.2424  decode.d2.loss_dice: 0.2331  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.2418  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.1582  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.2319  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.2469  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.2395  decode.d6.loss_dice: 0.2384  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.2437  decode.d7.loss_dice: 0.2476  decode.d8.loss_cls: 0.0257  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.2624
09/30 15:31:06 - mmengine - INFO - Iter(train) [ 53500/320000]  base_lr: 8.4819e-05 lr: 8.4819e-06  eta: 1 day, 8:09:08  time: 0.4368  data_time: 0.0097  memory: 5120  grad_norm: 117.1340  loss: 10.5579  decode.loss_cls: 0.3083  decode.loss_mask: 0.3578  decode.loss_dice: 0.3392  decode.d0.loss_cls: 0.9448  decode.d0.loss_mask: 0.3499  decode.d0.loss_dice: 0.3404  decode.d1.loss_cls: 0.2703  decode.d1.loss_mask: 0.3324  decode.d1.loss_dice: 0.3592  decode.d2.loss_cls: 0.2869  decode.d2.loss_mask: 0.3553  decode.d2.loss_dice: 0.3292  decode.d3.loss_cls: 0.2549  decode.d3.loss_mask: 0.4536  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.2036  decode.d4.loss_mask: 0.4622  decode.d4.loss_dice: 0.3114  decode.d5.loss_cls: 0.1856  decode.d5.loss_mask: 0.4379  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.2126  decode.d6.loss_mask: 0.4674  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 0.3133  decode.d7.loss_mask: 0.4346  decode.d7.loss_dice: 0.3397  decode.d8.loss_cls: 0.2649  decode.d8.loss_mask: 0.3449  decode.d8.loss_dice: 0.3217
09/30 15:31:28 - mmengine - INFO - Iter(train) [ 53550/320000]  base_lr: 8.4805e-05 lr: 8.4805e-06  eta: 1 day, 8:08:46  time: 0.4361  data_time: 0.0096  memory: 5104  grad_norm: 60.1891  loss: 7.4074  decode.loss_cls: 0.0802  decode.loss_mask: 0.2586  decode.loss_dice: 0.2732  decode.d0.loss_cls: 0.9582  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.1067  decode.d1.loss_mask: 0.2614  decode.d1.loss_dice: 0.2927  decode.d2.loss_cls: 0.0966  decode.d2.loss_mask: 0.2633  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.1712  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.1911  decode.d4.loss_mask: 0.2623  decode.d4.loss_dice: 0.2609  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.2756  decode.d6.loss_cls: 0.0961  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2673  decode.d7.loss_cls: 0.1387  decode.d7.loss_mask: 0.2598  decode.d7.loss_dice: 0.2705  decode.d8.loss_cls: 0.1231  decode.d8.loss_mask: 0.2592  decode.d8.loss_dice: 0.2550
09/30 15:31:50 - mmengine - INFO - Iter(train) [ 53600/320000]  base_lr: 8.4790e-05 lr: 8.4790e-06  eta: 1 day, 8:08:25  time: 0.4361  data_time: 0.0096  memory: 5145  grad_norm: 67.0505  loss: 5.2935  decode.loss_cls: 0.1173  decode.loss_mask: 0.1664  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.8137  decode.d0.loss_mask: 0.1679  decode.d0.loss_dice: 0.2054  decode.d1.loss_cls: 0.1223  decode.d1.loss_mask: 0.1657  decode.d1.loss_dice: 0.1973  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 0.1682  decode.d2.loss_dice: 0.1943  decode.d3.loss_cls: 0.1029  decode.d3.loss_mask: 0.1678  decode.d3.loss_dice: 0.1963  decode.d4.loss_cls: 0.0972  decode.d4.loss_mask: 0.1672  decode.d4.loss_dice: 0.2031  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.1684  decode.d5.loss_dice: 0.1945  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.1695  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.1691  decode.d7.loss_dice: 0.2059  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 0.1662  decode.d8.loss_dice: 0.1910
09/30 15:32:12 - mmengine - INFO - Iter(train) [ 53650/320000]  base_lr: 8.4776e-05 lr: 8.4776e-06  eta: 1 day, 8:08:04  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 35.1451  loss: 5.2054  decode.loss_cls: 0.0079  decode.loss_mask: 0.2170  decode.loss_dice: 0.1843  decode.d0.loss_cls: 0.8266  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.2005  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2027  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.1967  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.2361  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2179  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.2186  decode.d7.loss_dice: 0.2000  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.2165  decode.d8.loss_dice: 0.1943
09/30 15:32:33 - mmengine - INFO - Iter(train) [ 53700/320000]  base_lr: 8.4762e-05 lr: 8.4762e-06  eta: 1 day, 8:07:43  time: 0.4371  data_time: 0.0095  memory: 5145  grad_norm: 29.0954  loss: 5.7932  decode.loss_cls: 0.1434  decode.loss_mask: 0.2256  decode.loss_dice: 0.1759  decode.d0.loss_cls: 0.7814  decode.d0.loss_mask: 0.2280  decode.d0.loss_dice: 0.1752  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.2250  decode.d1.loss_dice: 0.1766  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.1910  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.1914  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.2257  decode.d5.loss_cls: 0.1509  decode.d5.loss_mask: 0.2242  decode.d5.loss_dice: 0.1829  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.2233  decode.d6.loss_dice: 0.1911  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2356  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.2251  decode.d8.loss_dice: 0.2150
09/30 15:32:55 - mmengine - INFO - Iter(train) [ 53750/320000]  base_lr: 8.4748e-05 lr: 8.4748e-06  eta: 1 day, 8:07:22  time: 0.4373  data_time: 0.0096  memory: 5129  grad_norm: 80.8915  loss: 9.2283  decode.loss_cls: 0.2784  decode.loss_mask: 0.2254  decode.loss_dice: 0.3370  decode.d0.loss_cls: 0.9975  decode.d0.loss_mask: 0.2272  decode.d0.loss_dice: 0.3764  decode.d1.loss_cls: 0.3612  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.3677  decode.d2.loss_cls: 0.2769  decode.d2.loss_mask: 0.2264  decode.d2.loss_dice: 0.3444  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.3367  decode.d4.loss_cls: 0.2625  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.3327  decode.d5.loss_cls: 0.2349  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.3612  decode.d6.loss_cls: 0.2671  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.3557  decode.d7.loss_cls: 0.2649  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.3476  decode.d8.loss_cls: 0.2774  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.3487
09/30 15:33:17 - mmengine - INFO - Iter(train) [ 53800/320000]  base_lr: 8.4733e-05 lr: 8.4733e-06  eta: 1 day, 8:07:01  time: 0.4362  data_time: 0.0097  memory: 5120  grad_norm: 85.6385  loss: 5.0789  decode.loss_cls: 0.0961  decode.loss_mask: 0.1703  decode.loss_dice: 0.1580  decode.d0.loss_cls: 0.8985  decode.d0.loss_mask: 0.1747  decode.d0.loss_dice: 0.1620  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.1710  decode.d1.loss_dice: 0.1573  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.1711  decode.d2.loss_dice: 0.1572  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.1714  decode.d3.loss_dice: 0.1566  decode.d4.loss_cls: 0.1246  decode.d4.loss_mask: 0.1737  decode.d4.loss_dice: 0.1560  decode.d5.loss_cls: 0.1083  decode.d5.loss_mask: 0.1718  decode.d5.loss_dice: 0.1592  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.1713  decode.d6.loss_dice: 0.1556  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.1710  decode.d7.loss_dice: 0.1552  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.1727  decode.d8.loss_dice: 0.1587
09/30 15:33:39 - mmengine - INFO - Iter(train) [ 53850/320000]  base_lr: 8.4719e-05 lr: 8.4719e-06  eta: 1 day, 8:06:40  time: 0.4376  data_time: 0.0098  memory: 5145  grad_norm: 71.5865  loss: 7.8764  decode.loss_cls: 0.1920  decode.loss_mask: 0.2502  decode.loss_dice: 0.2507  decode.d0.loss_cls: 1.0458  decode.d0.loss_mask: 0.2478  decode.d0.loss_dice: 0.2510  decode.d1.loss_cls: 0.2435  decode.d1.loss_mask: 0.2469  decode.d1.loss_dice: 0.2654  decode.d2.loss_cls: 0.2200  decode.d2.loss_mask: 0.2491  decode.d2.loss_dice: 0.2484  decode.d3.loss_cls: 0.2171  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2657  decode.d4.loss_cls: 0.2118  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.2527  decode.d5.loss_cls: 0.1836  decode.d5.loss_mask: 0.2463  decode.d5.loss_dice: 0.2661  decode.d6.loss_cls: 0.1494  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.1903  decode.d7.loss_mask: 0.2485  decode.d7.loss_dice: 0.2365  decode.d8.loss_cls: 0.1860  decode.d8.loss_mask: 0.2490  decode.d8.loss_dice: 0.2473
09/30 15:34:01 - mmengine - INFO - Iter(train) [ 53900/320000]  base_lr: 8.4705e-05 lr: 8.4705e-06  eta: 1 day, 8:06:19  time: 0.4370  data_time: 0.0097  memory: 5145  grad_norm: 24.1825  loss: 5.2352  decode.loss_cls: 0.0689  decode.loss_mask: 0.2299  decode.loss_dice: 0.1754  decode.d0.loss_cls: 0.8284  decode.d0.loss_mask: 0.2281  decode.d0.loss_dice: 0.1782  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.1765  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.2300  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.2269  decode.d3.loss_dice: 0.1821  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.2276  decode.d4.loss_dice: 0.1894  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.2300  decode.d5.loss_dice: 0.1785  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.2286  decode.d6.loss_dice: 0.1735  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.1754  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.1771
09/30 15:34:23 - mmengine - INFO - Iter(train) [ 53950/320000]  base_lr: 8.4690e-05 lr: 8.4690e-06  eta: 1 day, 8:05:58  time: 0.4365  data_time: 0.0097  memory: 5129  grad_norm: 51.0081  loss: 6.4602  decode.loss_cls: 0.0302  decode.loss_mask: 0.3137  decode.loss_dice: 0.2222  decode.d0.loss_cls: 0.8871  decode.d0.loss_mask: 0.3235  decode.d0.loss_dice: 0.2376  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.3077  decode.d1.loss_dice: 0.2270  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.3149  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.3134  decode.d4.loss_dice: 0.2183  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.3105  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.3089  decode.d6.loss_dice: 0.2242  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.3124  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.3143  decode.d8.loss_dice: 0.2206
09/30 15:34:45 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:34:45 - mmengine - INFO - Iter(train) [ 54000/320000]  base_lr: 8.4676e-05 lr: 8.4676e-06  eta: 1 day, 8:05:37  time: 0.4372  data_time: 0.0097  memory: 5130  grad_norm: 31.4470  loss: 5.3740  decode.loss_cls: 0.0668  decode.loss_mask: 0.2113  decode.loss_dice: 0.1919  decode.d0.loss_cls: 0.8735  decode.d0.loss_mask: 0.2152  decode.d0.loss_dice: 0.1997  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.1901  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.2094  decode.d2.loss_dice: 0.1913  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.1893  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.2083  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.2105  decode.d5.loss_dice: 0.1916  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.1979  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.2078  decode.d7.loss_dice: 0.1913  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.2108  decode.d8.loss_dice: 0.1921
09/30 15:35:06 - mmengine - INFO - Iter(train) [ 54050/320000]  base_lr: 8.4662e-05 lr: 8.4662e-06  eta: 1 day, 8:05:16  time: 0.4362  data_time: 0.0095  memory: 5129  grad_norm: 58.0997  loss: 5.7644  decode.loss_cls: 0.0323  decode.loss_mask: 0.3007  decode.loss_dice: 0.1757  decode.d0.loss_cls: 0.8300  decode.d0.loss_mask: 0.2429  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.1004  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.1705  decode.d2.loss_cls: 0.0288  decode.d2.loss_mask: 0.3032  decode.d2.loss_dice: 0.1809  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2957  decode.d3.loss_dice: 0.1725  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.3006  decode.d4.loss_dice: 0.1783  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.1766  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.1801  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.3095  decode.d7.loss_dice: 0.1744  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.3036  decode.d8.loss_dice: 0.1770
09/30 15:35:28 - mmengine - INFO - Iter(train) [ 54100/320000]  base_lr: 8.4647e-05 lr: 8.4647e-06  eta: 1 day, 8:04:55  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 55.4719  loss: 7.0186  decode.loss_cls: 0.0951  decode.loss_mask: 0.2327  decode.loss_dice: 0.2393  decode.d0.loss_cls: 1.0584  decode.d0.loss_mask: 0.2340  decode.d0.loss_dice: 0.2163  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 0.2350  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.1341  decode.d2.loss_mask: 0.2337  decode.d2.loss_dice: 0.2492  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.1463  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.2681  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.1213  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2310  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.2345  decode.d8.loss_dice: 0.2510
09/30 15:35:50 - mmengine - INFO - Iter(train) [ 54150/320000]  base_lr: 8.4633e-05 lr: 8.4633e-06  eta: 1 day, 8:04:34  time: 0.4370  data_time: 0.0098  memory: 5129  grad_norm: 85.5624  loss: 7.5142  decode.loss_cls: 0.1312  decode.loss_mask: 0.3013  decode.loss_dice: 0.2304  decode.d0.loss_cls: 0.8700  decode.d0.loss_mask: 0.2974  decode.d0.loss_dice: 0.2230  decode.d1.loss_cls: 0.1225  decode.d1.loss_mask: 0.3029  decode.d1.loss_dice: 0.2457  decode.d2.loss_cls: 0.1215  decode.d2.loss_mask: 0.2981  decode.d2.loss_dice: 0.2095  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.4116  decode.d3.loss_dice: 0.2450  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.4029  decode.d4.loss_dice: 0.2351  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.4053  decode.d5.loss_dice: 0.2442  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.3989  decode.d6.loss_dice: 0.2285  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.4007  decode.d7.loss_dice: 0.2295  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.3909  decode.d8.loss_dice: 0.2339
09/30 15:36:12 - mmengine - INFO - Iter(train) [ 54200/320000]  base_lr: 8.4619e-05 lr: 8.4619e-06  eta: 1 day, 8:04:12  time: 0.4378  data_time: 0.0097  memory: 5129  grad_norm: 78.6892  loss: 7.6438  decode.loss_cls: 0.1318  decode.loss_mask: 0.3228  decode.loss_dice: 0.2135  decode.d0.loss_cls: 0.8279  decode.d0.loss_mask: 0.3350  decode.d0.loss_dice: 0.2449  decode.d1.loss_cls: 0.1472  decode.d1.loss_mask: 0.3283  decode.d1.loss_dice: 0.2491  decode.d2.loss_cls: 0.1840  decode.d2.loss_mask: 0.3255  decode.d2.loss_dice: 0.2272  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 0.3268  decode.d3.loss_dice: 0.2436  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.3351  decode.d4.loss_dice: 0.2360  decode.d5.loss_cls: 0.1516  decode.d5.loss_mask: 0.3292  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.1086  decode.d6.loss_mask: 0.3280  decode.d6.loss_dice: 0.2478  decode.d7.loss_cls: 0.1788  decode.d7.loss_mask: 0.3235  decode.d7.loss_dice: 0.2282  decode.d8.loss_cls: 0.1003  decode.d8.loss_mask: 0.3209  decode.d8.loss_dice: 0.2298
09/30 15:36:34 - mmengine - INFO - Iter(train) [ 54250/320000]  base_lr: 8.4604e-05 lr: 8.4604e-06  eta: 1 day, 8:03:51  time: 0.4369  data_time: 0.0097  memory: 5145  grad_norm: 144.7199  loss: 5.7767  decode.loss_cls: 0.0529  decode.loss_mask: 0.2511  decode.loss_dice: 0.1921  decode.d0.loss_cls: 0.8237  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.2013  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.2522  decode.d1.loss_dice: 0.1978  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.2523  decode.d2.loss_dice: 0.1984  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.1920  decode.d4.loss_cls: 0.0394  decode.d4.loss_mask: 0.2526  decode.d4.loss_dice: 0.2020  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2019  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.2485  decode.d8.loss_dice: 0.1904
09/30 15:36:56 - mmengine - INFO - Iter(train) [ 54300/320000]  base_lr: 8.4590e-05 lr: 8.4590e-06  eta: 1 day, 8:03:30  time: 0.4373  data_time: 0.0098  memory: 5120  grad_norm: 31.3021  loss: 6.3598  decode.loss_cls: 0.0981  decode.loss_mask: 0.2381  decode.loss_dice: 0.1925  decode.d0.loss_cls: 1.0078  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.2022  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.1937  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.1947  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.2392  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.1342  decode.d4.loss_mask: 0.2415  decode.d4.loss_dice: 0.2173  decode.d5.loss_cls: 0.1072  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.2118  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.2403  decode.d8.loss_dice: 0.2214
09/30 15:37:18 - mmengine - INFO - Iter(train) [ 54350/320000]  base_lr: 8.4576e-05 lr: 8.4576e-06  eta: 1 day, 8:03:09  time: 0.4372  data_time: 0.0094  memory: 5120  grad_norm: 44.4277  loss: 5.0762  decode.loss_cls: 0.0692  decode.loss_mask: 0.1522  decode.loss_dice: 0.1450  decode.d0.loss_cls: 0.9302  decode.d0.loss_mask: 0.1514  decode.d0.loss_dice: 0.1533  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 0.1531  decode.d1.loss_dice: 0.1800  decode.d2.loss_cls: 0.1219  decode.d2.loss_mask: 0.1535  decode.d2.loss_dice: 0.1749  decode.d3.loss_cls: 0.1017  decode.d3.loss_mask: 0.1501  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.1137  decode.d4.loss_mask: 0.1519  decode.d4.loss_dice: 0.1755  decode.d5.loss_cls: 0.1233  decode.d5.loss_mask: 0.1524  decode.d5.loss_dice: 0.1689  decode.d6.loss_cls: 0.1263  decode.d6.loss_mask: 0.1515  decode.d6.loss_dice: 0.1732  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.1521  decode.d7.loss_dice: 0.1771  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.1509  decode.d8.loss_dice: 0.1743
09/30 15:37:39 - mmengine - INFO - Iter(train) [ 54400/320000]  base_lr: 8.4561e-05 lr: 8.4561e-06  eta: 1 day, 8:02:48  time: 0.4364  data_time: 0.0097  memory: 5129  grad_norm: 21.8316  loss: 5.2001  decode.loss_cls: 0.0262  decode.loss_mask: 0.2085  decode.loss_dice: 0.2029  decode.d0.loss_cls: 0.7736  decode.d0.loss_mask: 0.2109  decode.d0.loss_dice: 0.2090  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.2050  decode.d1.loss_dice: 0.2042  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.2069  decode.d2.loss_dice: 0.2105  decode.d3.loss_cls: 0.0319  decode.d3.loss_mask: 0.2032  decode.d3.loss_dice: 0.1993  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.0253  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.2006  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.2069  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2083  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.1960
09/30 15:38:01 - mmengine - INFO - Iter(train) [ 54450/320000]  base_lr: 8.4547e-05 lr: 8.4547e-06  eta: 1 day, 8:02:27  time: 0.4367  data_time: 0.0096  memory: 5145  grad_norm: 67.0069  loss: 6.7667  decode.loss_cls: 0.1005  decode.loss_mask: 0.2781  decode.loss_dice: 0.1837  decode.d0.loss_cls: 1.0391  decode.d0.loss_mask: 0.2913  decode.d0.loss_dice: 0.2030  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2151  decode.d1.loss_dice: 0.1945  decode.d2.loss_cls: 0.1100  decode.d2.loss_mask: 0.2735  decode.d2.loss_dice: 0.2141  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.2057  decode.d3.loss_dice: 0.2038  decode.d4.loss_cls: 0.1744  decode.d4.loss_mask: 0.2087  decode.d4.loss_dice: 0.1959  decode.d5.loss_cls: 0.1054  decode.d5.loss_mask: 0.2706  decode.d5.loss_dice: 0.2068  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 0.2769  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.2802  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.1041  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.1860
09/30 15:38:23 - mmengine - INFO - Iter(train) [ 54500/320000]  base_lr: 8.4533e-05 lr: 8.4533e-06  eta: 1 day, 8:02:06  time: 0.4367  data_time: 0.0097  memory: 5129  grad_norm: 135.3049  loss: 10.5939  decode.loss_cls: 0.2465  decode.loss_mask: 0.4411  decode.loss_dice: 0.3594  decode.d0.loss_cls: 1.0191  decode.d0.loss_mask: 0.4102  decode.d0.loss_dice: 0.3794  decode.d1.loss_cls: 0.2243  decode.d1.loss_mask: 0.3801  decode.d1.loss_dice: 0.3401  decode.d2.loss_cls: 0.2466  decode.d2.loss_mask: 0.3973  decode.d2.loss_dice: 0.3417  decode.d3.loss_cls: 0.2263  decode.d3.loss_mask: 0.3834  decode.d3.loss_dice: 0.3294  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 0.4616  decode.d4.loss_dice: 0.3033  decode.d5.loss_cls: 0.1511  decode.d5.loss_mask: 0.4962  decode.d5.loss_dice: 0.3443  decode.d6.loss_cls: 0.1803  decode.d6.loss_mask: 0.4969  decode.d6.loss_dice: 0.3556  decode.d7.loss_cls: 0.2384  decode.d7.loss_mask: 0.3849  decode.d7.loss_dice: 0.3185  decode.d8.loss_cls: 0.2267  decode.d8.loss_mask: 0.4008  decode.d8.loss_dice: 0.3472
09/30 15:38:45 - mmengine - INFO - Iter(train) [ 54550/320000]  base_lr: 8.4518e-05 lr: 8.4518e-06  eta: 1 day, 8:01:45  time: 0.4372  data_time: 0.0096  memory: 5145  grad_norm: 112.3386  loss: 7.3057  decode.loss_cls: 0.0739  decode.loss_mask: 0.2705  decode.loss_dice: 0.2512  decode.d0.loss_cls: 0.9031  decode.d0.loss_mask: 0.2737  decode.d0.loss_dice: 0.2804  decode.d1.loss_cls: 0.2362  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2602  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.2595  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.2806  decode.d3.loss_dice: 0.2711  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 0.2738  decode.d4.loss_dice: 0.2456  decode.d5.loss_cls: 0.1513  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2492  decode.d6.loss_cls: 0.1121  decode.d6.loss_mask: 0.2742  decode.d6.loss_dice: 0.2619  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.2708  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.0860  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.2628
09/30 15:39:07 - mmengine - INFO - Iter(train) [ 54600/320000]  base_lr: 8.4504e-05 lr: 8.4504e-06  eta: 1 day, 8:01:23  time: 0.4370  data_time: 0.0096  memory: 5145  grad_norm: 47.3151  loss: 6.5151  decode.loss_cls: 0.2066  decode.loss_mask: 0.2028  decode.loss_dice: 0.1771  decode.d0.loss_cls: 0.8037  decode.d0.loss_mask: 0.2097  decode.d0.loss_dice: 0.2050  decode.d1.loss_cls: 0.2149  decode.d1.loss_mask: 0.2041  decode.d1.loss_dice: 0.1712  decode.d2.loss_cls: 0.1515  decode.d2.loss_mask: 0.2061  decode.d2.loss_dice: 0.2101  decode.d3.loss_cls: 0.1724  decode.d3.loss_mask: 0.2048  decode.d3.loss_dice: 0.2169  decode.d4.loss_cls: 0.2052  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.2023  decode.d5.loss_cls: 0.2301  decode.d5.loss_mask: 0.2043  decode.d5.loss_dice: 0.1750  decode.d6.loss_cls: 0.1933  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.1769  decode.d7.loss_cls: 0.1862  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.1835  decode.d8.loss_cls: 0.1953  decode.d8.loss_mask: 0.2037  decode.d8.loss_dice: 0.1834
09/30 15:39:29 - mmengine - INFO - Iter(train) [ 54650/320000]  base_lr: 8.4490e-05 lr: 8.4490e-06  eta: 1 day, 8:01:02  time: 0.4362  data_time: 0.0096  memory: 5129  grad_norm: 18.3660  loss: 4.9565  decode.loss_cls: 0.0119  decode.loss_mask: 0.2181  decode.loss_dice: 0.1786  decode.d0.loss_cls: 0.7921  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.1862  decode.d1.loss_cls: 0.0205  decode.d1.loss_mask: 0.2208  decode.d1.loss_dice: 0.1893  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.2184  decode.d2.loss_dice: 0.1895  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.1857  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.1812  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2175  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0169  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.1797  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.1810
09/30 15:39:51 - mmengine - INFO - Iter(train) [ 54700/320000]  base_lr: 8.4475e-05 lr: 8.4475e-06  eta: 1 day, 8:00:41  time: 0.4375  data_time: 0.0098  memory: 5129  grad_norm: 88.1684  loss: 7.3065  decode.loss_cls: 0.2235  decode.loss_mask: 0.2385  decode.loss_dice: 0.2295  decode.d0.loss_cls: 1.0312  decode.d0.loss_mask: 0.2450  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.1185  decode.d1.loss_mask: 0.2399  decode.d1.loss_dice: 0.2678  decode.d2.loss_cls: 0.1533  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.1336  decode.d3.loss_mask: 0.2357  decode.d3.loss_dice: 0.2333  decode.d4.loss_cls: 0.1578  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.1576  decode.d5.loss_mask: 0.2370  decode.d5.loss_dice: 0.2339  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.2415  decode.d7.loss_cls: 0.1524  decode.d7.loss_mask: 0.2387  decode.d7.loss_dice: 0.2377  decode.d8.loss_cls: 0.1766  decode.d8.loss_mask: 0.2400  decode.d8.loss_dice: 0.2377
09/30 15:40:12 - mmengine - INFO - Iter(train) [ 54750/320000]  base_lr: 8.4461e-05 lr: 8.4461e-06  eta: 1 day, 8:00:20  time: 0.4361  data_time: 0.0096  memory: 5120  grad_norm: 62.2947  loss: 6.4837  decode.loss_cls: 0.0670  decode.loss_mask: 0.2511  decode.loss_dice: 0.2416  decode.d0.loss_cls: 0.7983  decode.d0.loss_mask: 0.2603  decode.d0.loss_dice: 0.2536  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.2612  decode.d1.loss_dice: 0.2478  decode.d2.loss_cls: 0.0538  decode.d2.loss_mask: 0.2600  decode.d2.loss_dice: 0.2476  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.2344  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.2457  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.2554  decode.d5.loss_dice: 0.2468  decode.d6.loss_cls: 0.0954  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.2482  decode.d7.loss_cls: 0.0817  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.0855  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.2304
09/30 15:40:34 - mmengine - INFO - Iter(train) [ 54800/320000]  base_lr: 8.4447e-05 lr: 8.4447e-06  eta: 1 day, 7:59:59  time: 0.4374  data_time: 0.0096  memory: 5145  grad_norm: 30.7713  loss: 5.2422  decode.loss_cls: 0.0123  decode.loss_mask: 0.2308  decode.loss_dice: 0.1958  decode.d0.loss_cls: 0.8902  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.1985  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.2303  decode.d1.loss_dice: 0.1961  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.1904  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.1913  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.1900  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.2299  decode.d8.loss_dice: 0.1982
09/30 15:40:56 - mmengine - INFO - Iter(train) [ 54850/320000]  base_lr: 8.4432e-05 lr: 8.4432e-06  eta: 1 day, 7:59:38  time: 0.4365  data_time: 0.0097  memory: 5145  grad_norm: 53.8762  loss: 5.0041  decode.loss_cls: 0.0414  decode.loss_mask: 0.2139  decode.loss_dice: 0.1795  decode.d0.loss_cls: 0.7980  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.1908  decode.d1.loss_cls: 0.0179  decode.d1.loss_mask: 0.2148  decode.d1.loss_dice: 0.1811  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.2194  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.2166  decode.d3.loss_dice: 0.1813  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.1796  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.1834  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.2145  decode.d6.loss_dice: 0.1829  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.2131  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0351  decode.d8.loss_mask: 0.2151  decode.d8.loss_dice: 0.1835
09/30 15:41:18 - mmengine - INFO - Iter(train) [ 54900/320000]  base_lr: 8.4418e-05 lr: 8.4418e-06  eta: 1 day, 7:59:17  time: 0.4360  data_time: 0.0097  memory: 5129  grad_norm: 61.7974  loss: 5.2378  decode.loss_cls: 0.0310  decode.loss_mask: 0.2396  decode.loss_dice: 0.1827  decode.d0.loss_cls: 0.8054  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.2005  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.2363  decode.d1.loss_dice: 0.1741  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.2389  decode.d2.loss_dice: 0.1746  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.1741  decode.d4.loss_cls: 0.0253  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.1787  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.2347  decode.d5.loss_dice: 0.1700  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.1733  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.1717  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.1611
09/30 15:41:40 - mmengine - INFO - Iter(train) [ 54950/320000]  base_lr: 8.4404e-05 lr: 8.4404e-06  eta: 1 day, 7:58:55  time: 0.4372  data_time: 0.0094  memory: 5145  grad_norm: 30.3262  loss: 5.1730  decode.loss_cls: 0.0740  decode.loss_mask: 0.1858  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.8881  decode.d0.loss_mask: 0.1895  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0869  decode.d1.loss_mask: 0.1852  decode.d1.loss_dice: 0.1740  decode.d2.loss_cls: 0.0865  decode.d2.loss_mask: 0.1836  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.1261  decode.d3.loss_mask: 0.1829  decode.d3.loss_dice: 0.1677  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 0.1836  decode.d4.loss_dice: 0.1733  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.1836  decode.d5.loss_dice: 0.1777  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.1825  decode.d6.loss_dice: 0.1763  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.1819  decode.d7.loss_dice: 0.1705  decode.d8.loss_cls: 0.0639  decode.d8.loss_mask: 0.1874  decode.d8.loss_dice: 0.1768
09/30 15:42:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:42:02 - mmengine - INFO - Iter(train) [ 55000/320000]  base_lr: 8.4389e-05 lr: 8.4389e-06  eta: 1 day, 7:58:34  time: 0.4366  data_time: 0.0096  memory: 5129  grad_norm: 39.3543  loss: 6.5626  decode.loss_cls: 0.0476  decode.loss_mask: 0.3033  decode.loss_dice: 0.2191  decode.d0.loss_cls: 0.8450  decode.d0.loss_mask: 0.2976  decode.d0.loss_dice: 0.2432  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.2171  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.2943  decode.d2.loss_dice: 0.2234  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.2900  decode.d3.loss_dice: 0.2120  decode.d4.loss_cls: 0.0626  decode.d4.loss_mask: 0.2884  decode.d4.loss_dice: 0.2133  decode.d5.loss_cls: 0.0560  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.2956  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.2977  decode.d7.loss_dice: 0.2191  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.2211
09/30 15:42:23 - mmengine - INFO - Iter(train) [ 55050/320000]  base_lr: 8.4375e-05 lr: 8.4375e-06  eta: 1 day, 7:58:13  time: 0.4373  data_time: 0.0095  memory: 5129  grad_norm: 19.7821  loss: 4.1718  decode.loss_cls: 0.0165  decode.loss_mask: 0.1737  decode.loss_dice: 0.1494  decode.d0.loss_cls: 0.8183  decode.d0.loss_mask: 0.1724  decode.d0.loss_dice: 0.1507  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.1719  decode.d1.loss_dice: 0.1534  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.1723  decode.d2.loss_dice: 0.1492  decode.d3.loss_cls: 0.0115  decode.d3.loss_mask: 0.1735  decode.d3.loss_dice: 0.1511  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.1734  decode.d4.loss_dice: 0.1532  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.1754  decode.d5.loss_dice: 0.1545  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.1501  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.1714  decode.d7.loss_dice: 0.1506  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.1720  decode.d8.loss_dice: 0.1511
09/30 15:42:45 - mmengine - INFO - Iter(train) [ 55100/320000]  base_lr: 8.4361e-05 lr: 8.4361e-06  eta: 1 day, 7:57:52  time: 0.4366  data_time: 0.0095  memory: 5145  grad_norm: 78.6356  loss: 5.6662  decode.loss_cls: 0.1214  decode.loss_mask: 0.1972  decode.loss_dice: 0.1794  decode.d0.loss_cls: 0.8758  decode.d0.loss_mask: 0.2006  decode.d0.loss_dice: 0.1747  decode.d1.loss_cls: 0.1584  decode.d1.loss_mask: 0.1938  decode.d1.loss_dice: 0.1593  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.1963  decode.d2.loss_dice: 0.1741  decode.d3.loss_cls: 0.1167  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.1718  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.1995  decode.d4.loss_dice: 0.1749  decode.d5.loss_cls: 0.1194  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.1798  decode.d6.loss_cls: 0.1201  decode.d6.loss_mask: 0.1937  decode.d6.loss_dice: 0.1690  decode.d7.loss_cls: 0.1209  decode.d7.loss_mask: 0.2133  decode.d7.loss_dice: 0.2052  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.2087
09/30 15:43:07 - mmengine - INFO - Iter(train) [ 55150/320000]  base_lr: 8.4346e-05 lr: 8.4346e-06  eta: 1 day, 7:57:31  time: 0.4371  data_time: 0.0098  memory: 5120  grad_norm: 69.1029  loss: 5.2866  decode.loss_cls: 0.0483  decode.loss_mask: 0.2185  decode.loss_dice: 0.1919  decode.d0.loss_cls: 0.8584  decode.d0.loss_mask: 0.2168  decode.d0.loss_dice: 0.1969  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.1936  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.2043  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.2183  decode.d3.loss_dice: 0.1862  decode.d4.loss_cls: 0.0340  decode.d4.loss_mask: 0.2186  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.1881  decode.d6.loss_cls: 0.0303  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.1812  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 0.2190  decode.d7.loss_dice: 0.1983  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.1827
09/30 15:43:29 - mmengine - INFO - Iter(train) [ 55200/320000]  base_lr: 8.4332e-05 lr: 8.4332e-06  eta: 1 day, 7:57:10  time: 0.4367  data_time: 0.0096  memory: 5129  grad_norm: 69.2811  loss: 5.9255  decode.loss_cls: 0.0274  decode.loss_mask: 0.2400  decode.loss_dice: 0.2407  decode.d0.loss_cls: 0.7249  decode.d0.loss_mask: 0.2346  decode.d0.loss_dice: 0.2307  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.2353  decode.d1.loss_dice: 0.2335  decode.d2.loss_cls: 0.0928  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.2397  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2307  decode.d4.loss_cls: 0.0912  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.2353  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.2362  decode.d5.loss_dice: 0.2265  decode.d6.loss_cls: 0.0324  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.2258  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.2406  decode.d7.loss_dice: 0.2395  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2399
09/30 15:43:51 - mmengine - INFO - Iter(train) [ 55250/320000]  base_lr: 8.4318e-05 lr: 8.4318e-06  eta: 1 day, 7:56:48  time: 0.4359  data_time: 0.0097  memory: 5145  grad_norm: 37.4660  loss: 5.3982  decode.loss_cls: 0.0833  decode.loss_mask: 0.2092  decode.loss_dice: 0.1799  decode.d0.loss_cls: 0.7453  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.1132  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.1783  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.2089  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.1017  decode.d3.loss_mask: 0.2081  decode.d3.loss_dice: 0.1760  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.1879  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.1955  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.2093  decode.d6.loss_dice: 0.1871  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 0.2085  decode.d7.loss_dice: 0.1839  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.1790
09/30 15:44:13 - mmengine - INFO - Iter(train) [ 55300/320000]  base_lr: 8.4303e-05 lr: 8.4303e-06  eta: 1 day, 7:56:27  time: 0.4369  data_time: 0.0095  memory: 5145  grad_norm: 44.7910  loss: 5.0102  decode.loss_cls: 0.1007  decode.loss_mask: 0.1652  decode.loss_dice: 0.1647  decode.d0.loss_cls: 0.8908  decode.d0.loss_mask: 0.1690  decode.d0.loss_dice: 0.1683  decode.d1.loss_cls: 0.0909  decode.d1.loss_mask: 0.1645  decode.d1.loss_dice: 0.1588  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.1657  decode.d2.loss_dice: 0.1753  decode.d3.loss_cls: 0.0747  decode.d3.loss_mask: 0.1640  decode.d3.loss_dice: 0.1568  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.1654  decode.d4.loss_dice: 0.1967  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.1635  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.0894  decode.d6.loss_mask: 0.1610  decode.d6.loss_dice: 0.1693  decode.d7.loss_cls: 0.1200  decode.d7.loss_mask: 0.1627  decode.d7.loss_dice: 0.1628  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.1632  decode.d8.loss_dice: 0.1605
09/30 15:44:35 - mmengine - INFO - Iter(train) [ 55350/320000]  base_lr: 8.4289e-05 lr: 8.4289e-06  eta: 1 day, 7:56:06  time: 0.4376  data_time: 0.0095  memory: 5129  grad_norm: 97.4080  loss: 5.3764  decode.loss_cls: 0.0537  decode.loss_mask: 0.2129  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.7412  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.1860  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.1955  decode.d2.loss_cls: 0.0591  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1959  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.2151  decode.d3.loss_dice: 0.2005  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.2163  decode.d4.loss_dice: 0.1968  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.1987  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.2119  decode.d6.loss_dice: 0.2010  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.1953
09/30 15:44:56 - mmengine - INFO - Iter(train) [ 55400/320000]  base_lr: 8.4275e-05 lr: 8.4275e-06  eta: 1 day, 7:55:45  time: 0.4367  data_time: 0.0096  memory: 5145  grad_norm: 74.2997  loss: 5.7960  decode.loss_cls: 0.1510  decode.loss_mask: 0.2022  decode.loss_dice: 0.1851  decode.d0.loss_cls: 0.9136  decode.d0.loss_mask: 0.2061  decode.d0.loss_dice: 0.1912  decode.d1.loss_cls: 0.1160  decode.d1.loss_mask: 0.2033  decode.d1.loss_dice: 0.1825  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.2040  decode.d2.loss_dice: 0.1854  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.1997  decode.d3.loss_dice: 0.1855  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 0.2010  decode.d4.loss_dice: 0.1809  decode.d5.loss_cls: 0.1165  decode.d5.loss_mask: 0.2030  decode.d5.loss_dice: 0.1767  decode.d6.loss_cls: 0.1219  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.1816  decode.d7.loss_cls: 0.1415  decode.d7.loss_mask: 0.2026  decode.d7.loss_dice: 0.1843  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.2024  decode.d8.loss_dice: 0.1790
09/30 15:45:18 - mmengine - INFO - Iter(train) [ 55450/320000]  base_lr: 8.4260e-05 lr: 8.4260e-06  eta: 1 day, 7:55:24  time: 0.4384  data_time: 0.0098  memory: 5129  grad_norm: 40.6381  loss: 7.2758  decode.loss_cls: 0.1528  decode.loss_mask: 0.2632  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.9346  decode.d0.loss_mask: 0.2662  decode.d0.loss_dice: 0.1797  decode.d1.loss_cls: 0.1566  decode.d1.loss_mask: 0.2639  decode.d1.loss_dice: 0.1864  decode.d2.loss_cls: 0.1539  decode.d2.loss_mask: 0.2636  decode.d2.loss_dice: 0.1851  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.4422  decode.d3.loss_dice: 0.2045  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.4445  decode.d4.loss_dice: 0.2042  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.4561  decode.d5.loss_dice: 0.2036  decode.d6.loss_cls: 0.1549  decode.d6.loss_mask: 0.2658  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.1519  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.1854  decode.d8.loss_cls: 0.1745  decode.d8.loss_mask: 0.2613  decode.d8.loss_dice: 0.1823
09/30 15:45:40 - mmengine - INFO - Iter(train) [ 55500/320000]  base_lr: 8.4246e-05 lr: 8.4246e-06  eta: 1 day, 7:55:04  time: 0.4377  data_time: 0.0099  memory: 5145  grad_norm: 74.8909  loss: 7.1907  decode.loss_cls: 0.1589  decode.loss_mask: 0.2323  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.9574  decode.d0.loss_mask: 0.2350  decode.d0.loss_dice: 0.2969  decode.d1.loss_cls: 0.1321  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.2769  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.2325  decode.d3.loss_dice: 0.2861  decode.d4.loss_cls: 0.0767  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.2898  decode.d5.loss_cls: 0.1122  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2698  decode.d6.loss_cls: 0.1416  decode.d6.loss_mask: 0.2324  decode.d6.loss_dice: 0.2735  decode.d7.loss_cls: 0.1548  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.2775  decode.d8.loss_cls: 0.1400  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2856
09/30 15:46:02 - mmengine - INFO - Iter(train) [ 55550/320000]  base_lr: 8.4232e-05 lr: 8.4232e-06  eta: 1 day, 7:54:43  time: 0.4360  data_time: 0.0097  memory: 5129  grad_norm: 45.5205  loss: 6.5182  decode.loss_cls: 0.0937  decode.loss_mask: 0.2442  decode.loss_dice: 0.2272  decode.d0.loss_cls: 0.8616  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.2518  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 0.2462  decode.d1.loss_dice: 0.2005  decode.d2.loss_cls: 0.1122  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.2153  decode.d3.loss_cls: 0.1674  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.2156  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.2282  decode.d5.loss_cls: 0.1033  decode.d5.loss_mask: 0.2451  decode.d5.loss_dice: 0.2233  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2241  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 0.2448  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.2243
09/30 15:46:24 - mmengine - INFO - Iter(train) [ 55600/320000]  base_lr: 8.4217e-05 lr: 8.4217e-06  eta: 1 day, 7:54:22  time: 0.4360  data_time: 0.0096  memory: 5129  grad_norm: 90.7046  loss: 6.1772  decode.loss_cls: 0.0685  decode.loss_mask: 0.2609  decode.loss_dice: 0.1948  decode.d0.loss_cls: 0.7900  decode.d0.loss_mask: 0.3481  decode.d0.loss_dice: 0.2064  decode.d1.loss_cls: 0.0930  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.2017  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.2635  decode.d2.loss_dice: 0.2067  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.2571  decode.d3.loss_dice: 0.2015  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.2553  decode.d4.loss_dice: 0.1977  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.2568  decode.d5.loss_dice: 0.1947  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.2610  decode.d6.loss_dice: 0.1989  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.1990  decode.d8.loss_cls: 0.0873  decode.d8.loss_mask: 0.2566  decode.d8.loss_dice: 0.1946
09/30 15:46:46 - mmengine - INFO - Iter(train) [ 55650/320000]  base_lr: 8.4203e-05 lr: 8.4203e-06  eta: 1 day, 7:54:01  time: 0.4373  data_time: 0.0098  memory: 5129  grad_norm: 23.0592  loss: 5.7147  decode.loss_cls: 0.0100  decode.loss_mask: 0.3081  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.7312  decode.d0.loss_mask: 0.3154  decode.d0.loss_dice: 0.1789  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.3150  decode.d1.loss_dice: 0.1805  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.3149  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.3095  decode.d3.loss_dice: 0.1795  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.3086  decode.d4.loss_dice: 0.1816  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.3076  decode.d5.loss_dice: 0.1802  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.3063  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.3109  decode.d7.loss_dice: 0.1815  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.2232  decode.d8.loss_dice: 0.1678
09/30 15:47:08 - mmengine - INFO - Iter(train) [ 55700/320000]  base_lr: 8.4189e-05 lr: 8.4189e-06  eta: 1 day, 7:53:40  time: 0.4362  data_time: 0.0098  memory: 5129  grad_norm: 171.5038  loss: 7.3449  decode.loss_cls: 0.0610  decode.loss_mask: 0.3210  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.8935  decode.d0.loss_mask: 0.3308  decode.d0.loss_dice: 0.2322  decode.d1.loss_cls: 0.1629  decode.d1.loss_mask: 0.3118  decode.d1.loss_dice: 0.2395  decode.d2.loss_cls: 0.0896  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.2549  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.2518  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.3184  decode.d4.loss_dice: 0.2620  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.3238  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.3176  decode.d6.loss_dice: 0.2473  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.3188  decode.d7.loss_dice: 0.2745  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.3195  decode.d8.loss_dice: 0.2508
09/30 15:47:30 - mmengine - INFO - Iter(train) [ 55750/320000]  base_lr: 8.4174e-05 lr: 8.4174e-06  eta: 1 day, 7:53:19  time: 0.4372  data_time: 0.0096  memory: 5129  grad_norm: 37.7464  loss: 6.2789  decode.loss_cls: 0.1111  decode.loss_mask: 0.2155  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.7719  decode.d0.loss_mask: 0.2202  decode.d0.loss_dice: 0.2447  decode.d1.loss_cls: 0.1691  decode.d1.loss_mask: 0.2143  decode.d1.loss_dice: 0.2313  decode.d2.loss_cls: 0.1699  decode.d2.loss_mask: 0.2161  decode.d2.loss_dice: 0.2044  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.2162  decode.d3.loss_dice: 0.2018  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.2216  decode.d6.loss_cls: 0.0891  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.1316  decode.d7.loss_mask: 0.2150  decode.d7.loss_dice: 0.2428  decode.d8.loss_cls: 0.1671  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.2420
09/30 15:47:51 - mmengine - INFO - Iter(train) [ 55800/320000]  base_lr: 8.4160e-05 lr: 8.4160e-06  eta: 1 day, 7:52:58  time: 0.4370  data_time: 0.0095  memory: 5145  grad_norm: 159.2358  loss: 6.7718  decode.loss_cls: 0.1749  decode.loss_mask: 0.2044  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.8578  decode.d0.loss_mask: 0.2083  decode.d0.loss_dice: 0.2356  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 0.2060  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.1579  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 0.2025  decode.d3.loss_dice: 0.2203  decode.d4.loss_cls: 0.2057  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.2054  decode.d5.loss_cls: 0.1793  decode.d5.loss_mask: 0.2048  decode.d5.loss_dice: 0.2053  decode.d6.loss_cls: 0.1588  decode.d6.loss_mask: 0.2048  decode.d6.loss_dice: 0.2386  decode.d7.loss_cls: 0.1661  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.2289  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 0.2042  decode.d8.loss_dice: 0.2402
09/30 15:48:13 - mmengine - INFO - Iter(train) [ 55850/320000]  base_lr: 8.4146e-05 lr: 8.4146e-06  eta: 1 day, 7:52:36  time: 0.4357  data_time: 0.0097  memory: 5145  grad_norm: 43.2268  loss: 8.3122  decode.loss_cls: 0.1392  decode.loss_mask: 0.4062  decode.loss_dice: 0.2128  decode.d0.loss_cls: 0.7988  decode.d0.loss_mask: 0.4178  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.1406  decode.d1.loss_mask: 0.4082  decode.d1.loss_dice: 0.2108  decode.d2.loss_cls: 0.1300  decode.d2.loss_mask: 0.4199  decode.d2.loss_dice: 0.2187  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 0.4216  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 0.4236  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 0.4307  decode.d5.loss_dice: 0.2156  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.4089  decode.d6.loss_dice: 0.2104  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.4183  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.1365  decode.d8.loss_mask: 0.4181  decode.d8.loss_dice: 0.2158
09/30 15:48:35 - mmengine - INFO - Iter(train) [ 55900/320000]  base_lr: 8.4131e-05 lr: 8.4131e-06  eta: 1 day, 7:52:15  time: 0.4370  data_time: 0.0096  memory: 5145  grad_norm: 28.3510  loss: 5.9486  decode.loss_cls: 0.0610  decode.loss_mask: 0.2726  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.8407  decode.d0.loss_mask: 0.2750  decode.d0.loss_dice: 0.1967  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.2689  decode.d1.loss_dice: 0.1966  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.1958  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.2713  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.2692  decode.d4.loss_dice: 0.2042  decode.d5.loss_cls: 0.0342  decode.d5.loss_mask: 0.2777  decode.d5.loss_dice: 0.2096  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.2738  decode.d6.loss_dice: 0.1963  decode.d7.loss_cls: 0.0379  decode.d7.loss_mask: 0.2694  decode.d7.loss_dice: 0.1969  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.2712  decode.d8.loss_dice: 0.1978
09/30 15:48:57 - mmengine - INFO - Iter(train) [ 55950/320000]  base_lr: 8.4117e-05 lr: 8.4117e-06  eta: 1 day, 7:51:54  time: 0.4359  data_time: 0.0095  memory: 5145  grad_norm: 28.3015  loss: 5.8130  decode.loss_cls: 0.0475  decode.loss_mask: 0.2324  decode.loss_dice: 0.1988  decode.d0.loss_cls: 0.9826  decode.d0.loss_mask: 0.2446  decode.d0.loss_dice: 0.2088  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.2348  decode.d1.loss_dice: 0.1985  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.2310  decode.d2.loss_dice: 0.2054  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.1999  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2342  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.2075  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.2055  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2063  decode.d8.loss_cls: 0.0528  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.2065
09/30 15:49:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:49:19 - mmengine - INFO - Iter(train) [ 56000/320000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 1 day, 7:51:33  time: 0.4364  data_time: 0.0095  memory: 5145  grad_norm: 36.3066  loss: 6.3064  decode.loss_cls: 0.0356  decode.loss_mask: 0.2954  decode.loss_dice: 0.2347  decode.d0.loss_cls: 0.8204  decode.d0.loss_mask: 0.3096  decode.d0.loss_dice: 0.2312  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.2951  decode.d2.loss_dice: 0.2290  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.2972  decode.d3.loss_dice: 0.2325  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.2971  decode.d4.loss_dice: 0.2344  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2982  decode.d5.loss_dice: 0.2364  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.2195  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.2981  decode.d7.loss_dice: 0.2313  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.3002  decode.d8.loss_dice: 0.2282
09/30 15:49:41 - mmengine - INFO - Iter(train) [ 56050/320000]  base_lr: 8.4088e-05 lr: 8.4088e-06  eta: 1 day, 7:51:11  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 54.9854  loss: 8.3506  decode.loss_cls: 0.1923  decode.loss_mask: 0.2446  decode.loss_dice: 0.3290  decode.d0.loss_cls: 1.0235  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.3140  decode.d1.loss_cls: 0.1968  decode.d1.loss_mask: 0.2498  decode.d1.loss_dice: 0.3169  decode.d2.loss_cls: 0.2124  decode.d2.loss_mask: 0.2478  decode.d2.loss_dice: 0.2784  decode.d3.loss_cls: 0.1953  decode.d3.loss_mask: 0.2456  decode.d3.loss_dice: 0.2751  decode.d4.loss_cls: 0.2201  decode.d4.loss_mask: 0.2422  decode.d4.loss_dice: 0.2939  decode.d5.loss_cls: 0.2019  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.3017  decode.d6.loss_cls: 0.1905  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.3067  decode.d7.loss_cls: 0.1983  decode.d7.loss_mask: 0.2480  decode.d7.loss_dice: 0.3155  decode.d8.loss_cls: 0.2028  decode.d8.loss_mask: 0.2454  decode.d8.loss_dice: 0.3153
09/30 15:50:02 - mmengine - INFO - Iter(train) [ 56100/320000]  base_lr: 8.4074e-05 lr: 8.4074e-06  eta: 1 day, 7:50:50  time: 0.4372  data_time: 0.0098  memory: 5129  grad_norm: 31.9009  loss: 5.5709  decode.loss_cls: 0.0609  decode.loss_mask: 0.2268  decode.loss_dice: 0.1788  decode.d0.loss_cls: 0.7570  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.1943  decode.d1.loss_cls: 0.1363  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.1777  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.0639  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1817  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.1835  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.1828  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.1812  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.1795
09/30 15:50:24 - mmengine - INFO - Iter(train) [ 56150/320000]  base_lr: 8.4060e-05 lr: 8.4060e-06  eta: 1 day, 7:50:29  time: 0.4363  data_time: 0.0097  memory: 5145  grad_norm: 65.1237  loss: 6.0936  decode.loss_cls: 0.1624  decode.loss_mask: 0.2129  decode.loss_dice: 0.1938  decode.d0.loss_cls: 0.7908  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.0940  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.2298  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.2150  decode.d3.loss_dice: 0.2090  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.2145  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.1146  decode.d6.loss_mask: 0.2154  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.1438  decode.d7.loss_mask: 0.2149  decode.d7.loss_dice: 0.2175  decode.d8.loss_cls: 0.1445  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.2134
09/30 15:50:46 - mmengine - INFO - Iter(train) [ 56200/320000]  base_lr: 8.4045e-05 lr: 8.4045e-06  eta: 1 day, 7:50:08  time: 0.4366  data_time: 0.0097  memory: 5145  grad_norm: 50.6780  loss: 6.6962  decode.loss_cls: 0.0788  decode.loss_mask: 0.2668  decode.loss_dice: 0.2391  decode.d0.loss_cls: 0.8664  decode.d0.loss_mask: 0.2669  decode.d0.loss_dice: 0.2728  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.2460  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.2651  decode.d2.loss_dice: 0.2490  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.2462  decode.d4.loss_cls: 0.0585  decode.d4.loss_mask: 0.2661  decode.d4.loss_dice: 0.2623  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.2626  decode.d5.loss_dice: 0.2673  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2513  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.2629  decode.d7.loss_dice: 0.2758  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.2625  decode.d8.loss_dice: 0.2513
09/30 15:51:08 - mmengine - INFO - Iter(train) [ 56250/320000]  base_lr: 8.4031e-05 lr: 8.4031e-06  eta: 1 day, 7:49:46  time: 0.4362  data_time: 0.0098  memory: 5129  grad_norm: 152.7880  loss: 5.3357  decode.loss_cls: 0.0019  decode.loss_mask: 0.2371  decode.loss_dice: 0.2126  decode.d0.loss_cls: 0.7969  decode.d0.loss_mask: 0.2370  decode.d0.loss_dice: 0.2204  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2160  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.2385  decode.d2.loss_dice: 0.2108  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.2347  decode.d3.loss_dice: 0.2103  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2329  decode.d4.loss_dice: 0.2196  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.2197  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.2098  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.2122
09/30 15:51:30 - mmengine - INFO - Iter(train) [ 56300/320000]  base_lr: 8.4017e-05 lr: 8.4017e-06  eta: 1 day, 7:49:25  time: 0.4362  data_time: 0.0096  memory: 5145  grad_norm: 34.1671  loss: 5.2305  decode.loss_cls: 0.0523  decode.loss_mask: 0.1923  decode.loss_dice: 0.1890  decode.d0.loss_cls: 0.6794  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.1928  decode.d1.loss_cls: 0.1631  decode.d1.loss_mask: 0.1911  decode.d1.loss_dice: 0.1997  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.1921  decode.d2.loss_dice: 0.1923  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.1926  decode.d3.loss_dice: 0.1982  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.1927  decode.d4.loss_dice: 0.1941  decode.d5.loss_cls: 0.0963  decode.d5.loss_mask: 0.1907  decode.d5.loss_dice: 0.1942  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.1888  decode.d7.loss_cls: 0.0394  decode.d7.loss_mask: 0.1938  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.1828
09/30 15:51:52 - mmengine - INFO - Iter(train) [ 56350/320000]  base_lr: 8.4002e-05 lr: 8.4002e-06  eta: 1 day, 7:49:04  time: 0.4358  data_time: 0.0097  memory: 5104  grad_norm: 86.1520  loss: 4.7848  decode.loss_cls: 0.0252  decode.loss_mask: 0.1879  decode.loss_dice: 0.1596  decode.d0.loss_cls: 1.0102  decode.d0.loss_mask: 0.1892  decode.d0.loss_dice: 0.1624  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.1885  decode.d1.loss_dice: 0.1647  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.2003  decode.d2.loss_dice: 0.1601  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.1910  decode.d3.loss_dice: 0.1573  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.1839  decode.d4.loss_dice: 0.1648  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.1889  decode.d5.loss_dice: 0.1610  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.1611  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.1876  decode.d7.loss_dice: 0.1597  decode.d8.loss_cls: 0.0301  decode.d8.loss_mask: 0.1884  decode.d8.loss_dice: 0.1635
09/30 15:52:13 - mmengine - INFO - Iter(train) [ 56400/320000]  base_lr: 8.3988e-05 lr: 8.3988e-06  eta: 1 day, 7:48:43  time: 0.4358  data_time: 0.0097  memory: 5120  grad_norm: 149.6108  loss: 5.3560  decode.loss_cls: 0.0445  decode.loss_mask: 0.2210  decode.loss_dice: 0.1722  decode.d0.loss_cls: 0.7634  decode.d0.loss_mask: 0.2193  decode.d0.loss_dice: 0.1721  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.1851  decode.d2.loss_cls: 0.0814  decode.d2.loss_mask: 0.2204  decode.d2.loss_dice: 0.1685  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.1667  decode.d4.loss_cls: 0.1019  decode.d4.loss_mask: 0.2183  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0973  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.1660  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.2186  decode.d6.loss_dice: 0.1691  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.2190  decode.d7.loss_dice: 0.1680  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.2177  decode.d8.loss_dice: 0.1668
09/30 15:52:35 - mmengine - INFO - Iter(train) [ 56450/320000]  base_lr: 8.3974e-05 lr: 8.3974e-06  eta: 1 day, 7:48:21  time: 0.4355  data_time: 0.0097  memory: 5129  grad_norm: 32.7649  loss: 4.7494  decode.loss_cls: 0.0151  decode.loss_mask: 0.2167  decode.loss_dice: 0.1582  decode.d0.loss_cls: 0.8703  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.1670  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.1532  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.1562  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.1579  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.1582  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.2169  decode.d6.loss_dice: 0.1586  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.2147  decode.d7.loss_dice: 0.1609  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.2151  decode.d8.loss_dice: 0.1593
09/30 15:52:57 - mmengine - INFO - Iter(train) [ 56500/320000]  base_lr: 8.3959e-05 lr: 8.3959e-06  eta: 1 day, 7:48:00  time: 0.4362  data_time: 0.0096  memory: 5129  grad_norm: 47.2039  loss: 6.3750  decode.loss_cls: 0.0561  decode.loss_mask: 0.2889  decode.loss_dice: 0.2078  decode.d0.loss_cls: 0.8305  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.2105  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.2165  decode.d2.loss_cls: 0.1238  decode.d2.loss_mask: 0.2385  decode.d2.loss_dice: 0.2083  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.2920  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.2907  decode.d4.loss_dice: 0.2185  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.2881  decode.d5.loss_dice: 0.2153  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.2156  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.2901  decode.d7.loss_dice: 0.2175  decode.d8.loss_cls: 0.0493  decode.d8.loss_mask: 0.2910  decode.d8.loss_dice: 0.2239
09/30 15:53:19 - mmengine - INFO - Iter(train) [ 56550/320000]  base_lr: 8.3945e-05 lr: 8.3945e-06  eta: 1 day, 7:47:39  time: 0.4366  data_time: 0.0097  memory: 5129  grad_norm: 43.6898  loss: 5.9091  decode.loss_cls: 0.0453  decode.loss_mask: 0.2439  decode.loss_dice: 0.1978  decode.d0.loss_cls: 0.7214  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.2218  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.2431  decode.d1.loss_dice: 0.2141  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.2425  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.1964  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.2441  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.0558  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.2216
09/30 15:53:41 - mmengine - INFO - Iter(train) [ 56600/320000]  base_lr: 8.3931e-05 lr: 8.3931e-06  eta: 1 day, 7:47:18  time: 0.4369  data_time: 0.0098  memory: 5120  grad_norm: 45.1765  loss: 6.1495  decode.loss_cls: 0.0464  decode.loss_mask: 0.2391  decode.loss_dice: 0.2414  decode.d0.loss_cls: 0.8822  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.2724  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.2420  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.2412  decode.d2.loss_dice: 0.2318  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2378  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2311  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.2300  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.2496  decode.d8.loss_cls: 0.0390  decode.d8.loss_mask: 0.2384  decode.d8.loss_dice: 0.2242
09/30 15:54:03 - mmengine - INFO - Iter(train) [ 56650/320000]  base_lr: 8.3916e-05 lr: 8.3916e-06  eta: 1 day, 7:46:57  time: 0.4367  data_time: 0.0099  memory: 5129  grad_norm: 59.7790  loss: 7.4658  decode.loss_cls: 0.0910  decode.loss_mask: 0.3325  decode.loss_dice: 0.2630  decode.d0.loss_cls: 0.8256  decode.d0.loss_mask: 0.3172  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 0.3315  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.1038  decode.d2.loss_mask: 0.3295  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.3299  decode.d3.loss_dice: 0.2633  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.3298  decode.d4.loss_dice: 0.2493  decode.d5.loss_cls: 0.0965  decode.d5.loss_mask: 0.3301  decode.d5.loss_dice: 0.2546  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 0.3316  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.3264  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.3246  decode.d8.loss_dice: 0.2547
09/30 15:54:24 - mmengine - INFO - Iter(train) [ 56700/320000]  base_lr: 8.3902e-05 lr: 8.3902e-06  eta: 1 day, 7:46:35  time: 0.4358  data_time: 0.0096  memory: 5120  grad_norm: 35.7919  loss: 8.4541  decode.loss_cls: 0.2465  decode.loss_mask: 0.2298  decode.loss_dice: 0.2689  decode.d0.loss_cls: 1.0101  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.2757  decode.d1.loss_cls: 0.2659  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2798  decode.d2.loss_cls: 0.2633  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2765  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 0.2908  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.1844  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.2679  decode.d5.loss_cls: 0.1615  decode.d5.loss_mask: 0.2998  decode.d5.loss_dice: 0.2684  decode.d6.loss_cls: 0.2419  decode.d6.loss_mask: 0.2882  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.2608  decode.d7.loss_mask: 0.2484  decode.d7.loss_dice: 0.2734  decode.d8.loss_cls: 0.2666  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2691
09/30 15:54:46 - mmengine - INFO - Iter(train) [ 56750/320000]  base_lr: 8.3888e-05 lr: 8.3888e-06  eta: 1 day, 7:46:14  time: 0.4364  data_time: 0.0097  memory: 5129  grad_norm: 36.7783  loss: 7.5036  decode.loss_cls: 0.1539  decode.loss_mask: 0.2195  decode.loss_dice: 0.3870  decode.d0.loss_cls: 1.0624  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.3179  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.2167  decode.d1.loss_dice: 0.3048  decode.d2.loss_cls: 0.1035  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.3010  decode.d3.loss_cls: 0.1803  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.3000  decode.d4.loss_cls: 0.1547  decode.d4.loss_mask: 0.2142  decode.d4.loss_dice: 0.3059  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.2177  decode.d5.loss_dice: 0.3078  decode.d6.loss_cls: 0.1057  decode.d6.loss_mask: 0.2164  decode.d6.loss_dice: 0.3156  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.2132  decode.d7.loss_dice: 0.2951  decode.d8.loss_cls: 0.1195  decode.d8.loss_mask: 0.2150  decode.d8.loss_dice: 0.3202
09/30 15:55:08 - mmengine - INFO - Iter(train) [ 56800/320000]  base_lr: 8.3873e-05 lr: 8.3873e-06  eta: 1 day, 7:45:53  time: 0.4368  data_time: 0.0095  memory: 5129  grad_norm: 19.8290  loss: 4.5482  decode.loss_cls: 0.0042  decode.loss_mask: 0.1886  decode.loss_dice: 0.1734  decode.d0.loss_cls: 0.8388  decode.d0.loss_mask: 0.1914  decode.d0.loss_dice: 0.1677  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.1912  decode.d1.loss_dice: 0.1712  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.1922  decode.d2.loss_dice: 0.1728  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.1877  decode.d3.loss_dice: 0.1736  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.1892  decode.d4.loss_dice: 0.1705  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.1903  decode.d6.loss_dice: 0.1702  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.1915  decode.d8.loss_dice: 0.1761
09/30 15:55:30 - mmengine - INFO - Iter(train) [ 56850/320000]  base_lr: 8.3859e-05 lr: 8.3859e-06  eta: 1 day, 7:45:32  time: 0.4368  data_time: 0.0097  memory: 5130  grad_norm: 53.0019  loss: 5.2307  decode.loss_cls: 0.0419  decode.loss_mask: 0.2289  decode.loss_dice: 0.1737  decode.d0.loss_cls: 0.8689  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1666  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.1838  decode.d2.loss_cls: 0.0487  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.2294  decode.d4.loss_dice: 0.1672  decode.d5.loss_cls: 0.0345  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1711  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.1723  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.1699  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.1699
09/30 15:55:52 - mmengine - INFO - Iter(train) [ 56900/320000]  base_lr: 8.3845e-05 lr: 8.3845e-06  eta: 1 day, 7:45:10  time: 0.4357  data_time: 0.0094  memory: 5120  grad_norm: 72.5602  loss: 5.2463  decode.loss_cls: 0.0762  decode.loss_mask: 0.2094  decode.loss_dice: 0.1666  decode.d0.loss_cls: 0.8158  decode.d0.loss_mask: 0.2105  decode.d0.loss_dice: 0.1727  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.1719  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.2074  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 0.2078  decode.d3.loss_dice: 0.1644  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.1668  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.2200  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.2166  decode.d6.loss_dice: 0.1727  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.2093  decode.d7.loss_dice: 0.1671  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.1636
09/30 15:56:14 - mmengine - INFO - Iter(train) [ 56950/320000]  base_lr: 8.3830e-05 lr: 8.3830e-06  eta: 1 day, 7:44:49  time: 0.4375  data_time: 0.0097  memory: 5129  grad_norm: 99.6305  loss: 8.1569  decode.loss_cls: 0.1780  decode.loss_mask: 0.2553  decode.loss_dice: 0.3110  decode.d0.loss_cls: 0.8638  decode.d0.loss_mask: 0.2490  decode.d0.loss_dice: 0.3261  decode.d1.loss_cls: 0.2091  decode.d1.loss_mask: 0.2493  decode.d1.loss_dice: 0.3142  decode.d2.loss_cls: 0.1858  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.3105  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 0.2450  decode.d3.loss_dice: 0.3174  decode.d4.loss_cls: 0.2550  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.3180  decode.d5.loss_cls: 0.1360  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.2945  decode.d6.loss_cls: 0.1501  decode.d6.loss_mask: 0.2546  decode.d6.loss_dice: 0.3219  decode.d7.loss_cls: 0.2076  decode.d7.loss_mask: 0.2534  decode.d7.loss_dice: 0.3088  decode.d8.loss_cls: 0.1582  decode.d8.loss_mask: 0.2566  decode.d8.loss_dice: 0.3035
09/30 15:56:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 15:56:35 - mmengine - INFO - Iter(train) [ 57000/320000]  base_lr: 8.3816e-05 lr: 8.3816e-06  eta: 1 day, 7:44:28  time: 0.4367  data_time: 0.0098  memory: 5129  grad_norm: 30.3522  loss: 6.0339  decode.loss_cls: 0.0705  decode.loss_mask: 0.2462  decode.loss_dice: 0.2081  decode.d0.loss_cls: 0.7250  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.2320  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.2497  decode.d1.loss_dice: 0.1972  decode.d2.loss_cls: 0.1344  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.1150  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.2258  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.2377  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.1023  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.2073  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2054
09/30 15:56:57 - mmengine - INFO - Iter(train) [ 57050/320000]  base_lr: 8.3802e-05 lr: 8.3802e-06  eta: 1 day, 7:44:06  time: 0.4372  data_time: 0.0097  memory: 5146  grad_norm: 88.7175  loss: 8.8613  decode.loss_cls: 0.2925  decode.loss_mask: 0.2942  decode.loss_dice: 0.2426  decode.d0.loss_cls: 0.9481  decode.d0.loss_mask: 0.2926  decode.d0.loss_dice: 0.2469  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.2378  decode.d2.loss_cls: 0.2981  decode.d2.loss_mask: 0.2975  decode.d2.loss_dice: 0.2407  decode.d3.loss_cls: 0.3212  decode.d3.loss_mask: 0.3013  decode.d3.loss_dice: 0.2753  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.2528  decode.d5.loss_cls: 0.2870  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.2287  decode.d6.loss_cls: 0.2604  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.2529  decode.d7.loss_cls: 0.2861  decode.d7.loss_mask: 0.3424  decode.d7.loss_dice: 0.2301  decode.d8.loss_cls: 0.2462  decode.d8.loss_mask: 0.2925  decode.d8.loss_dice: 0.2338
09/30 15:57:19 - mmengine - INFO - Iter(train) [ 57100/320000]  base_lr: 8.3787e-05 lr: 8.3787e-06  eta: 1 day, 7:43:45  time: 0.4367  data_time: 0.0096  memory: 5145  grad_norm: 23.7685  loss: 4.8501  decode.loss_cls: 0.0078  decode.loss_mask: 0.2153  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.8753  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.1722  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.1752  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.1797  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.2163  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.2137  decode.d6.loss_dice: 0.1724  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2161  decode.d7.loss_dice: 0.1705  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.2172  decode.d8.loss_dice: 0.1760
09/30 15:57:41 - mmengine - INFO - Iter(train) [ 57150/320000]  base_lr: 8.3773e-05 lr: 8.3773e-06  eta: 1 day, 7:43:25  time: 0.4367  data_time: 0.0096  memory: 5129  grad_norm: 90.9030  loss: 5.9192  decode.loss_cls: 0.0763  decode.loss_mask: 0.2011  decode.loss_dice: 0.2050  decode.d0.loss_cls: 0.8167  decode.d0.loss_mask: 0.2014  decode.d0.loss_dice: 0.2347  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.2187  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.2004  decode.d2.loss_dice: 0.2289  decode.d3.loss_cls: 0.0944  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.2063  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.2089  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.0866  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.2075  decode.d6.loss_cls: 0.1473  decode.d6.loss_mask: 0.2032  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.1250  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.2041  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.2011  decode.d8.loss_dice: 0.2077
09/30 15:58:03 - mmengine - INFO - Iter(train) [ 57200/320000]  base_lr: 8.3759e-05 lr: 8.3759e-06  eta: 1 day, 7:43:04  time: 0.4381  data_time: 0.0097  memory: 5145  grad_norm: 31.6532  loss: 5.2186  decode.loss_cls: 0.0718  decode.loss_mask: 0.1964  decode.loss_dice: 0.1944  decode.d0.loss_cls: 0.7967  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.1786  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.1942  decode.d1.loss_dice: 0.1749  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.1761  decode.d3.loss_cls: 0.0975  decode.d3.loss_mask: 0.1976  decode.d3.loss_dice: 0.1762  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.1953  decode.d5.loss_dice: 0.1726  decode.d6.loss_cls: 0.0899  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.1746  decode.d7.loss_cls: 0.0657  decode.d7.loss_mask: 0.1950  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2706  decode.d8.loss_dice: 0.1889
09/30 15:58:25 - mmengine - INFO - Iter(train) [ 57250/320000]  base_lr: 8.3744e-05 lr: 8.3744e-06  eta: 1 day, 7:42:43  time: 0.4350  data_time: 0.0095  memory: 5145  grad_norm: 125.6256  loss: 5.5930  decode.loss_cls: 0.0155  decode.loss_mask: 0.2035  decode.loss_dice: 0.2372  decode.d0.loss_cls: 0.8546  decode.d0.loss_mask: 0.2116  decode.d0.loss_dice: 0.2161  decode.d1.loss_cls: 0.1610  decode.d1.loss_mask: 0.2077  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.0507  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.2146  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.2057  decode.d3.loss_dice: 0.2323  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.2080  decode.d4.loss_dice: 0.2298  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.2408  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.2056  decode.d8.loss_dice: 0.2329
09/30 15:58:47 - mmengine - INFO - Iter(train) [ 57300/320000]  base_lr: 8.3730e-05 lr: 8.3730e-06  eta: 1 day, 7:42:21  time: 0.4357  data_time: 0.0095  memory: 5129  grad_norm: 70.0712  loss: 6.4052  decode.loss_cls: 0.0957  decode.loss_mask: 0.2199  decode.loss_dice: 0.2302  decode.d0.loss_cls: 0.9142  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2557  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.2142  decode.d2.loss_cls: 0.1277  decode.d2.loss_mask: 0.2191  decode.d2.loss_dice: 0.2199  decode.d3.loss_cls: 0.1443  decode.d3.loss_mask: 0.2173  decode.d3.loss_dice: 0.2265  decode.d4.loss_cls: 0.1081  decode.d4.loss_mask: 0.2181  decode.d4.loss_dice: 0.2420  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.2310  decode.d6.loss_cls: 0.1147  decode.d6.loss_mask: 0.2159  decode.d6.loss_dice: 0.2270  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.2227  decode.d8.loss_cls: 0.1100  decode.d8.loss_mask: 0.2171  decode.d8.loss_dice: 0.2346
09/30 15:59:08 - mmengine - INFO - Iter(train) [ 57350/320000]  base_lr: 8.3716e-05 lr: 8.3716e-06  eta: 1 day, 7:41:59  time: 0.4348  data_time: 0.0094  memory: 5120  grad_norm: 52.7337  loss: 6.4352  decode.loss_cls: 0.0955  decode.loss_mask: 0.2475  decode.loss_dice: 0.1846  decode.d0.loss_cls: 0.9313  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.1909  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 0.2394  decode.d1.loss_dice: 0.1892  decode.d2.loss_cls: 0.1323  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.1501  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.1801  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.2410  decode.d4.loss_dice: 0.1825  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 0.2381  decode.d5.loss_dice: 0.1883  decode.d6.loss_cls: 0.1455  decode.d6.loss_mask: 0.2424  decode.d6.loss_dice: 0.1846  decode.d7.loss_cls: 0.1527  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.1892  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.2410  decode.d8.loss_dice: 0.1827
09/30 15:59:30 - mmengine - INFO - Iter(train) [ 57400/320000]  base_lr: 8.3701e-05 lr: 8.3701e-06  eta: 1 day, 7:41:38  time: 0.4354  data_time: 0.0095  memory: 5130  grad_norm: 130.3641  loss: 9.0408  decode.loss_cls: 0.1846  decode.loss_mask: 0.3586  decode.loss_dice: 0.2862  decode.d0.loss_cls: 0.9926  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.2494  decode.d1.loss_cls: 0.2526  decode.d1.loss_mask: 0.3022  decode.d1.loss_dice: 0.2692  decode.d2.loss_cls: 0.2965  decode.d2.loss_mask: 0.3261  decode.d2.loss_dice: 0.2799  decode.d3.loss_cls: 0.2370  decode.d3.loss_mask: 0.3327  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.2426  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.2768  decode.d5.loss_cls: 0.1806  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.2695  decode.d6.loss_cls: 0.2505  decode.d6.loss_mask: 0.3159  decode.d6.loss_dice: 0.2782  decode.d7.loss_cls: 0.1759  decode.d7.loss_mask: 0.3566  decode.d7.loss_dice: 0.2888  decode.d8.loss_cls: 0.2315  decode.d8.loss_mask: 0.3537  decode.d8.loss_dice: 0.2896
09/30 15:59:52 - mmengine - INFO - Iter(train) [ 57450/320000]  base_lr: 8.3687e-05 lr: 8.3687e-06  eta: 1 day, 7:41:16  time: 0.4347  data_time: 0.0095  memory: 5129  grad_norm: 43.7276  loss: 7.1262  decode.loss_cls: 0.1332  decode.loss_mask: 0.2543  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.9490  decode.d0.loss_mask: 0.2617  decode.d0.loss_dice: 0.2639  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.2553  decode.d1.loss_dice: 0.2382  decode.d2.loss_cls: 0.0800  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.2583  decode.d3.loss_cls: 0.1370  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.2502  decode.d4.loss_cls: 0.1180  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.1557  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.2476  decode.d6.loss_cls: 0.1119  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.2669  decode.d7.loss_cls: 0.1135  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.2811  decode.d8.loss_cls: 0.1269  decode.d8.loss_mask: 0.2554  decode.d8.loss_dice: 0.2459
09/30 16:00:14 - mmengine - INFO - Iter(train) [ 57500/320000]  base_lr: 8.3672e-05 lr: 8.3672e-06  eta: 1 day, 7:40:55  time: 0.4351  data_time: 0.0095  memory: 5145  grad_norm: 24.7530  loss: 5.6044  decode.loss_cls: 0.0052  decode.loss_mask: 0.2691  decode.loss_dice: 0.2004  decode.d0.loss_cls: 0.8180  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.1990  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.2691  decode.d1.loss_dice: 0.1975  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.2047  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.2017  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.2681  decode.d4.loss_dice: 0.2055  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.2677  decode.d5.loss_dice: 0.2053  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.1964  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.2711  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.2660  decode.d8.loss_dice: 0.2000
09/30 16:00:36 - mmengine - INFO - Iter(train) [ 57550/320000]  base_lr: 8.3658e-05 lr: 8.3658e-06  eta: 1 day, 7:40:34  time: 0.4378  data_time: 0.0096  memory: 5129  grad_norm: 51.8112  loss: 4.7129  decode.loss_cls: 0.0515  decode.loss_mask: 0.1821  decode.loss_dice: 0.1659  decode.d0.loss_cls: 0.7203  decode.d0.loss_mask: 0.1819  decode.d0.loss_dice: 0.1608  decode.d1.loss_cls: 0.0764  decode.d1.loss_mask: 0.1805  decode.d1.loss_dice: 0.1745  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.1822  decode.d2.loss_dice: 0.1618  decode.d3.loss_cls: 0.0825  decode.d3.loss_mask: 0.1830  decode.d3.loss_dice: 0.1572  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.1830  decode.d4.loss_dice: 0.1575  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.1859  decode.d5.loss_dice: 0.1579  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.1824  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.1628  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.1802  decode.d8.loss_dice: 0.1607
09/30 16:00:58 - mmengine - INFO - Iter(train) [ 57600/320000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 1 day, 7:40:13  time: 0.4371  data_time: 0.0097  memory: 5129  grad_norm: 282.8937  loss: 8.5274  decode.loss_cls: 0.3431  decode.loss_mask: 0.2559  decode.loss_dice: 0.1920  decode.d0.loss_cls: 1.0782  decode.d0.loss_mask: 0.2585  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.2288  decode.d1.loss_mask: 0.2724  decode.d1.loss_dice: 0.2037  decode.d2.loss_cls: 0.2829  decode.d2.loss_mask: 0.2541  decode.d2.loss_dice: 0.1936  decode.d3.loss_cls: 0.2918  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.1956  decode.d4.loss_cls: 0.2322  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.2074  decode.d5.loss_cls: 0.2961  decode.d5.loss_mask: 0.3298  decode.d5.loss_dice: 0.2108  decode.d6.loss_cls: 0.3214  decode.d6.loss_mask: 0.2638  decode.d6.loss_dice: 0.2003  decode.d7.loss_cls: 0.2800  decode.d7.loss_mask: 0.3318  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.2850  decode.d8.loss_mask: 0.3291  decode.d8.loss_dice: 0.2088
09/30 16:01:19 - mmengine - INFO - Iter(train) [ 57650/320000]  base_lr: 8.3629e-05 lr: 8.3629e-06  eta: 1 day, 7:39:52  time: 0.4380  data_time: 0.0099  memory: 5129  grad_norm: 54.7907  loss: 7.5501  decode.loss_cls: 0.0511  decode.loss_mask: 0.3139  decode.loss_dice: 0.3021  decode.d0.loss_cls: 0.8161  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.2856  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.3136  decode.d1.loss_dice: 0.3016  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.3145  decode.d2.loss_dice: 0.2937  decode.d3.loss_cls: 0.0832  decode.d3.loss_mask: 0.3132  decode.d3.loss_dice: 0.2835  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.3176  decode.d4.loss_dice: 0.2879  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.3211  decode.d5.loss_dice: 0.2951  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.3176  decode.d6.loss_dice: 0.2969  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.3121  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.3008
09/30 16:01:41 - mmengine - INFO - Iter(train) [ 57700/320000]  base_lr: 8.3615e-05 lr: 8.3615e-06  eta: 1 day, 7:39:31  time: 0.4387  data_time: 0.0096  memory: 5129  grad_norm: 77.9686  loss: 5.2361  decode.loss_cls: 0.0421  decode.loss_mask: 0.1859  decode.loss_dice: 0.2125  decode.d0.loss_cls: 0.8839  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.2113  decode.d1.loss_cls: 0.0296  decode.d1.loss_mask: 0.1852  decode.d1.loss_dice: 0.1953  decode.d2.loss_cls: 0.0871  decode.d2.loss_mask: 0.1850  decode.d2.loss_dice: 0.1894  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.1852  decode.d3.loss_dice: 0.1923  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.1836  decode.d4.loss_dice: 0.1983  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.2017  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.2027  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 0.1843  decode.d7.loss_dice: 0.2087  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.1854  decode.d8.loss_dice: 0.1964
09/30 16:02:03 - mmengine - INFO - Iter(train) [ 57750/320000]  base_lr: 8.3601e-05 lr: 8.3601e-06  eta: 1 day, 7:39:10  time: 0.4388  data_time: 0.0097  memory: 5145  grad_norm: 64.3428  loss: 6.7774  decode.loss_cls: 0.0216  decode.loss_mask: 0.3339  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.7728  decode.d0.loss_mask: 0.3370  decode.d0.loss_dice: 0.2296  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.3347  decode.d1.loss_dice: 0.2317  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.3290  decode.d2.loss_dice: 0.2243  decode.d3.loss_cls: 0.0504  decode.d3.loss_mask: 0.3283  decode.d3.loss_dice: 0.2255  decode.d4.loss_cls: 0.0471  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.2343  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.3281  decode.d5.loss_dice: 0.2324  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.3326  decode.d6.loss_dice: 0.2333  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.3290  decode.d7.loss_dice: 0.2285  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.3305  decode.d8.loss_dice: 0.2291
09/30 16:02:25 - mmengine - INFO - Iter(train) [ 57800/320000]  base_lr: 8.3586e-05 lr: 8.3586e-06  eta: 1 day, 7:38:49  time: 0.4386  data_time: 0.0095  memory: 5129  grad_norm: 71.7811  loss: 7.7023  decode.loss_cls: 0.2525  decode.loss_mask: 0.2544  decode.loss_dice: 0.2304  decode.d0.loss_cls: 0.8699  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.2400  decode.d1.loss_cls: 0.1364  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.2376  decode.d2.loss_cls: 0.1899  decode.d2.loss_mask: 0.2556  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.2048  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.2334  decode.d4.loss_cls: 0.1978  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.2386  decode.d5.loss_mask: 0.2521  decode.d5.loss_dice: 0.2298  decode.d6.loss_cls: 0.2511  decode.d6.loss_mask: 0.2560  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 0.2605  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.2441  decode.d8.loss_mask: 0.2537  decode.d8.loss_dice: 0.2289
09/30 16:02:47 - mmengine - INFO - Iter(train) [ 57850/320000]  base_lr: 8.3572e-05 lr: 8.3572e-06  eta: 1 day, 7:38:29  time: 0.4389  data_time: 0.0098  memory: 5129  grad_norm: 40.3541  loss: 5.5431  decode.loss_cls: 0.0927  decode.loss_mask: 0.2046  decode.loss_dice: 0.1800  decode.d0.loss_cls: 0.8914  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.1776  decode.d1.loss_cls: 0.1097  decode.d1.loss_mask: 0.2087  decode.d1.loss_dice: 0.1845  decode.d2.loss_cls: 0.0690  decode.d2.loss_mask: 0.2051  decode.d2.loss_dice: 0.2049  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.2061  decode.d3.loss_dice: 0.1995  decode.d4.loss_cls: 0.1038  decode.d4.loss_mask: 0.2088  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.1150  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.1847  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.1845  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.1965  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1808
09/30 16:03:09 - mmengine - INFO - Iter(train) [ 57900/320000]  base_lr: 8.3558e-05 lr: 8.3558e-06  eta: 1 day, 7:38:08  time: 0.4381  data_time: 0.0095  memory: 5129  grad_norm: 30.1512  loss: 5.7792  decode.loss_cls: 0.0728  decode.loss_mask: 0.2120  decode.loss_dice: 0.2246  decode.d0.loss_cls: 0.8349  decode.d0.loss_mask: 0.2122  decode.d0.loss_dice: 0.2169  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.2103  decode.d1.loss_dice: 0.2145  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.2109  decode.d2.loss_dice: 0.2176  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.2211  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2143  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.2107  decode.d5.loss_dice: 0.2047  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.2130  decode.d6.loss_dice: 0.2019  decode.d7.loss_cls: 0.0727  decode.d7.loss_mask: 0.2108  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.2217
09/30 16:03:31 - mmengine - INFO - Iter(train) [ 57950/320000]  base_lr: 8.3543e-05 lr: 8.3543e-06  eta: 1 day, 7:37:46  time: 0.4361  data_time: 0.0095  memory: 5120  grad_norm: 46.4424  loss: 5.5382  decode.loss_cls: 0.0828  decode.loss_mask: 0.2354  decode.loss_dice: 0.1713  decode.d0.loss_cls: 0.8768  decode.d0.loss_mask: 0.2310  decode.d0.loss_dice: 0.1628  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.2328  decode.d1.loss_dice: 0.1700  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.2322  decode.d2.loss_dice: 0.1672  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.2316  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.1692  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.2345  decode.d5.loss_dice: 0.1678  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.2328  decode.d6.loss_dice: 0.1661  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.1723  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.2323  decode.d8.loss_dice: 0.1703
09/30 16:03:53 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:03:53 - mmengine - INFO - Iter(train) [ 58000/320000]  base_lr: 8.3529e-05 lr: 8.3529e-06  eta: 1 day, 7:37:25  time: 0.4354  data_time: 0.0094  memory: 5129  grad_norm: 53.2606  loss: 5.2320  decode.loss_cls: 0.1285  decode.loss_mask: 0.1877  decode.loss_dice: 0.1818  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.1874  decode.d0.loss_dice: 0.1717  decode.d1.loss_cls: 0.1325  decode.d1.loss_mask: 0.1942  decode.d1.loss_dice: 0.1782  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.1916  decode.d3.loss_dice: 0.1811  decode.d4.loss_cls: 0.0952  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.1694  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.1894  decode.d5.loss_dice: 0.1917  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.1747  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.1909  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.0281  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.1794
09/30 16:04:14 - mmengine - INFO - Iter(train) [ 58050/320000]  base_lr: 8.3515e-05 lr: 8.3515e-06  eta: 1 day, 7:37:04  time: 0.4353  data_time: 0.0094  memory: 5120  grad_norm: 174.2112  loss: 7.4712  decode.loss_cls: 0.0966  decode.loss_mask: 0.3063  decode.loss_dice: 0.2375  decode.d0.loss_cls: 0.9369  decode.d0.loss_mask: 0.2918  decode.d0.loss_dice: 0.2264  decode.d1.loss_cls: 0.1102  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.2390  decode.d2.loss_cls: 0.1916  decode.d2.loss_mask: 0.2951  decode.d2.loss_dice: 0.2254  decode.d3.loss_cls: 0.1092  decode.d3.loss_mask: 0.3163  decode.d3.loss_dice: 0.2789  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.3135  decode.d4.loss_dice: 0.2685  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 0.3198  decode.d5.loss_dice: 0.2645  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.3098  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.3306  decode.d8.loss_dice: 0.2672
09/30 16:04:36 - mmengine - INFO - Iter(train) [ 58100/320000]  base_lr: 8.3500e-05 lr: 8.3500e-06  eta: 1 day, 7:36:42  time: 0.4350  data_time: 0.0094  memory: 5129  grad_norm: 106.2346  loss: 7.9881  decode.loss_cls: 0.1107  decode.loss_mask: 0.4589  decode.loss_dice: 0.1978  decode.d0.loss_cls: 0.9665  decode.d0.loss_mask: 0.3150  decode.d0.loss_dice: 0.1912  decode.d1.loss_cls: 0.1806  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.1910  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.3097  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.1783  decode.d3.loss_mask: 0.3252  decode.d3.loss_dice: 0.2060  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 0.4648  decode.d4.loss_dice: 0.1975  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.4677  decode.d5.loss_dice: 0.1953  decode.d6.loss_cls: 0.1599  decode.d6.loss_mask: 0.3207  decode.d6.loss_dice: 0.2289  decode.d7.loss_cls: 0.1994  decode.d7.loss_mask: 0.3033  decode.d7.loss_dice: 0.1781  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 0.3190  decode.d8.loss_dice: 0.2206
09/30 16:04:58 - mmengine - INFO - Iter(train) [ 58150/320000]  base_lr: 8.3486e-05 lr: 8.3486e-06  eta: 1 day, 7:36:20  time: 0.4359  data_time: 0.0095  memory: 5145  grad_norm: 85.1052  loss: 6.2247  decode.loss_cls: 0.0731  decode.loss_mask: 0.2371  decode.loss_dice: 0.1930  decode.d0.loss_cls: 1.0221  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.1976  decode.d1.loss_cls: 0.1242  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.1893  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.2021  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2081  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.2099  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.2375  decode.d6.loss_dice: 0.2080  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.2381  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.0815  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.1928
09/30 16:05:20 - mmengine - INFO - Iter(train) [ 58200/320000]  base_lr: 8.3472e-05 lr: 8.3472e-06  eta: 1 day, 7:35:59  time: 0.4356  data_time: 0.0096  memory: 5120  grad_norm: 51.4217  loss: 6.5705  decode.loss_cls: 0.1234  decode.loss_mask: 0.2485  decode.loss_dice: 0.2232  decode.d0.loss_cls: 0.7548  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.2370  decode.d1.loss_cls: 0.2047  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.2148  decode.d2.loss_cls: 0.0884  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2403  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2203  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.2523  decode.d4.loss_dice: 0.2232  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2264  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 0.2493  decode.d6.loss_dice: 0.2241  decode.d7.loss_cls: 0.1374  decode.d7.loss_mask: 0.2487  decode.d7.loss_dice: 0.2155  decode.d8.loss_cls: 0.1170  decode.d8.loss_mask: 0.2506  decode.d8.loss_dice: 0.2232
09/30 16:05:42 - mmengine - INFO - Iter(train) [ 58250/320000]  base_lr: 8.3457e-05 lr: 8.3457e-06  eta: 1 day, 7:35:38  time: 0.4393  data_time: 0.0097  memory: 5129  grad_norm: 49.7569  loss: 5.5592  decode.loss_cls: 0.0508  decode.loss_mask: 0.2395  decode.loss_dice: 0.1773  decode.d0.loss_cls: 0.8516  decode.d0.loss_mask: 0.2354  decode.d0.loss_dice: 0.1818  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.1793  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.2322  decode.d2.loss_dice: 0.1779  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.0629  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.1828  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.1762  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.2382  decode.d7.loss_dice: 0.1803  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.1806
09/30 16:06:04 - mmengine - INFO - Iter(train) [ 58300/320000]  base_lr: 8.3443e-05 lr: 8.3443e-06  eta: 1 day, 7:35:17  time: 0.4374  data_time: 0.0097  memory: 5129  grad_norm: 93.1016  loss: 6.6486  decode.loss_cls: 0.1279  decode.loss_mask: 0.2139  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.8546  decode.d0.loss_mask: 0.2135  decode.d0.loss_dice: 0.2231  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.2225  decode.d2.loss_cls: 0.2526  decode.d2.loss_mask: 0.2255  decode.d2.loss_dice: 0.2286  decode.d3.loss_cls: 0.2216  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.1983  decode.d4.loss_cls: 0.1665  decode.d4.loss_mask: 0.2110  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.1416  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.2203  decode.d6.loss_cls: 0.1400  decode.d6.loss_mask: 0.2093  decode.d6.loss_dice: 0.1995  decode.d7.loss_cls: 0.1651  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.1743  decode.d8.loss_mask: 0.2096  decode.d8.loss_dice: 0.2063
09/30 16:06:26 - mmengine - INFO - Iter(train) [ 58350/320000]  base_lr: 8.3429e-05 lr: 8.3429e-06  eta: 1 day, 7:34:56  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 42.7254  loss: 7.1249  decode.loss_cls: 0.1287  decode.loss_mask: 0.2615  decode.loss_dice: 0.2040  decode.d0.loss_cls: 0.8043  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.2170  decode.d1.loss_cls: 0.3140  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.2337  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.2052  decode.d3.loss_mask: 0.2604  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.2122  decode.d5.loss_cls: 0.1328  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2162  decode.d6.loss_cls: 0.1375  decode.d6.loss_mask: 0.2613  decode.d6.loss_dice: 0.2151  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 0.2607  decode.d7.loss_dice: 0.2152  decode.d8.loss_cls: 0.1183  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.1978
09/30 16:06:47 - mmengine - INFO - Iter(train) [ 58400/320000]  base_lr: 8.3414e-05 lr: 8.3414e-06  eta: 1 day, 7:34:35  time: 0.4389  data_time: 0.0097  memory: 5129  grad_norm: 28.7119  loss: 5.6624  decode.loss_cls: 0.0151  decode.loss_mask: 0.2388  decode.loss_dice: 0.1995  decode.d0.loss_cls: 0.8042  decode.d0.loss_mask: 0.2460  decode.d0.loss_dice: 0.2002  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.1909  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.2430  decode.d2.loss_dice: 0.2074  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.1966  decode.d4.loss_cls: 0.0888  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.1919  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.2422  decode.d6.loss_dice: 0.2054  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.2046  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.1954
09/30 16:07:09 - mmengine - INFO - Iter(train) [ 58450/320000]  base_lr: 8.3400e-05 lr: 8.3400e-06  eta: 1 day, 7:34:14  time: 0.4393  data_time: 0.0098  memory: 5129  grad_norm: 36.3563  loss: 6.5089  decode.loss_cls: 0.0679  decode.loss_mask: 0.2306  decode.loss_dice: 0.2611  decode.d0.loss_cls: 0.8104  decode.d0.loss_mask: 0.2312  decode.d0.loss_dice: 0.2621  decode.d1.loss_cls: 0.1350  decode.d1.loss_mask: 0.2348  decode.d1.loss_dice: 0.2497  decode.d2.loss_cls: 0.1155  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.2393  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.2434  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.0993  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.2532  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.2445  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.2651  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.2344  decode.d8.loss_dice: 0.2452
09/30 16:07:31 - mmengine - INFO - Iter(train) [ 58500/320000]  base_lr: 8.3386e-05 lr: 8.3386e-06  eta: 1 day, 7:33:53  time: 0.4368  data_time: 0.0099  memory: 5129  grad_norm: 40.9035  loss: 6.8981  decode.loss_cls: 0.0929  decode.loss_mask: 0.2844  decode.loss_dice: 0.2231  decode.d0.loss_cls: 0.9291  decode.d0.loss_mask: 0.2454  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.2879  decode.d1.loss_dice: 0.2217  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 0.2888  decode.d2.loss_dice: 0.2318  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.2220  decode.d4.loss_cls: 0.1202  decode.d4.loss_mask: 0.2881  decode.d4.loss_dice: 0.2224  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.2901  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.1055  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.2226  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.2912  decode.d7.loss_dice: 0.2299  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.2245
09/30 16:07:53 - mmengine - INFO - Iter(train) [ 58550/320000]  base_lr: 8.3371e-05 lr: 8.3371e-06  eta: 1 day, 7:33:32  time: 0.4369  data_time: 0.0099  memory: 5145  grad_norm: 63.2803  loss: 7.4236  decode.loss_cls: 0.1949  decode.loss_mask: 0.2318  decode.loss_dice: 0.2305  decode.d0.loss_cls: 0.9662  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.2500  decode.d1.loss_cls: 0.1644  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.2133  decode.d2.loss_cls: 0.1684  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.2449  decode.d3.loss_cls: 0.0981  decode.d3.loss_mask: 0.3081  decode.d3.loss_dice: 0.2591  decode.d4.loss_cls: 0.1212  decode.d4.loss_mask: 0.3441  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.3305  decode.d5.loss_dice: 0.2312  decode.d6.loss_cls: 0.1337  decode.d6.loss_mask: 0.3109  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.1208  decode.d7.loss_mask: 0.3238  decode.d7.loss_dice: 0.2394  decode.d8.loss_cls: 0.0868  decode.d8.loss_mask: 0.3284  decode.d8.loss_dice: 0.2372
09/30 16:08:15 - mmengine - INFO - Iter(train) [ 58600/320000]  base_lr: 8.3357e-05 lr: 8.3357e-06  eta: 1 day, 7:33:11  time: 0.4364  data_time: 0.0095  memory: 5129  grad_norm: 42.9348  loss: 5.8081  decode.loss_cls: 0.0214  decode.loss_mask: 0.2171  decode.loss_dice: 0.2132  decode.d0.loss_cls: 1.0302  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1817  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2064  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.2077  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.2147  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.2095  decode.d4.loss_dice: 0.1970  decode.d5.loss_cls: 0.1367  decode.d5.loss_mask: 0.2073  decode.d5.loss_dice: 0.1935  decode.d6.loss_cls: 0.1105  decode.d6.loss_mask: 0.2030  decode.d6.loss_dice: 0.1754  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.2077  decode.d7.loss_dice: 0.1725  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.2050  decode.d8.loss_dice: 0.1947
09/30 16:08:37 - mmengine - INFO - Iter(train) [ 58650/320000]  base_lr: 8.3342e-05 lr: 8.3342e-06  eta: 1 day, 7:32:50  time: 0.4373  data_time: 0.0098  memory: 5119  grad_norm: 43.6359  loss: 6.6772  decode.loss_cls: 0.1446  decode.loss_mask: 0.2346  decode.loss_dice: 0.2223  decode.d0.loss_cls: 0.7882  decode.d0.loss_mask: 0.2361  decode.d0.loss_dice: 0.2178  decode.d1.loss_cls: 0.1496  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.1770  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.2065  decode.d3.loss_cls: 0.1623  decode.d3.loss_mask: 0.2316  decode.d3.loss_dice: 0.2126  decode.d4.loss_cls: 0.1418  decode.d4.loss_mask: 0.2325  decode.d4.loss_dice: 0.2142  decode.d5.loss_cls: 0.1606  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.2189  decode.d6.loss_cls: 0.1464  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.2197  decode.d7.loss_cls: 0.1468  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2168  decode.d8.loss_cls: 0.1721  decode.d8.loss_mask: 0.2334  decode.d8.loss_dice: 0.2063
09/30 16:08:59 - mmengine - INFO - Iter(train) [ 58700/320000]  base_lr: 8.3328e-05 lr: 8.3328e-06  eta: 1 day, 7:32:29  time: 0.4370  data_time: 0.0096  memory: 5129  grad_norm: 27.1328  loss: 4.4591  decode.loss_cls: 0.0178  decode.loss_mask: 0.1686  decode.loss_dice: 0.1603  decode.d0.loss_cls: 0.9419  decode.d0.loss_mask: 0.1732  decode.d0.loss_dice: 0.1733  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.1663  decode.d1.loss_dice: 0.1611  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.1690  decode.d2.loss_dice: 0.1678  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.1688  decode.d3.loss_dice: 0.1604  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.1669  decode.d4.loss_dice: 0.1691  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.1700  decode.d5.loss_dice: 0.1634  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.1699  decode.d6.loss_dice: 0.1664  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.1695  decode.d7.loss_dice: 0.1620  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.1689  decode.d8.loss_dice: 0.1662
09/30 16:09:21 - mmengine - INFO - Iter(train) [ 58750/320000]  base_lr: 8.3314e-05 lr: 8.3314e-06  eta: 1 day, 7:32:07  time: 0.4369  data_time: 0.0097  memory: 5129  grad_norm: 42.8067  loss: 6.6402  decode.loss_cls: 0.1297  decode.loss_mask: 0.2186  decode.loss_dice: 0.2451  decode.d0.loss_cls: 0.7953  decode.d0.loss_mask: 0.2238  decode.d0.loss_dice: 0.2519  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.2303  decode.d2.loss_cls: 0.1300  decode.d2.loss_mask: 0.2222  decode.d2.loss_dice: 0.2231  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 0.2187  decode.d3.loss_dice: 0.2526  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.2193  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.1228  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.2485  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.2626  decode.d7.loss_cls: 0.1276  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.2188  decode.d8.loss_dice: 0.2474
09/30 16:09:43 - mmengine - INFO - Iter(train) [ 58800/320000]  base_lr: 8.3299e-05 lr: 8.3299e-06  eta: 1 day, 7:31:47  time: 0.4357  data_time: 0.0096  memory: 5129  grad_norm: 35.5854  loss: 5.6814  decode.loss_cls: 0.0644  decode.loss_mask: 0.2346  decode.loss_dice: 0.1871  decode.d0.loss_cls: 0.7806  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.2378  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.2077  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.2026  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.2339  decode.d5.loss_dice: 0.1895  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.2128  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.1950
09/30 16:10:04 - mmengine - INFO - Iter(train) [ 58850/320000]  base_lr: 8.3285e-05 lr: 8.3285e-06  eta: 1 day, 7:31:25  time: 0.4350  data_time: 0.0093  memory: 5129  grad_norm: 36.0780  loss: 5.8966  decode.loss_cls: 0.1411  decode.loss_mask: 0.2185  decode.loss_dice: 0.1783  decode.d0.loss_cls: 0.8262  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.1708  decode.d1.loss_cls: 0.1279  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.1542  decode.d2.loss_mask: 0.2168  decode.d2.loss_dice: 0.1683  decode.d3.loss_cls: 0.1020  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.1687  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.1637  decode.d5.loss_cls: 0.1568  decode.d5.loss_mask: 0.2172  decode.d5.loss_dice: 0.1699  decode.d6.loss_cls: 0.1382  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.1662  decode.d7.loss_cls: 0.1353  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.1667  decode.d8.loss_cls: 0.1191  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.1688
09/30 16:10:26 - mmengine - INFO - Iter(train) [ 58900/320000]  base_lr: 8.3271e-05 lr: 8.3271e-06  eta: 1 day, 7:31:04  time: 0.4355  data_time: 0.0095  memory: 5145  grad_norm: 28.9014  loss: 4.9998  decode.loss_cls: 0.0662  decode.loss_mask: 0.1938  decode.loss_dice: 0.1565  decode.d0.loss_cls: 0.9771  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.1590  decode.d1.loss_cls: 0.0338  decode.d1.loss_mask: 0.1975  decode.d1.loss_dice: 0.1641  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.1958  decode.d2.loss_dice: 0.1586  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.1557  decode.d4.loss_cls: 0.0629  decode.d4.loss_mask: 0.2005  decode.d4.loss_dice: 0.1590  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.1973  decode.d5.loss_dice: 0.1598  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.1976  decode.d6.loss_dice: 0.1581  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.1965  decode.d7.loss_dice: 0.1575  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.1952  decode.d8.loss_dice: 0.1554
09/30 16:10:48 - mmengine - INFO - Iter(train) [ 58950/320000]  base_lr: 8.3256e-05 lr: 8.3256e-06  eta: 1 day, 7:30:43  time: 0.4370  data_time: 0.0096  memory: 5129  grad_norm: 43.7364  loss: 6.3439  decode.loss_cls: 0.0811  decode.loss_mask: 0.2586  decode.loss_dice: 0.2205  decode.d0.loss_cls: 0.8988  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.2226  decode.d1.loss_cls: 0.1625  decode.d1.loss_mask: 0.2555  decode.d1.loss_dice: 0.2168  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2184  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2109  decode.d4.loss_cls: 0.0782  decode.d4.loss_mask: 0.2529  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.2533  decode.d5.loss_dice: 0.2122  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.2537  decode.d7.loss_dice: 0.2199  decode.d8.loss_cls: 0.0860  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2145
09/30 16:11:10 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:11:10 - mmengine - INFO - Iter(train) [ 59000/320000]  base_lr: 8.3242e-05 lr: 8.3242e-06  eta: 1 day, 7:30:21  time: 0.4359  data_time: 0.0093  memory: 5129  grad_norm: 251.9444  loss: 6.2925  decode.loss_cls: 0.0709  decode.loss_mask: 0.2502  decode.loss_dice: 0.1919  decode.d0.loss_cls: 0.9759  decode.d0.loss_mask: 0.2651  decode.d0.loss_dice: 0.1985  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.2001  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.3361  decode.d2.loss_dice: 0.2181  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.2681  decode.d3.loss_dice: 0.1991  decode.d4.loss_cls: 0.0751  decode.d4.loss_mask: 0.2816  decode.d4.loss_dice: 0.2002  decode.d5.loss_cls: 0.1511  decode.d5.loss_mask: 0.2513  decode.d5.loss_dice: 0.1932  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.2781  decode.d6.loss_dice: 0.2066  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.2776  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.2820  decode.d8.loss_dice: 0.2083
09/30 16:11:32 - mmengine - INFO - Iter(train) [ 59050/320000]  base_lr: 8.3228e-05 lr: 8.3228e-06  eta: 1 day, 7:30:00  time: 0.4355  data_time: 0.0094  memory: 5129  grad_norm: 18.5520  loss: 4.6305  decode.loss_cls: 0.0075  decode.loss_mask: 0.1912  decode.loss_dice: 0.1644  decode.d0.loss_cls: 0.9073  decode.d0.loss_mask: 0.1953  decode.d0.loss_dice: 0.1667  decode.d1.loss_cls: 0.0786  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.1622  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.1610  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.1937  decode.d3.loss_dice: 0.1642  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.1688  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.1897  decode.d5.loss_dice: 0.1682  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.1629  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.1660  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.1903  decode.d8.loss_dice: 0.1687
09/30 16:11:53 - mmengine - INFO - Iter(train) [ 59100/320000]  base_lr: 8.3213e-05 lr: 8.3213e-06  eta: 1 day, 7:29:38  time: 0.4365  data_time: 0.0097  memory: 5129  grad_norm: 51.7214  loss: 4.7460  decode.loss_cls: 0.0332  decode.loss_mask: 0.2054  decode.loss_dice: 0.1443  decode.d0.loss_cls: 0.8433  decode.d0.loss_mask: 0.2049  decode.d0.loss_dice: 0.1425  decode.d1.loss_cls: 0.0836  decode.d1.loss_mask: 0.2078  decode.d1.loss_dice: 0.1412  decode.d2.loss_cls: 0.0551  decode.d2.loss_mask: 0.2052  decode.d2.loss_dice: 0.1415  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1438  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.1416  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.2038  decode.d5.loss_dice: 0.1457  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.2036  decode.d6.loss_dice: 0.1472  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.2009  decode.d7.loss_dice: 0.1429  decode.d8.loss_cls: 0.0273  decode.d8.loss_mask: 0.2061  decode.d8.loss_dice: 0.1441
09/30 16:12:15 - mmengine - INFO - Iter(train) [ 59150/320000]  base_lr: 8.3199e-05 lr: 8.3199e-06  eta: 1 day, 7:29:17  time: 0.4364  data_time: 0.0095  memory: 5129  grad_norm: 87.2332  loss: 7.5227  decode.loss_cls: 0.1621  decode.loss_mask: 0.2794  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.9493  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.2225  decode.d1.loss_cls: 0.1700  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.2088  decode.d2.loss_cls: 0.1180  decode.d2.loss_mask: 0.2745  decode.d2.loss_dice: 0.2493  decode.d3.loss_cls: 0.1662  decode.d3.loss_mask: 0.2695  decode.d3.loss_dice: 0.2205  decode.d4.loss_cls: 0.1691  decode.d4.loss_mask: 0.2666  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.1965  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2410  decode.d6.loss_cls: 0.2072  decode.d6.loss_mask: 0.2911  decode.d6.loss_dice: 0.2486  decode.d7.loss_cls: 0.1908  decode.d7.loss_mask: 0.2672  decode.d7.loss_dice: 0.2219  decode.d8.loss_cls: 0.1718  decode.d8.loss_mask: 0.2665  decode.d8.loss_dice: 0.2181
09/30 16:12:37 - mmengine - INFO - Iter(train) [ 59200/320000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 1 day, 7:28:56  time: 0.4354  data_time: 0.0095  memory: 5145  grad_norm: 26.9788  loss: 5.3121  decode.loss_cls: 0.0593  decode.loss_mask: 0.2058  decode.loss_dice: 0.1841  decode.d0.loss_cls: 0.9059  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.1850  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.1814  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.1853  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.2039  decode.d6.loss_dice: 0.1791  decode.d7.loss_cls: 0.0560  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.1763  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.2026  decode.d8.loss_dice: 0.1824
09/30 16:12:59 - mmengine - INFO - Iter(train) [ 59250/320000]  base_lr: 8.3170e-05 lr: 8.3170e-06  eta: 1 day, 7:28:34  time: 0.4367  data_time: 0.0098  memory: 5104  grad_norm: 212.9516  loss: 7.5667  decode.loss_cls: 0.1632  decode.loss_mask: 0.2371  decode.loss_dice: 0.2937  decode.d0.loss_cls: 0.8537  decode.d0.loss_mask: 0.2360  decode.d0.loss_dice: 0.3185  decode.d1.loss_cls: 0.1721  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.3121  decode.d2.loss_cls: 0.1239  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.3154  decode.d4.loss_cls: 0.1764  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.1206  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.3180  decode.d6.loss_cls: 0.1835  decode.d6.loss_mask: 0.2320  decode.d6.loss_dice: 0.2933  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.3111  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 0.2419  decode.d8.loss_dice: 0.3106
09/30 16:13:21 - mmengine - INFO - Iter(train) [ 59300/320000]  base_lr: 8.3156e-05 lr: 8.3156e-06  eta: 1 day, 7:28:13  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 40.3699  loss: 7.9555  decode.loss_cls: 0.1973  decode.loss_mask: 0.2722  decode.loss_dice: 0.2435  decode.d0.loss_cls: 1.1319  decode.d0.loss_mask: 0.2426  decode.d0.loss_dice: 0.2292  decode.d1.loss_cls: 0.2436  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2155  decode.d2.loss_cls: 0.2562  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.1605  decode.d3.loss_mask: 0.2719  decode.d3.loss_dice: 0.2458  decode.d4.loss_cls: 0.1684  decode.d4.loss_mask: 0.3173  decode.d4.loss_dice: 0.2474  decode.d5.loss_cls: 0.1720  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.2343  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.2770  decode.d6.loss_dice: 0.2299  decode.d7.loss_cls: 0.1922  decode.d7.loss_mask: 0.2708  decode.d7.loss_dice: 0.2215  decode.d8.loss_cls: 0.2032  decode.d8.loss_mask: 0.2805  decode.d8.loss_dice: 0.2359
09/30 16:13:43 - mmengine - INFO - Iter(train) [ 59350/320000]  base_lr: 8.3142e-05 lr: 8.3142e-06  eta: 1 day, 7:27:52  time: 0.4356  data_time: 0.0096  memory: 5120  grad_norm: 41.4388  loss: 5.9452  decode.loss_cls: 0.0299  decode.loss_mask: 0.2336  decode.loss_dice: 0.2285  decode.d0.loss_cls: 0.8344  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.2269  decode.d1.loss_cls: 0.1425  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.2407  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.2428  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.2348  decode.d3.loss_dice: 0.2074  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2411  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.2439  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2423  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.2055  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2274
09/30 16:14:04 - mmengine - INFO - Iter(train) [ 59400/320000]  base_lr: 8.3127e-05 lr: 8.3127e-06  eta: 1 day, 7:27:30  time: 0.4362  data_time: 0.0096  memory: 5129  grad_norm: 89.8933  loss: 6.7547  decode.loss_cls: 0.0217  decode.loss_mask: 0.3299  decode.loss_dice: 0.2252  decode.d0.loss_cls: 0.8299  decode.d0.loss_mask: 0.3344  decode.d0.loss_dice: 0.2474  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.3344  decode.d1.loss_dice: 0.2305  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.3309  decode.d2.loss_dice: 0.2319  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.3293  decode.d3.loss_dice: 0.2281  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.3302  decode.d4.loss_dice: 0.2347  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.3296  decode.d5.loss_dice: 0.2314  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.3309  decode.d6.loss_dice: 0.2303  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.3281  decode.d7.loss_dice: 0.2288  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.3274  decode.d8.loss_dice: 0.2309
09/30 16:14:26 - mmengine - INFO - Iter(train) [ 59450/320000]  base_lr: 8.3113e-05 lr: 8.3113e-06  eta: 1 day, 7:27:09  time: 0.4370  data_time: 0.0099  memory: 5145  grad_norm: 25.4416  loss: 4.8371  decode.loss_cls: 0.0232  decode.loss_mask: 0.2160  decode.loss_dice: 0.1706  decode.d0.loss_cls: 0.7254  decode.d0.loss_mask: 0.2203  decode.d0.loss_dice: 0.1756  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.2151  decode.d1.loss_dice: 0.1776  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1713  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.2135  decode.d3.loss_dice: 0.1731  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1713  decode.d5.loss_cls: 0.0247  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.1744  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.2158  decode.d6.loss_dice: 0.1762  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.2162  decode.d7.loss_dice: 0.1720  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.2143  decode.d8.loss_dice: 0.1726
09/30 16:14:48 - mmengine - INFO - Iter(train) [ 59500/320000]  base_lr: 8.3099e-05 lr: 8.3099e-06  eta: 1 day, 7:26:48  time: 0.4362  data_time: 0.0097  memory: 5120  grad_norm: 31.9573  loss: 4.5068  decode.loss_cls: 0.0244  decode.loss_mask: 0.2004  decode.loss_dice: 0.1473  decode.d0.loss_cls: 0.8530  decode.d0.loss_mask: 0.2085  decode.d0.loss_dice: 0.1505  decode.d1.loss_cls: 0.0395  decode.d1.loss_mask: 0.1979  decode.d1.loss_dice: 0.1437  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1490  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.2033  decode.d3.loss_dice: 0.1505  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.1507  decode.d5.loss_cls: 0.0121  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.1478  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.1982  decode.d6.loss_dice: 0.1462  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.1476  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.2002  decode.d8.loss_dice: 0.1483
09/30 16:15:10 - mmengine - INFO - Iter(train) [ 59550/320000]  base_lr: 8.3084e-05 lr: 8.3084e-06  eta: 1 day, 7:26:27  time: 0.4362  data_time: 0.0097  memory: 5145  grad_norm: 162.6894  loss: 13.6998  decode.loss_cls: 0.5286  decode.loss_mask: 0.3371  decode.loss_dice: 0.3663  decode.d0.loss_cls: 1.2060  decode.d0.loss_mask: 0.3226  decode.d0.loss_dice: 0.3917  decode.d1.loss_cls: 0.4375  decode.d1.loss_mask: 0.3191  decode.d1.loss_dice: 0.3658  decode.d2.loss_cls: 0.3947  decode.d2.loss_mask: 0.3591  decode.d2.loss_dice: 0.4077  decode.d3.loss_cls: 0.3523  decode.d3.loss_mask: 0.7400  decode.d3.loss_dice: 0.4202  decode.d4.loss_cls: 0.2622  decode.d4.loss_mask: 0.6458  decode.d4.loss_dice: 0.4363  decode.d5.loss_cls: 0.3429  decode.d5.loss_mask: 0.6396  decode.d5.loss_dice: 0.4262  decode.d6.loss_cls: 0.3863  decode.d6.loss_mask: 0.5394  decode.d6.loss_dice: 0.4176  decode.d7.loss_cls: 0.3759  decode.d7.loss_mask: 0.5645  decode.d7.loss_dice: 0.4244  decode.d8.loss_cls: 0.5495  decode.d8.loss_mask: 0.3375  decode.d8.loss_dice: 0.4030
09/30 16:15:32 - mmengine - INFO - Iter(train) [ 59600/320000]  base_lr: 8.3070e-05 lr: 8.3070e-06  eta: 1 day, 7:26:05  time: 0.4356  data_time: 0.0096  memory: 5120  grad_norm: 26.8228  loss: 5.2070  decode.loss_cls: 0.0126  decode.loss_mask: 0.2698  decode.loss_dice: 0.1532  decode.d0.loss_cls: 0.7833  decode.d0.loss_mask: 0.2735  decode.d0.loss_dice: 0.1587  decode.d1.loss_cls: 0.0384  decode.d1.loss_mask: 0.2722  decode.d1.loss_dice: 0.1533  decode.d2.loss_cls: 0.0188  decode.d2.loss_mask: 0.2693  decode.d2.loss_dice: 0.1512  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.2711  decode.d3.loss_dice: 0.1540  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.1567  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.2654  decode.d5.loss_dice: 0.1539  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.1520  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.1584  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.2689  decode.d8.loss_dice: 0.1540
09/30 16:15:54 - mmengine - INFO - Iter(train) [ 59650/320000]  base_lr: 8.3055e-05 lr: 8.3055e-06  eta: 1 day, 7:25:44  time: 0.4366  data_time: 0.0096  memory: 5120  grad_norm: 72.0253  loss: 6.1838  decode.loss_cls: 0.0899  decode.loss_mask: 0.2536  decode.loss_dice: 0.1766  decode.d0.loss_cls: 0.9210  decode.d0.loss_mask: 0.2472  decode.d0.loss_dice: 0.1813  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.1792  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.1798  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.2510  decode.d3.loss_dice: 0.1773  decode.d4.loss_cls: 0.1082  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.1050  decode.d5.loss_mask: 0.2554  decode.d5.loss_dice: 0.1775  decode.d6.loss_cls: 0.1264  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.1783  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.2496  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.1193  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.1777
09/30 16:16:15 - mmengine - INFO - Iter(train) [ 59700/320000]  base_lr: 8.3041e-05 lr: 8.3041e-06  eta: 1 day, 7:25:23  time: 0.4367  data_time: 0.0097  memory: 5120  grad_norm: 25.6845  loss: 6.3047  decode.loss_cls: 0.1102  decode.loss_mask: 0.2342  decode.loss_dice: 0.2256  decode.d0.loss_cls: 0.8040  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 0.2362  decode.d1.loss_dice: 0.2264  decode.d2.loss_cls: 0.1008  decode.d2.loss_mask: 0.2342  decode.d2.loss_dice: 0.2213  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.2336  decode.d4.loss_dice: 0.2235  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.2358  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.2258
09/30 16:16:37 - mmengine - INFO - Iter(train) [ 59750/320000]  base_lr: 8.3027e-05 lr: 8.3027e-06  eta: 1 day, 7:25:02  time: 0.4362  data_time: 0.0098  memory: 5145  grad_norm: 59.0807  loss: 4.8372  decode.loss_cls: 0.1089  decode.loss_mask: 0.1765  decode.loss_dice: 0.1696  decode.d0.loss_cls: 0.8157  decode.d0.loss_mask: 0.1759  decode.d0.loss_dice: 0.1625  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.1755  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0340  decode.d2.loss_mask: 0.1771  decode.d2.loss_dice: 0.1659  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.1781  decode.d3.loss_dice: 0.1770  decode.d4.loss_cls: 0.0216  decode.d4.loss_mask: 0.1768  decode.d4.loss_dice: 0.1567  decode.d5.loss_cls: 0.0373  decode.d5.loss_mask: 0.1794  decode.d5.loss_dice: 0.1727  decode.d6.loss_cls: 0.0916  decode.d6.loss_mask: 0.1790  decode.d6.loss_dice: 0.1652  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.1778  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.1759  decode.d8.loss_dice: 0.1588
09/30 16:16:59 - mmengine - INFO - Iter(train) [ 59800/320000]  base_lr: 8.3012e-05 lr: 8.3012e-06  eta: 1 day, 7:24:40  time: 0.4367  data_time: 0.0097  memory: 5129  grad_norm: 56.9643  loss: 5.9741  decode.loss_cls: 0.1619  decode.loss_mask: 0.2257  decode.loss_dice: 0.1787  decode.d0.loss_cls: 0.8814  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.1771  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.1809  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.1748  decode.d3.loss_cls: 0.1300  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.1798  decode.d4.loss_cls: 0.1358  decode.d4.loss_mask: 0.2265  decode.d4.loss_dice: 0.1817  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 0.2239  decode.d5.loss_dice: 0.1764  decode.d6.loss_cls: 0.0980  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.1744  decode.d7.loss_cls: 0.1093  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.1774  decode.d8.loss_cls: 0.1426  decode.d8.loss_mask: 0.2255  decode.d8.loss_dice: 0.1785
09/30 16:17:21 - mmengine - INFO - Iter(train) [ 59850/320000]  base_lr: 8.2998e-05 lr: 8.2998e-06  eta: 1 day, 7:24:19  time: 0.4369  data_time: 0.0097  memory: 5145  grad_norm: 24.7731  loss: 4.6585  decode.loss_cls: 0.0046  decode.loss_mask: 0.2103  decode.loss_dice: 0.1716  decode.d0.loss_cls: 0.7894  decode.d0.loss_mask: 0.2141  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.1705  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.2089  decode.d2.loss_dice: 0.1740  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.2088  decode.d3.loss_dice: 0.1728  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.1717  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2101  decode.d5.loss_dice: 0.1715  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.2076  decode.d6.loss_dice: 0.1706  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.1708  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.2099  decode.d8.loss_dice: 0.1681
09/30 16:17:43 - mmengine - INFO - Iter(train) [ 59900/320000]  base_lr: 8.2984e-05 lr: 8.2984e-06  eta: 1 day, 7:23:58  time: 0.4366  data_time: 0.0097  memory: 5145  grad_norm: 24.7079  loss: 5.6628  decode.loss_cls: 0.0532  decode.loss_mask: 0.2265  decode.loss_dice: 0.1865  decode.d0.loss_cls: 0.9035  decode.d0.loss_mask: 0.2280  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.1903  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.1821  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.2235  decode.d4.loss_dice: 0.2071  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.1861  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.2237  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.2268  decode.d8.loss_dice: 0.1853
09/30 16:18:05 - mmengine - INFO - Iter(train) [ 59950/320000]  base_lr: 8.2969e-05 lr: 8.2969e-06  eta: 1 day, 7:23:36  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 45.7285  loss: 6.7678  decode.loss_cls: 0.1611  decode.loss_mask: 0.1907  decode.loss_dice: 0.2384  decode.d0.loss_cls: 0.8874  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.2455  decode.d1.loss_cls: 0.2182  decode.d1.loss_mask: 0.1921  decode.d1.loss_dice: 0.2214  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 0.1958  decode.d2.loss_dice: 0.2405  decode.d3.loss_cls: 0.1667  decode.d3.loss_mask: 0.1949  decode.d3.loss_dice: 0.2184  decode.d4.loss_cls: 0.1981  decode.d4.loss_mask: 0.1906  decode.d4.loss_dice: 0.2327  decode.d5.loss_cls: 0.1574  decode.d5.loss_mask: 0.1914  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.2014  decode.d6.loss_mask: 0.1918  decode.d6.loss_dice: 0.2167  decode.d7.loss_cls: 0.2072  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.2225  decode.d8.loss_cls: 0.1644  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.2509
09/30 16:18:26 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:18:26 - mmengine - INFO - Iter(train) [ 60000/320000]  base_lr: 8.2955e-05 lr: 8.2955e-06  eta: 1 day, 7:23:15  time: 0.4356  data_time: 0.0096  memory: 5129  grad_norm: 202.3611  loss: 6.3115  decode.loss_cls: 0.0079  decode.loss_mask: 0.3216  decode.loss_dice: 0.2086  decode.d0.loss_cls: 0.8786  decode.d0.loss_mask: 0.2696  decode.d0.loss_dice: 0.2103  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.3078  decode.d1.loss_dice: 0.1977  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.3322  decode.d2.loss_dice: 0.2180  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.3462  decode.d3.loss_dice: 0.2203  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.3277  decode.d4.loss_dice: 0.2045  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.3314  decode.d5.loss_dice: 0.2123  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.3314  decode.d6.loss_dice: 0.2120  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3277  decode.d7.loss_dice: 0.2018  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.3141  decode.d8.loss_dice: 0.2043
09/30 16:18:48 - mmengine - INFO - Iter(train) [ 60050/320000]  base_lr: 8.2941e-05 lr: 8.2941e-06  eta: 1 day, 7:22:54  time: 0.4360  data_time: 0.0097  memory: 5145  grad_norm: 676.2905  loss: 7.3347  decode.loss_cls: 0.0777  decode.loss_mask: 0.2806  decode.loss_dice: 0.2778  decode.d0.loss_cls: 0.9120  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.2663  decode.d1.loss_cls: 0.1373  decode.d1.loss_mask: 0.2613  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.1361  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.2715  decode.d3.loss_cls: 0.0991  decode.d3.loss_mask: 0.2926  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.0966  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.2754  decode.d5.loss_cls: 0.0789  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.2766  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2901  decode.d6.loss_dice: 0.2761  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.2947  decode.d7.loss_dice: 0.2837  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 0.2826  decode.d8.loss_dice: 0.2758
09/30 16:19:10 - mmengine - INFO - Iter(train) [ 60100/320000]  base_lr: 8.2926e-05 lr: 8.2926e-06  eta: 1 day, 7:22:32  time: 0.4363  data_time: 0.0095  memory: 5129  grad_norm: 27.6467  loss: 4.5906  decode.loss_cls: 0.0654  decode.loss_mask: 0.1388  decode.loss_dice: 0.1512  decode.d0.loss_cls: 0.9395  decode.d0.loss_mask: 0.1379  decode.d0.loss_dice: 0.1557  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.1412  decode.d1.loss_dice: 0.1464  decode.d2.loss_cls: 0.1112  decode.d2.loss_mask: 0.1345  decode.d2.loss_dice: 0.1401  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.1384  decode.d3.loss_dice: 0.1455  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.1398  decode.d4.loss_dice: 0.1496  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.1400  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.1103  decode.d6.loss_mask: 0.1353  decode.d6.loss_dice: 0.1488  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.1394  decode.d7.loss_dice: 0.1405  decode.d8.loss_cls: 0.1016  decode.d8.loss_mask: 0.1350  decode.d8.loss_dice: 0.1398
09/30 16:19:32 - mmengine - INFO - Iter(train) [ 60150/320000]  base_lr: 8.2912e-05 lr: 8.2912e-06  eta: 1 day, 7:22:11  time: 0.4365  data_time: 0.0098  memory: 5129  grad_norm: 48.0886  loss: 7.0324  decode.loss_cls: 0.0683  decode.loss_mask: 0.2879  decode.loss_dice: 0.2400  decode.d0.loss_cls: 0.8499  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.2495  decode.d1.loss_cls: 0.0996  decode.d1.loss_mask: 0.2939  decode.d1.loss_dice: 0.2467  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.2502  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.2614  decode.d4.loss_cls: 0.1025  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.2516  decode.d5.loss_cls: 0.0980  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.2579  decode.d6.loss_cls: 0.1100  decode.d6.loss_mask: 0.2940  decode.d6.loss_dice: 0.2509  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.2919  decode.d7.loss_dice: 0.2527  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.2909  decode.d8.loss_dice: 0.2450
09/30 16:19:54 - mmengine - INFO - Iter(train) [ 60200/320000]  base_lr: 8.2898e-05 lr: 8.2898e-06  eta: 1 day, 7:21:50  time: 0.4363  data_time: 0.0096  memory: 5129  grad_norm: 53.0876  loss: 5.6634  decode.loss_cls: 0.0825  decode.loss_mask: 0.1862  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.8856  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.2300  decode.d1.loss_cls: 0.1085  decode.d1.loss_mask: 0.1861  decode.d1.loss_dice: 0.2197  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 0.1831  decode.d2.loss_dice: 0.2195  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.1829  decode.d3.loss_dice: 0.2077  decode.d4.loss_cls: 0.0819  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.2203  decode.d6.loss_cls: 0.0665  decode.d6.loss_mask: 0.1839  decode.d6.loss_dice: 0.2244  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.1850  decode.d7.loss_dice: 0.2209  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.1851  decode.d8.loss_dice: 0.2272
09/30 16:20:16 - mmengine - INFO - Iter(train) [ 60250/320000]  base_lr: 8.2883e-05 lr: 8.2883e-06  eta: 1 day, 7:21:28  time: 0.4359  data_time: 0.0096  memory: 5145  grad_norm: 57.9361  loss: 7.4199  decode.loss_cls: 0.0594  decode.loss_mask: 0.4088  decode.loss_dice: 0.2090  decode.d0.loss_cls: 0.8493  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.2029  decode.d1.loss_cls: 0.1747  decode.d1.loss_mask: 0.3339  decode.d1.loss_dice: 0.2003  decode.d2.loss_cls: 0.1337  decode.d2.loss_mask: 0.3334  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.1401  decode.d3.loss_mask: 0.3277  decode.d3.loss_dice: 0.1941  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 0.3256  decode.d4.loss_dice: 0.1979  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.3234  decode.d5.loss_dice: 0.1988  decode.d6.loss_cls: 0.1449  decode.d6.loss_mask: 0.3280  decode.d6.loss_dice: 0.1971  decode.d7.loss_cls: 0.1333  decode.d7.loss_mask: 0.3262  decode.d7.loss_dice: 0.1976  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.1967
09/30 16:20:37 - mmengine - INFO - Iter(train) [ 60300/320000]  base_lr: 8.2869e-05 lr: 8.2869e-06  eta: 1 day, 7:21:07  time: 0.4369  data_time: 0.0097  memory: 5129  grad_norm: 85.6419  loss: 7.0337  decode.loss_cls: 0.0960  decode.loss_mask: 0.3075  decode.loss_dice: 0.1764  decode.d0.loss_cls: 1.0253  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.1850  decode.d1.loss_cls: 0.1743  decode.d1.loss_mask: 0.2996  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.1591  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.2311  decode.d3.loss_cls: 0.1173  decode.d3.loss_mask: 0.3233  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.1036  decode.d4.loss_mask: 0.3067  decode.d4.loss_dice: 0.2057  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.1763  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.3818  decode.d6.loss_dice: 0.1752  decode.d7.loss_cls: 0.0878  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.1791  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.2051
09/30 16:20:59 - mmengine - INFO - Iter(train) [ 60350/320000]  base_lr: 8.2854e-05 lr: 8.2854e-06  eta: 1 day, 7:20:46  time: 0.4367  data_time: 0.0095  memory: 5129  grad_norm: 236.5202  loss: 7.6823  decode.loss_cls: 0.1653  decode.loss_mask: 0.2961  decode.loss_dice: 0.2466  decode.d0.loss_cls: 0.9964  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1477  decode.d1.loss_mask: 0.3061  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 0.3044  decode.d2.loss_dice: 0.2605  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.2961  decode.d3.loss_dice: 0.2505  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.2959  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.1145  decode.d5.loss_mask: 0.3003  decode.d5.loss_dice: 0.2737  decode.d6.loss_cls: 0.1305  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.2475  decode.d7.loss_cls: 0.1743  decode.d7.loss_mask: 0.2987  decode.d7.loss_dice: 0.2578  decode.d8.loss_cls: 0.1171  decode.d8.loss_mask: 0.3121  decode.d8.loss_dice: 0.2549
09/30 16:21:21 - mmengine - INFO - Iter(train) [ 60400/320000]  base_lr: 8.2840e-05 lr: 8.2840e-06  eta: 1 day, 7:20:25  time: 0.4354  data_time: 0.0093  memory: 5145  grad_norm: 105.4330  loss: 6.7901  decode.loss_cls: 0.0973  decode.loss_mask: 0.2502  decode.loss_dice: 0.2348  decode.d0.loss_cls: 0.9211  decode.d0.loss_mask: 0.2514  decode.d0.loss_dice: 0.2445  decode.d1.loss_cls: 0.1838  decode.d1.loss_mask: 0.2475  decode.d1.loss_dice: 0.2381  decode.d2.loss_cls: 0.1643  decode.d2.loss_mask: 0.2466  decode.d2.loss_dice: 0.2446  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.2456  decode.d3.loss_dice: 0.2321  decode.d4.loss_cls: 0.0914  decode.d4.loss_mask: 0.2468  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.0847  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.2363  decode.d6.loss_cls: 0.0857  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.2333  decode.d7.loss_cls: 0.1155  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.2373  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.2308
09/30 16:21:43 - mmengine - INFO - Iter(train) [ 60450/320000]  base_lr: 8.2826e-05 lr: 8.2826e-06  eta: 1 day, 7:20:04  time: 0.4368  data_time: 0.0097  memory: 5120  grad_norm: 61.9395  loss: 5.5103  decode.loss_cls: 0.0095  decode.loss_mask: 0.2353  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.8661  decode.d0.loss_mask: 0.2529  decode.d0.loss_dice: 0.2267  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2170  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2198  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.2381  decode.d3.loss_dice: 0.2251  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.2107  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.2408  decode.d5.loss_dice: 0.2054  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.2400  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.2388  decode.d7.loss_dice: 0.2025  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2095
09/30 16:22:05 - mmengine - INFO - Iter(train) [ 60500/320000]  base_lr: 8.2811e-05 lr: 8.2811e-06  eta: 1 day, 7:19:43  time: 0.4371  data_time: 0.0096  memory: 5145  grad_norm: 97.0516  loss: 5.7062  decode.loss_cls: 0.0558  decode.loss_mask: 0.2201  decode.loss_dice: 0.1902  decode.d0.loss_cls: 0.8167  decode.d0.loss_mask: 0.2218  decode.d0.loss_dice: 0.1838  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 0.2200  decode.d1.loss_dice: 0.1916  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.2204  decode.d2.loss_dice: 0.1898  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.1872  decode.d4.loss_cls: 0.1290  decode.d4.loss_mask: 0.2190  decode.d4.loss_dice: 0.1867  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.1889  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0910  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.1929  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.1912
09/30 16:22:27 - mmengine - INFO - Iter(train) [ 60550/320000]  base_lr: 8.2797e-05 lr: 8.2797e-06  eta: 1 day, 7:19:21  time: 0.4374  data_time: 0.0097  memory: 5129  grad_norm: 60.7321  loss: 5.6257  decode.loss_cls: 0.0351  decode.loss_mask: 0.2321  decode.loss_dice: 0.1936  decode.d0.loss_cls: 0.7840  decode.d0.loss_mask: 0.2427  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.1923  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.1890  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.2346  decode.d3.loss_dice: 0.1887  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.2377  decode.d4.loss_dice: 0.1889  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.1862  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.2045  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.2343  decode.d8.loss_dice: 0.1897
09/30 16:22:49 - mmengine - INFO - Iter(train) [ 60600/320000]  base_lr: 8.2783e-05 lr: 8.2783e-06  eta: 1 day, 7:19:00  time: 0.4370  data_time: 0.0096  memory: 5120  grad_norm: 18.8154  loss: 4.7813  decode.loss_cls: 0.0107  decode.loss_mask: 0.2312  decode.loss_dice: 0.1555  decode.d0.loss_cls: 0.7675  decode.d0.loss_mask: 0.2347  decode.d0.loss_dice: 0.1559  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.1544  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.1536  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.2282  decode.d3.loss_dice: 0.1537  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.0202  decode.d5.loss_mask: 0.2316  decode.d5.loss_dice: 0.1571  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.2310  decode.d6.loss_dice: 0.1561  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.1571  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.1556
09/30 16:23:10 - mmengine - INFO - Iter(train) [ 60650/320000]  base_lr: 8.2768e-05 lr: 8.2768e-06  eta: 1 day, 7:18:39  time: 0.4373  data_time: 0.0099  memory: 5129  grad_norm: 54.4158  loss: 6.1336  decode.loss_cls: 0.0223  decode.loss_mask: 0.2963  decode.loss_dice: 0.2177  decode.d0.loss_cls: 0.7220  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.2265  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.2934  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.2964  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.2946  decode.d3.loss_dice: 0.2150  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.2195  decode.d5.loss_cls: 0.0266  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.2121  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.2926  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.2980  decode.d7.loss_dice: 0.2163  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.2980  decode.d8.loss_dice: 0.2162
09/30 16:23:32 - mmengine - INFO - Iter(train) [ 60700/320000]  base_lr: 8.2754e-05 lr: 8.2754e-06  eta: 1 day, 7:18:18  time: 0.4368  data_time: 0.0096  memory: 5145  grad_norm: 38.2525  loss: 6.1929  decode.loss_cls: 0.0963  decode.loss_mask: 0.2234  decode.loss_dice: 0.2123  decode.d0.loss_cls: 0.8593  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.2364  decode.d1.loss_cls: 0.1435  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.2251  decode.d2.loss_cls: 0.0804  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.2041  decode.d4.loss_cls: 0.1599  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.1217  decode.d5.loss_mask: 0.2227  decode.d5.loss_dice: 0.2100  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.2110  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.2233  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.2085
09/30 16:23:54 - mmengine - INFO - Iter(train) [ 60750/320000]  base_lr: 8.2740e-05 lr: 8.2740e-06  eta: 1 day, 7:17:56  time: 0.4361  data_time: 0.0098  memory: 5145  grad_norm: 72.8809  loss: 4.7160  decode.loss_cls: 0.0189  decode.loss_mask: 0.2209  decode.loss_dice: 0.1541  decode.d0.loss_cls: 0.8106  decode.d0.loss_mask: 0.2370  decode.d0.loss_dice: 0.1685  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1549  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.1519  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.1564  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2246  decode.d4.loss_dice: 0.1551  decode.d5.loss_cls: 0.0121  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.1555  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.1564  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.1544
09/30 16:24:16 - mmengine - INFO - Iter(train) [ 60800/320000]  base_lr: 8.2725e-05 lr: 8.2725e-06  eta: 1 day, 7:17:35  time: 0.4364  data_time: 0.0096  memory: 5129  grad_norm: 126.0546  loss: 6.8906  decode.loss_cls: 0.1800  decode.loss_mask: 0.2225  decode.loss_dice: 0.2263  decode.d0.loss_cls: 0.9226  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.2680  decode.d1.loss_cls: 0.1615  decode.d1.loss_mask: 0.2205  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.1498  decode.d2.loss_mask: 0.2271  decode.d2.loss_dice: 0.2256  decode.d3.loss_cls: 0.1450  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2140  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.2188  decode.d5.loss_cls: 0.1432  decode.d5.loss_mask: 0.2208  decode.d5.loss_dice: 0.2439  decode.d6.loss_cls: 0.1646  decode.d6.loss_mask: 0.2161  decode.d6.loss_dice: 0.2364  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.2403  decode.d8.loss_cls: 0.1478  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.2399
09/30 16:24:38 - mmengine - INFO - Iter(train) [ 60850/320000]  base_lr: 8.2711e-05 lr: 8.2711e-06  eta: 1 day, 7:17:14  time: 0.4374  data_time: 0.0097  memory: 5120  grad_norm: 38.2506  loss: 5.6293  decode.loss_cls: 0.0207  decode.loss_mask: 0.2533  decode.loss_dice: 0.2043  decode.d0.loss_cls: 0.7365  decode.d0.loss_mask: 0.2505  decode.d0.loss_dice: 0.2151  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 0.2519  decode.d1.loss_dice: 0.2076  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.2025  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.1998  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2035  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.2524  decode.d7.loss_dice: 0.2070  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.2481  decode.d8.loss_dice: 0.2011
09/30 16:25:00 - mmengine - INFO - Iter(train) [ 60900/320000]  base_lr: 8.2696e-05 lr: 8.2696e-06  eta: 1 day, 7:16:53  time: 0.4372  data_time: 0.0096  memory: 5120  grad_norm: 104.7702  loss: 6.8730  decode.loss_cls: 0.0255  decode.loss_mask: 0.3032  decode.loss_dice: 0.2359  decode.d0.loss_cls: 0.7775  decode.d0.loss_mask: 0.3252  decode.d0.loss_dice: 0.2732  decode.d1.loss_cls: 0.1256  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.2356  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.3013  decode.d2.loss_dice: 0.2403  decode.d3.loss_cls: 0.1002  decode.d3.loss_mask: 0.3041  decode.d3.loss_dice: 0.2365  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 0.3087  decode.d4.loss_dice: 0.2431  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.3014  decode.d5.loss_dice: 0.2382  decode.d6.loss_cls: 0.0449  decode.d6.loss_mask: 0.2999  decode.d6.loss_dice: 0.2341  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.2373  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.2967  decode.d8.loss_dice: 0.2490
09/30 16:25:22 - mmengine - INFO - Iter(train) [ 60950/320000]  base_lr: 8.2682e-05 lr: 8.2682e-06  eta: 1 day, 7:16:31  time: 0.4367  data_time: 0.0093  memory: 5129  grad_norm: 44.8863  loss: 6.3831  decode.loss_cls: 0.0866  decode.loss_mask: 0.2808  decode.loss_dice: 0.2068  decode.d0.loss_cls: 0.6838  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.2112  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.2083  decode.d2.loss_cls: 0.0819  decode.d2.loss_mask: 0.2820  decode.d2.loss_dice: 0.2093  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.2826  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.2112  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.2071  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.2807  decode.d8.loss_dice: 0.2128
09/30 16:25:44 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:25:44 - mmengine - INFO - Iter(train) [ 61000/320000]  base_lr: 8.2668e-05 lr: 8.2668e-06  eta: 1 day, 7:16:10  time: 0.4384  data_time: 0.0095  memory: 5129  grad_norm: 98.9782  loss: 7.0408  decode.loss_cls: 0.1743  decode.loss_mask: 0.2268  decode.loss_dice: 0.2321  decode.d0.loss_cls: 0.9072  decode.d0.loss_mask: 0.2335  decode.d0.loss_dice: 0.2183  decode.d1.loss_cls: 0.1536  decode.d1.loss_mask: 0.2314  decode.d1.loss_dice: 0.2419  decode.d2.loss_cls: 0.1629  decode.d2.loss_mask: 0.2293  decode.d2.loss_dice: 0.2463  decode.d3.loss_cls: 0.1790  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.1954  decode.d4.loss_cls: 0.1658  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.2509  decode.d5.loss_cls: 0.1583  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2408  decode.d6.loss_cls: 0.1648  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.2346  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2533  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.2624
09/30 16:26:05 - mmengine - INFO - Iter(train) [ 61050/320000]  base_lr: 8.2653e-05 lr: 8.2653e-06  eta: 1 day, 7:15:49  time: 0.4364  data_time: 0.0094  memory: 5129  grad_norm: 106.7926  loss: 6.5116  decode.loss_cls: 0.1084  decode.loss_mask: 0.2279  decode.loss_dice: 0.2142  decode.d0.loss_cls: 0.8416  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.2303  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.2442  decode.d1.loss_dice: 0.2234  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.1432  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.2297  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.2272  decode.d5.loss_cls: 0.1062  decode.d5.loss_mask: 0.2385  decode.d5.loss_dice: 0.2343  decode.d6.loss_cls: 0.1516  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.1297  decode.d7.loss_mask: 0.2282  decode.d7.loss_dice: 0.2192  decode.d8.loss_cls: 0.1265  decode.d8.loss_mask: 0.2238  decode.d8.loss_dice: 0.2104
09/30 16:26:27 - mmengine - INFO - Iter(train) [ 61100/320000]  base_lr: 8.2639e-05 lr: 8.2639e-06  eta: 1 day, 7:15:28  time: 0.4363  data_time: 0.0097  memory: 5129  grad_norm: 49.0932  loss: 5.5706  decode.loss_cls: 0.1188  decode.loss_mask: 0.2011  decode.loss_dice: 0.1701  decode.d0.loss_cls: 0.9184  decode.d0.loss_mask: 0.2050  decode.d0.loss_dice: 0.1755  decode.d1.loss_cls: 0.1368  decode.d1.loss_mask: 0.2010  decode.d1.loss_dice: 0.1653  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 0.2027  decode.d2.loss_dice: 0.1697  decode.d3.loss_cls: 0.0806  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.1724  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.2029  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.2031  decode.d5.loss_dice: 0.1732  decode.d6.loss_cls: 0.1112  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.1728  decode.d7.loss_cls: 0.1131  decode.d7.loss_mask: 0.2042  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.1049  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.1617
09/30 16:26:49 - mmengine - INFO - Iter(train) [ 61150/320000]  base_lr: 8.2625e-05 lr: 8.2625e-06  eta: 1 day, 7:15:06  time: 0.4364  data_time: 0.0097  memory: 5145  grad_norm: 60.2782  loss: 7.1496  decode.loss_cls: 0.1052  decode.loss_mask: 0.2245  decode.loss_dice: 0.2349  decode.d0.loss_cls: 1.0381  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.3021  decode.d1.loss_cls: 0.1343  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.2677  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.2609  decode.d3.loss_cls: 0.1617  decode.d3.loss_mask: 0.2210  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 0.2225  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.1389  decode.d5.loss_mask: 0.2222  decode.d5.loss_dice: 0.2518  decode.d6.loss_cls: 0.1385  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.2584  decode.d7.loss_cls: 0.1406  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.2758  decode.d8.loss_cls: 0.1307  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2735
09/30 16:27:11 - mmengine - INFO - Iter(train) [ 61200/320000]  base_lr: 8.2610e-05 lr: 8.2610e-06  eta: 1 day, 7:14:45  time: 0.4362  data_time: 0.0096  memory: 5129  grad_norm: 110.0258  loss: 9.5613  decode.loss_cls: 0.2519  decode.loss_mask: 0.2481  decode.loss_dice: 0.3340  decode.d0.loss_cls: 1.1355  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.3543  decode.d1.loss_cls: 0.2838  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.3265  decode.d2.loss_cls: 0.2805  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.3173  decode.d3.loss_cls: 0.3273  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.3436  decode.d4.loss_cls: 0.2630  decode.d4.loss_mask: 0.2529  decode.d4.loss_dice: 0.3466  decode.d5.loss_cls: 0.2650  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.3274  decode.d6.loss_cls: 0.2837  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.3523  decode.d7.loss_cls: 0.2437  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.3507  decode.d8.loss_cls: 0.2645  decode.d8.loss_mask: 0.2562  decode.d8.loss_dice: 0.3312
09/30 16:27:33 - mmengine - INFO - Iter(train) [ 61250/320000]  base_lr: 8.2596e-05 lr: 8.2596e-06  eta: 1 day, 7:14:24  time: 0.4382  data_time: 0.0097  memory: 5129  grad_norm: 99.5246  loss: 6.7137  decode.loss_cls: 0.0814  decode.loss_mask: 0.3056  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.2306  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.2857  decode.d1.loss_dice: 0.2196  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.2868  decode.d2.loss_dice: 0.2194  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.2259  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.2918  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.2867  decode.d5.loss_dice: 0.2193  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.2881  decode.d6.loss_dice: 0.2272  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.2922  decode.d7.loss_dice: 0.2402  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.3062  decode.d8.loss_dice: 0.2529
09/30 16:27:55 - mmengine - INFO - Iter(train) [ 61300/320000]  base_lr: 8.2582e-05 lr: 8.2582e-06  eta: 1 day, 7:14:03  time: 0.4370  data_time: 0.0097  memory: 5120  grad_norm: 138.7229  loss: 5.1179  decode.loss_cls: 0.0565  decode.loss_mask: 0.1973  decode.loss_dice: 0.1817  decode.d0.loss_cls: 0.7579  decode.d0.loss_mask: 0.1988  decode.d0.loss_dice: 0.1763  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.1986  decode.d1.loss_dice: 0.1857  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.1821  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.1992  decode.d3.loss_dice: 0.1788  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.1989  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.1980  decode.d5.loss_dice: 0.1818  decode.d6.loss_cls: 0.0801  decode.d6.loss_mask: 0.1971  decode.d6.loss_dice: 0.1860  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.1994  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.1850
09/30 16:28:16 - mmengine - INFO - Iter(train) [ 61350/320000]  base_lr: 8.2567e-05 lr: 8.2567e-06  eta: 1 day, 7:13:42  time: 0.4381  data_time: 0.0098  memory: 5120  grad_norm: 67.7224  loss: 7.3242  decode.loss_cls: 0.1641  decode.loss_mask: 0.2644  decode.loss_dice: 0.1966  decode.d0.loss_cls: 0.9251  decode.d0.loss_mask: 0.2971  decode.d0.loss_dice: 0.2046  decode.d1.loss_cls: 0.1624  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.2059  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 0.2681  decode.d3.loss_dice: 0.2027  decode.d4.loss_cls: 0.1462  decode.d4.loss_mask: 0.2749  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.1766  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.2073  decode.d6.loss_cls: 0.1768  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.2136  decode.d7.loss_cls: 0.1686  decode.d7.loss_mask: 0.2973  decode.d7.loss_dice: 0.2324  decode.d8.loss_cls: 0.1584  decode.d8.loss_mask: 0.2711  decode.d8.loss_dice: 0.2130
09/30 16:28:38 - mmengine - INFO - Iter(train) [ 61400/320000]  base_lr: 8.2553e-05 lr: 8.2553e-06  eta: 1 day, 7:13:20  time: 0.4369  data_time: 0.0097  memory: 5129  grad_norm: 89.2636  loss: 8.3684  decode.loss_cls: 0.2347  decode.loss_mask: 0.2489  decode.loss_dice: 0.2368  decode.d0.loss_cls: 1.0021  decode.d0.loss_mask: 0.2477  decode.d0.loss_dice: 0.2663  decode.d1.loss_cls: 0.2622  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.2555  decode.d2.loss_cls: 0.2367  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.2678  decode.d3.loss_cls: 0.2380  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.2470  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.2662  decode.d5.loss_cls: 0.2309  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.2321  decode.d6.loss_cls: 0.2573  decode.d6.loss_mask: 0.2595  decode.d6.loss_dice: 0.2702  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 0.4590  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.2373  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2302
09/30 16:29:00 - mmengine - INFO - Iter(train) [ 61450/320000]  base_lr: 8.2538e-05 lr: 8.2538e-06  eta: 1 day, 7:12:59  time: 0.4364  data_time: 0.0097  memory: 5129  grad_norm: 35.8923  loss: 5.9807  decode.loss_cls: 0.0040  decode.loss_mask: 0.2856  decode.loss_dice: 0.2295  decode.d0.loss_cls: 0.8314  decode.d0.loss_mask: 0.2823  decode.d0.loss_dice: 0.2178  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2253  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.2289  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2817  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2840  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2827  decode.d5.loss_dice: 0.2240  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2845  decode.d6.loss_dice: 0.2263  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.2823  decode.d7.loss_dice: 0.2240  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.2858  decode.d8.loss_dice: 0.2278
09/30 16:29:22 - mmengine - INFO - Iter(train) [ 61500/320000]  base_lr: 8.2524e-05 lr: 8.2524e-06  eta: 1 day, 7:12:38  time: 0.4377  data_time: 0.0095  memory: 5129  grad_norm: 169.7566  loss: 5.8894  decode.loss_cls: 0.1185  decode.loss_mask: 0.1884  decode.loss_dice: 0.1948  decode.d0.loss_cls: 0.9056  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 0.1843  decode.d1.loss_dice: 0.1716  decode.d2.loss_cls: 0.1735  decode.d2.loss_mask: 0.1850  decode.d2.loss_dice: 0.1874  decode.d3.loss_cls: 0.1393  decode.d3.loss_mask: 0.1867  decode.d3.loss_dice: 0.1900  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 0.1883  decode.d4.loss_dice: 0.2024  decode.d5.loss_cls: 0.1563  decode.d5.loss_mask: 0.1855  decode.d5.loss_dice: 0.1808  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.1903  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.1113  decode.d8.loss_mask: 0.1834  decode.d8.loss_dice: 0.1878
09/30 16:29:44 - mmengine - INFO - Iter(train) [ 61550/320000]  base_lr: 8.2510e-05 lr: 8.2510e-06  eta: 1 day, 7:12:16  time: 0.4367  data_time: 0.0096  memory: 5129  grad_norm: 40.9947  loss: 6.0773  decode.loss_cls: 0.1745  decode.loss_mask: 0.2694  decode.loss_dice: 0.1787  decode.d0.loss_cls: 0.8031  decode.d0.loss_mask: 0.1760  decode.d0.loss_dice: 0.1708  decode.d1.loss_cls: 0.1765  decode.d1.loss_mask: 0.1947  decode.d1.loss_dice: 0.1609  decode.d2.loss_cls: 0.2045  decode.d2.loss_mask: 0.1850  decode.d2.loss_dice: 0.1463  decode.d3.loss_cls: 0.1803  decode.d3.loss_mask: 0.1797  decode.d3.loss_dice: 0.1568  decode.d4.loss_cls: 0.1866  decode.d4.loss_mask: 0.1825  decode.d4.loss_dice: 0.1459  decode.d5.loss_cls: 0.1748  decode.d5.loss_mask: 0.1728  decode.d5.loss_dice: 0.1445  decode.d6.loss_cls: 0.1721  decode.d6.loss_mask: 0.1802  decode.d6.loss_dice: 0.1589  decode.d7.loss_cls: 0.1269  decode.d7.loss_mask: 0.2638  decode.d7.loss_dice: 0.1544  decode.d8.loss_cls: 0.2002  decode.d8.loss_mask: 0.3057  decode.d8.loss_dice: 0.1508
09/30 16:30:06 - mmengine - INFO - Iter(train) [ 61600/320000]  base_lr: 8.2495e-05 lr: 8.2495e-06  eta: 1 day, 7:11:55  time: 0.4382  data_time: 0.0099  memory: 5129  grad_norm: 43.4217  loss: 6.3579  decode.loss_cls: 0.0645  decode.loss_mask: 0.2887  decode.loss_dice: 0.2104  decode.d0.loss_cls: 0.7932  decode.d0.loss_mask: 0.2891  decode.d0.loss_dice: 0.2090  decode.d1.loss_cls: 0.0940  decode.d1.loss_mask: 0.2798  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.2831  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.2826  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.2810  decode.d4.loss_dice: 0.2006  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.2830  decode.d5.loss_dice: 0.2018  decode.d6.loss_cls: 0.0703  decode.d6.loss_mask: 0.2801  decode.d6.loss_dice: 0.2009  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.2798  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.2809  decode.d8.loss_dice: 0.2098
09/30 16:30:28 - mmengine - INFO - Iter(train) [ 61650/320000]  base_lr: 8.2481e-05 lr: 8.2481e-06  eta: 1 day, 7:11:34  time: 0.4364  data_time: 0.0097  memory: 5129  grad_norm: 26.1213  loss: 4.4815  decode.loss_cls: 0.0043  decode.loss_mask: 0.2062  decode.loss_dice: 0.1587  decode.d0.loss_cls: 0.7830  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.1591  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.2051  decode.d1.loss_dice: 0.1529  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1545  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.1557  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.1607  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.2067  decode.d5.loss_dice: 0.1571  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.1589  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.2055  decode.d7.loss_dice: 0.1585  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.2073  decode.d8.loss_dice: 0.1572
09/30 16:30:49 - mmengine - INFO - Iter(train) [ 61700/320000]  base_lr: 8.2467e-05 lr: 8.2467e-06  eta: 1 day, 7:11:13  time: 0.4371  data_time: 0.0096  memory: 5145  grad_norm: 61.9276  loss: 8.2870  decode.loss_cls: 0.2220  decode.loss_mask: 0.2686  decode.loss_dice: 0.3035  decode.d0.loss_cls: 1.0154  decode.d0.loss_mask: 0.2682  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 0.2673  decode.d1.loss_dice: 0.2930  decode.d2.loss_cls: 0.1777  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.2858  decode.d3.loss_cls: 0.1487  decode.d3.loss_mask: 0.2691  decode.d3.loss_dice: 0.3075  decode.d4.loss_cls: 0.1755  decode.d4.loss_mask: 0.2685  decode.d4.loss_dice: 0.3193  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.2664  decode.d5.loss_dice: 0.2974  decode.d6.loss_cls: 0.1690  decode.d6.loss_mask: 0.2702  decode.d6.loss_dice: 0.2908  decode.d7.loss_cls: 0.1493  decode.d7.loss_mask: 0.2628  decode.d7.loss_dice: 0.3006  decode.d8.loss_cls: 0.1962  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.2903
09/30 16:31:11 - mmengine - INFO - Iter(train) [ 61750/320000]  base_lr: 8.2452e-05 lr: 8.2452e-06  eta: 1 day, 7:10:52  time: 0.4374  data_time: 0.0096  memory: 5129  grad_norm: 51.9431  loss: 6.7210  decode.loss_cls: 0.0949  decode.loss_mask: 0.2679  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.7456  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.2748  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 0.2710  decode.d1.loss_dice: 0.2538  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2716  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.2687  decode.d3.loss_dice: 0.2674  decode.d4.loss_cls: 0.0779  decode.d4.loss_mask: 0.2695  decode.d4.loss_dice: 0.2608  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.2687  decode.d5.loss_dice: 0.2613  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.2660  decode.d6.loss_dice: 0.2280  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2685  decode.d7.loss_dice: 0.2374  decode.d8.loss_cls: 0.0808  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.2581
09/30 16:31:33 - mmengine - INFO - Iter(train) [ 61800/320000]  base_lr: 8.2438e-05 lr: 8.2438e-06  eta: 1 day, 7:10:30  time: 0.4375  data_time: 0.0097  memory: 5145  grad_norm: 70.5357  loss: 8.7894  decode.loss_cls: 0.0983  decode.loss_mask: 0.3934  decode.loss_dice: 0.3022  decode.d0.loss_cls: 0.8907  decode.d0.loss_mask: 0.3414  decode.d0.loss_dice: 0.3094  decode.d1.loss_cls: 0.1596  decode.d1.loss_mask: 0.3951  decode.d1.loss_dice: 0.2946  decode.d2.loss_cls: 0.1066  decode.d2.loss_mask: 0.3981  decode.d2.loss_dice: 0.2998  decode.d3.loss_cls: 0.0940  decode.d3.loss_mask: 0.4076  decode.d3.loss_dice: 0.2953  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.3927  decode.d4.loss_dice: 0.2981  decode.d5.loss_cls: 0.1176  decode.d5.loss_mask: 0.3933  decode.d5.loss_dice: 0.2934  decode.d6.loss_cls: 0.1493  decode.d6.loss_mask: 0.3976  decode.d6.loss_dice: 0.2893  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.4000  decode.d7.loss_dice: 0.2913  decode.d8.loss_cls: 0.1023  decode.d8.loss_mask: 0.4002  decode.d8.loss_dice: 0.2966
09/30 16:31:55 - mmengine - INFO - Iter(train) [ 61850/320000]  base_lr: 8.2424e-05 lr: 8.2424e-06  eta: 1 day, 7:10:09  time: 0.4373  data_time: 0.0098  memory: 5129  grad_norm: 74.3267  loss: 6.3353  decode.loss_cls: 0.0067  decode.loss_mask: 0.3260  decode.loss_dice: 0.2203  decode.d0.loss_cls: 0.7686  decode.d0.loss_mask: 0.3287  decode.d0.loss_dice: 0.2170  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.3320  decode.d1.loss_dice: 0.2201  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.3367  decode.d2.loss_dice: 0.2195  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.3232  decode.d3.loss_dice: 0.2175  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.3332  decode.d4.loss_dice: 0.2194  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.3242  decode.d5.loss_dice: 0.2176  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.3249  decode.d6.loss_dice: 0.2165  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.3290  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.3287  decode.d8.loss_dice: 0.2193
09/30 16:32:17 - mmengine - INFO - Iter(train) [ 61900/320000]  base_lr: 8.2409e-05 lr: 8.2409e-06  eta: 1 day, 7:09:48  time: 0.4370  data_time: 0.0097  memory: 5129  grad_norm: 42.1610  loss: 4.3347  decode.loss_cls: 0.0062  decode.loss_mask: 0.1764  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.8472  decode.d0.loss_mask: 0.1771  decode.d0.loss_dice: 0.1646  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.1764  decode.d1.loss_dice: 0.1620  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.1744  decode.d2.loss_dice: 0.1620  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.1773  decode.d3.loss_dice: 0.1644  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.1739  decode.d4.loss_dice: 0.1654  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.1737  decode.d5.loss_dice: 0.1617  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.1775  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.1767  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.1763  decode.d8.loss_dice: 0.1638
09/30 16:32:39 - mmengine - INFO - Iter(train) [ 61950/320000]  base_lr: 8.2395e-05 lr: 8.2395e-06  eta: 1 day, 7:09:27  time: 0.4372  data_time: 0.0097  memory: 5145  grad_norm: 48.1418  loss: 7.3798  decode.loss_cls: 0.0962  decode.loss_mask: 0.2531  decode.loss_dice: 0.3069  decode.d0.loss_cls: 0.9509  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.3260  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.2526  decode.d1.loss_dice: 0.3054  decode.d2.loss_cls: 0.0962  decode.d2.loss_mask: 0.2542  decode.d2.loss_dice: 0.3053  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.2568  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.0926  decode.d5.loss_mask: 0.2536  decode.d5.loss_dice: 0.3076  decode.d6.loss_cls: 0.0970  decode.d6.loss_mask: 0.2486  decode.d6.loss_dice: 0.2896  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.2748  decode.d8.loss_cls: 0.1233  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.2830
09/30 16:33:01 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:33:01 - mmengine - INFO - Iter(train) [ 62000/320000]  base_lr: 8.2380e-05 lr: 8.2380e-06  eta: 1 day, 7:09:05  time: 0.4366  data_time: 0.0098  memory: 5146  grad_norm: 54.3943  loss: 7.4587  decode.loss_cls: 0.1770  decode.loss_mask: 0.2712  decode.loss_dice: 0.2475  decode.d0.loss_cls: 0.7470  decode.d0.loss_mask: 0.2842  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.1965  decode.d1.loss_mask: 0.2700  decode.d1.loss_dice: 0.2416  decode.d2.loss_cls: 0.1621  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.2526  decode.d3.loss_cls: 0.1464  decode.d3.loss_mask: 0.2728  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.1502  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.2492  decode.d5.loss_cls: 0.1519  decode.d5.loss_mask: 0.2731  decode.d5.loss_dice: 0.2401  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 0.2702  decode.d6.loss_dice: 0.2490  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.1820  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.2417
09/30 16:33:23 - mmengine - INFO - Iter(train) [ 62050/320000]  base_lr: 8.2366e-05 lr: 8.2366e-06  eta: 1 day, 7:08:44  time: 0.4366  data_time: 0.0098  memory: 5129  grad_norm: 57.4642  loss: 7.6360  decode.loss_cls: 0.2350  decode.loss_mask: 0.2463  decode.loss_dice: 0.2261  decode.d0.loss_cls: 0.9205  decode.d0.loss_mask: 0.2575  decode.d0.loss_dice: 0.2344  decode.d1.loss_cls: 0.2369  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2396  decode.d2.loss_cls: 0.2011  decode.d2.loss_mask: 0.2455  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.2200  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.2345  decode.d4.loss_cls: 0.1814  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2320  decode.d5.loss_cls: 0.1962  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2331  decode.d6.loss_cls: 0.1985  decode.d6.loss_mask: 0.2530  decode.d6.loss_dice: 0.2344  decode.d7.loss_cls: 0.2071  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.2209  decode.d8.loss_cls: 0.2288  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.2244
09/30 16:33:45 - mmengine - INFO - Iter(train) [ 62100/320000]  base_lr: 8.2352e-05 lr: 8.2352e-06  eta: 1 day, 7:08:24  time: 0.4377  data_time: 0.0097  memory: 5145  grad_norm: 155.0683  loss: 7.6927  decode.loss_cls: 0.1898  decode.loss_mask: 0.2329  decode.loss_dice: 0.2515  decode.d0.loss_cls: 0.9062  decode.d0.loss_mask: 0.2475  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.2020  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.2707  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.2395  decode.d3.loss_cls: 0.1852  decode.d3.loss_mask: 0.2400  decode.d3.loss_dice: 0.2487  decode.d4.loss_cls: 0.2362  decode.d4.loss_mask: 0.2375  decode.d4.loss_dice: 0.2680  decode.d5.loss_cls: 0.2328  decode.d5.loss_mask: 0.2313  decode.d5.loss_dice: 0.2226  decode.d6.loss_cls: 0.2325  decode.d6.loss_mask: 0.2315  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.2206  decode.d7.loss_mask: 0.2320  decode.d7.loss_dice: 0.2537  decode.d8.loss_cls: 0.2318  decode.d8.loss_mask: 0.2298  decode.d8.loss_dice: 0.2404
09/30 16:34:06 - mmengine - INFO - Iter(train) [ 62150/320000]  base_lr: 8.2337e-05 lr: 8.2337e-06  eta: 1 day, 7:08:02  time: 0.4365  data_time: 0.0098  memory: 5119  grad_norm: 79.0258  loss: 9.5004  decode.loss_cls: 0.2540  decode.loss_mask: 0.3326  decode.loss_dice: 0.2923  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 0.3374  decode.d0.loss_dice: 0.3033  decode.d1.loss_cls: 0.3266  decode.d1.loss_mask: 0.3353  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.2876  decode.d2.loss_mask: 0.3332  decode.d2.loss_dice: 0.2883  decode.d3.loss_cls: 0.2285  decode.d3.loss_mask: 0.3264  decode.d3.loss_dice: 0.2619  decode.d4.loss_cls: 0.2439  decode.d4.loss_mask: 0.3351  decode.d4.loss_dice: 0.3015  decode.d5.loss_cls: 0.2710  decode.d5.loss_mask: 0.3382  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.2045  decode.d6.loss_mask: 0.3371  decode.d6.loss_dice: 0.3011  decode.d7.loss_cls: 0.2237  decode.d7.loss_mask: 0.3330  decode.d7.loss_dice: 0.2662  decode.d8.loss_cls: 0.2620  decode.d8.loss_mask: 0.3327  decode.d8.loss_dice: 0.2828
09/30 16:34:28 - mmengine - INFO - Iter(train) [ 62200/320000]  base_lr: 8.2323e-05 lr: 8.2323e-06  eta: 1 day, 7:07:41  time: 0.4390  data_time: 0.0098  memory: 5145  grad_norm: 132.2278  loss: 8.3715  decode.loss_cls: 0.0677  decode.loss_mask: 0.3736  decode.loss_dice: 0.2685  decode.d0.loss_cls: 0.9311  decode.d0.loss_mask: 0.3486  decode.d0.loss_dice: 0.2688  decode.d1.loss_cls: 0.1929  decode.d1.loss_mask: 0.3835  decode.d1.loss_dice: 0.2685  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.3445  decode.d2.loss_dice: 0.2406  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 0.4200  decode.d3.loss_dice: 0.2704  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.3950  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.0796  decode.d5.loss_mask: 0.3950  decode.d5.loss_dice: 0.2625  decode.d6.loss_cls: 0.1633  decode.d6.loss_mask: 0.3521  decode.d6.loss_dice: 0.2502  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.4009  decode.d7.loss_dice: 0.2714  decode.d8.loss_cls: 0.1473  decode.d8.loss_mask: 0.3707  decode.d8.loss_dice: 0.2634
09/30 16:34:50 - mmengine - INFO - Iter(train) [ 62250/320000]  base_lr: 8.2309e-05 lr: 8.2309e-06  eta: 1 day, 7:07:20  time: 0.4376  data_time: 0.0097  memory: 5129  grad_norm: 46.3190  loss: 4.4993  decode.loss_cls: 0.0241  decode.loss_mask: 0.1940  decode.loss_dice: 0.1509  decode.d0.loss_cls: 0.8143  decode.d0.loss_mask: 0.1895  decode.d0.loss_dice: 0.1492  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.1524  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.1923  decode.d2.loss_dice: 0.1528  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.1923  decode.d3.loss_dice: 0.1503  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.1891  decode.d4.loss_dice: 0.1487  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.1913  decode.d5.loss_dice: 0.1546  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.1503  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.1932  decode.d7.loss_dice: 0.1513  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.1926  decode.d8.loss_dice: 0.1532
09/30 16:35:12 - mmengine - INFO - Iter(train) [ 62300/320000]  base_lr: 8.2294e-05 lr: 8.2294e-06  eta: 1 day, 7:06:59  time: 0.4371  data_time: 0.0096  memory: 5120  grad_norm: 141.4099  loss: 6.9468  decode.loss_cls: 0.2008  decode.loss_mask: 0.2514  decode.loss_dice: 0.2373  decode.d0.loss_cls: 0.8824  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.1534  decode.d1.loss_mask: 0.2443  decode.d1.loss_dice: 0.2062  decode.d2.loss_cls: 0.1502  decode.d2.loss_mask: 0.2349  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.1622  decode.d3.loss_mask: 0.2422  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.1349  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.1676  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.2413  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.1736  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.1953  decode.d8.loss_cls: 0.1707  decode.d8.loss_mask: 0.2478  decode.d8.loss_dice: 0.2395
09/30 16:35:34 - mmengine - INFO - Iter(train) [ 62350/320000]  base_lr: 8.2280e-05 lr: 8.2280e-06  eta: 1 day, 7:06:38  time: 0.4370  data_time: 0.0094  memory: 5129  grad_norm: 44.5309  loss: 5.6097  decode.loss_cls: 0.0936  decode.loss_mask: 0.1865  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.8062  decode.d0.loss_mask: 0.1893  decode.d0.loss_dice: 0.1942  decode.d1.loss_cls: 0.1176  decode.d1.loss_mask: 0.1871  decode.d1.loss_dice: 0.2052  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.1863  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.1216  decode.d3.loss_mask: 0.1878  decode.d3.loss_dice: 0.2020  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.1883  decode.d4.loss_dice: 0.2049  decode.d5.loss_cls: 0.1338  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.2013  decode.d6.loss_cls: 0.1064  decode.d6.loss_mask: 0.1863  decode.d6.loss_dice: 0.1795  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.1861  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.1997
09/30 16:35:56 - mmengine - INFO - Iter(train) [ 62400/320000]  base_lr: 8.2265e-05 lr: 8.2265e-06  eta: 1 day, 7:06:16  time: 0.4374  data_time: 0.0097  memory: 5129  grad_norm: 38.1409  loss: 5.2448  decode.loss_cls: 0.0482  decode.loss_mask: 0.1948  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.8637  decode.d0.loss_mask: 0.1978  decode.d0.loss_dice: 0.1973  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.1975  decode.d1.loss_dice: 0.1942  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.1982  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.1965  decode.d3.loss_dice: 0.1863  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.1961  decode.d4.loss_dice: 0.1950  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.1967  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.1954  decode.d6.loss_dice: 0.1932  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.1952  decode.d8.loss_dice: 0.2060
09/30 16:36:18 - mmengine - INFO - Iter(train) [ 62450/320000]  base_lr: 8.2251e-05 lr: 8.2251e-06  eta: 1 day, 7:05:55  time: 0.4363  data_time: 0.0097  memory: 5129  grad_norm: 58.8359  loss: 7.0341  decode.loss_cls: 0.0764  decode.loss_mask: 0.3030  decode.loss_dice: 0.2606  decode.d0.loss_cls: 0.7270  decode.d0.loss_mask: 0.3092  decode.d0.loss_dice: 0.2804  decode.d1.loss_cls: 0.0929  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.2368  decode.d2.loss_cls: 0.0963  decode.d2.loss_mask: 0.3074  decode.d2.loss_dice: 0.2692  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.3060  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.3067  decode.d4.loss_dice: 0.2510  decode.d5.loss_cls: 0.0879  decode.d5.loss_mask: 0.3069  decode.d5.loss_dice: 0.2403  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.3060  decode.d6.loss_dice: 0.2447  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.3054  decode.d7.loss_dice: 0.2548  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.3065  decode.d8.loss_dice: 0.2680
09/30 16:36:40 - mmengine - INFO - Iter(train) [ 62500/320000]  base_lr: 8.2237e-05 lr: 8.2237e-06  eta: 1 day, 7:05:34  time: 0.4384  data_time: 0.0097  memory: 5129  grad_norm: 26.5281  loss: 4.9125  decode.loss_cls: 0.0441  decode.loss_mask: 0.1948  decode.loss_dice: 0.1839  decode.d0.loss_cls: 0.8274  decode.d0.loss_mask: 0.1956  decode.d0.loss_dice: 0.1695  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.1678  decode.d2.loss_cls: 0.0419  decode.d2.loss_mask: 0.1978  decode.d2.loss_dice: 0.1774  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.1963  decode.d3.loss_dice: 0.1709  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.1943  decode.d4.loss_dice: 0.1734  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.1929  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.1947  decode.d6.loss_dice: 0.1648  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.1955  decode.d7.loss_dice: 0.1752  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.1938  decode.d8.loss_dice: 0.1631
09/30 16:37:01 - mmengine - INFO - Iter(train) [ 62550/320000]  base_lr: 8.2222e-05 lr: 8.2222e-06  eta: 1 day, 7:05:13  time: 0.4374  data_time: 0.0095  memory: 5129  grad_norm: 77.2425  loss: 7.9774  decode.loss_cls: 0.2469  decode.loss_mask: 0.2590  decode.loss_dice: 0.2254  decode.d0.loss_cls: 0.9331  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.2410  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2057  decode.d2.loss_cls: 0.2341  decode.d2.loss_mask: 0.2468  decode.d2.loss_dice: 0.2068  decode.d3.loss_cls: 0.2758  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2108  decode.d4.loss_cls: 0.1950  decode.d4.loss_mask: 0.2605  decode.d4.loss_dice: 0.2118  decode.d5.loss_cls: 0.1557  decode.d5.loss_mask: 0.2828  decode.d5.loss_dice: 0.2327  decode.d6.loss_cls: 0.2871  decode.d6.loss_mask: 0.2793  decode.d6.loss_dice: 0.2475  decode.d7.loss_cls: 0.2410  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.2697  decode.d8.loss_mask: 0.2866  decode.d8.loss_dice: 0.2501
09/30 16:37:23 - mmengine - INFO - Iter(train) [ 62600/320000]  base_lr: 8.2208e-05 lr: 8.2208e-06  eta: 1 day, 7:04:52  time: 0.4364  data_time: 0.0093  memory: 5145  grad_norm: 101.7772  loss: 6.5610  decode.loss_cls: 0.2050  decode.loss_mask: 0.2165  decode.loss_dice: 0.2056  decode.d0.loss_cls: 0.9105  decode.d0.loss_mask: 0.2184  decode.d0.loss_dice: 0.2075  decode.d1.loss_cls: 0.2051  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.1232  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.1973  decode.d3.loss_cls: 0.1149  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.1954  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.2117  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.1653  decode.d5.loss_mask: 0.2145  decode.d5.loss_dice: 0.2045  decode.d6.loss_cls: 0.1759  decode.d6.loss_mask: 0.2155  decode.d6.loss_dice: 0.2027  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 0.2207  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.1568  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.2085
09/30 16:37:45 - mmengine - INFO - Iter(train) [ 62650/320000]  base_lr: 8.2194e-05 lr: 8.2194e-06  eta: 1 day, 7:04:30  time: 0.4360  data_time: 0.0095  memory: 5129  grad_norm: 98.3783  loss: 5.8332  decode.loss_cls: 0.0664  decode.loss_mask: 0.2556  decode.loss_dice: 0.1734  decode.d0.loss_cls: 0.8245  decode.d0.loss_mask: 0.2720  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.0886  decode.d1.loss_mask: 0.2570  decode.d1.loss_dice: 0.1791  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.1752  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.2607  decode.d3.loss_dice: 0.1785  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.0939  decode.d5.loss_mask: 0.2548  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.1771  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.2565  decode.d7.loss_dice: 0.1774  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.2570  decode.d8.loss_dice: 0.1768
09/30 16:38:07 - mmengine - INFO - Iter(train) [ 62700/320000]  base_lr: 8.2179e-05 lr: 8.2179e-06  eta: 1 day, 7:04:09  time: 0.4369  data_time: 0.0095  memory: 5120  grad_norm: 31.3657  loss: 5.9491  decode.loss_cls: 0.0457  decode.loss_mask: 0.2782  decode.loss_dice: 0.1743  decode.d0.loss_cls: 0.8742  decode.d0.loss_mask: 0.2277  decode.d0.loss_dice: 0.1711  decode.d1.loss_cls: 0.1546  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.1634  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.2897  decode.d2.loss_dice: 0.1703  decode.d3.loss_cls: 0.0832  decode.d3.loss_mask: 0.2883  decode.d3.loss_dice: 0.1733  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.2899  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.0785  decode.d5.loss_mask: 0.2830  decode.d5.loss_dice: 0.1742  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.2818  decode.d6.loss_dice: 0.1759  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.2817  decode.d7.loss_dice: 0.1820  decode.d8.loss_cls: 0.0960  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.1631
09/30 16:38:29 - mmengine - INFO - Iter(train) [ 62750/320000]  base_lr: 8.2165e-05 lr: 8.2165e-06  eta: 1 day, 7:03:48  time: 0.4371  data_time: 0.0094  memory: 5129  grad_norm: 15.8836  loss: 4.7726  decode.loss_cls: 0.0078  decode.loss_mask: 0.1939  decode.loss_dice: 0.1851  decode.d0.loss_cls: 0.8200  decode.d0.loss_mask: 0.1964  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.1960  decode.d1.loss_dice: 0.1902  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.1877  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.1941  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.1967  decode.d5.loss_dice: 0.1920  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.1926  decode.d6.loss_dice: 0.1949  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.1959  decode.d7.loss_dice: 0.1931  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.1953  decode.d8.loss_dice: 0.1944
09/30 16:38:51 - mmengine - INFO - Iter(train) [ 62800/320000]  base_lr: 8.2150e-05 lr: 8.2150e-06  eta: 1 day, 7:03:27  time: 0.4370  data_time: 0.0097  memory: 5129  grad_norm: 117.5921  loss: 5.6801  decode.loss_cls: 0.0421  decode.loss_mask: 0.2536  decode.loss_dice: 0.1781  decode.d0.loss_cls: 0.9651  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.1703  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.2137  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.1689  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.1929  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2703  decode.d4.loss_dice: 0.1906  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.2528  decode.d5.loss_dice: 0.1700  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.1687  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.2525  decode.d7.loss_dice: 0.1704  decode.d8.loss_cls: 0.0238  decode.d8.loss_mask: 0.2558  decode.d8.loss_dice: 0.1734
09/30 16:39:13 - mmengine - INFO - Iter(train) [ 62850/320000]  base_lr: 8.2136e-05 lr: 8.2136e-06  eta: 1 day, 7:03:05  time: 0.4378  data_time: 0.0097  memory: 5145  grad_norm: 75.0467  loss: 6.4648  decode.loss_cls: 0.0917  decode.loss_mask: 0.2297  decode.loss_dice: 0.2285  decode.d0.loss_cls: 0.7639  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2112  decode.d1.loss_cls: 0.1446  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2158  decode.d2.loss_cls: 0.1701  decode.d2.loss_mask: 0.2298  decode.d2.loss_dice: 0.2099  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2190  decode.d4.loss_cls: 0.1310  decode.d4.loss_mask: 0.2302  decode.d4.loss_dice: 0.2036  decode.d5.loss_cls: 0.1948  decode.d5.loss_mask: 0.2279  decode.d5.loss_dice: 0.2081  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.2162  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.2081  decode.d8.loss_cls: 0.1658  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.2396
09/30 16:39:34 - mmengine - INFO - Iter(train) [ 62900/320000]  base_lr: 8.2122e-05 lr: 8.2122e-06  eta: 1 day, 7:02:44  time: 0.4375  data_time: 0.0097  memory: 5129  grad_norm: 34.3498  loss: 6.1266  decode.loss_cls: 0.0077  decode.loss_mask: 0.3092  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.7260  decode.d0.loss_mask: 0.3156  decode.d0.loss_dice: 0.2233  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.3120  decode.d1.loss_dice: 0.2233  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.3097  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.3103  decode.d3.loss_dice: 0.2218  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.3106  decode.d4.loss_dice: 0.2225  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.3096  decode.d5.loss_dice: 0.2190  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.3094  decode.d6.loss_dice: 0.2227  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.3104  decode.d7.loss_dice: 0.2217  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.3115  decode.d8.loss_dice: 0.2268
09/30 16:39:56 - mmengine - INFO - Iter(train) [ 62950/320000]  base_lr: 8.2107e-05 lr: 8.2107e-06  eta: 1 day, 7:02:23  time: 0.4382  data_time: 0.0100  memory: 5129  grad_norm: 227.5046  loss: 8.3645  decode.loss_cls: 0.2235  decode.loss_mask: 0.2392  decode.loss_dice: 0.2672  decode.d0.loss_cls: 0.9984  decode.d0.loss_mask: 0.2439  decode.d0.loss_dice: 0.2897  decode.d1.loss_cls: 0.2735  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.2149  decode.d2.loss_mask: 0.2357  decode.d2.loss_dice: 0.2664  decode.d3.loss_cls: 0.2520  decode.d3.loss_mask: 0.2391  decode.d3.loss_dice: 0.2709  decode.d4.loss_cls: 0.2421  decode.d4.loss_mask: 0.3096  decode.d4.loss_dice: 0.3047  decode.d5.loss_cls: 0.2385  decode.d5.loss_mask: 0.2658  decode.d5.loss_dice: 0.3121  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.3057  decode.d7.loss_cls: 0.1887  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.2732  decode.d8.loss_cls: 0.2123  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.2730
09/30 16:40:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:40:18 - mmengine - INFO - Iter(train) [ 63000/320000]  base_lr: 8.2093e-05 lr: 8.2093e-06  eta: 1 day, 7:02:02  time: 0.4368  data_time: 0.0096  memory: 5129  grad_norm: 49.4416  loss: 5.8312  decode.loss_cls: 0.1109  decode.loss_mask: 0.2269  decode.loss_dice: 0.1986  decode.d0.loss_cls: 0.8445  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.2117  decode.d1.loss_cls: 0.1085  decode.d1.loss_mask: 0.2260  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0840  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.1963  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.1992  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.2028  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.1991  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.2279  decode.d6.loss_dice: 0.2009  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.2273  decode.d7.loss_dice: 0.1999  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.2283  decode.d8.loss_dice: 0.2021
09/30 16:40:40 - mmengine - INFO - Iter(train) [ 63050/320000]  base_lr: 8.2079e-05 lr: 8.2079e-06  eta: 1 day, 7:01:41  time: 0.4383  data_time: 0.0096  memory: 5129  grad_norm: 86.2684  loss: 7.7332  decode.loss_cls: 0.1362  decode.loss_mask: 0.2945  decode.loss_dice: 0.2472  decode.d0.loss_cls: 0.9589  decode.d0.loss_mask: 0.2985  decode.d0.loss_dice: 0.2686  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.1512  decode.d2.loss_mask: 0.2914  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 0.2905  decode.d3.loss_dice: 0.2447  decode.d4.loss_cls: 0.1283  decode.d4.loss_mask: 0.2908  decode.d4.loss_dice: 0.2464  decode.d5.loss_cls: 0.1392  decode.d5.loss_mask: 0.2931  decode.d5.loss_dice: 0.2710  decode.d6.loss_cls: 0.1418  decode.d6.loss_mask: 0.2928  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.1444  decode.d7.loss_mask: 0.2975  decode.d7.loss_dice: 0.2774  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 0.2944  decode.d8.loss_dice: 0.2596
09/30 16:41:02 - mmengine - INFO - Iter(train) [ 63100/320000]  base_lr: 8.2064e-05 lr: 8.2064e-06  eta: 1 day, 7:01:19  time: 0.4373  data_time: 0.0097  memory: 5145  grad_norm: 52.9803  loss: 6.6264  decode.loss_cls: 0.0249  decode.loss_mask: 0.3080  decode.loss_dice: 0.2441  decode.d0.loss_cls: 0.8851  decode.d0.loss_mask: 0.3233  decode.d0.loss_dice: 0.2243  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.3074  decode.d1.loss_dice: 0.2377  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.3075  decode.d2.loss_dice: 0.2263  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.2445  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.2401  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.3076  decode.d5.loss_dice: 0.2360  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.3082  decode.d6.loss_dice: 0.2363  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.2357  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.3089  decode.d8.loss_dice: 0.2309
09/30 16:41:24 - mmengine - INFO - Iter(train) [ 63150/320000]  base_lr: 8.2050e-05 lr: 8.2050e-06  eta: 1 day, 7:00:58  time: 0.4373  data_time: 0.0098  memory: 5119  grad_norm: 36.4693  loss: 7.3338  decode.loss_cls: 0.0883  decode.loss_mask: 0.3128  decode.loss_dice: 0.2498  decode.d0.loss_cls: 0.8436  decode.d0.loss_mask: 0.3256  decode.d0.loss_dice: 0.2509  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.3132  decode.d1.loss_dice: 0.2449  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.3149  decode.d2.loss_dice: 0.2388  decode.d3.loss_cls: 0.0867  decode.d3.loss_mask: 0.3166  decode.d3.loss_dice: 0.2365  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.3170  decode.d4.loss_dice: 0.2486  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.3179  decode.d5.loss_dice: 0.2473  decode.d6.loss_cls: 0.1128  decode.d6.loss_mask: 0.3193  decode.d6.loss_dice: 0.2452  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.3181  decode.d7.loss_dice: 0.2433  decode.d8.loss_cls: 0.1098  decode.d8.loss_mask: 0.3186  decode.d8.loss_dice: 0.2437
09/30 16:41:46 - mmengine - INFO - Iter(train) [ 63200/320000]  base_lr: 8.2035e-05 lr: 8.2035e-06  eta: 1 day, 7:00:37  time: 0.4374  data_time: 0.0098  memory: 5120  grad_norm: 17.7953  loss: 4.5198  decode.loss_cls: 0.0864  decode.loss_mask: 0.1798  decode.loss_dice: 0.1450  decode.d0.loss_cls: 0.8488  decode.d0.loss_mask: 0.1852  decode.d0.loss_dice: 0.1488  decode.d1.loss_cls: 0.0532  decode.d1.loss_mask: 0.1784  decode.d1.loss_dice: 0.1416  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.1829  decode.d2.loss_dice: 0.1456  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.1804  decode.d3.loss_dice: 0.1450  decode.d4.loss_cls: 0.0292  decode.d4.loss_mask: 0.1839  decode.d4.loss_dice: 0.1462  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.1817  decode.d5.loss_dice: 0.1437  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.1804  decode.d6.loss_dice: 0.1466  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.1817  decode.d7.loss_dice: 0.1459  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.1818  decode.d8.loss_dice: 0.1464
09/30 16:42:08 - mmengine - INFO - Iter(train) [ 63250/320000]  base_lr: 8.2021e-05 lr: 8.2021e-06  eta: 1 day, 7:00:16  time: 0.4371  data_time: 0.0098  memory: 5145  grad_norm: 39.9081  loss: 5.3419  decode.loss_cls: 0.0850  decode.loss_mask: 0.2037  decode.loss_dice: 0.1965  decode.d0.loss_cls: 0.6929  decode.d0.loss_mask: 0.2077  decode.d0.loss_dice: 0.1845  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.2053  decode.d1.loss_dice: 0.1970  decode.d2.loss_cls: 0.1015  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.1788  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.2063  decode.d3.loss_dice: 0.1610  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.1885  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.2052  decode.d5.loss_dice: 0.1925  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.2041  decode.d6.loss_dice: 0.1917  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.2109  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.2028  decode.d8.loss_dice: 0.1611
09/30 16:42:30 - mmengine - INFO - Iter(train) [ 63300/320000]  base_lr: 8.2007e-05 lr: 8.2007e-06  eta: 1 day, 6:59:55  time: 0.4381  data_time: 0.0100  memory: 5120  grad_norm: 46.7675  loss: 7.6602  decode.loss_cls: 0.1753  decode.loss_mask: 0.2753  decode.loss_dice: 0.2594  decode.d0.loss_cls: 0.9867  decode.d0.loss_mask: 0.2834  decode.d0.loss_dice: 0.2465  decode.d1.loss_cls: 0.1786  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.2452  decode.d2.loss_cls: 0.1735  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2531  decode.d3.loss_cls: 0.1363  decode.d3.loss_mask: 0.2707  decode.d3.loss_dice: 0.2666  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.2729  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.1632  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.2703  decode.d7.loss_cls: 0.1240  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.2544  decode.d8.loss_cls: 0.1624  decode.d8.loss_mask: 0.2792  decode.d8.loss_dice: 0.2732
09/30 16:42:51 - mmengine - INFO - Iter(train) [ 63350/320000]  base_lr: 8.1992e-05 lr: 8.1992e-06  eta: 1 day, 6:59:34  time: 0.4372  data_time: 0.0097  memory: 5120  grad_norm: 26.8833  loss: 4.8990  decode.loss_cls: 0.0426  decode.loss_mask: 0.1876  decode.loss_dice: 0.1739  decode.d0.loss_cls: 0.8328  decode.d0.loss_mask: 0.1898  decode.d0.loss_dice: 0.1672  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.1880  decode.d1.loss_dice: 0.1663  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.1881  decode.d2.loss_dice: 0.1724  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.1871  decode.d3.loss_dice: 0.1766  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.1859  decode.d4.loss_dice: 0.1847  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.1883  decode.d5.loss_dice: 0.1858  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.1918  decode.d6.loss_dice: 0.1874  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.1923  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.1885  decode.d8.loss_dice: 0.1680
09/30 16:43:13 - mmengine - INFO - Iter(train) [ 63400/320000]  base_lr: 8.1978e-05 lr: 8.1978e-06  eta: 1 day, 6:59:13  time: 0.4386  data_time: 0.0098  memory: 5120  grad_norm: 33.1206  loss: 5.7519  decode.loss_cls: 0.0471  decode.loss_mask: 0.2381  decode.loss_dice: 0.1921  decode.d0.loss_cls: 0.8530  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.2003  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.1985  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.1927  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.2000  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.1974  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.2363  decode.d5.loss_dice: 0.1975  decode.d6.loss_cls: 0.0541  decode.d6.loss_mask: 0.2367  decode.d6.loss_dice: 0.1968  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.1955  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.1979
09/30 16:43:35 - mmengine - INFO - Iter(train) [ 63450/320000]  base_lr: 8.1964e-05 lr: 8.1964e-06  eta: 1 day, 6:58:51  time: 0.4372  data_time: 0.0097  memory: 5129  grad_norm: 35.9669  loss: 5.5462  decode.loss_cls: 0.0853  decode.loss_mask: 0.2064  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.8724  decode.d0.loss_mask: 0.2046  decode.d0.loss_dice: 0.1958  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.2040  decode.d1.loss_dice: 0.1939  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.1919  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.2061  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.2014  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.2054  decode.d5.loss_dice: 0.1998  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.2036  decode.d6.loss_dice: 0.1925  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.1952  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.2028  decode.d8.loss_dice: 0.1856
09/30 16:43:57 - mmengine - INFO - Iter(train) [ 63500/320000]  base_lr: 8.1949e-05 lr: 8.1949e-06  eta: 1 day, 6:58:30  time: 0.4371  data_time: 0.0097  memory: 5145  grad_norm: 52.1520  loss: 5.8478  decode.loss_cls: 0.0590  decode.loss_mask: 0.2400  decode.loss_dice: 0.1965  decode.d0.loss_cls: 0.9101  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.2402  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.2425  decode.d2.loss_dice: 0.1971  decode.d3.loss_cls: 0.0296  decode.d3.loss_mask: 0.2436  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.1933  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.1990  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.2385  decode.d6.loss_dice: 0.2028  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.1963
09/30 16:44:19 - mmengine - INFO - Iter(train) [ 63550/320000]  base_lr: 8.1935e-05 lr: 8.1935e-06  eta: 1 day, 6:58:09  time: 0.4365  data_time: 0.0098  memory: 5129  grad_norm: 34.7649  loss: 4.5969  decode.loss_cls: 0.0178  decode.loss_mask: 0.1973  decode.loss_dice: 0.1476  decode.d0.loss_cls: 0.8165  decode.d0.loss_mask: 0.1900  decode.d0.loss_dice: 0.1499  decode.d1.loss_cls: 0.0834  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1424  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.1900  decode.d2.loss_dice: 0.1429  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.1856  decode.d3.loss_dice: 0.1400  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.1884  decode.d4.loss_dice: 0.1508  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.1875  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0347  decode.d6.loss_mask: 0.1898  decode.d6.loss_dice: 0.1488  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.1905  decode.d7.loss_dice: 0.1486  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.1855  decode.d8.loss_dice: 0.1440
09/30 16:44:41 - mmengine - INFO - Iter(train) [ 63600/320000]  base_lr: 8.1920e-05 lr: 8.1920e-06  eta: 1 day, 6:57:48  time: 0.4377  data_time: 0.0098  memory: 5129  grad_norm: 30.7890  loss: 5.4517  decode.loss_cls: 0.0247  decode.loss_mask: 0.2439  decode.loss_dice: 0.1829  decode.d0.loss_cls: 0.9341  decode.d0.loss_mask: 0.2460  decode.d0.loss_dice: 0.1942  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.1854  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.2410  decode.d2.loss_dice: 0.1820  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.1806  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.2452  decode.d4.loss_dice: 0.1829  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.1844  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.2444  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.2436  decode.d7.loss_dice: 0.1804  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.1861
09/30 16:45:03 - mmengine - INFO - Iter(train) [ 63650/320000]  base_lr: 8.1906e-05 lr: 8.1906e-06  eta: 1 day, 6:57:27  time: 0.4376  data_time: 0.0098  memory: 5129  grad_norm: 173.8539  loss: 8.1541  decode.loss_cls: 0.1714  decode.loss_mask: 0.2670  decode.loss_dice: 0.2325  decode.d0.loss_cls: 0.9330  decode.d0.loss_mask: 0.2901  decode.d0.loss_dice: 0.3200  decode.d1.loss_cls: 0.1289  decode.d1.loss_mask: 0.2702  decode.d1.loss_dice: 0.2315  decode.d2.loss_cls: 0.1342  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2853  decode.d3.loss_cls: 0.1714  decode.d3.loss_mask: 0.2654  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.1323  decode.d4.loss_mask: 0.3809  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.1797  decode.d5.loss_mask: 0.2948  decode.d5.loss_dice: 0.3023  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 0.2835  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.2326  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.2969  decode.d8.loss_cls: 0.2198  decode.d8.loss_mask: 0.2663  decode.d8.loss_dice: 0.2455
09/30 16:45:25 - mmengine - INFO - Iter(train) [ 63700/320000]  base_lr: 8.1892e-05 lr: 8.1892e-06  eta: 1 day, 6:57:06  time: 0.4384  data_time: 0.0098  memory: 5129  grad_norm: 33.3481  loss: 5.3997  decode.loss_cls: 0.0756  decode.loss_mask: 0.2107  decode.loss_dice: 0.1784  decode.d0.loss_cls: 0.9288  decode.d0.loss_mask: 0.2104  decode.d0.loss_dice: 0.1930  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.2101  decode.d1.loss_dice: 0.1847  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.2097  decode.d2.loss_dice: 0.1814  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.2089  decode.d3.loss_dice: 0.1896  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.1882  decode.d6.loss_cls: 0.0481  decode.d6.loss_mask: 0.2067  decode.d6.loss_dice: 0.1783  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.2066  decode.d7.loss_dice: 0.1907  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.1786
09/30 16:45:47 - mmengine - INFO - Iter(train) [ 63750/320000]  base_lr: 8.1877e-05 lr: 8.1877e-06  eta: 1 day, 6:56:45  time: 0.4374  data_time: 0.0099  memory: 5129  grad_norm: 44.2013  loss: 8.6813  decode.loss_cls: 0.1903  decode.loss_mask: 0.2944  decode.loss_dice: 0.2570  decode.d0.loss_cls: 0.9206  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.2471  decode.d1.loss_cls: 0.1727  decode.d1.loss_mask: 0.3253  decode.d1.loss_dice: 0.2577  decode.d2.loss_cls: 0.1778  decode.d2.loss_mask: 0.3761  decode.d2.loss_dice: 0.2638  decode.d3.loss_cls: 0.1778  decode.d3.loss_mask: 0.4038  decode.d3.loss_dice: 0.2817  decode.d4.loss_cls: 0.1863  decode.d4.loss_mask: 0.3172  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.1913  decode.d5.loss_mask: 0.3376  decode.d5.loss_dice: 0.2471  decode.d6.loss_cls: 0.2028  decode.d6.loss_mask: 0.3926  decode.d6.loss_dice: 0.2627  decode.d7.loss_cls: 0.1979  decode.d7.loss_mask: 0.3983  decode.d7.loss_dice: 0.2531  decode.d8.loss_cls: 0.2004  decode.d8.loss_mask: 0.3373  decode.d8.loss_dice: 0.2414
09/30 16:46:09 - mmengine - INFO - Iter(train) [ 63800/320000]  base_lr: 8.1863e-05 lr: 8.1863e-06  eta: 1 day, 6:56:24  time: 0.4375  data_time: 0.0097  memory: 5130  grad_norm: 56.2555  loss: 8.5822  decode.loss_cls: 0.1670  decode.loss_mask: 0.3391  decode.loss_dice: 0.2738  decode.d0.loss_cls: 0.9197  decode.d0.loss_mask: 0.3490  decode.d0.loss_dice: 0.2671  decode.d1.loss_cls: 0.2500  decode.d1.loss_mask: 0.3346  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.2019  decode.d2.loss_mask: 0.3337  decode.d2.loss_dice: 0.2541  decode.d3.loss_cls: 0.1924  decode.d3.loss_mask: 0.3342  decode.d3.loss_dice: 0.2587  decode.d4.loss_cls: 0.1985  decode.d4.loss_mask: 0.3321  decode.d4.loss_dice: 0.2549  decode.d5.loss_cls: 0.2054  decode.d5.loss_mask: 0.3327  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.3435  decode.d6.loss_dice: 0.2525  decode.d7.loss_cls: 0.1375  decode.d7.loss_mask: 0.3421  decode.d7.loss_dice: 0.2468  decode.d8.loss_cls: 0.1740  decode.d8.loss_mask: 0.3393  decode.d8.loss_dice: 0.2633
09/30 16:46:30 - mmengine - INFO - Iter(train) [ 63850/320000]  base_lr: 8.1849e-05 lr: 8.1849e-06  eta: 1 day, 6:56:03  time: 0.4365  data_time: 0.0098  memory: 5145  grad_norm: 68.2500  loss: 9.5796  decode.loss_cls: 0.2799  decode.loss_mask: 0.2867  decode.loss_dice: 0.3164  decode.d0.loss_cls: 0.9087  decode.d0.loss_mask: 0.2577  decode.d0.loss_dice: 0.3103  decode.d1.loss_cls: 0.3061  decode.d1.loss_mask: 0.2468  decode.d1.loss_dice: 0.2706  decode.d2.loss_cls: 0.3388  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.2788  decode.d3.loss_cls: 0.3225  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.3102  decode.d4.loss_cls: 0.2585  decode.d4.loss_mask: 0.4013  decode.d4.loss_dice: 0.2954  decode.d5.loss_cls: 0.3790  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.2833  decode.d6.loss_cls: 0.2789  decode.d6.loss_mask: 0.3420  decode.d6.loss_dice: 0.3243  decode.d7.loss_cls: 0.2752  decode.d7.loss_mask: 0.3319  decode.d7.loss_dice: 0.2900  decode.d8.loss_cls: 0.3025  decode.d8.loss_mask: 0.2842  decode.d8.loss_dice: 0.3122
09/30 16:46:52 - mmengine - INFO - Iter(train) [ 63900/320000]  base_lr: 8.1834e-05 lr: 8.1834e-06  eta: 1 day, 6:55:41  time: 0.4375  data_time: 0.0098  memory: 5129  grad_norm: 16.3481  loss: 4.4437  decode.loss_cls: 0.0078  decode.loss_mask: 0.2040  decode.loss_dice: 0.1610  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.1597  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2005  decode.d1.loss_dice: 0.1561  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.2009  decode.d2.loss_dice: 0.1591  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.2015  decode.d3.loss_dice: 0.1589  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.1591  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.1561  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.2006  decode.d6.loss_dice: 0.1579  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.1619  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.1633
09/30 16:47:14 - mmengine - INFO - Iter(train) [ 63950/320000]  base_lr: 8.1820e-05 lr: 8.1820e-06  eta: 1 day, 6:55:20  time: 0.4381  data_time: 0.0099  memory: 5129  grad_norm: 35.4104  loss: 6.3877  decode.loss_cls: 0.1430  decode.loss_mask: 0.2238  decode.loss_dice: 0.2162  decode.d0.loss_cls: 0.9303  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.1458  decode.d1.loss_mask: 0.2203  decode.d1.loss_dice: 0.1990  decode.d2.loss_cls: 0.1206  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.2032  decode.d3.loss_cls: 0.1083  decode.d3.loss_mask: 0.2215  decode.d3.loss_dice: 0.2100  decode.d4.loss_cls: 0.1209  decode.d4.loss_mask: 0.2181  decode.d4.loss_dice: 0.1996  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.2219  decode.d5.loss_dice: 0.2205  decode.d6.loss_cls: 0.1149  decode.d6.loss_mask: 0.2242  decode.d6.loss_dice: 0.2114  decode.d7.loss_cls: 0.1217  decode.d7.loss_mask: 0.2229  decode.d7.loss_dice: 0.2077  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.2051
09/30 16:47:36 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:47:36 - mmengine - INFO - Iter(train) [ 64000/320000]  base_lr: 8.1805e-05 lr: 8.1805e-06  eta: 1 day, 6:54:59  time: 0.4376  data_time: 0.0097  memory: 5145  grad_norm: 37.8378  loss: 5.8861  decode.loss_cls: 0.0990  decode.loss_mask: 0.2119  decode.loss_dice: 0.1886  decode.d0.loss_cls: 0.9601  decode.d0.loss_mask: 0.2152  decode.d0.loss_dice: 0.1878  decode.d1.loss_cls: 0.0788  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1972  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.2138  decode.d2.loss_dice: 0.1896  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.2139  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.0858  decode.d4.loss_mask: 0.2140  decode.d4.loss_dice: 0.1946  decode.d5.loss_cls: 0.1198  decode.d5.loss_mask: 0.2145  decode.d5.loss_dice: 0.1949  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.2134  decode.d7.loss_dice: 0.1893  decode.d8.loss_cls: 0.1105  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.1867
09/30 16:47:58 - mmengine - INFO - Iter(train) [ 64050/320000]  base_lr: 8.1791e-05 lr: 8.1791e-06  eta: 1 day, 6:54:38  time: 0.4375  data_time: 0.0097  memory: 5129  grad_norm: 188.8658  loss: 8.4756  decode.loss_cls: 0.1715  decode.loss_mask: 0.3289  decode.loss_dice: 0.2577  decode.d0.loss_cls: 0.8935  decode.d0.loss_mask: 0.3038  decode.d0.loss_dice: 0.2781  decode.d1.loss_cls: 0.2160  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.2699  decode.d2.loss_cls: 0.1565  decode.d2.loss_mask: 0.3216  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.1974  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.2659  decode.d4.loss_cls: 0.1749  decode.d4.loss_mask: 0.3278  decode.d4.loss_dice: 0.2723  decode.d5.loss_cls: 0.2103  decode.d5.loss_mask: 0.3230  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.2312  decode.d6.loss_mask: 0.2914  decode.d6.loss_dice: 0.2536  decode.d7.loss_cls: 0.2444  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.2639  decode.d8.loss_cls: 0.2573  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.2420
09/30 16:48:20 - mmengine - INFO - Iter(train) [ 64100/320000]  base_lr: 8.1777e-05 lr: 8.1777e-06  eta: 1 day, 6:54:17  time: 0.4382  data_time: 0.0099  memory: 5129  grad_norm: 85.0066  loss: 5.0341  decode.loss_cls: 0.0455  decode.loss_mask: 0.1996  decode.loss_dice: 0.1711  decode.d0.loss_cls: 0.9024  decode.d0.loss_mask: 0.1908  decode.d0.loss_dice: 0.1679  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.1712  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.2010  decode.d2.loss_dice: 0.1815  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.1635  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.1928  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.2040  decode.d7.loss_dice: 0.1694  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.2171  decode.d8.loss_dice: 0.1737
09/30 16:48:42 - mmengine - INFO - Iter(train) [ 64150/320000]  base_lr: 8.1762e-05 lr: 8.1762e-06  eta: 1 day, 6:53:56  time: 0.4371  data_time: 0.0098  memory: 5120  grad_norm: 38.0427  loss: 5.7888  decode.loss_cls: 0.0208  decode.loss_mask: 0.2383  decode.loss_dice: 0.2020  decode.d0.loss_cls: 1.0351  decode.d0.loss_mask: 0.2393  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.1328  decode.d1.loss_mask: 0.2421  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2007  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.1909  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.2407  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.2406  decode.d6.loss_dice: 0.2065  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.2043
09/30 16:49:04 - mmengine - INFO - Iter(train) [ 64200/320000]  base_lr: 8.1748e-05 lr: 8.1748e-06  eta: 1 day, 6:53:35  time: 0.4375  data_time: 0.0098  memory: 5120  grad_norm: 75.4503  loss: 6.7699  decode.loss_cls: 0.0858  decode.loss_mask: 0.2824  decode.loss_dice: 0.2171  decode.d0.loss_cls: 0.7012  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.1608  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.2372  decode.d2.loss_cls: 0.1184  decode.d2.loss_mask: 0.2863  decode.d2.loss_dice: 0.2437  decode.d3.loss_cls: 0.1017  decode.d3.loss_mask: 0.2823  decode.d3.loss_dice: 0.2323  decode.d4.loss_cls: 0.0952  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.2291  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.2834  decode.d5.loss_dice: 0.2278  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.2792  decode.d6.loss_dice: 0.2357  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.0947  decode.d8.loss_mask: 0.2841  decode.d8.loss_dice: 0.2186
09/30 16:49:26 - mmengine - INFO - Iter(train) [ 64250/320000]  base_lr: 8.1734e-05 lr: 8.1734e-06  eta: 1 day, 6:53:13  time: 0.4372  data_time: 0.0096  memory: 5129  grad_norm: 43.5915  loss: 5.6651  decode.loss_cls: 0.0047  decode.loss_mask: 0.2518  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.7912  decode.d0.loss_mask: 0.2689  decode.d0.loss_dice: 0.2339  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.2145  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.2551  decode.d2.loss_dice: 0.2282  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.2522  decode.d3.loss_dice: 0.2228  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.2496  decode.d4.loss_dice: 0.2132  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.2282  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.2154  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2505  decode.d7.loss_dice: 0.2140  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2528  decode.d8.loss_dice: 0.2222
09/30 16:49:47 - mmengine - INFO - Iter(train) [ 64300/320000]  base_lr: 8.1719e-05 lr: 8.1719e-06  eta: 1 day, 6:52:52  time: 0.4378  data_time: 0.0096  memory: 5145  grad_norm: 62.5329  loss: 5.9612  decode.loss_cls: 0.0572  decode.loss_mask: 0.2194  decode.loss_dice: 0.2033  decode.d0.loss_cls: 1.0048  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.2273  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.2092  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0699  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.1978  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.2005  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.2104  decode.d4.loss_dice: 0.2326  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 0.1937  decode.d5.loss_dice: 0.2301  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.2092  decode.d6.loss_dice: 0.2347  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.2289  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.2143  decode.d8.loss_dice: 0.2230
09/30 16:50:09 - mmengine - INFO - Iter(train) [ 64350/320000]  base_lr: 8.1705e-05 lr: 8.1705e-06  eta: 1 day, 6:52:31  time: 0.4376  data_time: 0.0098  memory: 5145  grad_norm: 108.8388  loss: 7.7649  decode.loss_cls: 0.2717  decode.loss_mask: 0.2580  decode.loss_dice: 0.2028  decode.d0.loss_cls: 1.1926  decode.d0.loss_mask: 0.2175  decode.d0.loss_dice: 0.1821  decode.d1.loss_cls: 0.2766  decode.d1.loss_mask: 0.2179  decode.d1.loss_dice: 0.1931  decode.d2.loss_cls: 0.3285  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.1891  decode.d3.loss_cls: 0.2112  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.1649  decode.d4.loss_mask: 0.2636  decode.d4.loss_dice: 0.2050  decode.d5.loss_cls: 0.2283  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.1958  decode.d6.loss_cls: 0.2424  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.2599  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.1976  decode.d8.loss_cls: 0.3086  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1940
09/30 16:50:31 - mmengine - INFO - Iter(train) [ 64400/320000]  base_lr: 8.1690e-05 lr: 8.1690e-06  eta: 1 day, 6:52:10  time: 0.4366  data_time: 0.0097  memory: 5129  grad_norm: 74.1029  loss: 6.8069  decode.loss_cls: 0.2094  decode.loss_mask: 0.2173  decode.loss_dice: 0.1976  decode.d0.loss_cls: 0.8719  decode.d0.loss_mask: 0.2181  decode.d0.loss_dice: 0.1829  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 0.2301  decode.d1.loss_dice: 0.2009  decode.d2.loss_cls: 0.1420  decode.d2.loss_mask: 0.2200  decode.d2.loss_dice: 0.1938  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 0.2436  decode.d3.loss_dice: 0.2240  decode.d4.loss_cls: 0.1365  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.1864  decode.d5.loss_mask: 0.2362  decode.d5.loss_dice: 0.1994  decode.d6.loss_cls: 0.2044  decode.d6.loss_mask: 0.2209  decode.d6.loss_dice: 0.2122  decode.d7.loss_cls: 0.1771  decode.d7.loss_mask: 0.2347  decode.d7.loss_dice: 0.1978  decode.d8.loss_cls: 0.2046  decode.d8.loss_mask: 0.2513  decode.d8.loss_dice: 0.2317
09/30 16:50:53 - mmengine - INFO - Iter(train) [ 64450/320000]  base_lr: 8.1676e-05 lr: 8.1676e-06  eta: 1 day, 6:51:49  time: 0.4375  data_time: 0.0098  memory: 5129  grad_norm: 102.0763  loss: 6.4007  decode.loss_cls: 0.1249  decode.loss_mask: 0.2272  decode.loss_dice: 0.2056  decode.d0.loss_cls: 0.9355  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.2244  decode.d1.loss_cls: 0.1435  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.2200  decode.d2.loss_cls: 0.0665  decode.d2.loss_mask: 0.2415  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.1502  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2120  decode.d4.loss_cls: 0.0785  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2218  decode.d5.loss_cls: 0.1024  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.2132  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.0872  decode.d7.loss_mask: 0.2246  decode.d7.loss_dice: 0.2181  decode.d8.loss_cls: 0.1481  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.2096
09/30 16:51:15 - mmengine - INFO - Iter(train) [ 64500/320000]  base_lr: 8.1662e-05 lr: 8.1662e-06  eta: 1 day, 6:51:27  time: 0.4375  data_time: 0.0097  memory: 5145  grad_norm: 120.4436  loss: 6.2026  decode.loss_cls: 0.0482  decode.loss_mask: 0.2491  decode.loss_dice: 0.2246  decode.d0.loss_cls: 0.8439  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.2166  decode.d1.loss_cls: 0.1099  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.2265  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.0703  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.2251  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.2222  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2190  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.2231  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2227  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.2187
09/30 16:51:37 - mmengine - INFO - Iter(train) [ 64550/320000]  base_lr: 8.1647e-05 lr: 8.1647e-06  eta: 1 day, 6:51:06  time: 0.4377  data_time: 0.0097  memory: 5145  grad_norm: 29.8106  loss: 5.7220  decode.loss_cls: 0.0828  decode.loss_mask: 0.1902  decode.loss_dice: 0.1872  decode.d0.loss_cls: 0.9298  decode.d0.loss_mask: 0.1976  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.1391  decode.d1.loss_mask: 0.1904  decode.d1.loss_dice: 0.2105  decode.d2.loss_cls: 0.0980  decode.d2.loss_mask: 0.1903  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.1898  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.1978  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.1925  decode.d5.loss_dice: 0.2007  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.1730  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.1893  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.1113  decode.d8.loss_mask: 0.1877  decode.d8.loss_dice: 0.2052
09/30 16:51:59 - mmengine - INFO - Iter(train) [ 64600/320000]  base_lr: 8.1633e-05 lr: 8.1633e-06  eta: 1 day, 6:50:45  time: 0.4373  data_time: 0.0097  memory: 5119  grad_norm: 42.7101  loss: 5.4405  decode.loss_cls: 0.0855  decode.loss_mask: 0.1821  decode.loss_dice: 0.2141  decode.d0.loss_cls: 0.7816  decode.d0.loss_mask: 0.1837  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.0972  decode.d1.loss_mask: 0.1812  decode.d1.loss_dice: 0.2301  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 0.1811  decode.d2.loss_dice: 0.2256  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.1811  decode.d4.loss_dice: 0.2135  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.1817  decode.d5.loss_dice: 0.1855  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.1819  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.0589  decode.d7.loss_mask: 0.1816  decode.d7.loss_dice: 0.2184  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.1810  decode.d8.loss_dice: 0.2248
09/30 16:52:21 - mmengine - INFO - Iter(train) [ 64650/320000]  base_lr: 8.1618e-05 lr: 8.1618e-06  eta: 1 day, 6:50:24  time: 0.4382  data_time: 0.0098  memory: 5129  grad_norm: 17.6208  loss: 4.4905  decode.loss_cls: 0.0052  decode.loss_mask: 0.1827  decode.loss_dice: 0.1741  decode.d0.loss_cls: 0.8079  decode.d0.loss_mask: 0.1882  decode.d0.loss_dice: 0.1756  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.1829  decode.d1.loss_dice: 0.1709  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.1845  decode.d2.loss_dice: 0.1783  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.1855  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.1818  decode.d4.loss_dice: 0.1752  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.1858  decode.d5.loss_dice: 0.1800  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.1841  decode.d6.loss_dice: 0.1830  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.1750  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.1840  decode.d8.loss_dice: 0.1756
09/30 16:52:43 - mmengine - INFO - Iter(train) [ 64700/320000]  base_lr: 8.1604e-05 lr: 8.1604e-06  eta: 1 day, 6:50:03  time: 0.4372  data_time: 0.0096  memory: 5129  grad_norm: 22.4962  loss: 6.2194  decode.loss_cls: 0.1613  decode.loss_mask: 0.2089  decode.loss_dice: 0.2173  decode.d0.loss_cls: 0.7525  decode.d0.loss_mask: 0.2139  decode.d0.loss_dice: 0.2025  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.2084  decode.d2.loss_cls: 0.1342  decode.d2.loss_mask: 0.2090  decode.d2.loss_dice: 0.1955  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.2098  decode.d3.loss_dice: 0.2038  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 0.2115  decode.d5.loss_dice: 0.2169  decode.d6.loss_cls: 0.1312  decode.d6.loss_mask: 0.2090  decode.d6.loss_dice: 0.2152  decode.d7.loss_cls: 0.1682  decode.d7.loss_mask: 0.2098  decode.d7.loss_dice: 0.2105  decode.d8.loss_cls: 0.1598  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.2069
09/30 16:53:04 - mmengine - INFO - Iter(train) [ 64750/320000]  base_lr: 8.1590e-05 lr: 8.1590e-06  eta: 1 day, 6:49:41  time: 0.4375  data_time: 0.0099  memory: 5145  grad_norm: 21.9136  loss: 4.7061  decode.loss_cls: 0.0131  decode.loss_mask: 0.2083  decode.loss_dice: 0.1637  decode.d0.loss_cls: 0.8381  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.1707  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.1633  decode.d2.loss_cls: 0.0142  decode.d2.loss_mask: 0.2114  decode.d2.loss_dice: 0.1637  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.2093  decode.d4.loss_dice: 0.1642  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.1617  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.2090  decode.d6.loss_dice: 0.1621  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1633  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.1619
09/30 16:53:26 - mmengine - INFO - Iter(train) [ 64800/320000]  base_lr: 8.1575e-05 lr: 8.1575e-06  eta: 1 day, 6:49:20  time: 0.4376  data_time: 0.0098  memory: 5129  grad_norm: 22.2241  loss: 6.0104  decode.loss_cls: 0.0813  decode.loss_mask: 0.2164  decode.loss_dice: 0.2444  decode.d0.loss_cls: 0.7139  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2438  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 0.2154  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.0690  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.2422  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.2393  decode.d4.loss_cls: 0.0948  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.2387  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.2119  decode.d5.loss_dice: 0.2354  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.2210  decode.d6.loss_dice: 0.2405  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.2168  decode.d7.loss_dice: 0.2421  decode.d8.loss_cls: 0.0781  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.2396
09/30 16:53:48 - mmengine - INFO - Iter(train) [ 64850/320000]  base_lr: 8.1561e-05 lr: 8.1561e-06  eta: 1 day, 6:48:59  time: 0.4382  data_time: 0.0097  memory: 5145  grad_norm: 18.7473  loss: 4.7659  decode.loss_cls: 0.0736  decode.loss_mask: 0.1681  decode.loss_dice: 0.1614  decode.d0.loss_cls: 0.7903  decode.d0.loss_mask: 0.1708  decode.d0.loss_dice: 0.1681  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.1691  decode.d1.loss_dice: 0.1623  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.1668  decode.d2.loss_dice: 0.1601  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.1699  decode.d3.loss_dice: 0.1606  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.1682  decode.d4.loss_dice: 0.1608  decode.d5.loss_cls: 0.0796  decode.d5.loss_mask: 0.1684  decode.d5.loss_dice: 0.1596  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.1707  decode.d6.loss_dice: 0.1638  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.1688  decode.d7.loss_dice: 0.1614  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.1705  decode.d8.loss_dice: 0.1672
09/30 16:54:10 - mmengine - INFO - Iter(train) [ 64900/320000]  base_lr: 8.1547e-05 lr: 8.1547e-06  eta: 1 day, 6:48:38  time: 0.4369  data_time: 0.0098  memory: 5129  grad_norm: 67.4025  loss: 5.8604  decode.loss_cls: 0.0897  decode.loss_mask: 0.2278  decode.loss_dice: 0.2128  decode.d0.loss_cls: 0.8639  decode.d0.loss_mask: 0.2384  decode.d0.loss_dice: 0.2230  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.0420  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.2129  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.1992  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.2148  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.2158  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.2159  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2143  decode.d8.loss_cls: 0.0922  decode.d8.loss_mask: 0.2240  decode.d8.loss_dice: 0.2043
09/30 16:54:32 - mmengine - INFO - Iter(train) [ 64950/320000]  base_lr: 8.1532e-05 lr: 8.1532e-06  eta: 1 day, 6:48:17  time: 0.4372  data_time: 0.0096  memory: 5129  grad_norm: 51.3829  loss: 4.7740  decode.loss_cls: 0.0036  decode.loss_mask: 0.1775  decode.loss_dice: 0.1865  decode.d0.loss_cls: 0.9265  decode.d0.loss_mask: 0.1788  decode.d0.loss_dice: 0.1857  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.1860  decode.d1.loss_dice: 0.2062  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.1849  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.1892  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.1776  decode.d4.loss_dice: 0.1753  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.1773  decode.d5.loss_dice: 0.1812  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.1803  decode.d6.loss_dice: 0.1820  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.1774  decode.d7.loss_dice: 0.1855  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.1793  decode.d8.loss_dice: 0.1790
09/30 16:54:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 16:54:54 - mmengine - INFO - Iter(train) [ 65000/320000]  base_lr: 8.1518e-05 lr: 8.1518e-06  eta: 1 day, 6:47:55  time: 0.4375  data_time: 0.0097  memory: 5145  grad_norm: 20.5461  loss: 4.9912  decode.loss_cls: 0.0043  decode.loss_mask: 0.2037  decode.loss_dice: 0.2002  decode.d0.loss_cls: 0.9103  decode.d0.loss_mask: 0.2072  decode.d0.loss_dice: 0.1916  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.2039  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.2036  decode.d2.loss_dice: 0.1910  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.2042  decode.d4.loss_dice: 0.1987  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.2042  decode.d5.loss_dice: 0.1874  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.1960  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2031  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.2037  decode.d8.loss_dice: 0.1951
09/30 16:55:16 - mmengine - INFO - Iter(train) [ 65050/320000]  base_lr: 8.1503e-05 lr: 8.1503e-06  eta: 1 day, 6:47:34  time: 0.4385  data_time: 0.0100  memory: 5129  grad_norm: 63.8452  loss: 5.0427  decode.loss_cls: 0.0756  decode.loss_mask: 0.2209  decode.loss_dice: 0.1597  decode.d0.loss_cls: 0.7444  decode.d0.loss_mask: 0.2236  decode.d0.loss_dice: 0.1551  decode.d1.loss_cls: 0.0386  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1565  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.1585  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.1563  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.1545  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.1550  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.2196  decode.d6.loss_dice: 0.1596  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.1547  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.2169  decode.d8.loss_dice: 0.1558
09/30 16:55:38 - mmengine - INFO - Iter(train) [ 65100/320000]  base_lr: 8.1489e-05 lr: 8.1489e-06  eta: 1 day, 6:47:13  time: 0.4378  data_time: 0.0100  memory: 5129  grad_norm: 103.7630  loss: 6.5688  decode.loss_cls: 0.0793  decode.loss_mask: 0.2825  decode.loss_dice: 0.1940  decode.d0.loss_cls: 0.9535  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.1993  decode.d1.loss_cls: 0.0952  decode.d1.loss_mask: 0.2846  decode.d1.loss_dice: 0.2049  decode.d2.loss_cls: 0.0982  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.1957  decode.d3.loss_cls: 0.0891  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.1987  decode.d4.loss_cls: 0.0844  decode.d4.loss_mask: 0.2844  decode.d4.loss_dice: 0.1998  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.2001  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.2883  decode.d6.loss_dice: 0.1976  decode.d7.loss_cls: 0.0847  decode.d7.loss_mask: 0.2863  decode.d7.loss_dice: 0.1933  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.1991
09/30 16:56:00 - mmengine - INFO - Iter(train) [ 65150/320000]  base_lr: 8.1475e-05 lr: 8.1475e-06  eta: 1 day, 6:46:52  time: 0.4365  data_time: 0.0096  memory: 5129  grad_norm: 30.8623  loss: 5.6301  decode.loss_cls: 0.0786  decode.loss_mask: 0.2113  decode.loss_dice: 0.1567  decode.d0.loss_cls: 0.9769  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.1501  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.2115  decode.d1.loss_dice: 0.1483  decode.d2.loss_cls: 0.1026  decode.d2.loss_mask: 0.2149  decode.d2.loss_dice: 0.1467  decode.d3.loss_cls: 0.1085  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.1507  decode.d4.loss_cls: 0.1423  decode.d4.loss_mask: 0.2140  decode.d4.loss_dice: 0.1525  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.3073  decode.d5.loss_dice: 0.1610  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.3079  decode.d6.loss_dice: 0.1636  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.2388  decode.d7.loss_dice: 0.1650  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.2106  decode.d8.loss_dice: 0.1531
09/30 16:56:21 - mmengine - INFO - Iter(train) [ 65200/320000]  base_lr: 8.1460e-05 lr: 8.1460e-06  eta: 1 day, 6:46:31  time: 0.4380  data_time: 0.0097  memory: 5145  grad_norm: 47.7150  loss: 4.6968  decode.loss_cls: 0.0424  decode.loss_mask: 0.1742  decode.loss_dice: 0.1713  decode.d0.loss_cls: 0.8568  decode.d0.loss_mask: 0.1774  decode.d0.loss_dice: 0.1689  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.1741  decode.d1.loss_dice: 0.1670  decode.d2.loss_cls: 0.0498  decode.d2.loss_mask: 0.1730  decode.d2.loss_dice: 0.1616  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.1732  decode.d3.loss_dice: 0.1605  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.1720  decode.d4.loss_dice: 0.1602  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.1754  decode.d5.loss_dice: 0.1569  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.1755  decode.d6.loss_dice: 0.1644  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.1736  decode.d7.loss_dice: 0.1619  decode.d8.loss_cls: 0.0364  decode.d8.loss_mask: 0.1738  decode.d8.loss_dice: 0.1620
09/30 16:56:43 - mmengine - INFO - Iter(train) [ 65250/320000]  base_lr: 8.1446e-05 lr: 8.1446e-06  eta: 1 day, 6:46:10  time: 0.4378  data_time: 0.0098  memory: 5129  grad_norm: 21.8107  loss: 5.6846  decode.loss_cls: 0.0377  decode.loss_mask: 0.2429  decode.loss_dice: 0.2024  decode.d0.loss_cls: 0.9094  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.1997  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.2372  decode.d1.loss_dice: 0.1888  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2045  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.1943  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.2395  decode.d5.loss_dice: 0.1937  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.2379  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.1902  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.1957
09/30 16:57:05 - mmengine - INFO - Iter(train) [ 65300/320000]  base_lr: 8.1431e-05 lr: 8.1431e-06  eta: 1 day, 6:45:49  time: 0.4382  data_time: 0.0099  memory: 5129  grad_norm: 352.4051  loss: 8.9099  decode.loss_cls: 0.1751  decode.loss_mask: 0.3686  decode.loss_dice: 0.2718  decode.d0.loss_cls: 0.9463  decode.d0.loss_mask: 0.3077  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.2001  decode.d1.loss_mask: 0.3058  decode.d1.loss_dice: 0.2549  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.3273  decode.d2.loss_dice: 0.2758  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 0.3579  decode.d3.loss_dice: 0.2714  decode.d4.loss_cls: 0.2597  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.2826  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.2657  decode.d6.loss_mask: 0.3493  decode.d6.loss_dice: 0.2618  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.3630  decode.d7.loss_dice: 0.2869  decode.d8.loss_cls: 0.1943  decode.d8.loss_mask: 0.3532  decode.d8.loss_dice: 0.2700
09/30 16:57:27 - mmengine - INFO - Iter(train) [ 65350/320000]  base_lr: 8.1417e-05 lr: 8.1417e-06  eta: 1 day, 6:45:28  time: 0.4389  data_time: 0.0097  memory: 5129  grad_norm: 59.8805  loss: 6.6756  decode.loss_cls: 0.0635  decode.loss_mask: 0.3114  decode.loss_dice: 0.2997  decode.d0.loss_cls: 0.9090  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2412  decode.d1.loss_cls: 0.2150  decode.d1.loss_mask: 0.2401  decode.d1.loss_dice: 0.2360  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.2382  decode.d2.loss_dice: 0.2413  decode.d3.loss_cls: 0.1109  decode.d3.loss_mask: 0.2393  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.2571  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.2500  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2403  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.2042  decode.d8.loss_cls: 0.0812  decode.d8.loss_mask: 0.2605  decode.d8.loss_dice: 0.2891
09/30 16:57:49 - mmengine - INFO - Iter(train) [ 65400/320000]  base_lr: 8.1403e-05 lr: 8.1403e-06  eta: 1 day, 6:45:07  time: 0.4380  data_time: 0.0095  memory: 5129  grad_norm: 101.9818  loss: 5.8316  decode.loss_cls: 0.0519  decode.loss_mask: 0.1889  decode.loss_dice: 0.2222  decode.d0.loss_cls: 0.8339  decode.d0.loss_mask: 0.1907  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.1582  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2214  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.1915  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.0722  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.2362  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.1931  decode.d4.loss_dice: 0.2292  decode.d5.loss_cls: 0.1052  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.1020  decode.d6.loss_mask: 0.1928  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.2354  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.1914  decode.d8.loss_dice: 0.2359
09/30 16:58:11 - mmengine - INFO - Iter(train) [ 65450/320000]  base_lr: 8.1388e-05 lr: 8.1388e-06  eta: 1 day, 6:44:46  time: 0.4376  data_time: 0.0096  memory: 5129  grad_norm: 41.6713  loss: 5.3014  decode.loss_cls: 0.0523  decode.loss_mask: 0.1607  decode.loss_dice: 0.2082  decode.d0.loss_cls: 0.9634  decode.d0.loss_mask: 0.1633  decode.d0.loss_dice: 0.2169  decode.d1.loss_cls: 0.2110  decode.d1.loss_mask: 0.1624  decode.d1.loss_dice: 0.1825  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.1602  decode.d2.loss_dice: 0.1635  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.1581  decode.d3.loss_dice: 0.2036  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.1612  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.1582  decode.d5.loss_dice: 0.1790  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.1597  decode.d6.loss_dice: 0.1977  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.1592  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0778  decode.d8.loss_mask: 0.1602  decode.d8.loss_dice: 0.2103
09/30 16:58:33 - mmengine - INFO - Iter(train) [ 65500/320000]  base_lr: 8.1374e-05 lr: 8.1374e-06  eta: 1 day, 6:44:25  time: 0.4379  data_time: 0.0096  memory: 5145  grad_norm: 59.6209  loss: 5.6944  decode.loss_cls: 0.0665  decode.loss_mask: 0.2157  decode.loss_dice: 0.1846  decode.d0.loss_cls: 0.8481  decode.d0.loss_mask: 0.2170  decode.d0.loss_dice: 0.2051  decode.d1.loss_cls: 0.1539  decode.d1.loss_mask: 0.2156  decode.d1.loss_dice: 0.2018  decode.d2.loss_cls: 0.0968  decode.d2.loss_mask: 0.2135  decode.d2.loss_dice: 0.1925  decode.d3.loss_cls: 0.0545  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.1901  decode.d4.loss_cls: 0.0899  decode.d4.loss_mask: 0.2138  decode.d4.loss_dice: 0.1809  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.1881  decode.d6.loss_cls: 0.0933  decode.d6.loss_mask: 0.2155  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.0958  decode.d7.loss_mask: 0.2149  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.2134  decode.d8.loss_dice: 0.1990
09/30 16:58:55 - mmengine - INFO - Iter(train) [ 65550/320000]  base_lr: 8.1360e-05 lr: 8.1360e-06  eta: 1 day, 6:44:04  time: 0.4371  data_time: 0.0096  memory: 5129  grad_norm: 32.1206  loss: 5.4027  decode.loss_cls: 0.0425  decode.loss_mask: 0.1792  decode.loss_dice: 0.2342  decode.d0.loss_cls: 0.8474  decode.d0.loss_mask: 0.1782  decode.d0.loss_dice: 0.2202  decode.d1.loss_cls: 0.0892  decode.d1.loss_mask: 0.1770  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.0353  decode.d2.loss_mask: 0.1764  decode.d2.loss_dice: 0.2387  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.1792  decode.d3.loss_dice: 0.2479  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.1760  decode.d4.loss_dice: 0.2230  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 0.1780  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.1783  decode.d6.loss_dice: 0.2171  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.1780  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.1742  decode.d8.loss_dice: 0.2432
09/30 16:59:17 - mmengine - INFO - Iter(train) [ 65600/320000]  base_lr: 8.1345e-05 lr: 8.1345e-06  eta: 1 day, 6:43:42  time: 0.4378  data_time: 0.0098  memory: 5129  grad_norm: 63.2692  loss: 6.7315  decode.loss_cls: 0.0769  decode.loss_mask: 0.2971  decode.loss_dice: 0.2445  decode.d0.loss_cls: 0.8417  decode.d0.loss_mask: 0.2340  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.2427  decode.d2.loss_cls: 0.1230  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.2318  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.2457  decode.d4.loss_cls: 0.1408  decode.d4.loss_mask: 0.2309  decode.d4.loss_dice: 0.2435  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 0.2327  decode.d5.loss_dice: 0.2162  decode.d6.loss_cls: 0.1091  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.2486  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.2544
09/30 16:59:39 - mmengine - INFO - Iter(train) [ 65650/320000]  base_lr: 8.1331e-05 lr: 8.1331e-06  eta: 1 day, 6:43:21  time: 0.4381  data_time: 0.0096  memory: 5129  grad_norm: 87.2801  loss: 5.4899  decode.loss_cls: 0.0504  decode.loss_mask: 0.2135  decode.loss_dice: 0.1958  decode.d0.loss_cls: 0.8213  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.2196  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.2136  decode.d1.loss_dice: 0.1949  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 0.2286  decode.d2.loss_dice: 0.2181  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.2856  decode.d3.loss_dice: 0.2373  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 0.2148  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.2138  decode.d5.loss_dice: 0.2096  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.2094  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.2142  decode.d7.loss_dice: 0.2174  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.2164
09/30 17:00:01 - mmengine - INFO - Iter(train) [ 65700/320000]  base_lr: 8.1316e-05 lr: 8.1316e-06  eta: 1 day, 6:43:00  time: 0.4374  data_time: 0.0097  memory: 5129  grad_norm: 128.6029  loss: 7.1905  decode.loss_cls: 0.0182  decode.loss_mask: 0.3649  decode.loss_dice: 0.2421  decode.d0.loss_cls: 0.8101  decode.d0.loss_mask: 0.3746  decode.d0.loss_dice: 0.2298  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.3696  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.3651  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 0.3710  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.3679  decode.d4.loss_dice: 0.2448  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.3663  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.3670  decode.d6.loss_dice: 0.2488  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.3648  decode.d7.loss_dice: 0.2514  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.3635  decode.d8.loss_dice: 0.2497
09/30 17:00:23 - mmengine - INFO - Iter(train) [ 65750/320000]  base_lr: 8.1302e-05 lr: 8.1302e-06  eta: 1 day, 6:42:39  time: 0.4379  data_time: 0.0099  memory: 5145  grad_norm: 42.9531  loss: 8.3108  decode.loss_cls: 0.0976  decode.loss_mask: 0.2986  decode.loss_dice: 0.3571  decode.d0.loss_cls: 0.8169  decode.d0.loss_mask: 0.3011  decode.d0.loss_dice: 0.3330  decode.d1.loss_cls: 0.1509  decode.d1.loss_mask: 0.2995  decode.d1.loss_dice: 0.3414  decode.d2.loss_cls: 0.1474  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.3126  decode.d3.loss_cls: 0.1196  decode.d3.loss_mask: 0.3007  decode.d3.loss_dice: 0.3748  decode.d4.loss_cls: 0.1011  decode.d4.loss_mask: 0.3024  decode.d4.loss_dice: 0.3099  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.2939  decode.d5.loss_dice: 0.3114  decode.d6.loss_cls: 0.1071  decode.d6.loss_mask: 0.2989  decode.d6.loss_dice: 0.3344  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 0.3033  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.1598  decode.d8.loss_mask: 0.3011  decode.d8.loss_dice: 0.3284
09/30 17:00:44 - mmengine - INFO - Iter(train) [ 65800/320000]  base_lr: 8.1288e-05 lr: 8.1288e-06  eta: 1 day, 6:42:18  time: 0.4380  data_time: 0.0099  memory: 5129  grad_norm: 54.5224  loss: 6.9755  decode.loss_cls: 0.0967  decode.loss_mask: 0.3135  decode.loss_dice: 0.1975  decode.d0.loss_cls: 0.8908  decode.d0.loss_mask: 0.3175  decode.d0.loss_dice: 0.2116  decode.d1.loss_cls: 0.1281  decode.d1.loss_mask: 0.3115  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.1351  decode.d2.loss_mask: 0.3034  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.1190  decode.d3.loss_mask: 0.3165  decode.d3.loss_dice: 0.2008  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.3046  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.1965  decode.d6.loss_cls: 0.1119  decode.d6.loss_mask: 0.3085  decode.d6.loss_dice: 0.2023  decode.d7.loss_cls: 0.1046  decode.d7.loss_mask: 0.3011  decode.d7.loss_dice: 0.1919  decode.d8.loss_cls: 0.1084  decode.d8.loss_mask: 0.3126  decode.d8.loss_dice: 0.1943
09/30 17:01:06 - mmengine - INFO - Iter(train) [ 65850/320000]  base_lr: 8.1273e-05 lr: 8.1273e-06  eta: 1 day, 6:41:57  time: 0.4375  data_time: 0.0097  memory: 5120  grad_norm: 26.3247  loss: 5.7963  decode.loss_cls: 0.0044  decode.loss_mask: 0.2784  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.7662  decode.d0.loss_mask: 0.2868  decode.d0.loss_dice: 0.2129  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.2161  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.2843  decode.d2.loss_dice: 0.2122  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2857  decode.d3.loss_dice: 0.2130  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.2858  decode.d4.loss_dice: 0.2183  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.2838  decode.d5.loss_dice: 0.2148  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.2144  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2844  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2824  decode.d8.loss_dice: 0.2197
09/30 17:01:28 - mmengine - INFO - Iter(train) [ 65900/320000]  base_lr: 8.1259e-05 lr: 8.1259e-06  eta: 1 day, 6:41:35  time: 0.4375  data_time: 0.0095  memory: 5120  grad_norm: 41.0448  loss: 5.3552  decode.loss_cls: 0.1409  decode.loss_mask: 0.1993  decode.loss_dice: 0.1407  decode.d0.loss_cls: 0.9882  decode.d0.loss_mask: 0.2055  decode.d0.loss_dice: 0.1373  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.1412  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.2009  decode.d2.loss_dice: 0.1392  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.2006  decode.d3.loss_dice: 0.1372  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.1991  decode.d4.loss_dice: 0.1396  decode.d5.loss_cls: 0.0889  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.1417  decode.d6.loss_cls: 0.1176  decode.d6.loss_mask: 0.1965  decode.d6.loss_dice: 0.1466  decode.d7.loss_cls: 0.1448  decode.d7.loss_mask: 0.2040  decode.d7.loss_dice: 0.1441  decode.d8.loss_cls: 0.1361  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.1497
09/30 17:01:50 - mmengine - INFO - Iter(train) [ 65950/320000]  base_lr: 8.1244e-05 lr: 8.1244e-06  eta: 1 day, 6:41:14  time: 0.4373  data_time: 0.0096  memory: 5129  grad_norm: 47.7974  loss: 6.1555  decode.loss_cls: 0.0977  decode.loss_mask: 0.2653  decode.loss_dice: 0.1771  decode.d0.loss_cls: 0.8586  decode.d0.loss_mask: 0.2709  decode.d0.loss_dice: 0.2020  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.2719  decode.d1.loss_dice: 0.1781  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.1743  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.2024  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.1761  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.2606  decode.d5.loss_dice: 0.1746  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.2616  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.1969  decode.d8.loss_cls: 0.1021  decode.d8.loss_mask: 0.2646  decode.d8.loss_dice: 0.1758
09/30 17:02:12 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:02:12 - mmengine - INFO - Iter(train) [ 66000/320000]  base_lr: 8.1230e-05 lr: 8.1230e-06  eta: 1 day, 6:40:53  time: 0.4379  data_time: 0.0097  memory: 5129  grad_norm: 104.9295  loss: 6.5353  decode.loss_cls: 0.0250  decode.loss_mask: 0.3028  decode.loss_dice: 0.2453  decode.d0.loss_cls: 0.7191  decode.d0.loss_mask: 0.3078  decode.d0.loss_dice: 0.2465  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.0446  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.2501  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.2984  decode.d3.loss_dice: 0.2495  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.3002  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.3006  decode.d5.loss_dice: 0.2489  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.3002  decode.d6.loss_dice: 0.2475  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.3001  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.0235  decode.d8.loss_mask: 0.3024  decode.d8.loss_dice: 0.2614
09/30 17:02:34 - mmengine - INFO - Iter(train) [ 66050/320000]  base_lr: 8.1216e-05 lr: 8.1216e-06  eta: 1 day, 6:40:32  time: 0.4376  data_time: 0.0097  memory: 5129  grad_norm: 126.9674  loss: 6.1058  decode.loss_cls: 0.1181  decode.loss_mask: 0.1858  decode.loss_dice: 0.2304  decode.d0.loss_cls: 0.7735  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.2401  decode.d1.loss_cls: 0.2306  decode.d1.loss_mask: 0.1894  decode.d1.loss_dice: 0.2259  decode.d2.loss_cls: 0.1887  decode.d2.loss_mask: 0.1873  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.1440  decode.d3.loss_mask: 0.1865  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.1092  decode.d4.loss_mask: 0.1897  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.1239  decode.d5.loss_mask: 0.1886  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.1864  decode.d6.loss_dice: 0.2207  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.1886  decode.d7.loss_dice: 0.2341  decode.d8.loss_cls: 0.0811  decode.d8.loss_mask: 0.1898  decode.d8.loss_dice: 0.2314
09/30 17:02:56 - mmengine - INFO - Iter(train) [ 66100/320000]  base_lr: 8.1201e-05 lr: 8.1201e-06  eta: 1 day, 6:40:11  time: 0.4381  data_time: 0.0096  memory: 5145  grad_norm: 59.9105  loss: 6.7261  decode.loss_cls: 0.0889  decode.loss_mask: 0.3090  decode.loss_dice: 0.2111  decode.d0.loss_cls: 0.9200  decode.d0.loss_mask: 0.2938  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.2080  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.2014  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.3554  decode.d3.loss_dice: 0.1925  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.3547  decode.d4.loss_dice: 0.1983  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.2090  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.2979  decode.d6.loss_dice: 0.2049  decode.d7.loss_cls: 0.1125  decode.d7.loss_mask: 0.3002  decode.d7.loss_dice: 0.2065  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.3536  decode.d8.loss_dice: 0.1905
09/30 17:03:18 - mmengine - INFO - Iter(train) [ 66150/320000]  base_lr: 8.1187e-05 lr: 8.1187e-06  eta: 1 day, 6:39:50  time: 0.4378  data_time: 0.0097  memory: 5129  grad_norm: 28.2195  loss: 5.4703  decode.loss_cls: 0.0113  decode.loss_mask: 0.2557  decode.loss_dice: 0.2055  decode.d0.loss_cls: 0.7841  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.1968  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.2018  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.1933  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2584  decode.d5.loss_dice: 0.1939  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.1996  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.1928  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.2575  decode.d8.loss_dice: 0.2051
09/30 17:03:40 - mmengine - INFO - Iter(train) [ 66200/320000]  base_lr: 8.1172e-05 lr: 8.1172e-06  eta: 1 day, 6:39:28  time: 0.4378  data_time: 0.0097  memory: 5120  grad_norm: 44.6898  loss: 6.3015  decode.loss_cls: 0.1071  decode.loss_mask: 0.2156  decode.loss_dice: 0.2955  decode.d0.loss_cls: 0.7452  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.2423  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.2113  decode.d1.loss_dice: 0.2585  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.2124  decode.d2.loss_dice: 0.2567  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.2126  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.0804  decode.d4.loss_mask: 0.2103  decode.d4.loss_dice: 0.2355  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.2105  decode.d5.loss_dice: 0.2391  decode.d6.loss_cls: 0.1081  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.2654  decode.d7.loss_cls: 0.1344  decode.d7.loss_mask: 0.2124  decode.d7.loss_dice: 0.2677  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.2687
09/30 17:04:02 - mmengine - INFO - Iter(train) [ 66250/320000]  base_lr: 8.1158e-05 lr: 8.1158e-06  eta: 1 day, 6:39:07  time: 0.4384  data_time: 0.0095  memory: 5129  grad_norm: 23.2420  loss: 4.1121  decode.loss_cls: 0.0063  decode.loss_mask: 0.1718  decode.loss_dice: 0.1533  decode.d0.loss_cls: 0.8256  decode.d0.loss_mask: 0.1702  decode.d0.loss_dice: 0.1484  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.1708  decode.d1.loss_dice: 0.1463  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.1720  decode.d2.loss_dice: 0.1490  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.1725  decode.d3.loss_dice: 0.1491  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.1711  decode.d4.loss_dice: 0.1522  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.1679  decode.d5.loss_dice: 0.1498  decode.d6.loss_cls: 0.0208  decode.d6.loss_mask: 0.1701  decode.d6.loss_dice: 0.1487  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.1719  decode.d7.loss_dice: 0.1530  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.1678  decode.d8.loss_dice: 0.1516
09/30 17:04:23 - mmengine - INFO - Iter(train) [ 66300/320000]  base_lr: 8.1144e-05 lr: 8.1144e-06  eta: 1 day, 6:38:46  time: 0.4363  data_time: 0.0097  memory: 5120  grad_norm: 48.7797  loss: 5.9794  decode.loss_cls: 0.0491  decode.loss_mask: 0.2739  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.8406  decode.d0.loss_mask: 0.2731  decode.d0.loss_dice: 0.1870  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.2721  decode.d1.loss_dice: 0.1951  decode.d2.loss_cls: 0.0607  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.1958  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.2699  decode.d3.loss_dice: 0.1943  decode.d4.loss_cls: 0.0527  decode.d4.loss_mask: 0.2755  decode.d4.loss_dice: 0.2023  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.2723  decode.d5.loss_dice: 0.1953  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.1938  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.2729  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.2729  decode.d8.loss_dice: 0.1979
09/30 17:04:45 - mmengine - INFO - Iter(train) [ 66350/320000]  base_lr: 8.1129e-05 lr: 8.1129e-06  eta: 1 day, 6:38:25  time: 0.4389  data_time: 0.0099  memory: 5129  grad_norm: 54.9121  loss: 5.6124  decode.loss_cls: 0.0699  decode.loss_mask: 0.2036  decode.loss_dice: 0.1925  decode.d0.loss_cls: 0.7931  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.2053  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.2048  decode.d1.loss_dice: 0.2109  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.2219  decode.d3.loss_cls: 0.0479  decode.d3.loss_mask: 0.2048  decode.d3.loss_dice: 0.2173  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.2076  decode.d4.loss_dice: 0.2312  decode.d5.loss_cls: 0.1027  decode.d5.loss_mask: 0.2042  decode.d5.loss_dice: 0.2158  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2054  decode.d6.loss_dice: 0.2215  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.2167  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.2056  decode.d8.loss_dice: 0.1974
09/30 17:05:07 - mmengine - INFO - Iter(train) [ 66400/320000]  base_lr: 8.1115e-05 lr: 8.1115e-06  eta: 1 day, 6:38:04  time: 0.4373  data_time: 0.0098  memory: 5129  grad_norm: 67.5989  loss: 5.7768  decode.loss_cls: 0.0229  decode.loss_mask: 0.2556  decode.loss_dice: 0.1948  decode.d0.loss_cls: 0.8536  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.1919  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.1906  decode.d2.loss_cls: 0.1055  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.1850  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.1934  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.1920  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.2539  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 0.2415  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.2577  decode.d8.loss_dice: 0.1903
09/30 17:05:29 - mmengine - INFO - Iter(train) [ 66450/320000]  base_lr: 8.1100e-05 lr: 8.1100e-06  eta: 1 day, 6:37:43  time: 0.4381  data_time: 0.0097  memory: 5120  grad_norm: 225.5997  loss: 10.4040  decode.loss_cls: 0.2754  decode.loss_mask: 0.2757  decode.loss_dice: 0.4397  decode.d0.loss_cls: 1.0185  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.4699  decode.d1.loss_cls: 0.3055  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.4406  decode.d2.loss_cls: 0.2256  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.4348  decode.d3.loss_cls: 0.2418  decode.d3.loss_mask: 0.2700  decode.d3.loss_dice: 0.4651  decode.d4.loss_cls: 0.2224  decode.d4.loss_mask: 0.2678  decode.d4.loss_dice: 0.4348  decode.d5.loss_cls: 0.2409  decode.d5.loss_mask: 0.2711  decode.d5.loss_dice: 0.4175  decode.d6.loss_cls: 0.2061  decode.d6.loss_mask: 0.2664  decode.d6.loss_dice: 0.4479  decode.d7.loss_cls: 0.2429  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.4486  decode.d8.loss_cls: 0.2798  decode.d8.loss_mask: 0.2702  decode.d8.loss_dice: 0.4594
09/30 17:05:51 - mmengine - INFO - Iter(train) [ 66500/320000]  base_lr: 8.1086e-05 lr: 8.1086e-06  eta: 1 day, 6:37:22  time: 0.4371  data_time: 0.0097  memory: 5129  grad_norm: 23.6004  loss: 5.8753  decode.loss_cls: 0.1264  decode.loss_mask: 0.2103  decode.loss_dice: 0.2017  decode.d0.loss_cls: 0.9217  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0675  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.1948  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.1890  decode.d3.loss_cls: 0.0947  decode.d3.loss_mask: 0.2081  decode.d3.loss_dice: 0.1706  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.2103  decode.d4.loss_dice: 0.1840  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.2098  decode.d5.loss_dice: 0.1747  decode.d6.loss_cls: 0.1212  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.1920  decode.d7.loss_cls: 0.1379  decode.d7.loss_mask: 0.2105  decode.d7.loss_dice: 0.1838  decode.d8.loss_cls: 0.1382  decode.d8.loss_mask: 0.2115  decode.d8.loss_dice: 0.2012
09/30 17:06:13 - mmengine - INFO - Iter(train) [ 66550/320000]  base_lr: 8.1072e-05 lr: 8.1072e-06  eta: 1 day, 6:37:00  time: 0.4388  data_time: 0.0098  memory: 5120  grad_norm: 21.0142  loss: 4.1332  decode.loss_cls: 0.0079  decode.loss_mask: 0.1732  decode.loss_dice: 0.1730  decode.d0.loss_cls: 0.7180  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.1749  decode.d1.loss_dice: 0.1531  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.1743  decode.d2.loss_dice: 0.1496  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.1734  decode.d3.loss_dice: 0.1599  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.1746  decode.d4.loss_dice: 0.1526  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.1714  decode.d5.loss_dice: 0.1612  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.1729  decode.d6.loss_dice: 0.1465  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.1731  decode.d7.loss_dice: 0.1664  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.1750  decode.d8.loss_dice: 0.1578
09/30 17:06:35 - mmengine - INFO - Iter(train) [ 66600/320000]  base_lr: 8.1057e-05 lr: 8.1057e-06  eta: 1 day, 6:36:39  time: 0.4379  data_time: 0.0097  memory: 5129  grad_norm: 20.8715  loss: 5.0705  decode.loss_cls: 0.0132  decode.loss_mask: 0.2208  decode.loss_dice: 0.1794  decode.d0.loss_cls: 0.8964  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.1883  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.2205  decode.d1.loss_dice: 0.1856  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.1802  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.1828  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.1807  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.2176  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.2197  decode.d7.loss_dice: 0.1877  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.1828
09/30 17:06:57 - mmengine - INFO - Iter(train) [ 66650/320000]  base_lr: 8.1043e-05 lr: 8.1043e-06  eta: 1 day, 6:36:18  time: 0.4364  data_time: 0.0093  memory: 5129  grad_norm: 138.3489  loss: 7.4151  decode.loss_cls: 0.1447  decode.loss_mask: 0.4205  decode.loss_dice: 0.2111  decode.d0.loss_cls: 0.9083  decode.d0.loss_mask: 0.2983  decode.d0.loss_dice: 0.2191  decode.d1.loss_cls: 0.1677  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.1872  decode.d2.loss_cls: 0.1545  decode.d2.loss_mask: 0.2765  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.1435  decode.d3.loss_mask: 0.2863  decode.d3.loss_dice: 0.2137  decode.d4.loss_cls: 0.1572  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.1899  decode.d5.loss_cls: 0.0889  decode.d5.loss_mask: 0.3892  decode.d5.loss_dice: 0.1918  decode.d6.loss_cls: 0.1773  decode.d6.loss_mask: 0.3420  decode.d6.loss_dice: 0.2097  decode.d7.loss_cls: 0.1685  decode.d7.loss_mask: 0.3010  decode.d7.loss_dice: 0.1960  decode.d8.loss_cls: 0.1567  decode.d8.loss_mask: 0.3018  decode.d8.loss_dice: 0.2113
09/30 17:07:19 - mmengine - INFO - Iter(train) [ 66700/320000]  base_lr: 8.1029e-05 lr: 8.1029e-06  eta: 1 day, 6:35:57  time: 0.4370  data_time: 0.0094  memory: 5145  grad_norm: 46.4949  loss: 4.5004  decode.loss_cls: 0.0287  decode.loss_mask: 0.1860  decode.loss_dice: 0.1417  decode.d0.loss_cls: 0.7645  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.1480  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.1863  decode.d1.loss_dice: 0.1482  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.1855  decode.d2.loss_dice: 0.1435  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.1743  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.1599  decode.d5.loss_cls: 0.1063  decode.d5.loss_mask: 0.1835  decode.d5.loss_dice: 0.1477  decode.d6.loss_cls: 0.0271  decode.d6.loss_mask: 0.1825  decode.d6.loss_dice: 0.1480  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.1854  decode.d7.loss_dice: 0.1475  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.1842  decode.d8.loss_dice: 0.1426
09/30 17:07:41 - mmengine - INFO - Iter(train) [ 66750/320000]  base_lr: 8.1014e-05 lr: 8.1014e-06  eta: 1 day, 6:35:35  time: 0.4374  data_time: 0.0096  memory: 5129  grad_norm: 22.3914  loss: 5.0743  decode.loss_cls: 0.0192  decode.loss_mask: 0.2081  decode.loss_dice: 0.1760  decode.d0.loss_cls: 0.8443  decode.d0.loss_mask: 0.2099  decode.d0.loss_dice: 0.1711  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.2061  decode.d2.loss_dice: 0.1687  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.2085  decode.d3.loss_dice: 0.1667  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.1716  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.2049  decode.d5.loss_dice: 0.1648  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.2076  decode.d6.loss_dice: 0.1682  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.2072  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.1656
09/30 17:08:02 - mmengine - INFO - Iter(train) [ 66800/320000]  base_lr: 8.1000e-05 lr: 8.1000e-06  eta: 1 day, 6:35:14  time: 0.4385  data_time: 0.0096  memory: 5145  grad_norm: 65.3428  loss: 4.9721  decode.loss_cls: 0.0498  decode.loss_mask: 0.1880  decode.loss_dice: 0.1776  decode.d0.loss_cls: 0.7867  decode.d0.loss_mask: 0.1939  decode.d0.loss_dice: 0.1764  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.1932  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.1897  decode.d3.loss_dice: 0.1562  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.1903  decode.d4.loss_dice: 0.1736  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.1913  decode.d5.loss_dice: 0.1869  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.1923  decode.d6.loss_dice: 0.1808  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.1917  decode.d7.loss_dice: 0.1848  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.1887  decode.d8.loss_dice: 0.1795
09/30 17:08:24 - mmengine - INFO - Iter(train) [ 66850/320000]  base_lr: 8.0985e-05 lr: 8.0985e-06  eta: 1 day, 6:34:53  time: 0.4373  data_time: 0.0097  memory: 5120  grad_norm: 31.4385  loss: 5.0802  decode.loss_cls: 0.0213  decode.loss_mask: 0.2180  decode.loss_dice: 0.1854  decode.d0.loss_cls: 0.8795  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.1997  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.2168  decode.d1.loss_dice: 0.1856  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.1817  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.2148  decode.d4.loss_dice: 0.1766  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.1779  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.1795  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.1747  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.2195  decode.d8.loss_dice: 0.1828
09/30 17:08:46 - mmengine - INFO - Iter(train) [ 66900/320000]  base_lr: 8.0971e-05 lr: 8.0971e-06  eta: 1 day, 6:34:32  time: 0.4386  data_time: 0.0096  memory: 5145  grad_norm: 105.3204  loss: 5.7770  decode.loss_cls: 0.0719  decode.loss_mask: 0.2258  decode.loss_dice: 0.2114  decode.d0.loss_cls: 0.7874  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.2142  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.2025  decode.d2.loss_cls: 0.1012  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.2012  decode.d3.loss_cls: 0.0921  decode.d3.loss_mask: 0.2269  decode.d3.loss_dice: 0.2029  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2065  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.2234  decode.d5.loss_dice: 0.1976  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.2011  decode.d7.loss_cls: 0.0890  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.1990  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.2050
09/30 17:09:08 - mmengine - INFO - Iter(train) [ 66950/320000]  base_lr: 8.0957e-05 lr: 8.0957e-06  eta: 1 day, 6:34:11  time: 0.4382  data_time: 0.0098  memory: 5120  grad_norm: 23.9474  loss: 4.8034  decode.loss_cls: 0.0027  decode.loss_mask: 0.2283  decode.loss_dice: 0.1748  decode.d0.loss_cls: 0.7572  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.1727  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.1722  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.1700  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.2266  decode.d3.loss_dice: 0.1706  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.2282  decode.d4.loss_dice: 0.1735  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.2279  decode.d5.loss_dice: 0.1694  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1747  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2298  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.1710
09/30 17:09:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:09:30 - mmengine - INFO - Iter(train) [ 67000/320000]  base_lr: 8.0942e-05 lr: 8.0942e-06  eta: 1 day, 6:33:49  time: 0.4390  data_time: 0.0095  memory: 5129  grad_norm: 79.9636  loss: 6.8474  decode.loss_cls: 0.1499  decode.loss_mask: 0.2491  decode.loss_dice: 0.2206  decode.d0.loss_cls: 0.9314  decode.d0.loss_mask: 0.2570  decode.d0.loss_dice: 0.2143  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2204  decode.d2.loss_cls: 0.1512  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2288  decode.d3.loss_cls: 0.1087  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.2215  decode.d4.loss_cls: 0.1357  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2251  decode.d6.loss_cls: 0.1435  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.2220  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.2531  decode.d7.loss_dice: 0.2294  decode.d8.loss_cls: 0.1088  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.2138
09/30 17:09:52 - mmengine - INFO - Iter(train) [ 67050/320000]  base_lr: 8.0928e-05 lr: 8.0928e-06  eta: 1 day, 6:33:29  time: 0.4380  data_time: 0.0098  memory: 5145  grad_norm: 62.4967  loss: 6.9737  decode.loss_cls: 0.1429  decode.loss_mask: 0.1979  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.9826  decode.d0.loss_mask: 0.2005  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1671  decode.d1.loss_mask: 0.1943  decode.d1.loss_dice: 0.2388  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.1953  decode.d2.loss_dice: 0.2458  decode.d3.loss_cls: 0.1541  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.2620  decode.d4.loss_cls: 0.1474  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.2757  decode.d5.loss_cls: 0.1891  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.2893  decode.d6.loss_cls: 0.1434  decode.d6.loss_mask: 0.1963  decode.d6.loss_dice: 0.2549  decode.d7.loss_cls: 0.1541  decode.d7.loss_mask: 0.1973  decode.d7.loss_dice: 0.2846  decode.d8.loss_cls: 0.1258  decode.d8.loss_mask: 0.1977  decode.d8.loss_dice: 0.2914
09/30 17:10:14 - mmengine - INFO - Iter(train) [ 67100/320000]  base_lr: 8.0913e-05 lr: 8.0913e-06  eta: 1 day, 6:33:08  time: 0.4398  data_time: 0.0097  memory: 5129  grad_norm: 60.1557  loss: 6.0064  decode.loss_cls: 0.1488  decode.loss_mask: 0.1784  decode.loss_dice: 0.1804  decode.d0.loss_cls: 1.0471  decode.d0.loss_mask: 0.1783  decode.d0.loss_dice: 0.1749  decode.d1.loss_cls: 0.1753  decode.d1.loss_mask: 0.1766  decode.d1.loss_dice: 0.1720  decode.d2.loss_cls: 0.1475  decode.d2.loss_mask: 0.1796  decode.d2.loss_dice: 0.1713  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 0.1803  decode.d3.loss_dice: 0.1802  decode.d4.loss_cls: 0.1501  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.1676  decode.d5.loss_cls: 0.1623  decode.d5.loss_mask: 0.1789  decode.d5.loss_dice: 0.1697  decode.d6.loss_cls: 0.1430  decode.d6.loss_mask: 0.1802  decode.d6.loss_dice: 0.1792  decode.d7.loss_cls: 0.1413  decode.d7.loss_mask: 0.1810  decode.d7.loss_dice: 0.1731  decode.d8.loss_cls: 0.2121  decode.d8.loss_mask: 0.1821  decode.d8.loss_dice: 0.1596
09/30 17:10:36 - mmengine - INFO - Iter(train) [ 67150/320000]  base_lr: 8.0899e-05 lr: 8.0899e-06  eta: 1 day, 6:32:47  time: 0.4381  data_time: 0.0098  memory: 5129  grad_norm: 147.8841  loss: 9.6951  decode.loss_cls: 0.1741  decode.loss_mask: 0.4577  decode.loss_dice: 0.2298  decode.d0.loss_cls: 0.9134  decode.d0.loss_mask: 0.4437  decode.d0.loss_dice: 0.2270  decode.d1.loss_cls: 0.2057  decode.d1.loss_mask: 0.4677  decode.d1.loss_dice: 0.2299  decode.d2.loss_cls: 0.1704  decode.d2.loss_mask: 0.4498  decode.d2.loss_dice: 0.2349  decode.d3.loss_cls: 0.1833  decode.d3.loss_mask: 0.4788  decode.d3.loss_dice: 0.2459  decode.d4.loss_cls: 0.2196  decode.d4.loss_mask: 0.4951  decode.d4.loss_dice: 0.2585  decode.d5.loss_cls: 0.2350  decode.d5.loss_mask: 0.5248  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.2139  decode.d6.loss_mask: 0.4530  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.1948  decode.d7.loss_mask: 0.4526  decode.d7.loss_dice: 0.2224  decode.d8.loss_cls: 0.1973  decode.d8.loss_mask: 0.4550  decode.d8.loss_dice: 0.2186
09/30 17:10:58 - mmengine - INFO - Iter(train) [ 67200/320000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 1 day, 6:32:25  time: 0.4383  data_time: 0.0096  memory: 5145  grad_norm: 24.3355  loss: 5.2772  decode.loss_cls: 0.0838  decode.loss_mask: 0.1806  decode.loss_dice: 0.1848  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1967  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.1810  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.1786  decode.d2.loss_dice: 0.1848  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.1795  decode.d3.loss_dice: 0.1900  decode.d4.loss_cls: 0.0769  decode.d4.loss_mask: 0.1788  decode.d4.loss_dice: 0.1881  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.1774  decode.d5.loss_dice: 0.1801  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.1802  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.0818  decode.d7.loss_mask: 0.1814  decode.d7.loss_dice: 0.1960  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.1795  decode.d8.loss_dice: 0.1929
09/30 17:11:20 - mmengine - INFO - Iter(train) [ 67250/320000]  base_lr: 8.0870e-05 lr: 8.0870e-06  eta: 1 day, 6:32:04  time: 0.4383  data_time: 0.0099  memory: 5120  grad_norm: 96.6780  loss: 7.6707  decode.loss_cls: 0.0912  decode.loss_mask: 0.3530  decode.loss_dice: 0.2544  decode.d0.loss_cls: 0.8267  decode.d0.loss_mask: 0.3370  decode.d0.loss_dice: 0.2506  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.3467  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.3464  decode.d2.loss_dice: 0.2443  decode.d3.loss_cls: 0.0993  decode.d3.loss_mask: 0.3431  decode.d3.loss_dice: 0.2535  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.3423  decode.d4.loss_dice: 0.2500  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.3403  decode.d5.loss_dice: 0.2390  decode.d6.loss_cls: 0.1036  decode.d6.loss_mask: 0.3417  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.3436  decode.d7.loss_dice: 0.2485  decode.d8.loss_cls: 0.0970  decode.d8.loss_mask: 0.3471  decode.d8.loss_dice: 0.2511
09/30 17:11:42 - mmengine - INFO - Iter(train) [ 67300/320000]  base_lr: 8.0856e-05 lr: 8.0856e-06  eta: 1 day, 6:31:43  time: 0.4377  data_time: 0.0099  memory: 5145  grad_norm: 43.5526  loss: 5.7741  decode.loss_cls: 0.0633  decode.loss_mask: 0.2410  decode.loss_dice: 0.1795  decode.d0.loss_cls: 1.0049  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.1860  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.1773  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.2454  decode.d2.loss_dice: 0.1801  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.1803  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.2472  decode.d5.loss_dice: 0.1797  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.2414  decode.d6.loss_dice: 0.1739  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.2437  decode.d7.loss_dice: 0.1864  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.1917
09/30 17:12:04 - mmengine - INFO - Iter(train) [ 67350/320000]  base_lr: 8.0841e-05 lr: 8.0841e-06  eta: 1 day, 6:31:22  time: 0.4384  data_time: 0.0099  memory: 5120  grad_norm: 70.8297  loss: 5.9105  decode.loss_cls: 0.0806  decode.loss_mask: 0.1794  decode.loss_dice: 0.1675  decode.d0.loss_cls: 0.8571  decode.d0.loss_mask: 0.1831  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.1485  decode.d1.loss_mask: 0.1809  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 0.1819  decode.d2.loss_dice: 0.2584  decode.d3.loss_cls: 0.1609  decode.d3.loss_mask: 0.1820  decode.d3.loss_dice: 0.2536  decode.d4.loss_cls: 0.1679  decode.d4.loss_mask: 0.1794  decode.d4.loss_dice: 0.2553  decode.d5.loss_cls: 0.1214  decode.d5.loss_mask: 0.1758  decode.d5.loss_dice: 0.1523  decode.d6.loss_cls: 0.1066  decode.d6.loss_mask: 0.1791  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.1025  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.1560  decode.d8.loss_cls: 0.1248  decode.d8.loss_mask: 0.1794  decode.d8.loss_dice: 0.2259
09/30 17:12:26 - mmengine - INFO - Iter(train) [ 67400/320000]  base_lr: 8.0827e-05 lr: 8.0827e-06  eta: 1 day, 6:31:01  time: 0.4380  data_time: 0.0098  memory: 5129  grad_norm: 34.4697  loss: 6.3430  decode.loss_cls: 0.0698  decode.loss_mask: 0.2928  decode.loss_dice: 0.2257  decode.d0.loss_cls: 0.8149  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.0889  decode.d1.loss_mask: 0.2856  decode.d1.loss_dice: 0.2172  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.2867  decode.d2.loss_dice: 0.2252  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.2837  decode.d3.loss_dice: 0.2146  decode.d4.loss_cls: 0.0234  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.2258  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.2854  decode.d5.loss_dice: 0.2291  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.2215  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.2894  decode.d7.loss_dice: 0.2143  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.2938  decode.d8.loss_dice: 0.2222
09/30 17:12:47 - mmengine - INFO - Iter(train) [ 67450/320000]  base_lr: 8.0813e-05 lr: 8.0813e-06  eta: 1 day, 6:30:40  time: 0.4384  data_time: 0.0099  memory: 5145  grad_norm: 20.0592  loss: 4.8877  decode.loss_cls: 0.0401  decode.loss_mask: 0.2028  decode.loss_dice: 0.1895  decode.d0.loss_cls: 0.7055  decode.d0.loss_mask: 0.2025  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.1690  decode.d2.loss_cls: 0.0388  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1710  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.2025  decode.d3.loss_dice: 0.1838  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.1775  decode.d5.loss_cls: 0.0416  decode.d5.loss_mask: 0.2034  decode.d5.loss_dice: 0.1701  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.1828  decode.d7.loss_cls: 0.0367  decode.d7.loss_mask: 0.2027  decode.d7.loss_dice: 0.1721  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.1768
09/30 17:13:09 - mmengine - INFO - Iter(train) [ 67500/320000]  base_lr: 8.0798e-05 lr: 8.0798e-06  eta: 1 day, 6:30:19  time: 0.4382  data_time: 0.0097  memory: 5129  grad_norm: 175.9929  loss: 5.2595  decode.loss_cls: 0.1472  decode.loss_mask: 0.1839  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.7445  decode.d0.loss_mask: 0.1824  decode.d0.loss_dice: 0.1468  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 0.1844  decode.d1.loss_dice: 0.1535  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.1830  decode.d2.loss_dice: 0.1527  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.1820  decode.d3.loss_dice: 0.1489  decode.d4.loss_cls: 0.1305  decode.d4.loss_mask: 0.1846  decode.d4.loss_dice: 0.1550  decode.d5.loss_cls: 0.1295  decode.d5.loss_mask: 0.1817  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.1578  decode.d6.loss_mask: 0.1831  decode.d6.loss_dice: 0.1580  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 0.1835  decode.d7.loss_dice: 0.1523  decode.d8.loss_cls: 0.1430  decode.d8.loss_mask: 0.1823  decode.d8.loss_dice: 0.1514
09/30 17:13:31 - mmengine - INFO - Iter(train) [ 67550/320000]  base_lr: 8.0784e-05 lr: 8.0784e-06  eta: 1 day, 6:29:58  time: 0.4384  data_time: 0.0099  memory: 5145  grad_norm: 121.3410  loss: 8.0351  decode.loss_cls: 0.1736  decode.loss_mask: 0.3514  decode.loss_dice: 0.2344  decode.d0.loss_cls: 0.9657  decode.d0.loss_mask: 0.3253  decode.d0.loss_dice: 0.2246  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 0.3380  decode.d1.loss_dice: 0.2163  decode.d2.loss_cls: 0.1759  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.2208  decode.d3.loss_cls: 0.1785  decode.d3.loss_mask: 0.3212  decode.d3.loss_dice: 0.2248  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.2384  decode.d5.loss_cls: 0.1595  decode.d5.loss_mask: 0.3112  decode.d5.loss_dice: 0.2171  decode.d6.loss_cls: 0.1681  decode.d6.loss_mask: 0.3232  decode.d6.loss_dice: 0.2242  decode.d7.loss_cls: 0.1733  decode.d7.loss_mask: 0.3128  decode.d7.loss_dice: 0.2120  decode.d8.loss_cls: 0.1965  decode.d8.loss_mask: 0.3194  decode.d8.loss_dice: 0.2248
09/30 17:13:53 - mmengine - INFO - Iter(train) [ 67600/320000]  base_lr: 8.0769e-05 lr: 8.0769e-06  eta: 1 day, 6:29:36  time: 0.4384  data_time: 0.0097  memory: 5129  grad_norm: 142.9082  loss: 5.9202  decode.loss_cls: 0.0190  decode.loss_mask: 0.2978  decode.loss_dice: 0.1906  decode.d0.loss_cls: 0.9058  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.1938  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.1955  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.1930  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.1948  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.2887  decode.d5.loss_dice: 0.1948  decode.d6.loss_cls: 0.0203  decode.d6.loss_mask: 0.2919  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.2836  decode.d7.loss_dice: 0.1927  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.1934
09/30 17:14:15 - mmengine - INFO - Iter(train) [ 67650/320000]  base_lr: 8.0755e-05 lr: 8.0755e-06  eta: 1 day, 6:29:15  time: 0.4357  data_time: 0.0094  memory: 5129  grad_norm: 27.8671  loss: 4.7508  decode.loss_cls: 0.0089  decode.loss_mask: 0.2056  decode.loss_dice: 0.1709  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 0.2088  decode.d0.loss_dice: 0.1742  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.1700  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1691  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.2061  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1682  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2040  decode.d5.loss_dice: 0.1675  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.1637  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.1710
09/30 17:14:37 - mmengine - INFO - Iter(train) [ 67700/320000]  base_lr: 8.0741e-05 lr: 8.0741e-06  eta: 1 day, 6:28:54  time: 0.4381  data_time: 0.0096  memory: 5145  grad_norm: 38.0014  loss: 5.7465  decode.loss_cls: 0.0942  decode.loss_mask: 0.2153  decode.loss_dice: 0.1957  decode.d0.loss_cls: 0.8161  decode.d0.loss_mask: 0.2193  decode.d0.loss_dice: 0.1950  decode.d1.loss_cls: 0.1067  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.2035  decode.d2.loss_cls: 0.0935  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.1989  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2082  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.1932  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.2191  decode.d5.loss_dice: 0.1957  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.1989  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.2020  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.2172  decode.d8.loss_dice: 0.1956
09/30 17:14:59 - mmengine - INFO - Iter(train) [ 67750/320000]  base_lr: 8.0726e-05 lr: 8.0726e-06  eta: 1 day, 6:28:33  time: 0.4385  data_time: 0.0098  memory: 5145  grad_norm: 48.4138  loss: 5.6855  decode.loss_cls: 0.0121  decode.loss_mask: 0.2623  decode.loss_dice: 0.2281  decode.d0.loss_cls: 0.7541  decode.d0.loss_mask: 0.2599  decode.d0.loss_dice: 0.2133  decode.d1.loss_cls: 0.0191  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.2602  decode.d2.loss_dice: 0.2193  decode.d3.loss_cls: 0.0103  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.2224  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2229  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2279  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2251
09/30 17:15:21 - mmengine - INFO - Iter(train) [ 67800/320000]  base_lr: 8.0712e-05 lr: 8.0712e-06  eta: 1 day, 6:28:12  time: 0.4384  data_time: 0.0099  memory: 5129  grad_norm: 79.1790  loss: 5.4110  decode.loss_cls: 0.1058  decode.loss_mask: 0.2124  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.8037  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.1832  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.1908  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.1842  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.2082  decode.d3.loss_dice: 0.1755  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.2132  decode.d4.loss_dice: 0.1932  decode.d5.loss_cls: 0.0405  decode.d5.loss_mask: 0.2128  decode.d5.loss_dice: 0.1871  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.1796  decode.d7.loss_cls: 0.0901  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.1853  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.2123  decode.d8.loss_dice: 0.1958
09/30 17:15:43 - mmengine - INFO - Iter(train) [ 67850/320000]  base_lr: 8.0697e-05 lr: 8.0697e-06  eta: 1 day, 6:27:51  time: 0.4395  data_time: 0.0100  memory: 5120  grad_norm: 52.3602  loss: 5.8969  decode.loss_cls: 0.1579  decode.loss_mask: 0.2327  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.8371  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.1778  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 0.2257  decode.d2.loss_dice: 0.1834  decode.d3.loss_cls: 0.0801  decode.d3.loss_mask: 0.2270  decode.d3.loss_dice: 0.1923  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.1868  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.1818  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.2243  decode.d6.loss_dice: 0.1883  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.1924  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.2286  decode.d8.loss_dice: 0.1982
09/30 17:16:05 - mmengine - INFO - Iter(train) [ 67900/320000]  base_lr: 8.0683e-05 lr: 8.0683e-06  eta: 1 day, 6:27:30  time: 0.4388  data_time: 0.0100  memory: 5129  grad_norm: 43.0846  loss: 6.5224  decode.loss_cls: 0.1351  decode.loss_mask: 0.2390  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.8989  decode.d0.loss_mask: 0.2447  decode.d0.loss_dice: 0.2583  decode.d1.loss_cls: 0.0473  decode.d1.loss_mask: 0.2402  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.2387  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.2407  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.2388  decode.d4.loss_dice: 0.2439  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.2471  decode.d6.loss_cls: 0.1418  decode.d6.loss_mask: 0.2393  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.1180  decode.d7.loss_mask: 0.2362  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.2574
09/30 17:16:27 - mmengine - INFO - Iter(train) [ 67950/320000]  base_lr: 8.0669e-05 lr: 8.0669e-06  eta: 1 day, 6:27:08  time: 0.4377  data_time: 0.0099  memory: 5120  grad_norm: 48.6391  loss: 5.9375  decode.loss_cls: 0.0748  decode.loss_mask: 0.2372  decode.loss_dice: 0.2109  decode.d0.loss_cls: 0.6913  decode.d0.loss_mask: 0.2397  decode.d0.loss_dice: 0.2306  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 0.2381  decode.d1.loss_dice: 0.2010  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2333  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.2353  decode.d4.loss_dice: 0.2123  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.2368  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2169  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.2367  decode.d7.loss_dice: 0.2101  decode.d8.loss_cls: 0.0680  decode.d8.loss_mask: 0.2375  decode.d8.loss_dice: 0.2163
09/30 17:16:49 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:16:49 - mmengine - INFO - Iter(train) [ 68000/320000]  base_lr: 8.0654e-05 lr: 8.0654e-06  eta: 1 day, 6:26:47  time: 0.4379  data_time: 0.0097  memory: 5145  grad_norm: 21.8646  loss: 4.8127  decode.loss_cls: 0.0637  decode.loss_mask: 0.1866  decode.loss_dice: 0.1738  decode.d0.loss_cls: 0.8145  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.1563  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.1890  decode.d1.loss_dice: 0.1562  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.1844  decode.d2.loss_dice: 0.1511  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.1843  decode.d3.loss_dice: 0.1530  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.1848  decode.d4.loss_dice: 0.1745  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.1865  decode.d5.loss_dice: 0.1572  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.1867  decode.d6.loss_dice: 0.1512  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.1843  decode.d7.loss_dice: 0.1701  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.1858  decode.d8.loss_dice: 0.1594
09/30 17:17:10 - mmengine - INFO - Iter(train) [ 68050/320000]  base_lr: 8.0640e-05 lr: 8.0640e-06  eta: 1 day, 6:26:26  time: 0.4375  data_time: 0.0097  memory: 5145  grad_norm: 41.7162  loss: 4.3621  decode.loss_cls: 0.0274  decode.loss_mask: 0.1744  decode.loss_dice: 0.1522  decode.d0.loss_cls: 0.8373  decode.d0.loss_mask: 0.1778  decode.d0.loss_dice: 0.1657  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.1731  decode.d1.loss_dice: 0.1591  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.1717  decode.d2.loss_dice: 0.1561  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.1734  decode.d3.loss_dice: 0.1543  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.1783  decode.d4.loss_dice: 0.1583  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.1775  decode.d5.loss_dice: 0.1574  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.1743  decode.d6.loss_dice: 0.1591  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.1752  decode.d7.loss_dice: 0.1545  decode.d8.loss_cls: 0.0188  decode.d8.loss_mask: 0.1738  decode.d8.loss_dice: 0.1570
09/30 17:17:32 - mmengine - INFO - Iter(train) [ 68100/320000]  base_lr: 8.0625e-05 lr: 8.0625e-06  eta: 1 day, 6:26:05  time: 0.4380  data_time: 0.0097  memory: 5129  grad_norm: 33.1166  loss: 5.3627  decode.loss_cls: 0.0789  decode.loss_mask: 0.2060  decode.loss_dice: 0.1781  decode.d0.loss_cls: 0.9298  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.1660  decode.d1.loss_cls: 0.0892  decode.d1.loss_mask: 0.2050  decode.d1.loss_dice: 0.1704  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.2057  decode.d2.loss_dice: 0.1705  decode.d3.loss_cls: 0.0495  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.1678  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.2055  decode.d4.loss_dice: 0.1759  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0796  decode.d6.loss_mask: 0.2072  decode.d6.loss_dice: 0.1725  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1728  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.2074  decode.d8.loss_dice: 0.1740
09/30 17:17:54 - mmengine - INFO - Iter(train) [ 68150/320000]  base_lr: 8.0611e-05 lr: 8.0611e-06  eta: 1 day, 6:25:43  time: 0.4373  data_time: 0.0096  memory: 5129  grad_norm: 73.7543  loss: 7.6529  decode.loss_cls: 0.0866  decode.loss_mask: 0.2890  decode.loss_dice: 0.3127  decode.d0.loss_cls: 0.8710  decode.d0.loss_mask: 0.2974  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.2993  decode.d2.loss_cls: 0.1094  decode.d2.loss_mask: 0.2875  decode.d2.loss_dice: 0.2895  decode.d3.loss_cls: 0.1000  decode.d3.loss_mask: 0.2906  decode.d3.loss_dice: 0.2777  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.2870  decode.d4.loss_dice: 0.3078  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.0967  decode.d6.loss_mask: 0.2901  decode.d6.loss_dice: 0.2894  decode.d7.loss_cls: 0.0876  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.2813  decode.d8.loss_cls: 0.1057  decode.d8.loss_mask: 0.2892  decode.d8.loss_dice: 0.2886
09/30 17:18:16 - mmengine - INFO - Iter(train) [ 68200/320000]  base_lr: 8.0597e-05 lr: 8.0597e-06  eta: 1 day, 6:25:22  time: 0.4375  data_time: 0.0097  memory: 5129  grad_norm: 27.2407  loss: 5.0843  decode.loss_cls: 0.0065  decode.loss_mask: 0.2307  decode.loss_dice: 0.1961  decode.d0.loss_cls: 0.7339  decode.d0.loss_mask: 0.2359  decode.d0.loss_dice: 0.1922  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.2303  decode.d1.loss_dice: 0.1868  decode.d2.loss_cls: 0.0253  decode.d2.loss_mask: 0.2327  decode.d2.loss_dice: 0.1914  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.1918  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.2298  decode.d4.loss_dice: 0.1914  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.1925  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.2303  decode.d6.loss_dice: 0.1940  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.1947  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.2326  decode.d8.loss_dice: 0.1941
09/30 17:18:38 - mmengine - INFO - Iter(train) [ 68250/320000]  base_lr: 8.0582e-05 lr: 8.0582e-06  eta: 1 day, 6:25:01  time: 0.4382  data_time: 0.0097  memory: 5129  grad_norm: 83.4729  loss: 6.2438  decode.loss_cls: 0.1886  decode.loss_mask: 0.1852  decode.loss_dice: 0.1698  decode.d0.loss_cls: 0.9335  decode.d0.loss_mask: 0.1892  decode.d0.loss_dice: 0.1870  decode.d1.loss_cls: 0.1744  decode.d1.loss_mask: 0.1870  decode.d1.loss_dice: 0.1631  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 0.1838  decode.d2.loss_dice: 0.1739  decode.d3.loss_cls: 0.1854  decode.d3.loss_mask: 0.1859  decode.d3.loss_dice: 0.1839  decode.d4.loss_cls: 0.1805  decode.d4.loss_mask: 0.1846  decode.d4.loss_dice: 0.1896  decode.d5.loss_cls: 0.2026  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1647  decode.d6.loss_cls: 0.2074  decode.d6.loss_mask: 0.1878  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.1851  decode.d7.loss_dice: 0.1752  decode.d8.loss_cls: 0.2090  decode.d8.loss_mask: 0.1859  decode.d8.loss_dice: 0.1728
09/30 17:19:00 - mmengine - INFO - Iter(train) [ 68300/320000]  base_lr: 8.0568e-05 lr: 8.0568e-06  eta: 1 day, 6:24:40  time: 0.4376  data_time: 0.0096  memory: 5129  grad_norm: 25.0818  loss: 5.2889  decode.loss_cls: 0.0533  decode.loss_mask: 0.2172  decode.loss_dice: 0.1753  decode.d0.loss_cls: 0.8430  decode.d0.loss_mask: 0.2258  decode.d0.loss_dice: 0.1706  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.1817  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.2182  decode.d2.loss_dice: 0.1809  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.2217  decode.d3.loss_dice: 0.1757  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.1783  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 0.2207  decode.d6.loss_dice: 0.1661  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.1700  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.1790
09/30 17:19:22 - mmengine - INFO - Iter(train) [ 68350/320000]  base_lr: 8.0553e-05 lr: 8.0553e-06  eta: 1 day, 6:24:18  time: 0.4374  data_time: 0.0098  memory: 5129  grad_norm: 141.2744  loss: 6.3289  decode.loss_cls: 0.1363  decode.loss_mask: 0.2237  decode.loss_dice: 0.1890  decode.d0.loss_cls: 0.8377  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2134  decode.d1.loss_cls: 0.1802  decode.d1.loss_mask: 0.2242  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.2284  decode.d2.loss_dice: 0.2115  decode.d3.loss_cls: 0.1516  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.1945  decode.d4.loss_cls: 0.1396  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.1391  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.1858  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.1998  decode.d7.loss_cls: 0.1369  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.1807  decode.d8.loss_cls: 0.1374  decode.d8.loss_mask: 0.2235  decode.d8.loss_dice: 0.1915
09/30 17:19:44 - mmengine - INFO - Iter(train) [ 68400/320000]  base_lr: 8.0539e-05 lr: 8.0539e-06  eta: 1 day, 6:23:57  time: 0.4375  data_time: 0.0097  memory: 5129  grad_norm: 84.7505  loss: 9.0459  decode.loss_cls: 0.2258  decode.loss_mask: 0.3007  decode.loss_dice: 0.2964  decode.d0.loss_cls: 0.8699  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.3029  decode.d1.loss_cls: 0.2442  decode.d1.loss_mask: 0.3006  decode.d1.loss_dice: 0.2917  decode.d2.loss_cls: 0.2577  decode.d2.loss_mask: 0.2977  decode.d2.loss_dice: 0.2898  decode.d3.loss_cls: 0.2518  decode.d3.loss_mask: 0.3014  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.2177  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.2962  decode.d5.loss_cls: 0.2297  decode.d5.loss_mask: 0.3010  decode.d5.loss_dice: 0.2939  decode.d6.loss_cls: 0.2476  decode.d6.loss_mask: 0.2983  decode.d6.loss_dice: 0.2914  decode.d7.loss_cls: 0.2777  decode.d7.loss_mask: 0.2997  decode.d7.loss_dice: 0.2907  decode.d8.loss_cls: 0.2611  decode.d8.loss_mask: 0.3098  decode.d8.loss_dice: 0.3064
09/30 17:20:06 - mmengine - INFO - Iter(train) [ 68450/320000]  base_lr: 8.0525e-05 lr: 8.0525e-06  eta: 1 day, 6:23:36  time: 0.4386  data_time: 0.0096  memory: 5129  grad_norm: 110.7519  loss: 6.2170  decode.loss_cls: 0.0986  decode.loss_mask: 0.2093  decode.loss_dice: 0.2318  decode.d0.loss_cls: 1.0766  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.2288  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.2104  decode.d1.loss_dice: 0.2286  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.2087  decode.d2.loss_dice: 0.2281  decode.d3.loss_cls: 0.0944  decode.d3.loss_mask: 0.2088  decode.d3.loss_dice: 0.2278  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.2510  decode.d5.loss_cls: 0.0853  decode.d5.loss_mask: 0.2089  decode.d5.loss_dice: 0.2366  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.2083  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.2099  decode.d8.loss_dice: 0.2399
09/30 17:20:28 - mmengine - INFO - Iter(train) [ 68500/320000]  base_lr: 8.0510e-05 lr: 8.0510e-06  eta: 1 day, 6:23:15  time: 0.4382  data_time: 0.0097  memory: 5145  grad_norm: 47.3882  loss: 8.0156  decode.loss_cls: 0.2224  decode.loss_mask: 0.2282  decode.loss_dice: 0.2109  decode.d0.loss_cls: 1.0501  decode.d0.loss_mask: 0.2272  decode.d0.loss_dice: 0.2310  decode.d1.loss_cls: 0.3904  decode.d1.loss_mask: 0.2286  decode.d1.loss_dice: 0.2324  decode.d2.loss_cls: 0.2517  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.2302  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.2760  decode.d4.loss_mask: 0.2328  decode.d4.loss_dice: 0.2163  decode.d5.loss_cls: 0.2215  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.2338  decode.d6.loss_cls: 0.1830  decode.d6.loss_mask: 0.3129  decode.d6.loss_dice: 0.2406  decode.d7.loss_cls: 0.2628  decode.d7.loss_mask: 0.2316  decode.d7.loss_dice: 0.2138  decode.d8.loss_cls: 0.2468  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.2366
09/30 17:20:49 - mmengine - INFO - Iter(train) [ 68550/320000]  base_lr: 8.0496e-05 lr: 8.0496e-06  eta: 1 day, 6:22:54  time: 0.4386  data_time: 0.0098  memory: 5129  grad_norm: 25.1417  loss: 5.0375  decode.loss_cls: 0.0048  decode.loss_mask: 0.2204  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.8590  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.2008  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.2212  decode.d1.loss_dice: 0.1882  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.2192  decode.d2.loss_dice: 0.1925  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.2221  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.1884  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.1891  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.2200  decode.d7.loss_dice: 0.1911  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.1934
09/30 17:21:11 - mmengine - INFO - Iter(train) [ 68600/320000]  base_lr: 8.0481e-05 lr: 8.0481e-06  eta: 1 day, 6:22:33  time: 0.4378  data_time: 0.0098  memory: 5129  grad_norm: 31.8035  loss: 6.4850  decode.loss_cls: 0.0182  decode.loss_mask: 0.3221  decode.loss_dice: 0.2265  decode.d0.loss_cls: 0.8191  decode.d0.loss_mask: 0.3305  decode.d0.loss_dice: 0.2231  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.3288  decode.d1.loss_dice: 0.2249  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.3295  decode.d2.loss_dice: 0.2235  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.3250  decode.d3.loss_dice: 0.2239  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.3243  decode.d4.loss_dice: 0.2244  decode.d5.loss_cls: 0.0189  decode.d5.loss_mask: 0.3209  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.3203  decode.d6.loss_dice: 0.2228  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.3286  decode.d7.loss_dice: 0.2241  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.3255  decode.d8.loss_dice: 0.2252
09/30 17:21:33 - mmengine - INFO - Iter(train) [ 68650/320000]  base_lr: 8.0467e-05 lr: 8.0467e-06  eta: 1 day, 6:22:11  time: 0.4373  data_time: 0.0096  memory: 5145  grad_norm: 63.3446  loss: 5.8864  decode.loss_cls: 0.0485  decode.loss_mask: 0.2341  decode.loss_dice: 0.2324  decode.d0.loss_cls: 0.8238  decode.d0.loss_mask: 0.2393  decode.d0.loss_dice: 0.2245  decode.d1.loss_cls: 0.0200  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.2337  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.2323  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.2345  decode.d4.loss_cls: 0.0333  decode.d4.loss_mask: 0.2343  decode.d4.loss_dice: 0.2264  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.2363  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.2330  decode.d6.loss_dice: 0.2315  decode.d7.loss_cls: 0.0371  decode.d7.loss_mask: 0.2340  decode.d7.loss_dice: 0.2352  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.2335
09/30 17:21:55 - mmengine - INFO - Iter(train) [ 68700/320000]  base_lr: 8.0452e-05 lr: 8.0452e-06  eta: 1 day, 6:21:51  time: 0.4384  data_time: 0.0095  memory: 5145  grad_norm: 97.4155  loss: 5.7540  decode.loss_cls: 0.0362  decode.loss_mask: 0.2645  decode.loss_dice: 0.1861  decode.d0.loss_cls: 0.8581  decode.d0.loss_mask: 0.2619  decode.d0.loss_dice: 0.1844  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.2639  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.1857  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.1855  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2698  decode.d4.loss_dice: 0.1898  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.2590  decode.d5.loss_dice: 0.1839  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.2626  decode.d6.loss_dice: 0.1856  decode.d7.loss_cls: 0.0442  decode.d7.loss_mask: 0.2595  decode.d7.loss_dice: 0.1846  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.2616  decode.d8.loss_dice: 0.1850
09/30 17:22:17 - mmengine - INFO - Iter(train) [ 68750/320000]  base_lr: 8.0438e-05 lr: 8.0438e-06  eta: 1 day, 6:21:30  time: 0.4386  data_time: 0.0098  memory: 5145  grad_norm: 23.0607  loss: 5.6713  decode.loss_cls: 0.0779  decode.loss_mask: 0.2117  decode.loss_dice: 0.2207  decode.d0.loss_cls: 0.8480  decode.d0.loss_mask: 0.2109  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.0864  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.2193  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.2109  decode.d3.loss_dice: 0.2274  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.2105  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.2222  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.2117  decode.d6.loss_dice: 0.2259  decode.d7.loss_cls: 0.0429  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.2222  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.2123  decode.d8.loss_dice: 0.2264
09/30 17:22:39 - mmengine - INFO - Iter(train) [ 68800/320000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 1 day, 6:21:09  time: 0.4380  data_time: 0.0098  memory: 5120  grad_norm: 37.6348  loss: 6.5107  decode.loss_cls: 0.0891  decode.loss_mask: 0.2552  decode.loss_dice: 0.2223  decode.d0.loss_cls: 0.8245  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.2207  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.2568  decode.d1.loss_dice: 0.2206  decode.d2.loss_cls: 0.0908  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2098  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.2534  decode.d3.loss_dice: 0.2130  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2155  decode.d5.loss_cls: 0.1075  decode.d5.loss_mask: 0.2535  decode.d5.loss_dice: 0.2128  decode.d6.loss_cls: 0.1195  decode.d6.loss_mask: 0.2534  decode.d6.loss_dice: 0.2169  decode.d7.loss_cls: 0.1256  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.2206  decode.d8.loss_cls: 0.1136  decode.d8.loss_mask: 0.2998  decode.d8.loss_dice: 0.2369
09/30 17:23:01 - mmengine - INFO - Iter(train) [ 68850/320000]  base_lr: 8.0409e-05 lr: 8.0409e-06  eta: 1 day, 6:20:47  time: 0.4378  data_time: 0.0098  memory: 5129  grad_norm: 90.0092  loss: 6.7962  decode.loss_cls: 0.0387  decode.loss_mask: 0.3005  decode.loss_dice: 0.2426  decode.d0.loss_cls: 0.7468  decode.d0.loss_mask: 0.3029  decode.d0.loss_dice: 0.2288  decode.d1.loss_cls: 0.0958  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.1048  decode.d2.loss_mask: 0.3029  decode.d2.loss_dice: 0.2419  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.3008  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.0953  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.3001  decode.d6.loss_dice: 0.2525  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.2427
09/30 17:23:23 - mmengine - INFO - Iter(train) [ 68900/320000]  base_lr: 8.0395e-05 lr: 8.0395e-06  eta: 1 day, 6:20:26  time: 0.4394  data_time: 0.0099  memory: 5120  grad_norm: 62.0292  loss: 5.9477  decode.loss_cls: 0.1320  decode.loss_mask: 0.2152  decode.loss_dice: 0.2122  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.2195  decode.d0.loss_dice: 0.1889  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.2143  decode.d1.loss_dice: 0.1785  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.1787  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.1789  decode.d4.loss_cls: 0.1172  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0874  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.1780  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.2123  decode.d7.loss_cls: 0.1170  decode.d7.loss_mask: 0.2178  decode.d7.loss_dice: 0.1834  decode.d8.loss_cls: 0.1413  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.2139
09/30 17:23:45 - mmengine - INFO - Iter(train) [ 68950/320000]  base_lr: 8.0380e-05 lr: 8.0380e-06  eta: 1 day, 6:20:05  time: 0.4378  data_time: 0.0097  memory: 5129  grad_norm: 34.4881  loss: 4.9269  decode.loss_cls: 0.0063  decode.loss_mask: 0.1938  decode.loss_dice: 0.1867  decode.d0.loss_cls: 0.9398  decode.d0.loss_mask: 0.1961  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.1979  decode.d1.loss_dice: 0.2223  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.1871  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.1928  decode.d3.loss_dice: 0.1882  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.1821  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.1931  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.1917  decode.d7.loss_dice: 0.1823  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.1798
09/30 17:24:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:24:07 - mmengine - INFO - Iter(train) [ 69000/320000]  base_lr: 8.0366e-05 lr: 8.0366e-06  eta: 1 day, 6:19:44  time: 0.4375  data_time: 0.0097  memory: 5120  grad_norm: 50.9567  loss: 6.1784  decode.loss_cls: 0.1543  decode.loss_mask: 0.1850  decode.loss_dice: 0.2436  decode.d0.loss_cls: 0.8684  decode.d0.loss_mask: 0.1865  decode.d0.loss_dice: 0.2307  decode.d1.loss_cls: 0.1621  decode.d1.loss_mask: 0.1846  decode.d1.loss_dice: 0.2190  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.1830  decode.d2.loss_dice: 0.2145  decode.d3.loss_cls: 0.1149  decode.d3.loss_mask: 0.1824  decode.d3.loss_dice: 0.2262  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.1842  decode.d4.loss_dice: 0.2394  decode.d5.loss_cls: 0.1314  decode.d5.loss_mask: 0.1833  decode.d5.loss_dice: 0.2366  decode.d6.loss_cls: 0.1694  decode.d6.loss_mask: 0.1837  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.1310  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.2377  decode.d8.loss_cls: 0.1277  decode.d8.loss_mask: 0.1831  decode.d8.loss_dice: 0.2264
09/30 17:24:29 - mmengine - INFO - Iter(train) [ 69050/320000]  base_lr: 8.0352e-05 lr: 8.0352e-06  eta: 1 day, 6:19:23  time: 0.4371  data_time: 0.0097  memory: 5129  grad_norm: 139.3832  loss: 6.5952  decode.loss_cls: 0.0368  decode.loss_mask: 0.2401  decode.loss_dice: 0.2413  decode.d0.loss_cls: 0.8185  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.1990  decode.d1.loss_mask: 0.2408  decode.d1.loss_dice: 0.2228  decode.d2.loss_cls: 0.1686  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.2322  decode.d3.loss_cls: 0.1041  decode.d3.loss_mask: 0.2346  decode.d3.loss_dice: 0.2365  decode.d4.loss_cls: 0.1487  decode.d4.loss_mask: 0.2351  decode.d4.loss_dice: 0.2330  decode.d5.loss_cls: 0.1151  decode.d5.loss_mask: 0.2349  decode.d5.loss_dice: 0.2380  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.2412  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.0936  decode.d7.loss_mask: 0.2390  decode.d7.loss_dice: 0.2379  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2316
09/30 17:24:51 - mmengine - INFO - Iter(train) [ 69100/320000]  base_lr: 8.0337e-05 lr: 8.0337e-06  eta: 1 day, 6:19:02  time: 0.4370  data_time: 0.0095  memory: 5145  grad_norm: 61.7217  loss: 4.9805  decode.loss_cls: 0.0305  decode.loss_mask: 0.2027  decode.loss_dice: 0.1810  decode.d0.loss_cls: 0.8154  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.2014  decode.d1.loss_dice: 0.1710  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.2031  decode.d2.loss_dice: 0.1809  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.2045  decode.d3.loss_dice: 0.1833  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.2033  decode.d4.loss_dice: 0.1853  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.1864  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.1722  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.2022  decode.d8.loss_dice: 0.1818
09/30 17:25:13 - mmengine - INFO - Iter(train) [ 69150/320000]  base_lr: 8.0323e-05 lr: 8.0323e-06  eta: 1 day, 6:18:40  time: 0.4377  data_time: 0.0097  memory: 5129  grad_norm: 46.6025  loss: 5.2423  decode.loss_cls: 0.1050  decode.loss_mask: 0.2065  decode.loss_dice: 0.1813  decode.d0.loss_cls: 0.8103  decode.d0.loss_mask: 0.2083  decode.d0.loss_dice: 0.1843  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.2076  decode.d1.loss_dice: 0.1794  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.1838  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.2063  decode.d3.loss_dice: 0.1878  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2063  decode.d4.loss_dice: 0.1842  decode.d5.loss_cls: 0.0526  decode.d5.loss_mask: 0.2079  decode.d5.loss_dice: 0.1820  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.1792  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.2083  decode.d7.loss_dice: 0.1795  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.2080  decode.d8.loss_dice: 0.1816
09/30 17:25:35 - mmengine - INFO - Iter(train) [ 69200/320000]  base_lr: 8.0308e-05 lr: 8.0308e-06  eta: 1 day, 6:18:19  time: 0.4377  data_time: 0.0098  memory: 5129  grad_norm: 39.9296  loss: 4.6904  decode.loss_cls: 0.0038  decode.loss_mask: 0.2136  decode.loss_dice: 0.1749  decode.d0.loss_cls: 0.7988  decode.d0.loss_mask: 0.2230  decode.d0.loss_dice: 0.1815  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.2132  decode.d1.loss_dice: 0.1675  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.1724  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.2092  decode.d3.loss_dice: 0.1686  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.1660  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.2116  decode.d5.loss_dice: 0.1654  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2098  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2131  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.2131  decode.d8.loss_dice: 0.1732
09/30 17:25:56 - mmengine - INFO - Iter(train) [ 69250/320000]  base_lr: 8.0294e-05 lr: 8.0294e-06  eta: 1 day, 6:17:58  time: 0.4387  data_time: 0.0100  memory: 5129  grad_norm: 99.7574  loss: 6.3026  decode.loss_cls: 0.1273  decode.loss_mask: 0.2161  decode.loss_dice: 0.2126  decode.d0.loss_cls: 0.8441  decode.d0.loss_mask: 0.2136  decode.d0.loss_dice: 0.1898  decode.d1.loss_cls: 0.1739  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.1626  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.1493  decode.d3.loss_mask: 0.2161  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.1725  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.2029  decode.d5.loss_cls: 0.1737  decode.d5.loss_mask: 0.2136  decode.d5.loss_dice: 0.1915  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.2145  decode.d6.loss_dice: 0.1860  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 0.2135  decode.d7.loss_dice: 0.1867  decode.d8.loss_cls: 0.1272  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.1844
09/30 17:26:18 - mmengine - INFO - Iter(train) [ 69300/320000]  base_lr: 8.0280e-05 lr: 8.0280e-06  eta: 1 day, 6:17:37  time: 0.4384  data_time: 0.0099  memory: 5145  grad_norm: 62.7731  loss: 6.1114  decode.loss_cls: 0.0581  decode.loss_mask: 0.2280  decode.loss_dice: 0.2397  decode.d0.loss_cls: 0.8901  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.2533  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2236  decode.d1.loss_dice: 0.2358  decode.d2.loss_cls: 0.0371  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.2463  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.2231  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2462  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.2324  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.2478  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2319  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2287
09/30 17:26:40 - mmengine - INFO - Iter(train) [ 69350/320000]  base_lr: 8.0265e-05 lr: 8.0265e-06  eta: 1 day, 6:17:16  time: 0.4365  data_time: 0.0097  memory: 5129  grad_norm: 117.2458  loss: 5.6593  decode.loss_cls: 0.0433  decode.loss_mask: 0.2347  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.7238  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2175  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.2315  decode.d1.loss_dice: 0.2075  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2000  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.2308  decode.d3.loss_dice: 0.2053  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.2159  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 0.2288  decode.d6.loss_dice: 0.2098  decode.d7.loss_cls: 0.1442  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.2147
09/30 17:27:02 - mmengine - INFO - Iter(train) [ 69400/320000]  base_lr: 8.0251e-05 lr: 8.0251e-06  eta: 1 day, 6:16:54  time: 0.4375  data_time: 0.0097  memory: 5145  grad_norm: 63.7769  loss: 8.5673  decode.loss_cls: 0.2283  decode.loss_mask: 0.2396  decode.loss_dice: 0.3070  decode.d0.loss_cls: 0.8943  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.3283  decode.d1.loss_cls: 0.2322  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.3103  decode.d2.loss_cls: 0.2060  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.3046  decode.d3.loss_cls: 0.2010  decode.d3.loss_mask: 0.2413  decode.d3.loss_dice: 0.3518  decode.d4.loss_cls: 0.2473  decode.d4.loss_mask: 0.2452  decode.d4.loss_dice: 0.3470  decode.d5.loss_cls: 0.1766  decode.d5.loss_mask: 0.2576  decode.d5.loss_dice: 0.3626  decode.d6.loss_cls: 0.1853  decode.d6.loss_mask: 0.2523  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 0.1952  decode.d7.loss_mask: 0.2762  decode.d7.loss_dice: 0.3138  decode.d8.loss_cls: 0.2138  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.3603
09/30 17:27:24 - mmengine - INFO - Iter(train) [ 69450/320000]  base_lr: 8.0236e-05 lr: 8.0236e-06  eta: 1 day, 6:16:33  time: 0.4380  data_time: 0.0096  memory: 5129  grad_norm: 139.1536  loss: 5.7766  decode.loss_cls: 0.1027  decode.loss_mask: 0.2634  decode.loss_dice: 0.1949  decode.d0.loss_cls: 0.7775  decode.d0.loss_mask: 0.2619  decode.d0.loss_dice: 0.1964  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.2648  decode.d1.loss_dice: 0.1917  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.2655  decode.d2.loss_dice: 0.1978  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.2681  decode.d3.loss_dice: 0.1922  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.1909  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.2623  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.1903  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.1892  decode.d8.loss_cls: 0.0956  decode.d8.loss_mask: 0.2606  decode.d8.loss_dice: 0.1939
09/30 17:27:46 - mmengine - INFO - Iter(train) [ 69500/320000]  base_lr: 8.0222e-05 lr: 8.0222e-06  eta: 1 day, 6:16:12  time: 0.4380  data_time: 0.0098  memory: 5145  grad_norm: 19.7947  loss: 4.7491  decode.loss_cls: 0.0629  decode.loss_mask: 0.1662  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.8369  decode.d0.loss_mask: 0.1654  decode.d0.loss_dice: 0.1892  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.1612  decode.d1.loss_dice: 0.1827  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.1639  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.1602  decode.d3.loss_dice: 0.1486  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.1580  decode.d4.loss_dice: 0.1545  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.1617  decode.d5.loss_dice: 0.1751  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.1594  decode.d6.loss_dice: 0.1523  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.1601  decode.d7.loss_dice: 0.1319  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.1621  decode.d8.loss_dice: 0.1777
09/30 17:28:08 - mmengine - INFO - Iter(train) [ 69550/320000]  base_lr: 8.0208e-05 lr: 8.0208e-06  eta: 1 day, 6:15:51  time: 0.4391  data_time: 0.0098  memory: 5145  grad_norm: 138.5408  loss: 5.3611  decode.loss_cls: 0.1225  decode.loss_mask: 0.1951  decode.loss_dice: 0.1976  decode.d0.loss_cls: 0.7929  decode.d0.loss_mask: 0.1953  decode.d0.loss_dice: 0.1815  decode.d1.loss_cls: 0.0798  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.1782  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.1942  decode.d2.loss_dice: 0.1981  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.1930  decode.d3.loss_dice: 0.1814  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.1934  decode.d4.loss_dice: 0.1799  decode.d5.loss_cls: 0.0903  decode.d5.loss_mask: 0.1912  decode.d5.loss_dice: 0.1841  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.1837  decode.d7.loss_cls: 0.0935  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.1871  decode.d8.loss_cls: 0.1132  decode.d8.loss_mask: 0.1923  decode.d8.loss_dice: 0.1842
09/30 17:28:30 - mmengine - INFO - Iter(train) [ 69600/320000]  base_lr: 8.0193e-05 lr: 8.0193e-06  eta: 1 day, 6:15:30  time: 0.4357  data_time: 0.0096  memory: 5120  grad_norm: 28.6116  loss: 5.3851  decode.loss_cls: 0.0364  decode.loss_mask: 0.2440  decode.loss_dice: 0.1705  decode.d0.loss_cls: 0.7386  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.1715  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.2438  decode.d1.loss_dice: 0.1715  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.1645  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.1725  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.2455  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.1626  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.2421  decode.d7.loss_dice: 0.1643  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.2418  decode.d8.loss_dice: 0.1669
09/30 17:28:52 - mmengine - INFO - Iter(train) [ 69650/320000]  base_lr: 8.0179e-05 lr: 8.0179e-06  eta: 1 day, 6:15:08  time: 0.4372  data_time: 0.0096  memory: 5120  grad_norm: 65.3253  loss: 6.7679  decode.loss_cls: 0.0992  decode.loss_mask: 0.2445  decode.loss_dice: 0.2289  decode.d0.loss_cls: 0.9224  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.2247  decode.d1.loss_cls: 0.1192  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.2448  decode.d2.loss_cls: 0.0976  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2507  decode.d3.loss_cls: 0.1096  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.2317  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.2443  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.1178  decode.d5.loss_mask: 0.2460  decode.d5.loss_dice: 0.2492  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 0.2450  decode.d6.loss_dice: 0.2532  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.2367  decode.d8.loss_cls: 0.1077  decode.d8.loss_mask: 0.2458  decode.d8.loss_dice: 0.2287
09/30 17:29:14 - mmengine - INFO - Iter(train) [ 69700/320000]  base_lr: 8.0164e-05 lr: 8.0164e-06  eta: 1 day, 6:14:47  time: 0.4389  data_time: 0.0099  memory: 5129  grad_norm: 80.6129  loss: 5.0305  decode.loss_cls: 0.0199  decode.loss_mask: 0.2168  decode.loss_dice: 0.1782  decode.d0.loss_cls: 0.9034  decode.d0.loss_mask: 0.2244  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.1738  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.1660  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.1694  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.2148  decode.d4.loss_dice: 0.1668  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.1632  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.1638  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.2274  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.2155  decode.d8.loss_dice: 0.1732
09/30 17:29:36 - mmengine - INFO - Iter(train) [ 69750/320000]  base_lr: 8.0150e-05 lr: 8.0150e-06  eta: 1 day, 6:14:26  time: 0.4389  data_time: 0.0096  memory: 5145  grad_norm: 53.5122  loss: 6.1816  decode.loss_cls: 0.0100  decode.loss_mask: 0.2509  decode.loss_dice: 0.2518  decode.d0.loss_cls: 0.7859  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2726  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.2478  decode.d1.loss_dice: 0.2536  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.2523  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.2532  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2563  decode.d4.loss_dice: 0.2540  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.2553  decode.d5.loss_dice: 0.2605  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.2551  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.2520  decode.d7.loss_dice: 0.2518  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.2494  decode.d8.loss_dice: 0.2569
09/30 17:29:58 - mmengine - INFO - Iter(train) [ 69800/320000]  base_lr: 8.0135e-05 lr: 8.0135e-06  eta: 1 day, 6:14:05  time: 0.4379  data_time: 0.0095  memory: 5129  grad_norm: 50.3868  loss: 5.5616  decode.loss_cls: 0.0527  decode.loss_mask: 0.1991  decode.loss_dice: 0.1736  decode.d0.loss_cls: 0.8992  decode.d0.loss_mask: 0.2035  decode.d0.loss_dice: 0.2217  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.1972  decode.d1.loss_dice: 0.2051  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 0.1968  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.1997  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.1022  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.2115  decode.d5.loss_cls: 0.0746  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.1973  decode.d6.loss_dice: 0.2145  decode.d7.loss_cls: 0.0541  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.2051  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.1981  decode.d8.loss_dice: 0.1833
09/30 17:30:20 - mmengine - INFO - Iter(train) [ 69850/320000]  base_lr: 8.0121e-05 lr: 8.0121e-06  eta: 1 day, 6:13:44  time: 0.4384  data_time: 0.0096  memory: 5129  grad_norm: 32.4518  loss: 4.9479  decode.loss_cls: 0.0267  decode.loss_mask: 0.1889  decode.loss_dice: 0.2018  decode.d0.loss_cls: 0.8822  decode.d0.loss_mask: 0.1970  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.1932  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0211  decode.d2.loss_mask: 0.1922  decode.d2.loss_dice: 0.1968  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.1970  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.1906  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.0234  decode.d5.loss_mask: 0.1912  decode.d5.loss_dice: 0.1940  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.1866  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.1933  decode.d7.loss_dice: 0.1978  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.1901  decode.d8.loss_dice: 0.1940
09/30 17:30:42 - mmengine - INFO - Iter(train) [ 69900/320000]  base_lr: 8.0107e-05 lr: 8.0107e-06  eta: 1 day, 6:13:23  time: 0.4395  data_time: 0.0098  memory: 5129  grad_norm: 17.2748  loss: 4.8138  decode.loss_cls: 0.0020  decode.loss_mask: 0.2267  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.7898  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.1792  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2258  decode.d2.loss_dice: 0.1741  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.2253  decode.d3.loss_dice: 0.1721  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2228  decode.d5.loss_dice: 0.1760  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.1725  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.1698  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2259  decode.d8.loss_dice: 0.1750
09/30 17:31:03 - mmengine - INFO - Iter(train) [ 69950/320000]  base_lr: 8.0092e-05 lr: 8.0092e-06  eta: 1 day, 6:13:02  time: 0.4388  data_time: 0.0098  memory: 5145  grad_norm: 31.1990  loss: 5.8564  decode.loss_cls: 0.0588  decode.loss_mask: 0.2779  decode.loss_dice: 0.1917  decode.d0.loss_cls: 0.7509  decode.d0.loss_mask: 0.2852  decode.d0.loss_dice: 0.1897  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.2761  decode.d1.loss_dice: 0.1880  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.2754  decode.d2.loss_dice: 0.1866  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.2778  decode.d3.loss_dice: 0.1841  decode.d4.loss_cls: 0.0822  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.2774  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.2766  decode.d6.loss_dice: 0.1783  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.1852  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.1838
09/30 17:31:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:31:25 - mmengine - INFO - Iter(train) [ 70000/320000]  base_lr: 8.0078e-05 lr: 8.0078e-06  eta: 1 day, 6:12:41  time: 0.4388  data_time: 0.0097  memory: 5129  grad_norm: 41.2006  loss: 5.1790  decode.loss_cls: 0.0270  decode.loss_mask: 0.2266  decode.loss_dice: 0.1891  decode.d0.loss_cls: 0.8435  decode.d0.loss_mask: 0.2232  decode.d0.loss_dice: 0.1903  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.1886  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.2271  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.1906  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.2253  decode.d6.loss_dice: 0.1932  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.1900  decode.d8.loss_cls: 0.0215  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.1905
09/30 17:31:47 - mmengine - INFO - Iter(train) [ 70050/320000]  base_lr: 8.0063e-05 lr: 8.0063e-06  eta: 1 day, 6:12:20  time: 0.4373  data_time: 0.0096  memory: 5120  grad_norm: 58.1457  loss: 6.4964  decode.loss_cls: 0.1157  decode.loss_mask: 0.2728  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.7739  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.1917  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.2705  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.2688  decode.d2.loss_dice: 0.1904  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.2661  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.1255  decode.d4.loss_mask: 0.2704  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.1310  decode.d5.loss_mask: 0.2689  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.1275  decode.d6.loss_mask: 0.2685  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.1207  decode.d7.loss_mask: 0.2673  decode.d7.loss_dice: 0.1908  decode.d8.loss_cls: 0.1200  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.1915
09/30 17:32:09 - mmengine - INFO - Iter(train) [ 70100/320000]  base_lr: 8.0049e-05 lr: 8.0049e-06  eta: 1 day, 6:11:59  time: 0.4380  data_time: 0.0094  memory: 5146  grad_norm: 47.8684  loss: 5.8627  decode.loss_cls: 0.0340  decode.loss_mask: 0.2275  decode.loss_dice: 0.1997  decode.d0.loss_cls: 1.0590  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.0532  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.1976  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.2300  decode.d2.loss_dice: 0.2074  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.2298  decode.d3.loss_dice: 0.2014  decode.d4.loss_cls: 0.0459  decode.d4.loss_mask: 0.2274  decode.d4.loss_dice: 0.2027  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.2293  decode.d5.loss_dice: 0.2117  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2031  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.2317  decode.d8.loss_dice: 0.2204
09/30 17:32:31 - mmengine - INFO - Iter(train) [ 70150/320000]  base_lr: 8.0035e-05 lr: 8.0035e-06  eta: 1 day, 6:11:37  time: 0.4378  data_time: 0.0094  memory: 5129  grad_norm: 85.3311  loss: 5.9547  decode.loss_cls: 0.0382  decode.loss_mask: 0.2564  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.7598  decode.d0.loss_mask: 0.2670  decode.d0.loss_dice: 0.2348  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.2153  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.2134  decode.d3.loss_cls: 0.0817  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.2139  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2132  decode.d5.loss_cls: 0.0405  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.2169  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.2255  decode.d7.loss_cls: 0.0275  decode.d7.loss_mask: 0.2590  decode.d7.loss_dice: 0.2235  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.2600  decode.d8.loss_dice: 0.2207
09/30 17:32:53 - mmengine - INFO - Iter(train) [ 70200/320000]  base_lr: 8.0020e-05 lr: 8.0020e-06  eta: 1 day, 6:11:16  time: 0.4378  data_time: 0.0095  memory: 5120  grad_norm: 32.6615  loss: 5.7308  decode.loss_cls: 0.1359  decode.loss_mask: 0.1845  decode.loss_dice: 0.1845  decode.d0.loss_cls: 0.7519  decode.d0.loss_mask: 0.1919  decode.d0.loss_dice: 0.1833  decode.d1.loss_cls: 0.0982  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1692  decode.d2.loss_cls: 0.1254  decode.d2.loss_mask: 0.1902  decode.d2.loss_dice: 0.1793  decode.d3.loss_cls: 0.1457  decode.d3.loss_mask: 0.1867  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.1468  decode.d4.loss_mask: 0.1879  decode.d4.loss_dice: 0.1813  decode.d5.loss_cls: 0.1517  decode.d5.loss_mask: 0.1860  decode.d5.loss_dice: 0.1836  decode.d6.loss_cls: 0.1543  decode.d6.loss_mask: 0.1925  decode.d6.loss_dice: 0.1889  decode.d7.loss_cls: 0.1406  decode.d7.loss_mask: 0.1876  decode.d7.loss_dice: 0.1961  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 0.1852  decode.d8.loss_dice: 0.1899
09/30 17:33:15 - mmengine - INFO - Iter(train) [ 70250/320000]  base_lr: 8.0006e-05 lr: 8.0006e-06  eta: 1 day, 6:10:55  time: 0.4383  data_time: 0.0096  memory: 5120  grad_norm: 76.1664  loss: 6.4176  decode.loss_cls: 0.0729  decode.loss_mask: 0.2588  decode.loss_dice: 0.2262  decode.d0.loss_cls: 0.9096  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.2237  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.2571  decode.d2.loss_dice: 0.2191  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.2226  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.2573  decode.d4.loss_dice: 0.2168  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.2180  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.2596  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.2582  decode.d8.loss_dice: 0.2220
09/30 17:33:37 - mmengine - INFO - Iter(train) [ 70300/320000]  base_lr: 7.9991e-05 lr: 7.9991e-06  eta: 1 day, 6:10:34  time: 0.4372  data_time: 0.0095  memory: 5120  grad_norm: 36.2463  loss: 5.4047  decode.loss_cls: 0.0288  decode.loss_mask: 0.2546  decode.loss_dice: 0.1686  decode.d0.loss_cls: 0.7994  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.1657  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.1670  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.2561  decode.d2.loss_dice: 0.1662  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.1659  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.2588  decode.d4.loss_dice: 0.1689  decode.d5.loss_cls: 0.0409  decode.d5.loss_mask: 0.2572  decode.d5.loss_dice: 0.1690  decode.d6.loss_cls: 0.0340  decode.d6.loss_mask: 0.2590  decode.d6.loss_dice: 0.1682  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.2558  decode.d7.loss_dice: 0.1673  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.2558  decode.d8.loss_dice: 0.1672
09/30 17:33:59 - mmengine - INFO - Iter(train) [ 70350/320000]  base_lr: 7.9977e-05 lr: 7.9977e-06  eta: 1 day, 6:10:13  time: 0.4380  data_time: 0.0094  memory: 5145  grad_norm: 18.1380  loss: 4.3632  decode.loss_cls: 0.0045  decode.loss_mask: 0.1936  decode.loss_dice: 0.1686  decode.d0.loss_cls: 0.7346  decode.d0.loss_mask: 0.1926  decode.d0.loss_dice: 0.1685  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.1945  decode.d1.loss_dice: 0.1679  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1934  decode.d3.loss_dice: 0.1651  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.1699  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.1672  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.1923  decode.d6.loss_dice: 0.1649  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1939  decode.d7.loss_dice: 0.1665  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.1937  decode.d8.loss_dice: 0.1635
09/30 17:34:21 - mmengine - INFO - Iter(train) [ 70400/320000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 1 day, 6:09:52  time: 0.4382  data_time: 0.0095  memory: 5145  grad_norm: 133.8926  loss: 5.4652  decode.loss_cls: 0.1289  decode.loss_mask: 0.1885  decode.loss_dice: 0.1571  decode.d0.loss_cls: 0.9072  decode.d0.loss_mask: 0.1885  decode.d0.loss_dice: 0.1562  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.1621  decode.d2.loss_cls: 0.1212  decode.d2.loss_mask: 0.1888  decode.d2.loss_dice: 0.1508  decode.d3.loss_cls: 0.1275  decode.d3.loss_mask: 0.1863  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 0.1870  decode.d4.loss_dice: 0.1545  decode.d5.loss_cls: 0.1299  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.1534  decode.d6.loss_cls: 0.1311  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.1555  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 0.1872  decode.d7.loss_dice: 0.1512  decode.d8.loss_cls: 0.1260  decode.d8.loss_mask: 0.1902  decode.d8.loss_dice: 0.1544
09/30 17:34:43 - mmengine - INFO - Iter(train) [ 70450/320000]  base_lr: 7.9948e-05 lr: 7.9948e-06  eta: 1 day, 6:09:31  time: 0.4383  data_time: 0.0098  memory: 5129  grad_norm: 55.9073  loss: 7.0958  decode.loss_cls: 0.1045  decode.loss_mask: 0.2900  decode.loss_dice: 0.2260  decode.d0.loss_cls: 0.8904  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.2521  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.2883  decode.d1.loss_dice: 0.2171  decode.d2.loss_cls: 0.1391  decode.d2.loss_mask: 0.2910  decode.d2.loss_dice: 0.2225  decode.d3.loss_cls: 0.1174  decode.d3.loss_mask: 0.2897  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.1208  decode.d5.loss_mask: 0.2906  decode.d5.loss_dice: 0.2339  decode.d6.loss_cls: 0.1094  decode.d6.loss_mask: 0.2920  decode.d6.loss_dice: 0.2284  decode.d7.loss_cls: 0.0395  decode.d7.loss_mask: 0.2939  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.0916  decode.d8.loss_mask: 0.2888  decode.d8.loss_dice: 0.2266
09/30 17:35:05 - mmengine - INFO - Iter(train) [ 70500/320000]  base_lr: 7.9934e-05 lr: 7.9934e-06  eta: 1 day, 6:09:09  time: 0.4382  data_time: 0.0095  memory: 5145  grad_norm: 28.2370  loss: 4.6951  decode.loss_cls: 0.0074  decode.loss_mask: 0.2038  decode.loss_dice: 0.1538  decode.d0.loss_cls: 0.9945  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.2042  decode.d1.loss_dice: 0.1594  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.2064  decode.d2.loss_dice: 0.1622  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.1605  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.2039  decode.d4.loss_dice: 0.1615  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.1582  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.1556  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2050  decode.d7.loss_dice: 0.1561  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.2037  decode.d8.loss_dice: 0.1563
09/30 17:35:27 - mmengine - INFO - Iter(train) [ 70550/320000]  base_lr: 7.9919e-05 lr: 7.9919e-06  eta: 1 day, 6:08:48  time: 0.4379  data_time: 0.0095  memory: 5129  grad_norm: 75.3230  loss: 6.4224  decode.loss_cls: 0.0951  decode.loss_mask: 0.2377  decode.loss_dice: 0.2502  decode.d0.loss_cls: 0.8185  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.2911  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.2351  decode.d1.loss_dice: 0.2321  decode.d2.loss_cls: 0.0980  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2372  decode.d3.loss_cls: 0.0862  decode.d3.loss_mask: 0.2404  decode.d3.loss_dice: 0.2592  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.2449  decode.d6.loss_cls: 0.0916  decode.d6.loss_mask: 0.2375  decode.d6.loss_dice: 0.2252  decode.d7.loss_cls: 0.0908  decode.d7.loss_mask: 0.2332  decode.d7.loss_dice: 0.2212  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.2367  decode.d8.loss_dice: 0.2411
09/30 17:35:49 - mmengine - INFO - Iter(train) [ 70600/320000]  base_lr: 7.9905e-05 lr: 7.9905e-06  eta: 1 day, 6:08:27  time: 0.4389  data_time: 0.0098  memory: 5129  grad_norm: 37.0455  loss: 5.3404  decode.loss_cls: 0.0721  decode.loss_mask: 0.2126  decode.loss_dice: 0.1754  decode.d0.loss_cls: 0.8704  decode.d0.loss_mask: 0.2135  decode.d0.loss_dice: 0.1759  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.2076  decode.d1.loss_dice: 0.1677  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.2111  decode.d2.loss_dice: 0.1707  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.2062  decode.d3.loss_dice: 0.1682  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 0.2093  decode.d4.loss_dice: 0.1680  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2064  decode.d5.loss_dice: 0.1662  decode.d6.loss_cls: 0.0819  decode.d6.loss_mask: 0.2084  decode.d6.loss_dice: 0.1686  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.1639  decode.d8.loss_cls: 0.0905  decode.d8.loss_mask: 0.2091  decode.d8.loss_dice: 0.1701
09/30 17:36:11 - mmengine - INFO - Iter(train) [ 70650/320000]  base_lr: 7.9890e-05 lr: 7.9890e-06  eta: 1 day, 6:08:06  time: 0.4368  data_time: 0.0092  memory: 5129  grad_norm: 132.8001  loss: 8.1965  decode.loss_cls: 0.2548  decode.loss_mask: 0.2280  decode.loss_dice: 0.2946  decode.d0.loss_cls: 0.9616  decode.d0.loss_mask: 0.2310  decode.d0.loss_dice: 0.2975  decode.d1.loss_cls: 0.1754  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.2696  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 0.2330  decode.d2.loss_dice: 0.2720  decode.d3.loss_cls: 0.2241  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2924  decode.d4.loss_cls: 0.1659  decode.d4.loss_mask: 0.2181  decode.d4.loss_dice: 0.2853  decode.d5.loss_cls: 0.1864  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.2669  decode.d6.loss_cls: 0.2355  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2808  decode.d7.loss_cls: 0.2503  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.2920  decode.d8.loss_cls: 0.2557  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.3027
09/30 17:36:32 - mmengine - INFO - Iter(train) [ 70700/320000]  base_lr: 7.9876e-05 lr: 7.9876e-06  eta: 1 day, 6:07:45  time: 0.4387  data_time: 0.0094  memory: 5129  grad_norm: 201.2422  loss: 6.5443  decode.loss_cls: 0.1184  decode.loss_mask: 0.2412  decode.loss_dice: 0.1925  decode.d0.loss_cls: 0.9045  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.2084  decode.d1.loss_cls: 0.1153  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.1883  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.1940  decode.d3.loss_cls: 0.1499  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.1999  decode.d4.loss_cls: 0.1130  decode.d4.loss_mask: 0.2453  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.1293  decode.d5.loss_mask: 0.2441  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 0.2416  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.1450  decode.d7.loss_mask: 0.2446  decode.d7.loss_dice: 0.1984  decode.d8.loss_cls: 0.1425  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.1958
09/30 17:36:54 - mmengine - INFO - Iter(train) [ 70750/320000]  base_lr: 7.9862e-05 lr: 7.9862e-06  eta: 1 day, 6:07:23  time: 0.4373  data_time: 0.0094  memory: 5145  grad_norm: 44.6625  loss: 5.1221  decode.loss_cls: 0.0369  decode.loss_mask: 0.1728  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.9777  decode.d0.loss_mask: 0.1738  decode.d0.loss_dice: 0.1712  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.1758  decode.d1.loss_dice: 0.1675  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.1728  decode.d2.loss_dice: 0.1658  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.1763  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.1718  decode.d5.loss_cls: 0.0920  decode.d5.loss_mask: 0.1733  decode.d5.loss_dice: 0.1641  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.1769  decode.d6.loss_dice: 0.1765  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.1740  decode.d7.loss_dice: 0.1752  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.1771  decode.d8.loss_dice: 0.1658
09/30 17:37:16 - mmengine - INFO - Iter(train) [ 70800/320000]  base_lr: 7.9847e-05 lr: 7.9847e-06  eta: 1 day, 6:07:02  time: 0.4389  data_time: 0.0095  memory: 5145  grad_norm: 18.6583  loss: 4.4591  decode.loss_cls: 0.0113  decode.loss_mask: 0.1829  decode.loss_dice: 0.1683  decode.d0.loss_cls: 0.7924  decode.d0.loss_mask: 0.1892  decode.d0.loss_dice: 0.1618  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.1853  decode.d2.loss_dice: 0.1640  decode.d3.loss_cls: 0.0287  decode.d3.loss_mask: 0.1844  decode.d3.loss_dice: 0.1663  decode.d4.loss_cls: 0.0212  decode.d4.loss_mask: 0.1839  decode.d4.loss_dice: 0.1666  decode.d5.loss_cls: 0.0197  decode.d5.loss_mask: 0.1820  decode.d5.loss_dice: 0.1651  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.1857  decode.d6.loss_dice: 0.1709  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.1831  decode.d7.loss_dice: 0.1652  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.1850  decode.d8.loss_dice: 0.1661
09/30 17:37:38 - mmengine - INFO - Iter(train) [ 70850/320000]  base_lr: 7.9833e-05 lr: 7.9833e-06  eta: 1 day, 6:06:41  time: 0.4383  data_time: 0.0095  memory: 5146  grad_norm: 164.1628  loss: 5.1664  decode.loss_cls: 0.0232  decode.loss_mask: 0.2272  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.7840  decode.d0.loss_mask: 0.2277  decode.d0.loss_dice: 0.1704  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 0.2199  decode.d1.loss_dice: 0.1491  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.1760  decode.d3.loss_cls: 0.0458  decode.d3.loss_mask: 0.2329  decode.d3.loss_dice: 0.1892  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.2260  decode.d4.loss_dice: 0.1740  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.1776  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.2262  decode.d6.loss_dice: 0.1786  decode.d7.loss_cls: 0.0221  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.1738  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.2256  decode.d8.loss_dice: 0.1747
09/30 17:38:00 - mmengine - INFO - Iter(train) [ 70900/320000]  base_lr: 7.9818e-05 lr: 7.9818e-06  eta: 1 day, 6:06:20  time: 0.4378  data_time: 0.0095  memory: 5129  grad_norm: 80.1249  loss: 6.6803  decode.loss_cls: 0.0354  decode.loss_mask: 0.2861  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.8070  decode.d0.loss_mask: 0.2954  decode.d0.loss_dice: 0.2670  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 0.2957  decode.d1.loss_dice: 0.2820  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.2912  decode.d2.loss_dice: 0.2726  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.2890  decode.d3.loss_dice: 0.2587  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.2545  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.2851  decode.d5.loss_dice: 0.2607  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.2633  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.2895  decode.d7.loss_dice: 0.2601  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.2662
09/30 17:38:22 - mmengine - INFO - Iter(train) [ 70950/320000]  base_lr: 7.9804e-05 lr: 7.9804e-06  eta: 1 day, 6:05:59  time: 0.4381  data_time: 0.0094  memory: 5120  grad_norm: 38.5057  loss: 5.3597  decode.loss_cls: 0.0723  decode.loss_mask: 0.1988  decode.loss_dice: 0.1740  decode.d0.loss_cls: 0.8339  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.1977  decode.d1.loss_dice: 0.2040  decode.d2.loss_cls: 0.0546  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.1783  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.2022  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.2000  decode.d5.loss_dice: 0.1734  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.1738  decode.d7.loss_cls: 0.0957  decode.d7.loss_mask: 0.1997  decode.d7.loss_dice: 0.1731  decode.d8.loss_cls: 0.0769  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.1727
09/30 17:38:44 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:38:44 - mmengine - INFO - Iter(train) [ 71000/320000]  base_lr: 7.9789e-05 lr: 7.9789e-06  eta: 1 day, 6:05:37  time: 0.4371  data_time: 0.0095  memory: 5145  grad_norm: 30.3719  loss: 6.1671  decode.loss_cls: 0.0096  decode.loss_mask: 0.2845  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.9021  decode.d0.loss_mask: 0.2927  decode.d0.loss_dice: 0.2135  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.2374  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.2271  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.2812  decode.d3.loss_dice: 0.2338  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.2805  decode.d4.loss_dice: 0.2309  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.2826  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.2273  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2824  decode.d7.loss_dice: 0.2357  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.2431
09/30 17:39:06 - mmengine - INFO - Iter(train) [ 71050/320000]  base_lr: 7.9775e-05 lr: 7.9775e-06  eta: 1 day, 6:05:16  time: 0.4383  data_time: 0.0096  memory: 5120  grad_norm: 46.0419  loss: 6.2444  decode.loss_cls: 0.1507  decode.loss_mask: 0.2086  decode.loss_dice: 0.1531  decode.d0.loss_cls: 1.0111  decode.d0.loss_mask: 0.2094  decode.d0.loss_dice: 0.1564  decode.d1.loss_cls: 0.1532  decode.d1.loss_mask: 0.2131  decode.d1.loss_dice: 0.1597  decode.d2.loss_cls: 0.1922  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.1640  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.1614  decode.d4.loss_cls: 0.1689  decode.d4.loss_mask: 0.2316  decode.d4.loss_dice: 0.1592  decode.d5.loss_cls: 0.1688  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.1547  decode.d6.loss_cls: 0.1599  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.1539  decode.d7.loss_cls: 0.1646  decode.d7.loss_mask: 0.2090  decode.d7.loss_dice: 0.1539  decode.d8.loss_cls: 0.1393  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.1530
09/30 17:39:28 - mmengine - INFO - Iter(train) [ 71100/320000]  base_lr: 7.9761e-05 lr: 7.9761e-06  eta: 1 day, 6:04:55  time: 0.4374  data_time: 0.0096  memory: 5129  grad_norm: 65.0075  loss: 7.1709  decode.loss_cls: 0.0926  decode.loss_mask: 0.2706  decode.loss_dice: 0.2518  decode.d0.loss_cls: 0.8094  decode.d0.loss_mask: 0.2726  decode.d0.loss_dice: 0.2581  decode.d1.loss_cls: 0.1355  decode.d1.loss_mask: 0.2683  decode.d1.loss_dice: 0.2447  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2489  decode.d3.loss_cls: 0.2226  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.2508  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.2636  decode.d5.loss_cls: 0.0902  decode.d5.loss_mask: 0.2694  decode.d5.loss_dice: 0.2356  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2740  decode.d6.loss_dice: 0.2496  decode.d7.loss_cls: 0.0975  decode.d7.loss_mask: 0.2672  decode.d7.loss_dice: 0.2325  decode.d8.loss_cls: 0.1499  decode.d8.loss_mask: 0.2746  decode.d8.loss_dice: 0.2517
09/30 17:39:50 - mmengine - INFO - Iter(train) [ 71150/320000]  base_lr: 7.9746e-05 lr: 7.9746e-06  eta: 1 day, 6:04:33  time: 0.4374  data_time: 0.0095  memory: 5120  grad_norm: 32.0858  loss: 7.0345  decode.loss_cls: 0.1225  decode.loss_mask: 0.2406  decode.loss_dice: 0.2633  decode.d0.loss_cls: 0.8024  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.2641  decode.d1.loss_cls: 0.1324  decode.d1.loss_mask: 0.2397  decode.d1.loss_dice: 0.2604  decode.d2.loss_cls: 0.1368  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.2606  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.1185  decode.d4.loss_mask: 0.2416  decode.d4.loss_dice: 0.2608  decode.d5.loss_cls: 0.1030  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.2765  decode.d6.loss_cls: 0.1528  decode.d6.loss_mask: 0.2407  decode.d6.loss_dice: 0.2644  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 0.2382  decode.d7.loss_dice: 0.2607  decode.d8.loss_cls: 0.1217  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.2615
09/30 17:40:11 - mmengine - INFO - Iter(train) [ 71200/320000]  base_lr: 7.9732e-05 lr: 7.9732e-06  eta: 1 day, 6:04:12  time: 0.4369  data_time: 0.0095  memory: 5104  grad_norm: 18.2999  loss: 5.0958  decode.loss_cls: 0.0133  decode.loss_mask: 0.2327  decode.loss_dice: 0.1715  decode.d0.loss_cls: 0.8934  decode.d0.loss_mask: 0.2381  decode.d0.loss_dice: 0.1675  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.1723  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.1725  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.2365  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.1740  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.1751  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.2338  decode.d6.loss_dice: 0.1717  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.1713  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.2308  decode.d8.loss_dice: 0.1701
09/30 17:40:33 - mmengine - INFO - Iter(train) [ 71250/320000]  base_lr: 7.9717e-05 lr: 7.9717e-06  eta: 1 day, 6:03:51  time: 0.4387  data_time: 0.0096  memory: 5129  grad_norm: 41.0580  loss: 6.8306  decode.loss_cls: 0.1609  decode.loss_mask: 0.2070  decode.loss_dice: 0.2005  decode.d0.loss_cls: 0.8196  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2373  decode.d1.loss_cls: 0.1629  decode.d1.loss_mask: 0.2065  decode.d1.loss_dice: 0.2266  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.2108  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.2715  decode.d3.loss_dice: 0.2543  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.2063  decode.d4.loss_dice: 0.2180  decode.d5.loss_cls: 0.1635  decode.d5.loss_mask: 0.2092  decode.d5.loss_dice: 0.2067  decode.d6.loss_cls: 0.1387  decode.d6.loss_mask: 0.3495  decode.d6.loss_dice: 0.2582  decode.d7.loss_cls: 0.1528  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2192  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.2275
09/30 17:40:55 - mmengine - INFO - Iter(train) [ 71300/320000]  base_lr: 7.9703e-05 lr: 7.9703e-06  eta: 1 day, 6:03:30  time: 0.4385  data_time: 0.0095  memory: 5145  grad_norm: 57.9223  loss: 5.8337  decode.loss_cls: 0.0141  decode.loss_mask: 0.2799  decode.loss_dice: 0.2052  decode.d0.loss_cls: 0.8289  decode.d0.loss_mask: 0.2913  decode.d0.loss_dice: 0.2029  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.2828  decode.d2.loss_dice: 0.2016  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.2017  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.2823  decode.d4.loss_dice: 0.2014  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.2738  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.2817  decode.d6.loss_dice: 0.2205  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.2810  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.2052
09/30 17:41:17 - mmengine - INFO - Iter(train) [ 71350/320000]  base_lr: 7.9689e-05 lr: 7.9689e-06  eta: 1 day, 6:03:08  time: 0.4382  data_time: 0.0095  memory: 5120  grad_norm: 40.7357  loss: 6.0548  decode.loss_cls: 0.0751  decode.loss_mask: 0.2633  decode.loss_dice: 0.1854  decode.d0.loss_cls: 0.7828  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.1956  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.1832  decode.d2.loss_cls: 0.1200  decode.d2.loss_mask: 0.2627  decode.d2.loss_dice: 0.1731  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2662  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.1756  decode.d5.loss_cls: 0.0962  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.1899  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.2667  decode.d6.loss_dice: 0.1835  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.2679  decode.d7.loss_dice: 0.1873  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.2676  decode.d8.loss_dice: 0.1791
09/30 17:41:39 - mmengine - INFO - Iter(train) [ 71400/320000]  base_lr: 7.9674e-05 lr: 7.9674e-06  eta: 1 day, 6:02:47  time: 0.4380  data_time: 0.0093  memory: 5120  grad_norm: 42.2655  loss: 4.6435  decode.loss_cls: 0.0125  decode.loss_mask: 0.2135  decode.loss_dice: 0.1565  decode.d0.loss_cls: 0.8059  decode.d0.loss_mask: 0.2126  decode.d0.loss_dice: 0.1554  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.1445  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.1475  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.2127  decode.d3.loss_dice: 0.1436  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.2161  decode.d4.loss_dice: 0.1472  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.1493  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.1505  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.1514  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.1510
09/30 17:42:01 - mmengine - INFO - Iter(train) [ 71450/320000]  base_lr: 7.9660e-05 lr: 7.9660e-06  eta: 1 day, 6:02:26  time: 0.4379  data_time: 0.0094  memory: 5129  grad_norm: 72.9681  loss: 7.8148  decode.loss_cls: 0.1709  decode.loss_mask: 0.2550  decode.loss_dice: 0.2645  decode.d0.loss_cls: 0.8491  decode.d0.loss_mask: 0.2943  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.1985  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.2563  decode.d2.loss_cls: 0.1820  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.2576  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 0.2504  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.1751  decode.d4.loss_mask: 0.2650  decode.d4.loss_dice: 0.2815  decode.d5.loss_cls: 0.1858  decode.d5.loss_mask: 0.2557  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.2085  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.2658  decode.d7.loss_cls: 0.1870  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.2678  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 0.2672  decode.d8.loss_dice: 0.2759
09/30 17:42:23 - mmengine - INFO - Iter(train) [ 71500/320000]  base_lr: 7.9645e-05 lr: 7.9645e-06  eta: 1 day, 6:02:04  time: 0.4368  data_time: 0.0094  memory: 5145  grad_norm: 57.2411  loss: 5.8100  decode.loss_cls: 0.0958  decode.loss_mask: 0.1976  decode.loss_dice: 0.2116  decode.d0.loss_cls: 0.9072  decode.d0.loss_mask: 0.2064  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.1992  decode.d1.loss_dice: 0.2087  decode.d2.loss_cls: 0.0905  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.0885  decode.d3.loss_mask: 0.1962  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.1937  decode.d4.loss_dice: 0.2097  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 0.1954  decode.d5.loss_dice: 0.2001  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.2160  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.2142  decode.d8.loss_cls: 0.0982  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.2073
09/30 17:42:45 - mmengine - INFO - Iter(train) [ 71550/320000]  base_lr: 7.9631e-05 lr: 7.9631e-06  eta: 1 day, 6:01:43  time: 0.4380  data_time: 0.0094  memory: 5129  grad_norm: 89.4979  loss: 7.8044  decode.loss_cls: 0.1460  decode.loss_mask: 0.2872  decode.loss_dice: 0.2349  decode.d0.loss_cls: 1.2091  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.2477  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.1599  decode.d2.loss_mask: 0.2897  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.1435  decode.d3.loss_mask: 0.2855  decode.d3.loss_dice: 0.2336  decode.d4.loss_cls: 0.1294  decode.d4.loss_mask: 0.2855  decode.d4.loss_dice: 0.2309  decode.d5.loss_cls: 0.1188  decode.d5.loss_mask: 0.2852  decode.d5.loss_dice: 0.2300  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.2278  decode.d7.loss_cls: 0.1335  decode.d7.loss_mask: 0.2854  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.1418  decode.d8.loss_mask: 0.2884  decode.d8.loss_dice: 0.2362
09/30 17:43:07 - mmengine - INFO - Iter(train) [ 71600/320000]  base_lr: 7.9616e-05 lr: 7.9616e-06  eta: 1 day, 6:01:22  time: 0.4376  data_time: 0.0095  memory: 5145  grad_norm: 59.3877  loss: 6.1785  decode.loss_cls: 0.0911  decode.loss_mask: 0.2224  decode.loss_dice: 0.2441  decode.d0.loss_cls: 0.8654  decode.d0.loss_mask: 0.2252  decode.d0.loss_dice: 0.2023  decode.d1.loss_cls: 0.0909  decode.d1.loss_mask: 0.2242  decode.d1.loss_dice: 0.2385  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.2242  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 0.2226  decode.d3.loss_dice: 0.2304  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.2310  decode.d5.loss_cls: 0.0879  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.2158  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.2356  decode.d7.loss_cls: 0.0962  decode.d7.loss_mask: 0.2205  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.0858  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.2393
09/30 17:43:29 - mmengine - INFO - Iter(train) [ 71650/320000]  base_lr: 7.9602e-05 lr: 7.9602e-06  eta: 1 day, 6:01:01  time: 0.4382  data_time: 0.0096  memory: 5145  grad_norm: 132.0624  loss: 7.2281  decode.loss_cls: 0.1629  decode.loss_mask: 0.2592  decode.loss_dice: 0.2639  decode.d0.loss_cls: 0.9111  decode.d0.loss_mask: 0.2664  decode.d0.loss_dice: 0.2668  decode.d1.loss_cls: 0.1164  decode.d1.loss_mask: 0.2616  decode.d1.loss_dice: 0.2446  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.2584  decode.d2.loss_dice: 0.2671  decode.d3.loss_cls: 0.0973  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.2526  decode.d4.loss_cls: 0.1049  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.0966  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2872  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.2601  decode.d7.loss_dice: 0.3031  decode.d8.loss_cls: 0.1705  decode.d8.loss_mask: 0.2587  decode.d8.loss_dice: 0.2793
09/30 17:43:51 - mmengine - INFO - Iter(train) [ 71700/320000]  base_lr: 7.9588e-05 lr: 7.9588e-06  eta: 1 day, 6:00:39  time: 0.4375  data_time: 0.0095  memory: 5129  grad_norm: 33.1087  loss: 5.8474  decode.loss_cls: 0.0347  decode.loss_mask: 0.1982  decode.loss_dice: 0.2531  decode.d0.loss_cls: 0.8724  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.2589  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.1984  decode.d1.loss_dice: 0.2565  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.2525  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.1999  decode.d3.loss_dice: 0.2520  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.2487  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.1970  decode.d5.loss_dice: 0.2434  decode.d6.loss_cls: 0.0377  decode.d6.loss_mask: 0.1966  decode.d6.loss_dice: 0.2464  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.1940  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.1971  decode.d8.loss_dice: 0.2485
09/30 17:44:12 - mmengine - INFO - Iter(train) [ 71750/320000]  base_lr: 7.9573e-05 lr: 7.9573e-06  eta: 1 day, 6:00:18  time: 0.4380  data_time: 0.0096  memory: 5129  grad_norm: 44.8919  loss: 5.0651  decode.loss_cls: 0.0568  decode.loss_mask: 0.1967  decode.loss_dice: 0.1873  decode.d0.loss_cls: 0.7356  decode.d0.loss_mask: 0.1966  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.0873  decode.d1.loss_mask: 0.1935  decode.d1.loss_dice: 0.1661  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.1936  decode.d2.loss_dice: 0.1607  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.1929  decode.d3.loss_dice: 0.1702  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.1920  decode.d4.loss_dice: 0.1786  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.1924  decode.d5.loss_dice: 0.1689  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.1943  decode.d6.loss_dice: 0.1711  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.1966  decode.d7.loss_dice: 0.1814  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.1956  decode.d8.loss_dice: 0.1929
09/30 17:44:34 - mmengine - INFO - Iter(train) [ 71800/320000]  base_lr: 7.9559e-05 lr: 7.9559e-06  eta: 1 day, 5:59:57  time: 0.4371  data_time: 0.0094  memory: 5145  grad_norm: 98.6159  loss: 5.8696  decode.loss_cls: 0.1440  decode.loss_mask: 0.1888  decode.loss_dice: 0.1880  decode.d0.loss_cls: 0.8307  decode.d0.loss_mask: 0.1906  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.2037  decode.d2.loss_cls: 0.1410  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.1979  decode.d3.loss_cls: 0.1147  decode.d3.loss_mask: 0.1882  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.1242  decode.d4.loss_mask: 0.1923  decode.d4.loss_dice: 0.2107  decode.d5.loss_cls: 0.1130  decode.d5.loss_mask: 0.1894  decode.d5.loss_dice: 0.1856  decode.d6.loss_cls: 0.1326  decode.d6.loss_mask: 0.1877  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.1516  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.1801  decode.d8.loss_cls: 0.1508  decode.d8.loss_mask: 0.1889  decode.d8.loss_dice: 0.1931
09/30 17:44:56 - mmengine - INFO - Iter(train) [ 71850/320000]  base_lr: 7.9544e-05 lr: 7.9544e-06  eta: 1 day, 5:59:35  time: 0.4377  data_time: 0.0095  memory: 5145  grad_norm: 61.3315  loss: 6.1320  decode.loss_cls: 0.0523  decode.loss_mask: 0.2728  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.8367  decode.d0.loss_mask: 0.2788  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.2755  decode.d3.loss_dice: 0.1933  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.1907  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.2703  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.2775  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.2745  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0975  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.1920
09/30 17:45:18 - mmengine - INFO - Iter(train) [ 71900/320000]  base_lr: 7.9530e-05 lr: 7.9530e-06  eta: 1 day, 5:59:14  time: 0.4372  data_time: 0.0095  memory: 5130  grad_norm: 90.1334  loss: 9.3875  decode.loss_cls: 0.2785  decode.loss_mask: 0.3248  decode.loss_dice: 0.3312  decode.d0.loss_cls: 0.9344  decode.d0.loss_mask: 0.2718  decode.d0.loss_dice: 0.3166  decode.d1.loss_cls: 0.2255  decode.d1.loss_mask: 0.2760  decode.d1.loss_dice: 0.3169  decode.d2.loss_cls: 0.2745  decode.d2.loss_mask: 0.2852  decode.d2.loss_dice: 0.3203  decode.d3.loss_cls: 0.2695  decode.d3.loss_mask: 0.2711  decode.d3.loss_dice: 0.3250  decode.d4.loss_cls: 0.2803  decode.d4.loss_mask: 0.2669  decode.d4.loss_dice: 0.3100  decode.d5.loss_cls: 0.2909  decode.d5.loss_mask: 0.2731  decode.d5.loss_dice: 0.3155  decode.d6.loss_cls: 0.2673  decode.d6.loss_mask: 0.2922  decode.d6.loss_dice: 0.3206  decode.d7.loss_cls: 0.2775  decode.d7.loss_mask: 0.3055  decode.d7.loss_dice: 0.3420  decode.d8.loss_cls: 0.2337  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.2944
09/30 17:45:40 - mmengine - INFO - Iter(train) [ 71950/320000]  base_lr: 7.9515e-05 lr: 7.9515e-06  eta: 1 day, 5:58:53  time: 0.4389  data_time: 0.0097  memory: 5120  grad_norm: 68.2403  loss: 5.1956  decode.loss_cls: 0.0517  decode.loss_mask: 0.2091  decode.loss_dice: 0.1645  decode.d0.loss_cls: 0.9046  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.1795  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.1697  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.2147  decode.d2.loss_dice: 0.1778  decode.d3.loss_cls: 0.0484  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.1693  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.1690  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.1760  decode.d6.loss_cls: 0.0421  decode.d6.loss_mask: 0.2104  decode.d6.loss_dice: 0.1754  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.2073  decode.d8.loss_dice: 0.1664
09/30 17:46:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:46:02 - mmengine - INFO - Iter(train) [ 72000/320000]  base_lr: 7.9501e-05 lr: 7.9501e-06  eta: 1 day, 5:58:33  time: 0.4404  data_time: 0.0098  memory: 5129  grad_norm: 41.3837  loss: 5.9142  decode.loss_cls: 0.0917  decode.loss_mask: 0.2529  decode.loss_dice: 0.2185  decode.d0.loss_cls: 0.8076  decode.d0.loss_mask: 0.2454  decode.d0.loss_dice: 0.2118  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.2146  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.2083  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.2537  decode.d3.loss_dice: 0.2063  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2455  decode.d4.loss_dice: 0.2318  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.2535  decode.d5.loss_dice: 0.2469  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2346  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.2248  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.2310
09/30 17:46:24 - mmengine - INFO - Iter(train) [ 72050/320000]  base_lr: 7.9487e-05 lr: 7.9487e-06  eta: 1 day, 5:58:12  time: 0.4386  data_time: 0.0098  memory: 5129  grad_norm: 54.0539  loss: 5.5813  decode.loss_cls: 0.0233  decode.loss_mask: 0.2351  decode.loss_dice: 0.1949  decode.d0.loss_cls: 0.9121  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.1952  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.1944  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.1908  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.2336  decode.d3.loss_dice: 0.1921  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.2354  decode.d4.loss_dice: 0.1909  decode.d5.loss_cls: 0.0308  decode.d5.loss_mask: 0.2350  decode.d5.loss_dice: 0.1955  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1882  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.2029  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.1966
09/30 17:46:46 - mmengine - INFO - Iter(train) [ 72100/320000]  base_lr: 7.9472e-05 lr: 7.9472e-06  eta: 1 day, 5:57:51  time: 0.4393  data_time: 0.0098  memory: 5130  grad_norm: 37.3056  loss: 6.4023  decode.loss_cls: 0.0999  decode.loss_mask: 0.2570  decode.loss_dice: 0.2125  decode.d0.loss_cls: 0.8076  decode.d0.loss_mask: 0.2641  decode.d0.loss_dice: 0.2279  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.2629  decode.d1.loss_dice: 0.2125  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.1949  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.2612  decode.d3.loss_dice: 0.2235  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.2589  decode.d4.loss_dice: 0.2356  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2165  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2580  decode.d6.loss_dice: 0.2507  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.2584  decode.d7.loss_dice: 0.2133  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.2597  decode.d8.loss_dice: 0.2375
09/30 17:47:08 - mmengine - INFO - Iter(train) [ 72150/320000]  base_lr: 7.9458e-05 lr: 7.9458e-06  eta: 1 day, 5:57:30  time: 0.4401  data_time: 0.0098  memory: 5129  grad_norm: 32.6106  loss: 6.5215  decode.loss_cls: 0.0473  decode.loss_mask: 0.3086  decode.loss_dice: 0.2271  decode.d0.loss_cls: 0.8006  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.1346  decode.d1.loss_mask: 0.2225  decode.d1.loss_dice: 0.2261  decode.d2.loss_cls: 0.1101  decode.d2.loss_mask: 0.2206  decode.d2.loss_dice: 0.2045  decode.d3.loss_cls: 0.1279  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.2006  decode.d4.loss_cls: 0.1461  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.1260  decode.d5.loss_mask: 0.2241  decode.d5.loss_dice: 0.2218  decode.d6.loss_cls: 0.1234  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2409  decode.d7.loss_cls: 0.1556  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.2230  decode.d8.loss_cls: 0.1565  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.2330
09/30 17:47:30 - mmengine - INFO - Iter(train) [ 72200/320000]  base_lr: 7.9443e-05 lr: 7.9443e-06  eta: 1 day, 5:57:09  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 54.6499  loss: 5.1670  decode.loss_cls: 0.0691  decode.loss_mask: 0.2168  decode.loss_dice: 0.1473  decode.d0.loss_cls: 0.8487  decode.d0.loss_mask: 0.2190  decode.d0.loss_dice: 0.1470  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1470  decode.d2.loss_cls: 0.1400  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.1462  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.1431  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.2181  decode.d4.loss_dice: 0.1440  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.2168  decode.d5.loss_dice: 0.1434  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.2312  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0725  decode.d7.loss_mask: 0.2144  decode.d7.loss_dice: 0.1419  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.1425
09/30 17:47:52 - mmengine - INFO - Iter(train) [ 72250/320000]  base_lr: 7.9429e-05 lr: 7.9429e-06  eta: 1 day, 5:56:48  time: 0.4379  data_time: 0.0096  memory: 5145  grad_norm: 60.9470  loss: 5.8464  decode.loss_cls: 0.0648  decode.loss_mask: 0.2485  decode.loss_dice: 0.1936  decode.d0.loss_cls: 0.8022  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.2063  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 0.2462  decode.d1.loss_dice: 0.2045  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.2000  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.2497  decode.d3.loss_dice: 0.2000  decode.d4.loss_cls: 0.0521  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.0546  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2036  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.2482  decode.d6.loss_dice: 0.2090  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.2473  decode.d7.loss_dice: 0.2001  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.2486  decode.d8.loss_dice: 0.1930
09/30 17:48:14 - mmengine - INFO - Iter(train) [ 72300/320000]  base_lr: 7.9414e-05 lr: 7.9414e-06  eta: 1 day, 5:56:26  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 75.0128  loss: 5.9401  decode.loss_cls: 0.1837  decode.loss_mask: 0.2141  decode.loss_dice: 0.1848  decode.d0.loss_cls: 0.9315  decode.d0.loss_mask: 0.2104  decode.d0.loss_dice: 0.2048  decode.d1.loss_cls: 0.0907  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.1917  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.2198  decode.d3.loss_dice: 0.1965  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.2153  decode.d4.loss_dice: 0.1984  decode.d5.loss_cls: 0.0859  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.1856  decode.d6.loss_cls: 0.1055  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.1965  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.1953  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.1890
09/30 17:48:36 - mmengine - INFO - Iter(train) [ 72350/320000]  base_lr: 7.9400e-05 lr: 7.9400e-06  eta: 1 day, 5:56:06  time: 0.4398  data_time: 0.0097  memory: 5120  grad_norm: 62.8541  loss: 6.7109  decode.loss_cls: 0.0624  decode.loss_mask: 0.2718  decode.loss_dice: 0.2860  decode.d0.loss_cls: 0.6910  decode.d0.loss_mask: 0.2840  decode.d0.loss_dice: 0.2851  decode.d1.loss_cls: 0.0681  decode.d1.loss_mask: 0.2795  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.2769  decode.d2.loss_dice: 0.2587  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.2803  decode.d3.loss_dice: 0.2679  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.2578  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.2769  decode.d5.loss_dice: 0.2618  decode.d6.loss_cls: 0.0556  decode.d6.loss_mask: 0.2782  decode.d6.loss_dice: 0.2725  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.2374  decode.d8.loss_cls: 0.0815  decode.d8.loss_mask: 0.2747  decode.d8.loss_dice: 0.2470
09/30 17:48:58 - mmengine - INFO - Iter(train) [ 72400/320000]  base_lr: 7.9386e-05 lr: 7.9386e-06  eta: 1 day, 5:55:45  time: 0.4394  data_time: 0.0094  memory: 5129  grad_norm: 61.6825  loss: 9.6390  decode.loss_cls: 0.3137  decode.loss_mask: 0.2776  decode.loss_dice: 0.2910  decode.d0.loss_cls: 1.0007  decode.d0.loss_mask: 0.2826  decode.d0.loss_dice: 0.2456  decode.d1.loss_cls: 0.3379  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.2514  decode.d2.loss_cls: 0.3035  decode.d2.loss_mask: 0.2840  decode.d2.loss_dice: 0.2641  decode.d3.loss_cls: 0.3153  decode.d3.loss_mask: 0.2949  decode.d3.loss_dice: 0.2810  decode.d4.loss_cls: 0.3910  decode.d4.loss_mask: 0.3593  decode.d4.loss_dice: 0.2784  decode.d5.loss_cls: 0.3335  decode.d5.loss_mask: 0.2809  decode.d5.loss_dice: 0.2723  decode.d6.loss_cls: 0.3394  decode.d6.loss_mask: 0.3285  decode.d6.loss_dice: 0.2954  decode.d7.loss_cls: 0.3046  decode.d7.loss_mask: 0.2889  decode.d7.loss_dice: 0.2732  decode.d8.loss_cls: 0.3321  decode.d8.loss_mask: 0.2745  decode.d8.loss_dice: 0.2796
09/30 17:49:20 - mmengine - INFO - Iter(train) [ 72450/320000]  base_lr: 7.9371e-05 lr: 7.9371e-06  eta: 1 day, 5:55:24  time: 0.4399  data_time: 0.0096  memory: 5120  grad_norm: 51.1773  loss: 6.9735  decode.loss_cls: 0.0982  decode.loss_mask: 0.2764  decode.loss_dice: 0.2211  decode.d0.loss_cls: 0.7910  decode.d0.loss_mask: 0.2748  decode.d0.loss_dice: 0.2355  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.2167  decode.d2.loss_cls: 0.2111  decode.d2.loss_mask: 0.2752  decode.d2.loss_dice: 0.2179  decode.d3.loss_cls: 0.1570  decode.d3.loss_mask: 0.2687  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.1482  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.1100  decode.d5.loss_mask: 0.2759  decode.d5.loss_dice: 0.2228  decode.d6.loss_cls: 0.1168  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.1077  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.1100  decode.d8.loss_mask: 0.2758  decode.d8.loss_dice: 0.2289
09/30 17:49:42 - mmengine - INFO - Iter(train) [ 72500/320000]  base_lr: 7.9357e-05 lr: 7.9357e-06  eta: 1 day, 5:55:03  time: 0.4396  data_time: 0.0096  memory: 5120  grad_norm: 41.9573  loss: 5.7376  decode.loss_cls: 0.1121  decode.loss_mask: 0.2224  decode.loss_dice: 0.1921  decode.d0.loss_cls: 0.8247  decode.d0.loss_mask: 0.2269  decode.d0.loss_dice: 0.2170  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.2238  decode.d1.loss_dice: 0.1925  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.2234  decode.d2.loss_dice: 0.1872  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.2196  decode.d3.loss_dice: 0.1923  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.1476  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.1823  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.1167  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.1877  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.2246  decode.d8.loss_dice: 0.1920
09/30 17:50:04 - mmengine - INFO - Iter(train) [ 72550/320000]  base_lr: 7.9342e-05 lr: 7.9342e-06  eta: 1 day, 5:54:42  time: 0.4396  data_time: 0.0095  memory: 5120  grad_norm: 153.5434  loss: 6.4224  decode.loss_cls: 0.0620  decode.loss_mask: 0.2225  decode.loss_dice: 0.2596  decode.d0.loss_cls: 0.9736  decode.d0.loss_mask: 0.2213  decode.d0.loss_dice: 0.2535  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.2264  decode.d1.loss_dice: 0.2755  decode.d2.loss_cls: 0.0149  decode.d2.loss_mask: 0.2203  decode.d2.loss_dice: 0.2790  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.2746  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.2626  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.2699  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 0.2205  decode.d6.loss_dice: 0.2698  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.2825  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.2889
09/30 17:50:26 - mmengine - INFO - Iter(train) [ 72600/320000]  base_lr: 7.9328e-05 lr: 7.9328e-06  eta: 1 day, 5:54:21  time: 0.4399  data_time: 0.0094  memory: 5129  grad_norm: 68.5439  loss: 5.8684  decode.loss_cls: 0.0150  decode.loss_mask: 0.2867  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.8071  decode.d0.loss_mask: 0.2965  decode.d0.loss_dice: 0.2031  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.2031  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.2877  decode.d2.loss_dice: 0.2027  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.2058  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.2025  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.2857  decode.d5.loss_dice: 0.2049  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.2844  decode.d6.loss_dice: 0.2056  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.2851  decode.d7.loss_dice: 0.2051  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2845  decode.d8.loss_dice: 0.2081
09/30 17:50:48 - mmengine - INFO - Iter(train) [ 72650/320000]  base_lr: 7.9313e-05 lr: 7.9313e-06  eta: 1 day, 5:54:00  time: 0.4403  data_time: 0.0096  memory: 5145  grad_norm: 44.8799  loss: 6.4036  decode.loss_cls: 0.0415  decode.loss_mask: 0.2703  decode.loss_dice: 0.2070  decode.d0.loss_cls: 0.8389  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.1636  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.2761  decode.d2.loss_dice: 0.2097  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.2745  decode.d3.loss_dice: 0.2142  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.2735  decode.d4.loss_dice: 0.2033  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2106  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.2765  decode.d6.loss_dice: 0.2135  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2007  decode.d8.loss_cls: 0.0341  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.2090
09/30 17:51:10 - mmengine - INFO - Iter(train) [ 72700/320000]  base_lr: 7.9299e-05 lr: 7.9299e-06  eta: 1 day, 5:53:39  time: 0.4402  data_time: 0.0095  memory: 5120  grad_norm: 17.7227  loss: 4.4546  decode.loss_cls: 0.0083  decode.loss_mask: 0.2078  decode.loss_dice: 0.1482  decode.d0.loss_cls: 0.7854  decode.d0.loss_mask: 0.2101  decode.d0.loss_dice: 0.1487  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.1520  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1506  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.2084  decode.d3.loss_dice: 0.1487  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.1495  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.2092  decode.d5.loss_dice: 0.1563  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.2078  decode.d6.loss_dice: 0.1503  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.1485  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2101  decode.d8.loss_dice: 0.1540
09/30 17:51:32 - mmengine - INFO - Iter(train) [ 72750/320000]  base_lr: 7.9285e-05 lr: 7.9285e-06  eta: 1 day, 5:53:18  time: 0.4398  data_time: 0.0096  memory: 5129  grad_norm: 18.0061  loss: 3.8668  decode.loss_cls: 0.0091  decode.loss_mask: 0.1648  decode.loss_dice: 0.1369  decode.d0.loss_cls: 0.7580  decode.d0.loss_mask: 0.1666  decode.d0.loss_dice: 0.1390  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.1667  decode.d1.loss_dice: 0.1383  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.1682  decode.d2.loss_dice: 0.1395  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.1654  decode.d3.loss_dice: 0.1353  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.1666  decode.d4.loss_dice: 0.1341  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.1675  decode.d5.loss_dice: 0.1370  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.1681  decode.d6.loss_dice: 0.1350  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.1688  decode.d7.loss_dice: 0.1374  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.1644  decode.d8.loss_dice: 0.1354
09/30 17:51:54 - mmengine - INFO - Iter(train) [ 72800/320000]  base_lr: 7.9270e-05 lr: 7.9270e-06  eta: 1 day, 5:52:56  time: 0.4378  data_time: 0.0095  memory: 5145  grad_norm: 92.8153  loss: 5.9878  decode.loss_cls: 0.0710  decode.loss_mask: 0.2195  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.8038  decode.d0.loss_mask: 0.2215  decode.d0.loss_dice: 0.2284  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.2204  decode.d1.loss_dice: 0.2309  decode.d2.loss_cls: 0.1541  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.2219  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.2171  decode.d3.loss_dice: 0.2312  decode.d4.loss_cls: 0.0485  decode.d4.loss_mask: 0.2202  decode.d4.loss_dice: 0.2262  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.2180  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.2168  decode.d6.loss_dice: 0.2205  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.2155  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.2223  decode.d8.loss_dice: 0.2394
09/30 17:52:16 - mmengine - INFO - Iter(train) [ 72850/320000]  base_lr: 7.9256e-05 lr: 7.9256e-06  eta: 1 day, 5:52:35  time: 0.4383  data_time: 0.0095  memory: 5120  grad_norm: 23.8603  loss: 4.8827  decode.loss_cls: 0.0629  decode.loss_mask: 0.2213  decode.loss_dice: 0.1852  decode.d0.loss_cls: 0.7917  decode.d0.loss_mask: 0.2015  decode.d0.loss_dice: 0.1619  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.1995  decode.d1.loss_dice: 0.1515  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.1995  decode.d2.loss_dice: 0.1545  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.1609  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.1993  decode.d4.loss_dice: 0.1556  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.2002  decode.d5.loss_dice: 0.1556  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1571  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.2051  decode.d7.loss_dice: 0.1595  decode.d8.loss_cls: 0.0403  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.1772
09/30 17:52:38 - mmengine - INFO - Iter(train) [ 72900/320000]  base_lr: 7.9241e-05 lr: 7.9241e-06  eta: 1 day, 5:52:14  time: 0.4370  data_time: 0.0096  memory: 5145  grad_norm: 29.8441  loss: 5.2270  decode.loss_cls: 0.0079  decode.loss_mask: 0.2381  decode.loss_dice: 0.1995  decode.d0.loss_cls: 0.8416  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.1928  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.2375  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.2333  decode.d3.loss_dice: 0.1963  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.2365  decode.d4.loss_dice: 0.1923  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.1949  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.1916  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.1980
09/30 17:53:00 - mmengine - INFO - Iter(train) [ 72950/320000]  base_lr: 7.9227e-05 lr: 7.9227e-06  eta: 1 day, 5:51:53  time: 0.4407  data_time: 0.0097  memory: 5129  grad_norm: 56.6469  loss: 7.0475  decode.loss_cls: 0.0676  decode.loss_mask: 0.2663  decode.loss_dice: 0.2146  decode.d0.loss_cls: 1.0046  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.2294  decode.d1.loss_cls: 0.2240  decode.d1.loss_mask: 0.2641  decode.d1.loss_dice: 0.2153  decode.d2.loss_cls: 0.1330  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2175  decode.d3.loss_cls: 0.1276  decode.d3.loss_mask: 0.2591  decode.d3.loss_dice: 0.2231  decode.d4.loss_cls: 0.1275  decode.d4.loss_mask: 0.2624  decode.d4.loss_dice: 0.2158  decode.d5.loss_cls: 0.0789  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.1347  decode.d6.loss_mask: 0.2643  decode.d6.loss_dice: 0.2267  decode.d7.loss_cls: 0.1381  decode.d7.loss_mask: 0.2655  decode.d7.loss_dice: 0.2296  decode.d8.loss_cls: 0.1286  decode.d8.loss_mask: 0.2656  decode.d8.loss_dice: 0.2316
09/30 17:53:22 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 17:53:22 - mmengine - INFO - Iter(train) [ 73000/320000]  base_lr: 7.9212e-05 lr: 7.9212e-06  eta: 1 day, 5:51:31  time: 0.4378  data_time: 0.0094  memory: 5145  grad_norm: 71.9711  loss: 6.1307  decode.loss_cls: 0.0623  decode.loss_mask: 0.2568  decode.loss_dice: 0.2197  decode.d0.loss_cls: 0.8069  decode.d0.loss_mask: 0.2639  decode.d0.loss_dice: 0.2167  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.2568  decode.d1.loss_dice: 0.2199  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.2577  decode.d2.loss_dice: 0.2169  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.2230  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.2603  decode.d4.loss_dice: 0.2208  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.2593  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.2207  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.2193  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.2192
09/30 17:53:44 - mmengine - INFO - Iter(train) [ 73050/320000]  base_lr: 7.9198e-05 lr: 7.9198e-06  eta: 1 day, 5:51:10  time: 0.4399  data_time: 0.0096  memory: 5129  grad_norm: 31.3211  loss: 5.9498  decode.loss_cls: 0.0158  decode.loss_mask: 0.2420  decode.loss_dice: 0.2390  decode.d0.loss_cls: 0.8743  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.2305  decode.d1.loss_cls: 0.1605  decode.d1.loss_mask: 0.2345  decode.d1.loss_dice: 0.2138  decode.d2.loss_cls: 0.0551  decode.d2.loss_mask: 0.2427  decode.d2.loss_dice: 0.2209  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.2400  decode.d6.loss_dice: 0.2177  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2432  decode.d7.loss_dice: 0.2391  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.2273
09/30 17:54:06 - mmengine - INFO - Iter(train) [ 73100/320000]  base_lr: 7.9184e-05 lr: 7.9184e-06  eta: 1 day, 5:50:49  time: 0.4399  data_time: 0.0095  memory: 5129  grad_norm: 52.7925  loss: 5.8268  decode.loss_cls: 0.0499  decode.loss_mask: 0.2325  decode.loss_dice: 0.2221  decode.d0.loss_cls: 0.7400  decode.d0.loss_mask: 0.2369  decode.d0.loss_dice: 0.2382  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2364  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2396  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.2235  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2299  decode.d6.loss_cls: 0.0437  decode.d6.loss_mask: 0.2325  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.2298  decode.d8.loss_dice: 0.2307
09/30 17:54:28 - mmengine - INFO - Iter(train) [ 73150/320000]  base_lr: 7.9169e-05 lr: 7.9169e-06  eta: 1 day, 5:50:28  time: 0.4383  data_time: 0.0095  memory: 5120  grad_norm: 52.0662  loss: 7.8130  decode.loss_cls: 0.1853  decode.loss_mask: 0.2114  decode.loss_dice: 0.3062  decode.d0.loss_cls: 0.9171  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.3045  decode.d1.loss_cls: 0.2196  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.3040  decode.d2.loss_cls: 0.1900  decode.d2.loss_mask: 0.2086  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.2249  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.2635  decode.d4.loss_cls: 0.2310  decode.d4.loss_mask: 0.2113  decode.d4.loss_dice: 0.3249  decode.d5.loss_cls: 0.1584  decode.d5.loss_mask: 0.2078  decode.d5.loss_dice: 0.3146  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.3063  decode.d7.loss_cls: 0.1919  decode.d7.loss_mask: 0.2078  decode.d7.loss_dice: 0.3027  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.3364
09/30 17:54:49 - mmengine - INFO - Iter(train) [ 73200/320000]  base_lr: 7.9155e-05 lr: 7.9155e-06  eta: 1 day, 5:50:07  time: 0.4371  data_time: 0.0093  memory: 5129  grad_norm: 13.7156  loss: 4.2171  decode.loss_cls: 0.0065  decode.loss_mask: 0.1665  decode.loss_dice: 0.1604  decode.d0.loss_cls: 0.8438  decode.d0.loss_mask: 0.1709  decode.d0.loss_dice: 0.1606  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.1705  decode.d1.loss_dice: 0.1668  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.1679  decode.d2.loss_dice: 0.1571  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.1685  decode.d3.loss_dice: 0.1640  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.1699  decode.d4.loss_dice: 0.1659  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.1688  decode.d5.loss_dice: 0.1635  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.1693  decode.d6.loss_dice: 0.1657  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.1668  decode.d7.loss_dice: 0.1649  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.1673  decode.d8.loss_dice: 0.1665
09/30 17:55:11 - mmengine - INFO - Iter(train) [ 73250/320000]  base_lr: 7.9140e-05 lr: 7.9140e-06  eta: 1 day, 5:49:46  time: 0.4388  data_time: 0.0096  memory: 5145  grad_norm: 64.6574  loss: 5.9915  decode.loss_cls: 0.1008  decode.loss_mask: 0.1852  decode.loss_dice: 0.2166  decode.d0.loss_cls: 0.9877  decode.d0.loss_mask: 0.1950  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.1365  decode.d1.loss_mask: 0.1897  decode.d1.loss_dice: 0.2010  decode.d2.loss_cls: 0.1347  decode.d2.loss_mask: 0.1868  decode.d2.loss_dice: 0.2000  decode.d3.loss_cls: 0.1417  decode.d3.loss_mask: 0.1880  decode.d3.loss_dice: 0.2026  decode.d4.loss_cls: 0.1187  decode.d4.loss_mask: 0.1895  decode.d4.loss_dice: 0.2023  decode.d5.loss_cls: 0.1202  decode.d5.loss_mask: 0.1909  decode.d5.loss_dice: 0.1934  decode.d6.loss_cls: 0.1168  decode.d6.loss_mask: 0.1895  decode.d6.loss_dice: 0.1897  decode.d7.loss_cls: 0.1167  decode.d7.loss_mask: 0.1897  decode.d7.loss_dice: 0.2015  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.1902  decode.d8.loss_dice: 0.2081
09/30 17:55:33 - mmengine - INFO - Iter(train) [ 73300/320000]  base_lr: 7.9126e-05 lr: 7.9126e-06  eta: 1 day, 5:49:24  time: 0.4399  data_time: 0.0097  memory: 5129  grad_norm: 46.0536  loss: 7.1416  decode.loss_cls: 0.0767  decode.loss_mask: 0.2970  decode.loss_dice: 0.2439  decode.d0.loss_cls: 0.7249  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.0976  decode.d1.loss_mask: 0.2930  decode.d1.loss_dice: 0.2487  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.2735  decode.d3.loss_cls: 0.1449  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.2853  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3028  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 0.2959  decode.d5.loss_dice: 0.2750  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.2949  decode.d6.loss_dice: 0.2499  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.2782  decode.d8.loss_cls: 0.0729  decode.d8.loss_mask: 0.2982  decode.d8.loss_dice: 0.2451
09/30 17:55:55 - mmengine - INFO - Iter(train) [ 73350/320000]  base_lr: 7.9111e-05 lr: 7.9111e-06  eta: 1 day, 5:49:03  time: 0.4379  data_time: 0.0096  memory: 5129  grad_norm: 47.5569  loss: 5.8065  decode.loss_cls: 0.1111  decode.loss_mask: 0.2168  decode.loss_dice: 0.1783  decode.d0.loss_cls: 0.9543  decode.d0.loss_mask: 0.2193  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0933  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.1826  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.2171  decode.d2.loss_dice: 0.1816  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.2151  decode.d3.loss_dice: 0.1780  decode.d4.loss_cls: 0.0779  decode.d4.loss_mask: 0.2149  decode.d4.loss_dice: 0.1847  decode.d5.loss_cls: 0.0885  decode.d5.loss_mask: 0.2147  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.1035  decode.d6.loss_mask: 0.2289  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.1143  decode.d8.loss_mask: 0.2173  decode.d8.loss_dice: 0.1786
09/30 17:56:17 - mmengine - INFO - Iter(train) [ 73400/320000]  base_lr: 7.9097e-05 lr: 7.9097e-06  eta: 1 day, 5:48:42  time: 0.4393  data_time: 0.0096  memory: 5145  grad_norm: 22.1816  loss: 4.5833  decode.loss_cls: 0.0026  decode.loss_mask: 0.2050  decode.loss_dice: 0.1686  decode.d0.loss_cls: 0.8124  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.1783  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.1697  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1706  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.2044  decode.d3.loss_dice: 0.1713  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.2054  decode.d4.loss_dice: 0.1732  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.2036  decode.d5.loss_dice: 0.1684  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2058  decode.d6.loss_dice: 0.1645  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2039  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.2034  decode.d8.loss_dice: 0.1643
09/30 17:56:39 - mmengine - INFO - Iter(train) [ 73450/320000]  base_lr: 7.9083e-05 lr: 7.9083e-06  eta: 1 day, 5:48:21  time: 0.4380  data_time: 0.0095  memory: 5129  grad_norm: 57.4866  loss: 5.0161  decode.loss_cls: 0.0135  decode.loss_mask: 0.2171  decode.loss_dice: 0.1773  decode.d0.loss_cls: 0.8239  decode.d0.loss_mask: 0.2203  decode.d0.loss_dice: 0.1731  decode.d1.loss_cls: 0.0460  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.1752  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.2213  decode.d2.loss_dice: 0.1753  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.1756  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.2200  decode.d5.loss_dice: 0.1748  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.1723  decode.d7.loss_cls: 0.0320  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.1803  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.1783
09/30 17:57:01 - mmengine - INFO - Iter(train) [ 73500/320000]  base_lr: 7.9068e-05 lr: 7.9068e-06  eta: 1 day, 5:47:59  time: 0.4381  data_time: 0.0096  memory: 5129  grad_norm: 31.7511  loss: 7.3509  decode.loss_cls: 0.0792  decode.loss_mask: 0.3609  decode.loss_dice: 0.2115  decode.d0.loss_cls: 0.8365  decode.d0.loss_mask: 0.3876  decode.d0.loss_dice: 0.2030  decode.d1.loss_cls: 0.1627  decode.d1.loss_mask: 0.3272  decode.d1.loss_dice: 0.2010  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.3618  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.3582  decode.d3.loss_dice: 0.2068  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.3538  decode.d4.loss_dice: 0.2070  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.3620  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.1636  decode.d6.loss_mask: 0.3284  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.3587  decode.d7.loss_dice: 0.2071  decode.d8.loss_cls: 0.0793  decode.d8.loss_mask: 0.3639  decode.d8.loss_dice: 0.2037
09/30 17:57:23 - mmengine - INFO - Iter(train) [ 73550/320000]  base_lr: 7.9054e-05 lr: 7.9054e-06  eta: 1 day, 5:47:38  time: 0.4378  data_time: 0.0095  memory: 5145  grad_norm: 39.0284  loss: 5.7725  decode.loss_cls: 0.0425  decode.loss_mask: 0.2215  decode.loss_dice: 0.2094  decode.d0.loss_cls: 0.9160  decode.d0.loss_mask: 0.2193  decode.d0.loss_dice: 0.2004  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.1901  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.2174  decode.d2.loss_dice: 0.1995  decode.d3.loss_cls: 0.0801  decode.d3.loss_mask: 0.2205  decode.d3.loss_dice: 0.1875  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.2191  decode.d4.loss_dice: 0.2074  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.1968  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 0.2177  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.1142  decode.d7.loss_mask: 0.2171  decode.d7.loss_dice: 0.1930  decode.d8.loss_cls: 0.0381  decode.d8.loss_mask: 0.2221  decode.d8.loss_dice: 0.2077
09/30 17:57:45 - mmengine - INFO - Iter(train) [ 73600/320000]  base_lr: 7.9039e-05 lr: 7.9039e-06  eta: 1 day, 5:47:17  time: 0.4380  data_time: 0.0095  memory: 5129  grad_norm: 81.3926  loss: 5.5080  decode.loss_cls: 0.0173  decode.loss_mask: 0.2292  decode.loss_dice: 0.2080  decode.d0.loss_cls: 0.8813  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2048  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.2313  decode.d2.loss_dice: 0.1971  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2309  decode.d3.loss_dice: 0.2030  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.2288  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.1952  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2295  decode.d7.loss_dice: 0.1967  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.2297  decode.d8.loss_dice: 0.2019
09/30 17:58:07 - mmengine - INFO - Iter(train) [ 73650/320000]  base_lr: 7.9025e-05 lr: 7.9025e-06  eta: 1 day, 5:46:56  time: 0.4397  data_time: 0.0097  memory: 5129  grad_norm: 48.6773  loss: 4.6355  decode.loss_cls: 0.0120  decode.loss_mask: 0.1886  decode.loss_dice: 0.1669  decode.d0.loss_cls: 0.9163  decode.d0.loss_mask: 0.1919  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.1750  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.1888  decode.d2.loss_dice: 0.1727  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.1878  decode.d3.loss_dice: 0.1679  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.1900  decode.d4.loss_dice: 0.1714  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.1889  decode.d5.loss_dice: 0.1712  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.1886  decode.d6.loss_dice: 0.1699  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.1697  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.1879  decode.d8.loss_dice: 0.1720
09/30 17:58:29 - mmengine - INFO - Iter(train) [ 73700/320000]  base_lr: 7.9010e-05 lr: 7.9010e-06  eta: 1 day, 5:46:35  time: 0.4369  data_time: 0.0092  memory: 5145  grad_norm: 22.4791  loss: 4.8660  decode.loss_cls: 0.0144  decode.loss_mask: 0.2190  decode.loss_dice: 0.1658  decode.d0.loss_cls: 0.8362  decode.d0.loss_mask: 0.2220  decode.d0.loss_dice: 0.1696  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.2219  decode.d1.loss_dice: 0.1670  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.1731  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.1665  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.1738  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.2196  decode.d5.loss_dice: 0.1676  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1692  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.2203  decode.d7.loss_dice: 0.1665  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.1714
09/30 17:58:51 - mmengine - INFO - Iter(train) [ 73750/320000]  base_lr: 7.8996e-05 lr: 7.8996e-06  eta: 1 day, 5:46:14  time: 0.4380  data_time: 0.0095  memory: 5129  grad_norm: 68.6940  loss: 4.2995  decode.loss_cls: 0.0291  decode.loss_mask: 0.1859  decode.loss_dice: 0.1242  decode.d0.loss_cls: 0.8574  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.1317  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.1335  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.1903  decode.d2.loss_dice: 0.1317  decode.d3.loss_cls: 0.0262  decode.d3.loss_mask: 0.1889  decode.d3.loss_dice: 0.1271  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.1871  decode.d4.loss_dice: 0.1293  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.1863  decode.d5.loss_dice: 0.1248  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.1287  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.1852  decode.d7.loss_dice: 0.1282  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.1863  decode.d8.loss_dice: 0.1265
09/30 17:59:13 - mmengine - INFO - Iter(train) [ 73800/320000]  base_lr: 7.8982e-05 lr: 7.8982e-06  eta: 1 day, 5:45:52  time: 0.4377  data_time: 0.0094  memory: 5129  grad_norm: 23.1078  loss: 5.2050  decode.loss_cls: 0.0627  decode.loss_mask: 0.2145  decode.loss_dice: 0.1714  decode.d0.loss_cls: 0.8050  decode.d0.loss_mask: 0.2147  decode.d0.loss_dice: 0.1806  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.2125  decode.d1.loss_dice: 0.1682  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.2168  decode.d2.loss_dice: 0.1803  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.2156  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.2126  decode.d5.loss_dice: 0.1748  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.1749  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.2148  decode.d7.loss_dice: 0.1672  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.2140  decode.d8.loss_dice: 0.1726
09/30 17:59:35 - mmengine - INFO - Iter(train) [ 73850/320000]  base_lr: 7.8967e-05 lr: 7.8967e-06  eta: 1 day, 5:45:31  time: 0.4394  data_time: 0.0098  memory: 5129  grad_norm: 36.0526  loss: 6.6883  decode.loss_cls: 0.1036  decode.loss_mask: 0.2545  decode.loss_dice: 0.2235  decode.d0.loss_cls: 0.9295  decode.d0.loss_mask: 0.2447  decode.d0.loss_dice: 0.1940  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2182  decode.d2.loss_cls: 0.1457  decode.d2.loss_mask: 0.2463  decode.d2.loss_dice: 0.2053  decode.d3.loss_cls: 0.1373  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.1242  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2303  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.2260  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.2543  decode.d6.loss_dice: 0.2289  decode.d7.loss_cls: 0.1146  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.2171  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.2175
09/30 17:59:57 - mmengine - INFO - Iter(train) [ 73900/320000]  base_lr: 7.8953e-05 lr: 7.8953e-06  eta: 1 day, 5:45:10  time: 0.4376  data_time: 0.0095  memory: 5129  grad_norm: 201.3322  loss: 5.3049  decode.loss_cls: 0.0029  decode.loss_mask: 0.2874  decode.loss_dice: 0.1697  decode.d0.loss_cls: 0.7002  decode.d0.loss_mask: 0.2939  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.2788  decode.d1.loss_dice: 0.1633  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2904  decode.d2.loss_dice: 0.1662  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.2875  decode.d3.loss_dice: 0.1680  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2889  decode.d4.loss_dice: 0.1672  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.1650  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2866  decode.d6.loss_dice: 0.1684  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2904  decode.d7.loss_dice: 0.1699  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.2907  decode.d8.loss_dice: 0.1689
09/30 18:00:18 - mmengine - INFO - Iter(train) [ 73950/320000]  base_lr: 7.8938e-05 lr: 7.8938e-06  eta: 1 day, 5:44:49  time: 0.4381  data_time: 0.0095  memory: 5146  grad_norm: 112.9126  loss: 7.0778  decode.loss_cls: 0.1971  decode.loss_mask: 0.2330  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.7760  decode.d0.loss_mask: 0.2372  decode.d0.loss_dice: 0.2820  decode.d1.loss_cls: 0.1765  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.1927  decode.d2.loss_cls: 0.1642  decode.d2.loss_mask: 0.2347  decode.d2.loss_dice: 0.2223  decode.d3.loss_cls: 0.1707  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.2680  decode.d4.loss_cls: 0.1796  decode.d4.loss_mask: 0.2367  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.2006  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.2229  decode.d6.loss_cls: 0.2010  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2549  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 0.2333  decode.d7.loss_dice: 0.1968  decode.d8.loss_cls: 0.1619  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.1976
09/30 18:00:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:00:40 - mmengine - INFO - Iter(train) [ 74000/320000]  base_lr: 7.8924e-05 lr: 7.8924e-06  eta: 1 day, 5:44:27  time: 0.4383  data_time: 0.0097  memory: 5145  grad_norm: 89.9844  loss: 6.7258  decode.loss_cls: 0.0588  decode.loss_mask: 0.2323  decode.loss_dice: 0.2757  decode.d0.loss_cls: 0.7704  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2772  decode.d1.loss_cls: 0.1423  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2645  decode.d2.loss_cls: 0.1275  decode.d2.loss_mask: 0.2363  decode.d2.loss_dice: 0.2628  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2337  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.2772  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.2368  decode.d5.loss_dice: 0.2817  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.1235  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2528  decode.d8.loss_cls: 0.1194  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2355
09/30 18:01:02 - mmengine - INFO - Iter(train) [ 74050/320000]  base_lr: 7.8909e-05 lr: 7.8909e-06  eta: 1 day, 5:44:06  time: 0.4382  data_time: 0.0096  memory: 5120  grad_norm: 88.1625  loss: 9.2346  decode.loss_cls: 0.1358  decode.loss_mask: 0.4229  decode.loss_dice: 0.2960  decode.d0.loss_cls: 0.7975  decode.d0.loss_mask: 0.3403  decode.d0.loss_dice: 0.3320  decode.d1.loss_cls: 0.1245  decode.d1.loss_mask: 0.4256  decode.d1.loss_dice: 0.3077  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.4291  decode.d2.loss_dice: 0.3646  decode.d3.loss_cls: 0.1319  decode.d3.loss_mask: 0.4298  decode.d3.loss_dice: 0.3152  decode.d4.loss_cls: 0.1319  decode.d4.loss_mask: 0.4298  decode.d4.loss_dice: 0.3192  decode.d5.loss_cls: 0.1258  decode.d5.loss_mask: 0.4259  decode.d5.loss_dice: 0.3057  decode.d6.loss_cls: 0.1224  decode.d6.loss_mask: 0.4291  decode.d6.loss_dice: 0.3002  decode.d7.loss_cls: 0.1332  decode.d7.loss_mask: 0.4207  decode.d7.loss_dice: 0.2971  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.4313  decode.d8.loss_dice: 0.2965
09/30 18:01:24 - mmengine - INFO - Iter(train) [ 74100/320000]  base_lr: 7.8895e-05 lr: 7.8895e-06  eta: 1 day, 5:43:45  time: 0.4389  data_time: 0.0097  memory: 5129  grad_norm: 25.3879  loss: 4.3427  decode.loss_cls: 0.0162  decode.loss_mask: 0.1839  decode.loss_dice: 0.1534  decode.d0.loss_cls: 0.8429  decode.d0.loss_mask: 0.1854  decode.d0.loss_dice: 0.1541  decode.d1.loss_cls: 0.0274  decode.d1.loss_mask: 0.1845  decode.d1.loss_dice: 0.1525  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 0.1820  decode.d2.loss_dice: 0.1536  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.1543  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.1834  decode.d4.loss_dice: 0.1518  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.1523  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.1844  decode.d6.loss_dice: 0.1571  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.1815  decode.d7.loss_dice: 0.1530  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.1841  decode.d8.loss_dice: 0.1496
09/30 18:01:46 - mmengine - INFO - Iter(train) [ 74150/320000]  base_lr: 7.8880e-05 lr: 7.8880e-06  eta: 1 day, 5:43:24  time: 0.4388  data_time: 0.0095  memory: 5145  grad_norm: 86.9704  loss: 8.0196  decode.loss_cls: 0.1122  decode.loss_mask: 0.3218  decode.loss_dice: 0.2945  decode.d0.loss_cls: 0.8244  decode.d0.loss_mask: 0.3194  decode.d0.loss_dice: 0.3044  decode.d1.loss_cls: 0.1315  decode.d1.loss_mask: 0.3217  decode.d1.loss_dice: 0.3007  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.3000  decode.d3.loss_cls: 0.1058  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 0.3213  decode.d4.loss_dice: 0.3009  decode.d5.loss_cls: 0.1119  decode.d5.loss_mask: 0.3242  decode.d5.loss_dice: 0.2975  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 0.3214  decode.d6.loss_dice: 0.2953  decode.d7.loss_cls: 0.1082  decode.d7.loss_mask: 0.3215  decode.d7.loss_dice: 0.2965  decode.d8.loss_cls: 0.1182  decode.d8.loss_mask: 0.3195  decode.d8.loss_dice: 0.2830
09/30 18:02:08 - mmengine - INFO - Iter(train) [ 74200/320000]  base_lr: 7.8866e-05 lr: 7.8866e-06  eta: 1 day, 5:43:02  time: 0.4373  data_time: 0.0094  memory: 5129  grad_norm: 53.3634  loss: 6.8761  decode.loss_cls: 0.1846  decode.loss_mask: 0.2400  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.7973  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.0865  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2670  decode.d2.loss_cls: 0.2032  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.2470  decode.d3.loss_cls: 0.1033  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.1335  decode.d4.loss_mask: 0.2395  decode.d4.loss_dice: 0.2392  decode.d5.loss_cls: 0.1404  decode.d5.loss_mask: 0.2386  decode.d5.loss_dice: 0.2495  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2495  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.2417  decode.d7.loss_dice: 0.2608  decode.d8.loss_cls: 0.1116  decode.d8.loss_mask: 0.2419  decode.d8.loss_dice: 0.2151
09/30 18:02:30 - mmengine - INFO - Iter(train) [ 74250/320000]  base_lr: 7.8852e-05 lr: 7.8852e-06  eta: 1 day, 5:42:41  time: 0.4405  data_time: 0.0096  memory: 5129  grad_norm: 32.1003  loss: 4.7115  decode.loss_cls: 0.0026  decode.loss_mask: 0.2268  decode.loss_dice: 0.1665  decode.d0.loss_cls: 0.7755  decode.d0.loss_mask: 0.2252  decode.d0.loss_dice: 0.1587  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.1662  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.2255  decode.d2.loss_dice: 0.1662  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.1647  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.1619  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.2260  decode.d5.loss_dice: 0.1627  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2215  decode.d6.loss_dice: 0.1632  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2248  decode.d7.loss_dice: 0.1633  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2251  decode.d8.loss_dice: 0.1633
09/30 18:02:52 - mmengine - INFO - Iter(train) [ 74300/320000]  base_lr: 7.8837e-05 lr: 7.8837e-06  eta: 1 day, 5:42:20  time: 0.4405  data_time: 0.0097  memory: 5145  grad_norm: 63.5463  loss: 6.5189  decode.loss_cls: 0.1515  decode.loss_mask: 0.2878  decode.loss_dice: 0.1957  decode.d0.loss_cls: 0.9469  decode.d0.loss_mask: 0.2473  decode.d0.loss_dice: 0.1880  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 0.2355  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.1500  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.1749  decode.d3.loss_cls: 0.1551  decode.d3.loss_mask: 0.2425  decode.d3.loss_dice: 0.1813  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.2300  decode.d4.loss_dice: 0.1783  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.1786  decode.d6.loss_cls: 0.0797  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.1632  decode.d7.loss_cls: 0.0777  decode.d7.loss_mask: 0.2841  decode.d7.loss_dice: 0.1715  decode.d8.loss_cls: 0.1526  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.1772
09/30 18:03:14 - mmengine - INFO - Iter(train) [ 74350/320000]  base_lr: 7.8823e-05 lr: 7.8823e-06  eta: 1 day, 5:42:00  time: 0.4400  data_time: 0.0098  memory: 5145  grad_norm: 33.9883  loss: 5.2825  decode.loss_cls: 0.0336  decode.loss_mask: 0.2351  decode.loss_dice: 0.1574  decode.d0.loss_cls: 0.8307  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.1684  decode.d2.loss_cls: 0.0556  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.1625  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.1706  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.2372  decode.d5.loss_dice: 0.1589  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.1607  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.1725  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.1679
09/30 18:03:36 - mmengine - INFO - Iter(train) [ 74400/320000]  base_lr: 7.8808e-05 lr: 7.8808e-06  eta: 1 day, 5:41:39  time: 0.4409  data_time: 0.0098  memory: 5145  grad_norm: 39.7574  loss: 4.8854  decode.loss_cls: 0.0113  decode.loss_mask: 0.1725  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.8620  decode.d0.loss_mask: 0.1745  decode.d0.loss_dice: 0.2175  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.1742  decode.d1.loss_dice: 0.2158  decode.d2.loss_cls: 0.0512  decode.d2.loss_mask: 0.1731  decode.d2.loss_dice: 0.2192  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.1750  decode.d3.loss_dice: 0.2191  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.1738  decode.d4.loss_dice: 0.2154  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.1721  decode.d5.loss_dice: 0.2026  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.1706  decode.d6.loss_dice: 0.2086  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.1723  decode.d7.loss_dice: 0.2017  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.1732  decode.d8.loss_dice: 0.2056
09/30 18:03:58 - mmengine - INFO - Iter(train) [ 74450/320000]  base_lr: 7.8794e-05 lr: 7.8794e-06  eta: 1 day, 5:41:18  time: 0.4407  data_time: 0.0094  memory: 5129  grad_norm: 103.9517  loss: 5.5864  decode.loss_cls: 0.0624  decode.loss_mask: 0.2273  decode.loss_dice: 0.2046  decode.d0.loss_cls: 0.7985  decode.d0.loss_mask: 0.2130  decode.d0.loss_dice: 0.1590  decode.d1.loss_cls: 0.0834  decode.d1.loss_mask: 0.2166  decode.d1.loss_dice: 0.1973  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.2062  decode.d2.loss_dice: 0.1797  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.2078  decode.d3.loss_dice: 0.1843  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.2122  decode.d4.loss_dice: 0.1970  decode.d5.loss_cls: 0.0713  decode.d5.loss_mask: 0.2251  decode.d5.loss_dice: 0.2043  decode.d6.loss_cls: 0.0788  decode.d6.loss_mask: 0.2254  decode.d6.loss_dice: 0.2042  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.2042  decode.d8.loss_cls: 0.0721  decode.d8.loss_mask: 0.2197  decode.d8.loss_dice: 0.2002
09/30 18:04:20 - mmengine - INFO - Iter(train) [ 74500/320000]  base_lr: 7.8779e-05 lr: 7.8779e-06  eta: 1 day, 5:40:57  time: 0.4434  data_time: 0.0096  memory: 5145  grad_norm: 78.7142  loss: 8.0241  decode.loss_cls: 0.1879  decode.loss_mask: 0.3399  decode.loss_dice: 0.2234  decode.d0.loss_cls: 0.8865  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.1941  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 0.3132  decode.d1.loss_dice: 0.2106  decode.d2.loss_cls: 0.1917  decode.d2.loss_mask: 0.3372  decode.d2.loss_dice: 0.2264  decode.d3.loss_cls: 0.1715  decode.d3.loss_mask: 0.3151  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.1971  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.2082  decode.d6.loss_cls: 0.1896  decode.d6.loss_mask: 0.3031  decode.d6.loss_dice: 0.2133  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.3304  decode.d7.loss_dice: 0.2118  decode.d8.loss_cls: 0.2185  decode.d8.loss_mask: 0.4145  decode.d8.loss_dice: 0.2182
09/30 18:04:42 - mmengine - INFO - Iter(train) [ 74550/320000]  base_lr: 7.8765e-05 lr: 7.8765e-06  eta: 1 day, 5:40:36  time: 0.4403  data_time: 0.0096  memory: 5129  grad_norm: 20.7094  loss: 5.3765  decode.loss_cls: 0.0481  decode.loss_mask: 0.2315  decode.loss_dice: 0.1800  decode.d0.loss_cls: 0.7993  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.1725  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.2285  decode.d1.loss_dice: 0.1753  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.2277  decode.d3.loss_dice: 0.1714  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.2256  decode.d4.loss_dice: 0.1766  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.2271  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.1768  decode.d7.loss_cls: 0.0610  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.1747
09/30 18:05:04 - mmengine - INFO - Iter(train) [ 74600/320000]  base_lr: 7.8751e-05 lr: 7.8751e-06  eta: 1 day, 5:40:15  time: 0.4376  data_time: 0.0095  memory: 5129  grad_norm: 32.2638  loss: 5.8518  decode.loss_cls: 0.0068  decode.loss_mask: 0.2859  decode.loss_dice: 0.2251  decode.d0.loss_cls: 0.7475  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.2322  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.2849  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2821  decode.d3.loss_dice: 0.1965  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.2858  decode.d4.loss_dice: 0.1971  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.2866  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.2177  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2868  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.2893  decode.d8.loss_dice: 0.2184
09/30 18:05:26 - mmengine - INFO - Iter(train) [ 74650/320000]  base_lr: 7.8736e-05 lr: 7.8736e-06  eta: 1 day, 5:39:54  time: 0.4370  data_time: 0.0095  memory: 5129  grad_norm: 73.5803  loss: 5.9413  decode.loss_cls: 0.0030  decode.loss_mask: 0.3202  decode.loss_dice: 0.1915  decode.d0.loss_cls: 0.7759  decode.d0.loss_mask: 0.3214  decode.d0.loss_dice: 0.1909  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.3218  decode.d2.loss_dice: 0.1920  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.3226  decode.d3.loss_dice: 0.1920  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.3246  decode.d4.loss_dice: 0.1898  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.3234  decode.d5.loss_dice: 0.1907  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3204  decode.d6.loss_dice: 0.1904  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.1924  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.3200  decode.d8.loss_dice: 0.1902
09/30 18:05:48 - mmengine - INFO - Iter(train) [ 74700/320000]  base_lr: 7.8722e-05 lr: 7.8722e-06  eta: 1 day, 5:39:32  time: 0.4384  data_time: 0.0095  memory: 5145  grad_norm: 112.5237  loss: 7.3941  decode.loss_cls: 0.0880  decode.loss_mask: 0.3109  decode.loss_dice: 0.2211  decode.d0.loss_cls: 1.0770  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.1172  decode.d1.loss_mask: 0.3300  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 0.3215  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.0999  decode.d3.loss_mask: 0.3273  decode.d3.loss_dice: 0.2225  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.3189  decode.d4.loss_dice: 0.2168  decode.d5.loss_cls: 0.1123  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.2281  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.3168  decode.d6.loss_dice: 0.2315  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 0.3171  decode.d7.loss_dice: 0.2270  decode.d8.loss_cls: 0.0963  decode.d8.loss_mask: 0.3046  decode.d8.loss_dice: 0.2258
09/30 18:06:10 - mmengine - INFO - Iter(train) [ 74750/320000]  base_lr: 7.8707e-05 lr: 7.8707e-06  eta: 1 day, 5:39:11  time: 0.4398  data_time: 0.0098  memory: 5129  grad_norm: 38.9717  loss: 6.5272  decode.loss_cls: 0.0228  decode.loss_mask: 0.3268  decode.loss_dice: 0.2099  decode.d0.loss_cls: 0.8386  decode.d0.loss_mask: 0.3329  decode.d0.loss_dice: 0.2125  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.3337  decode.d1.loss_dice: 0.2153  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.3338  decode.d2.loss_dice: 0.2127  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.3291  decode.d3.loss_dice: 0.2121  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.2150  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.3359  decode.d5.loss_dice: 0.2152  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.3340  decode.d6.loss_dice: 0.2130  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.3311  decode.d7.loss_dice: 0.2127  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.3300  decode.d8.loss_dice: 0.2114
09/30 18:06:32 - mmengine - INFO - Iter(train) [ 74800/320000]  base_lr: 7.8693e-05 lr: 7.8693e-06  eta: 1 day, 5:38:50  time: 0.4394  data_time: 0.0096  memory: 5129  grad_norm: 30.0100  loss: 5.8064  decode.loss_cls: 0.0019  decode.loss_mask: 0.2483  decode.loss_dice: 0.2301  decode.d0.loss_cls: 0.9987  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.2243  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.2494  decode.d1.loss_dice: 0.2295  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2499  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2301  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2252  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2478  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.2357
09/30 18:06:54 - mmengine - INFO - Iter(train) [ 74850/320000]  base_lr: 7.8678e-05 lr: 7.8678e-06  eta: 1 day, 5:38:29  time: 0.4377  data_time: 0.0097  memory: 5120  grad_norm: 33.6073  loss: 5.3533  decode.loss_cls: 0.0070  decode.loss_mask: 0.2488  decode.loss_dice: 0.1984  decode.d0.loss_cls: 0.8161  decode.d0.loss_mask: 0.2510  decode.d0.loss_dice: 0.2092  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.1940  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.2495  decode.d2.loss_dice: 0.1956  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.1946  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.2511  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.1974  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2482  decode.d7.loss_dice: 0.1988  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2464  decode.d8.loss_dice: 0.1901
09/30 18:07:16 - mmengine - INFO - Iter(train) [ 74900/320000]  base_lr: 7.8664e-05 lr: 7.8664e-06  eta: 1 day, 5:38:08  time: 0.4403  data_time: 0.0098  memory: 5145  grad_norm: 89.3075  loss: 5.2649  decode.loss_cls: 0.0697  decode.loss_mask: 0.1939  decode.loss_dice: 0.1953  decode.d0.loss_cls: 0.8218  decode.d0.loss_mask: 0.1993  decode.d0.loss_dice: 0.1863  decode.d1.loss_cls: 0.0523  decode.d1.loss_mask: 0.1969  decode.d1.loss_dice: 0.1931  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.1966  decode.d2.loss_dice: 0.1940  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.1946  decode.d3.loss_dice: 0.1911  decode.d4.loss_cls: 0.0657  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.1952  decode.d5.loss_dice: 0.1951  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.1952  decode.d6.loss_dice: 0.1889  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.1968  decode.d7.loss_dice: 0.1989  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.1963  decode.d8.loss_dice: 0.1942
09/30 18:07:38 - mmengine - INFO - Iter(train) [ 74950/320000]  base_lr: 7.8649e-05 lr: 7.8649e-06  eta: 1 day, 5:37:46  time: 0.4384  data_time: 0.0096  memory: 5120  grad_norm: 24.2037  loss: 5.3181  decode.loss_cls: 0.0364  decode.loss_mask: 0.2216  decode.loss_dice: 0.1888  decode.d0.loss_cls: 0.7660  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.1911  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.1854  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.1940  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.1952  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.1930  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.2202  decode.d7.loss_dice: 0.1866  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.2221  decode.d8.loss_dice: 0.1907
09/30 18:08:00 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:08:00 - mmengine - INFO - Iter(train) [ 75000/320000]  base_lr: 7.8635e-05 lr: 7.8635e-06  eta: 1 day, 5:37:25  time: 0.4375  data_time: 0.0096  memory: 5145  grad_norm: 33.9242  loss: 5.5659  decode.loss_cls: 0.0381  decode.loss_mask: 0.2447  decode.loss_dice: 0.2111  decode.d0.loss_cls: 0.8190  decode.d0.loss_mask: 0.2418  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.2376  decode.d1.loss_dice: 0.2025  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.2380  decode.d2.loss_dice: 0.1956  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.2035  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.1995  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.2388  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.2406  decode.d6.loss_dice: 0.2030  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.2381  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.2056
09/30 18:08:22 - mmengine - INFO - Iter(train) [ 75050/320000]  base_lr: 7.8621e-05 lr: 7.8621e-06  eta: 1 day, 5:37:04  time: 0.4380  data_time: 0.0097  memory: 5145  grad_norm: 129.1767  loss: 6.2695  decode.loss_cls: 0.1059  decode.loss_mask: 0.2655  decode.loss_dice: 0.1969  decode.d0.loss_cls: 0.9139  decode.d0.loss_mask: 0.2760  decode.d0.loss_dice: 0.1902  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.1978  decode.d3.loss_cls: 0.0961  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.1928  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.1942  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.2643  decode.d5.loss_dice: 0.1917  decode.d6.loss_cls: 0.0941  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.1887  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.2665  decode.d7.loss_dice: 0.1989  decode.d8.loss_cls: 0.1053  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.1968
09/30 18:08:44 - mmengine - INFO - Iter(train) [ 75100/320000]  base_lr: 7.8606e-05 lr: 7.8606e-06  eta: 1 day, 5:36:43  time: 0.4390  data_time: 0.0098  memory: 5145  grad_norm: 35.1283  loss: 5.2555  decode.loss_cls: 0.1218  decode.loss_mask: 0.2083  decode.loss_dice: 0.1833  decode.d0.loss_cls: 0.7151  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.0297  decode.d1.loss_mask: 0.2037  decode.d1.loss_dice: 0.1842  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.1780  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.1795  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.2037  decode.d4.loss_dice: 0.1945  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.2036  decode.d5.loss_dice: 0.1797  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.1796  decode.d8.loss_cls: 0.1122  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.1858
09/30 18:09:06 - mmengine - INFO - Iter(train) [ 75150/320000]  base_lr: 7.8592e-05 lr: 7.8592e-06  eta: 1 day, 5:36:21  time: 0.4378  data_time: 0.0096  memory: 5145  grad_norm: 60.4437  loss: 6.2100  decode.loss_cls: 0.0309  decode.loss_mask: 0.2134  decode.loss_dice: 0.2637  decode.d0.loss_cls: 1.0066  decode.d0.loss_mask: 0.2080  decode.d0.loss_dice: 0.2492  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.2644  decode.d2.loss_cls: 0.0198  decode.d2.loss_mask: 0.2148  decode.d2.loss_dice: 0.2673  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.2728  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.2715  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.2177  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.2693  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.2077  decode.d8.loss_dice: 0.2600
09/30 18:09:28 - mmengine - INFO - Iter(train) [ 75200/320000]  base_lr: 7.8577e-05 lr: 7.8577e-06  eta: 1 day, 5:36:00  time: 0.4387  data_time: 0.0097  memory: 5129  grad_norm: 49.5125  loss: 6.2012  decode.loss_cls: 0.1357  decode.loss_mask: 0.2403  decode.loss_dice: 0.1905  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 0.2420  decode.d0.loss_dice: 0.2083  decode.d1.loss_cls: 0.1527  decode.d1.loss_mask: 0.2408  decode.d1.loss_dice: 0.1876  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2033  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.1873  decode.d4.loss_cls: 0.0924  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0964  decode.d5.loss_mask: 0.2416  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.1091  decode.d6.loss_mask: 0.2419  decode.d6.loss_dice: 0.1943  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.2316  decode.d8.loss_cls: 0.0931  decode.d8.loss_mask: 0.2371  decode.d8.loss_dice: 0.1898
09/30 18:09:49 - mmengine - INFO - Iter(train) [ 75250/320000]  base_lr: 7.8563e-05 lr: 7.8563e-06  eta: 1 day, 5:35:39  time: 0.4390  data_time: 0.0097  memory: 5119  grad_norm: 31.6595  loss: 4.2326  decode.loss_cls: 0.0148  decode.loss_mask: 0.1832  decode.loss_dice: 0.1478  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.1465  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.1832  decode.d1.loss_dice: 0.1454  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.1838  decode.d2.loss_dice: 0.1469  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.1843  decode.d3.loss_dice: 0.1482  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.1830  decode.d4.loss_dice: 0.1455  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.1867  decode.d5.loss_dice: 0.1497  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.1830  decode.d6.loss_dice: 0.1491  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.1856  decode.d7.loss_dice: 0.1483  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.1842  decode.d8.loss_dice: 0.1483
09/30 18:10:12 - mmengine - INFO - Iter(train) [ 75300/320000]  base_lr: 7.8548e-05 lr: 7.8548e-06  eta: 1 day, 5:35:18  time: 0.4378  data_time: 0.0096  memory: 5120  grad_norm: 164.0395  loss: 7.6881  decode.loss_cls: 0.1735  decode.loss_mask: 0.2481  decode.loss_dice: 0.2186  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 0.2761  decode.d0.loss_dice: 0.2473  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 0.2917  decode.d1.loss_dice: 0.2472  decode.d2.loss_cls: 0.2074  decode.d2.loss_mask: 0.2931  decode.d2.loss_dice: 0.2332  decode.d3.loss_cls: 0.1506  decode.d3.loss_mask: 0.3081  decode.d3.loss_dice: 0.2578  decode.d4.loss_cls: 0.1534  decode.d4.loss_mask: 0.4050  decode.d4.loss_dice: 0.2395  decode.d5.loss_cls: 0.1560  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.2206  decode.d6.loss_cls: 0.1488  decode.d6.loss_mask: 0.2545  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.1778  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.2017  decode.d8.loss_mask: 0.2635  decode.d8.loss_dice: 0.2349
09/30 18:10:33 - mmengine - INFO - Iter(train) [ 75350/320000]  base_lr: 7.8534e-05 lr: 7.8534e-06  eta: 1 day, 5:34:57  time: 0.4383  data_time: 0.0097  memory: 5145  grad_norm: 31.1030  loss: 5.8511  decode.loss_cls: 0.1139  decode.loss_mask: 0.2429  decode.loss_dice: 0.1830  decode.d0.loss_cls: 0.7746  decode.d0.loss_mask: 0.2544  decode.d0.loss_dice: 0.1820  decode.d1.loss_cls: 0.1026  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.1856  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.1865  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.1859  decode.d5.loss_cls: 0.0597  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.1880  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.1207  decode.d7.loss_mask: 0.2489  decode.d7.loss_dice: 0.1859  decode.d8.loss_cls: 0.0833  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.1887
09/30 18:10:55 - mmengine - INFO - Iter(train) [ 75400/320000]  base_lr: 7.8519e-05 lr: 7.8519e-06  eta: 1 day, 5:34:35  time: 0.4381  data_time: 0.0096  memory: 5120  grad_norm: 44.8588  loss: 5.7120  decode.loss_cls: 0.0539  decode.loss_mask: 0.2272  decode.loss_dice: 0.2328  decode.d0.loss_cls: 0.8386  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.2298  decode.d1.loss_cls: 0.0995  decode.d1.loss_mask: 0.2251  decode.d1.loss_dice: 0.2403  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.2246  decode.d2.loss_dice: 0.2378  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.2266  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.2319  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.0164  decode.d6.loss_mask: 0.2251  decode.d6.loss_dice: 0.2345  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.2264  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.2271
09/30 18:11:17 - mmengine - INFO - Iter(train) [ 75450/320000]  base_lr: 7.8505e-05 lr: 7.8505e-06  eta: 1 day, 5:34:14  time: 0.4378  data_time: 0.0095  memory: 5145  grad_norm: 141.0194  loss: 7.0871  decode.loss_cls: 0.1526  decode.loss_mask: 0.2558  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.8911  decode.d0.loss_mask: 0.2578  decode.d0.loss_dice: 0.2456  decode.d1.loss_cls: 0.1260  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.2234  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 0.2577  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.1089  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.1675  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.2525  decode.d5.loss_cls: 0.1629  decode.d5.loss_mask: 0.2547  decode.d5.loss_dice: 0.2293  decode.d6.loss_cls: 0.1536  decode.d6.loss_mask: 0.2582  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.1253  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.2403  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.2583  decode.d8.loss_dice: 0.2373
09/30 18:11:39 - mmengine - INFO - Iter(train) [ 75500/320000]  base_lr: 7.8491e-05 lr: 7.8491e-06  eta: 1 day, 5:33:53  time: 0.4377  data_time: 0.0096  memory: 5120  grad_norm: 31.2203  loss: 5.6211  decode.loss_cls: 0.1114  decode.loss_mask: 0.2276  decode.loss_dice: 0.1771  decode.d0.loss_cls: 0.8111  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.1790  decode.d1.loss_cls: 0.1250  decode.d1.loss_mask: 0.2280  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.1804  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.1830  decode.d4.loss_cls: 0.0346  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.1796  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.2293  decode.d5.loss_dice: 0.1843  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.1777  decode.d7.loss_cls: 0.0847  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.1813  decode.d8.loss_cls: 0.1094  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1836
09/30 18:12:01 - mmengine - INFO - Iter(train) [ 75550/320000]  base_lr: 7.8476e-05 lr: 7.8476e-06  eta: 1 day, 5:33:31  time: 0.4378  data_time: 0.0097  memory: 5129  grad_norm: 44.9603  loss: 6.1767  decode.loss_cls: 0.1437  decode.loss_mask: 0.2023  decode.loss_dice: 0.2353  decode.d0.loss_cls: 0.8386  decode.d0.loss_mask: 0.2064  decode.d0.loss_dice: 0.2174  decode.d1.loss_cls: 0.1564  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.0971  decode.d2.loss_mask: 0.2003  decode.d2.loss_dice: 0.2327  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.1272  decode.d4.loss_mask: 0.2081  decode.d4.loss_dice: 0.2332  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.2008  decode.d5.loss_dice: 0.2279  decode.d6.loss_cls: 0.1161  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.2068  decode.d7.loss_dice: 0.2173  decode.d8.loss_cls: 0.1127  decode.d8.loss_mask: 0.1995  decode.d8.loss_dice: 0.2299
09/30 18:12:23 - mmengine - INFO - Iter(train) [ 75600/320000]  base_lr: 7.8462e-05 lr: 7.8462e-06  eta: 1 day, 5:33:10  time: 0.4386  data_time: 0.0098  memory: 5129  grad_norm: 33.1613  loss: 5.8585  decode.loss_cls: 0.0780  decode.loss_mask: 0.2724  decode.loss_dice: 0.1848  decode.d0.loss_cls: 0.8470  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 0.2783  decode.d1.loss_dice: 0.1857  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.2741  decode.d2.loss_dice: 0.1839  decode.d3.loss_cls: 0.0434  decode.d3.loss_mask: 0.2711  decode.d3.loss_dice: 0.1868  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.2727  decode.d4.loss_dice: 0.1866  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.2734  decode.d5.loss_dice: 0.1855  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 0.2747  decode.d6.loss_dice: 0.1820  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.2795  decode.d7.loss_dice: 0.1866  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.1842
09/30 18:12:45 - mmengine - INFO - Iter(train) [ 75650/320000]  base_lr: 7.8447e-05 lr: 7.8447e-06  eta: 1 day, 5:32:49  time: 0.4399  data_time: 0.0097  memory: 5145  grad_norm: 21.2251  loss: 5.0857  decode.loss_cls: 0.0143  decode.loss_mask: 0.2427  decode.loss_dice: 0.1782  decode.d0.loss_cls: 0.8179  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.1751  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.2421  decode.d1.loss_dice: 0.1771  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.2393  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.2387  decode.d3.loss_dice: 0.1740  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.2413  decode.d5.loss_dice: 0.1758  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.1759  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.1767  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.1777
09/30 18:13:07 - mmengine - INFO - Iter(train) [ 75700/320000]  base_lr: 7.8433e-05 lr: 7.8433e-06  eta: 1 day, 5:32:28  time: 0.4391  data_time: 0.0097  memory: 5130  grad_norm: 77.1739  loss: 5.2750  decode.loss_cls: 0.0027  decode.loss_mask: 0.2440  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.8448  decode.d0.loss_mask: 0.2542  decode.d0.loss_dice: 0.1764  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.2443  decode.d1.loss_dice: 0.1800  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.1855  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2487  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0377  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.1843  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.2485  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.2444  decode.d6.loss_dice: 0.1795  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.1810  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.1792
09/30 18:13:29 - mmengine - INFO - Iter(train) [ 75750/320000]  base_lr: 7.8418e-05 lr: 7.8418e-06  eta: 1 day, 5:32:06  time: 0.4387  data_time: 0.0096  memory: 5129  grad_norm: 33.4272  loss: 5.7702  decode.loss_cls: 0.0876  decode.loss_mask: 0.1987  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.8116  decode.d0.loss_mask: 0.2056  decode.d0.loss_dice: 0.2142  decode.d1.loss_cls: 0.1481  decode.d1.loss_mask: 0.2015  decode.d1.loss_dice: 0.2290  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2002  decode.d2.loss_dice: 0.2200  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.2023  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.1995  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.2052  decode.d6.loss_cls: 0.1102  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.2029  decode.d7.loss_dice: 0.2172  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.2007  decode.d8.loss_dice: 0.2168
09/30 18:13:51 - mmengine - INFO - Iter(train) [ 75800/320000]  base_lr: 7.8404e-05 lr: 7.8404e-06  eta: 1 day, 5:31:45  time: 0.4383  data_time: 0.0095  memory: 5129  grad_norm: 36.1463  loss: 5.1699  decode.loss_cls: 0.0033  decode.loss_mask: 0.2323  decode.loss_dice: 0.1967  decode.d0.loss_cls: 0.8341  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2049  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.1946  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.2380  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.1955  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.1901  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.1939  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.2293  decode.d8.loss_dice: 0.2010
09/30 18:14:13 - mmengine - INFO - Iter(train) [ 75850/320000]  base_lr: 7.8389e-05 lr: 7.8389e-06  eta: 1 day, 5:31:24  time: 0.4384  data_time: 0.0097  memory: 5129  grad_norm: 48.8918  loss: 5.8993  decode.loss_cls: 0.0117  decode.loss_mask: 0.2984  decode.loss_dice: 0.1779  decode.d0.loss_cls: 0.8951  decode.d0.loss_mask: 0.2467  decode.d0.loss_dice: 0.2002  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.2070  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.2081  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.2124  decode.d3.loss_dice: 0.1740  decode.d4.loss_cls: 0.0527  decode.d4.loss_mask: 0.2041  decode.d4.loss_dice: 0.1632  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.2088  decode.d6.loss_cls: 0.0741  decode.d6.loss_mask: 0.2110  decode.d6.loss_dice: 0.1682  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.1620  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.3265  decode.d8.loss_dice: 0.2196
09/30 18:14:35 - mmengine - INFO - Iter(train) [ 75900/320000]  base_lr: 7.8375e-05 lr: 7.8375e-06  eta: 1 day, 5:31:02  time: 0.4381  data_time: 0.0097  memory: 5129  grad_norm: 18.9339  loss: 4.2840  decode.loss_cls: 0.0049  decode.loss_mask: 0.1848  decode.loss_dice: 0.1571  decode.d0.loss_cls: 0.8115  decode.d0.loss_mask: 0.1862  decode.d0.loss_dice: 0.1589  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.1866  decode.d1.loss_dice: 0.1600  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.1853  decode.d2.loss_dice: 0.1511  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.1581  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.1848  decode.d4.loss_dice: 0.1574  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.1835  decode.d5.loss_dice: 0.1499  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.1860  decode.d6.loss_dice: 0.1529  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.1865  decode.d7.loss_dice: 0.1579  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.1843  decode.d8.loss_dice: 0.1607
09/30 18:14:56 - mmengine - INFO - Iter(train) [ 75950/320000]  base_lr: 7.8360e-05 lr: 7.8360e-06  eta: 1 day, 5:30:41  time: 0.4383  data_time: 0.0096  memory: 5145  grad_norm: 33.2054  loss: 4.7452  decode.loss_cls: 0.0237  decode.loss_mask: 0.1950  decode.loss_dice: 0.1736  decode.d0.loss_cls: 0.9069  decode.d0.loss_mask: 0.1952  decode.d0.loss_dice: 0.1802  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.1931  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.1941  decode.d2.loss_dice: 0.1764  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.1742  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.1863  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.1743  decode.d6.loss_cls: 0.0200  decode.d6.loss_mask: 0.1933  decode.d6.loss_dice: 0.1725  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.1951  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.1945  decode.d8.loss_dice: 0.1661
09/30 18:15:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:15:18 - mmengine - INFO - Iter(train) [ 76000/320000]  base_lr: 7.8346e-05 lr: 7.8346e-06  eta: 1 day, 5:30:20  time: 0.4394  data_time: 0.0096  memory: 5129  grad_norm: 44.2796  loss: 6.0799  decode.loss_cls: 0.0339  decode.loss_mask: 0.2326  decode.loss_dice: 0.2315  decode.d0.loss_cls: 1.1318  decode.d0.loss_mask: 0.2285  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.0203  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.2362  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 0.2324  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.2316  decode.d4.loss_dice: 0.2123  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2105  decode.d6.loss_cls: 0.0296  decode.d6.loss_mask: 0.2341  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.0862  decode.d7.loss_mask: 0.2364  decode.d7.loss_dice: 0.2643  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.2156
09/30 18:15:40 - mmengine - INFO - Iter(train) [ 76050/320000]  base_lr: 7.8332e-05 lr: 7.8332e-06  eta: 1 day, 5:29:59  time: 0.4386  data_time: 0.0096  memory: 5129  grad_norm: 18.9740  loss: 4.4188  decode.loss_cls: 0.0061  decode.loss_mask: 0.2013  decode.loss_dice: 0.1601  decode.d0.loss_cls: 0.7879  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.1536  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.1604  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2026  decode.d2.loss_dice: 0.1580  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.2009  decode.d3.loss_dice: 0.1576  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.1580  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.2015  decode.d5.loss_dice: 0.1571  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.1989  decode.d6.loss_dice: 0.1541  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1552  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.2030  decode.d8.loss_dice: 0.1598
09/30 18:16:02 - mmengine - INFO - Iter(train) [ 76100/320000]  base_lr: 7.8317e-05 lr: 7.8317e-06  eta: 1 day, 5:29:37  time: 0.4384  data_time: 0.0096  memory: 5120  grad_norm: 116.5943  loss: 5.3199  decode.loss_cls: 0.0680  decode.loss_mask: 0.2023  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.8771  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.1687  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.2064  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.2050  decode.d2.loss_dice: 0.1692  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.2023  decode.d3.loss_dice: 0.1674  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.2224  decode.d4.loss_dice: 0.1836  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.1659  decode.d6.loss_cls: 0.0761  decode.d6.loss_mask: 0.2042  decode.d6.loss_dice: 0.1659  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.2051  decode.d7.loss_dice: 0.1671  decode.d8.loss_cls: 0.0873  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.1650
09/30 18:16:24 - mmengine - INFO - Iter(train) [ 76150/320000]  base_lr: 7.8303e-05 lr: 7.8303e-06  eta: 1 day, 5:29:16  time: 0.4431  data_time: 0.0099  memory: 5129  grad_norm: 36.1045  loss: 5.2872  decode.loss_cls: 0.0437  decode.loss_mask: 0.2040  decode.loss_dice: 0.1906  decode.d0.loss_cls: 0.7882  decode.d0.loss_mask: 0.2013  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.1984  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.1986  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.1156  decode.d3.loss_mask: 0.2015  decode.d3.loss_dice: 0.1976  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.1813  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.2023  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.1778  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.1793
09/30 18:16:46 - mmengine - INFO - Iter(train) [ 76200/320000]  base_lr: 7.8288e-05 lr: 7.8288e-06  eta: 1 day, 5:28:55  time: 0.4376  data_time: 0.0095  memory: 5129  grad_norm: 88.5069  loss: 6.2486  decode.loss_cls: 0.0999  decode.loss_mask: 0.2513  decode.loss_dice: 0.1969  decode.d0.loss_cls: 0.8259  decode.d0.loss_mask: 0.2470  decode.d0.loss_dice: 0.1810  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.2375  decode.d1.loss_dice: 0.1805  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.1804  decode.d4.loss_cls: 0.1130  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.1897  decode.d5.loss_cls: 0.1219  decode.d5.loss_mask: 0.2497  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.1166  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2032  decode.d7.loss_cls: 0.1571  decode.d7.loss_mask: 0.2444  decode.d7.loss_dice: 0.1940  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.1952
09/30 18:17:08 - mmengine - INFO - Iter(train) [ 76250/320000]  base_lr: 7.8274e-05 lr: 7.8274e-06  eta: 1 day, 5:28:34  time: 0.4402  data_time: 0.0094  memory: 5145  grad_norm: 58.3714  loss: 5.4720  decode.loss_cls: 0.0946  decode.loss_mask: 0.1801  decode.loss_dice: 0.1765  decode.d0.loss_cls: 0.9719  decode.d0.loss_mask: 0.1820  decode.d0.loss_dice: 0.1677  decode.d1.loss_cls: 0.1436  decode.d1.loss_mask: 0.1845  decode.d1.loss_dice: 0.1780  decode.d2.loss_cls: 0.1096  decode.d2.loss_mask: 0.1812  decode.d2.loss_dice: 0.1744  decode.d3.loss_cls: 0.1297  decode.d3.loss_mask: 0.1805  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.1783  decode.d4.loss_dice: 0.1636  decode.d5.loss_cls: 0.0955  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.1106  decode.d6.loss_mask: 0.1807  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0922  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.1730  decode.d8.loss_cls: 0.0919  decode.d8.loss_mask: 0.1816  decode.d8.loss_dice: 0.1667
09/30 18:17:30 - mmengine - INFO - Iter(train) [ 76300/320000]  base_lr: 7.8259e-05 lr: 7.8259e-06  eta: 1 day, 5:28:13  time: 0.4400  data_time: 0.0099  memory: 5145  grad_norm: 22.5930  loss: 4.6704  decode.loss_cls: 0.0034  decode.loss_mask: 0.2100  decode.loss_dice: 0.1796  decode.d0.loss_cls: 0.7232  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.1781  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 0.2101  decode.d1.loss_dice: 0.1736  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2105  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.2085  decode.d3.loss_dice: 0.1762  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.2128  decode.d4.loss_dice: 0.1796  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2107  decode.d6.loss_dice: 0.1798  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.1826  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.1854
09/30 18:17:52 - mmengine - INFO - Iter(train) [ 76350/320000]  base_lr: 7.8245e-05 lr: 7.8245e-06  eta: 1 day, 5:27:51  time: 0.4387  data_time: 0.0097  memory: 5129  grad_norm: 224.8879  loss: 9.2088  decode.loss_cls: 0.2126  decode.loss_mask: 0.3672  decode.loss_dice: 0.3180  decode.d0.loss_cls: 1.1151  decode.d0.loss_mask: 0.3738  decode.d0.loss_dice: 0.2922  decode.d1.loss_cls: 0.1984  decode.d1.loss_mask: 0.3846  decode.d1.loss_dice: 0.3264  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 0.3810  decode.d2.loss_dice: 0.3175  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.3701  decode.d3.loss_dice: 0.3155  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.3736  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.0994  decode.d5.loss_mask: 0.3757  decode.d5.loss_dice: 0.3084  decode.d6.loss_cls: 0.1170  decode.d6.loss_mask: 0.3739  decode.d6.loss_dice: 0.3058  decode.d7.loss_cls: 0.1129  decode.d7.loss_mask: 0.3702  decode.d7.loss_dice: 0.3085  decode.d8.loss_cls: 0.1471  decode.d8.loss_mask: 0.3815  decode.d8.loss_dice: 0.3138
09/30 18:18:14 - mmengine - INFO - Iter(train) [ 76400/320000]  base_lr: 7.8230e-05 lr: 7.8230e-06  eta: 1 day, 5:27:30  time: 0.4387  data_time: 0.0095  memory: 5129  grad_norm: 32.3661  loss: 5.2724  decode.loss_cls: 0.0440  decode.loss_mask: 0.2182  decode.loss_dice: 0.1758  decode.d0.loss_cls: 0.8225  decode.d0.loss_mask: 0.2262  decode.d0.loss_dice: 0.1754  decode.d1.loss_cls: 0.1189  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.1741  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.1749  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.2206  decode.d4.loss_dice: 0.1748  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.1803  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.1724  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.2190  decode.d7.loss_dice: 0.1782  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.2188  decode.d8.loss_dice: 0.1754
09/30 18:18:36 - mmengine - INFO - Iter(train) [ 76450/320000]  base_lr: 7.8216e-05 lr: 7.8216e-06  eta: 1 day, 5:27:09  time: 0.4388  data_time: 0.0097  memory: 5145  grad_norm: 81.6221  loss: 6.5770  decode.loss_cls: 0.1326  decode.loss_mask: 0.2273  decode.loss_dice: 0.2074  decode.d0.loss_cls: 1.0397  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.1877  decode.d1.loss_cls: 0.1716  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.1856  decode.d2.loss_cls: 0.1569  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.1927  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.1928  decode.d4.loss_cls: 0.1464  decode.d4.loss_mask: 0.2258  decode.d4.loss_dice: 0.1914  decode.d5.loss_cls: 0.1293  decode.d5.loss_mask: 0.2268  decode.d5.loss_dice: 0.1904  decode.d6.loss_cls: 0.1499  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.1573  decode.d7.loss_mask: 0.2275  decode.d7.loss_dice: 0.1816  decode.d8.loss_cls: 0.1411  decode.d8.loss_mask: 0.2313  decode.d8.loss_dice: 0.1880
09/30 18:18:58 - mmengine - INFO - Iter(train) [ 76500/320000]  base_lr: 7.8202e-05 lr: 7.8202e-06  eta: 1 day, 5:26:48  time: 0.4389  data_time: 0.0097  memory: 5159  grad_norm: 33.4085  loss: 5.6116  decode.loss_cls: 0.0750  decode.loss_mask: 0.2075  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.9498  decode.d0.loss_mask: 0.2171  decode.d0.loss_dice: 0.1911  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1789  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.2112  decode.d2.loss_dice: 0.1908  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.2084  decode.d3.loss_dice: 0.1822  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.2095  decode.d4.loss_dice: 0.1838  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1982  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.2083  decode.d6.loss_dice: 0.1837  decode.d7.loss_cls: 0.0878  decode.d7.loss_mask: 0.2103  decode.d7.loss_dice: 0.1777  decode.d8.loss_cls: 0.0824  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.1814
09/30 18:19:20 - mmengine - INFO - Iter(train) [ 76550/320000]  base_lr: 7.8187e-05 lr: 7.8187e-06  eta: 1 day, 5:26:26  time: 0.4377  data_time: 0.0094  memory: 5129  grad_norm: 103.0201  loss: 5.7803  decode.loss_cls: 0.0617  decode.loss_mask: 0.1831  decode.loss_dice: 0.2255  decode.d0.loss_cls: 0.9325  decode.d0.loss_mask: 0.1853  decode.d0.loss_dice: 0.2013  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.1857  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.1397  decode.d2.loss_mask: 0.1848  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.1086  decode.d3.loss_mask: 0.1821  decode.d3.loss_dice: 0.1947  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.1834  decode.d4.loss_dice: 0.2049  decode.d5.loss_cls: 0.1299  decode.d5.loss_mask: 0.1857  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.1135  decode.d6.loss_mask: 0.1824  decode.d6.loss_dice: 0.1710  decode.d7.loss_cls: 0.1196  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.1947  decode.d8.loss_cls: 0.1417  decode.d8.loss_mask: 0.1822  decode.d8.loss_dice: 0.2117
09/30 18:19:42 - mmengine - INFO - Iter(train) [ 76600/320000]  base_lr: 7.8173e-05 lr: 7.8173e-06  eta: 1 day, 5:26:05  time: 0.4388  data_time: 0.0095  memory: 5129  grad_norm: 69.6081  loss: 5.1073  decode.loss_cls: 0.0185  decode.loss_mask: 0.2257  decode.loss_dice: 0.1960  decode.d0.loss_cls: 0.7000  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.2265  decode.d1.loss_dice: 0.1917  decode.d2.loss_cls: 0.0227  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.1965  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2240  decode.d3.loss_dice: 0.1934  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.2262  decode.d5.loss_dice: 0.2022  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.2288  decode.d6.loss_dice: 0.1932  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.1882  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.1930
09/30 18:20:04 - mmengine - INFO - Iter(train) [ 76650/320000]  base_lr: 7.8158e-05 lr: 7.8158e-06  eta: 1 day, 5:25:44  time: 0.4379  data_time: 0.0095  memory: 5145  grad_norm: 35.2794  loss: 5.7461  decode.loss_cls: 0.1136  decode.loss_mask: 0.1864  decode.loss_dice: 0.1911  decode.d0.loss_cls: 0.8981  decode.d0.loss_mask: 0.1866  decode.d0.loss_dice: 0.1930  decode.d1.loss_cls: 0.1260  decode.d1.loss_mask: 0.1889  decode.d1.loss_dice: 0.2012  decode.d2.loss_cls: 0.1550  decode.d2.loss_mask: 0.1838  decode.d2.loss_dice: 0.1881  decode.d3.loss_cls: 0.1161  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.1913  decode.d4.loss_cls: 0.1076  decode.d4.loss_mask: 0.1874  decode.d4.loss_dice: 0.1940  decode.d5.loss_cls: 0.1202  decode.d5.loss_mask: 0.1854  decode.d5.loss_dice: 0.1949  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.1847  decode.d6.loss_dice: 0.1900  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.1873  decode.d7.loss_dice: 0.1945  decode.d8.loss_cls: 0.1299  decode.d8.loss_mask: 0.1884  decode.d8.loss_dice: 0.1978
09/30 18:20:26 - mmengine - INFO - Iter(train) [ 76700/320000]  base_lr: 7.8144e-05 lr: 7.8144e-06  eta: 1 day, 5:25:23  time: 0.4395  data_time: 0.0095  memory: 5145  grad_norm: 32.3598  loss: 5.8405  decode.loss_cls: 0.0472  decode.loss_mask: 0.2360  decode.loss_dice: 0.2016  decode.d0.loss_cls: 0.8398  decode.d0.loss_mask: 0.2347  decode.d0.loss_dice: 0.1963  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.2094  decode.d2.loss_cls: 0.1294  decode.d2.loss_mask: 0.2314  decode.d2.loss_dice: 0.1916  decode.d3.loss_cls: 0.1235  decode.d3.loss_mask: 0.2335  decode.d3.loss_dice: 0.1868  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.2036  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.1943  decode.d6.loss_cls: 0.0490  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.1089  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.2375  decode.d8.loss_dice: 0.2034
09/30 18:20:48 - mmengine - INFO - Iter(train) [ 76750/320000]  base_lr: 7.8129e-05 lr: 7.8129e-06  eta: 1 day, 5:25:01  time: 0.4386  data_time: 0.0097  memory: 5129  grad_norm: 31.3189  loss: 5.5198  decode.loss_cls: 0.1394  decode.loss_mask: 0.1876  decode.loss_dice: 0.1873  decode.d0.loss_cls: 0.9595  decode.d0.loss_mask: 0.1927  decode.d0.loss_dice: 0.1862  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.1853  decode.d1.loss_dice: 0.1843  decode.d2.loss_cls: 0.0952  decode.d2.loss_mask: 0.1859  decode.d2.loss_dice: 0.1934  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.1855  decode.d3.loss_dice: 0.1844  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.1883  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0985  decode.d6.loss_mask: 0.1856  decode.d6.loss_dice: 0.1960  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.1844  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.1140  decode.d8.loss_mask: 0.1833  decode.d8.loss_dice: 0.1859
09/30 18:21:09 - mmengine - INFO - Iter(train) [ 76800/320000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 1 day, 5:24:40  time: 0.4379  data_time: 0.0094  memory: 5129  grad_norm: 46.3084  loss: 4.9160  decode.loss_cls: 0.0543  decode.loss_mask: 0.1753  decode.loss_dice: 0.1649  decode.d0.loss_cls: 0.9372  decode.d0.loss_mask: 0.1758  decode.d0.loss_dice: 0.1622  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.1712  decode.d1.loss_dice: 0.1653  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.1742  decode.d2.loss_dice: 0.1596  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.1731  decode.d3.loss_dice: 0.1571  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.1730  decode.d4.loss_dice: 0.1671  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.1717  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.1763  decode.d6.loss_dice: 0.1774  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.1727  decode.d7.loss_dice: 0.1608  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.1718  decode.d8.loss_dice: 0.1692
09/30 18:21:31 - mmengine - INFO - Iter(train) [ 76850/320000]  base_lr: 7.8100e-05 lr: 7.8100e-06  eta: 1 day, 5:24:18  time: 0.4364  data_time: 0.0094  memory: 5104  grad_norm: 31.6144  loss: 5.3006  decode.loss_cls: 0.0762  decode.loss_mask: 0.2031  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.7977  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.2037  decode.d1.loss_dice: 0.2051  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.2089  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.2044  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.2053  decode.d4.loss_dice: 0.2351  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.2052  decode.d5.loss_dice: 0.2005  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.2055  decode.d6.loss_dice: 0.2064  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.1990  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.2018
09/30 18:21:53 - mmengine - INFO - Iter(train) [ 76900/320000]  base_lr: 7.8086e-05 lr: 7.8086e-06  eta: 1 day, 5:23:57  time: 0.4388  data_time: 0.0097  memory: 5129  grad_norm: 77.0024  loss: 7.1173  decode.loss_cls: 0.1111  decode.loss_mask: 0.2760  decode.loss_dice: 0.2783  decode.d0.loss_cls: 0.7609  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.2593  decode.d1.loss_cls: 0.1173  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.2659  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.2650  decode.d3.loss_cls: 0.1067  decode.d3.loss_mask: 0.2701  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.1122  decode.d4.loss_mask: 0.2750  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 0.2709  decode.d5.loss_dice: 0.2682  decode.d6.loss_cls: 0.0975  decode.d6.loss_mask: 0.2718  decode.d6.loss_dice: 0.2685  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.1274  decode.d8.loss_mask: 0.2766  decode.d8.loss_dice: 0.2697
09/30 18:22:15 - mmengine - INFO - Iter(train) [ 76950/320000]  base_lr: 7.8071e-05 lr: 7.8071e-06  eta: 1 day, 5:23:37  time: 0.4385  data_time: 0.0098  memory: 5145  grad_norm: 75.2011  loss: 6.0065  decode.loss_cls: 0.0707  decode.loss_mask: 0.2509  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.8502  decode.d0.loss_mask: 0.2606  decode.d0.loss_dice: 0.2186  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.2516  decode.d1.loss_dice: 0.1998  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.2522  decode.d2.loss_dice: 0.1917  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.1895  decode.d4.loss_cls: 0.0171  decode.d4.loss_mask: 0.2533  decode.d4.loss_dice: 0.2082  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.1850  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.1883  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.1974  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.1982
09/30 18:22:37 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:22:37 - mmengine - INFO - Iter(train) [ 77000/320000]  base_lr: 7.8057e-05 lr: 7.8057e-06  eta: 1 day, 5:23:15  time: 0.4383  data_time: 0.0096  memory: 5129  grad_norm: 170.1422  loss: 7.2968  decode.loss_cls: 0.1823  decode.loss_mask: 0.2399  decode.loss_dice: 0.2049  decode.d0.loss_cls: 0.9414  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.2154  decode.d1.loss_cls: 0.2402  decode.d1.loss_mask: 0.2469  decode.d1.loss_dice: 0.2161  decode.d2.loss_cls: 0.2106  decode.d2.loss_mask: 0.2427  decode.d2.loss_dice: 0.2180  decode.d3.loss_cls: 0.2056  decode.d3.loss_mask: 0.2399  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.2649  decode.d4.loss_mask: 0.2336  decode.d4.loss_dice: 0.1887  decode.d5.loss_cls: 0.2100  decode.d5.loss_mask: 0.2334  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.1905  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.2367  decode.d7.loss_mask: 0.2333  decode.d7.loss_dice: 0.1920  decode.d8.loss_cls: 0.2176  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.1941
09/30 18:22:59 - mmengine - INFO - Iter(train) [ 77050/320000]  base_lr: 7.8043e-05 lr: 7.8043e-06  eta: 1 day, 5:22:54  time: 0.4385  data_time: 0.0097  memory: 5129  grad_norm: 25.8844  loss: 4.5464  decode.loss_cls: 0.0108  decode.loss_mask: 0.2002  decode.loss_dice: 0.1671  decode.d0.loss_cls: 0.7868  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.1613  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.1998  decode.d2.loss_dice: 0.1573  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.2006  decode.d3.loss_dice: 0.1607  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.2026  decode.d4.loss_dice: 0.1701  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.1976  decode.d5.loss_dice: 0.1631  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.1993  decode.d6.loss_dice: 0.1599  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.1974  decode.d7.loss_dice: 0.1558  decode.d8.loss_cls: 0.0171  decode.d8.loss_mask: 0.1990  decode.d8.loss_dice: 0.1523
09/30 18:23:21 - mmengine - INFO - Iter(train) [ 77100/320000]  base_lr: 7.8028e-05 lr: 7.8028e-06  eta: 1 day, 5:22:33  time: 0.4391  data_time: 0.0097  memory: 5129  grad_norm: 20.8417  loss: 4.9193  decode.loss_cls: 0.0306  decode.loss_mask: 0.1894  decode.loss_dice: 0.1922  decode.d0.loss_cls: 0.8810  decode.d0.loss_mask: 0.1882  decode.d0.loss_dice: 0.1918  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.1853  decode.d1.loss_dice: 0.1975  decode.d2.loss_cls: 0.0481  decode.d2.loss_mask: 0.1856  decode.d2.loss_dice: 0.1904  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.1868  decode.d3.loss_dice: 0.1929  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.1854  decode.d4.loss_dice: 0.1914  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.1857  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.1878  decode.d6.loss_dice: 0.1763  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.1873  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.1892  decode.d8.loss_dice: 0.1958
09/30 18:23:43 - mmengine - INFO - Iter(train) [ 77150/320000]  base_lr: 7.8014e-05 lr: 7.8014e-06  eta: 1 day, 5:22:12  time: 0.4394  data_time: 0.0098  memory: 5145  grad_norm: 79.6698  loss: 6.5695  decode.loss_cls: 0.0666  decode.loss_mask: 0.2714  decode.loss_dice: 0.2481  decode.d0.loss_cls: 0.8972  decode.d0.loss_mask: 0.2265  decode.d0.loss_dice: 0.2215  decode.d1.loss_cls: 0.1025  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2244  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.2635  decode.d2.loss_dice: 0.2450  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.2480  decode.d4.loss_cls: 0.1240  decode.d4.loss_mask: 0.2340  decode.d4.loss_dice: 0.2251  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 0.2284  decode.d5.loss_dice: 0.2349  decode.d6.loss_cls: 0.1249  decode.d6.loss_mask: 0.2415  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.0908  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2400
09/30 18:24:05 - mmengine - INFO - Iter(train) [ 77200/320000]  base_lr: 7.7999e-05 lr: 7.7999e-06  eta: 1 day, 5:21:50  time: 0.4387  data_time: 0.0097  memory: 5129  grad_norm: 39.7626  loss: 4.5270  decode.loss_cls: 0.0405  decode.loss_mask: 0.1709  decode.loss_dice: 0.1573  decode.d0.loss_cls: 0.8785  decode.d0.loss_mask: 0.1749  decode.d0.loss_dice: 0.1616  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.1738  decode.d1.loss_dice: 0.1655  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.1738  decode.d2.loss_dice: 0.1613  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.1734  decode.d3.loss_dice: 0.1596  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.1720  decode.d4.loss_dice: 0.1602  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.1748  decode.d5.loss_dice: 0.1638  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.1731  decode.d6.loss_dice: 0.1592  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.1716  decode.d7.loss_dice: 0.1575  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.1721  decode.d8.loss_dice: 0.1599
09/30 18:24:27 - mmengine - INFO - Iter(train) [ 77250/320000]  base_lr: 7.7985e-05 lr: 7.7985e-06  eta: 1 day, 5:21:29  time: 0.4392  data_time: 0.0099  memory: 5129  grad_norm: 21.0372  loss: 5.3954  decode.loss_cls: 0.1029  decode.loss_mask: 0.1758  decode.loss_dice: 0.1971  decode.d0.loss_cls: 0.8973  decode.d0.loss_mask: 0.1751  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.1752  decode.d1.loss_dice: 0.1943  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.1750  decode.d2.loss_dice: 0.1865  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.1749  decode.d3.loss_dice: 0.1987  decode.d4.loss_cls: 0.0861  decode.d4.loss_mask: 0.1775  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.1752  decode.d5.loss_dice: 0.2078  decode.d6.loss_cls: 0.0843  decode.d6.loss_mask: 0.1758  decode.d6.loss_dice: 0.1974  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.1754  decode.d7.loss_dice: 0.1956  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.1763  decode.d8.loss_dice: 0.1987
09/30 18:24:49 - mmengine - INFO - Iter(train) [ 77300/320000]  base_lr: 7.7970e-05 lr: 7.7970e-06  eta: 1 day, 5:21:08  time: 0.4397  data_time: 0.0099  memory: 5145  grad_norm: 44.9445  loss: 5.6359  decode.loss_cls: 0.0896  decode.loss_mask: 0.1881  decode.loss_dice: 0.1917  decode.d0.loss_cls: 0.8884  decode.d0.loss_mask: 0.1914  decode.d0.loss_dice: 0.2010  decode.d1.loss_cls: 0.1511  decode.d1.loss_mask: 0.1898  decode.d1.loss_dice: 0.1955  decode.d2.loss_cls: 0.1443  decode.d2.loss_mask: 0.1895  decode.d2.loss_dice: 0.1825  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.2046  decode.d4.loss_cls: 0.0959  decode.d4.loss_mask: 0.1910  decode.d4.loss_dice: 0.1783  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.1898  decode.d5.loss_dice: 0.1811  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.1892  decode.d6.loss_dice: 0.1860  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 0.1933  decode.d7.loss_dice: 0.1920  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.1766
09/30 18:25:11 - mmengine - INFO - Iter(train) [ 77350/320000]  base_lr: 7.7956e-05 lr: 7.7956e-06  eta: 1 day, 5:20:47  time: 0.4386  data_time: 0.0098  memory: 5129  grad_norm: 133.8498  loss: 8.0475  decode.loss_cls: 0.1874  decode.loss_mask: 0.3088  decode.loss_dice: 0.2638  decode.d0.loss_cls: 0.8550  decode.d0.loss_mask: 0.3150  decode.d0.loss_dice: 0.2481  decode.d1.loss_cls: 0.1841  decode.d1.loss_mask: 0.3087  decode.d1.loss_dice: 0.2573  decode.d2.loss_cls: 0.1508  decode.d2.loss_mask: 0.3109  decode.d2.loss_dice: 0.2470  decode.d3.loss_cls: 0.1393  decode.d3.loss_mask: 0.3123  decode.d3.loss_dice: 0.2568  decode.d4.loss_cls: 0.1639  decode.d4.loss_mask: 0.3115  decode.d4.loss_dice: 0.2592  decode.d5.loss_cls: 0.1733  decode.d5.loss_mask: 0.3100  decode.d5.loss_dice: 0.2663  decode.d6.loss_cls: 0.1745  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.2628  decode.d7.loss_cls: 0.1447  decode.d7.loss_mask: 0.3160  decode.d7.loss_dice: 0.2641  decode.d8.loss_cls: 0.1612  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.2662
09/30 18:25:33 - mmengine - INFO - Iter(train) [ 77400/320000]  base_lr: 7.7941e-05 lr: 7.7941e-06  eta: 1 day, 5:20:26  time: 0.4389  data_time: 0.0099  memory: 5129  grad_norm: 45.8983  loss: 7.4365  decode.loss_cls: 0.1024  decode.loss_mask: 0.3223  decode.loss_dice: 0.2448  decode.d0.loss_cls: 0.7456  decode.d0.loss_mask: 0.3352  decode.d0.loss_dice: 0.2426  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.3215  decode.d1.loss_dice: 0.2346  decode.d2.loss_cls: 0.1191  decode.d2.loss_mask: 0.3179  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.1240  decode.d3.loss_mask: 0.3206  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 0.3202  decode.d4.loss_dice: 0.2212  decode.d5.loss_cls: 0.1104  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.2445  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.2287  decode.d7.loss_cls: 0.1469  decode.d7.loss_mask: 0.3206  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.3198  decode.d8.loss_dice: 0.2431
09/30 18:25:55 - mmengine - INFO - Iter(train) [ 77450/320000]  base_lr: 7.7927e-05 lr: 7.7927e-06  eta: 1 day, 5:20:04  time: 0.4402  data_time: 0.0098  memory: 5120  grad_norm: 32.0117  loss: 5.4418  decode.loss_cls: 0.0594  decode.loss_mask: 0.2078  decode.loss_dice: 0.2053  decode.d0.loss_cls: 0.8127  decode.d0.loss_mask: 0.2079  decode.d0.loss_dice: 0.1896  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.2087  decode.d1.loss_dice: 0.1967  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1924  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.0872  decode.d4.loss_mask: 0.2042  decode.d4.loss_dice: 0.2000  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.2023  decode.d5.loss_dice: 0.1808  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2036  decode.d6.loss_dice: 0.1870  decode.d7.loss_cls: 0.0620  decode.d7.loss_mask: 0.2044  decode.d7.loss_dice: 0.1886  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.2027  decode.d8.loss_dice: 0.1986
09/30 18:26:17 - mmengine - INFO - Iter(train) [ 77500/320000]  base_lr: 7.7912e-05 lr: 7.7912e-06  eta: 1 day, 5:19:43  time: 0.4397  data_time: 0.0098  memory: 5145  grad_norm: 50.6093  loss: 5.5996  decode.loss_cls: 0.0937  decode.loss_mask: 0.2100  decode.loss_dice: 0.2136  decode.d0.loss_cls: 0.8029  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.2096  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0621  decode.d2.loss_mask: 0.2120  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.2039  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.2126  decode.d4.loss_dice: 0.2274  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.2000  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2037  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.2140  decode.d7.loss_dice: 0.2014  decode.d8.loss_cls: 0.1283  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.1929
09/30 18:26:39 - mmengine - INFO - Iter(train) [ 77550/320000]  base_lr: 7.7898e-05 lr: 7.7898e-06  eta: 1 day, 5:19:22  time: 0.4392  data_time: 0.0098  memory: 5129  grad_norm: 43.1384  loss: 5.1649  decode.loss_cls: 0.0106  decode.loss_mask: 0.2065  decode.loss_dice: 0.2208  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 0.2065  decode.d0.loss_dice: 0.2055  decode.d1.loss_cls: 0.0460  decode.d1.loss_mask: 0.2065  decode.d1.loss_dice: 0.2170  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.2097  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.2230  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.2060  decode.d4.loss_dice: 0.2136  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.0125  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.2154  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.2018  decode.d7.loss_dice: 0.2190  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.2020  decode.d8.loss_dice: 0.2110
09/30 18:27:01 - mmengine - INFO - Iter(train) [ 77600/320000]  base_lr: 7.7884e-05 lr: 7.7884e-06  eta: 1 day, 5:19:01  time: 0.4395  data_time: 0.0097  memory: 5145  grad_norm: 35.9250  loss: 5.7402  decode.loss_cls: 0.0425  decode.loss_mask: 0.2121  decode.loss_dice: 0.2276  decode.d0.loss_cls: 0.8371  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.2330  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.2193  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.2331  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.2149  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.2141  decode.d4.loss_dice: 0.2245  decode.d5.loss_cls: 0.0680  decode.d5.loss_mask: 0.2128  decode.d5.loss_dice: 0.2209  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.2091  decode.d6.loss_dice: 0.2122  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2147
09/30 18:27:23 - mmengine - INFO - Iter(train) [ 77650/320000]  base_lr: 7.7869e-05 lr: 7.7869e-06  eta: 1 day, 5:18:40  time: 0.4380  data_time: 0.0096  memory: 5120  grad_norm: 33.3306  loss: 4.8358  decode.loss_cls: 0.0036  decode.loss_mask: 0.2000  decode.loss_dice: 0.1803  decode.d0.loss_cls: 0.8425  decode.d0.loss_mask: 0.2053  decode.d0.loss_dice: 0.1927  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.2025  decode.d1.loss_dice: 0.1835  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0144  decode.d3.loss_mask: 0.2019  decode.d3.loss_dice: 0.1834  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.1983  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.1949  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.1875  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2007  decode.d8.loss_dice: 0.1823
09/30 18:27:45 - mmengine - INFO - Iter(train) [ 77700/320000]  base_lr: 7.7855e-05 lr: 7.7855e-06  eta: 1 day, 5:18:18  time: 0.4387  data_time: 0.0097  memory: 5120  grad_norm: 24.9582  loss: 5.7388  decode.loss_cls: 0.0720  decode.loss_mask: 0.2563  decode.loss_dice: 0.1926  decode.d0.loss_cls: 0.7917  decode.d0.loss_mask: 0.2657  decode.d0.loss_dice: 0.1876  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0396  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.1721  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.2571  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.2600  decode.d4.loss_dice: 0.1844  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.2580  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.2560  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.2605  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.1818
09/30 18:28:07 - mmengine - INFO - Iter(train) [ 77750/320000]  base_lr: 7.7840e-05 lr: 7.7840e-06  eta: 1 day, 5:17:57  time: 0.4381  data_time: 0.0097  memory: 5145  grad_norm: 18.0491  loss: 3.9108  decode.loss_cls: 0.0126  decode.loss_mask: 0.1591  decode.loss_dice: 0.1531  decode.d0.loss_cls: 0.7125  decode.d0.loss_mask: 0.1575  decode.d0.loss_dice: 0.1453  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.1590  decode.d1.loss_dice: 0.1508  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.1598  decode.d2.loss_dice: 0.1530  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.1587  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.1547  decode.d4.loss_dice: 0.1538  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.1576  decode.d5.loss_dice: 0.1541  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.1590  decode.d6.loss_dice: 0.1517  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.1586  decode.d7.loss_dice: 0.1563  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.1573  decode.d8.loss_dice: 0.1532
09/30 18:28:29 - mmengine - INFO - Iter(train) [ 77800/320000]  base_lr: 7.7826e-05 lr: 7.7826e-06  eta: 1 day, 5:17:36  time: 0.4456  data_time: 0.0101  memory: 5120  grad_norm: 44.6042  loss: 6.5537  decode.loss_cls: 0.1259  decode.loss_mask: 0.1960  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.9832  decode.d0.loss_mask: 0.1990  decode.d0.loss_dice: 0.2674  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 0.2000  decode.d1.loss_dice: 0.2763  decode.d2.loss_cls: 0.1414  decode.d2.loss_mask: 0.1998  decode.d2.loss_dice: 0.2764  decode.d3.loss_cls: 0.1269  decode.d3.loss_mask: 0.2003  decode.d3.loss_dice: 0.2530  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.2779  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.2020  decode.d5.loss_dice: 0.2810  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.2874  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.2006  decode.d7.loss_dice: 0.2914  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.1981  decode.d8.loss_dice: 0.2791
09/30 18:28:51 - mmengine - INFO - Iter(train) [ 77850/320000]  base_lr: 7.7811e-05 lr: 7.7811e-06  eta: 1 day, 5:17:15  time: 0.4394  data_time: 0.0098  memory: 5119  grad_norm: 40.1354  loss: 5.4844  decode.loss_cls: 0.0513  decode.loss_mask: 0.2082  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.9013  decode.d0.loss_mask: 0.2048  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.1162  decode.d1.loss_mask: 0.2083  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.0523  decode.d2.loss_mask: 0.2072  decode.d2.loss_dice: 0.2039  decode.d3.loss_cls: 0.0479  decode.d3.loss_mask: 0.2062  decode.d3.loss_dice: 0.2011  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2075  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.2066  decode.d5.loss_dice: 0.2030  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.2047  decode.d6.loss_dice: 0.1991  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1924  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.2046  decode.d8.loss_dice: 0.1999
09/30 18:29:13 - mmengine - INFO - Iter(train) [ 77900/320000]  base_lr: 7.7797e-05 lr: 7.7797e-06  eta: 1 day, 5:16:54  time: 0.4400  data_time: 0.0100  memory: 5129  grad_norm: 50.0071  loss: 6.4083  decode.loss_cls: 0.0877  decode.loss_mask: 0.2564  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.7964  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.2173  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.2171  decode.d2.loss_cls: 0.0910  decode.d2.loss_mask: 0.2620  decode.d2.loss_dice: 0.2163  decode.d3.loss_cls: 0.0942  decode.d3.loss_mask: 0.2563  decode.d3.loss_dice: 0.2217  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.2635  decode.d4.loss_dice: 0.2258  decode.d5.loss_cls: 0.1312  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.2576  decode.d6.loss_dice: 0.2152  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.2578  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.2611  decode.d8.loss_dice: 0.2233
09/30 18:29:35 - mmengine - INFO - Iter(train) [ 77950/320000]  base_lr: 7.7782e-05 lr: 7.7782e-06  eta: 1 day, 5:16:33  time: 0.4381  data_time: 0.0099  memory: 5129  grad_norm: 59.4058  loss: 10.5434  decode.loss_cls: 0.2877  decode.loss_mask: 0.4018  decode.loss_dice: 0.3637  decode.d0.loss_cls: 1.0381  decode.d0.loss_mask: 0.3068  decode.d0.loss_dice: 0.3740  decode.d1.loss_cls: 0.3064  decode.d1.loss_mask: 0.3319  decode.d1.loss_dice: 0.3700  decode.d2.loss_cls: 0.2873  decode.d2.loss_mask: 0.3178  decode.d2.loss_dice: 0.3849  decode.d3.loss_cls: 0.2973  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.3615  decode.d4.loss_cls: 0.2959  decode.d4.loss_mask: 0.2971  decode.d4.loss_dice: 0.3720  decode.d5.loss_cls: 0.2766  decode.d5.loss_mask: 0.3007  decode.d5.loss_dice: 0.3671  decode.d6.loss_cls: 0.2761  decode.d6.loss_mask: 0.3019  decode.d6.loss_dice: 0.3769  decode.d7.loss_cls: 0.2656  decode.d7.loss_mask: 0.3027  decode.d7.loss_dice: 0.3655  decode.d8.loss_cls: 0.3143  decode.d8.loss_mask: 0.3060  decode.d8.loss_dice: 0.3650
09/30 18:29:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:29:57 - mmengine - INFO - Iter(train) [ 78000/320000]  base_lr: 7.7768e-05 lr: 7.7768e-06  eta: 1 day, 5:16:11  time: 0.4398  data_time: 0.0099  memory: 5120  grad_norm: 41.4579  loss: 5.3983  decode.loss_cls: 0.0467  decode.loss_mask: 0.1939  decode.loss_dice: 0.2194  decode.d0.loss_cls: 0.8717  decode.d0.loss_mask: 0.1941  decode.d0.loss_dice: 0.2162  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.1898  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.1942  decode.d2.loss_dice: 0.2076  decode.d3.loss_cls: 0.0993  decode.d3.loss_mask: 0.1926  decode.d3.loss_dice: 0.2075  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.2039  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.1955  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.0818  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.2166  decode.d7.loss_cls: 0.0311  decode.d7.loss_mask: 0.1931  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.1922  decode.d8.loss_dice: 0.2283
09/30 18:30:19 - mmengine - INFO - Iter(train) [ 78050/320000]  base_lr: 7.7753e-05 lr: 7.7753e-06  eta: 1 day, 5:15:50  time: 0.4377  data_time: 0.0097  memory: 5145  grad_norm: 48.3827  loss: 5.9385  decode.loss_cls: 0.0747  decode.loss_mask: 0.2109  decode.loss_dice: 0.1966  decode.d0.loss_cls: 0.8920  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.1229  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.2155  decode.d2.loss_cls: 0.0803  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.2327  decode.d3.loss_cls: 0.0841  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.2002  decode.d4.loss_cls: 0.0787  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.2124  decode.d5.loss_dice: 0.1962  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.2164  decode.d6.loss_dice: 0.2050  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 0.2140  decode.d7.loss_dice: 0.2309  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.2125  decode.d8.loss_dice: 0.2373
09/30 18:30:40 - mmengine - INFO - Iter(train) [ 78100/320000]  base_lr: 7.7739e-05 lr: 7.7739e-06  eta: 1 day, 5:15:29  time: 0.4391  data_time: 0.0096  memory: 5129  grad_norm: 108.4573  loss: 6.3653  decode.loss_cls: 0.0048  decode.loss_mask: 0.3188  decode.loss_dice: 0.2368  decode.d0.loss_cls: 0.7412  decode.d0.loss_mask: 0.3242  decode.d0.loss_dice: 0.2383  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.3189  decode.d1.loss_dice: 0.2322  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.3206  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.3218  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3216  decode.d4.loss_dice: 0.2392  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.3209  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.3164  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.2375  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.3194  decode.d8.loss_dice: 0.2411
09/30 18:31:02 - mmengine - INFO - Iter(train) [ 78150/320000]  base_lr: 7.7724e-05 lr: 7.7724e-06  eta: 1 day, 5:15:08  time: 0.4376  data_time: 0.0096  memory: 5145  grad_norm: 51.0401  loss: 5.7903  decode.loss_cls: 0.0543  decode.loss_mask: 0.1993  decode.loss_dice: 0.2177  decode.d0.loss_cls: 0.7515  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.1615  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.2290  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.1067  decode.d3.loss_mask: 0.1993  decode.d3.loss_dice: 0.2215  decode.d4.loss_cls: 0.1141  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.2104  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.1980  decode.d5.loss_dice: 0.2115  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.2171  decode.d7.loss_cls: 0.1141  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.2193  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.2226
09/30 18:31:24 - mmengine - INFO - Iter(train) [ 78200/320000]  base_lr: 7.7710e-05 lr: 7.7710e-06  eta: 1 day, 5:14:46  time: 0.4388  data_time: 0.0098  memory: 5145  grad_norm: 35.3700  loss: 6.3780  decode.loss_cls: 0.1186  decode.loss_mask: 0.2209  decode.loss_dice: 0.2265  decode.d0.loss_cls: 0.8496  decode.d0.loss_mask: 0.2236  decode.d0.loss_dice: 0.2287  decode.d1.loss_cls: 0.1010  decode.d1.loss_mask: 0.2196  decode.d1.loss_dice: 0.2129  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 0.2221  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.2195  decode.d3.loss_dice: 0.2347  decode.d4.loss_cls: 0.1311  decode.d4.loss_mask: 0.2190  decode.d4.loss_dice: 0.2348  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.2368  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.2340  decode.d7.loss_cls: 0.1257  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2416  decode.d8.loss_cls: 0.1189  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2493
09/30 18:31:46 - mmengine - INFO - Iter(train) [ 78250/320000]  base_lr: 7.7696e-05 lr: 7.7696e-06  eta: 1 day, 5:14:25  time: 0.4385  data_time: 0.0098  memory: 5129  grad_norm: 61.8802  loss: 6.9074  decode.loss_cls: 0.0587  decode.loss_mask: 0.2603  decode.loss_dice: 0.2773  decode.d0.loss_cls: 0.8702  decode.d0.loss_mask: 0.2599  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.1423  decode.d1.loss_mask: 0.2573  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.1484  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.2701  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.2598  decode.d3.loss_dice: 0.2814  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.2580  decode.d4.loss_dice: 0.2760  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.2779  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.2593  decode.d6.loss_dice: 0.3010  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.2554  decode.d7.loss_dice: 0.2744  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.2584  decode.d8.loss_dice: 0.2668
09/30 18:32:08 - mmengine - INFO - Iter(train) [ 78300/320000]  base_lr: 7.7681e-05 lr: 7.7681e-06  eta: 1 day, 5:14:04  time: 0.4404  data_time: 0.0099  memory: 5129  grad_norm: 22.2204  loss: 5.2598  decode.loss_cls: 0.0030  decode.loss_mask: 0.2215  decode.loss_dice: 0.1986  decode.d0.loss_cls: 0.8693  decode.d0.loss_mask: 0.1945  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.1961  decode.d1.loss_dice: 0.1935  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.1956  decode.d3.loss_dice: 0.1984  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.1991  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.1969  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.1965  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.1973  decode.d7.loss_dice: 0.1955  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1944
09/30 18:32:30 - mmengine - INFO - Iter(train) [ 78350/320000]  base_lr: 7.7667e-05 lr: 7.7667e-06  eta: 1 day, 5:13:43  time: 0.4378  data_time: 0.0093  memory: 5129  grad_norm: 39.6869  loss: 4.4237  decode.loss_cls: 0.0137  decode.loss_mask: 0.1645  decode.loss_dice: 0.1778  decode.d0.loss_cls: 0.9104  decode.d0.loss_mask: 0.1676  decode.d0.loss_dice: 0.1620  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.1666  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.1614  decode.d2.loss_dice: 0.1770  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.1594  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.1648  decode.d4.loss_dice: 0.1775  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.1625  decode.d5.loss_dice: 0.1712  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.1629  decode.d6.loss_dice: 0.1697  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.1633  decode.d7.loss_dice: 0.1721  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.1653  decode.d8.loss_dice: 0.1727
09/30 18:32:52 - mmengine - INFO - Iter(train) [ 78400/320000]  base_lr: 7.7652e-05 lr: 7.7652e-06  eta: 1 day, 5:13:21  time: 0.4399  data_time: 0.0098  memory: 5129  grad_norm: 26.6544  loss: 5.1132  decode.loss_cls: 0.0766  decode.loss_mask: 0.1834  decode.loss_dice: 0.1773  decode.d0.loss_cls: 0.7694  decode.d0.loss_mask: 0.1883  decode.d0.loss_dice: 0.1825  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.1854  decode.d1.loss_dice: 0.1794  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.1849  decode.d2.loss_dice: 0.1841  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.1847  decode.d3.loss_dice: 0.1818  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.1833  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.1789  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.1857  decode.d6.loss_dice: 0.1465  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0961  decode.d8.loss_mask: 0.1824  decode.d8.loss_dice: 0.1780
09/30 18:33:14 - mmengine - INFO - Iter(train) [ 78450/320000]  base_lr: 7.7638e-05 lr: 7.7638e-06  eta: 1 day, 5:13:00  time: 0.4388  data_time: 0.0101  memory: 5145  grad_norm: 33.3000  loss: 6.0507  decode.loss_cls: 0.0994  decode.loss_mask: 0.2100  decode.loss_dice: 0.2162  decode.d0.loss_cls: 0.9241  decode.d0.loss_mask: 0.2135  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.2227  decode.d2.loss_cls: 0.0967  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.2261  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.2127  decode.d3.loss_dice: 0.2162  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.2117  decode.d4.loss_dice: 0.2109  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.2121  decode.d5.loss_dice: 0.2205  decode.d6.loss_cls: 0.0952  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.2280  decode.d7.loss_cls: 0.0910  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2174  decode.d8.loss_cls: 0.1043  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2129
09/30 18:33:36 - mmengine - INFO - Iter(train) [ 78500/320000]  base_lr: 7.7623e-05 lr: 7.7623e-06  eta: 1 day, 5:12:39  time: 0.4401  data_time: 0.0098  memory: 5145  grad_norm: 64.0304  loss: 6.3820  decode.loss_cls: 0.0583  decode.loss_mask: 0.2467  decode.loss_dice: 0.2763  decode.d0.loss_cls: 0.9742  decode.d0.loss_mask: 0.2070  decode.d0.loss_dice: 0.2181  decode.d1.loss_cls: 0.1486  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.2184  decode.d2.loss_cls: 0.1166  decode.d2.loss_mask: 0.1991  decode.d2.loss_dice: 0.1860  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.2220  decode.d4.loss_cls: 0.0844  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.2287  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.2413  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.2476
09/30 18:33:58 - mmengine - INFO - Iter(train) [ 78550/320000]  base_lr: 7.7609e-05 lr: 7.7609e-06  eta: 1 day, 5:12:18  time: 0.4380  data_time: 0.0097  memory: 5129  grad_norm: 27.0272  loss: 5.0855  decode.loss_cls: 0.0075  decode.loss_mask: 0.2507  decode.loss_dice: 0.1621  decode.d0.loss_cls: 0.8140  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.1677  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.2560  decode.d1.loss_dice: 0.1688  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.1676  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.1654  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.1677  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.1623  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.1630  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.2488  decode.d7.loss_dice: 0.1626  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.1616
09/30 18:34:20 - mmengine - INFO - Iter(train) [ 78600/320000]  base_lr: 7.7594e-05 lr: 7.7594e-06  eta: 1 day, 5:11:57  time: 0.4388  data_time: 0.0098  memory: 5129  grad_norm: 33.3616  loss: 5.4263  decode.loss_cls: 0.0339  decode.loss_mask: 0.1802  decode.loss_dice: 0.2274  decode.d0.loss_cls: 0.9939  decode.d0.loss_mask: 0.1768  decode.d0.loss_dice: 0.2244  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.1817  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.1808  decode.d2.loss_dice: 0.2284  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.1800  decode.d3.loss_dice: 0.2263  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.1773  decode.d4.loss_dice: 0.2197  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.1794  decode.d5.loss_dice: 0.2250  decode.d6.loss_cls: 0.0273  decode.d6.loss_mask: 0.1783  decode.d6.loss_dice: 0.2316  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.1796  decode.d7.loss_dice: 0.2309  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.1795  decode.d8.loss_dice: 0.2274
09/30 18:34:42 - mmengine - INFO - Iter(train) [ 78650/320000]  base_lr: 7.7580e-05 lr: 7.7580e-06  eta: 1 day, 5:11:36  time: 0.4395  data_time: 0.0099  memory: 5129  grad_norm: 49.8096  loss: 7.6181  decode.loss_cls: 0.2580  decode.loss_mask: 0.2061  decode.loss_dice: 0.1963  decode.d0.loss_cls: 0.9078  decode.d0.loss_mask: 0.2065  decode.d0.loss_dice: 0.2224  decode.d1.loss_cls: 0.3047  decode.d1.loss_mask: 0.2034  decode.d1.loss_dice: 0.2123  decode.d2.loss_cls: 0.2770  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.2127  decode.d3.loss_cls: 0.2874  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.2575  decode.d4.loss_mask: 0.2052  decode.d4.loss_dice: 0.2252  decode.d5.loss_cls: 0.2799  decode.d5.loss_mask: 0.2024  decode.d5.loss_dice: 0.2173  decode.d6.loss_cls: 0.2719  decode.d6.loss_mask: 0.2039  decode.d6.loss_dice: 0.2222  decode.d7.loss_cls: 0.2874  decode.d7.loss_mask: 0.2045  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.2851  decode.d8.loss_mask: 0.2069  decode.d8.loss_dice: 0.2121
09/30 18:35:04 - mmengine - INFO - Iter(train) [ 78700/320000]  base_lr: 7.7565e-05 lr: 7.7565e-06  eta: 1 day, 5:11:15  time: 0.4391  data_time: 0.0099  memory: 5129  grad_norm: 41.0685  loss: 5.1257  decode.loss_cls: 0.0029  decode.loss_mask: 0.2415  decode.loss_dice: 0.1943  decode.d0.loss_cls: 0.7549  decode.d0.loss_mask: 0.2401  decode.d0.loss_dice: 0.1891  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.1950  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.1927  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.2420  decode.d4.loss_dice: 0.1962  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.1945  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.2419  decode.d6.loss_dice: 0.1946  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.1946  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.1919
09/30 18:35:26 - mmengine - INFO - Iter(train) [ 78750/320000]  base_lr: 7.7551e-05 lr: 7.7551e-06  eta: 1 day, 5:10:54  time: 0.4386  data_time: 0.0099  memory: 5120  grad_norm: 23.9612  loss: 4.8341  decode.loss_cls: 0.0107  decode.loss_mask: 0.2208  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.8080  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.1617  decode.d1.loss_cls: 0.0269  decode.d1.loss_mask: 0.2199  decode.d1.loss_dice: 0.1691  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.2190  decode.d2.loss_dice: 0.1685  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.1710  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.1708  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.1701  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.1704  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.2205  decode.d7.loss_dice: 0.1694  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.2197  decode.d8.loss_dice: 0.1699
09/30 18:35:48 - mmengine - INFO - Iter(train) [ 78800/320000]  base_lr: 7.7536e-05 lr: 7.7536e-06  eta: 1 day, 5:10:33  time: 0.4384  data_time: 0.0099  memory: 5119  grad_norm: 58.0594  loss: 6.9669  decode.loss_cls: 0.0616  decode.loss_mask: 0.3031  decode.loss_dice: 0.2648  decode.d0.loss_cls: 0.7687  decode.d0.loss_mask: 0.3029  decode.d0.loss_dice: 0.2566  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 0.3006  decode.d1.loss_dice: 0.2623  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.3003  decode.d2.loss_dice: 0.2789  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.3012  decode.d3.loss_dice: 0.2626  decode.d4.loss_cls: 0.1022  decode.d4.loss_mask: 0.2998  decode.d4.loss_dice: 0.2550  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.3009  decode.d5.loss_dice: 0.2603  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.2977  decode.d6.loss_dice: 0.2633  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.3023  decode.d7.loss_dice: 0.2526  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.2670
09/30 18:36:10 - mmengine - INFO - Iter(train) [ 78850/320000]  base_lr: 7.7522e-05 lr: 7.7522e-06  eta: 1 day, 5:10:12  time: 0.4385  data_time: 0.0099  memory: 5145  grad_norm: 42.8211  loss: 6.2466  decode.loss_cls: 0.1163  decode.loss_mask: 0.2326  decode.loss_dice: 0.2211  decode.d0.loss_cls: 0.8814  decode.d0.loss_mask: 0.2354  decode.d0.loss_dice: 0.2159  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2107  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.1808  decode.d3.loss_cls: 0.1420  decode.d3.loss_mask: 0.2319  decode.d3.loss_dice: 0.2094  decode.d4.loss_cls: 0.1079  decode.d4.loss_mask: 0.2329  decode.d4.loss_dice: 0.2074  decode.d5.loss_cls: 0.1161  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.2141  decode.d6.loss_cls: 0.1022  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2189  decode.d7.loss_cls: 0.0935  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2076  decode.d8.loss_cls: 0.1170  decode.d8.loss_mask: 0.2324  decode.d8.loss_dice: 0.2104
09/30 18:36:32 - mmengine - INFO - Iter(train) [ 78900/320000]  base_lr: 7.7508e-05 lr: 7.7508e-06  eta: 1 day, 5:09:50  time: 0.4386  data_time: 0.0098  memory: 5145  grad_norm: 60.8845  loss: 7.2578  decode.loss_cls: 0.1530  decode.loss_mask: 0.2954  decode.loss_dice: 0.2220  decode.d0.loss_cls: 1.0042  decode.d0.loss_mask: 0.3066  decode.d0.loss_dice: 0.2227  decode.d1.loss_cls: 0.1086  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.2247  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.2264  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.3022  decode.d3.loss_dice: 0.2305  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.3063  decode.d4.loss_dice: 0.2286  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.2228  decode.d6.loss_cls: 0.1154  decode.d6.loss_mask: 0.3003  decode.d6.loss_dice: 0.2281  decode.d7.loss_cls: 0.1237  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.1039  decode.d8.loss_mask: 0.3010  decode.d8.loss_dice: 0.2340
09/30 18:36:54 - mmengine - INFO - Iter(train) [ 78950/320000]  base_lr: 7.7493e-05 lr: 7.7493e-06  eta: 1 day, 5:09:29  time: 0.4399  data_time: 0.0100  memory: 5145  grad_norm: 43.0508  loss: 6.2460  decode.loss_cls: 0.0828  decode.loss_mask: 0.2341  decode.loss_dice: 0.2288  decode.d0.loss_cls: 0.8843  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.2242  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.2334  decode.d2.loss_cls: 0.1008  decode.d2.loss_mask: 0.2268  decode.d2.loss_dice: 0.2199  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.2258  decode.d4.loss_cls: 0.1181  decode.d4.loss_mask: 0.2410  decode.d4.loss_dice: 0.2408  decode.d5.loss_cls: 0.0863  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.2367  decode.d6.loss_cls: 0.0903  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.2220  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2276  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.2273
09/30 18:37:16 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:37:16 - mmengine - INFO - Iter(train) [ 79000/320000]  base_lr: 7.7479e-05 lr: 7.7479e-06  eta: 1 day, 5:09:08  time: 0.4399  data_time: 0.0098  memory: 5129  grad_norm: 62.0315  loss: 5.6810  decode.loss_cls: 0.0760  decode.loss_mask: 0.2109  decode.loss_dice: 0.1955  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.1956  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.1842  decode.d2.loss_cls: 0.1170  decode.d2.loss_mask: 0.2128  decode.d2.loss_dice: 0.1734  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.1678  decode.d4.loss_cls: 0.1004  decode.d4.loss_mask: 0.2103  decode.d4.loss_dice: 0.1906  decode.d5.loss_cls: 0.1098  decode.d5.loss_mask: 0.2126  decode.d5.loss_dice: 0.1927  decode.d6.loss_cls: 0.1021  decode.d6.loss_mask: 0.2120  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.2132  decode.d7.loss_dice: 0.1799  decode.d8.loss_cls: 0.1120  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.1789
09/30 18:37:38 - mmengine - INFO - Iter(train) [ 79050/320000]  base_lr: 7.7464e-05 lr: 7.7464e-06  eta: 1 day, 5:08:47  time: 0.4390  data_time: 0.0098  memory: 5145  grad_norm: 49.8543  loss: 5.9767  decode.loss_cls: 0.0091  decode.loss_mask: 0.2637  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.8272  decode.d0.loss_mask: 0.2607  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.2195  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.2680  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.2663  decode.d3.loss_dice: 0.2212  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2635  decode.d4.loss_dice: 0.2327  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.2645  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2662  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2637  decode.d7.loss_dice: 0.2313  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.2642  decode.d8.loss_dice: 0.2301
09/30 18:38:00 - mmengine - INFO - Iter(train) [ 79100/320000]  base_lr: 7.7450e-05 lr: 7.7450e-06  eta: 1 day, 5:08:26  time: 0.4371  data_time: 0.0099  memory: 5129  grad_norm: 34.0883  loss: 6.2811  decode.loss_cls: 0.0602  decode.loss_mask: 0.2510  decode.loss_dice: 0.2217  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.2229  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.2379  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.2506  decode.d2.loss_dice: 0.2333  decode.d3.loss_cls: 0.1371  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2030  decode.d4.loss_cls: 0.1438  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.2312  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.2481  decode.d5.loss_dice: 0.2297  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.2234  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.2514  decode.d7.loss_dice: 0.2256  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.2279
09/30 18:38:22 - mmengine - INFO - Iter(train) [ 79150/320000]  base_lr: 7.7435e-05 lr: 7.7435e-06  eta: 1 day, 5:08:05  time: 0.4390  data_time: 0.0097  memory: 5129  grad_norm: 17.7090  loss: 4.1098  decode.loss_cls: 0.0074  decode.loss_mask: 0.1543  decode.loss_dice: 0.1613  decode.d0.loss_cls: 0.8352  decode.d0.loss_mask: 0.1559  decode.d0.loss_dice: 0.1613  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.1552  decode.d1.loss_dice: 0.1803  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.1543  decode.d2.loss_dice: 0.1663  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.1551  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.1517  decode.d4.loss_dice: 0.1628  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.1576  decode.d5.loss_dice: 0.1665  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.1550  decode.d6.loss_dice: 0.1661  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1542  decode.d7.loss_dice: 0.1617  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.1562  decode.d8.loss_dice: 0.1636
09/30 18:38:44 - mmengine - INFO - Iter(train) [ 79200/320000]  base_lr: 7.7421e-05 lr: 7.7421e-06  eta: 1 day, 5:07:43  time: 0.4399  data_time: 0.0100  memory: 5159  grad_norm: 171.3093  loss: 8.6838  decode.loss_cls: 0.1520  decode.loss_mask: 0.4521  decode.loss_dice: 0.2661  decode.d0.loss_cls: 0.9118  decode.d0.loss_mask: 0.2954  decode.d0.loss_dice: 0.2479  decode.d1.loss_cls: 0.1402  decode.d1.loss_mask: 0.3699  decode.d1.loss_dice: 0.2796  decode.d2.loss_cls: 0.1340  decode.d2.loss_mask: 0.4286  decode.d2.loss_dice: 0.2625  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.3987  decode.d3.loss_dice: 0.2827  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.3916  decode.d4.loss_dice: 0.2692  decode.d5.loss_cls: 0.2068  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.1924  decode.d6.loss_mask: 0.3473  decode.d6.loss_dice: 0.2804  decode.d7.loss_cls: 0.1973  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.2348  decode.d8.loss_cls: 0.2077  decode.d8.loss_mask: 0.3593  decode.d8.loss_dice: 0.2556
09/30 18:39:06 - mmengine - INFO - Iter(train) [ 79250/320000]  base_lr: 7.7406e-05 lr: 7.7406e-06  eta: 1 day, 5:07:22  time: 0.4395  data_time: 0.0097  memory: 5145  grad_norm: 55.0058  loss: 6.2456  decode.loss_cls: 0.1445  decode.loss_mask: 0.2139  decode.loss_dice: 0.2204  decode.d0.loss_cls: 0.8103  decode.d0.loss_mask: 0.2141  decode.d0.loss_dice: 0.2300  decode.d1.loss_cls: 0.1327  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.2298  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.2080  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2045  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.1259  decode.d5.loss_mask: 0.2177  decode.d5.loss_dice: 0.1922  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 0.2169  decode.d6.loss_dice: 0.2311  decode.d7.loss_cls: 0.1300  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2154  decode.d8.loss_cls: 0.1120  decode.d8.loss_mask: 0.2182  decode.d8.loss_dice: 0.2040
09/30 18:39:28 - mmengine - INFO - Iter(train) [ 79300/320000]  base_lr: 7.7392e-05 lr: 7.7392e-06  eta: 1 day, 5:07:01  time: 0.4392  data_time: 0.0099  memory: 5129  grad_norm: 60.1063  loss: 7.8878  decode.loss_cls: 0.1249  decode.loss_mask: 0.2850  decode.loss_dice: 0.2690  decode.d0.loss_cls: 0.9244  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.2365  decode.d1.loss_cls: 0.2439  decode.d1.loss_mask: 0.2937  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.1910  decode.d2.loss_mask: 0.2937  decode.d2.loss_dice: 0.2430  decode.d3.loss_cls: 0.1958  decode.d3.loss_mask: 0.2912  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.1962  decode.d4.loss_mask: 0.2906  decode.d4.loss_dice: 0.2708  decode.d5.loss_cls: 0.1521  decode.d5.loss_mask: 0.2889  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.1712  decode.d6.loss_mask: 0.2894  decode.d6.loss_dice: 0.2566  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 0.2850  decode.d7.loss_dice: 0.2517  decode.d8.loss_cls: 0.1734  decode.d8.loss_mask: 0.2873  decode.d8.loss_dice: 0.2379
09/30 18:39:50 - mmengine - INFO - Iter(train) [ 79350/320000]  base_lr: 7.7377e-05 lr: 7.7377e-06  eta: 1 day, 5:06:40  time: 0.4394  data_time: 0.0097  memory: 5129  grad_norm: 30.7438  loss: 5.1847  decode.loss_cls: 0.0558  decode.loss_mask: 0.1835  decode.loss_dice: 0.1713  decode.d0.loss_cls: 0.8236  decode.d0.loss_mask: 0.1838  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 0.1872  decode.d1.loss_dice: 0.1766  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.1833  decode.d2.loss_dice: 0.1823  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 0.1844  decode.d3.loss_dice: 0.1735  decode.d4.loss_cls: 0.1043  decode.d4.loss_mask: 0.1866  decode.d4.loss_dice: 0.1739  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.1840  decode.d5.loss_dice: 0.1696  decode.d6.loss_cls: 0.0796  decode.d6.loss_mask: 0.1859  decode.d6.loss_dice: 0.1741  decode.d7.loss_cls: 0.1127  decode.d7.loss_mask: 0.1842  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.1841  decode.d8.loss_dice: 0.1733
09/30 18:40:12 - mmengine - INFO - Iter(train) [ 79400/320000]  base_lr: 7.7363e-05 lr: 7.7363e-06  eta: 1 day, 5:06:18  time: 0.4390  data_time: 0.0097  memory: 5120  grad_norm: 154.1995  loss: 8.3770  decode.loss_cls: 0.0997  decode.loss_mask: 0.4352  decode.loss_dice: 0.1972  decode.d0.loss_cls: 1.0955  decode.d0.loss_mask: 0.3373  decode.d0.loss_dice: 0.2181  decode.d1.loss_cls: 0.1797  decode.d1.loss_mask: 0.3646  decode.d1.loss_dice: 0.2338  decode.d2.loss_cls: 0.1973  decode.d2.loss_mask: 0.3523  decode.d2.loss_dice: 0.2216  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 0.4563  decode.d3.loss_dice: 0.1932  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.4221  decode.d4.loss_dice: 0.1883  decode.d5.loss_cls: 0.1797  decode.d5.loss_mask: 0.3365  decode.d5.loss_dice: 0.2425  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.4527  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.1514  decode.d7.loss_mask: 0.3736  decode.d7.loss_dice: 0.2128  decode.d8.loss_cls: 0.2036  decode.d8.loss_mask: 0.3524  decode.d8.loss_dice: 0.2241
09/30 18:40:34 - mmengine - INFO - Iter(train) [ 79450/320000]  base_lr: 7.7348e-05 lr: 7.7348e-06  eta: 1 day, 5:05:57  time: 0.4390  data_time: 0.0099  memory: 5129  grad_norm: 31.6736  loss: 5.0979  decode.loss_cls: 0.0058  decode.loss_mask: 0.2542  decode.loss_dice: 0.1791  decode.d0.loss_cls: 0.7120  decode.d0.loss_mask: 0.2549  decode.d0.loss_dice: 0.1817  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.1846  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.1830  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.2495  decode.d3.loss_dice: 0.1815  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.1806  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.1803  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.2506  decode.d6.loss_dice: 0.1810  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.1815  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.1772
09/30 18:40:56 - mmengine - INFO - Iter(train) [ 79500/320000]  base_lr: 7.7334e-05 lr: 7.7334e-06  eta: 1 day, 5:05:36  time: 0.4384  data_time: 0.0100  memory: 5129  grad_norm: 51.9487  loss: 6.1871  decode.loss_cls: 0.0096  decode.loss_mask: 0.3317  decode.loss_dice: 0.2073  decode.d0.loss_cls: 0.7377  decode.d0.loss_mask: 0.3333  decode.d0.loss_dice: 0.1989  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.3384  decode.d1.loss_dice: 0.2054  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.3305  decode.d2.loss_dice: 0.2071  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.3338  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.3303  decode.d4.loss_dice: 0.2067  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.3230  decode.d5.loss_dice: 0.2077  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.3301  decode.d6.loss_dice: 0.2098  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.3321  decode.d7.loss_dice: 0.2094  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.3296  decode.d8.loss_dice: 0.2070
09/30 18:41:18 - mmengine - INFO - Iter(train) [ 79550/320000]  base_lr: 7.7319e-05 lr: 7.7319e-06  eta: 1 day, 5:05:15  time: 0.4394  data_time: 0.0098  memory: 5129  grad_norm: 34.4889  loss: 5.9410  decode.loss_cls: 0.0199  decode.loss_mask: 0.2938  decode.loss_dice: 0.2250  decode.d0.loss_cls: 0.8171  decode.d0.loss_mask: 0.2194  decode.d0.loss_dice: 0.2071  decode.d1.loss_cls: 0.1517  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.1848  decode.d2.loss_cls: 0.1232  decode.d2.loss_mask: 0.2174  decode.d2.loss_dice: 0.1951  decode.d3.loss_cls: 0.1138  decode.d3.loss_mask: 0.2118  decode.d3.loss_dice: 0.1894  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.2105  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.1081  decode.d5.loss_mask: 0.2132  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.0923  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.2018  decode.d7.loss_cls: 0.0931  decode.d7.loss_mask: 0.2142  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.1144  decode.d8.loss_mask: 0.2175  decode.d8.loss_dice: 0.2062
09/30 18:41:40 - mmengine - INFO - Iter(train) [ 79600/320000]  base_lr: 7.7305e-05 lr: 7.7305e-06  eta: 1 day, 5:04:54  time: 0.4381  data_time: 0.0094  memory: 5129  grad_norm: 38.5930  loss: 5.1766  decode.loss_cls: 0.0266  decode.loss_mask: 0.2273  decode.loss_dice: 0.1860  decode.d0.loss_cls: 0.8129  decode.d0.loss_mask: 0.2316  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.2292  decode.d1.loss_dice: 0.1858  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.2268  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.1753  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.2268  decode.d4.loss_dice: 0.1767  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.1818  decode.d7.loss_cls: 0.0221  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.1821  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.1811
09/30 18:42:02 - mmengine - INFO - Iter(train) [ 79650/320000]  base_lr: 7.7290e-05 lr: 7.7290e-06  eta: 1 day, 5:04:32  time: 0.4386  data_time: 0.0096  memory: 5120  grad_norm: 92.3628  loss: 7.4969  decode.loss_cls: 0.2046  decode.loss_mask: 0.2181  decode.loss_dice: 0.2363  decode.d0.loss_cls: 0.9133  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.1794  decode.d1.loss_mask: 0.2173  decode.d1.loss_dice: 0.2412  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.2465  decode.d3.loss_cls: 0.2420  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.2475  decode.d4.loss_cls: 0.2304  decode.d4.loss_mask: 0.2146  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.2503  decode.d5.loss_mask: 0.2194  decode.d5.loss_dice: 0.2350  decode.d6.loss_cls: 0.2302  decode.d6.loss_mask: 0.2168  decode.d6.loss_dice: 0.2272  decode.d7.loss_cls: 0.2252  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.1580  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.2628
09/30 18:42:24 - mmengine - INFO - Iter(train) [ 79700/320000]  base_lr: 7.7276e-05 lr: 7.7276e-06  eta: 1 day, 5:04:11  time: 0.4388  data_time: 0.0098  memory: 5120  grad_norm: 27.3294  loss: 5.4686  decode.loss_cls: 0.0258  decode.loss_mask: 0.2551  decode.loss_dice: 0.1844  decode.d0.loss_cls: 0.8594  decode.d0.loss_mask: 0.2529  decode.d0.loss_dice: 0.1753  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.1838  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 0.2580  decode.d2.loss_dice: 0.1863  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.2604  decode.d3.loss_dice: 0.1868  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.2574  decode.d4.loss_dice: 0.1841  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.2578  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.0301  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.1818
09/30 18:42:46 - mmengine - INFO - Iter(train) [ 79750/320000]  base_lr: 7.7262e-05 lr: 7.7262e-06  eta: 1 day, 5:03:50  time: 0.4383  data_time: 0.0095  memory: 5129  grad_norm: 36.8404  loss: 5.5848  decode.loss_cls: 0.0046  decode.loss_mask: 0.2507  decode.loss_dice: 0.1968  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 0.2578  decode.d0.loss_dice: 0.1970  decode.d1.loss_cls: 0.1429  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.1961  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.2543  decode.d2.loss_dice: 0.1984  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.2040  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2013  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2599  decode.d5.loss_dice: 0.2041  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.2514  decode.d6.loss_dice: 0.1970  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.2546  decode.d7.loss_dice: 0.2033  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2554  decode.d8.loss_dice: 0.2008
09/30 18:43:08 - mmengine - INFO - Iter(train) [ 79800/320000]  base_lr: 7.7247e-05 lr: 7.7247e-06  eta: 1 day, 5:03:28  time: 0.4382  data_time: 0.0095  memory: 5145  grad_norm: 118.6940  loss: 4.8759  decode.loss_cls: 0.0284  decode.loss_mask: 0.2066  decode.loss_dice: 0.1523  decode.d0.loss_cls: 0.8117  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.1500  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.2076  decode.d1.loss_dice: 0.1513  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.1578  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1534  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.2063  decode.d4.loss_dice: 0.1550  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.2070  decode.d5.loss_dice: 0.1529  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.2078  decode.d6.loss_dice: 0.1537  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.1547  decode.d8.loss_cls: 0.0318  decode.d8.loss_mask: 0.2084  decode.d8.loss_dice: 0.1495
09/30 18:43:30 - mmengine - INFO - Iter(train) [ 79850/320000]  base_lr: 7.7233e-05 lr: 7.7233e-06  eta: 1 day, 5:03:07  time: 0.4381  data_time: 0.0096  memory: 5120  grad_norm: 192.9185  loss: 10.2256  decode.loss_cls: 0.3029  decode.loss_mask: 0.3278  decode.loss_dice: 0.2979  decode.d0.loss_cls: 1.0173  decode.d0.loss_mask: 0.3300  decode.d0.loss_dice: 0.2872  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 0.5153  decode.d1.loss_dice: 0.3161  decode.d2.loss_cls: 0.3545  decode.d2.loss_mask: 0.3847  decode.d2.loss_dice: 0.3301  decode.d3.loss_cls: 0.3185  decode.d3.loss_mask: 0.3137  decode.d3.loss_dice: 0.3323  decode.d4.loss_cls: 0.3159  decode.d4.loss_mask: 0.3285  decode.d4.loss_dice: 0.3163  decode.d5.loss_cls: 0.3404  decode.d5.loss_mask: 0.3113  decode.d5.loss_dice: 0.3024  decode.d6.loss_cls: 0.3007  decode.d6.loss_mask: 0.3191  decode.d6.loss_dice: 0.2927  decode.d7.loss_cls: 0.2952  decode.d7.loss_mask: 0.2970  decode.d7.loss_dice: 0.2908  decode.d8.loss_cls: 0.2576  decode.d8.loss_mask: 0.3574  decode.d8.loss_dice: 0.2924
09/30 18:43:51 - mmengine - INFO - Iter(train) [ 79900/320000]  base_lr: 7.7218e-05 lr: 7.7218e-06  eta: 1 day, 5:02:46  time: 0.4386  data_time: 0.0095  memory: 5120  grad_norm: 25.0075  loss: 4.6445  decode.loss_cls: 0.0069  decode.loss_mask: 0.2007  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.7817  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.1869  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.1784  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.2004  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.1808  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.1989  decode.d4.loss_dice: 0.1725  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.2026  decode.d5.loss_dice: 0.1859  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.1774  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.1989  decode.d7.loss_dice: 0.1765  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.1790
09/30 18:44:13 - mmengine - INFO - Iter(train) [ 79950/320000]  base_lr: 7.7204e-05 lr: 7.7204e-06  eta: 1 day, 5:02:24  time: 0.4379  data_time: 0.0095  memory: 5104  grad_norm: 21.0663  loss: 5.2173  decode.loss_cls: 0.0759  decode.loss_mask: 0.1844  decode.loss_dice: 0.1680  decode.d0.loss_cls: 0.8700  decode.d0.loss_mask: 0.1871  decode.d0.loss_dice: 0.1631  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.1842  decode.d1.loss_dice: 0.1712  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 0.1820  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.1686  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 0.1853  decode.d4.loss_dice: 0.1700  decode.d5.loss_cls: 0.0949  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.1688  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.1856  decode.d6.loss_dice: 0.1718  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.1851  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.1836  decode.d8.loss_dice: 0.1696
09/30 18:44:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:44:35 - mmengine - INFO - Iter(train) [ 80000/320000]  base_lr: 7.7189e-05 lr: 7.7189e-06  eta: 1 day, 5:02:03  time: 0.4388  data_time: 0.0098  memory: 5146  grad_norm: 57.9137  loss: 6.5556  decode.loss_cls: 0.1787  decode.loss_mask: 0.2386  decode.loss_dice: 0.1845  decode.d0.loss_cls: 0.9803  decode.d0.loss_mask: 0.2426  decode.d0.loss_dice: 0.1955  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.2361  decode.d1.loss_dice: 0.1899  decode.d2.loss_cls: 0.1226  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.1941  decode.d3.loss_cls: 0.1508  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.1824  decode.d4.loss_cls: 0.1232  decode.d4.loss_mask: 0.2430  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.1739  decode.d5.loss_mask: 0.2408  decode.d5.loss_dice: 0.1841  decode.d6.loss_cls: 0.1207  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.1976  decode.d7.loss_cls: 0.1165  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.1549  decode.d8.loss_mask: 0.2384  decode.d8.loss_dice: 0.1917
09/30 18:44:35 - mmengine - INFO - Saving checkpoint at 80000 iterations
09/30 18:44:46 - mmengine - INFO - Iter(val) [ 50/206]    eta: 0:00:25  time: 0.1775  data_time: 0.0045  memory: 2997  
09/30 18:44:54 - mmengine - INFO - Iter(val) [100/206]    eta: 0:00:18  time: 0.1772  data_time: 0.0045  memory: 2997  
09/30 18:45:03 - mmengine - INFO - Iter(val) [150/206]    eta: 0:00:09  time: 0.1774  data_time: 0.0044  memory: 2997  
09/30 18:45:12 - mmengine - INFO - Iter(val) [200/206]    eta: 0:00:01  time: 0.1758  data_time: 0.0040  memory: 2997  
09/30 18:45:13 - mmengine - INFO - per class results:
09/30 18:45:13 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|      background     | 98.63 | 99.39 |
|   beetroot-poriyal  | 97.98 | 99.11 |
|        bhindi       | 71.98 | 98.35 |
| capsicum-green-peas | 95.98 | 98.79 |
|     dosakay-dal     | 90.78 | 91.94 |
|    dosakaya-curry   | 95.38 | 98.01 |
|    jaipuri-sabji    | 97.61 | 98.91 |
|  ladiesfinger-curry | 97.59 | 99.29 |
|    lobiya-masala    | 95.84 | 99.17 |
|        pongal       | 33.52 | 33.75 |
|    pumpkin-gravy    | 98.23 | 98.94 |
|     pumpkin-dry     | 94.24 | 95.15 |
|     rajma-masala    |  97.9 | 98.49 |
|      tomato-dal     | 93.22 | 97.91 |
|     turai-moong     | 91.92 | 98.69 |
|     turai-tomato    | 84.17 | 84.96 |
|    beerakay-curry   | 97.28 | 98.29 |
|   cabbage-poriyal   | 97.01 | 98.88 |
|    capsicum-gravy   | 97.65 | 98.54 |
|     chana-masala    | 96.44 | 98.46 |
|      chow-chow      | 97.07 | 98.55 |
|       chutney       | 72.64 | 72.96 |
|      curd-rice      | 89.78 | 92.41 |
|         dal         | 96.72 | 97.38 |
|      dal-tadka      | 97.17 | 98.18 |
|        daliya       | 97.64 | 98.41 |
|     daliya-upma     | 93.18 | 97.97 |
|     donda-curry     | 96.87 | 97.26 |
|    dosakaya-gravy   | 95.87 | 97.44 |
|      egg-white      |  90.3 | 95.65 |
|         idly        | 86.54 |  87.5 |
|       khichdi       | 92.73 | 98.32 |
| ladies-finger-gravy | 97.59 | 98.56 |
|      methi-dal      | 97.48 | 98.61 |
|  mixed-veg-poriyal  |  95.1 | 97.23 |
|   palak-soya-curry  | 96.82 | 98.33 |
|     paneer-gravy    | 97.18 | 97.87 |
|         poha        | 48.39 | 48.58 |
|    pumpkin-masala   | 92.79 | 98.36 |
|    raw-banana-dry   | 96.76 | 98.17 |
|         rice        |  96.4 | 97.77 |
|         roti        | 95.68 | 98.75 |
|        sambar       | 77.94 | 90.42 |
|    snakegourd-dry   |  0.0  |  0.0  |
|   snakeguard-curry  | 97.48 | 98.13 |
|      soya-gravy     | 92.23 |  98.7 |
|   thotakura-pappu   | 96.83 | 98.14 |
|         upma        | 94.59 |  97.8 |
|       uttapam       |  0.0  |  0.0  |
+---------------------+-------+-------+
09/30 18:45:13 - mmengine - INFO - Iter(val) [206/206]    aAcc: 98.7300  mIoU: 87.8200  mAcc: 90.4600  data_time: 0.0047  time: 0.1735
09/30 18:45:35 - mmengine - INFO - Iter(train) [ 80050/320000]  base_lr: 7.7175e-05 lr: 7.7175e-06  eta: 1 day, 5:01:42  time: 0.4364  data_time: 0.0094  memory: 5129  grad_norm: 30.8782  loss: 5.5703  decode.loss_cls: 0.0430  decode.loss_mask: 0.2553  decode.loss_dice: 0.1764  decode.d0.loss_cls: 0.7135  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.1757  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.1705  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.1721  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.2579  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.2568  decode.d6.loss_dice: 0.1759  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2004  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.2583  decode.d8.loss_dice: 0.1736
09/30 18:45:57 - mmengine - INFO - Iter(train) [ 80100/320000]  base_lr: 7.7160e-05 lr: 7.7160e-06  eta: 1 day, 5:01:21  time: 0.4382  data_time: 0.0096  memory: 5129  grad_norm: 55.8214  loss: 5.5375  decode.loss_cls: 0.0053  decode.loss_mask: 0.2647  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.7924  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.2104  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.2648  decode.d1.loss_dice: 0.2038  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.2612  decode.d2.loss_dice: 0.2010  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.2030  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2015  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.2617  decode.d5.loss_dice: 0.2055  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.2638  decode.d6.loss_dice: 0.2006  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.2615  decode.d7.loss_dice: 0.2004  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2634  decode.d8.loss_dice: 0.2011
09/30 18:46:19 - mmengine - INFO - Iter(train) [ 80150/320000]  base_lr: 7.7146e-05 lr: 7.7146e-06  eta: 1 day, 5:00:59  time: 0.4398  data_time: 0.0097  memory: 5129  grad_norm: 99.2570  loss: 10.7177  decode.loss_cls: 0.3505  decode.loss_mask: 0.4077  decode.loss_dice: 0.3990  decode.d0.loss_cls: 0.9610  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.3283  decode.d1.loss_cls: 0.4383  decode.d1.loss_mask: 0.3105  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.2852  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.3238  decode.d3.loss_cls: 0.3799  decode.d3.loss_mask: 0.3172  decode.d3.loss_dice: 0.3118  decode.d4.loss_cls: 0.2755  decode.d4.loss_mask: 0.3187  decode.d4.loss_dice: 0.3451  decode.d5.loss_cls: 0.2931  decode.d5.loss_mask: 0.2980  decode.d5.loss_dice: 0.3344  decode.d6.loss_cls: 0.2970  decode.d6.loss_mask: 0.3123  decode.d6.loss_dice: 0.3349  decode.d7.loss_cls: 0.3183  decode.d7.loss_mask: 0.3180  decode.d7.loss_dice: 0.3319  decode.d8.loss_cls: 0.3626  decode.d8.loss_mask: 0.4054  decode.d8.loss_dice: 0.3684
09/30 18:46:41 - mmengine - INFO - Iter(train) [ 80200/320000]  base_lr: 7.7131e-05 lr: 7.7131e-06  eta: 1 day, 5:00:38  time: 0.4375  data_time: 0.0094  memory: 5145  grad_norm: 30.3557  loss: 5.9546  decode.loss_cls: 0.0056  decode.loss_mask: 0.2687  decode.loss_dice: 0.2256  decode.d0.loss_cls: 0.9683  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2097  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.1133  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.1947  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.2133  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.1923  decode.d4.loss_dice: 0.1860  decode.d5.loss_cls: 0.1363  decode.d5.loss_mask: 0.1959  decode.d5.loss_dice: 0.1981  decode.d6.loss_cls: 0.1372  decode.d6.loss_mask: 0.1997  decode.d6.loss_dice: 0.1941  decode.d7.loss_cls: 0.1366  decode.d7.loss_mask: 0.1916  decode.d7.loss_dice: 0.2039  decode.d8.loss_cls: 0.1271  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.2092
09/30 18:47:03 - mmengine - INFO - Iter(train) [ 80250/320000]  base_lr: 7.7117e-05 lr: 7.7117e-06  eta: 1 day, 5:00:17  time: 0.4398  data_time: 0.0098  memory: 5120  grad_norm: 30.9086  loss: 4.6116  decode.loss_cls: 0.0040  decode.loss_mask: 0.2310  decode.loss_dice: 0.1597  decode.d0.loss_cls: 0.6467  decode.d0.loss_mask: 0.2345  decode.d0.loss_dice: 0.1672  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.1588  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.1580  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.1586  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.1594  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.1602  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1609  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2316  decode.d7.loss_dice: 0.1597  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.1592
09/30 18:47:25 - mmengine - INFO - Iter(train) [ 80300/320000]  base_lr: 7.7102e-05 lr: 7.7102e-06  eta: 1 day, 4:59:56  time: 0.4397  data_time: 0.0098  memory: 5119  grad_norm: 69.5007  loss: 6.4251  decode.loss_cls: 0.0866  decode.loss_mask: 0.2505  decode.loss_dice: 0.2238  decode.d0.loss_cls: 0.7725  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.2371  decode.d1.loss_cls: 0.1171  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.2305  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.2541  decode.d2.loss_dice: 0.2312  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.1977  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.2539  decode.d4.loss_dice: 0.2121  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 0.2551  decode.d5.loss_dice: 0.2279  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.2244  decode.d7.loss_cls: 0.1060  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.2250  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.2152
09/30 18:47:47 - mmengine - INFO - Iter(train) [ 80350/320000]  base_lr: 7.7088e-05 lr: 7.7088e-06  eta: 1 day, 4:59:34  time: 0.4384  data_time: 0.0094  memory: 5129  grad_norm: 28.8351  loss: 5.1393  decode.loss_cls: 0.0708  decode.loss_mask: 0.1968  decode.loss_dice: 0.1616  decode.d0.loss_cls: 0.8757  decode.d0.loss_mask: 0.1944  decode.d0.loss_dice: 0.1572  decode.d1.loss_cls: 0.0981  decode.d1.loss_mask: 0.1974  decode.d1.loss_dice: 0.1626  decode.d2.loss_cls: 0.0906  decode.d2.loss_mask: 0.1976  decode.d2.loss_dice: 0.1719  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.1983  decode.d3.loss_dice: 0.1792  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.1970  decode.d4.loss_dice: 0.1886  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.1963  decode.d5.loss_dice: 0.1655  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.1979  decode.d6.loss_dice: 0.1773  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.1962  decode.d7.loss_dice: 0.1635  decode.d8.loss_cls: 0.0509  decode.d8.loss_mask: 0.1977  decode.d8.loss_dice: 0.1694
09/30 18:48:09 - mmengine - INFO - Iter(train) [ 80400/320000]  base_lr: 7.7073e-05 lr: 7.7073e-06  eta: 1 day, 4:59:13  time: 0.4396  data_time: 0.0099  memory: 5145  grad_norm: 25.5762  loss: 5.2360  decode.loss_cls: 0.0378  decode.loss_mask: 0.2356  decode.loss_dice: 0.1760  decode.d0.loss_cls: 0.8135  decode.d0.loss_mask: 0.2387  decode.d0.loss_dice: 0.1777  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.2359  decode.d1.loss_dice: 0.1786  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.1758  decode.d3.loss_cls: 0.0310  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.0327  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.1767  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.2366  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.1743  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.1742  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.1761
09/30 18:48:31 - mmengine - INFO - Iter(train) [ 80450/320000]  base_lr: 7.7059e-05 lr: 7.7059e-06  eta: 1 day, 4:58:52  time: 0.4391  data_time: 0.0097  memory: 5159  grad_norm: 47.1260  loss: 6.0776  decode.loss_cls: 0.1159  decode.loss_mask: 0.2067  decode.loss_dice: 0.2391  decode.d0.loss_cls: 0.9370  decode.d0.loss_mask: 0.2101  decode.d0.loss_dice: 0.2171  decode.d1.loss_cls: 0.1403  decode.d1.loss_mask: 0.2059  decode.d1.loss_dice: 0.2248  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.2117  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.2051  decode.d5.loss_dice: 0.2093  decode.d6.loss_cls: 0.1213  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.2281  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.2344  decode.d8.loss_cls: 0.1118  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.2360
09/30 18:48:53 - mmengine - INFO - Iter(train) [ 80500/320000]  base_lr: 7.7044e-05 lr: 7.7044e-06  eta: 1 day, 4:58:31  time: 0.4392  data_time: 0.0099  memory: 5130  grad_norm: 114.9238  loss: 8.4006  decode.loss_cls: 0.1273  decode.loss_mask: 0.3313  decode.loss_dice: 0.3164  decode.d0.loss_cls: 0.9332  decode.d0.loss_mask: 0.3229  decode.d0.loss_dice: 0.3114  decode.d1.loss_cls: 0.2291  decode.d1.loss_mask: 0.3107  decode.d1.loss_dice: 0.2936  decode.d2.loss_cls: 0.1687  decode.d2.loss_mask: 0.3193  decode.d2.loss_dice: 0.2512  decode.d3.loss_cls: 0.1923  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.2627  decode.d4.loss_cls: 0.1177  decode.d4.loss_mask: 0.3226  decode.d4.loss_dice: 0.2949  decode.d5.loss_cls: 0.1845  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.2258  decode.d6.loss_cls: 0.1242  decode.d6.loss_mask: 0.3141  decode.d6.loss_dice: 0.2707  decode.d7.loss_cls: 0.1179  decode.d7.loss_mask: 0.3253  decode.d7.loss_dice: 0.3040  decode.d8.loss_cls: 0.1652  decode.d8.loss_mask: 0.3354  decode.d8.loss_dice: 0.3088
09/30 18:49:15 - mmengine - INFO - Iter(train) [ 80550/320000]  base_lr: 7.7030e-05 lr: 7.7030e-06  eta: 1 day, 4:58:10  time: 0.4396  data_time: 0.0100  memory: 5129  grad_norm: 33.4922  loss: 4.7065  decode.loss_cls: 0.0089  decode.loss_mask: 0.1913  decode.loss_dice: 0.1868  decode.d0.loss_cls: 0.7712  decode.d0.loss_mask: 0.1915  decode.d0.loss_dice: 0.1938  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.1912  decode.d1.loss_dice: 0.1957  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.1933  decode.d2.loss_dice: 0.1949  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.1916  decode.d3.loss_dice: 0.2030  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.1903  decode.d4.loss_dice: 0.1932  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.1901  decode.d5.loss_dice: 0.1968  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.1909  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.1906  decode.d8.loss_dice: 0.1987
09/30 18:49:37 - mmengine - INFO - Iter(train) [ 80600/320000]  base_lr: 7.7015e-05 lr: 7.7015e-06  eta: 1 day, 4:57:49  time: 0.4394  data_time: 0.0100  memory: 5129  grad_norm: 28.2330  loss: 5.2947  decode.loss_cls: 0.0388  decode.loss_mask: 0.2284  decode.loss_dice: 0.1920  decode.d0.loss_cls: 0.7061  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.1891  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.2306  decode.d2.loss_dice: 0.1907  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.1872  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.1869  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.2299  decode.d6.loss_dice: 0.1890  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.1906
09/30 18:49:59 - mmengine - INFO - Iter(train) [ 80650/320000]  base_lr: 7.7001e-05 lr: 7.7001e-06  eta: 1 day, 4:57:27  time: 0.4404  data_time: 0.0099  memory: 5145  grad_norm: 65.0278  loss: 6.6250  decode.loss_cls: 0.0361  decode.loss_mask: 0.2816  decode.loss_dice: 0.2310  decode.d0.loss_cls: 0.9183  decode.d0.loss_mask: 0.2873  decode.d0.loss_dice: 0.2365  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.2825  decode.d1.loss_dice: 0.2302  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.2277  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.2330  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.2820  decode.d4.loss_dice: 0.2279  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.2813  decode.d5.loss_dice: 0.2335  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.2260  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.2810  decode.d7.loss_dice: 0.2294  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.2314
09/30 18:50:21 - mmengine - INFO - Iter(train) [ 80700/320000]  base_lr: 7.6987e-05 lr: 7.6987e-06  eta: 1 day, 4:57:07  time: 0.4387  data_time: 0.0096  memory: 5145  grad_norm: 40.7561  loss: 5.5480  decode.loss_cls: 0.0303  decode.loss_mask: 0.2414  decode.loss_dice: 0.1910  decode.d0.loss_cls: 0.8882  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.1839  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.2424  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.1890  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.2438  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.2454  decode.d4.loss_dice: 0.1863  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.1895  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.2398  decode.d6.loss_dice: 0.1930  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.2414  decode.d7.loss_dice: 0.1877  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.1878
09/30 18:50:43 - mmengine - INFO - Iter(train) [ 80750/320000]  base_lr: 7.6972e-05 lr: 7.6972e-06  eta: 1 day, 4:56:45  time: 0.4382  data_time: 0.0097  memory: 5120  grad_norm: 75.7703  loss: 6.3816  decode.loss_cls: 0.1607  decode.loss_mask: 0.1885  decode.loss_dice: 0.2085  decode.d0.loss_cls: 0.7472  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.1789  decode.d1.loss_cls: 0.2351  decode.d1.loss_mask: 0.1911  decode.d1.loss_dice: 0.1858  decode.d2.loss_cls: 0.2469  decode.d2.loss_mask: 0.1887  decode.d2.loss_dice: 0.1930  decode.d3.loss_cls: 0.1733  decode.d3.loss_mask: 0.1917  decode.d3.loss_dice: 0.1685  decode.d4.loss_cls: 0.1950  decode.d4.loss_mask: 0.1876  decode.d4.loss_dice: 0.1994  decode.d5.loss_cls: 0.1534  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.1702  decode.d6.loss_cls: 0.2680  decode.d6.loss_mask: 0.1927  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.2064  decode.d7.loss_mask: 0.1925  decode.d7.loss_dice: 0.1815  decode.d8.loss_cls: 0.2283  decode.d8.loss_mask: 0.1921  decode.d8.loss_dice: 0.1815
09/30 18:51:05 - mmengine - INFO - Iter(train) [ 80800/320000]  base_lr: 7.6958e-05 lr: 7.6958e-06  eta: 1 day, 4:56:24  time: 0.4393  data_time: 0.0100  memory: 5129  grad_norm: 31.3020  loss: 5.5597  decode.loss_cls: 0.0437  decode.loss_mask: 0.2489  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.7755  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2096  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.2510  decode.d1.loss_dice: 0.1724  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.2493  decode.d2.loss_dice: 0.1888  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.1744  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.1759  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.2475  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.2495  decode.d8.loss_dice: 0.1790
09/30 18:51:27 - mmengine - INFO - Iter(train) [ 80850/320000]  base_lr: 7.6943e-05 lr: 7.6943e-06  eta: 1 day, 4:56:03  time: 0.4396  data_time: 0.0100  memory: 5129  grad_norm: 49.6406  loss: 5.1214  decode.loss_cls: 0.0296  decode.loss_mask: 0.2181  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.7878  decode.d0.loss_mask: 0.2150  decode.d0.loss_dice: 0.1757  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.2155  decode.d1.loss_dice: 0.1750  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.2143  decode.d2.loss_dice: 0.1753  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.1709  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2154  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.2136  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.1711  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.1735
09/30 18:51:49 - mmengine - INFO - Iter(train) [ 80900/320000]  base_lr: 7.6929e-05 lr: 7.6929e-06  eta: 1 day, 4:55:42  time: 0.4399  data_time: 0.0097  memory: 5129  grad_norm: 40.5863  loss: 5.3843  decode.loss_cls: 0.0701  decode.loss_mask: 0.1932  decode.loss_dice: 0.2124  decode.d0.loss_cls: 0.8237  decode.d0.loss_mask: 0.1961  decode.d0.loss_dice: 0.2073  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.1926  decode.d1.loss_dice: 0.2082  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.1923  decode.d2.loss_dice: 0.2027  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.1946  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.1926  decode.d4.loss_dice: 0.2127  decode.d5.loss_cls: 0.1183  decode.d5.loss_mask: 0.1941  decode.d5.loss_dice: 0.1998  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.1923  decode.d6.loss_dice: 0.1800  decode.d7.loss_cls: 0.0487  decode.d7.loss_mask: 0.1930  decode.d7.loss_dice: 0.1983  decode.d8.loss_cls: 0.1195  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.1979
09/30 18:52:11 - mmengine - INFO - Iter(train) [ 80950/320000]  base_lr: 7.6914e-05 lr: 7.6914e-06  eta: 1 day, 4:55:21  time: 0.4391  data_time: 0.0097  memory: 5145  grad_norm: 67.4696  loss: 8.1535  decode.loss_cls: 0.1916  decode.loss_mask: 0.2150  decode.loss_dice: 0.3224  decode.d0.loss_cls: 1.0463  decode.d0.loss_mask: 0.2250  decode.d0.loss_dice: 0.3487  decode.d1.loss_cls: 0.1602  decode.d1.loss_mask: 0.2178  decode.d1.loss_dice: 0.3281  decode.d2.loss_cls: 0.1823  decode.d2.loss_mask: 0.2129  decode.d2.loss_dice: 0.3187  decode.d3.loss_cls: 0.1722  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.3169  decode.d4.loss_cls: 0.1788  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.3188  decode.d5.loss_cls: 0.2139  decode.d5.loss_mask: 0.2157  decode.d5.loss_dice: 0.3319  decode.d6.loss_cls: 0.2298  decode.d6.loss_mask: 0.2165  decode.d6.loss_dice: 0.3395  decode.d7.loss_cls: 0.1795  decode.d7.loss_mask: 0.2152  decode.d7.loss_dice: 0.3238  decode.d8.loss_cls: 0.1621  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.3317
09/30 18:52:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:52:33 - mmengine - INFO - Iter(train) [ 81000/320000]  base_lr: 7.6900e-05 lr: 7.6900e-06  eta: 1 day, 4:55:00  time: 0.4395  data_time: 0.0100  memory: 5129  grad_norm: 59.5268  loss: 5.3950  decode.loss_cls: 0.0676  decode.loss_mask: 0.2099  decode.loss_dice: 0.1880  decode.d0.loss_cls: 0.7360  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0788  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1839  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.2096  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.2086  decode.d4.loss_dice: 0.1818  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.2095  decode.d5.loss_dice: 0.1831  decode.d6.loss_cls: 0.0760  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.1789  decode.d7.loss_cls: 0.0910  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.2065  decode.d8.loss_dice: 0.1859
09/30 18:52:55 - mmengine - INFO - Iter(train) [ 81050/320000]  base_lr: 7.6885e-05 lr: 7.6885e-06  eta: 1 day, 4:54:39  time: 0.4397  data_time: 0.0097  memory: 5129  grad_norm: 61.0250  loss: 5.6249  decode.loss_cls: 0.1158  decode.loss_mask: 0.1622  decode.loss_dice: 0.1400  decode.d0.loss_cls: 0.9801  decode.d0.loss_mask: 0.1650  decode.d0.loss_dice: 0.1404  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 0.1656  decode.d1.loss_dice: 0.1438  decode.d2.loss_cls: 0.1846  decode.d2.loss_mask: 0.2362  decode.d2.loss_dice: 0.1715  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.1846  decode.d3.loss_dice: 0.1596  decode.d4.loss_cls: 0.1675  decode.d4.loss_mask: 0.1723  decode.d4.loss_dice: 0.1528  decode.d5.loss_cls: 0.1587  decode.d5.loss_mask: 0.1636  decode.d5.loss_dice: 0.1412  decode.d6.loss_cls: 0.1564  decode.d6.loss_mask: 0.1648  decode.d6.loss_dice: 0.1388  decode.d7.loss_cls: 0.1707  decode.d7.loss_mask: 0.1684  decode.d7.loss_dice: 0.1471  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.1879  decode.d8.loss_dice: 0.1659
09/30 18:53:17 - mmengine - INFO - Iter(train) [ 81100/320000]  base_lr: 7.6871e-05 lr: 7.6871e-06  eta: 1 day, 4:54:17  time: 0.4392  data_time: 0.0098  memory: 5129  grad_norm: 69.3624  loss: 5.3486  decode.loss_cls: 0.0307  decode.loss_mask: 0.2414  decode.loss_dice: 0.2004  decode.d0.loss_cls: 0.7164  decode.d0.loss_mask: 0.2497  decode.d0.loss_dice: 0.2038  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.2429  decode.d1.loss_dice: 0.1891  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.2469  decode.d2.loss_dice: 0.1990  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.2416  decode.d3.loss_dice: 0.1949  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.1927  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.1860  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.1988  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.2413  decode.d8.loss_dice: 0.1969
09/30 18:53:39 - mmengine - INFO - Iter(train) [ 81150/320000]  base_lr: 7.6856e-05 lr: 7.6856e-06  eta: 1 day, 4:53:56  time: 0.4393  data_time: 0.0099  memory: 5129  grad_norm: 25.3357  loss: 5.4474  decode.loss_cls: 0.0046  decode.loss_mask: 0.2709  decode.loss_dice: 0.1860  decode.d0.loss_cls: 0.8166  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.1778  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.2749  decode.d1.loss_dice: 0.1797  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.2790  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.1791  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2754  decode.d4.loss_dice: 0.1795  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2760  decode.d5.loss_dice: 0.1813  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.2773  decode.d6.loss_dice: 0.1830  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.2742  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.2749  decode.d8.loss_dice: 0.1841
09/30 18:54:01 - mmengine - INFO - Iter(train) [ 81200/320000]  base_lr: 7.6842e-05 lr: 7.6842e-06  eta: 1 day, 4:53:35  time: 0.4397  data_time: 0.0100  memory: 5129  grad_norm: 36.9792  loss: 5.5484  decode.loss_cls: 0.0770  decode.loss_mask: 0.2293  decode.loss_dice: 0.1881  decode.d0.loss_cls: 0.8504  decode.d0.loss_mask: 0.2324  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.1858  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.2273  decode.d3.loss_dice: 0.1794  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.1793  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.2248  decode.d5.loss_dice: 0.1813  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.2286  decode.d6.loss_dice: 0.1769  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.1844  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.2264  decode.d8.loss_dice: 0.1814
09/30 18:54:23 - mmengine - INFO - Iter(train) [ 81250/320000]  base_lr: 7.6827e-05 lr: 7.6827e-06  eta: 1 day, 4:53:14  time: 0.4396  data_time: 0.0099  memory: 5129  grad_norm: 35.0127  loss: 5.6613  decode.loss_cls: 0.0806  decode.loss_mask: 0.2006  decode.loss_dice: 0.2228  decode.d0.loss_cls: 0.8523  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.1964  decode.d1.loss_dice: 0.2130  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.1984  decode.d2.loss_dice: 0.2165  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.2158  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.2039  decode.d4.loss_dice: 0.2252  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2182  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.1993  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.1996  decode.d7.loss_dice: 0.2170  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.2038  decode.d8.loss_dice: 0.2249
09/30 18:54:45 - mmengine - INFO - Iter(train) [ 81300/320000]  base_lr: 7.6813e-05 lr: 7.6813e-06  eta: 1 day, 4:52:53  time: 0.4401  data_time: 0.0100  memory: 5145  grad_norm: 53.7285  loss: 5.7850  decode.loss_cls: 0.0713  decode.loss_mask: 0.2387  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.7820  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.2046  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.2378  decode.d1.loss_dice: 0.2005  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.1983  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.1986  decode.d6.loss_cls: 0.0421  decode.d6.loss_mask: 0.2383  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.1982  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2174
09/30 18:55:07 - mmengine - INFO - Iter(train) [ 81350/320000]  base_lr: 7.6798e-05 lr: 7.6798e-06  eta: 1 day, 4:52:32  time: 0.4396  data_time: 0.0099  memory: 5120  grad_norm: 19.1580  loss: 4.7687  decode.loss_cls: 0.0152  decode.loss_mask: 0.2061  decode.loss_dice: 0.1820  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 0.2063  decode.d0.loss_dice: 0.1811  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.2060  decode.d1.loss_dice: 0.1755  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1733  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.2051  decode.d3.loss_dice: 0.1796  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.2072  decode.d4.loss_dice: 0.1719  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.2066  decode.d5.loss_dice: 0.1703  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.2056  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.2078  decode.d7.loss_dice: 0.1754  decode.d8.loss_cls: 0.0103  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.1774
09/30 18:55:29 - mmengine - INFO - Iter(train) [ 81400/320000]  base_lr: 7.6784e-05 lr: 7.6784e-06  eta: 1 day, 4:52:11  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 128.8347  loss: 6.5801  decode.loss_cls: 0.0916  decode.loss_mask: 0.2389  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.8449  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.1689  decode.d1.loss_mask: 0.2959  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.2090  decode.d3.loss_cls: 0.1462  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.1471  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.1897  decode.d5.loss_cls: 0.1521  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.1342  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.2099  decode.d7.loss_cls: 0.1298  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.1817  decode.d8.loss_cls: 0.1191  decode.d8.loss_mask: 0.2415  decode.d8.loss_dice: 0.1994
09/30 18:55:51 - mmengine - INFO - Iter(train) [ 81450/320000]  base_lr: 7.6769e-05 lr: 7.6769e-06  eta: 1 day, 4:51:49  time: 0.4398  data_time: 0.0097  memory: 5120  grad_norm: 49.8811  loss: 6.2441  decode.loss_cls: 0.1111  decode.loss_mask: 0.2308  decode.loss_dice: 0.2171  decode.d0.loss_cls: 0.9182  decode.d0.loss_mask: 0.2356  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.2349  decode.d1.loss_dice: 0.2083  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.2014  decode.d3.loss_cls: 0.0958  decode.d3.loss_mask: 0.2304  decode.d3.loss_dice: 0.2211  decode.d4.loss_cls: 0.1506  decode.d4.loss_mask: 0.2294  decode.d4.loss_dice: 0.2138  decode.d5.loss_cls: 0.1154  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2169  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1989  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.2310  decode.d7.loss_dice: 0.2033  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.2321  decode.d8.loss_dice: 0.1923
09/30 18:56:13 - mmengine - INFO - Iter(train) [ 81500/320000]  base_lr: 7.6755e-05 lr: 7.6755e-06  eta: 1 day, 4:51:28  time: 0.4415  data_time: 0.0097  memory: 5145  grad_norm: 91.3100  loss: 6.9085  decode.loss_cls: 0.0623  decode.loss_mask: 0.2912  decode.loss_dice: 0.2482  decode.d0.loss_cls: 0.8585  decode.d0.loss_mask: 0.2990  decode.d0.loss_dice: 0.2401  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.2921  decode.d2.loss_dice: 0.2615  decode.d3.loss_cls: 0.0774  decode.d3.loss_mask: 0.2976  decode.d3.loss_dice: 0.2544  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.2968  decode.d4.loss_dice: 0.2494  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.2990  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.3000  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.2501
09/30 18:56:35 - mmengine - INFO - Iter(train) [ 81550/320000]  base_lr: 7.6740e-05 lr: 7.6740e-06  eta: 1 day, 4:51:07  time: 0.4411  data_time: 0.0099  memory: 5129  grad_norm: 29.5272  loss: 4.1179  decode.loss_cls: 0.0086  decode.loss_mask: 0.1589  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.7441  decode.d0.loss_mask: 0.1607  decode.d0.loss_dice: 0.1810  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.1596  decode.d1.loss_dice: 0.1706  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.1593  decode.d2.loss_dice: 0.1685  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.1595  decode.d3.loss_dice: 0.1669  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.1594  decode.d4.loss_dice: 0.1732  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.1583  decode.d5.loss_dice: 0.1762  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.1586  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.1611  decode.d7.loss_dice: 0.1726  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.1607  decode.d8.loss_dice: 0.1715
09/30 18:56:57 - mmengine - INFO - Iter(train) [ 81600/320000]  base_lr: 7.6726e-05 lr: 7.6726e-06  eta: 1 day, 4:50:46  time: 0.4401  data_time: 0.0096  memory: 5145  grad_norm: 145.7798  loss: 5.5403  decode.loss_cls: 0.0121  decode.loss_mask: 0.2626  decode.loss_dice: 0.1878  decode.d0.loss_cls: 0.7807  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.1815  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.1939  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.2609  decode.d2.loss_dice: 0.1893  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.1943  decode.d4.loss_cls: 0.0485  decode.d4.loss_mask: 0.2627  decode.d4.loss_dice: 0.1929  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.2621  decode.d5.loss_dice: 0.1850  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.1832  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.2594  decode.d7.loss_dice: 0.1893  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.2592  decode.d8.loss_dice: 0.1900
09/30 18:57:19 - mmengine - INFO - Iter(train) [ 81650/320000]  base_lr: 7.6711e-05 lr: 7.6711e-06  eta: 1 day, 4:50:25  time: 0.4405  data_time: 0.0098  memory: 5145  grad_norm: 80.9764  loss: 6.2240  decode.loss_cls: 0.1052  decode.loss_mask: 0.2371  decode.loss_dice: 0.1812  decode.d0.loss_cls: 0.8017  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.1869  decode.d1.loss_cls: 0.1537  decode.d1.loss_mask: 0.2363  decode.d1.loss_dice: 0.1784  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.2386  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.2019  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.1817  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.1826  decode.d6.loss_cls: 0.1361  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.1825  decode.d7.loss_cls: 0.1230  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.1806  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.1808
09/30 18:57:41 - mmengine - INFO - Iter(train) [ 81700/320000]  base_lr: 7.6697e-05 lr: 7.6697e-06  eta: 1 day, 4:50:04  time: 0.4393  data_time: 0.0097  memory: 5129  grad_norm: 20.8601  loss: 5.3536  decode.loss_cls: 0.1106  decode.loss_mask: 0.1476  decode.loss_dice: 0.2073  decode.d0.loss_cls: 0.8622  decode.d0.loss_mask: 0.1468  decode.d0.loss_dice: 0.2216  decode.d1.loss_cls: 0.1119  decode.d1.loss_mask: 0.1443  decode.d1.loss_dice: 0.1996  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.1479  decode.d2.loss_dice: 0.2126  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.1465  decode.d3.loss_dice: 0.2204  decode.d4.loss_cls: 0.0814  decode.d4.loss_mask: 0.1433  decode.d4.loss_dice: 0.2207  decode.d5.loss_cls: 0.0884  decode.d5.loss_mask: 0.1473  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.1446  decode.d6.loss_dice: 0.2123  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.1440  decode.d7.loss_dice: 0.2123  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.1449  decode.d8.loss_dice: 0.2061
09/30 18:58:03 - mmengine - INFO - Iter(train) [ 81750/320000]  base_lr: 7.6682e-05 lr: 7.6682e-06  eta: 1 day, 4:49:43  time: 0.4399  data_time: 0.0097  memory: 5145  grad_norm: 57.8297  loss: 6.6391  decode.loss_cls: 0.1134  decode.loss_mask: 0.2257  decode.loss_dice: 0.2339  decode.d0.loss_cls: 1.0583  decode.d0.loss_mask: 0.2397  decode.d0.loss_dice: 0.2147  decode.d1.loss_cls: 0.1393  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.2336  decode.d2.loss_dice: 0.2427  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.2378  decode.d3.loss_dice: 0.2483  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.2220  decode.d6.loss_cls: 0.1070  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.2495  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.2311  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.2511
09/30 18:58:25 - mmengine - INFO - Iter(train) [ 81800/320000]  base_lr: 7.6668e-05 lr: 7.6668e-06  eta: 1 day, 4:49:22  time: 0.4395  data_time: 0.0097  memory: 5159  grad_norm: 36.1317  loss: 5.4303  decode.loss_cls: 0.0025  decode.loss_mask: 0.2754  decode.loss_dice: 0.1788  decode.d0.loss_cls: 0.8064  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.1801  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.1839  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.2762  decode.d2.loss_dice: 0.1826  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.1841  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2781  decode.d4.loss_dice: 0.1822  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.2774  decode.d5.loss_dice: 0.1818  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.2811  decode.d6.loss_dice: 0.1847  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2749  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.1890
09/30 18:58:47 - mmengine - INFO - Iter(train) [ 81850/320000]  base_lr: 7.6653e-05 lr: 7.6653e-06  eta: 1 day, 4:49:01  time: 0.4397  data_time: 0.0098  memory: 5129  grad_norm: 18.1783  loss: 4.8406  decode.loss_cls: 0.0662  decode.loss_mask: 0.1723  decode.loss_dice: 0.1863  decode.d0.loss_cls: 0.8110  decode.d0.loss_mask: 0.1697  decode.d0.loss_dice: 0.1833  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.1678  decode.d1.loss_dice: 0.1801  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.1681  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.1689  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.1700  decode.d4.loss_dice: 0.1832  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.1696  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0364  decode.d6.loss_mask: 0.1698  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.1709  decode.d7.loss_dice: 0.1790  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.1741  decode.d8.loss_dice: 0.1842
09/30 18:59:09 - mmengine - INFO - Iter(train) [ 81900/320000]  base_lr: 7.6639e-05 lr: 7.6639e-06  eta: 1 day, 4:48:40  time: 0.4403  data_time: 0.0100  memory: 5120  grad_norm: 43.9995  loss: 6.7795  decode.loss_cls: 0.0751  decode.loss_mask: 0.2631  decode.loss_dice: 0.2591  decode.d0.loss_cls: 0.8525  decode.d0.loss_mask: 0.2701  decode.d0.loss_dice: 0.2632  decode.d1.loss_cls: 0.0691  decode.d1.loss_mask: 0.2686  decode.d1.loss_dice: 0.2642  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.2678  decode.d2.loss_dice: 0.2617  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2645  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.2627  decode.d4.loss_dice: 0.2558  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.2515  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.2646  decode.d6.loss_dice: 0.2534  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.2642  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.2620  decode.d8.loss_dice: 0.2607
09/30 18:59:31 - mmengine - INFO - Iter(train) [ 81950/320000]  base_lr: 7.6624e-05 lr: 7.6624e-06  eta: 1 day, 4:48:19  time: 0.4395  data_time: 0.0100  memory: 5129  grad_norm: 32.1367  loss: 5.4330  decode.loss_cls: 0.0049  decode.loss_mask: 0.2298  decode.loss_dice: 0.2240  decode.d0.loss_cls: 0.8447  decode.d0.loss_mask: 0.2356  decode.d0.loss_dice: 0.2106  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.2220  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.2328  decode.d4.loss_dice: 0.2180  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2160  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.2054  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.2154  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2288  decode.d8.loss_dice: 0.2082
09/30 18:59:53 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 18:59:53 - mmengine - INFO - Iter(train) [ 82000/320000]  base_lr: 7.6610e-05 lr: 7.6610e-06  eta: 1 day, 4:47:57  time: 0.4397  data_time: 0.0097  memory: 5145  grad_norm: 91.4170  loss: 5.2935  decode.loss_cls: 0.0457  decode.loss_mask: 0.2238  decode.loss_dice: 0.1838  decode.d0.loss_cls: 0.6931  decode.d0.loss_mask: 0.2279  decode.d0.loss_dice: 0.1878  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.2017  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.1984  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.1939  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.2261  decode.d4.loss_dice: 0.1968  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.2287  decode.d5.loss_dice: 0.1847  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.1920  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.2287  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.2269  decode.d8.loss_dice: 0.1892
09/30 19:00:15 - mmengine - INFO - Iter(train) [ 82050/320000]  base_lr: 7.6596e-05 lr: 7.6596e-06  eta: 1 day, 4:47:36  time: 0.4395  data_time: 0.0098  memory: 5120  grad_norm: 54.0903  loss: 4.3945  decode.loss_cls: 0.0082  decode.loss_mask: 0.1771  decode.loss_dice: 0.1475  decode.d0.loss_cls: 0.9696  decode.d0.loss_mask: 0.1790  decode.d0.loss_dice: 0.1495  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.1833  decode.d1.loss_dice: 0.1518  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.1780  decode.d2.loss_dice: 0.1503  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.1781  decode.d3.loss_dice: 0.1532  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.1766  decode.d4.loss_dice: 0.1495  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.1782  decode.d5.loss_dice: 0.1508  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.1784  decode.d6.loss_dice: 0.1481  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.1775  decode.d7.loss_dice: 0.1493  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.1805  decode.d8.loss_dice: 0.1511
09/30 19:00:37 - mmengine - INFO - Iter(train) [ 82100/320000]  base_lr: 7.6581e-05 lr: 7.6581e-06  eta: 1 day, 4:47:15  time: 0.4398  data_time: 0.0099  memory: 5120  grad_norm: 33.2360  loss: 6.8978  decode.loss_cls: 0.1291  decode.loss_mask: 0.2581  decode.loss_dice: 0.2501  decode.d0.loss_cls: 0.8844  decode.d0.loss_mask: 0.2562  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.1015  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.1059  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.2035  decode.d4.loss_cls: 0.1254  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.2444  decode.d5.loss_cls: 0.1194  decode.d5.loss_mask: 0.2543  decode.d5.loss_dice: 0.2376  decode.d6.loss_cls: 0.1428  decode.d6.loss_mask: 0.2527  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.2581  decode.d8.loss_dice: 0.2445
09/30 19:01:00 - mmengine - INFO - Iter(train) [ 82150/320000]  base_lr: 7.6567e-05 lr: 7.6567e-06  eta: 1 day, 4:46:54  time: 0.4404  data_time: 0.0100  memory: 5129  grad_norm: 57.5456  loss: 5.6829  decode.loss_cls: 0.0786  decode.loss_mask: 0.2221  decode.loss_dice: 0.1932  decode.d0.loss_cls: 0.8474  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.2033  decode.d1.loss_cls: 0.0545  decode.d1.loss_mask: 0.2264  decode.d1.loss_dice: 0.1955  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.2265  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.2221  decode.d3.loss_dice: 0.1950  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.1956  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.2339  decode.d5.loss_dice: 0.2008  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.2233  decode.d6.loss_dice: 0.1949  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.2219  decode.d7.loss_dice: 0.1988  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.1952
09/30 19:01:22 - mmengine - INFO - Iter(train) [ 82200/320000]  base_lr: 7.6552e-05 lr: 7.6552e-06  eta: 1 day, 4:46:33  time: 0.4397  data_time: 0.0098  memory: 5130  grad_norm: 78.6466  loss: 6.1504  decode.loss_cls: 0.0180  decode.loss_mask: 0.2815  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.8351  decode.d0.loss_mask: 0.2808  decode.d0.loss_dice: 0.2288  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.2262  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.2825  decode.d2.loss_dice: 0.2217  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.2815  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.0423  decode.d4.loss_mask: 0.2843  decode.d4.loss_dice: 0.2233  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.2196  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.2789  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2831  decode.d7.loss_dice: 0.2198  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.2836  decode.d8.loss_dice: 0.2200
09/30 19:01:44 - mmengine - INFO - Iter(train) [ 82250/320000]  base_lr: 7.6538e-05 lr: 7.6538e-06  eta: 1 day, 4:46:12  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 36.1613  loss: 5.4899  decode.loss_cls: 0.0926  decode.loss_mask: 0.2150  decode.loss_dice: 0.1855  decode.d0.loss_cls: 0.8046  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.1676  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.2167  decode.d1.loss_dice: 0.1599  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.2190  decode.d2.loss_dice: 0.1611  decode.d3.loss_cls: 0.0958  decode.d3.loss_mask: 0.2182  decode.d3.loss_dice: 0.1689  decode.d4.loss_cls: 0.0952  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.1682  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.2150  decode.d5.loss_dice: 0.1693  decode.d6.loss_cls: 0.0968  decode.d6.loss_mask: 0.2167  decode.d6.loss_dice: 0.1644  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.2168  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0904  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.1745
09/30 19:02:06 - mmengine - INFO - Iter(train) [ 82300/320000]  base_lr: 7.6523e-05 lr: 7.6523e-06  eta: 1 day, 4:45:51  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 43.0692  loss: 5.8911  decode.loss_cls: 0.1108  decode.loss_mask: 0.2093  decode.loss_dice: 0.1736  decode.d0.loss_cls: 0.7895  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.1759  decode.d1.loss_cls: 0.1277  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.1703  decode.d2.loss_cls: 0.1322  decode.d2.loss_mask: 0.2094  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.1440  decode.d3.loss_mask: 0.2067  decode.d3.loss_dice: 0.1760  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 0.2095  decode.d4.loss_dice: 0.1777  decode.d5.loss_cls: 0.1322  decode.d5.loss_mask: 0.2109  decode.d5.loss_dice: 0.1758  decode.d6.loss_cls: 0.1643  decode.d6.loss_mask: 0.2091  decode.d6.loss_dice: 0.1866  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.2114  decode.d7.loss_dice: 0.1749  decode.d8.loss_cls: 0.1245  decode.d8.loss_mask: 0.2101  decode.d8.loss_dice: 0.1774
09/30 19:02:28 - mmengine - INFO - Iter(train) [ 82350/320000]  base_lr: 7.6509e-05 lr: 7.6509e-06  eta: 1 day, 4:45:30  time: 0.4404  data_time: 0.0099  memory: 5145  grad_norm: 52.3019  loss: 6.3380  decode.loss_cls: 0.0890  decode.loss_mask: 0.2690  decode.loss_dice: 0.2192  decode.d0.loss_cls: 0.8681  decode.d0.loss_mask: 0.2006  decode.d0.loss_dice: 0.2124  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.1312  decode.d2.loss_mask: 0.2016  decode.d2.loss_dice: 0.2063  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.1932  decode.d4.loss_cls: 0.1401  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.2031  decode.d5.loss_cls: 0.1694  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.1962  decode.d6.loss_mask: 0.2011  decode.d6.loss_dice: 0.1884  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.1985  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.0938  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2181
09/30 19:02:50 - mmengine - INFO - Iter(train) [ 82400/320000]  base_lr: 7.6494e-05 lr: 7.6494e-06  eta: 1 day, 4:45:09  time: 0.4404  data_time: 0.0098  memory: 5120  grad_norm: 23.8446  loss: 4.2811  decode.loss_cls: 0.0029  decode.loss_mask: 0.1919  decode.loss_dice: 0.1600  decode.d0.loss_cls: 0.7317  decode.d0.loss_mask: 0.1937  decode.d0.loss_dice: 0.1574  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.1920  decode.d1.loss_dice: 0.1562  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.1918  decode.d2.loss_dice: 0.1573  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.1626  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.1913  decode.d5.loss_dice: 0.1603  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.1896  decode.d6.loss_dice: 0.1575  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.1925  decode.d7.loss_dice: 0.1577  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.1903  decode.d8.loss_dice: 0.1589
09/30 19:03:12 - mmengine - INFO - Iter(train) [ 82450/320000]  base_lr: 7.6480e-05 lr: 7.6480e-06  eta: 1 day, 4:44:48  time: 0.4397  data_time: 0.0099  memory: 5129  grad_norm: 68.5684  loss: 6.7848  decode.loss_cls: 0.1953  decode.loss_mask: 0.1864  decode.loss_dice: 0.2854  decode.d0.loss_cls: 0.8400  decode.d0.loss_mask: 0.1883  decode.d0.loss_dice: 0.2950  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.1892  decode.d1.loss_dice: 0.2714  decode.d2.loss_cls: 0.1791  decode.d2.loss_mask: 0.1865  decode.d2.loss_dice: 0.2632  decode.d3.loss_cls: 0.1123  decode.d3.loss_mask: 0.1850  decode.d3.loss_dice: 0.2873  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.1869  decode.d4.loss_dice: 0.2564  decode.d5.loss_cls: 0.1469  decode.d5.loss_mask: 0.1829  decode.d5.loss_dice: 0.2685  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 0.1864  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.1859  decode.d7.loss_dice: 0.2734  decode.d8.loss_cls: 0.1599  decode.d8.loss_mask: 0.1851  decode.d8.loss_dice: 0.2724
09/30 19:03:34 - mmengine - INFO - Iter(train) [ 82500/320000]  base_lr: 7.6465e-05 lr: 7.6465e-06  eta: 1 day, 4:44:27  time: 0.4399  data_time: 0.0098  memory: 5145  grad_norm: 20.9708  loss: 4.7176  decode.loss_cls: 0.0293  decode.loss_mask: 0.2206  decode.loss_dice: 0.1500  decode.d0.loss_cls: 0.7733  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.1533  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.1456  decode.d2.loss_cls: 0.0247  decode.d2.loss_mask: 0.2234  decode.d2.loss_dice: 0.1465  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.2236  decode.d3.loss_dice: 0.1455  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.2227  decode.d4.loss_dice: 0.1476  decode.d5.loss_cls: 0.0252  decode.d5.loss_mask: 0.2242  decode.d5.loss_dice: 0.1471  decode.d6.loss_cls: 0.0222  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.1488  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.1479  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.2238  decode.d8.loss_dice: 0.1506
09/30 19:03:56 - mmengine - INFO - Iter(train) [ 82550/320000]  base_lr: 7.6451e-05 lr: 7.6451e-06  eta: 1 day, 4:44:06  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 55.7289  loss: 5.4394  decode.loss_cls: 0.0558  decode.loss_mask: 0.1823  decode.loss_dice: 0.2013  decode.d0.loss_cls: 1.0260  decode.d0.loss_mask: 0.1829  decode.d0.loss_dice: 0.1875  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.1828  decode.d1.loss_dice: 0.2021  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.1816  decode.d2.loss_dice: 0.1960  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.1838  decode.d3.loss_dice: 0.1925  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.1934  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.2040  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.1836  decode.d6.loss_dice: 0.2026  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.1848  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0704  decode.d8.loss_mask: 0.1828  decode.d8.loss_dice: 0.1989
09/30 19:04:18 - mmengine - INFO - Iter(train) [ 82600/320000]  base_lr: 7.6436e-05 lr: 7.6436e-06  eta: 1 day, 4:43:45  time: 0.4395  data_time: 0.0098  memory: 5129  grad_norm: 71.4275  loss: 5.4505  decode.loss_cls: 0.1241  decode.loss_mask: 0.2119  decode.loss_dice: 0.1819  decode.d0.loss_cls: 0.8405  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.1938  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.2165  decode.d1.loss_dice: 0.1854  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.2149  decode.d2.loss_dice: 0.1860  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.2106  decode.d3.loss_dice: 0.1829  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1848  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.1787  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.2113  decode.d6.loss_dice: 0.1821  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.2144  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.1853
09/30 19:04:40 - mmengine - INFO - Iter(train) [ 82650/320000]  base_lr: 7.6422e-05 lr: 7.6422e-06  eta: 1 day, 4:43:23  time: 0.4395  data_time: 0.0097  memory: 5129  grad_norm: 83.1776  loss: 5.8671  decode.loss_cls: 0.0324  decode.loss_mask: 0.2668  decode.loss_dice: 0.2189  decode.d0.loss_cls: 0.7591  decode.d0.loss_mask: 0.2680  decode.d0.loss_dice: 0.2158  decode.d1.loss_cls: 0.0399  decode.d1.loss_mask: 0.2617  decode.d1.loss_dice: 0.2188  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.2622  decode.d2.loss_dice: 0.2188  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.2599  decode.d3.loss_dice: 0.2171  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.2676  decode.d4.loss_dice: 0.2179  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.2645  decode.d5.loss_dice: 0.2145  decode.d6.loss_cls: 0.0297  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.2184  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.2194
09/30 19:05:02 - mmengine - INFO - Iter(train) [ 82700/320000]  base_lr: 7.6407e-05 lr: 7.6407e-06  eta: 1 day, 4:43:02  time: 0.4398  data_time: 0.0097  memory: 5145  grad_norm: 50.2056  loss: 5.7167  decode.loss_cls: 0.0258  decode.loss_mask: 0.2307  decode.loss_dice: 0.1976  decode.d0.loss_cls: 0.8479  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.2157  decode.d1.loss_cls: 0.1199  decode.d1.loss_mask: 0.2315  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.1756  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.2110  decode.d4.loss_cls: 0.0311  decode.d4.loss_mask: 0.2326  decode.d4.loss_dice: 0.2040  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.2052  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.2321  decode.d6.loss_dice: 0.2061  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.1935  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.2051
09/30 19:05:24 - mmengine - INFO - Iter(train) [ 82750/320000]  base_lr: 7.6393e-05 lr: 7.6393e-06  eta: 1 day, 4:42:41  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 33.0249  loss: 5.0558  decode.loss_cls: 0.0057  decode.loss_mask: 0.2286  decode.loss_dice: 0.1771  decode.d0.loss_cls: 0.7769  decode.d0.loss_mask: 0.2293  decode.d0.loss_dice: 0.1898  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.2301  decode.d1.loss_dice: 0.2012  decode.d2.loss_cls: 0.0134  decode.d2.loss_mask: 0.2297  decode.d2.loss_dice: 0.2052  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.2289  decode.d3.loss_dice: 0.1939  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.1875  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.1798  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.1811  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.1796
09/30 19:05:46 - mmengine - INFO - Iter(train) [ 82800/320000]  base_lr: 7.6378e-05 lr: 7.6378e-06  eta: 1 day, 4:42:20  time: 0.4402  data_time: 0.0098  memory: 5145  grad_norm: 46.5254  loss: 6.2230  decode.loss_cls: 0.0830  decode.loss_mask: 0.2754  decode.loss_dice: 0.2038  decode.d0.loss_cls: 0.7608  decode.d0.loss_mask: 0.2775  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.1010  decode.d1.loss_mask: 0.2735  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.2016  decode.d3.loss_cls: 0.0936  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.2766  decode.d4.loss_dice: 0.2061  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.2714  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.1953  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.1928  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.1970
09/30 19:06:08 - mmengine - INFO - Iter(train) [ 82850/320000]  base_lr: 7.6364e-05 lr: 7.6364e-06  eta: 1 day, 4:41:59  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 47.8638  loss: 5.6398  decode.loss_cls: 0.0549  decode.loss_mask: 0.2067  decode.loss_dice: 0.2024  decode.d0.loss_cls: 0.8455  decode.d0.loss_mask: 0.2083  decode.d0.loss_dice: 0.1965  decode.d1.loss_cls: 0.1315  decode.d1.loss_mask: 0.2056  decode.d1.loss_dice: 0.1981  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.0772  decode.d3.loss_mask: 0.2055  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.0955  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.1900  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.2074  decode.d5.loss_dice: 0.1877  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.2058  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.1177  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.0756  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.1959
09/30 19:06:30 - mmengine - INFO - Iter(train) [ 82900/320000]  base_lr: 7.6349e-05 lr: 7.6349e-06  eta: 1 day, 4:41:38  time: 0.4395  data_time: 0.0097  memory: 5145  grad_norm: 22.1507  loss: 5.0318  decode.loss_cls: 0.0062  decode.loss_mask: 0.2296  decode.loss_dice: 0.1866  decode.d0.loss_cls: 0.7730  decode.d0.loss_mask: 0.2352  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.1827  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.1922  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.2319  decode.d3.loss_dice: 0.1909  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.1900  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.1863  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.2294  decode.d6.loss_dice: 0.1892  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.2298  decode.d7.loss_dice: 0.1854  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2308  decode.d8.loss_dice: 0.1854
09/30 19:06:52 - mmengine - INFO - Iter(train) [ 82950/320000]  base_lr: 7.6335e-05 lr: 7.6335e-06  eta: 1 day, 4:41:17  time: 0.4419  data_time: 0.0101  memory: 5119  grad_norm: 91.9470  loss: 7.1322  decode.loss_cls: 0.0636  decode.loss_mask: 0.2783  decode.loss_dice: 0.2489  decode.d0.loss_cls: 0.8281  decode.d0.loss_mask: 0.2700  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.1405  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.2425  decode.d2.loss_cls: 0.1451  decode.d2.loss_mask: 0.2690  decode.d2.loss_dice: 0.2588  decode.d3.loss_cls: 0.1249  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.2551  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 0.3021  decode.d4.loss_dice: 0.2723  decode.d5.loss_cls: 0.1756  decode.d5.loss_mask: 0.2916  decode.d5.loss_dice: 0.2626  decode.d6.loss_cls: 0.0772  decode.d6.loss_mask: 0.2809  decode.d6.loss_dice: 0.2519  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.2727  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.2869  decode.d8.loss_dice: 0.2625
09/30 19:07:14 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:07:14 - mmengine - INFO - Iter(train) [ 83000/320000]  base_lr: 7.6320e-05 lr: 7.6320e-06  eta: 1 day, 4:40:55  time: 0.4405  data_time: 0.0100  memory: 5129  grad_norm: 33.1276  loss: 6.5209  decode.loss_cls: 0.1139  decode.loss_mask: 0.3006  decode.loss_dice: 0.1954  decode.d0.loss_cls: 0.8726  decode.d0.loss_mask: 0.2591  decode.d0.loss_dice: 0.2069  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 0.2516  decode.d1.loss_dice: 0.1969  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 0.2551  decode.d2.loss_dice: 0.2047  decode.d3.loss_cls: 0.0976  decode.d3.loss_mask: 0.2588  decode.d3.loss_dice: 0.1991  decode.d4.loss_cls: 0.1303  decode.d4.loss_mask: 0.2514  decode.d4.loss_dice: 0.1940  decode.d5.loss_cls: 0.1430  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.1987  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.1028  decode.d7.loss_mask: 0.2456  decode.d7.loss_dice: 0.1943  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.2527  decode.d8.loss_dice: 0.2009
09/30 19:07:36 - mmengine - INFO - Iter(train) [ 83050/320000]  base_lr: 7.6306e-05 lr: 7.6306e-06  eta: 1 day, 4:40:34  time: 0.4407  data_time: 0.0101  memory: 5120  grad_norm: 48.5386  loss: 6.0252  decode.loss_cls: 0.0638  decode.loss_mask: 0.2386  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.8614  decode.d0.loss_mask: 0.2430  decode.d0.loss_dice: 0.2120  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.2379  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2003  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.2197  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2062  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2309  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.1929  decode.d7.loss_cls: 0.0595  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.0528  decode.d8.loss_mask: 0.2361  decode.d8.loss_dice: 0.2227
09/30 19:07:58 - mmengine - INFO - Iter(train) [ 83100/320000]  base_lr: 7.6291e-05 lr: 7.6291e-06  eta: 1 day, 4:40:13  time: 0.4400  data_time: 0.0099  memory: 5120  grad_norm: 81.6281  loss: 5.5012  decode.loss_cls: 0.1276  decode.loss_mask: 0.1858  decode.loss_dice: 0.2098  decode.d0.loss_cls: 0.9008  decode.d0.loss_mask: 0.1896  decode.d0.loss_dice: 0.2073  decode.d1.loss_cls: 0.1188  decode.d1.loss_mask: 0.1831  decode.d1.loss_dice: 0.1779  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 0.1838  decode.d2.loss_dice: 0.1538  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.1845  decode.d3.loss_dice: 0.1953  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 0.1840  decode.d4.loss_dice: 0.1713  decode.d5.loss_cls: 0.1121  decode.d5.loss_mask: 0.1836  decode.d5.loss_dice: 0.1539  decode.d6.loss_cls: 0.1014  decode.d6.loss_mask: 0.1834  decode.d6.loss_dice: 0.1520  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.1859  decode.d7.loss_dice: 0.1668  decode.d8.loss_cls: 0.1043  decode.d8.loss_mask: 0.1854  decode.d8.loss_dice: 0.1759
09/30 19:08:20 - mmengine - INFO - Iter(train) [ 83150/320000]  base_lr: 7.6277e-05 lr: 7.6277e-06  eta: 1 day, 4:39:52  time: 0.4388  data_time: 0.0098  memory: 5120  grad_norm: 18.9971  loss: 4.5370  decode.loss_cls: 0.0010  decode.loss_mask: 0.1848  decode.loss_dice: 0.1799  decode.d0.loss_cls: 0.9093  decode.d0.loss_mask: 0.1881  decode.d0.loss_dice: 0.1760  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.1844  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.1813  decode.d2.loss_dice: 0.1780  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1869  decode.d3.loss_dice: 0.1758  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.1817  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.1850  decode.d5.loss_dice: 0.1729  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1838  decode.d6.loss_dice: 0.1718  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.1793  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1829  decode.d8.loss_dice: 0.1758
09/30 19:08:42 - mmengine - INFO - Iter(train) [ 83200/320000]  base_lr: 7.6262e-05 lr: 7.6262e-06  eta: 1 day, 4:39:31  time: 0.4394  data_time: 0.0098  memory: 5129  grad_norm: 36.5799  loss: 5.2357  decode.loss_cls: 0.0044  decode.loss_mask: 0.2308  decode.loss_dice: 0.2145  decode.d0.loss_cls: 0.7739  decode.d0.loss_mask: 0.2318  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.2339  decode.d1.loss_dice: 0.2026  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.2313  decode.d2.loss_dice: 0.2013  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2310  decode.d3.loss_dice: 0.2207  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.2321  decode.d4.loss_dice: 0.2039  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.1992  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.2343  decode.d6.loss_dice: 0.2158  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.2335  decode.d7.loss_dice: 0.2071  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2132
09/30 19:09:04 - mmengine - INFO - Iter(train) [ 83250/320000]  base_lr: 7.6248e-05 lr: 7.6248e-06  eta: 1 day, 4:39:10  time: 0.4407  data_time: 0.0099  memory: 5129  grad_norm: 24.0307  loss: 5.1820  decode.loss_cls: 0.0784  decode.loss_mask: 0.2010  decode.loss_dice: 0.2056  decode.d0.loss_cls: 0.8172  decode.d0.loss_mask: 0.2033  decode.d0.loss_dice: 0.2375  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.1945  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2028  decode.d2.loss_dice: 0.2087  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.2030  decode.d5.loss_dice: 0.2082  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.2026  decode.d6.loss_dice: 0.2064  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.2038  decode.d8.loss_dice: 0.2034
09/30 19:09:26 - mmengine - INFO - Iter(train) [ 83300/320000]  base_lr: 7.6233e-05 lr: 7.6233e-06  eta: 1 day, 4:38:49  time: 0.4389  data_time: 0.0096  memory: 5129  grad_norm: 72.1610  loss: 6.7948  decode.loss_cls: 0.1481  decode.loss_mask: 0.1969  decode.loss_dice: 0.2192  decode.d0.loss_cls: 0.8692  decode.d0.loss_mask: 0.2006  decode.d0.loss_dice: 0.2181  decode.d1.loss_cls: 0.1843  decode.d1.loss_mask: 0.1987  decode.d1.loss_dice: 0.2293  decode.d2.loss_cls: 0.2139  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.1886  decode.d3.loss_mask: 0.2210  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.2571  decode.d5.loss_cls: 0.1668  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2308  decode.d6.loss_cls: 0.1663  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.2290  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.1988  decode.d7.loss_dice: 0.2275  decode.d8.loss_cls: 0.1622  decode.d8.loss_mask: 0.2034  decode.d8.loss_dice: 0.2324
09/30 19:09:48 - mmengine - INFO - Iter(train) [ 83350/320000]  base_lr: 7.6219e-05 lr: 7.6219e-06  eta: 1 day, 4:38:27  time: 0.4403  data_time: 0.0099  memory: 5129  grad_norm: 30.8085  loss: 4.7560  decode.loss_cls: 0.0650  decode.loss_mask: 0.1900  decode.loss_dice: 0.1476  decode.d0.loss_cls: 0.7550  decode.d0.loss_mask: 0.1917  decode.d0.loss_dice: 0.1507  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.1915  decode.d1.loss_dice: 0.1496  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.1499  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.1911  decode.d3.loss_dice: 0.1519  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.1498  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.1905  decode.d5.loss_dice: 0.1491  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.1460  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.1897  decode.d7.loss_dice: 0.1466  decode.d8.loss_cls: 0.0812  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.1467
09/30 19:10:10 - mmengine - INFO - Iter(train) [ 83400/320000]  base_lr: 7.6204e-05 lr: 7.6204e-06  eta: 1 day, 4:38:06  time: 0.4396  data_time: 0.0100  memory: 5129  grad_norm: 46.1593  loss: 5.5444  decode.loss_cls: 0.0874  decode.loss_mask: 0.2037  decode.loss_dice: 0.1628  decode.d0.loss_cls: 0.8917  decode.d0.loss_mask: 0.2079  decode.d0.loss_dice: 0.1761  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1773  decode.d2.loss_cls: 0.1428  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.1824  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.2078  decode.d3.loss_dice: 0.1696  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.2062  decode.d4.loss_dice: 0.1826  decode.d5.loss_cls: 0.1005  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.2090  decode.d6.loss_dice: 0.1894  decode.d7.loss_cls: 0.0975  decode.d7.loss_mask: 0.2071  decode.d7.loss_dice: 0.1670  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.1730
09/30 19:10:32 - mmengine - INFO - Iter(train) [ 83450/320000]  base_lr: 7.6190e-05 lr: 7.6190e-06  eta: 1 day, 4:37:45  time: 0.4404  data_time: 0.0099  memory: 5145  grad_norm: 31.7623  loss: 4.9366  decode.loss_cls: 0.0089  decode.loss_mask: 0.1992  decode.loss_dice: 0.2028  decode.d0.loss_cls: 0.8013  decode.d0.loss_mask: 0.2055  decode.d0.loss_dice: 0.2036  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.2001  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.1987  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2008  decode.d3.loss_dice: 0.2039  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.2100  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.2016  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.2061  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.2148  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.1974
09/30 19:10:54 - mmengine - INFO - Iter(train) [ 83500/320000]  base_lr: 7.6175e-05 lr: 7.6175e-06  eta: 1 day, 4:37:24  time: 0.4408  data_time: 0.0101  memory: 5120  grad_norm: 77.4248  loss: 7.1706  decode.loss_cls: 0.0696  decode.loss_mask: 0.2998  decode.loss_dice: 0.2878  decode.d0.loss_cls: 0.6549  decode.d0.loss_mask: 0.3070  decode.d0.loss_dice: 0.2806  decode.d1.loss_cls: 0.0853  decode.d1.loss_mask: 0.3046  decode.d1.loss_dice: 0.2765  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.2695  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.2970  decode.d3.loss_dice: 0.2857  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.2988  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.2978  decode.d5.loss_dice: 0.2623  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.3039  decode.d6.loss_dice: 0.2650  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.2788  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.3589  decode.d8.loss_dice: 0.2827
09/30 19:11:16 - mmengine - INFO - Iter(train) [ 83550/320000]  base_lr: 7.6161e-05 lr: 7.6161e-06  eta: 1 day, 4:37:03  time: 0.4404  data_time: 0.0099  memory: 5129  grad_norm: 17.0000  loss: 4.1334  decode.loss_cls: 0.0024  decode.loss_mask: 0.1852  decode.loss_dice: 0.1589  decode.d0.loss_cls: 0.7162  decode.d0.loss_mask: 0.1845  decode.d0.loss_dice: 0.1581  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.1829  decode.d1.loss_dice: 0.1599  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1825  decode.d2.loss_dice: 0.1599  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.1813  decode.d3.loss_dice: 0.1605  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.1817  decode.d4.loss_dice: 0.1541  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.1820  decode.d5.loss_dice: 0.1511  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.1814  decode.d6.loss_dice: 0.1508  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.1822  decode.d7.loss_dice: 0.1565  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.1817  decode.d8.loss_dice: 0.1536
09/30 19:11:38 - mmengine - INFO - Iter(train) [ 83600/320000]  base_lr: 7.6146e-05 lr: 7.6146e-06  eta: 1 day, 4:36:42  time: 0.4394  data_time: 0.0100  memory: 5129  grad_norm: 38.9405  loss: 6.6637  decode.loss_cls: 0.0880  decode.loss_mask: 0.2450  decode.loss_dice: 0.2511  decode.d0.loss_cls: 0.9748  decode.d0.loss_mask: 0.2451  decode.d0.loss_dice: 0.2499  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.2454  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.2425  decode.d2.loss_dice: 0.2503  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.1010  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.2564  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.2474  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2610  decode.d7.loss_cls: 0.0826  decode.d7.loss_mask: 0.2462  decode.d7.loss_dice: 0.2575  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2520
09/30 19:12:00 - mmengine - INFO - Iter(train) [ 83650/320000]  base_lr: 7.6132e-05 lr: 7.6132e-06  eta: 1 day, 4:36:20  time: 0.4401  data_time: 0.0100  memory: 5145  grad_norm: 54.7989  loss: 5.3166  decode.loss_cls: 0.1445  decode.loss_mask: 0.1949  decode.loss_dice: 0.1631  decode.d0.loss_cls: 0.8655  decode.d0.loss_mask: 0.1960  decode.d0.loss_dice: 0.1674  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 0.1978  decode.d1.loss_dice: 0.1649  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.1697  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.1959  decode.d4.loss_dice: 0.1641  decode.d5.loss_cls: 0.1190  decode.d5.loss_mask: 0.1925  decode.d5.loss_dice: 0.1562  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.1652  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.1968  decode.d7.loss_dice: 0.1688  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.1971  decode.d8.loss_dice: 0.1632
09/30 19:12:22 - mmengine - INFO - Iter(train) [ 83700/320000]  base_lr: 7.6117e-05 lr: 7.6117e-06  eta: 1 day, 4:35:59  time: 0.4400  data_time: 0.0101  memory: 5120  grad_norm: 35.1859  loss: 5.2938  decode.loss_cls: 0.0111  decode.loss_mask: 0.2640  decode.loss_dice: 0.1848  decode.d0.loss_cls: 0.6670  decode.d0.loss_mask: 0.2668  decode.d0.loss_dice: 0.1760  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.2687  decode.d1.loss_dice: 0.1823  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.2700  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.1882  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.1803  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.1828  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2657  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.1832  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.2689  decode.d8.loss_dice: 0.1857
09/30 19:12:44 - mmengine - INFO - Iter(train) [ 83750/320000]  base_lr: 7.6103e-05 lr: 7.6103e-06  eta: 1 day, 4:35:38  time: 0.4397  data_time: 0.0098  memory: 5129  grad_norm: 124.4818  loss: 7.6951  decode.loss_cls: 0.1138  decode.loss_mask: 0.3509  decode.loss_dice: 0.2573  decode.d0.loss_cls: 0.8709  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.2674  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.3260  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.0531  decode.d2.loss_mask: 0.3234  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.1210  decode.d3.loss_mask: 0.3336  decode.d3.loss_dice: 0.2639  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.3287  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.1308  decode.d5.loss_mask: 0.3265  decode.d5.loss_dice: 0.2598  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.3183  decode.d6.loss_dice: 0.2965  decode.d7.loss_cls: 0.1175  decode.d7.loss_mask: 0.3382  decode.d7.loss_dice: 0.2503  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.3765  decode.d8.loss_dice: 0.2833
09/30 19:13:06 - mmengine - INFO - Iter(train) [ 83800/320000]  base_lr: 7.6088e-05 lr: 7.6088e-06  eta: 1 day, 4:35:17  time: 0.4397  data_time: 0.0100  memory: 5129  grad_norm: 70.8579  loss: 6.1552  decode.loss_cls: 0.0269  decode.loss_mask: 0.2509  decode.loss_dice: 0.2404  decode.d0.loss_cls: 0.8069  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.2423  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.2538  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.2535  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2494  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.2523  decode.d4.loss_dice: 0.2095  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.2476  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.2539  decode.d6.loss_dice: 0.2068  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.2507  decode.d8.loss_dice: 0.2263
09/30 19:13:28 - mmengine - INFO - Iter(train) [ 83850/320000]  base_lr: 7.6074e-05 lr: 7.6074e-06  eta: 1 day, 4:34:56  time: 0.4389  data_time: 0.0098  memory: 5119  grad_norm: 44.8840  loss: 6.4780  decode.loss_cls: 0.1292  decode.loss_mask: 0.2527  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.7701  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.2024  decode.d1.loss_cls: 0.1772  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.2096  decode.d2.loss_cls: 0.0994  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2090  decode.d3.loss_cls: 0.1412  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.1989  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.2551  decode.d4.loss_dice: 0.1911  decode.d5.loss_cls: 0.1247  decode.d5.loss_mask: 0.2497  decode.d5.loss_dice: 0.2008  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 0.2503  decode.d6.loss_dice: 0.1862  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.2131  decode.d8.loss_cls: 0.1460  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.1963
09/30 19:13:50 - mmengine - INFO - Iter(train) [ 83900/320000]  base_lr: 7.6059e-05 lr: 7.6059e-06  eta: 1 day, 4:34:35  time: 0.4383  data_time: 0.0096  memory: 5145  grad_norm: 69.6272  loss: 6.8687  decode.loss_cls: 0.0598  decode.loss_mask: 0.2755  decode.loss_dice: 0.2193  decode.d0.loss_cls: 0.8723  decode.d0.loss_mask: 0.2839  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.2796  decode.d1.loss_mask: 0.2778  decode.d1.loss_dice: 0.2146  decode.d2.loss_cls: 0.1436  decode.d2.loss_mask: 0.2778  decode.d2.loss_dice: 0.2094  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.2437  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.2810  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.1291  decode.d5.loss_mask: 0.2772  decode.d5.loss_dice: 0.2126  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.2816  decode.d6.loss_dice: 0.2251  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.2797  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.2782  decode.d8.loss_dice: 0.2355
09/30 19:14:12 - mmengine - INFO - Iter(train) [ 83950/320000]  base_lr: 7.6045e-05 lr: 7.6045e-06  eta: 1 day, 4:34:13  time: 0.4393  data_time: 0.0097  memory: 5145  grad_norm: 31.7979  loss: 5.0710  decode.loss_cls: 0.0553  decode.loss_mask: 0.1971  decode.loss_dice: 0.1684  decode.d0.loss_cls: 0.8420  decode.d0.loss_mask: 0.2018  decode.d0.loss_dice: 0.1628  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.2008  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.1975  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.2003  decode.d3.loss_dice: 0.1669  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.1975  decode.d4.loss_dice: 0.1725  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.1718  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.1755  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.2106  decode.d7.loss_dice: 0.1747  decode.d8.loss_cls: 0.0721  decode.d8.loss_mask: 0.1996  decode.d8.loss_dice: 0.1710
09/30 19:14:34 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:14:34 - mmengine - INFO - Iter(train) [ 84000/320000]  base_lr: 7.6030e-05 lr: 7.6030e-06  eta: 1 day, 4:33:52  time: 0.4395  data_time: 0.0099  memory: 5120  grad_norm: 91.0030  loss: 7.4822  decode.loss_cls: 0.1774  decode.loss_mask: 0.2824  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.8198  decode.d0.loss_mask: 0.2871  decode.d0.loss_dice: 0.2313  decode.d1.loss_cls: 0.1098  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.2358  decode.d2.loss_cls: 0.1427  decode.d2.loss_mask: 0.2910  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.1734  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.2897  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.1794  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.2332  decode.d6.loss_cls: 0.1683  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.2357  decode.d7.loss_cls: 0.1936  decode.d7.loss_mask: 0.2878  decode.d7.loss_dice: 0.2341  decode.d8.loss_cls: 0.1778  decode.d8.loss_mask: 0.2908  decode.d8.loss_dice: 0.2262
09/30 19:14:57 - mmengine - INFO - Iter(train) [ 84050/320000]  base_lr: 7.6016e-05 lr: 7.6016e-06  eta: 1 day, 4:33:31  time: 0.4400  data_time: 0.0101  memory: 5129  grad_norm: 21.8573  loss: 4.8127  decode.loss_cls: 0.0067  decode.loss_mask: 0.2374  decode.loss_dice: 0.1641  decode.d0.loss_cls: 0.7435  decode.d0.loss_mask: 0.2384  decode.d0.loss_dice: 0.1680  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.2355  decode.d1.loss_dice: 0.1632  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.1623  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.1608  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.2350  decode.d6.loss_dice: 0.1614  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.1629  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.2359  decode.d8.loss_dice: 0.1642
09/30 19:15:19 - mmengine - INFO - Iter(train) [ 84100/320000]  base_lr: 7.6001e-05 lr: 7.6001e-06  eta: 1 day, 4:33:10  time: 0.4388  data_time: 0.0097  memory: 5145  grad_norm: 37.6799  loss: 5.1342  decode.loss_cls: 0.0726  decode.loss_mask: 0.1765  decode.loss_dice: 0.1712  decode.d0.loss_cls: 0.9364  decode.d0.loss_mask: 0.1761  decode.d0.loss_dice: 0.1667  decode.d1.loss_cls: 0.2072  decode.d1.loss_mask: 0.1755  decode.d1.loss_dice: 0.1599  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.1775  decode.d2.loss_dice: 0.1702  decode.d3.loss_cls: 0.0881  decode.d3.loss_mask: 0.1745  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.0758  decode.d4.loss_mask: 0.1747  decode.d4.loss_dice: 0.1681  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.1763  decode.d5.loss_dice: 0.1579  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.1749  decode.d6.loss_dice: 0.1586  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.1750  decode.d7.loss_dice: 0.1525  decode.d8.loss_cls: 0.0686  decode.d8.loss_mask: 0.1775  decode.d8.loss_dice: 0.1613
09/30 19:15:41 - mmengine - INFO - Iter(train) [ 84150/320000]  base_lr: 7.5987e-05 lr: 7.5987e-06  eta: 1 day, 4:32:49  time: 0.4398  data_time: 0.0100  memory: 5145  grad_norm: 71.1182  loss: 8.5734  decode.loss_cls: 0.2371  decode.loss_mask: 0.2758  decode.loss_dice: 0.2443  decode.d0.loss_cls: 1.0961  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.2654  decode.d1.loss_cls: 0.2522  decode.d1.loss_mask: 0.2760  decode.d1.loss_dice: 0.2408  decode.d2.loss_cls: 0.2480  decode.d2.loss_mask: 0.2762  decode.d2.loss_dice: 0.2409  decode.d3.loss_cls: 0.1815  decode.d3.loss_mask: 0.3747  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.1712  decode.d4.loss_mask: 0.3598  decode.d4.loss_dice: 0.2367  decode.d5.loss_cls: 0.2466  decode.d5.loss_mask: 0.2813  decode.d5.loss_dice: 0.2668  decode.d6.loss_cls: 0.2167  decode.d6.loss_mask: 0.2735  decode.d6.loss_dice: 0.2642  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 0.3562  decode.d7.loss_dice: 0.2321  decode.d8.loss_cls: 0.2569  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.2354
09/30 19:16:03 - mmengine - INFO - Iter(train) [ 84200/320000]  base_lr: 7.5972e-05 lr: 7.5972e-06  eta: 1 day, 4:32:28  time: 0.4390  data_time: 0.0097  memory: 5129  grad_norm: 16.7419  loss: 4.1828  decode.loss_cls: 0.0085  decode.loss_mask: 0.1830  decode.loss_dice: 0.1535  decode.d0.loss_cls: 0.7803  decode.d0.loss_mask: 0.1849  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.1831  decode.d1.loss_dice: 0.1421  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.1820  decode.d2.loss_dice: 0.1445  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.1800  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.1802  decode.d4.loss_dice: 0.1414  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.1789  decode.d5.loss_dice: 0.1464  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.1810  decode.d6.loss_dice: 0.1454  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.1807  decode.d7.loss_dice: 0.1506  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.1831  decode.d8.loss_dice: 0.1507
09/30 19:16:25 - mmengine - INFO - Iter(train) [ 84250/320000]  base_lr: 7.5958e-05 lr: 7.5958e-06  eta: 1 day, 4:32:06  time: 0.4394  data_time: 0.0096  memory: 5145  grad_norm: 31.5722  loss: 6.2354  decode.loss_cls: 0.1522  decode.loss_mask: 0.1901  decode.loss_dice: 0.2064  decode.d0.loss_cls: 0.8204  decode.d0.loss_mask: 0.1918  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.2026  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.1893  decode.d2.loss_dice: 0.1955  decode.d3.loss_cls: 0.1573  decode.d3.loss_mask: 0.1908  decode.d3.loss_dice: 0.2034  decode.d4.loss_cls: 0.1607  decode.d4.loss_mask: 0.1904  decode.d4.loss_dice: 0.2069  decode.d5.loss_cls: 0.1629  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.2062  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.1894  decode.d6.loss_dice: 0.1963  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.1894  decode.d7.loss_dice: 0.2001  decode.d8.loss_cls: 0.1558  decode.d8.loss_mask: 0.1918  decode.d8.loss_dice: 0.2093
09/30 19:16:47 - mmengine - INFO - Iter(train) [ 84300/320000]  base_lr: 7.5943e-05 lr: 7.5943e-06  eta: 1 day, 4:31:45  time: 0.4408  data_time: 0.0099  memory: 5129  grad_norm: 84.2033  loss: 6.0944  decode.loss_cls: 0.1857  decode.loss_mask: 0.1827  decode.loss_dice: 0.2104  decode.d0.loss_cls: 0.8915  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.1341  decode.d1.loss_mask: 0.1852  decode.d1.loss_dice: 0.1934  decode.d2.loss_cls: 0.1381  decode.d2.loss_mask: 0.1833  decode.d2.loss_dice: 0.2087  decode.d3.loss_cls: 0.1703  decode.d3.loss_mask: 0.1854  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.1454  decode.d4.loss_mask: 0.1831  decode.d4.loss_dice: 0.1812  decode.d5.loss_cls: 0.1418  decode.d5.loss_mask: 0.1861  decode.d5.loss_dice: 0.1715  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.2028  decode.d7.loss_cls: 0.1264  decode.d7.loss_mask: 0.1872  decode.d7.loss_dice: 0.1978  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 0.1870  decode.d8.loss_dice: 0.1799
09/30 19:17:09 - mmengine - INFO - Iter(train) [ 84350/320000]  base_lr: 7.5929e-05 lr: 7.5929e-06  eta: 1 day, 4:31:24  time: 0.4398  data_time: 0.0099  memory: 5129  grad_norm: 17.4711  loss: 4.8129  decode.loss_cls: 0.0321  decode.loss_mask: 0.2012  decode.loss_dice: 0.1619  decode.d0.loss_cls: 0.8774  decode.d0.loss_mask: 0.2027  decode.d0.loss_dice: 0.1564  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.1591  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.1590  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.1998  decode.d3.loss_dice: 0.1595  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.2007  decode.d4.loss_dice: 0.1573  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.1978  decode.d5.loss_dice: 0.1598  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1593  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.1554  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.1603
09/30 19:17:31 - mmengine - INFO - Iter(train) [ 84400/320000]  base_lr: 7.5914e-05 lr: 7.5914e-06  eta: 1 day, 4:31:03  time: 0.4411  data_time: 0.0099  memory: 5120  grad_norm: 33.2718  loss: 4.6072  decode.loss_cls: 0.0091  decode.loss_mask: 0.2046  decode.loss_dice: 0.1624  decode.d0.loss_cls: 0.8200  decode.d0.loss_mask: 0.2086  decode.d0.loss_dice: 0.1665  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.2077  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.1655  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.2062  decode.d3.loss_dice: 0.1642  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2053  decode.d4.loss_dice: 0.1629  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.1631  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.2039  decode.d6.loss_dice: 0.1614  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.1629  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.1639
09/30 19:17:53 - mmengine - INFO - Iter(train) [ 84450/320000]  base_lr: 7.5900e-05 lr: 7.5900e-06  eta: 1 day, 4:30:42  time: 0.4399  data_time: 0.0099  memory: 5129  grad_norm: 44.3323  loss: 5.2912  decode.loss_cls: 0.0104  decode.loss_mask: 0.2383  decode.loss_dice: 0.1952  decode.d0.loss_cls: 0.7663  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.2073  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.1985  decode.d2.loss_cls: 0.0202  decode.d2.loss_mask: 0.2393  decode.d2.loss_dice: 0.1969  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.1978  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.1998  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.2381  decode.d5.loss_dice: 0.2014  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.1973  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.2377  decode.d7.loss_dice: 0.1936  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2016
09/30 19:18:15 - mmengine - INFO - Iter(train) [ 84500/320000]  base_lr: 7.5885e-05 lr: 7.5885e-06  eta: 1 day, 4:30:21  time: 0.4414  data_time: 0.0099  memory: 5120  grad_norm: 43.6229  loss: 5.0838  decode.loss_cls: 0.0189  decode.loss_mask: 0.2106  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.1687  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.2230  decode.d1.loss_dice: 0.1642  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.2166  decode.d2.loss_dice: 0.1618  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.1674  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.2428  decode.d4.loss_dice: 0.1684  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.1674  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.1634  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.2242  decode.d7.loss_dice: 0.1727  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.1624
09/30 19:18:37 - mmengine - INFO - Iter(train) [ 84550/320000]  base_lr: 7.5871e-05 lr: 7.5871e-06  eta: 1 day, 4:29:59  time: 0.4399  data_time: 0.0101  memory: 5104  grad_norm: 62.3323  loss: 5.5820  decode.loss_cls: 0.0276  decode.loss_mask: 0.2740  decode.loss_dice: 0.1925  decode.d0.loss_cls: 0.7435  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.1958  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.1944  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.2766  decode.d2.loss_dice: 0.1970  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.2757  decode.d3.loss_dice: 0.1956  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.2753  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.2742  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.2726  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.1963  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.2719  decode.d8.loss_dice: 0.1904
09/30 19:18:59 - mmengine - INFO - Iter(train) [ 84600/320000]  base_lr: 7.5856e-05 lr: 7.5856e-06  eta: 1 day, 4:29:38  time: 0.4397  data_time: 0.0099  memory: 5129  grad_norm: 107.2350  loss: 8.5475  decode.loss_cls: 0.3420  decode.loss_mask: 0.2053  decode.loss_dice: 0.2574  decode.d0.loss_cls: 0.7626  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.2448  decode.d1.loss_cls: 0.3448  decode.d1.loss_mask: 0.2020  decode.d1.loss_dice: 0.2617  decode.d2.loss_cls: 0.3372  decode.d2.loss_mask: 0.2048  decode.d2.loss_dice: 0.2523  decode.d3.loss_cls: 0.3678  decode.d3.loss_mask: 0.2071  decode.d3.loss_dice: 0.2503  decode.d4.loss_cls: 0.3705  decode.d4.loss_mask: 0.2052  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.3683  decode.d5.loss_mask: 0.2030  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.3387  decode.d6.loss_mask: 0.2065  decode.d6.loss_dice: 0.2786  decode.d7.loss_cls: 0.3501  decode.d7.loss_mask: 0.2046  decode.d7.loss_dice: 0.2617  decode.d8.loss_cls: 0.3396  decode.d8.loss_mask: 0.2043  decode.d8.loss_dice: 0.2644
09/30 19:19:21 - mmengine - INFO - Iter(train) [ 84650/320000]  base_lr: 7.5842e-05 lr: 7.5842e-06  eta: 1 day, 4:29:17  time: 0.4388  data_time: 0.0097  memory: 5120  grad_norm: 86.6560  loss: 9.1197  decode.loss_cls: 0.2519  decode.loss_mask: 0.3112  decode.loss_dice: 0.2744  decode.d0.loss_cls: 0.8864  decode.d0.loss_mask: 0.3032  decode.d0.loss_dice: 0.2567  decode.d1.loss_cls: 0.1969  decode.d1.loss_mask: 0.3008  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.1938  decode.d2.loss_mask: 0.4425  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.7768  decode.d3.loss_dice: 0.2473  decode.d4.loss_cls: 0.2158  decode.d4.loss_mask: 0.3311  decode.d4.loss_dice: 0.2721  decode.d5.loss_cls: 0.2404  decode.d5.loss_mask: 0.2962  decode.d5.loss_dice: 0.2600  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 0.4494  decode.d6.loss_dice: 0.2678  decode.d7.loss_cls: 0.2236  decode.d7.loss_mask: 0.2991  decode.d7.loss_dice: 0.2711  decode.d8.loss_cls: 0.2196  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.2523
09/30 19:19:43 - mmengine - INFO - Iter(train) [ 84700/320000]  base_lr: 7.5827e-05 lr: 7.5827e-06  eta: 1 day, 4:28:56  time: 0.4392  data_time: 0.0099  memory: 5129  grad_norm: 43.1797  loss: 4.8023  decode.loss_cls: 0.0353  decode.loss_mask: 0.1967  decode.loss_dice: 0.1473  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 0.2019  decode.d0.loss_dice: 0.1534  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.1987  decode.d1.loss_dice: 0.1538  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.1963  decode.d2.loss_dice: 0.1522  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.1953  decode.d3.loss_dice: 0.1510  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.1962  decode.d4.loss_dice: 0.1495  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.1952  decode.d5.loss_dice: 0.1513  decode.d6.loss_cls: 0.0392  decode.d6.loss_mask: 0.1974  decode.d6.loss_dice: 0.1529  decode.d7.loss_cls: 0.0419  decode.d7.loss_mask: 0.1954  decode.d7.loss_dice: 0.1517  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.1958  decode.d8.loss_dice: 0.1548
09/30 19:20:05 - mmengine - INFO - Iter(train) [ 84750/320000]  base_lr: 7.5813e-05 lr: 7.5813e-06  eta: 1 day, 4:28:35  time: 0.4394  data_time: 0.0099  memory: 5120  grad_norm: 36.8435  loss: 5.6524  decode.loss_cls: 0.0699  decode.loss_mask: 0.2009  decode.loss_dice: 0.1989  decode.d0.loss_cls: 0.7690  decode.d0.loss_mask: 0.2031  decode.d0.loss_dice: 0.2342  decode.d1.loss_cls: 0.1251  decode.d1.loss_mask: 0.1982  decode.d1.loss_dice: 0.2794  decode.d2.loss_cls: 0.0354  decode.d2.loss_mask: 0.2017  decode.d2.loss_dice: 0.2131  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.1996  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.2038  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.2022  decode.d5.loss_dice: 0.2426  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.1995  decode.d6.loss_dice: 0.1912  decode.d7.loss_cls: 0.1253  decode.d7.loss_mask: 0.1999  decode.d7.loss_dice: 0.2167  decode.d8.loss_cls: 0.0813  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.2103
09/30 19:20:27 - mmengine - INFO - Iter(train) [ 84800/320000]  base_lr: 7.5798e-05 lr: 7.5798e-06  eta: 1 day, 4:28:13  time: 0.4411  data_time: 0.0100  memory: 5145  grad_norm: 25.6629  loss: 4.2774  decode.loss_cls: 0.0227  decode.loss_mask: 0.1738  decode.loss_dice: 0.1554  decode.d0.loss_cls: 0.7850  decode.d0.loss_mask: 0.1729  decode.d0.loss_dice: 0.1569  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.1754  decode.d1.loss_dice: 0.1587  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.1735  decode.d2.loss_dice: 0.1577  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.1731  decode.d3.loss_dice: 0.1546  decode.d4.loss_cls: 0.0427  decode.d4.loss_mask: 0.1739  decode.d4.loss_dice: 0.1497  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.1712  decode.d5.loss_dice: 0.1532  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.1726  decode.d6.loss_dice: 0.1572  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.1715  decode.d7.loss_dice: 0.1679  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.1741  decode.d8.loss_dice: 0.1673
09/30 19:20:49 - mmengine - INFO - Iter(train) [ 84850/320000]  base_lr: 7.5784e-05 lr: 7.5784e-06  eta: 1 day, 4:27:52  time: 0.4401  data_time: 0.0098  memory: 5145  grad_norm: 42.4999  loss: 6.7654  decode.loss_cls: 0.1716  decode.loss_mask: 0.2204  decode.loss_dice: 0.2416  decode.d0.loss_cls: 0.9891  decode.d0.loss_mask: 0.2171  decode.d0.loss_dice: 0.2352  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.2173  decode.d1.loss_dice: 0.2281  decode.d2.loss_cls: 0.1243  decode.d2.loss_mask: 0.2039  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.1491  decode.d4.loss_mask: 0.2312  decode.d4.loss_dice: 0.2279  decode.d5.loss_cls: 0.1702  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.2247  decode.d6.loss_cls: 0.1662  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.2128  decode.d8.loss_cls: 0.1390  decode.d8.loss_mask: 0.2070  decode.d8.loss_dice: 0.2217
09/30 19:21:11 - mmengine - INFO - Iter(train) [ 84900/320000]  base_lr: 7.5769e-05 lr: 7.5769e-06  eta: 1 day, 4:27:31  time: 0.4402  data_time: 0.0099  memory: 5120  grad_norm: 24.6120  loss: 4.9999  decode.loss_cls: 0.0469  decode.loss_mask: 0.2147  decode.loss_dice: 0.1673  decode.d0.loss_cls: 0.7654  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1710  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.1706  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.1709  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1698  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.2132  decode.d5.loss_dice: 0.1682  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.1674  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.2115  decode.d7.loss_dice: 0.1695  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.2096  decode.d8.loss_dice: 0.1654
09/30 19:21:33 - mmengine - INFO - Iter(train) [ 84950/320000]  base_lr: 7.5755e-05 lr: 7.5755e-06  eta: 1 day, 4:27:10  time: 0.4401  data_time: 0.0097  memory: 5145  grad_norm: 34.2274  loss: 5.0221  decode.loss_cls: 0.0290  decode.loss_mask: 0.2043  decode.loss_dice: 0.1932  decode.d0.loss_cls: 0.7691  decode.d0.loss_mask: 0.2035  decode.d0.loss_dice: 0.1822  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.2048  decode.d1.loss_dice: 0.1889  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.2033  decode.d2.loss_dice: 0.1926  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.2036  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.2040  decode.d4.loss_dice: 0.1888  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.1876  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.2032  decode.d6.loss_dice: 0.1888  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.2063  decode.d8.loss_dice: 0.1851
09/30 19:21:55 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:21:55 - mmengine - INFO - Iter(train) [ 85000/320000]  base_lr: 7.5740e-05 lr: 7.5740e-06  eta: 1 day, 4:26:49  time: 0.4407  data_time: 0.0100  memory: 5120  grad_norm: 100.2665  loss: 5.4889  decode.loss_cls: 0.0230  decode.loss_mask: 0.2713  decode.loss_dice: 0.1870  decode.d0.loss_cls: 0.7325  decode.d0.loss_mask: 0.2704  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.2692  decode.d1.loss_dice: 0.1819  decode.d2.loss_cls: 0.0259  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.1853  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.2681  decode.d4.loss_dice: 0.1799  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.1857  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.2698  decode.d7.loss_dice: 0.1851  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.1864
09/30 19:22:17 - mmengine - INFO - Iter(train) [ 85050/320000]  base_lr: 7.5726e-05 lr: 7.5726e-06  eta: 1 day, 4:26:28  time: 0.4409  data_time: 0.0099  memory: 5145  grad_norm: 12.0097  loss: 3.9266  decode.loss_cls: 0.0066  decode.loss_mask: 0.1542  decode.loss_dice: 0.1429  decode.d0.loss_cls: 0.8969  decode.d0.loss_mask: 0.1572  decode.d0.loss_dice: 0.1507  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.1516  decode.d1.loss_dice: 0.1417  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.1532  decode.d2.loss_dice: 0.1425  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.1553  decode.d3.loss_dice: 0.1369  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.1551  decode.d4.loss_dice: 0.1442  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.1526  decode.d5.loss_dice: 0.1425  decode.d6.loss_cls: 0.0096  decode.d6.loss_mask: 0.1548  decode.d6.loss_dice: 0.1435  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1526  decode.d7.loss_dice: 0.1391  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.1566  decode.d8.loss_dice: 0.1394
09/30 19:22:39 - mmengine - INFO - Iter(train) [ 85100/320000]  base_lr: 7.5711e-05 lr: 7.5711e-06  eta: 1 day, 4:26:06  time: 0.4405  data_time: 0.0099  memory: 5129  grad_norm: 66.5197  loss: 6.0873  decode.loss_cls: 0.0959  decode.loss_mask: 0.2177  decode.loss_dice: 0.2170  decode.d0.loss_cls: 0.7147  decode.d0.loss_mask: 0.2228  decode.d0.loss_dice: 0.2180  decode.d1.loss_cls: 0.1575  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.1994  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 0.2199  decode.d2.loss_dice: 0.1931  decode.d3.loss_cls: 0.1227  decode.d3.loss_mask: 0.2230  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.1229  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.2138  decode.d5.loss_cls: 0.1217  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.2102  decode.d6.loss_cls: 0.0871  decode.d6.loss_mask: 0.2251  decode.d6.loss_dice: 0.2248  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.2221  decode.d7.loss_dice: 0.2168  decode.d8.loss_cls: 0.0920  decode.d8.loss_mask: 0.2255  decode.d8.loss_dice: 0.2204
09/30 19:23:01 - mmengine - INFO - Iter(train) [ 85150/320000]  base_lr: 7.5697e-05 lr: 7.5697e-06  eta: 1 day, 4:25:45  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 48.9701  loss: 5.3793  decode.loss_cls: 0.0521  decode.loss_mask: 0.2106  decode.loss_dice: 0.1731  decode.d0.loss_cls: 0.8641  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.1742  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.2154  decode.d1.loss_dice: 0.1683  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.2103  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.2096  decode.d3.loss_dice: 0.1756  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.1709  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.2090  decode.d5.loss_dice: 0.1762  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.2105  decode.d6.loss_dice: 0.1791  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.1719  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.2131  decode.d8.loss_dice: 0.1944
09/30 19:23:23 - mmengine - INFO - Iter(train) [ 85200/320000]  base_lr: 7.5682e-05 lr: 7.5682e-06  eta: 1 day, 4:25:24  time: 0.4398  data_time: 0.0098  memory: 5129  grad_norm: 40.5131  loss: 4.8684  decode.loss_cls: 0.0112  decode.loss_mask: 0.2294  decode.loss_dice: 0.1699  decode.d0.loss_cls: 0.7849  decode.d0.loss_mask: 0.2294  decode.d0.loss_dice: 0.1668  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.1760  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.1669  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2288  decode.d3.loss_dice: 0.1677  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.1696  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.2261  decode.d6.loss_dice: 0.1649  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.2272  decode.d7.loss_dice: 0.1699  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.1686
09/30 19:23:45 - mmengine - INFO - Iter(train) [ 85250/320000]  base_lr: 7.5668e-05 lr: 7.5668e-06  eta: 1 day, 4:25:03  time: 0.4391  data_time: 0.0098  memory: 5145  grad_norm: 29.4576  loss: 5.2248  decode.loss_cls: 0.0414  decode.loss_mask: 0.2458  decode.loss_dice: 0.1843  decode.d0.loss_cls: 0.7746  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.1659  decode.d1.loss_cls: 0.0191  decode.d1.loss_mask: 0.2622  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.2405  decode.d2.loss_dice: 0.1720  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.1734  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.2455  decode.d4.loss_dice: 0.1758  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.2446  decode.d6.loss_dice: 0.1720  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.2457  decode.d7.loss_dice: 0.1711  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.1741
09/30 19:24:07 - mmengine - INFO - Iter(train) [ 85300/320000]  base_lr: 7.5653e-05 lr: 7.5653e-06  eta: 1 day, 4:24:42  time: 0.4412  data_time: 0.0100  memory: 5129  grad_norm: 91.4665  loss: 6.0720  decode.loss_cls: 0.0659  decode.loss_mask: 0.2417  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.9005  decode.d0.loss_mask: 0.2514  decode.d0.loss_dice: 0.2261  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.2377  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2177  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2298  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2186  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2204  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.2362  decode.d7.loss_dice: 0.2095  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.2180
09/30 19:24:29 - mmengine - INFO - Iter(train) [ 85350/320000]  base_lr: 7.5639e-05 lr: 7.5639e-06  eta: 1 day, 4:24:20  time: 0.4400  data_time: 0.0100  memory: 5129  grad_norm: 19.4940  loss: 4.7891  decode.loss_cls: 0.0813  decode.loss_mask: 0.1600  decode.loss_dice: 0.1643  decode.d0.loss_cls: 0.8671  decode.d0.loss_mask: 0.1583  decode.d0.loss_dice: 0.1739  decode.d1.loss_cls: 0.0588  decode.d1.loss_mask: 0.1576  decode.d1.loss_dice: 0.1782  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.1589  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.1583  decode.d3.loss_dice: 0.1740  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 0.1586  decode.d4.loss_dice: 0.1581  decode.d5.loss_cls: 0.0597  decode.d5.loss_mask: 0.1598  decode.d5.loss_dice: 0.1797  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.1579  decode.d6.loss_dice: 0.1796  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.1607  decode.d7.loss_dice: 0.1589  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.1592  decode.d8.loss_dice: 0.1821
09/30 19:24:51 - mmengine - INFO - Iter(train) [ 85400/320000]  base_lr: 7.5624e-05 lr: 7.5624e-06  eta: 1 day, 4:23:59  time: 0.4398  data_time: 0.0097  memory: 5120  grad_norm: 38.5364  loss: 5.5361  decode.loss_cls: 0.0653  decode.loss_mask: 0.2208  decode.loss_dice: 0.1945  decode.d0.loss_cls: 0.8880  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.1992  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.2172  decode.d2.loss_dice: 0.1938  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2052  decode.d4.loss_cls: 0.0405  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.1945  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.2099  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.2209  decode.d6.loss_dice: 0.2045  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.2194  decode.d7.loss_dice: 0.1965  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.1937
09/30 19:25:13 - mmengine - INFO - Iter(train) [ 85450/320000]  base_lr: 7.5610e-05 lr: 7.5610e-06  eta: 1 day, 4:23:38  time: 0.4397  data_time: 0.0101  memory: 5129  grad_norm: 43.7422  loss: 6.8320  decode.loss_cls: 0.1534  decode.loss_mask: 0.2198  decode.loss_dice: 0.2380  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.2203  decode.d1.loss_cls: 0.2367  decode.d1.loss_mask: 0.2267  decode.d1.loss_dice: 0.2330  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.1119  decode.d3.loss_mask: 0.2252  decode.d3.loss_dice: 0.2441  decode.d4.loss_cls: 0.2060  decode.d4.loss_mask: 0.2233  decode.d4.loss_dice: 0.2273  decode.d5.loss_cls: 0.1508  decode.d5.loss_mask: 0.2220  decode.d5.loss_dice: 0.2393  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2079  decode.d7.loss_cls: 0.1339  decode.d7.loss_mask: 0.2219  decode.d7.loss_dice: 0.2249  decode.d8.loss_cls: 0.1564  decode.d8.loss_mask: 0.2232  decode.d8.loss_dice: 0.2433
09/30 19:25:35 - mmengine - INFO - Iter(train) [ 85500/320000]  base_lr: 7.5595e-05 lr: 7.5595e-06  eta: 1 day, 4:23:17  time: 0.4400  data_time: 0.0096  memory: 5129  grad_norm: 43.4169  loss: 5.0612  decode.loss_cls: 0.0428  decode.loss_mask: 0.1997  decode.loss_dice: 0.1966  decode.d0.loss_cls: 0.8137  decode.d0.loss_mask: 0.2046  decode.d0.loss_dice: 0.1842  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.2033  decode.d1.loss_dice: 0.1752  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.2014  decode.d2.loss_dice: 0.1806  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.2032  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0268  decode.d4.loss_mask: 0.1986  decode.d4.loss_dice: 0.1735  decode.d5.loss_cls: 0.0452  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.1712  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.1691  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.1865
09/30 19:25:57 - mmengine - INFO - Iter(train) [ 85550/320000]  base_lr: 7.5581e-05 lr: 7.5581e-06  eta: 1 day, 4:22:56  time: 0.4401  data_time: 0.0099  memory: 5129  grad_norm: 33.5490  loss: 5.5904  decode.loss_cls: 0.0688  decode.loss_mask: 0.2541  decode.loss_dice: 0.1951  decode.d0.loss_cls: 0.8680  decode.d0.loss_mask: 0.2606  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.2548  decode.d1.loss_dice: 0.2002  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.2598  decode.d2.loss_dice: 0.2080  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.2488  decode.d3.loss_dice: 0.1957  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.1990  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.2513  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.0161  decode.d6.loss_mask: 0.2544  decode.d6.loss_dice: 0.1979  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.2548  decode.d7.loss_dice: 0.1994  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.1968
09/30 19:26:19 - mmengine - INFO - Iter(train) [ 85600/320000]  base_lr: 7.5566e-05 lr: 7.5566e-06  eta: 1 day, 4:22:34  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 32.6040  loss: 6.1128  decode.loss_cls: 0.1785  decode.loss_mask: 0.1795  decode.loss_dice: 0.1704  decode.d0.loss_cls: 1.0308  decode.d0.loss_mask: 0.1773  decode.d0.loss_dice: 0.1736  decode.d1.loss_cls: 0.1494  decode.d1.loss_mask: 0.1804  decode.d1.loss_dice: 0.1831  decode.d2.loss_cls: 0.1333  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.1589  decode.d3.loss_mask: 0.1772  decode.d3.loss_dice: 0.1758  decode.d4.loss_cls: 0.1500  decode.d4.loss_mask: 0.1775  decode.d4.loss_dice: 0.2005  decode.d5.loss_cls: 0.1792  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.2035  decode.d6.loss_cls: 0.1552  decode.d6.loss_mask: 0.1842  decode.d6.loss_dice: 0.1912  decode.d7.loss_cls: 0.1783  decode.d7.loss_mask: 0.1824  decode.d7.loss_dice: 0.1732  decode.d8.loss_cls: 0.1714  decode.d8.loss_mask: 0.1788  decode.d8.loss_dice: 0.1724
09/30 19:26:41 - mmengine - INFO - Iter(train) [ 85650/320000]  base_lr: 7.5552e-05 lr: 7.5552e-06  eta: 1 day, 4:22:14  time: 0.4397  data_time: 0.0099  memory: 5129  grad_norm: 33.6985  loss: 5.6043  decode.loss_cls: 0.0056  decode.loss_mask: 0.2571  decode.loss_dice: 0.2052  decode.d0.loss_cls: 0.8298  decode.d0.loss_mask: 0.2694  decode.d0.loss_dice: 0.1994  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.2041  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.2012  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.2073  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.2593  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.2605  decode.d5.loss_dice: 0.2083  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.2585  decode.d6.loss_dice: 0.2030  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.2591  decode.d7.loss_dice: 0.2071  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.2580  decode.d8.loss_dice: 0.2090
09/30 19:27:03 - mmengine - INFO - Iter(train) [ 85700/320000]  base_lr: 7.5537e-05 lr: 7.5537e-06  eta: 1 day, 4:21:52  time: 0.4397  data_time: 0.0100  memory: 5104  grad_norm: 59.4647  loss: 4.7557  decode.loss_cls: 0.0360  decode.loss_mask: 0.2047  decode.loss_dice: 0.1671  decode.d0.loss_cls: 0.8572  decode.d0.loss_mask: 0.2077  decode.d0.loss_dice: 0.1653  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.1673  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.2066  decode.d2.loss_dice: 0.1658  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.2061  decode.d3.loss_dice: 0.1727  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.2061  decode.d4.loss_dice: 0.1664  decode.d5.loss_cls: 0.0124  decode.d5.loss_mask: 0.2043  decode.d5.loss_dice: 0.1672  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.2023  decode.d6.loss_dice: 0.1628  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.1672  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.2052  decode.d8.loss_dice: 0.1686
09/30 19:27:25 - mmengine - INFO - Iter(train) [ 85750/320000]  base_lr: 7.5523e-05 lr: 7.5523e-06  eta: 1 day, 4:21:31  time: 0.4395  data_time: 0.0098  memory: 5129  grad_norm: 34.2860  loss: 5.3987  decode.loss_cls: 0.0378  decode.loss_mask: 0.2111  decode.loss_dice: 0.2120  decode.d0.loss_cls: 0.7926  decode.d0.loss_mask: 0.2191  decode.d0.loss_dice: 0.2188  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.2142  decode.d1.loss_dice: 0.2283  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.2076  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.2151  decode.d3.loss_dice: 0.2019  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.2173  decode.d5.loss_cls: 0.0476  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.1908  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.2131  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.2198  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.1957
09/30 19:27:47 - mmengine - INFO - Iter(train) [ 85800/320000]  base_lr: 7.5508e-05 lr: 7.5508e-06  eta: 1 day, 4:21:10  time: 0.4416  data_time: 0.0099  memory: 5145  grad_norm: 145.7167  loss: 5.3831  decode.loss_cls: 0.0364  decode.loss_mask: 0.1924  decode.loss_dice: 0.2183  decode.d0.loss_cls: 0.8136  decode.d0.loss_mask: 0.1925  decode.d0.loss_dice: 0.2075  decode.d1.loss_cls: 0.1216  decode.d1.loss_mask: 0.1891  decode.d1.loss_dice: 0.1898  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.1900  decode.d2.loss_dice: 0.2085  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.1870  decode.d3.loss_dice: 0.1997  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.1887  decode.d4.loss_dice: 0.1995  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.2164  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2176  decode.d7.loss_cls: 0.0589  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.2152  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.1911  decode.d8.loss_dice: 0.2157
09/30 19:28:09 - mmengine - INFO - Iter(train) [ 85850/320000]  base_lr: 7.5494e-05 lr: 7.5494e-06  eta: 1 day, 4:20:49  time: 0.4419  data_time: 0.0099  memory: 5145  grad_norm: 97.8231  loss: 5.1101  decode.loss_cls: 0.1153  decode.loss_mask: 0.1781  decode.loss_dice: 0.1500  decode.d0.loss_cls: 0.7533  decode.d0.loss_mask: 0.1821  decode.d0.loss_dice: 0.1524  decode.d1.loss_cls: 0.1047  decode.d1.loss_mask: 0.1816  decode.d1.loss_dice: 0.1490  decode.d2.loss_cls: 0.0962  decode.d2.loss_mask: 0.1804  decode.d2.loss_dice: 0.1521  decode.d3.loss_cls: 0.1470  decode.d3.loss_mask: 0.1780  decode.d3.loss_dice: 0.1545  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 0.1809  decode.d4.loss_dice: 0.1483  decode.d5.loss_cls: 0.1042  decode.d5.loss_mask: 0.1840  decode.d5.loss_dice: 0.1591  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.1795  decode.d6.loss_dice: 0.1553  decode.d7.loss_cls: 0.1220  decode.d7.loss_mask: 0.1770  decode.d7.loss_dice: 0.1568  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.1800  decode.d8.loss_dice: 0.1446
09/30 19:28:31 - mmengine - INFO - Iter(train) [ 85900/320000]  base_lr: 7.5479e-05 lr: 7.5479e-06  eta: 1 day, 4:20:28  time: 0.4400  data_time: 0.0098  memory: 5145  grad_norm: 106.9757  loss: 7.2256  decode.loss_cls: 0.1707  decode.loss_mask: 0.2471  decode.loss_dice: 0.2382  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 0.2460  decode.d0.loss_dice: 0.2552  decode.d1.loss_cls: 0.1813  decode.d1.loss_mask: 0.2385  decode.d1.loss_dice: 0.2486  decode.d2.loss_cls: 0.1369  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.2465  decode.d3.loss_cls: 0.1498  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2372  decode.d4.loss_cls: 0.1608  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.2475  decode.d5.loss_cls: 0.1807  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.2450  decode.d6.loss_cls: 0.1746  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.2489  decode.d7.loss_cls: 0.1578  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.2568  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.2547
09/30 19:28:53 - mmengine - INFO - Iter(train) [ 85950/320000]  base_lr: 7.5465e-05 lr: 7.5465e-06  eta: 1 day, 4:20:06  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 83.0126  loss: 6.4148  decode.loss_cls: 0.1126  decode.loss_mask: 0.2247  decode.loss_dice: 0.2044  decode.d0.loss_cls: 0.8410  decode.d0.loss_mask: 0.2263  decode.d0.loss_dice: 0.2219  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.2244  decode.d1.loss_dice: 0.2070  decode.d2.loss_cls: 0.1102  decode.d2.loss_mask: 0.2246  decode.d2.loss_dice: 0.2119  decode.d3.loss_cls: 0.1008  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.2286  decode.d4.loss_cls: 0.1482  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.2142  decode.d5.loss_cls: 0.1344  decode.d5.loss_mask: 0.2386  decode.d5.loss_dice: 0.2523  decode.d6.loss_cls: 0.1144  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.2039  decode.d7.loss_cls: 0.1557  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.1264  decode.d8.loss_mask: 0.2261  decode.d8.loss_dice: 0.2277
09/30 19:29:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:29:15 - mmengine - INFO - Iter(train) [ 86000/320000]  base_lr: 7.5450e-05 lr: 7.5450e-06  eta: 1 day, 4:19:45  time: 0.4408  data_time: 0.0099  memory: 5129  grad_norm: 74.1511  loss: 6.3458  decode.loss_cls: 0.0134  decode.loss_mask: 0.3093  decode.loss_dice: 0.2250  decode.d0.loss_cls: 0.7300  decode.d0.loss_mask: 0.3203  decode.d0.loss_dice: 0.2242  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.2299  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.3133  decode.d2.loss_dice: 0.2172  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.3109  decode.d3.loss_dice: 0.2217  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.3111  decode.d4.loss_dice: 0.2259  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 0.3088  decode.d5.loss_dice: 0.2215  decode.d6.loss_cls: 0.0204  decode.d6.loss_mask: 0.3071  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.0187  decode.d7.loss_mask: 0.3135  decode.d7.loss_dice: 0.2305  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.3096  decode.d8.loss_dice: 0.2284
09/30 19:29:37 - mmengine - INFO - Iter(train) [ 86050/320000]  base_lr: 7.5436e-05 lr: 7.5436e-06  eta: 1 day, 4:19:24  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 20.2714  loss: 4.1614  decode.loss_cls: 0.0083  decode.loss_mask: 0.1686  decode.loss_dice: 0.1574  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.1711  decode.d0.loss_dice: 0.1555  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.1676  decode.d1.loss_dice: 0.1612  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.1694  decode.d2.loss_dice: 0.1587  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.1673  decode.d3.loss_dice: 0.1534  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.1679  decode.d4.loss_dice: 0.1559  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.1675  decode.d5.loss_dice: 0.1553  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.1695  decode.d6.loss_dice: 0.1590  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.1675  decode.d7.loss_dice: 0.1592  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.1661  decode.d8.loss_dice: 0.1590
09/30 19:29:59 - mmengine - INFO - Iter(train) [ 86100/320000]  base_lr: 7.5421e-05 lr: 7.5421e-06  eta: 1 day, 4:19:03  time: 0.4409  data_time: 0.0099  memory: 5119  grad_norm: 78.9896  loss: 6.0539  decode.loss_cls: 0.1229  decode.loss_mask: 0.2208  decode.loss_dice: 0.2043  decode.d0.loss_cls: 0.9077  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.2143  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.2100  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.2208  decode.d4.loss_dice: 0.1988  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.2200  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 0.2236  decode.d6.loss_dice: 0.2017  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.1173  decode.d8.loss_mask: 0.2217  decode.d8.loss_dice: 0.1932
09/30 19:30:22 - mmengine - INFO - Iter(train) [ 86150/320000]  base_lr: 7.5407e-05 lr: 7.5407e-06  eta: 1 day, 4:18:42  time: 0.4406  data_time: 0.0099  memory: 5119  grad_norm: 21.4611  loss: 5.3348  decode.loss_cls: 0.0245  decode.loss_mask: 0.2289  decode.loss_dice: 0.1915  decode.d0.loss_cls: 0.6481  decode.d0.loss_mask: 0.2355  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.2280  decode.d1.loss_dice: 0.1853  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.1907  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.1880  decode.d4.loss_cls: 0.0634  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.1878  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2250  decode.d7.loss_dice: 0.1879  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1861
09/30 19:30:44 - mmengine - INFO - Iter(train) [ 86200/320000]  base_lr: 7.5392e-05 lr: 7.5392e-06  eta: 1 day, 4:18:21  time: 0.4405  data_time: 0.0100  memory: 5129  grad_norm: 204.6387  loss: 11.3549  decode.loss_cls: 0.0557  decode.loss_mask: 1.3652  decode.loss_dice: 0.3048  decode.d0.loss_cls: 1.1348  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.2778  decode.d1.loss_cls: 0.2706  decode.d1.loss_mask: 0.2982  decode.d1.loss_dice: 0.2368  decode.d2.loss_cls: 0.1941  decode.d2.loss_mask: 0.2807  decode.d2.loss_dice: 0.2853  decode.d3.loss_cls: 0.2648  decode.d3.loss_mask: 0.3391  decode.d3.loss_dice: 0.2734  decode.d4.loss_cls: 0.2336  decode.d4.loss_mask: 0.2668  decode.d4.loss_dice: 0.2653  decode.d5.loss_cls: 0.2260  decode.d5.loss_mask: 0.2907  decode.d5.loss_dice: 0.2481  decode.d6.loss_cls: 0.1797  decode.d6.loss_mask: 1.0450  decode.d6.loss_dice: 0.2946  decode.d7.loss_cls: 0.1909  decode.d7.loss_mask: 0.3060  decode.d7.loss_dice: 0.2692  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 1.2940  decode.d8.loss_dice: 0.2976
09/30 19:31:06 - mmengine - INFO - Iter(train) [ 86250/320000]  base_lr: 7.5378e-05 lr: 7.5378e-06  eta: 1 day, 4:18:00  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 20.9545  loss: 4.5457  decode.loss_cls: 0.0052  decode.loss_mask: 0.2177  decode.loss_dice: 0.1527  decode.d0.loss_cls: 0.8069  decode.d0.loss_mask: 0.2210  decode.d0.loss_dice: 0.1541  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.2158  decode.d1.loss_dice: 0.1551  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.1530  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.2108  decode.d3.loss_dice: 0.1522  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1515  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.2133  decode.d5.loss_dice: 0.1524  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.1575  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2110  decode.d7.loss_dice: 0.1565  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2151  decode.d8.loss_dice: 0.1563
09/30 19:31:28 - mmengine - INFO - Iter(train) [ 86300/320000]  base_lr: 7.5363e-05 lr: 7.5363e-06  eta: 1 day, 4:17:39  time: 0.4406  data_time: 0.0100  memory: 5145  grad_norm: 304.8864  loss: 6.8415  decode.loss_cls: 0.0536  decode.loss_mask: 0.3355  decode.loss_dice: 0.2234  decode.d0.loss_cls: 0.8813  decode.d0.loss_mask: 0.3123  decode.d0.loss_dice: 0.2214  decode.d1.loss_cls: 0.1136  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2088  decode.d2.loss_cls: 0.1190  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.1354  decode.d3.loss_mask: 0.2407  decode.d3.loss_dice: 0.1989  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.3530  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.3490  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.3410  decode.d6.loss_dice: 0.1990  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.3423  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.3393  decode.d8.loss_dice: 0.2071
09/30 19:31:50 - mmengine - INFO - Iter(train) [ 86350/320000]  base_lr: 7.5349e-05 lr: 7.5349e-06  eta: 1 day, 4:17:18  time: 0.4414  data_time: 0.0100  memory: 5129  grad_norm: 23.9501  loss: 4.7158  decode.loss_cls: 0.0148  decode.loss_mask: 0.1974  decode.loss_dice: 0.1672  decode.d0.loss_cls: 0.9037  decode.d0.loss_mask: 0.2002  decode.d0.loss_dice: 0.1846  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.1958  decode.d1.loss_dice: 0.1636  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.1975  decode.d2.loss_dice: 0.1713  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.1647  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.1956  decode.d4.loss_dice: 0.1761  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.1954  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.1980  decode.d6.loss_dice: 0.1722  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.1987  decode.d7.loss_dice: 0.1705  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.1978  decode.d8.loss_dice: 0.1727
09/30 19:32:12 - mmengine - INFO - Iter(train) [ 86400/320000]  base_lr: 7.5334e-05 lr: 7.5334e-06  eta: 1 day, 4:16:57  time: 0.4414  data_time: 0.0101  memory: 5129  grad_norm: 47.0565  loss: 6.0975  decode.loss_cls: 0.0841  decode.loss_mask: 0.2299  decode.loss_dice: 0.2050  decode.d0.loss_cls: 0.8141  decode.d0.loss_mask: 0.2294  decode.d0.loss_dice: 0.1968  decode.d1.loss_cls: 0.1519  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1954  decode.d2.loss_cls: 0.1135  decode.d2.loss_mask: 0.2271  decode.d2.loss_dice: 0.1981  decode.d3.loss_cls: 0.1056  decode.d3.loss_mask: 0.2276  decode.d3.loss_dice: 0.1944  decode.d4.loss_cls: 0.1132  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.1996  decode.d6.loss_cls: 0.1047  decode.d6.loss_mask: 0.2367  decode.d6.loss_dice: 0.2132  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2090  decode.d8.loss_cls: 0.1036  decode.d8.loss_mask: 0.2288  decode.d8.loss_dice: 0.2080
09/30 19:32:34 - mmengine - INFO - Iter(train) [ 86450/320000]  base_lr: 7.5320e-05 lr: 7.5320e-06  eta: 1 day, 4:16:35  time: 0.4415  data_time: 0.0099  memory: 5129  grad_norm: 39.5493  loss: 5.9161  decode.loss_cls: 0.0134  decode.loss_mask: 0.1962  decode.loss_dice: 0.2678  decode.d0.loss_cls: 0.9143  decode.d0.loss_mask: 0.1979  decode.d0.loss_dice: 0.2622  decode.d1.loss_cls: 0.1924  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.2009  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.2680  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.2002  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.1938  decode.d5.loss_dice: 0.2480  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.1953  decode.d6.loss_dice: 0.2759  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.1969  decode.d7.loss_dice: 0.2597  decode.d8.loss_cls: 0.0149  decode.d8.loss_mask: 0.1993  decode.d8.loss_dice: 0.2838
09/30 19:32:56 - mmengine - INFO - Iter(train) [ 86500/320000]  base_lr: 7.5305e-05 lr: 7.5305e-06  eta: 1 day, 4:16:14  time: 0.4405  data_time: 0.0100  memory: 5129  grad_norm: 21.9644  loss: 4.5877  decode.loss_cls: 0.0055  decode.loss_mask: 0.2078  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.8384  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.1637  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.1619  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.2074  decode.d2.loss_dice: 0.1583  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.2076  decode.d3.loss_dice: 0.1554  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.2070  decode.d4.loss_dice: 0.1582  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.2077  decode.d5.loss_dice: 0.1584  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.1573  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.1617  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.2070  decode.d8.loss_dice: 0.1600
09/30 19:33:18 - mmengine - INFO - Iter(train) [ 86550/320000]  base_lr: 7.5291e-05 lr: 7.5291e-06  eta: 1 day, 4:15:53  time: 0.4404  data_time: 0.0099  memory: 5129  grad_norm: 23.1061  loss: 5.1852  decode.loss_cls: 0.0026  decode.loss_mask: 0.2437  decode.loss_dice: 0.1967  decode.d0.loss_cls: 0.7905  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.1892  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2446  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2447  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.1900  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2489  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.1910  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.2457  decode.d6.loss_dice: 0.1909  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.2433  decode.d7.loss_dice: 0.1900  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.1926
09/30 19:33:40 - mmengine - INFO - Iter(train) [ 86600/320000]  base_lr: 7.5276e-05 lr: 7.5276e-06  eta: 1 day, 4:15:32  time: 0.4406  data_time: 0.0100  memory: 5129  grad_norm: 55.4258  loss: 5.4563  decode.loss_cls: 0.0277  decode.loss_mask: 0.2565  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.8295  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.1766  decode.d1.loss_cls: 0.1085  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.1798  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.1702  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.1750  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.1663  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.2565  decode.d5.loss_dice: 0.1720  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.2558  decode.d6.loss_dice: 0.1744  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.1662  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.2513  decode.d8.loss_dice: 0.1730
09/30 19:34:02 - mmengine - INFO - Iter(train) [ 86650/320000]  base_lr: 7.5262e-05 lr: 7.5262e-06  eta: 1 day, 4:15:11  time: 0.4406  data_time: 0.0101  memory: 5129  grad_norm: 80.6795  loss: 5.6362  decode.loss_cls: 0.1221  decode.loss_mask: 0.2177  decode.loss_dice: 0.1744  decode.d0.loss_cls: 0.8508  decode.d0.loss_mask: 0.2193  decode.d0.loss_dice: 0.1898  decode.d1.loss_cls: 0.0886  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1804  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.1783  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.1710  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.1795  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 0.2154  decode.d5.loss_dice: 0.1831  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.2209  decode.d6.loss_dice: 0.1747  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.1146  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.1728
09/30 19:34:24 - mmengine - INFO - Iter(train) [ 86700/320000]  base_lr: 7.5247e-05 lr: 7.5247e-06  eta: 1 day, 4:14:50  time: 0.4392  data_time: 0.0097  memory: 5129  grad_norm: 66.4806  loss: 6.5523  decode.loss_cls: 0.0337  decode.loss_mask: 0.2945  decode.loss_dice: 0.2611  decode.d0.loss_cls: 0.8197  decode.d0.loss_mask: 0.2942  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.3032  decode.d1.loss_dice: 0.2498  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.3025  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.3026  decode.d3.loss_dice: 0.2505  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.2933  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.2487  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.2938  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.2934  decode.d7.loss_dice: 0.2492  decode.d8.loss_cls: 0.0268  decode.d8.loss_mask: 0.2923  decode.d8.loss_dice: 0.2586
09/30 19:34:46 - mmengine - INFO - Iter(train) [ 86750/320000]  base_lr: 7.5233e-05 lr: 7.5233e-06  eta: 1 day, 4:14:29  time: 0.4407  data_time: 0.0100  memory: 5145  grad_norm: 60.5914  loss: 7.0406  decode.loss_cls: 0.0546  decode.loss_mask: 0.3265  decode.loss_dice: 0.2838  decode.d0.loss_cls: 0.8308  decode.d0.loss_mask: 0.2569  decode.d0.loss_dice: 0.2652  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.2875  decode.d1.loss_dice: 0.2656  decode.d2.loss_cls: 0.1366  decode.d2.loss_mask: 0.2603  decode.d2.loss_dice: 0.2578  decode.d3.loss_cls: 0.1022  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.2612  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.2644  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.2689  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.2857  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.2827  decode.d7.loss_dice: 0.2583  decode.d8.loss_cls: 0.0941  decode.d8.loss_mask: 0.2802  decode.d8.loss_dice: 0.2681
09/30 19:35:08 - mmengine - INFO - Iter(train) [ 86800/320000]  base_lr: 7.5218e-05 lr: 7.5218e-06  eta: 1 day, 4:14:07  time: 0.4401  data_time: 0.0100  memory: 5120  grad_norm: 89.5779  loss: 7.1752  decode.loss_cls: 0.1474  decode.loss_mask: 0.2516  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.8790  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.2620  decode.d1.loss_cls: 0.1352  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.2598  decode.d2.loss_cls: 0.1350  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.2571  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2481  decode.d3.loss_dice: 0.2523  decode.d4.loss_cls: 0.1371  decode.d4.loss_mask: 0.2525  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.2495  decode.d5.loss_dice: 0.2621  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.2495  decode.d6.loss_dice: 0.2562  decode.d7.loss_cls: 0.1344  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2604  decode.d8.loss_cls: 0.1433  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2471
09/30 19:35:30 - mmengine - INFO - Iter(train) [ 86850/320000]  base_lr: 7.5204e-05 lr: 7.5204e-06  eta: 1 day, 4:13:46  time: 0.4400  data_time: 0.0101  memory: 5145  grad_norm: 20.9833  loss: 4.9842  decode.loss_cls: 0.0040  decode.loss_mask: 0.2390  decode.loss_dice: 0.1906  decode.d0.loss_cls: 0.6370  decode.d0.loss_mask: 0.2429  decode.d0.loss_dice: 0.1885  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2391  decode.d1.loss_dice: 0.1929  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.1899  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.2393  decode.d5.loss_dice: 0.1957  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.2004
09/30 19:35:52 - mmengine - INFO - Iter(train) [ 86900/320000]  base_lr: 7.5189e-05 lr: 7.5189e-06  eta: 1 day, 4:13:25  time: 0.4401  data_time: 0.0100  memory: 5129  grad_norm: 48.4237  loss: 6.7953  decode.loss_cls: 0.1613  decode.loss_mask: 0.2513  decode.loss_dice: 0.2076  decode.d0.loss_cls: 0.7772  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.2052  decode.d1.loss_cls: 0.1636  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.1998  decode.d2.loss_cls: 0.1588  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.1911  decode.d3.loss_cls: 0.1567  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.1915  decode.d4.loss_cls: 0.1924  decode.d4.loss_mask: 0.2491  decode.d4.loss_dice: 0.1895  decode.d5.loss_cls: 0.1805  decode.d5.loss_mask: 0.2461  decode.d5.loss_dice: 0.1959  decode.d6.loss_cls: 0.1636  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.1941  decode.d7.loss_cls: 0.1766  decode.d7.loss_mask: 0.2610  decode.d7.loss_dice: 0.2024  decode.d8.loss_cls: 0.1684  decode.d8.loss_mask: 0.2457  decode.d8.loss_dice: 0.1923
09/30 19:36:14 - mmengine - INFO - Iter(train) [ 86950/320000]  base_lr: 7.5174e-05 lr: 7.5174e-06  eta: 1 day, 4:13:04  time: 0.4413  data_time: 0.0099  memory: 5145  grad_norm: 39.6861  loss: 4.8415  decode.loss_cls: 0.0066  decode.loss_mask: 0.2112  decode.loss_dice: 0.1786  decode.d0.loss_cls: 0.8676  decode.d0.loss_mask: 0.2131  decode.d0.loss_dice: 0.1832  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.2112  decode.d1.loss_dice: 0.1779  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.2156  decode.d2.loss_dice: 0.1800  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.1806  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.1768  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.1771  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.2136  decode.d6.loss_dice: 0.1794  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.1776  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2108  decode.d8.loss_dice: 0.1759
09/30 19:36:36 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:36:36 - mmengine - INFO - Iter(train) [ 87000/320000]  base_lr: 7.5160e-05 lr: 7.5160e-06  eta: 1 day, 4:12:43  time: 0.4408  data_time: 0.0101  memory: 5129  grad_norm: 37.0997  loss: 5.0720  decode.loss_cls: 0.0579  decode.loss_mask: 0.2041  decode.loss_dice: 0.1717  decode.d0.loss_cls: 0.7850  decode.d0.loss_mask: 0.2053  decode.d0.loss_dice: 0.1768  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.2055  decode.d1.loss_dice: 0.1785  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.2023  decode.d2.loss_dice: 0.1763  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.2041  decode.d3.loss_dice: 0.1723  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 0.2010  decode.d5.loss_dice: 0.1749  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.2035  decode.d6.loss_dice: 0.1779  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1630  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.1747
09/30 19:36:59 - mmengine - INFO - Iter(train) [ 87050/320000]  base_lr: 7.5145e-05 lr: 7.5145e-06  eta: 1 day, 4:12:22  time: 0.4413  data_time: 0.0100  memory: 5129  grad_norm: 68.7213  loss: 5.5478  decode.loss_cls: 0.0056  decode.loss_mask: 0.2434  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.8543  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2141  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2203  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2259  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2241  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.2258  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2408  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.2398  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.2185  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.2378  decode.d8.loss_dice: 0.2195
09/30 19:37:21 - mmengine - INFO - Iter(train) [ 87100/320000]  base_lr: 7.5131e-05 lr: 7.5131e-06  eta: 1 day, 4:12:01  time: 0.4416  data_time: 0.0101  memory: 5129  grad_norm: 83.8057  loss: 9.9445  decode.loss_cls: 0.2119  decode.loss_mask: 0.3836  decode.loss_dice: 0.3166  decode.d0.loss_cls: 0.9691  decode.d0.loss_mask: 0.4007  decode.d0.loss_dice: 0.3203  decode.d1.loss_cls: 0.2370  decode.d1.loss_mask: 0.3753  decode.d1.loss_dice: 0.3370  decode.d2.loss_cls: 0.1892  decode.d2.loss_mask: 0.3740  decode.d2.loss_dice: 0.3301  decode.d3.loss_cls: 0.2028  decode.d3.loss_mask: 0.3744  decode.d3.loss_dice: 0.3285  decode.d4.loss_cls: 0.1639  decode.d4.loss_mask: 0.3727  decode.d4.loss_dice: 0.3381  decode.d5.loss_cls: 0.2275  decode.d5.loss_mask: 0.3871  decode.d5.loss_dice: 0.3170  decode.d6.loss_cls: 0.2856  decode.d6.loss_mask: 0.3798  decode.d6.loss_dice: 0.3103  decode.d7.loss_cls: 0.2219  decode.d7.loss_mask: 0.3793  decode.d7.loss_dice: 0.3145  decode.d8.loss_cls: 0.1864  decode.d8.loss_mask: 0.3864  decode.d8.loss_dice: 0.3233
09/30 19:37:43 - mmengine - INFO - Iter(train) [ 87150/320000]  base_lr: 7.5116e-05 lr: 7.5116e-06  eta: 1 day, 4:11:40  time: 0.4399  data_time: 0.0099  memory: 5145  grad_norm: 353.6257  loss: 6.6745  decode.loss_cls: 0.0659  decode.loss_mask: 0.3048  decode.loss_dice: 0.2040  decode.d0.loss_cls: 0.9714  decode.d0.loss_mask: 0.2396  decode.d0.loss_dice: 0.2219  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.2115  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.2108  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.3214  decode.d3.loss_dice: 0.2121  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.3118  decode.d4.loss_dice: 0.2052  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.3091  decode.d5.loss_dice: 0.2132  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.3063  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.3069  decode.d7.loss_dice: 0.2066  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.2994  decode.d8.loss_dice: 0.2025
09/30 19:38:05 - mmengine - INFO - Iter(train) [ 87200/320000]  base_lr: 7.5102e-05 lr: 7.5102e-06  eta: 1 day, 4:11:18  time: 0.4408  data_time: 0.0100  memory: 5120  grad_norm: 44.6950  loss: 6.3000  decode.loss_cls: 0.0435  decode.loss_mask: 0.2971  decode.loss_dice: 0.2026  decode.d0.loss_cls: 0.7829  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.2081  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.2954  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.2138  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.2996  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.2960  decode.d4.loss_dice: 0.2059  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.3008  decode.d5.loss_dice: 0.2029  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.2959  decode.d6.loss_dice: 0.2056  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.2963  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.2955  decode.d8.loss_dice: 0.2035
09/30 19:38:27 - mmengine - INFO - Iter(train) [ 87250/320000]  base_lr: 7.5087e-05 lr: 7.5087e-06  eta: 1 day, 4:10:57  time: 0.4409  data_time: 0.0098  memory: 5129  grad_norm: 25.9868  loss: 4.5490  decode.loss_cls: 0.0149  decode.loss_mask: 0.1785  decode.loss_dice: 0.1676  decode.d0.loss_cls: 0.8302  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1700  decode.d1.loss_cls: 0.0888  decode.d1.loss_mask: 0.1811  decode.d1.loss_dice: 0.1648  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.1807  decode.d2.loss_dice: 0.1626  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.1825  decode.d3.loss_dice: 0.1639  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.1813  decode.d4.loss_dice: 0.1656  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.1810  decode.d5.loss_dice: 0.1724  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.1798  decode.d6.loss_dice: 0.1681  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.1801  decode.d7.loss_dice: 0.1704  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.1825  decode.d8.loss_dice: 0.1713
09/30 19:38:49 - mmengine - INFO - Iter(train) [ 87300/320000]  base_lr: 7.5073e-05 lr: 7.5073e-06  eta: 1 day, 4:10:37  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 49.7741  loss: 6.5945  decode.loss_cls: 0.1146  decode.loss_mask: 0.2425  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.8790  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.2163  decode.d1.loss_cls: 0.1350  decode.d1.loss_mask: 0.2435  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.2485  decode.d2.loss_dice: 0.2309  decode.d3.loss_cls: 0.1234  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 0.2499  decode.d4.loss_dice: 0.2213  decode.d5.loss_cls: 0.1256  decode.d5.loss_mask: 0.2433  decode.d5.loss_dice: 0.2149  decode.d6.loss_cls: 0.1170  decode.d6.loss_mask: 0.2436  decode.d6.loss_dice: 0.2050  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2218  decode.d8.loss_cls: 0.1131  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.2091
09/30 19:39:11 - mmengine - INFO - Iter(train) [ 87350/320000]  base_lr: 7.5058e-05 lr: 7.5058e-06  eta: 1 day, 4:10:16  time: 0.4401  data_time: 0.0097  memory: 5145  grad_norm: 19.7852  loss: 4.5955  decode.loss_cls: 0.0291  decode.loss_mask: 0.1861  decode.loss_dice: 0.1634  decode.d0.loss_cls: 0.9109  decode.d0.loss_mask: 0.1873  decode.d0.loss_dice: 0.1599  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.1858  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.1864  decode.d2.loss_dice: 0.1601  decode.d3.loss_cls: 0.0185  decode.d3.loss_mask: 0.1854  decode.d3.loss_dice: 0.1652  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.1563  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.1844  decode.d5.loss_dice: 0.1597  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.1853  decode.d6.loss_dice: 0.1540  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.1863  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.1867  decode.d8.loss_dice: 0.1595
09/30 19:39:33 - mmengine - INFO - Iter(train) [ 87400/320000]  base_lr: 7.5044e-05 lr: 7.5044e-06  eta: 1 day, 4:09:54  time: 0.4423  data_time: 0.0101  memory: 5120  grad_norm: 88.6706  loss: 5.0027  decode.loss_cls: 0.0201  decode.loss_mask: 0.2248  decode.loss_dice: 0.2036  decode.d0.loss_cls: 0.7377  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.1779  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.2182  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.1973  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.2174  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.2154  decode.d4.loss_dice: 0.1805  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.1788  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.1817  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.2140  decode.d7.loss_dice: 0.1837  decode.d8.loss_cls: 0.0241  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.1955
09/30 19:39:55 - mmengine - INFO - Iter(train) [ 87450/320000]  base_lr: 7.5029e-05 lr: 7.5029e-06  eta: 1 day, 4:09:33  time: 0.4414  data_time: 0.0100  memory: 5145  grad_norm: 38.2701  loss: 5.5104  decode.loss_cls: 0.0654  decode.loss_mask: 0.1873  decode.loss_dice: 0.2369  decode.d0.loss_cls: 0.8495  decode.d0.loss_mask: 0.1807  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.2459  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.1830  decode.d2.loss_dice: 0.2493  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.1843  decode.d3.loss_dice: 0.2492  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.1806  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.1820  decode.d5.loss_dice: 0.2471  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.1812  decode.d6.loss_dice: 0.2304  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.1832  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.1824  decode.d8.loss_dice: 0.2404
09/30 19:40:17 - mmengine - INFO - Iter(train) [ 87500/320000]  base_lr: 7.5015e-05 lr: 7.5015e-06  eta: 1 day, 4:09:12  time: 0.4409  data_time: 0.0100  memory: 5129  grad_norm: 38.1637  loss: 5.8640  decode.loss_cls: 0.0371  decode.loss_mask: 0.2320  decode.loss_dice: 0.1947  decode.d0.loss_cls: 0.8687  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.1633  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.1926  decode.d2.loss_cls: 0.0985  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2024  decode.d4.loss_cls: 0.0894  decode.d4.loss_mask: 0.2324  decode.d4.loss_dice: 0.1901  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.0850  decode.d6.loss_mask: 0.2333  decode.d6.loss_dice: 0.2118  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.2291  decode.d7.loss_dice: 0.1979  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.2309  decode.d8.loss_dice: 0.1932
09/30 19:40:39 - mmengine - INFO - Iter(train) [ 87550/320000]  base_lr: 7.5000e-05 lr: 7.5000e-06  eta: 1 day, 4:08:51  time: 0.4407  data_time: 0.0097  memory: 5145  grad_norm: 75.5770  loss: 7.3042  decode.loss_cls: 0.1244  decode.loss_mask: 0.2536  decode.loss_dice: 0.2288  decode.d0.loss_cls: 1.0591  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.2103  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.2596  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 0.2603  decode.d2.loss_dice: 0.2103  decode.d3.loss_cls: 0.1561  decode.d3.loss_mask: 0.2872  decode.d3.loss_dice: 0.2250  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2057  decode.d5.loss_cls: 0.1636  decode.d5.loss_mask: 0.2935  decode.d5.loss_dice: 0.2185  decode.d6.loss_cls: 0.1643  decode.d6.loss_mask: 0.2753  decode.d6.loss_dice: 0.2153  decode.d7.loss_cls: 0.1643  decode.d7.loss_mask: 0.2438  decode.d7.loss_dice: 0.2020  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 0.2842  decode.d8.loss_dice: 0.2367
09/30 19:41:01 - mmengine - INFO - Iter(train) [ 87600/320000]  base_lr: 7.4986e-05 lr: 7.4986e-06  eta: 1 day, 4:08:30  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 28.6010  loss: 5.7624  decode.loss_cls: 0.1186  decode.loss_mask: 0.1656  decode.loss_dice: 0.1778  decode.d0.loss_cls: 1.0300  decode.d0.loss_mask: 0.1673  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 0.1605  decode.d1.loss_dice: 0.1835  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.1633  decode.d2.loss_dice: 0.1991  decode.d3.loss_cls: 0.1316  decode.d3.loss_mask: 0.1685  decode.d3.loss_dice: 0.1859  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 0.1647  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.1423  decode.d5.loss_mask: 0.1639  decode.d5.loss_dice: 0.1875  decode.d6.loss_cls: 0.1232  decode.d6.loss_mask: 0.1640  decode.d6.loss_dice: 0.1905  decode.d7.loss_cls: 0.1469  decode.d7.loss_mask: 0.1649  decode.d7.loss_dice: 0.1925  decode.d8.loss_cls: 0.1350  decode.d8.loss_mask: 0.1653  decode.d8.loss_dice: 0.1881
09/30 19:41:23 - mmengine - INFO - Iter(train) [ 87650/320000]  base_lr: 7.4971e-05 lr: 7.4971e-06  eta: 1 day, 4:08:08  time: 0.4404  data_time: 0.0101  memory: 5129  grad_norm: 54.7948  loss: 7.0708  decode.loss_cls: 0.0895  decode.loss_mask: 0.2635  decode.loss_dice: 0.2388  decode.d0.loss_cls: 0.9497  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.2594  decode.d1.loss_cls: 0.1743  decode.d1.loss_mask: 0.2706  decode.d1.loss_dice: 0.2489  decode.d2.loss_cls: 0.1306  decode.d2.loss_mask: 0.2691  decode.d2.loss_dice: 0.2438  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2647  decode.d4.loss_cls: 0.1273  decode.d4.loss_mask: 0.2672  decode.d4.loss_dice: 0.2312  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.2651  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.2675  decode.d6.loss_dice: 0.2259  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.1029  decode.d8.loss_mask: 0.2659  decode.d8.loss_dice: 0.2407
09/30 19:41:45 - mmengine - INFO - Iter(train) [ 87700/320000]  base_lr: 7.4957e-05 lr: 7.4957e-06  eta: 1 day, 4:07:47  time: 0.4395  data_time: 0.0098  memory: 5159  grad_norm: 86.7047  loss: 7.1337  decode.loss_cls: 0.1823  decode.loss_mask: 0.2261  decode.loss_dice: 0.2247  decode.d0.loss_cls: 0.9401  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.1968  decode.d1.loss_cls: 0.2267  decode.d1.loss_mask: 0.2240  decode.d1.loss_dice: 0.1997  decode.d2.loss_cls: 0.1829  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.2141  decode.d3.loss_cls: 0.1864  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.2176  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.2042  decode.d5.loss_mask: 0.2165  decode.d5.loss_dice: 0.2075  decode.d6.loss_cls: 0.2296  decode.d6.loss_mask: 0.2251  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.2296  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.2136  decode.d8.loss_cls: 0.1848  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.2180
09/30 19:42:07 - mmengine - INFO - Iter(train) [ 87750/320000]  base_lr: 7.4942e-05 lr: 7.4942e-06  eta: 1 day, 4:07:26  time: 0.4406  data_time: 0.0099  memory: 5145  grad_norm: 19.8962  loss: 5.0905  decode.loss_cls: 0.0160  decode.loss_mask: 0.2323  decode.loss_dice: 0.1762  decode.d0.loss_cls: 0.7879  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.1817  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.1719  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.2328  decode.d2.loss_dice: 0.1797  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 0.2319  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.2318  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0296  decode.d6.loss_mask: 0.2293  decode.d6.loss_dice: 0.1795  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.1829  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.2282  decode.d8.loss_dice: 0.1766
09/30 19:42:29 - mmengine - INFO - Iter(train) [ 87800/320000]  base_lr: 7.4928e-05 lr: 7.4928e-06  eta: 1 day, 4:07:05  time: 0.4405  data_time: 0.0098  memory: 5120  grad_norm: 47.8909  loss: 4.9940  decode.loss_cls: 0.0314  decode.loss_mask: 0.1910  decode.loss_dice: 0.1976  decode.d0.loss_cls: 0.7676  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.1931  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.1906  decode.d1.loss_dice: 0.1852  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.1891  decode.d2.loss_dice: 0.1864  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.1885  decode.d3.loss_dice: 0.1950  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.1905  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.2015  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.1903  decode.d6.loss_dice: 0.2023  decode.d7.loss_cls: 0.0311  decode.d7.loss_mask: 0.1888  decode.d7.loss_dice: 0.1956  decode.d8.loss_cls: 0.0234  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.1931
09/30 19:42:52 - mmengine - INFO - Iter(train) [ 87850/320000]  base_lr: 7.4913e-05 lr: 7.4913e-06  eta: 1 day, 4:06:44  time: 0.4404  data_time: 0.0100  memory: 5129  grad_norm: 18.7692  loss: 4.3175  decode.loss_cls: 0.0020  decode.loss_mask: 0.2024  decode.loss_dice: 0.1444  decode.d0.loss_cls: 0.8517  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.1408  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.2015  decode.d1.loss_dice: 0.1464  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.2008  decode.d2.loss_dice: 0.1425  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.2043  decode.d3.loss_dice: 0.1426  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.1399  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2011  decode.d5.loss_dice: 0.1450  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.2009  decode.d6.loss_dice: 0.1402  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.1419  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2015  decode.d8.loss_dice: 0.1439
09/30 19:43:14 - mmengine - INFO - Iter(train) [ 87900/320000]  base_lr: 7.4899e-05 lr: 7.4899e-06  eta: 1 day, 4:06:23  time: 0.4415  data_time: 0.0101  memory: 5129  grad_norm: 82.4633  loss: 5.8935  decode.loss_cls: 0.0863  decode.loss_mask: 0.2182  decode.loss_dice: 0.2132  decode.d0.loss_cls: 0.7262  decode.d0.loss_mask: 0.2268  decode.d0.loss_dice: 0.2015  decode.d1.loss_cls: 0.1441  decode.d1.loss_mask: 0.2218  decode.d1.loss_dice: 0.1900  decode.d2.loss_cls: 0.1277  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.2139  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.1965  decode.d4.loss_cls: 0.0965  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.1911  decode.d5.loss_cls: 0.0869  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.2097  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.2228  decode.d6.loss_dice: 0.2183  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.2215  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.1936
09/30 19:43:36 - mmengine - INFO - Iter(train) [ 87950/320000]  base_lr: 7.4884e-05 lr: 7.4884e-06  eta: 1 day, 4:06:02  time: 0.4411  data_time: 0.0100  memory: 5129  grad_norm: 158.2170  loss: 4.8821  decode.loss_cls: 0.0660  decode.loss_mask: 0.1837  decode.loss_dice: 0.1655  decode.d0.loss_cls: 0.8400  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1702  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.1894  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.1854  decode.d2.loss_dice: 0.1725  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.1850  decode.d3.loss_dice: 0.1655  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.1818  decode.d4.loss_dice: 0.1640  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.1838  decode.d5.loss_dice: 0.1673  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.1843  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.1868  decode.d7.loss_dice: 0.1804  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.1826  decode.d8.loss_dice: 0.1670
09/30 19:43:58 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:43:58 - mmengine - INFO - Iter(train) [ 88000/320000]  base_lr: 7.4870e-05 lr: 7.4870e-06  eta: 1 day, 4:05:40  time: 0.4401  data_time: 0.0099  memory: 5129  grad_norm: 43.1011  loss: 5.2139  decode.loss_cls: 0.0201  decode.loss_mask: 0.1808  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.8703  decode.d0.loss_mask: 0.1840  decode.d0.loss_dice: 0.1980  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.1832  decode.d1.loss_dice: 0.2053  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.1806  decode.d2.loss_dice: 0.2149  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.1804  decode.d4.loss_dice: 0.2148  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.1811  decode.d5.loss_dice: 0.2051  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.1813  decode.d6.loss_dice: 0.1907  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.1787  decode.d7.loss_dice: 0.2027  decode.d8.loss_cls: 0.0827  decode.d8.loss_mask: 0.1813  decode.d8.loss_dice: 0.2081
09/30 19:44:20 - mmengine - INFO - Iter(train) [ 88050/320000]  base_lr: 7.4855e-05 lr: 7.4855e-06  eta: 1 day, 4:05:19  time: 0.4405  data_time: 0.0102  memory: 5129  grad_norm: 17.5219  loss: 4.5478  decode.loss_cls: 0.0085  decode.loss_mask: 0.2142  decode.loss_dice: 0.1480  decode.d0.loss_cls: 0.8383  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.1478  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.2143  decode.d1.loss_dice: 0.1487  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.1504  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.2140  decode.d3.loss_dice: 0.1476  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2134  decode.d4.loss_dice: 0.1486  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.2161  decode.d5.loss_dice: 0.1540  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.1483  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.1491  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.2151  decode.d8.loss_dice: 0.1492
09/30 19:44:42 - mmengine - INFO - Iter(train) [ 88100/320000]  base_lr: 7.4841e-05 lr: 7.4841e-06  eta: 1 day, 4:04:58  time: 0.4401  data_time: 0.0096  memory: 5145  grad_norm: 44.4429  loss: 5.0678  decode.loss_cls: 0.0505  decode.loss_mask: 0.1961  decode.loss_dice: 0.1809  decode.d0.loss_cls: 0.8247  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.1989  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.1954  decode.d1.loss_dice: 0.1808  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.1938  decode.d2.loss_dice: 0.1785  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.1959  decode.d3.loss_dice: 0.1793  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.1942  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.1871  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.1958  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.1937  decode.d7.loss_dice: 0.1789  decode.d8.loss_cls: 0.0300  decode.d8.loss_mask: 0.1966  decode.d8.loss_dice: 0.1955
09/30 19:45:04 - mmengine - INFO - Iter(train) [ 88150/320000]  base_lr: 7.4826e-05 lr: 7.4826e-06  eta: 1 day, 4:04:37  time: 0.4389  data_time: 0.0098  memory: 5129  grad_norm: 55.4888  loss: 6.2826  decode.loss_cls: 0.0605  decode.loss_mask: 0.2906  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.7241  decode.d0.loss_mask: 0.2879  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.1900  decode.d3.loss_cls: 0.0836  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.1925  decode.d4.loss_cls: 0.0918  decode.d4.loss_mask: 0.2840  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.1032  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.1906  decode.d6.loss_cls: 0.0881  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.1941  decode.d7.loss_cls: 0.0885  decode.d7.loss_mask: 0.2867  decode.d7.loss_dice: 0.1903  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.1990
09/30 19:45:26 - mmengine - INFO - Iter(train) [ 88200/320000]  base_lr: 7.4811e-05 lr: 7.4811e-06  eta: 1 day, 4:04:15  time: 0.4394  data_time: 0.0098  memory: 5129  grad_norm: 35.9339  loss: 5.1315  decode.loss_cls: 0.0479  decode.loss_mask: 0.1905  decode.loss_dice: 0.1751  decode.d0.loss_cls: 0.8804  decode.d0.loss_mask: 0.1967  decode.d0.loss_dice: 0.2073  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1775  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.1894  decode.d2.loss_dice: 0.1913  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.1910  decode.d3.loss_dice: 0.1879  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.1787  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.1905  decode.d5.loss_dice: 0.1865  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.1876  decode.d6.loss_dice: 0.1828  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.1886  decode.d7.loss_dice: 0.1859  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.1898  decode.d8.loss_dice: 0.1990
09/30 19:45:48 - mmengine - INFO - Iter(train) [ 88250/320000]  base_lr: 7.4797e-05 lr: 7.4797e-06  eta: 1 day, 4:03:54  time: 0.4406  data_time: 0.0100  memory: 5129  grad_norm: 53.0271  loss: 7.3540  decode.loss_cls: 0.1684  decode.loss_mask: 0.2509  decode.loss_dice: 0.2569  decode.d0.loss_cls: 1.0608  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.2701  decode.d1.loss_cls: 0.1535  decode.d1.loss_mask: 0.2486  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.1301  decode.d2.loss_mask: 0.2487  decode.d2.loss_dice: 0.2518  decode.d3.loss_cls: 0.1520  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.1217  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.2436  decode.d5.loss_cls: 0.1387  decode.d5.loss_mask: 0.2457  decode.d5.loss_dice: 0.2679  decode.d6.loss_cls: 0.1487  decode.d6.loss_mask: 0.2466  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.0958  decode.d7.loss_mask: 0.2475  decode.d7.loss_dice: 0.2594  decode.d8.loss_cls: 0.1607  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2585
09/30 19:46:10 - mmengine - INFO - Iter(train) [ 88300/320000]  base_lr: 7.4782e-05 lr: 7.4782e-06  eta: 1 day, 4:03:33  time: 0.4402  data_time: 0.0099  memory: 5129  grad_norm: 99.8278  loss: 7.7397  decode.loss_cls: 0.2069  decode.loss_mask: 0.2592  decode.loss_dice: 0.2599  decode.d0.loss_cls: 0.7659  decode.d0.loss_mask: 0.2679  decode.d0.loss_dice: 0.2699  decode.d1.loss_cls: 0.1749  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.2884  decode.d2.loss_cls: 0.1716  decode.d2.loss_mask: 0.2636  decode.d2.loss_dice: 0.2637  decode.d3.loss_cls: 0.1748  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.2564  decode.d4.loss_cls: 0.2140  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.1745  decode.d5.loss_mask: 0.2591  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.1684  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.2647  decode.d7.loss_cls: 0.2295  decode.d7.loss_mask: 0.2587  decode.d7.loss_dice: 0.2668  decode.d8.loss_cls: 0.1805  decode.d8.loss_mask: 0.2578  decode.d8.loss_dice: 0.2626
09/30 19:46:32 - mmengine - INFO - Iter(train) [ 88350/320000]  base_lr: 7.4768e-05 lr: 7.4768e-06  eta: 1 day, 4:03:12  time: 0.4402  data_time: 0.0100  memory: 5130  grad_norm: 39.7770  loss: 4.9114  decode.loss_cls: 0.0214  decode.loss_mask: 0.2258  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.7925  decode.d0.loss_mask: 0.2292  decode.d0.loss_dice: 0.1754  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.1847  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2246  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.1717  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.1671  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.2250  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.1692  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.2250  decode.d8.loss_dice: 0.1687
09/30 19:46:54 - mmengine - INFO - Iter(train) [ 88400/320000]  base_lr: 7.4753e-05 lr: 7.4753e-06  eta: 1 day, 4:02:51  time: 0.4406  data_time: 0.0100  memory: 5129  grad_norm: 28.3406  loss: 5.3417  decode.loss_cls: 0.0145  decode.loss_mask: 0.2188  decode.loss_dice: 0.2110  decode.d0.loss_cls: 0.8496  decode.d0.loss_mask: 0.2242  decode.d0.loss_dice: 0.2098  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.2141  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2085  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2090  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.2065  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.2233  decode.d5.loss_dice: 0.2093  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.2192  decode.d6.loss_dice: 0.2094  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.2175  decode.d8.loss_dice: 0.2079
09/30 19:47:16 - mmengine - INFO - Iter(train) [ 88450/320000]  base_lr: 7.4739e-05 lr: 7.4739e-06  eta: 1 day, 4:02:30  time: 0.4410  data_time: 0.0100  memory: 5129  grad_norm: 100.2327  loss: 6.7634  decode.loss_cls: 0.1757  decode.loss_mask: 0.2537  decode.loss_dice: 0.2083  decode.d0.loss_cls: 0.8368  decode.d0.loss_mask: 0.2603  decode.d0.loss_dice: 0.1985  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 0.2619  decode.d1.loss_dice: 0.2142  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2583  decode.d2.loss_dice: 0.2075  decode.d3.loss_cls: 0.1294  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.1993  decode.d4.loss_cls: 0.1282  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.2338  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.2577  decode.d6.loss_dice: 0.2048  decode.d7.loss_cls: 0.0693  decode.d7.loss_mask: 0.2721  decode.d7.loss_dice: 0.2305  decode.d8.loss_cls: 0.1410  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.1994
09/30 19:47:38 - mmengine - INFO - Iter(train) [ 88500/320000]  base_lr: 7.4724e-05 lr: 7.4724e-06  eta: 1 day, 4:02:08  time: 0.4405  data_time: 0.0096  memory: 5159  grad_norm: 121.6783  loss: 7.5700  decode.loss_cls: 0.2811  decode.loss_mask: 0.2197  decode.loss_dice: 0.2846  decode.d0.loss_cls: 1.0633  decode.d0.loss_mask: 0.1916  decode.d0.loss_dice: 0.2258  decode.d1.loss_cls: 0.2741  decode.d1.loss_mask: 0.2119  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.2927  decode.d2.loss_mask: 0.1679  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.2440  decode.d3.loss_mask: 0.1771  decode.d3.loss_dice: 0.2062  decode.d4.loss_cls: 0.1902  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.2589  decode.d5.loss_cls: 0.2141  decode.d5.loss_mask: 0.1928  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 0.1936  decode.d6.loss_dice: 0.2674  decode.d7.loss_cls: 0.2187  decode.d7.loss_mask: 0.1915  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.2321  decode.d8.loss_mask: 0.1858  decode.d8.loss_dice: 0.2473
09/30 19:48:00 - mmengine - INFO - Iter(train) [ 88550/320000]  base_lr: 7.4710e-05 lr: 7.4710e-06  eta: 1 day, 4:01:47  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 47.7528  loss: 5.4500  decode.loss_cls: 0.0193  decode.loss_mask: 0.2376  decode.loss_dice: 0.2010  decode.d0.loss_cls: 0.8438  decode.d0.loss_mask: 0.2476  decode.d0.loss_dice: 0.1943  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.2422  decode.d1.loss_dice: 0.1916  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.1855  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.2407  decode.d3.loss_dice: 0.1966  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.2413  decode.d4.loss_dice: 0.1961  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.2389  decode.d5.loss_dice: 0.2017  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.2390  decode.d6.loss_dice: 0.1950  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.2378  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.1984
09/30 19:48:22 - mmengine - INFO - Iter(train) [ 88600/320000]  base_lr: 7.4695e-05 lr: 7.4695e-06  eta: 1 day, 4:01:26  time: 0.4394  data_time: 0.0097  memory: 5129  grad_norm: 17.5808  loss: 4.4030  decode.loss_cls: 0.0017  decode.loss_mask: 0.1859  decode.loss_dice: 0.1606  decode.d0.loss_cls: 0.9042  decode.d0.loss_mask: 0.1905  decode.d0.loss_dice: 0.1561  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.1882  decode.d1.loss_dice: 0.1586  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.1535  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1882  decode.d3.loss_dice: 0.1524  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.1911  decode.d4.loss_dice: 0.1586  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.1901  decode.d5.loss_dice: 0.1537  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.1613  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1916  decode.d7.loss_dice: 0.1559  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.1877  decode.d8.loss_dice: 0.1599
09/30 19:48:44 - mmengine - INFO - Iter(train) [ 88650/320000]  base_lr: 7.4681e-05 lr: 7.4681e-06  eta: 1 day, 4:01:05  time: 0.4400  data_time: 0.0098  memory: 5129  grad_norm: 49.5120  loss: 5.7569  decode.loss_cls: 0.0696  decode.loss_mask: 0.1996  decode.loss_dice: 0.2148  decode.d0.loss_cls: 0.7322  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.2115  decode.d1.loss_cls: 0.1295  decode.d1.loss_mask: 0.1961  decode.d1.loss_dice: 0.2096  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.2032  decode.d2.loss_dice: 0.2098  decode.d3.loss_cls: 0.0998  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.2150  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.2020  decode.d4.loss_dice: 0.2152  decode.d5.loss_cls: 0.0868  decode.d5.loss_mask: 0.2008  decode.d5.loss_dice: 0.2101  decode.d6.loss_cls: 0.1123  decode.d6.loss_mask: 0.1995  decode.d6.loss_dice: 0.2067  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.2141  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.2026  decode.d8.loss_dice: 0.2063
09/30 19:49:06 - mmengine - INFO - Iter(train) [ 88700/320000]  base_lr: 7.4666e-05 lr: 7.4666e-06  eta: 1 day, 4:00:44  time: 0.4401  data_time: 0.0099  memory: 5129  grad_norm: 48.5380  loss: 5.1846  decode.loss_cls: 0.0086  decode.loss_mask: 0.2444  decode.loss_dice: 0.1832  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.2514  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 0.2454  decode.d1.loss_dice: 0.1905  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 0.2428  decode.d2.loss_dice: 0.1883  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.2421  decode.d3.loss_dice: 0.1886  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.2459  decode.d4.loss_dice: 0.1886  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.1869  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.1828  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.2431  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.1846
09/30 19:49:28 - mmengine - INFO - Iter(train) [ 88750/320000]  base_lr: 7.4652e-05 lr: 7.4652e-06  eta: 1 day, 4:00:22  time: 0.4403  data_time: 0.0099  memory: 5120  grad_norm: 21.3820  loss: 4.6840  decode.loss_cls: 0.0019  decode.loss_mask: 0.2195  decode.loss_dice: 0.1803  decode.d0.loss_cls: 0.7376  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.1744  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2140  decode.d2.loss_dice: 0.1757  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.2130  decode.d3.loss_dice: 0.1752  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.1776  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.1762  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.1771  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.1767
09/30 19:49:50 - mmengine - INFO - Iter(train) [ 88800/320000]  base_lr: 7.4637e-05 lr: 7.4637e-06  eta: 1 day, 4:00:01  time: 0.4415  data_time: 0.0100  memory: 5129  grad_norm: 35.2581  loss: 5.6887  decode.loss_cls: 0.1280  decode.loss_mask: 0.2233  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.8875  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.1831  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.1747  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.2215  decode.d2.loss_dice: 0.1803  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.2246  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.1887  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.2241  decode.d5.loss_dice: 0.1784  decode.d6.loss_cls: 0.0970  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.2246  decode.d7.loss_dice: 0.1862  decode.d8.loss_cls: 0.1003  decode.d8.loss_mask: 0.2251  decode.d8.loss_dice: 0.1903
09/30 19:50:12 - mmengine - INFO - Iter(train) [ 88850/320000]  base_lr: 7.4623e-05 lr: 7.4623e-06  eta: 1 day, 3:59:40  time: 0.4415  data_time: 0.0097  memory: 5120  grad_norm: 39.6006  loss: 4.7338  decode.loss_cls: 0.0396  decode.loss_mask: 0.1747  decode.loss_dice: 0.1880  decode.d0.loss_cls: 0.7238  decode.d0.loss_mask: 0.1776  decode.d0.loss_dice: 0.1884  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.1755  decode.d1.loss_dice: 0.2130  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.1744  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.1741  decode.d3.loss_dice: 0.1765  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.1766  decode.d4.loss_dice: 0.1704  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.1739  decode.d5.loss_dice: 0.1827  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.1767  decode.d6.loss_dice: 0.1816  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.1751  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.1734  decode.d8.loss_dice: 0.1861
09/30 19:50:34 - mmengine - INFO - Iter(train) [ 88900/320000]  base_lr: 7.4608e-05 lr: 7.4608e-06  eta: 1 day, 3:59:19  time: 0.4410  data_time: 0.0097  memory: 5120  grad_norm: 27.3198  loss: 4.8831  decode.loss_cls: 0.0058  decode.loss_mask: 0.1816  decode.loss_dice: 0.2194  decode.d0.loss_cls: 0.9567  decode.d0.loss_mask: 0.1849  decode.d0.loss_dice: 0.2010  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.1791  decode.d1.loss_dice: 0.2021  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.1805  decode.d2.loss_dice: 0.2011  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.1803  decode.d3.loss_dice: 0.1958  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.1994  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.1812  decode.d5.loss_dice: 0.1997  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.1784  decode.d6.loss_dice: 0.2108  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.1826  decode.d7.loss_dice: 0.2077  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.1842  decode.d8.loss_dice: 0.2115
09/30 19:50:57 - mmengine - INFO - Iter(train) [ 88950/320000]  base_lr: 7.4594e-05 lr: 7.4594e-06  eta: 1 day, 3:58:58  time: 0.4422  data_time: 0.0100  memory: 5145  grad_norm: 46.7453  loss: 6.1141  decode.loss_cls: 0.1548  decode.loss_mask: 0.1716  decode.loss_dice: 0.2272  decode.d0.loss_cls: 0.9380  decode.d0.loss_mask: 0.1731  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.0984  decode.d1.loss_mask: 0.1730  decode.d1.loss_dice: 0.2392  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.1695  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.1496  decode.d3.loss_mask: 0.1730  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.1292  decode.d4.loss_mask: 0.1683  decode.d4.loss_dice: 0.2173  decode.d5.loss_cls: 0.1132  decode.d5.loss_mask: 0.1721  decode.d5.loss_dice: 0.2473  decode.d6.loss_cls: 0.0956  decode.d6.loss_mask: 0.1718  decode.d6.loss_dice: 0.2418  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 0.1686  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.1419  decode.d8.loss_mask: 0.1737  decode.d8.loss_dice: 0.2496
09/30 19:51:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:51:19 - mmengine - INFO - Iter(train) [ 89000/320000]  base_lr: 7.4579e-05 lr: 7.4579e-06  eta: 1 day, 3:58:37  time: 0.4408  data_time: 0.0100  memory: 5145  grad_norm: 52.6806  loss: 5.5819  decode.loss_cls: 0.0280  decode.loss_mask: 0.2584  decode.loss_dice: 0.1738  decode.d0.loss_cls: 0.8341  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.1781  decode.d1.loss_cls: 0.1293  decode.d1.loss_mask: 0.2213  decode.d1.loss_dice: 0.1748  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.1631  decode.d3.loss_cls: 0.1429  decode.d3.loss_mask: 0.2070  decode.d3.loss_dice: 0.1606  decode.d4.loss_cls: 0.1146  decode.d4.loss_mask: 0.2044  decode.d4.loss_dice: 0.1571  decode.d5.loss_cls: 0.1145  decode.d5.loss_mask: 0.2097  decode.d5.loss_dice: 0.1628  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.1610  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.2037  decode.d7.loss_dice: 0.1599  decode.d8.loss_cls: 0.1049  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.1835
09/30 19:51:41 - mmengine - INFO - Iter(train) [ 89050/320000]  base_lr: 7.4565e-05 lr: 7.4565e-06  eta: 1 day, 3:58:16  time: 0.4422  data_time: 0.0100  memory: 5120  grad_norm: 74.3119  loss: 6.7546  decode.loss_cls: 0.0876  decode.loss_mask: 0.2703  decode.loss_dice: 0.2545  decode.d0.loss_cls: 0.8006  decode.d0.loss_mask: 0.2745  decode.d0.loss_dice: 0.2461  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.2395  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.2693  decode.d2.loss_dice: 0.2316  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.0957  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.2442  decode.d5.loss_cls: 0.1023  decode.d5.loss_mask: 0.2687  decode.d5.loss_dice: 0.2406  decode.d6.loss_cls: 0.1048  decode.d6.loss_mask: 0.2674  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.2429
09/30 19:52:03 - mmengine - INFO - Iter(train) [ 89100/320000]  base_lr: 7.4550e-05 lr: 7.4550e-06  eta: 1 day, 3:57:55  time: 0.4404  data_time: 0.0099  memory: 5145  grad_norm: 304.3172  loss: 5.3398  decode.loss_cls: 0.0220  decode.loss_mask: 0.2553  decode.loss_dice: 0.1788  decode.d0.loss_cls: 0.7719  decode.d0.loss_mask: 0.2602  decode.d0.loss_dice: 0.1808  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.1791  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.2575  decode.d2.loss_dice: 0.1743  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.1802  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.1798  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.1795  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.2559  decode.d6.loss_dice: 0.1756  decode.d7.loss_cls: 0.0215  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.1755  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.1723
09/30 19:52:25 - mmengine - INFO - Iter(train) [ 89150/320000]  base_lr: 7.4535e-05 lr: 7.4535e-06  eta: 1 day, 3:57:33  time: 0.4401  data_time: 0.0100  memory: 5120  grad_norm: 33.0862  loss: 5.0893  decode.loss_cls: 0.0148  decode.loss_mask: 0.1994  decode.loss_dice: 0.2089  decode.d0.loss_cls: 0.8013  decode.d0.loss_mask: 0.2007  decode.d0.loss_dice: 0.2103  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 0.2014  decode.d1.loss_dice: 0.2000  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.1987  decode.d2.loss_dice: 0.1785  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.1995  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2092  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2003  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.1761  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.1994  decode.d8.loss_dice: 0.2047
09/30 19:52:47 - mmengine - INFO - Iter(train) [ 89200/320000]  base_lr: 7.4521e-05 lr: 7.4521e-06  eta: 1 day, 3:57:12  time: 0.4400  data_time: 0.0099  memory: 5119  grad_norm: 92.5818  loss: 5.6990  decode.loss_cls: 0.0736  decode.loss_mask: 0.1994  decode.loss_dice: 0.1721  decode.d0.loss_cls: 1.0651  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.2101  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.0947  decode.d3.loss_mask: 0.1966  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0965  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.1686  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.1977  decode.d5.loss_dice: 0.1746  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.1951  decode.d6.loss_dice: 0.1782  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.2086  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.1995  decode.d8.loss_dice: 0.1802
09/30 19:53:09 - mmengine - INFO - Iter(train) [ 89250/320000]  base_lr: 7.4506e-05 lr: 7.4506e-06  eta: 1 day, 3:56:51  time: 0.4410  data_time: 0.0101  memory: 5120  grad_norm: 35.1726  loss: 5.4888  decode.loss_cls: 0.0763  decode.loss_mask: 0.2016  decode.loss_dice: 0.1813  decode.d0.loss_cls: 0.9113  decode.d0.loss_mask: 0.2048  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 0.1999  decode.d1.loss_dice: 0.1943  decode.d2.loss_cls: 0.0407  decode.d2.loss_mask: 0.2032  decode.d2.loss_dice: 0.1964  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.1920  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.1842  decode.d5.loss_cls: 0.0838  decode.d5.loss_mask: 0.2017  decode.d5.loss_dice: 0.1876  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.1841  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.2007  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.2036  decode.d8.loss_dice: 0.1883
09/30 19:53:31 - mmengine - INFO - Iter(train) [ 89300/320000]  base_lr: 7.4492e-05 lr: 7.4492e-06  eta: 1 day, 3:56:30  time: 0.4404  data_time: 0.0100  memory: 5129  grad_norm: 152.5226  loss: 8.1225  decode.loss_cls: 0.1611  decode.loss_mask: 0.2787  decode.loss_dice: 0.2139  decode.d0.loss_cls: 1.0396  decode.d0.loss_mask: 0.3433  decode.d0.loss_dice: 0.2486  decode.d1.loss_cls: 0.2317  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.2286  decode.d2.loss_cls: 0.2163  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.2285  decode.d3.loss_cls: 0.1547  decode.d3.loss_mask: 0.3001  decode.d3.loss_dice: 0.2430  decode.d4.loss_cls: 0.1539  decode.d4.loss_mask: 0.4060  decode.d4.loss_dice: 0.2549  decode.d5.loss_cls: 0.1697  decode.d5.loss_mask: 0.2841  decode.d5.loss_dice: 0.2317  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.3172  decode.d6.loss_dice: 0.2322  decode.d7.loss_cls: 0.1745  decode.d7.loss_mask: 0.3334  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.1658  decode.d8.loss_mask: 0.2829  decode.d8.loss_dice: 0.2194
09/30 19:53:53 - mmengine - INFO - Iter(train) [ 89350/320000]  base_lr: 7.4477e-05 lr: 7.4477e-06  eta: 1 day, 3:56:09  time: 0.4410  data_time: 0.0100  memory: 5129  grad_norm: 63.4179  loss: 5.8899  decode.loss_cls: 0.0846  decode.loss_mask: 0.2221  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.7591  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.2124  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.1944  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.2037  decode.d4.loss_cls: 0.1247  decode.d4.loss_mask: 0.2190  decode.d4.loss_dice: 0.2021  decode.d5.loss_cls: 0.1184  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2087  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.2191  decode.d6.loss_dice: 0.1961  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.2183  decode.d8.loss_dice: 0.2048
09/30 19:54:15 - mmengine - INFO - Iter(train) [ 89400/320000]  base_lr: 7.4463e-05 lr: 7.4463e-06  eta: 1 day, 3:55:47  time: 0.4401  data_time: 0.0099  memory: 5129  grad_norm: 29.9393  loss: 4.3164  decode.loss_cls: 0.0152  decode.loss_mask: 0.1928  decode.loss_dice: 0.1531  decode.d0.loss_cls: 0.7948  decode.d0.loss_mask: 0.2017  decode.d0.loss_dice: 0.1543  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.1943  decode.d1.loss_dice: 0.1506  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.1937  decode.d2.loss_dice: 0.1482  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.1935  decode.d3.loss_dice: 0.1484  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.1526  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.1904  decode.d5.loss_dice: 0.1512  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.1902  decode.d6.loss_dice: 0.1527  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.1915  decode.d7.loss_dice: 0.1503  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.1915  decode.d8.loss_dice: 0.1498
09/30 19:54:37 - mmengine - INFO - Iter(train) [ 89450/320000]  base_lr: 7.4448e-05 lr: 7.4448e-06  eta: 1 day, 3:55:26  time: 0.4407  data_time: 0.0102  memory: 5120  grad_norm: 82.2079  loss: 6.6854  decode.loss_cls: 0.2350  decode.loss_mask: 0.2230  decode.loss_dice: 0.1709  decode.d0.loss_cls: 0.7296  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.2207  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 0.2253  decode.d1.loss_dice: 0.1916  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 0.2257  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.1705  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.1898  decode.d4.loss_cls: 0.2109  decode.d4.loss_mask: 0.2256  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.1874  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.1902  decode.d6.loss_cls: 0.1940  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.1812  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.2200  decode.d7.loss_dice: 0.1744  decode.d8.loss_cls: 0.2300  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1761
09/30 19:54:59 - mmengine - INFO - Iter(train) [ 89500/320000]  base_lr: 7.4434e-05 lr: 7.4434e-06  eta: 1 day, 3:55:05  time: 0.4410  data_time: 0.0101  memory: 5129  grad_norm: 46.7354  loss: 7.5255  decode.loss_cls: 0.1774  decode.loss_mask: 0.2085  decode.loss_dice: 0.3087  decode.d0.loss_cls: 0.9007  decode.d0.loss_mask: 0.1982  decode.d0.loss_dice: 0.2813  decode.d1.loss_cls: 0.1672  decode.d1.loss_mask: 0.2024  decode.d1.loss_dice: 0.2598  decode.d2.loss_cls: 0.1785  decode.d2.loss_mask: 0.2061  decode.d2.loss_dice: 0.2682  decode.d3.loss_cls: 0.1927  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.2713  decode.d4.loss_cls: 0.2600  decode.d4.loss_mask: 0.1987  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.2469  decode.d5.loss_mask: 0.1951  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 0.1999  decode.d6.loss_dice: 0.2749  decode.d7.loss_cls: 0.2181  decode.d7.loss_mask: 0.1974  decode.d7.loss_dice: 0.2714  decode.d8.loss_cls: 0.1620  decode.d8.loss_mask: 0.2033  decode.d8.loss_dice: 0.2986
09/30 19:55:21 - mmengine - INFO - Iter(train) [ 89550/320000]  base_lr: 7.4419e-05 lr: 7.4419e-06  eta: 1 day, 3:54:44  time: 0.4415  data_time: 0.0100  memory: 5120  grad_norm: 21.3227  loss: 4.3369  decode.loss_cls: 0.0075  decode.loss_mask: 0.1925  decode.loss_dice: 0.1592  decode.d0.loss_cls: 0.7448  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.1614  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.1938  decode.d1.loss_dice: 0.1574  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.1949  decode.d2.loss_dice: 0.1579  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.1582  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.1917  decode.d4.loss_dice: 0.1588  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.1945  decode.d5.loss_dice: 0.1564  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.1931  decode.d6.loss_dice: 0.1558  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.1936  decode.d7.loss_dice: 0.1578  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.1936  decode.d8.loss_dice: 0.1631
09/30 19:55:43 - mmengine - INFO - Iter(train) [ 89600/320000]  base_lr: 7.4405e-05 lr: 7.4405e-06  eta: 1 day, 3:54:23  time: 0.4385  data_time: 0.0096  memory: 5129  grad_norm: 69.7055  loss: 5.4403  decode.loss_cls: 0.0967  decode.loss_mask: 0.2116  decode.loss_dice: 0.1750  decode.d0.loss_cls: 0.7711  decode.d0.loss_mask: 0.2153  decode.d0.loss_dice: 0.1694  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.1755  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.2150  decode.d2.loss_dice: 0.2196  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.1643  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.2123  decode.d4.loss_dice: 0.1848  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.2137  decode.d5.loss_dice: 0.1677  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.1732  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.1786  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.2118  decode.d8.loss_dice: 0.1712
09/30 19:56:05 - mmengine - INFO - Iter(train) [ 89650/320000]  base_lr: 7.4390e-05 lr: 7.4390e-06  eta: 1 day, 3:54:01  time: 0.4399  data_time: 0.0095  memory: 5120  grad_norm: 113.6190  loss: 6.5459  decode.loss_cls: 0.1128  decode.loss_mask: 0.2367  decode.loss_dice: 0.2121  decode.d0.loss_cls: 1.1350  decode.d0.loss_mask: 0.2517  decode.d0.loss_dice: 0.2270  decode.d1.loss_cls: 0.1170  decode.d1.loss_mask: 0.2408  decode.d1.loss_dice: 0.2078  decode.d2.loss_cls: 0.1338  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.2125  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.2386  decode.d3.loss_dice: 0.2115  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.2356  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.2354  decode.d5.loss_dice: 0.2113  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.2100  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.2339  decode.d8.loss_dice: 0.2024
09/30 19:56:27 - mmengine - INFO - Iter(train) [ 89700/320000]  base_lr: 7.4376e-05 lr: 7.4376e-06  eta: 1 day, 3:53:40  time: 0.4420  data_time: 0.0094  memory: 5129  grad_norm: 40.5585  loss: 5.5508  decode.loss_cls: 0.0465  decode.loss_mask: 0.1958  decode.loss_dice: 0.2051  decode.d0.loss_cls: 0.8631  decode.d0.loss_mask: 0.1967  decode.d0.loss_dice: 0.2047  decode.d1.loss_cls: 0.0488  decode.d1.loss_mask: 0.1950  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.1130  decode.d2.loss_mask: 0.1954  decode.d2.loss_dice: 0.2374  decode.d3.loss_cls: 0.1038  decode.d3.loss_mask: 0.1922  decode.d3.loss_dice: 0.2161  decode.d4.loss_cls: 0.1015  decode.d4.loss_mask: 0.1941  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.1927  decode.d5.loss_dice: 0.2026  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.1937  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 0.1935  decode.d7.loss_dice: 0.1992  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.1925  decode.d8.loss_dice: 0.1999
09/30 19:56:50 - mmengine - INFO - Iter(train) [ 89750/320000]  base_lr: 7.4361e-05 lr: 7.4361e-06  eta: 1 day, 3:53:19  time: 0.4405  data_time: 0.0095  memory: 5145  grad_norm: 63.4810  loss: 5.8928  decode.loss_cls: 0.1105  decode.loss_mask: 0.2149  decode.loss_dice: 0.1814  decode.d0.loss_cls: 0.9971  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1853  decode.d1.loss_cls: 0.1347  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.1813  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.2140  decode.d2.loss_dice: 0.1827  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.1887  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.2129  decode.d4.loss_dice: 0.1916  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.2128  decode.d5.loss_dice: 0.1807  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.2150  decode.d6.loss_dice: 0.1912  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.1894  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 0.2131  decode.d8.loss_dice: 0.1883
09/30 19:57:12 - mmengine - INFO - Iter(train) [ 89800/320000]  base_lr: 7.4347e-05 lr: 7.4347e-06  eta: 1 day, 3:52:58  time: 0.4399  data_time: 0.0096  memory: 5119  grad_norm: 46.5925  loss: 5.5022  decode.loss_cls: 0.0871  decode.loss_mask: 0.2279  decode.loss_dice: 0.1834  decode.d0.loss_cls: 0.8573  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.1852  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.1843  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.2296  decode.d2.loss_dice: 0.1835  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.2304  decode.d4.loss_dice: 0.1821  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 0.2288  decode.d5.loss_dice: 0.1831  decode.d6.loss_cls: 0.0759  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.1837  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.1866  decode.d8.loss_cls: 0.0845  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.1832
09/30 19:57:34 - mmengine - INFO - Iter(train) [ 89850/320000]  base_lr: 7.4332e-05 lr: 7.4332e-06  eta: 1 day, 3:52:37  time: 0.4392  data_time: 0.0095  memory: 5145  grad_norm: 21.9128  loss: 4.5450  decode.loss_cls: 0.0669  decode.loss_mask: 0.1716  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.8166  decode.d0.loss_mask: 0.1727  decode.d0.loss_dice: 0.1759  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.1745  decode.d1.loss_dice: 0.1767  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.1724  decode.d2.loss_dice: 0.1714  decode.d3.loss_cls: 0.0144  decode.d3.loss_mask: 0.1733  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.1731  decode.d4.loss_dice: 0.1674  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.1751  decode.d5.loss_dice: 0.1629  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.1741  decode.d6.loss_dice: 0.1834  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.1746  decode.d7.loss_dice: 0.1790  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.1743  decode.d8.loss_dice: 0.1676
09/30 19:57:56 - mmengine - INFO - Iter(train) [ 89900/320000]  base_lr: 7.4318e-05 lr: 7.4318e-06  eta: 1 day, 3:52:16  time: 0.4424  data_time: 0.0099  memory: 5145  grad_norm: 48.0257  loss: 5.0518  decode.loss_cls: 0.0562  decode.loss_mask: 0.2034  decode.loss_dice: 0.1729  decode.d0.loss_cls: 0.7930  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.1745  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.2028  decode.d1.loss_dice: 0.1732  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.2007  decode.d2.loss_dice: 0.1704  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.2005  decode.d3.loss_dice: 0.1706  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.2032  decode.d4.loss_dice: 0.1724  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.1738  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.2019  decode.d6.loss_dice: 0.1696  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 0.2048  decode.d7.loss_dice: 0.1722  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.2065  decode.d8.loss_dice: 0.1693
09/30 19:58:18 - mmengine - INFO - Iter(train) [ 89950/320000]  base_lr: 7.4303e-05 lr: 7.4303e-06  eta: 1 day, 3:51:54  time: 0.4403  data_time: 0.0097  memory: 5129  grad_norm: 43.8321  loss: 5.0969  decode.loss_cls: 0.0383  decode.loss_mask: 0.2314  decode.loss_dice: 0.1705  decode.d0.loss_cls: 0.7589  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.1691  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.1729  decode.d2.loss_cls: 0.0226  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.1737  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2321  decode.d3.loss_dice: 0.1675  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.2344  decode.d4.loss_dice: 0.1666  decode.d5.loss_cls: 0.0270  decode.d5.loss_mask: 0.2331  decode.d5.loss_dice: 0.1690  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.2377  decode.d6.loss_dice: 0.1705  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.2343  decode.d7.loss_dice: 0.1661  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.1718
09/30 19:58:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 19:58:40 - mmengine - INFO - Iter(train) [ 90000/320000]  base_lr: 7.4288e-05 lr: 7.4288e-06  eta: 1 day, 3:51:33  time: 0.4392  data_time: 0.0096  memory: 5129  grad_norm: 22.0741  loss: 5.5282  decode.loss_cls: 0.0688  decode.loss_mask: 0.2083  decode.loss_dice: 0.1928  decode.d0.loss_cls: 0.8222  decode.d0.loss_mask: 0.2141  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.1880  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.2114  decode.d2.loss_dice: 0.1863  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.2144  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0867  decode.d4.loss_mask: 0.2096  decode.d4.loss_dice: 0.1952  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.2097  decode.d5.loss_dice: 0.1852  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.2116  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.1855  decode.d8.loss_cls: 0.0937  decode.d8.loss_mask: 0.2079  decode.d8.loss_dice: 0.1917
09/30 19:59:02 - mmengine - INFO - Iter(train) [ 90050/320000]  base_lr: 7.4274e-05 lr: 7.4274e-06  eta: 1 day, 3:51:12  time: 0.4401  data_time: 0.0098  memory: 5145  grad_norm: 58.6807  loss: 7.0833  decode.loss_cls: 0.1727  decode.loss_mask: 0.2603  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.9991  decode.d0.loss_mask: 0.2191  decode.d0.loss_dice: 0.2097  decode.d1.loss_cls: 0.1959  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.1993  decode.d2.loss_cls: 0.1861  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.2052  decode.d3.loss_cls: 0.1686  decode.d3.loss_mask: 0.2287  decode.d3.loss_dice: 0.1936  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.1899  decode.d5.loss_cls: 0.1980  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2058  decode.d6.loss_cls: 0.1931  decode.d6.loss_mask: 0.2530  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 0.2480  decode.d7.loss_dice: 0.2203  decode.d8.loss_cls: 0.1763  decode.d8.loss_mask: 0.2223  decode.d8.loss_dice: 0.2032
09/30 19:59:24 - mmengine - INFO - Iter(train) [ 90100/320000]  base_lr: 7.4259e-05 lr: 7.4259e-06  eta: 1 day, 3:50:51  time: 0.4399  data_time: 0.0098  memory: 5145  grad_norm: 32.0867  loss: 4.2753  decode.loss_cls: 0.0009  decode.loss_mask: 0.1733  decode.loss_dice: 0.1662  decode.d0.loss_cls: 0.8650  decode.d0.loss_mask: 0.1712  decode.d0.loss_dice: 0.1696  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.1709  decode.d1.loss_dice: 0.1690  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.1724  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.1712  decode.d3.loss_dice: 0.1700  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.1714  decode.d4.loss_dice: 0.1660  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1703  decode.d5.loss_dice: 0.1673  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.1726  decode.d6.loss_dice: 0.1636  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.1700  decode.d7.loss_dice: 0.1619  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.1712  decode.d8.loss_dice: 0.1676
09/30 19:59:46 - mmengine - INFO - Iter(train) [ 90150/320000]  base_lr: 7.4245e-05 lr: 7.4245e-06  eta: 1 day, 3:50:29  time: 0.4403  data_time: 0.0097  memory: 5129  grad_norm: 101.7524  loss: 6.4823  decode.loss_cls: 0.1514  decode.loss_mask: 0.2029  decode.loss_dice: 0.1889  decode.d0.loss_cls: 0.9112  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.1962  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 0.1980  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.2146  decode.d3.loss_mask: 0.2010  decode.d3.loss_dice: 0.1799  decode.d4.loss_cls: 0.2114  decode.d4.loss_mask: 0.2028  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.2014  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.1911  decode.d6.loss_cls: 0.1748  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.2088  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.1699  decode.d8.loss_mask: 0.1989  decode.d8.loss_dice: 0.1865
09/30 20:00:08 - mmengine - INFO - Iter(train) [ 90200/320000]  base_lr: 7.4230e-05 lr: 7.4230e-06  eta: 1 day, 3:50:08  time: 0.4411  data_time: 0.0097  memory: 5146  grad_norm: 51.4034  loss: 5.9905  decode.loss_cls: 0.0733  decode.loss_mask: 0.2297  decode.loss_dice: 0.1914  decode.d0.loss_cls: 0.7971  decode.d0.loss_mask: 0.2344  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.2898  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.2927  decode.d2.loss_dice: 0.2085  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2047  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.2083  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.2035  decode.d6.loss_cls: 0.0870  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.2879  decode.d7.loss_dice: 0.2078  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.2271  decode.d8.loss_dice: 0.1910
09/30 20:00:30 - mmengine - INFO - Iter(train) [ 90250/320000]  base_lr: 7.4216e-05 lr: 7.4216e-06  eta: 1 day, 3:49:47  time: 0.4402  data_time: 0.0099  memory: 5145  grad_norm: 212.5024  loss: 5.8307  decode.loss_cls: 0.0538  decode.loss_mask: 0.2403  decode.loss_dice: 0.1829  decode.d0.loss_cls: 0.8678  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.1824  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.2536  decode.d2.loss_dice: 0.1927  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.2563  decode.d3.loss_dice: 0.2065  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.1888  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.2551  decode.d5.loss_dice: 0.1893  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.1867
09/30 20:00:52 - mmengine - INFO - Iter(train) [ 90300/320000]  base_lr: 7.4201e-05 lr: 7.4201e-06  eta: 1 day, 3:49:26  time: 0.4424  data_time: 0.0100  memory: 5129  grad_norm: 80.3857  loss: 5.0730  decode.loss_cls: 0.0708  decode.loss_mask: 0.1972  decode.loss_dice: 0.1662  decode.d0.loss_cls: 0.6613  decode.d0.loss_mask: 0.2005  decode.d0.loss_dice: 0.1779  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.1959  decode.d1.loss_dice: 0.1677  decode.d2.loss_cls: 0.1408  decode.d2.loss_mask: 0.1969  decode.d2.loss_dice: 0.1604  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.1655  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.1969  decode.d4.loss_dice: 0.1683  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.2000  decode.d5.loss_dice: 0.1683  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 0.2002  decode.d6.loss_dice: 0.1664  decode.d7.loss_cls: 0.0751  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.1760  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.1969  decode.d8.loss_dice: 0.1627
09/30 20:01:14 - mmengine - INFO - Iter(train) [ 90350/320000]  base_lr: 7.4187e-05 lr: 7.4187e-06  eta: 1 day, 3:49:04  time: 0.4409  data_time: 0.0099  memory: 5129  grad_norm: 28.3054  loss: 5.1509  decode.loss_cls: 0.0106  decode.loss_mask: 0.2497  decode.loss_dice: 0.1933  decode.d0.loss_cls: 0.6582  decode.d0.loss_mask: 0.2486  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.2468  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.2458  decode.d2.loss_dice: 0.1921  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.1938  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.1911  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.2458  decode.d5.loss_dice: 0.1914  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.1937  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.1923
09/30 20:01:36 - mmengine - INFO - Iter(train) [ 90400/320000]  base_lr: 7.4172e-05 lr: 7.4172e-06  eta: 1 day, 3:48:43  time: 0.4427  data_time: 0.0098  memory: 5129  grad_norm: 88.5574  loss: 6.0362  decode.loss_cls: 0.0680  decode.loss_mask: 0.2331  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.9130  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.2232  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.2207  decode.d1.loss_dice: 0.2290  decode.d2.loss_cls: 0.0918  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.2220  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.2221  decode.d3.loss_dice: 0.2327  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.2382  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.2264  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2366  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.0279  decode.d8.loss_mask: 0.2270  decode.d8.loss_dice: 0.2372
09/30 20:01:58 - mmengine - INFO - Iter(train) [ 90450/320000]  base_lr: 7.4158e-05 lr: 7.4158e-06  eta: 1 day, 3:48:22  time: 0.4408  data_time: 0.0098  memory: 5120  grad_norm: 14.4982  loss: 3.7685  decode.loss_cls: 0.0062  decode.loss_mask: 0.1544  decode.loss_dice: 0.1338  decode.d0.loss_cls: 0.8327  decode.d0.loss_mask: 0.1550  decode.d0.loss_dice: 0.1358  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.1544  decode.d1.loss_dice: 0.1339  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.1548  decode.d2.loss_dice: 0.1343  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.1538  decode.d3.loss_dice: 0.1361  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.1551  decode.d4.loss_dice: 0.1364  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.1524  decode.d5.loss_dice: 0.1319  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.1542  decode.d6.loss_dice: 0.1320  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.1547  decode.d7.loss_dice: 0.1331  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.1549  decode.d8.loss_dice: 0.1305
09/30 20:02:20 - mmengine - INFO - Iter(train) [ 90500/320000]  base_lr: 7.4143e-05 lr: 7.4143e-06  eta: 1 day, 3:48:01  time: 0.4398  data_time: 0.0099  memory: 5120  grad_norm: 54.2140  loss: 6.0032  decode.loss_cls: 0.0848  decode.loss_mask: 0.2444  decode.loss_dice: 0.2176  decode.d0.loss_cls: 0.7971  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0858  decode.d1.loss_mask: 0.2460  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2458  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.2411  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.2200  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.2117  decode.d6.loss_cls: 0.0673  decode.d6.loss_mask: 0.2431  decode.d6.loss_dice: 0.2100  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.2090  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.2418  decode.d8.loss_dice: 0.2003
09/30 20:02:42 - mmengine - INFO - Iter(train) [ 90550/320000]  base_lr: 7.4129e-05 lr: 7.4129e-06  eta: 1 day, 3:47:39  time: 0.4395  data_time: 0.0097  memory: 5129  grad_norm: 48.7850  loss: 4.6563  decode.loss_cls: 0.0074  decode.loss_mask: 0.1969  decode.loss_dice: 0.1806  decode.d0.loss_cls: 0.7736  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.1816  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.1961  decode.d1.loss_dice: 0.1864  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.1805  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.1958  decode.d3.loss_dice: 0.1786  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.1967  decode.d4.loss_dice: 0.1729  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.1957  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.1821  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.1941  decode.d7.loss_dice: 0.1833  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.1973  decode.d8.loss_dice: 0.1992
09/30 20:03:04 - mmengine - INFO - Iter(train) [ 90600/320000]  base_lr: 7.4114e-05 lr: 7.4114e-06  eta: 1 day, 3:47:19  time: 0.4410  data_time: 0.0099  memory: 5145  grad_norm: 48.4700  loss: 6.4401  decode.loss_cls: 0.1347  decode.loss_mask: 0.2260  decode.loss_dice: 0.2379  decode.d0.loss_cls: 0.7585  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2436  decode.d1.loss_cls: 0.1219  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2309  decode.d2.loss_cls: 0.1071  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2138  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.1546  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.2335  decode.d5.loss_cls: 0.1053  decode.d5.loss_mask: 0.2246  decode.d5.loss_dice: 0.2330  decode.d6.loss_cls: 0.1116  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.1489  decode.d7.loss_mask: 0.2261  decode.d7.loss_dice: 0.2292  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2142
09/30 20:03:26 - mmengine - INFO - Iter(train) [ 90650/320000]  base_lr: 7.4099e-05 lr: 7.4099e-06  eta: 1 day, 3:46:57  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 37.3161  loss: 5.6483  decode.loss_cls: 0.0759  decode.loss_mask: 0.2006  decode.loss_dice: 0.2213  decode.d0.loss_cls: 0.7596  decode.d0.loss_mask: 0.2107  decode.d0.loss_dice: 0.2244  decode.d1.loss_cls: 0.0955  decode.d1.loss_mask: 0.2045  decode.d1.loss_dice: 0.2190  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.1978  decode.d2.loss_dice: 0.2185  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2006  decode.d3.loss_dice: 0.2127  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.1992  decode.d4.loss_dice: 0.2122  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.2015  decode.d5.loss_dice: 0.2214  decode.d6.loss_cls: 0.0548  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.2206  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2238  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.1986  decode.d8.loss_dice: 0.2182
09/30 20:03:48 - mmengine - INFO - Iter(train) [ 90700/320000]  base_lr: 7.4085e-05 lr: 7.4085e-06  eta: 1 day, 3:46:36  time: 0.4411  data_time: 0.0099  memory: 5129  grad_norm: 61.9884  loss: 6.6159  decode.loss_cls: 0.0974  decode.loss_mask: 0.2428  decode.loss_dice: 0.2310  decode.d0.loss_cls: 0.9267  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.2528  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.2441  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.2431  decode.d2.loss_dice: 0.2342  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 0.2415  decode.d3.loss_dice: 0.2402  decode.d4.loss_cls: 0.0868  decode.d4.loss_mask: 0.2438  decode.d4.loss_dice: 0.2493  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.2447  decode.d5.loss_dice: 0.2494  decode.d6.loss_cls: 0.1173  decode.d6.loss_mask: 0.2439  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.0963  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.2487  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.2369
09/30 20:04:10 - mmengine - INFO - Iter(train) [ 90750/320000]  base_lr: 7.4070e-05 lr: 7.4070e-06  eta: 1 day, 3:46:15  time: 0.4404  data_time: 0.0099  memory: 5119  grad_norm: 38.6295  loss: 4.9097  decode.loss_cls: 0.0056  decode.loss_mask: 0.2358  decode.loss_dice: 0.1680  decode.d0.loss_cls: 0.8214  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.1736  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.1667  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.1625  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.2374  decode.d3.loss_dice: 0.1645  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.2390  decode.d4.loss_dice: 0.1630  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.2401  decode.d5.loss_dice: 0.1660  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.1665  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.1676  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.2374  decode.d8.loss_dice: 0.1637
09/30 20:04:33 - mmengine - INFO - Iter(train) [ 90800/320000]  base_lr: 7.4056e-05 lr: 7.4056e-06  eta: 1 day, 3:45:54  time: 0.4419  data_time: 0.0099  memory: 5145  grad_norm: 35.8947  loss: 4.7982  decode.loss_cls: 0.0205  decode.loss_mask: 0.1802  decode.loss_dice: 0.1872  decode.d0.loss_cls: 0.8596  decode.d0.loss_mask: 0.1813  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 0.1819  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0228  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.1814  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.1783  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.1858  decode.d4.loss_dice: 0.1865  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.1830  decode.d5.loss_dice: 0.1866  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.1814  decode.d6.loss_dice: 0.1792  decode.d7.loss_cls: 0.0283  decode.d7.loss_mask: 0.1843  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.1810  decode.d8.loss_dice: 0.1873
09/30 20:04:55 - mmengine - INFO - Iter(train) [ 90850/320000]  base_lr: 7.4041e-05 lr: 7.4041e-06  eta: 1 day, 3:45:33  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 56.6759  loss: 6.5253  decode.loss_cls: 0.0846  decode.loss_mask: 0.2257  decode.loss_dice: 0.2660  decode.d0.loss_cls: 0.8498  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.2418  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.2253  decode.d1.loss_dice: 0.2628  decode.d2.loss_cls: 0.1110  decode.d2.loss_mask: 0.2305  decode.d2.loss_dice: 0.2659  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2656  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.2778  decode.d5.loss_cls: 0.1140  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2401  decode.d6.loss_cls: 0.0630  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.2590  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.2264  decode.d8.loss_dice: 0.2602
09/30 20:05:17 - mmengine - INFO - Iter(train) [ 90900/320000]  base_lr: 7.4027e-05 lr: 7.4027e-06  eta: 1 day, 3:45:11  time: 0.4419  data_time: 0.0100  memory: 5145  grad_norm: 49.8480  loss: 5.6882  decode.loss_cls: 0.0940  decode.loss_mask: 0.2104  decode.loss_dice: 0.1815  decode.d0.loss_cls: 0.7834  decode.d0.loss_mask: 0.2122  decode.d0.loss_dice: 0.1958  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.2087  decode.d2.loss_dice: 0.1887  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.1901  decode.d4.loss_cls: 0.0960  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1899  decode.d5.loss_cls: 0.1103  decode.d5.loss_mask: 0.2120  decode.d5.loss_dice: 0.1862  decode.d6.loss_cls: 0.1026  decode.d6.loss_mask: 0.2128  decode.d6.loss_dice: 0.1882  decode.d7.loss_cls: 0.1128  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.1826  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.2101  decode.d8.loss_dice: 0.1846
09/30 20:05:39 - mmengine - INFO - Iter(train) [ 90950/320000]  base_lr: 7.4012e-05 lr: 7.4012e-06  eta: 1 day, 3:44:50  time: 0.4405  data_time: 0.0100  memory: 5120  grad_norm: 19.5536  loss: 4.8623  decode.loss_cls: 0.0644  decode.loss_mask: 0.2141  decode.loss_dice: 0.1432  decode.d0.loss_cls: 0.7402  decode.d0.loss_mask: 0.2163  decode.d0.loss_dice: 0.1493  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.1468  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.2138  decode.d2.loss_dice: 0.1463  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.1463  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1455  decode.d5.loss_cls: 0.0593  decode.d5.loss_mask: 0.2137  decode.d5.loss_dice: 0.1438  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.1444  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.2129  decode.d7.loss_dice: 0.1457  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.2151  decode.d8.loss_dice: 0.1459
09/30 20:06:01 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:06:01 - mmengine - INFO - Iter(train) [ 91000/320000]  base_lr: 7.3998e-05 lr: 7.3998e-06  eta: 1 day, 3:44:29  time: 0.4408  data_time: 0.0096  memory: 5129  grad_norm: 40.3708  loss: 4.2410  decode.loss_cls: 0.0164  decode.loss_mask: 0.1670  decode.loss_dice: 0.1582  decode.d0.loss_cls: 0.7813  decode.d0.loss_mask: 0.1718  decode.d0.loss_dice: 0.1549  decode.d1.loss_cls: 0.0230  decode.d1.loss_mask: 0.1668  decode.d1.loss_dice: 0.1594  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.1661  decode.d2.loss_dice: 0.1587  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.1701  decode.d3.loss_dice: 0.1572  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.1658  decode.d4.loss_dice: 0.1574  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.1667  decode.d5.loss_dice: 0.1644  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.1692  decode.d6.loss_dice: 0.1620  decode.d7.loss_cls: 0.0192  decode.d7.loss_mask: 0.1691  decode.d7.loss_dice: 0.1585  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.1674  decode.d8.loss_dice: 0.1585
09/30 20:06:23 - mmengine - INFO - Iter(train) [ 91050/320000]  base_lr: 7.3983e-05 lr: 7.3983e-06  eta: 1 day, 3:44:08  time: 0.4407  data_time: 0.0100  memory: 5145  grad_norm: 46.5134  loss: 7.2858  decode.loss_cls: 0.0801  decode.loss_mask: 0.3217  decode.loss_dice: 0.2302  decode.d0.loss_cls: 0.9927  decode.d0.loss_mask: 0.3306  decode.d0.loss_dice: 0.1898  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.3211  decode.d1.loss_dice: 0.2236  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.3275  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.3230  decode.d3.loss_dice: 0.2348  decode.d4.loss_cls: 0.1016  decode.d4.loss_mask: 0.3204  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.0977  decode.d5.loss_mask: 0.3177  decode.d5.loss_dice: 0.2278  decode.d6.loss_cls: 0.0773  decode.d6.loss_mask: 0.3230  decode.d6.loss_dice: 0.2303  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.3227  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.1015  decode.d8.loss_mask: 0.3243  decode.d8.loss_dice: 0.2441
09/30 20:06:45 - mmengine - INFO - Iter(train) [ 91100/320000]  base_lr: 7.3969e-05 lr: 7.3969e-06  eta: 1 day, 3:43:47  time: 0.4413  data_time: 0.0098  memory: 5119  grad_norm: 223.9640  loss: 7.7786  decode.loss_cls: 0.1356  decode.loss_mask: 0.3202  decode.loss_dice: 0.2144  decode.d0.loss_cls: 0.9434  decode.d0.loss_mask: 0.3322  decode.d0.loss_dice: 0.2176  decode.d1.loss_cls: 0.1827  decode.d1.loss_mask: 0.3450  decode.d1.loss_dice: 0.2347  decode.d2.loss_cls: 0.1936  decode.d2.loss_mask: 0.3288  decode.d2.loss_dice: 0.2189  decode.d3.loss_cls: 0.1302  decode.d3.loss_mask: 0.3260  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.0974  decode.d4.loss_mask: 0.3303  decode.d4.loss_dice: 0.2463  decode.d5.loss_cls: 0.1628  decode.d5.loss_mask: 0.3195  decode.d5.loss_dice: 0.2124  decode.d6.loss_cls: 0.1433  decode.d6.loss_mask: 0.3385  decode.d6.loss_dice: 0.2154  decode.d7.loss_cls: 0.1345  decode.d7.loss_mask: 0.3207  decode.d7.loss_dice: 0.2104  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 0.3342  decode.d8.loss_dice: 0.2290
09/30 20:07:07 - mmengine - INFO - Iter(train) [ 91150/320000]  base_lr: 7.3954e-05 lr: 7.3954e-06  eta: 1 day, 3:43:26  time: 0.4414  data_time: 0.0099  memory: 5129  grad_norm: 54.4959  loss: 5.4182  decode.loss_cls: 0.0156  decode.loss_mask: 0.2254  decode.loss_dice: 0.1994  decode.d0.loss_cls: 0.9088  decode.d0.loss_mask: 0.2310  decode.d0.loss_dice: 0.1962  decode.d1.loss_cls: 0.0386  decode.d1.loss_mask: 0.2268  decode.d1.loss_dice: 0.2043  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.2268  decode.d2.loss_dice: 0.2046  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.2064  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.0244  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.2009  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.1951  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.2019  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.2049
09/30 20:07:29 - mmengine - INFO - Iter(train) [ 91200/320000]  base_lr: 7.3940e-05 lr: 7.3940e-06  eta: 1 day, 3:43:04  time: 0.4397  data_time: 0.0099  memory: 5145  grad_norm: 186.0351  loss: 5.5883  decode.loss_cls: 0.0585  decode.loss_mask: 0.2601  decode.loss_dice: 0.1952  decode.d0.loss_cls: 0.7955  decode.d0.loss_mask: 0.2664  decode.d0.loss_dice: 0.2112  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.2601  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.1873  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.2584  decode.d3.loss_dice: 0.1901  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.2587  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.2539  decode.d5.loss_dice: 0.1953  decode.d6.loss_cls: 0.0263  decode.d6.loss_mask: 0.2563  decode.d6.loss_dice: 0.1941  decode.d7.loss_cls: 0.0283  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.2105  decode.d8.loss_cls: 0.0361  decode.d8.loss_mask: 0.2576  decode.d8.loss_dice: 0.1979
09/30 20:07:51 - mmengine - INFO - Iter(train) [ 91250/320000]  base_lr: 7.3925e-05 lr: 7.3925e-06  eta: 1 day, 3:42:43  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 21.6327  loss: 5.6738  decode.loss_cls: 0.0112  decode.loss_mask: 0.2037  decode.loss_dice: 0.2674  decode.d0.loss_cls: 0.8763  decode.d0.loss_mask: 0.2073  decode.d0.loss_dice: 0.2512  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.2572  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.2059  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.2065  decode.d3.loss_dice: 0.2741  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2075  decode.d4.loss_dice: 0.2551  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2039  decode.d6.loss_dice: 0.2645  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.2042  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.2069  decode.d8.loss_dice: 0.2687
09/30 20:08:13 - mmengine - INFO - Iter(train) [ 91300/320000]  base_lr: 7.3910e-05 lr: 7.3910e-06  eta: 1 day, 3:42:22  time: 0.4398  data_time: 0.0093  memory: 5145  grad_norm: 26.6175  loss: 5.3263  decode.loss_cls: 0.0735  decode.loss_mask: 0.2308  decode.loss_dice: 0.1595  decode.d0.loss_cls: 0.8542  decode.d0.loss_mask: 0.2215  decode.d0.loss_dice: 0.1694  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.2186  decode.d1.loss_dice: 0.1636  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.1614  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.2161  decode.d3.loss_dice: 0.1602  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.1565  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.1614  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.2242  decode.d6.loss_dice: 0.1630  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.2168  decode.d7.loss_dice: 0.1596  decode.d8.loss_cls: 0.0632  decode.d8.loss_mask: 0.2177  decode.d8.loss_dice: 0.1587
09/30 20:08:35 - mmengine - INFO - Iter(train) [ 91350/320000]  base_lr: 7.3896e-05 lr: 7.3896e-06  eta: 1 day, 3:42:01  time: 0.4404  data_time: 0.0095  memory: 5129  grad_norm: 55.0143  loss: 5.9261  decode.loss_cls: 0.0441  decode.loss_mask: 0.2328  decode.loss_dice: 0.2499  decode.d0.loss_cls: 0.7955  decode.d0.loss_mask: 0.2340  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.2300  decode.d1.loss_dice: 0.2400  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.2333  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.2502  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.2393  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.2340  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2421
09/30 20:08:57 - mmengine - INFO - Iter(train) [ 91400/320000]  base_lr: 7.3881e-05 lr: 7.3881e-06  eta: 1 day, 3:41:39  time: 0.4407  data_time: 0.0096  memory: 5120  grad_norm: 76.7971  loss: 4.7176  decode.loss_cls: 0.0119  decode.loss_mask: 0.2181  decode.loss_dice: 0.1629  decode.d0.loss_cls: 0.7841  decode.d0.loss_mask: 0.2208  decode.d0.loss_dice: 0.1609  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.1594  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.1632  decode.d3.loss_cls: 0.0115  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.1641  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.1632  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2145  decode.d6.loss_dice: 0.1611  decode.d7.loss_cls: 0.0116  decode.d7.loss_mask: 0.2156  decode.d7.loss_dice: 0.1642  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.1630
09/30 20:09:19 - mmengine - INFO - Iter(train) [ 91450/320000]  base_lr: 7.3867e-05 lr: 7.3867e-06  eta: 1 day, 3:41:18  time: 0.4414  data_time: 0.0099  memory: 5120  grad_norm: 63.4907  loss: 5.9306  decode.loss_cls: 0.0595  decode.loss_mask: 0.2311  decode.loss_dice: 0.2508  decode.d0.loss_cls: 0.7513  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2658  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.2729  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.2330  decode.d2.loss_dice: 0.2527  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.2596  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.2299  decode.d4.loss_dice: 0.2622  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2592  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.2279  decode.d6.loss_dice: 0.2578  decode.d7.loss_cls: 0.0368  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2537  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.2310  decode.d8.loss_dice: 0.2586
09/30 20:09:41 - mmengine - INFO - Iter(train) [ 91500/320000]  base_lr: 7.3852e-05 lr: 7.3852e-06  eta: 1 day, 3:40:57  time: 0.4405  data_time: 0.0099  memory: 5129  grad_norm: 54.7748  loss: 6.1781  decode.loss_cls: 0.0330  decode.loss_mask: 0.2708  decode.loss_dice: 0.2256  decode.d0.loss_cls: 0.8774  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.2282  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.2081  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.2677  decode.d2.loss_dice: 0.2144  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.2723  decode.d3.loss_dice: 0.2237  decode.d4.loss_cls: 0.0364  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.2278  decode.d5.loss_cls: 0.0309  decode.d5.loss_mask: 0.2672  decode.d5.loss_dice: 0.2285  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.2156  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.2707  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.0311  decode.d8.loss_mask: 0.2731  decode.d8.loss_dice: 0.2284
09/30 20:10:03 - mmengine - INFO - Iter(train) [ 91550/320000]  base_lr: 7.3838e-05 lr: 7.3838e-06  eta: 1 day, 3:40:36  time: 0.4408  data_time: 0.0099  memory: 5129  grad_norm: 49.5584  loss: 6.4213  decode.loss_cls: 0.0579  decode.loss_mask: 0.2243  decode.loss_dice: 0.2823  decode.d0.loss_cls: 0.8128  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.1508  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.2222  decode.d3.loss_dice: 0.2760  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.2258  decode.d4.loss_dice: 0.2604  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.2658  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2627  decode.d7.loss_cls: 0.0870  decode.d7.loss_mask: 0.2210  decode.d7.loss_dice: 0.2619  decode.d8.loss_cls: 0.0957  decode.d8.loss_mask: 0.2256  decode.d8.loss_dice: 0.2505
09/30 20:10:25 - mmengine - INFO - Iter(train) [ 91600/320000]  base_lr: 7.3823e-05 lr: 7.3823e-06  eta: 1 day, 3:40:14  time: 0.4405  data_time: 0.0099  memory: 5129  grad_norm: 39.9362  loss: 4.5829  decode.loss_cls: 0.0114  decode.loss_mask: 0.1900  decode.loss_dice: 0.1824  decode.d0.loss_cls: 0.7609  decode.d0.loss_mask: 0.1946  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1831  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.1802  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.1876  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.1917  decode.d4.loss_dice: 0.1862  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.1884  decode.d5.loss_dice: 0.1801  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.1784  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.1888  decode.d7.loss_dice: 0.1823  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.1897  decode.d8.loss_dice: 0.1821
09/30 20:10:48 - mmengine - INFO - Iter(train) [ 91650/320000]  base_lr: 7.3809e-05 lr: 7.3809e-06  eta: 1 day, 3:39:53  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 40.9851  loss: 5.1880  decode.loss_cls: 0.0065  decode.loss_mask: 0.2329  decode.loss_dice: 0.1871  decode.d0.loss_cls: 0.9078  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.1850  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.2314  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.1861  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.2300  decode.d3.loss_dice: 0.1849  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.2306  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2324  decode.d5.loss_dice: 0.1913  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.1850  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.2317  decode.d8.loss_dice: 0.1860
09/30 20:11:10 - mmengine - INFO - Iter(train) [ 91700/320000]  base_lr: 7.3794e-05 lr: 7.3794e-06  eta: 1 day, 3:39:32  time: 0.4404  data_time: 0.0098  memory: 5129  grad_norm: 235.3498  loss: 6.2414  decode.loss_cls: 0.0619  decode.loss_mask: 0.2830  decode.loss_dice: 0.1974  decode.d0.loss_cls: 0.8882  decode.d0.loss_mask: 0.2785  decode.d0.loss_dice: 0.1976  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.0481  decode.d2.loss_mask: 0.2931  decode.d2.loss_dice: 0.2015  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.2882  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.1946  decode.d5.loss_cls: 0.0687  decode.d5.loss_mask: 0.2853  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.2777  decode.d6.loss_dice: 0.1917  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.1959  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.2869  decode.d8.loss_dice: 0.1964
09/30 20:11:32 - mmengine - INFO - Iter(train) [ 91750/320000]  base_lr: 7.3780e-05 lr: 7.3780e-06  eta: 1 day, 3:39:11  time: 0.4420  data_time: 0.0100  memory: 5120  grad_norm: 52.5723  loss: 8.7021  decode.loss_cls: 0.2499  decode.loss_mask: 0.2608  decode.loss_dice: 0.2009  decode.d0.loss_cls: 1.0961  decode.d0.loss_mask: 0.2714  decode.d0.loss_dice: 0.2225  decode.d1.loss_cls: 0.3106  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.2017  decode.d2.loss_cls: 0.1860  decode.d2.loss_mask: 0.2581  decode.d2.loss_dice: 0.2519  decode.d3.loss_cls: 0.1741  decode.d3.loss_mask: 0.2644  decode.d3.loss_dice: 0.2722  decode.d4.loss_cls: 0.1908  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.2363  decode.d5.loss_cls: 0.2675  decode.d5.loss_mask: 0.4168  decode.d5.loss_dice: 0.2386  decode.d6.loss_cls: 0.2224  decode.d6.loss_mask: 0.2771  decode.d6.loss_dice: 0.2446  decode.d7.loss_cls: 0.2685  decode.d7.loss_mask: 0.3855  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.2027  decode.d8.loss_mask: 0.4918  decode.d8.loss_dice: 0.2850
09/30 20:11:54 - mmengine - INFO - Iter(train) [ 91800/320000]  base_lr: 7.3765e-05 lr: 7.3765e-06  eta: 1 day, 3:38:50  time: 0.4410  data_time: 0.0097  memory: 5145  grad_norm: 193.5866  loss: 6.2775  decode.loss_cls: 0.0419  decode.loss_mask: 0.3073  decode.loss_dice: 0.1862  decode.d0.loss_cls: 0.8481  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.1887  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.1804  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.3110  decode.d2.loss_dice: 0.1848  decode.d3.loss_cls: 0.0498  decode.d3.loss_mask: 0.3100  decode.d3.loss_dice: 0.1836  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.3030  decode.d4.loss_dice: 0.1839  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.1848  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.3106  decode.d6.loss_dice: 0.1805  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.1830  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 0.3106  decode.d8.loss_dice: 0.1840
09/30 20:12:16 - mmengine - INFO - Iter(train) [ 91850/320000]  base_lr: 7.3750e-05 lr: 7.3750e-06  eta: 1 day, 3:38:28  time: 0.4422  data_time: 0.0096  memory: 5145  grad_norm: 69.9615  loss: 7.3758  decode.loss_cls: 0.2262  decode.loss_mask: 0.2043  decode.loss_dice: 0.2344  decode.d0.loss_cls: 0.9549  decode.d0.loss_mask: 0.2048  decode.d0.loss_dice: 0.2288  decode.d1.loss_cls: 0.2382  decode.d1.loss_mask: 0.2025  decode.d1.loss_dice: 0.2269  decode.d2.loss_cls: 0.2420  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.2138  decode.d3.loss_cls: 0.2520  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.1611  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2219  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 0.2488  decode.d5.loss_dice: 0.2240  decode.d6.loss_cls: 0.1803  decode.d6.loss_mask: 0.2514  decode.d6.loss_dice: 0.2420  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 0.2642  decode.d7.loss_dice: 0.2337  decode.d8.loss_cls: 0.2295  decode.d8.loss_mask: 0.2006  decode.d8.loss_dice: 0.2008
09/30 20:12:38 - mmengine - INFO - Iter(train) [ 91900/320000]  base_lr: 7.3736e-05 lr: 7.3736e-06  eta: 1 day, 3:38:07  time: 0.4406  data_time: 0.0098  memory: 5120  grad_norm: 24.0656  loss: 5.0249  decode.loss_cls: 0.0371  decode.loss_mask: 0.2241  decode.loss_dice: 0.1760  decode.d0.loss_cls: 0.7059  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.1724  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.1706  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.2264  decode.d2.loss_dice: 0.1708  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.2268  decode.d4.loss_dice: 0.1736  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.2248  decode.d5.loss_dice: 0.1723  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.2244  decode.d6.loss_dice: 0.1736  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.2254  decode.d8.loss_dice: 0.1793
09/30 20:13:00 - mmengine - INFO - Iter(train) [ 91950/320000]  base_lr: 7.3721e-05 lr: 7.3721e-06  eta: 1 day, 3:37:46  time: 0.4422  data_time: 0.0095  memory: 5120  grad_norm: 24.9775  loss: 5.0518  decode.loss_cls: 0.0428  decode.loss_mask: 0.1532  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.9727  decode.d0.loss_mask: 0.1527  decode.d0.loss_dice: 0.2064  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.1539  decode.d1.loss_dice: 0.2038  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.1513  decode.d2.loss_dice: 0.1974  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.1535  decode.d3.loss_dice: 0.2136  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.1532  decode.d4.loss_dice: 0.2092  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.1558  decode.d5.loss_dice: 0.2118  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.1534  decode.d6.loss_dice: 0.2034  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.1542  decode.d7.loss_dice: 0.2097  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.1552  decode.d8.loss_dice: 0.2088
09/30 20:13:22 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:13:22 - mmengine - INFO - Iter(train) [ 92000/320000]  base_lr: 7.3707e-05 lr: 7.3707e-06  eta: 1 day, 3:37:24  time: 0.4406  data_time: 0.0098  memory: 5129  grad_norm: 23.6887  loss: 4.5441  decode.loss_cls: 0.0059  decode.loss_mask: 0.2169  decode.loss_dice: 0.1489  decode.d0.loss_cls: 0.8038  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.1505  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.1508  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.2198  decode.d2.loss_dice: 0.1512  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.1511  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.2144  decode.d4.loss_dice: 0.1478  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.1502  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2189  decode.d6.loss_dice: 0.1493  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2192  decode.d7.loss_dice: 0.1530  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2161  decode.d8.loss_dice: 0.1510
09/30 20:13:44 - mmengine - INFO - Iter(train) [ 92050/320000]  base_lr: 7.3692e-05 lr: 7.3692e-06  eta: 1 day, 3:37:03  time: 0.4397  data_time: 0.0096  memory: 5145  grad_norm: 46.4846  loss: 5.9062  decode.loss_cls: 0.0694  decode.loss_mask: 0.2410  decode.loss_dice: 0.1986  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.1906  decode.d1.loss_cls: 0.1543  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.2411  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.2403  decode.d3.loss_dice: 0.1891  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.1887  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.1913  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.1855  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.1877  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.1996
09/30 20:14:06 - mmengine - INFO - Iter(train) [ 92100/320000]  base_lr: 7.3678e-05 lr: 7.3678e-06  eta: 1 day, 3:36:42  time: 0.4397  data_time: 0.0096  memory: 5129  grad_norm: 78.1210  loss: 6.4244  decode.loss_cls: 0.0953  decode.loss_mask: 0.2330  decode.loss_dice: 0.2125  decode.d0.loss_cls: 0.8821  decode.d0.loss_mask: 0.2379  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.1542  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.2166  decode.d2.loss_cls: 0.1145  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.2060  decode.d3.loss_cls: 0.1295  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.2093  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 0.2342  decode.d4.loss_dice: 0.2101  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.2320  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.1168  decode.d6.loss_mask: 0.2339  decode.d6.loss_dice: 0.2133  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.2278  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.2319  decode.d8.loss_dice: 0.2133
09/30 20:14:28 - mmengine - INFO - Iter(train) [ 92150/320000]  base_lr: 7.3663e-05 lr: 7.3663e-06  eta: 1 day, 3:36:20  time: 0.4397  data_time: 0.0095  memory: 5129  grad_norm: 35.2169  loss: 5.3942  decode.loss_cls: 0.0644  decode.loss_mask: 0.2055  decode.loss_dice: 0.2000  decode.d0.loss_cls: 0.7618  decode.d0.loss_mask: 0.2086  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.2055  decode.d1.loss_dice: 0.1991  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.2002  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.2045  decode.d3.loss_dice: 0.2011  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.2000  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.2021  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.2032  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.2070  decode.d7.loss_dice: 0.1931  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.1956
09/30 20:14:50 - mmengine - INFO - Iter(train) [ 92200/320000]  base_lr: 7.3649e-05 lr: 7.3649e-06  eta: 1 day, 3:35:59  time: 0.4411  data_time: 0.0098  memory: 5145  grad_norm: 57.9691  loss: 7.2320  decode.loss_cls: 0.1995  decode.loss_mask: 0.2164  decode.loss_dice: 0.1897  decode.d0.loss_cls: 0.9100  decode.d0.loss_mask: 0.2269  decode.d0.loss_dice: 0.1986  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.2085  decode.d2.loss_cls: 0.1915  decode.d2.loss_mask: 0.2187  decode.d2.loss_dice: 0.1832  decode.d3.loss_cls: 0.1950  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.1854  decode.d4.loss_cls: 0.1349  decode.d4.loss_mask: 0.3864  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.1959  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.2257  decode.d6.loss_cls: 0.1818  decode.d6.loss_mask: 0.2255  decode.d6.loss_dice: 0.1905  decode.d7.loss_cls: 0.1070  decode.d7.loss_mask: 0.4757  decode.d7.loss_dice: 0.2245  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1824
09/30 20:15:12 - mmengine - INFO - Iter(train) [ 92250/320000]  base_lr: 7.3634e-05 lr: 7.3634e-06  eta: 1 day, 3:35:38  time: 0.4400  data_time: 0.0096  memory: 5145  grad_norm: 102.3661  loss: 5.5998  decode.loss_cls: 0.1245  decode.loss_mask: 0.1768  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.8964  decode.d0.loss_mask: 0.1780  decode.d0.loss_dice: 0.2035  decode.d1.loss_cls: 0.0998  decode.d1.loss_mask: 0.1763  decode.d1.loss_dice: 0.1858  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.1776  decode.d2.loss_dice: 0.1861  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 0.1772  decode.d3.loss_dice: 0.1851  decode.d4.loss_cls: 0.0993  decode.d4.loss_mask: 0.1763  decode.d4.loss_dice: 0.1839  decode.d5.loss_cls: 0.1072  decode.d5.loss_mask: 0.1761  decode.d5.loss_dice: 0.1855  decode.d6.loss_cls: 0.1076  decode.d6.loss_mask: 0.1760  decode.d6.loss_dice: 0.1827  decode.d7.loss_cls: 0.1824  decode.d7.loss_mask: 0.1769  decode.d7.loss_dice: 0.1764  decode.d8.loss_cls: 0.1473  decode.d8.loss_mask: 0.1769  decode.d8.loss_dice: 0.1894
09/30 20:15:34 - mmengine - INFO - Iter(train) [ 92300/320000]  base_lr: 7.3620e-05 lr: 7.3620e-06  eta: 1 day, 3:35:17  time: 0.4402  data_time: 0.0098  memory: 5145  grad_norm: 77.5308  loss: 5.8641  decode.loss_cls: 0.1457  decode.loss_mask: 0.2248  decode.loss_dice: 0.1730  decode.d0.loss_cls: 0.8598  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.1508  decode.d1.loss_cls: 0.0871  decode.d1.loss_mask: 0.2227  decode.d1.loss_dice: 0.1649  decode.d2.loss_cls: 0.1331  decode.d2.loss_mask: 0.2224  decode.d2.loss_dice: 0.1633  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.1674  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.2203  decode.d5.loss_dice: 0.1635  decode.d6.loss_cls: 0.1047  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.1621  decode.d7.loss_cls: 0.1372  decode.d7.loss_mask: 0.2224  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.1313  decode.d8.loss_mask: 0.2241  decode.d8.loss_dice: 0.1686
09/30 20:15:56 - mmengine - INFO - Iter(train) [ 92350/320000]  base_lr: 7.3605e-05 lr: 7.3605e-06  eta: 1 day, 3:34:56  time: 0.4397  data_time: 0.0095  memory: 5145  grad_norm: 27.7280  loss: 4.9384  decode.loss_cls: 0.0539  decode.loss_mask: 0.1984  decode.loss_dice: 0.1641  decode.d0.loss_cls: 0.8475  decode.d0.loss_mask: 0.1995  decode.d0.loss_dice: 0.1638  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.1989  decode.d1.loss_dice: 0.1666  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.1977  decode.d2.loss_dice: 0.1658  decode.d3.loss_cls: 0.0635  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.1620  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.1968  decode.d4.loss_dice: 0.1617  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.1964  decode.d5.loss_dice: 0.1631  decode.d6.loss_cls: 0.0461  decode.d6.loss_mask: 0.1960  decode.d6.loss_dice: 0.1604  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.1960  decode.d7.loss_dice: 0.1642  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.1983  decode.d8.loss_dice: 0.1631
09/30 20:16:18 - mmengine - INFO - Iter(train) [ 92400/320000]  base_lr: 7.3590e-05 lr: 7.3590e-06  eta: 1 day, 3:34:35  time: 0.4399  data_time: 0.0098  memory: 5129  grad_norm: 52.6439  loss: 9.0086  decode.loss_cls: 0.1699  decode.loss_mask: 0.2577  decode.loss_dice: 0.3224  decode.d0.loss_cls: 1.0538  decode.d0.loss_mask: 0.2521  decode.d0.loss_dice: 0.3737  decode.d1.loss_cls: 0.1945  decode.d1.loss_mask: 0.2564  decode.d1.loss_dice: 0.3778  decode.d2.loss_cls: 0.2828  decode.d2.loss_mask: 0.2524  decode.d2.loss_dice: 0.3697  decode.d3.loss_cls: 0.2120  decode.d3.loss_mask: 0.2541  decode.d3.loss_dice: 0.3438  decode.d4.loss_cls: 0.1647  decode.d4.loss_mask: 0.2546  decode.d4.loss_dice: 0.3704  decode.d5.loss_cls: 0.1675  decode.d5.loss_mask: 0.2604  decode.d5.loss_dice: 0.3473  decode.d6.loss_cls: 0.1956  decode.d6.loss_mask: 0.2548  decode.d6.loss_dice: 0.3638  decode.d7.loss_cls: 0.2138  decode.d7.loss_mask: 0.2538  decode.d7.loss_dice: 0.3590  decode.d8.loss_cls: 0.2247  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.3486
09/30 20:16:40 - mmengine - INFO - Iter(train) [ 92450/320000]  base_lr: 7.3576e-05 lr: 7.3576e-06  eta: 1 day, 3:34:13  time: 0.4404  data_time: 0.0097  memory: 5146  grad_norm: 54.9672  loss: 5.4134  decode.loss_cls: 0.0033  decode.loss_mask: 0.2463  decode.loss_dice: 0.1975  decode.d0.loss_cls: 0.8828  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.1991  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.2514  decode.d2.loss_dice: 0.2196  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.2513  decode.d3.loss_dice: 0.2191  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2483  decode.d4.loss_dice: 0.2059  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.2448  decode.d5.loss_dice: 0.1919  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.1991  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.2482  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.1976
09/30 20:17:02 - mmengine - INFO - Iter(train) [ 92500/320000]  base_lr: 7.3561e-05 lr: 7.3561e-06  eta: 1 day, 3:33:52  time: 0.4411  data_time: 0.0096  memory: 5145  grad_norm: 18.0953  loss: 4.3620  decode.loss_cls: 0.0042  decode.loss_mask: 0.2019  decode.loss_dice: 0.1516  decode.d0.loss_cls: 0.7695  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.1539  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.1532  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.1503  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.2039  decode.d3.loss_dice: 0.1497  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.2039  decode.d4.loss_dice: 0.1524  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.1528  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2031  decode.d6.loss_dice: 0.1520  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.2053  decode.d7.loss_dice: 0.1532  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.2034  decode.d8.loss_dice: 0.1501
09/30 20:17:24 - mmengine - INFO - Iter(train) [ 92550/320000]  base_lr: 7.3547e-05 lr: 7.3547e-06  eta: 1 day, 3:33:31  time: 0.4412  data_time: 0.0098  memory: 5129  grad_norm: 18.6229  loss: 4.1313  decode.loss_cls: 0.0027  decode.loss_mask: 0.2003  decode.loss_dice: 0.1372  decode.d0.loss_cls: 0.7329  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.1404  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.1386  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.2009  decode.d2.loss_dice: 0.1384  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.1998  decode.d3.loss_dice: 0.1377  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.1980  decode.d4.loss_dice: 0.1340  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.1396  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.1379  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.1976  decode.d7.loss_dice: 0.1366  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.1993  decode.d8.loss_dice: 0.1367
09/30 20:17:47 - mmengine - INFO - Iter(train) [ 92600/320000]  base_lr: 7.3532e-05 lr: 7.3532e-06  eta: 1 day, 3:33:10  time: 0.4406  data_time: 0.0098  memory: 5129  grad_norm: 86.1748  loss: 5.9508  decode.loss_cls: 0.1282  decode.loss_mask: 0.1780  decode.loss_dice: 0.1888  decode.d0.loss_cls: 0.9774  decode.d0.loss_mask: 0.1786  decode.d0.loss_dice: 0.1802  decode.d1.loss_cls: 0.1714  decode.d1.loss_mask: 0.1780  decode.d1.loss_dice: 0.1882  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.1797  decode.d2.loss_dice: 0.1866  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 0.1764  decode.d3.loss_dice: 0.1899  decode.d4.loss_cls: 0.1428  decode.d4.loss_mask: 0.1771  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.1293  decode.d5.loss_mask: 0.1762  decode.d5.loss_dice: 0.1895  decode.d6.loss_cls: 0.1199  decode.d6.loss_mask: 0.1771  decode.d6.loss_dice: 0.1830  decode.d7.loss_cls: 0.1375  decode.d7.loss_mask: 0.1780  decode.d7.loss_dice: 0.1883  decode.d8.loss_cls: 0.1384  decode.d8.loss_mask: 0.1769  decode.d8.loss_dice: 0.1933
09/30 20:18:09 - mmengine - INFO - Iter(train) [ 92650/320000]  base_lr: 7.3518e-05 lr: 7.3518e-06  eta: 1 day, 3:32:49  time: 0.4399  data_time: 0.0096  memory: 5120  grad_norm: 55.5046  loss: 7.0990  decode.loss_cls: 0.1841  decode.loss_mask: 0.1796  decode.loss_dice: 0.2674  decode.d0.loss_cls: 1.0318  decode.d0.loss_mask: 0.1806  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.2634  decode.d1.loss_mask: 0.1775  decode.d1.loss_dice: 0.2242  decode.d2.loss_cls: 0.1886  decode.d2.loss_mask: 0.1782  decode.d2.loss_dice: 0.2457  decode.d3.loss_cls: 0.2194  decode.d3.loss_mask: 0.1781  decode.d3.loss_dice: 0.2452  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 0.1811  decode.d4.loss_dice: 0.2415  decode.d5.loss_cls: 0.2226  decode.d5.loss_mask: 0.1799  decode.d5.loss_dice: 0.2797  decode.d6.loss_cls: 0.1453  decode.d6.loss_mask: 0.1808  decode.d6.loss_dice: 0.2688  decode.d7.loss_cls: 0.1702  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.1774  decode.d8.loss_dice: 0.2484
09/30 20:18:31 - mmengine - INFO - Iter(train) [ 92700/320000]  base_lr: 7.3503e-05 lr: 7.3503e-06  eta: 1 day, 3:32:27  time: 0.4398  data_time: 0.0096  memory: 5129  grad_norm: 28.1163  loss: 5.0642  decode.loss_cls: 0.0086  decode.loss_mask: 0.2395  decode.loss_dice: 0.1796  decode.d0.loss_cls: 0.7070  decode.d0.loss_mask: 0.2455  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.0523  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.1796  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.1774  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.1802  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.1823  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.2406  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.2429  decode.d8.loss_dice: 0.1793
09/30 20:18:53 - mmengine - INFO - Iter(train) [ 92750/320000]  base_lr: 7.3489e-05 lr: 7.3489e-06  eta: 1 day, 3:32:06  time: 0.4414  data_time: 0.0096  memory: 5130  grad_norm: 21.1186  loss: 4.4496  decode.loss_cls: 0.0040  decode.loss_mask: 0.1639  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.8598  decode.d0.loss_mask: 0.1666  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.1652  decode.d1.loss_dice: 0.1628  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.1654  decode.d2.loss_dice: 0.1986  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1649  decode.d3.loss_dice: 0.1831  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.1654  decode.d4.loss_dice: 0.1628  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.1652  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.1637  decode.d6.loss_dice: 0.1768  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.1641  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.1650  decode.d8.loss_dice: 0.1839
09/30 20:19:15 - mmengine - INFO - Iter(train) [ 92800/320000]  base_lr: 7.3474e-05 lr: 7.3474e-06  eta: 1 day, 3:31:45  time: 0.4417  data_time: 0.0098  memory: 5129  grad_norm: 55.2528  loss: 5.9545  decode.loss_cls: 0.0148  decode.loss_mask: 0.2652  decode.loss_dice: 0.2319  decode.d0.loss_cls: 0.8319  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.2437  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2186  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.2619  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.2620  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.2647  decode.d4.loss_dice: 0.2292  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.2262  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.2656  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2632  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.2653  decode.d8.loss_dice: 0.2204
09/30 20:19:37 - mmengine - INFO - Iter(train) [ 92850/320000]  base_lr: 7.3459e-05 lr: 7.3459e-06  eta: 1 day, 3:31:24  time: 0.4400  data_time: 0.0096  memory: 5129  grad_norm: 73.0537  loss: 7.8495  decode.loss_cls: 0.2488  decode.loss_mask: 0.2602  decode.loss_dice: 0.2120  decode.d0.loss_cls: 0.9036  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.2100  decode.d1.loss_cls: 0.2313  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2046  decode.d2.loss_cls: 0.2253  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.2026  decode.d3.loss_cls: 0.2647  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.3001  decode.d4.loss_mask: 0.2605  decode.d4.loss_dice: 0.2056  decode.d5.loss_cls: 0.3074  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.2623  decode.d6.loss_mask: 0.2517  decode.d6.loss_dice: 0.2038  decode.d7.loss_cls: 0.2625  decode.d7.loss_mask: 0.2519  decode.d7.loss_dice: 0.1977  decode.d8.loss_cls: 0.2567  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.2174
09/30 20:19:59 - mmengine - INFO - Iter(train) [ 92900/320000]  base_lr: 7.3445e-05 lr: 7.3445e-06  eta: 1 day, 3:31:02  time: 0.4405  data_time: 0.0097  memory: 5129  grad_norm: 59.2822  loss: 8.0135  decode.loss_cls: 0.1792  decode.loss_mask: 0.2472  decode.loss_dice: 0.2582  decode.d0.loss_cls: 1.0134  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.2764  decode.d1.loss_cls: 0.2303  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.2776  decode.d2.loss_cls: 0.1951  decode.d2.loss_mask: 0.2638  decode.d2.loss_dice: 0.2485  decode.d3.loss_cls: 0.1645  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3074  decode.d4.loss_cls: 0.1831  decode.d4.loss_mask: 0.2731  decode.d4.loss_dice: 0.2557  decode.d5.loss_cls: 0.1672  decode.d5.loss_mask: 0.3427  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.1893  decode.d6.loss_mask: 0.2451  decode.d6.loss_dice: 0.2330  decode.d7.loss_cls: 0.2215  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.1739  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2327
09/30 20:20:21 - mmengine - INFO - Iter(train) [ 92950/320000]  base_lr: 7.3430e-05 lr: 7.3430e-06  eta: 1 day, 3:30:41  time: 0.4419  data_time: 0.0101  memory: 5129  grad_norm: 22.1604  loss: 4.8401  decode.loss_cls: 0.0011  decode.loss_mask: 0.2035  decode.loss_dice: 0.1950  decode.d0.loss_cls: 0.7936  decode.d0.loss_mask: 0.2137  decode.d0.loss_dice: 0.2069  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.2051  decode.d2.loss_dice: 0.1956  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.2046  decode.d3.loss_dice: 0.1899  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2064  decode.d5.loss_dice: 0.1985  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2086  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.2068  decode.d7.loss_dice: 0.1932  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.1915
09/30 20:20:43 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:20:43 - mmengine - INFO - Iter(train) [ 93000/320000]  base_lr: 7.3416e-05 lr: 7.3416e-06  eta: 1 day, 3:30:20  time: 0.4412  data_time: 0.0097  memory: 5145  grad_norm: 148.8280  loss: 5.5451  decode.loss_cls: 0.0839  decode.loss_mask: 0.1856  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.8059  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.1008  decode.d1.loss_mask: 0.1885  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.1872  decode.d2.loss_dice: 0.1929  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.1877  decode.d3.loss_dice: 0.1880  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.2061  decode.d5.loss_cls: 0.1027  decode.d5.loss_mask: 0.1887  decode.d5.loss_dice: 0.2086  decode.d6.loss_cls: 0.0963  decode.d6.loss_mask: 0.1860  decode.d6.loss_dice: 0.2103  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.1866  decode.d7.loss_dice: 0.2147  decode.d8.loss_cls: 0.0899  decode.d8.loss_mask: 0.1870  decode.d8.loss_dice: 0.1990
09/30 20:21:05 - mmengine - INFO - Iter(train) [ 93050/320000]  base_lr: 7.3401e-05 lr: 7.3401e-06  eta: 1 day, 3:29:59  time: 0.4399  data_time: 0.0096  memory: 5145  grad_norm: 26.7964  loss: 4.5924  decode.loss_cls: 0.0030  decode.loss_mask: 0.1909  decode.loss_dice: 0.1717  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.1777  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.1935  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.1922  decode.d2.loss_dice: 0.1713  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.1726  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.1935  decode.d4.loss_dice: 0.1750  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.1770  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.1754  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.1920  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.1735
09/30 20:21:27 - mmengine - INFO - Iter(train) [ 93100/320000]  base_lr: 7.3387e-05 lr: 7.3387e-06  eta: 1 day, 3:29:37  time: 0.4407  data_time: 0.0095  memory: 5129  grad_norm: 48.0402  loss: 5.6390  decode.loss_cls: 0.0749  decode.loss_mask: 0.1967  decode.loss_dice: 0.2064  decode.d0.loss_cls: 0.9458  decode.d0.loss_mask: 0.1975  decode.d0.loss_dice: 0.2069  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.1986  decode.d1.loss_dice: 0.1994  decode.d2.loss_cls: 0.0827  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.2058  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.1963  decode.d3.loss_dice: 0.2063  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.1964  decode.d4.loss_dice: 0.2058  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.2004  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.1989  decode.d6.loss_dice: 0.2097  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.1949  decode.d7.loss_dice: 0.2055  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.1984  decode.d8.loss_dice: 0.1983
09/30 20:21:49 - mmengine - INFO - Iter(train) [ 93150/320000]  base_lr: 7.3372e-05 lr: 7.3372e-06  eta: 1 day, 3:29:16  time: 0.4403  data_time: 0.0096  memory: 5120  grad_norm: 64.2963  loss: 5.7509  decode.loss_cls: 0.0659  decode.loss_mask: 0.1857  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.9319  decode.d0.loss_mask: 0.1820  decode.d0.loss_dice: 0.2195  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 0.1882  decode.d1.loss_dice: 0.2271  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.1894  decode.d2.loss_dice: 0.2365  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.2241  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.1894  decode.d4.loss_dice: 0.2252  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.1903  decode.d5.loss_dice: 0.2267  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.1891  decode.d6.loss_dice: 0.2250  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.1843  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.1861  decode.d8.loss_dice: 0.2223
09/30 20:22:11 - mmengine - INFO - Iter(train) [ 93200/320000]  base_lr: 7.3358e-05 lr: 7.3358e-06  eta: 1 day, 3:28:55  time: 0.4408  data_time: 0.0097  memory: 5145  grad_norm: 49.8007  loss: 5.9746  decode.loss_cls: 0.0917  decode.loss_mask: 0.1870  decode.loss_dice: 0.2560  decode.d0.loss_cls: 0.9345  decode.d0.loss_mask: 0.1888  decode.d0.loss_dice: 0.2429  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.1890  decode.d1.loss_dice: 0.2233  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.2164  decode.d3.loss_cls: 0.0836  decode.d3.loss_mask: 0.1858  decode.d3.loss_dice: 0.2275  decode.d4.loss_cls: 0.1251  decode.d4.loss_mask: 0.1901  decode.d4.loss_dice: 0.2228  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 0.1865  decode.d5.loss_dice: 0.2415  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.1874  decode.d6.loss_dice: 0.2293  decode.d7.loss_cls: 0.0696  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.2037  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.1851  decode.d8.loss_dice: 0.2297
09/30 20:22:33 - mmengine - INFO - Iter(train) [ 93250/320000]  base_lr: 7.3343e-05 lr: 7.3343e-06  eta: 1 day, 3:28:33  time: 0.4396  data_time: 0.0094  memory: 5129  grad_norm: 48.8722  loss: 4.9157  decode.loss_cls: 0.0447  decode.loss_mask: 0.1830  decode.loss_dice: 0.1623  decode.d0.loss_cls: 0.8997  decode.d0.loss_mask: 0.1796  decode.d0.loss_dice: 0.1641  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.1830  decode.d1.loss_dice: 0.1596  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 0.1835  decode.d2.loss_dice: 0.1631  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.1811  decode.d3.loss_dice: 0.1628  decode.d4.loss_cls: 0.0838  decode.d4.loss_mask: 0.1812  decode.d4.loss_dice: 0.1573  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.1825  decode.d5.loss_dice: 0.1578  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.1820  decode.d6.loss_dice: 0.1577  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.1797  decode.d7.loss_dice: 0.1590  decode.d8.loss_cls: 0.0578  decode.d8.loss_mask: 0.1822  decode.d8.loss_dice: 0.1690
09/30 20:22:55 - mmengine - INFO - Iter(train) [ 93300/320000]  base_lr: 7.3328e-05 lr: 7.3328e-06  eta: 1 day, 3:28:12  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 236.8893  loss: 6.1121  decode.loss_cls: 0.0663  decode.loss_mask: 0.2656  decode.loss_dice: 0.1983  decode.d0.loss_cls: 0.7572  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.2058  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.2681  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.0664  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.2055  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.2651  decode.d3.loss_dice: 0.2051  decode.d4.loss_cls: 0.0684  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.2674  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.2637  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.2128
09/30 20:23:17 - mmengine - INFO - Iter(train) [ 93350/320000]  base_lr: 7.3314e-05 lr: 7.3314e-06  eta: 1 day, 3:27:51  time: 0.4401  data_time: 0.0096  memory: 5145  grad_norm: 30.4327  loss: 5.3974  decode.loss_cls: 0.0031  decode.loss_mask: 0.2478  decode.loss_dice: 0.1988  decode.d0.loss_cls: 0.7831  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.2203  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.2014  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2018  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.2043  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.1957  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.2481  decode.d5.loss_dice: 0.2012  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.1994  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2491  decode.d7.loss_dice: 0.2032  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.2501  decode.d8.loss_dice: 0.1962
09/30 20:23:39 - mmengine - INFO - Iter(train) [ 93400/320000]  base_lr: 7.3299e-05 lr: 7.3299e-06  eta: 1 day, 3:27:30  time: 0.4421  data_time: 0.0095  memory: 5145  grad_norm: 48.8234  loss: 5.1645  decode.loss_cls: 0.0923  decode.loss_mask: 0.1849  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.8445  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.1804  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.1852  decode.d1.loss_dice: 0.1790  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.1862  decode.d2.loss_dice: 0.1825  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.1814  decode.d3.loss_dice: 0.2033  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.1727  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.1732  decode.d5.loss_dice: 0.2055  decode.d6.loss_cls: 0.0917  decode.d6.loss_mask: 0.1794  decode.d6.loss_dice: 0.1707  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 0.1836  decode.d7.loss_dice: 0.1922  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.1825  decode.d8.loss_dice: 0.1710
09/30 20:24:01 - mmengine - INFO - Iter(train) [ 93450/320000]  base_lr: 7.3285e-05 lr: 7.3285e-06  eta: 1 day, 3:27:08  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 46.0328  loss: 6.8610  decode.loss_cls: 0.1717  decode.loss_mask: 0.2250  decode.loss_dice: 0.1984  decode.d0.loss_cls: 0.9389  decode.d0.loss_mask: 0.2273  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.2280  decode.d1.loss_dice: 0.1989  decode.d2.loss_cls: 0.1680  decode.d2.loss_mask: 0.2306  decode.d2.loss_dice: 0.1958  decode.d3.loss_cls: 0.2018  decode.d3.loss_mask: 0.2235  decode.d3.loss_dice: 0.2010  decode.d4.loss_cls: 0.1585  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.1947  decode.d5.loss_cls: 0.1738  decode.d5.loss_mask: 0.2301  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.2156  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.1965  decode.d7.loss_cls: 0.1776  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.1960  decode.d8.loss_cls: 0.1926  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.2014
09/30 20:24:23 - mmengine - INFO - Iter(train) [ 93500/320000]  base_lr: 7.3270e-05 lr: 7.3270e-06  eta: 1 day, 3:26:47  time: 0.4431  data_time: 0.0098  memory: 5129  grad_norm: 64.2981  loss: 5.8765  decode.loss_cls: 0.1035  decode.loss_mask: 0.1838  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.9690  decode.d0.loss_mask: 0.1863  decode.d0.loss_dice: 0.2380  decode.d1.loss_cls: 0.1551  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.2096  decode.d2.loss_cls: 0.1241  decode.d2.loss_mask: 0.1830  decode.d2.loss_dice: 0.1992  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 0.1840  decode.d4.loss_dice: 0.1994  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 0.1826  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.1070  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.2164  decode.d7.loss_cls: 0.1044  decode.d7.loss_mask: 0.1839  decode.d7.loss_dice: 0.2160  decode.d8.loss_cls: 0.1195  decode.d8.loss_mask: 0.1813  decode.d8.loss_dice: 0.1915
09/30 20:24:45 - mmengine - INFO - Iter(train) [ 93550/320000]  base_lr: 7.3256e-05 lr: 7.3256e-06  eta: 1 day, 3:26:26  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 42.5042  loss: 5.5015  decode.loss_cls: 0.1234  decode.loss_mask: 0.1700  decode.loss_dice: 0.1798  decode.d0.loss_cls: 0.9649  decode.d0.loss_mask: 0.1723  decode.d0.loss_dice: 0.1611  decode.d1.loss_cls: 0.1614  decode.d1.loss_mask: 0.1885  decode.d1.loss_dice: 0.1930  decode.d2.loss_cls: 0.1372  decode.d2.loss_mask: 0.1700  decode.d2.loss_dice: 0.1624  decode.d3.loss_cls: 0.1194  decode.d3.loss_mask: 0.1705  decode.d3.loss_dice: 0.1755  decode.d4.loss_cls: 0.1368  decode.d4.loss_mask: 0.1691  decode.d4.loss_dice: 0.1619  decode.d5.loss_cls: 0.1246  decode.d5.loss_mask: 0.1678  decode.d5.loss_dice: 0.1612  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 0.1685  decode.d6.loss_dice: 0.1647  decode.d7.loss_cls: 0.1149  decode.d7.loss_mask: 0.1705  decode.d7.loss_dice: 0.1679  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.1705  decode.d8.loss_dice: 0.1684
09/30 20:25:08 - mmengine - INFO - Iter(train) [ 93600/320000]  base_lr: 7.3241e-05 lr: 7.3241e-06  eta: 1 day, 3:26:05  time: 0.4402  data_time: 0.0095  memory: 5129  grad_norm: 46.9913  loss: 4.6820  decode.loss_cls: 0.0434  decode.loss_mask: 0.1783  decode.loss_dice: 0.1407  decode.d0.loss_cls: 0.8224  decode.d0.loss_mask: 0.1775  decode.d0.loss_dice: 0.1476  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 0.1766  decode.d1.loss_dice: 0.1439  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.1834  decode.d2.loss_dice: 0.1409  decode.d3.loss_cls: 0.1126  decode.d3.loss_mask: 0.1771  decode.d3.loss_dice: 0.1394  decode.d4.loss_cls: 0.1118  decode.d4.loss_mask: 0.1844  decode.d4.loss_dice: 0.1434  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.1787  decode.d5.loss_dice: 0.1400  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.1779  decode.d6.loss_dice: 0.1429  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.1808  decode.d7.loss_dice: 0.1422  decode.d8.loss_cls: 0.0474  decode.d8.loss_mask: 0.1769  decode.d8.loss_dice: 0.1418
09/30 20:25:30 - mmengine - INFO - Iter(train) [ 93650/320000]  base_lr: 7.3227e-05 lr: 7.3227e-06  eta: 1 day, 3:25:43  time: 0.4398  data_time: 0.0095  memory: 5145  grad_norm: 47.2650  loss: 5.2112  decode.loss_cls: 0.0790  decode.loss_mask: 0.1703  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.7092  decode.d0.loss_mask: 0.1743  decode.d0.loss_dice: 0.1864  decode.d1.loss_cls: 0.2055  decode.d1.loss_mask: 0.1737  decode.d1.loss_dice: 0.1935  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.1710  decode.d2.loss_dice: 0.1853  decode.d3.loss_cls: 0.1302  decode.d3.loss_mask: 0.1736  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.1477  decode.d4.loss_mask: 0.1754  decode.d4.loss_dice: 0.1784  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.1713  decode.d5.loss_dice: 0.1993  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.1724  decode.d6.loss_dice: 0.2111  decode.d7.loss_cls: 0.0526  decode.d7.loss_mask: 0.1727  decode.d7.loss_dice: 0.1764  decode.d8.loss_cls: 0.0558  decode.d8.loss_mask: 0.1706  decode.d8.loss_dice: 0.1814
09/30 20:25:52 - mmengine - INFO - Iter(train) [ 93700/320000]  base_lr: 7.3212e-05 lr: 7.3212e-06  eta: 1 day, 3:25:22  time: 0.4402  data_time: 0.0097  memory: 5129  grad_norm: 59.1838  loss: 6.5865  decode.loss_cls: 0.0946  decode.loss_mask: 0.2689  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.7455  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.2247  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.1035  decode.d3.loss_mask: 0.2662  decode.d3.loss_dice: 0.2248  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.2199  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.2323  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2686  decode.d6.loss_dice: 0.2131  decode.d7.loss_cls: 0.1214  decode.d7.loss_mask: 0.2722  decode.d7.loss_dice: 0.2245  decode.d8.loss_cls: 0.1218  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.2147
09/30 20:26:14 - mmengine - INFO - Iter(train) [ 93750/320000]  base_lr: 7.3197e-05 lr: 7.3197e-06  eta: 1 day, 3:25:01  time: 0.4403  data_time: 0.0098  memory: 5129  grad_norm: 59.9287  loss: 6.9239  decode.loss_cls: 0.1171  decode.loss_mask: 0.2866  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.8781  decode.d0.loss_mask: 0.2915  decode.d0.loss_dice: 0.2322  decode.d1.loss_cls: 0.1513  decode.d1.loss_mask: 0.2875  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.1227  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.2242  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.3141  decode.d3.loss_dice: 0.2451  decode.d4.loss_cls: 0.0803  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.2246  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.2837  decode.d5.loss_dice: 0.2272  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.2892  decode.d6.loss_dice: 0.2188  decode.d7.loss_cls: 0.0654  decode.d7.loss_mask: 0.2973  decode.d7.loss_dice: 0.2291  decode.d8.loss_cls: 0.0908  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.2224
09/30 20:26:36 - mmengine - INFO - Iter(train) [ 93800/320000]  base_lr: 7.3183e-05 lr: 7.3183e-06  eta: 1 day, 3:24:39  time: 0.4403  data_time: 0.0096  memory: 5129  grad_norm: 44.3552  loss: 7.2996  decode.loss_cls: 0.1178  decode.loss_mask: 0.2040  decode.loss_dice: 0.2956  decode.d0.loss_cls: 1.1158  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.2962  decode.d1.loss_cls: 0.1537  decode.d1.loss_mask: 0.2033  decode.d1.loss_dice: 0.2963  decode.d2.loss_cls: 0.1475  decode.d2.loss_mask: 0.2036  decode.d2.loss_dice: 0.2876  decode.d3.loss_cls: 0.1568  decode.d3.loss_mask: 0.2007  decode.d3.loss_dice: 0.2960  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.2049  decode.d4.loss_dice: 0.3101  decode.d5.loss_cls: 0.1244  decode.d5.loss_mask: 0.2008  decode.d5.loss_dice: 0.3063  decode.d6.loss_cls: 0.1357  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.3057  decode.d7.loss_cls: 0.1226  decode.d7.loss_mask: 0.1989  decode.d7.loss_dice: 0.2851  decode.d8.loss_cls: 0.1376  decode.d8.loss_mask: 0.2019  decode.d8.loss_dice: 0.3144
09/30 20:26:58 - mmengine - INFO - Iter(train) [ 93850/320000]  base_lr: 7.3168e-05 lr: 7.3168e-06  eta: 1 day, 3:24:18  time: 0.4412  data_time: 0.0101  memory: 5145  grad_norm: 54.0477  loss: 7.6416  decode.loss_cls: 0.1373  decode.loss_mask: 0.2689  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.8995  decode.d0.loss_mask: 0.2719  decode.d0.loss_dice: 0.2899  decode.d1.loss_cls: 0.1670  decode.d1.loss_mask: 0.2727  decode.d1.loss_dice: 0.2623  decode.d2.loss_cls: 0.1719  decode.d2.loss_mask: 0.2713  decode.d2.loss_dice: 0.2784  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.2637  decode.d4.loss_cls: 0.1690  decode.d4.loss_mask: 0.2713  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.1076  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.2636  decode.d6.loss_cls: 0.1129  decode.d6.loss_mask: 0.2702  decode.d6.loss_dice: 0.2733  decode.d7.loss_cls: 0.1662  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.1647  decode.d8.loss_mask: 0.2709  decode.d8.loss_dice: 0.2616
09/30 20:27:20 - mmengine - INFO - Iter(train) [ 93900/320000]  base_lr: 7.3154e-05 lr: 7.3154e-06  eta: 1 day, 3:23:57  time: 0.4413  data_time: 0.0096  memory: 5145  grad_norm: 43.5592  loss: 5.3990  decode.loss_cls: 0.0147  decode.loss_mask: 0.2382  decode.loss_dice: 0.1938  decode.d0.loss_cls: 0.8793  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.2387  decode.d1.loss_dice: 0.1942  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.1914  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.2404  decode.d3.loss_dice: 0.1958  decode.d4.loss_cls: 0.0323  decode.d4.loss_mask: 0.2403  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.0334  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.1930  decode.d6.loss_cls: 0.0204  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.2430  decode.d8.loss_dice: 0.1913
09/30 20:27:42 - mmengine - INFO - Iter(train) [ 93950/320000]  base_lr: 7.3139e-05 lr: 7.3139e-06  eta: 1 day, 3:23:36  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 26.9150  loss: 4.4236  decode.loss_cls: 0.0105  decode.loss_mask: 0.1868  decode.loss_dice: 0.1617  decode.d0.loss_cls: 0.8302  decode.d0.loss_mask: 0.1867  decode.d0.loss_dice: 0.1601  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.1859  decode.d1.loss_dice: 0.1657  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1622  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.1642  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.1876  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.1846  decode.d5.loss_dice: 0.1610  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.1830  decode.d6.loss_dice: 0.1609  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.1616  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.1850  decode.d8.loss_dice: 0.1609
09/30 20:28:04 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:28:04 - mmengine - INFO - Iter(train) [ 94000/320000]  base_lr: 7.3125e-05 lr: 7.3125e-06  eta: 1 day, 3:23:15  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 26.1335  loss: 5.0294  decode.loss_cls: 0.0240  decode.loss_mask: 0.2222  decode.loss_dice: 0.1761  decode.d0.loss_cls: 0.8364  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.1740  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.1770  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.2203  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.1754  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.1763  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.2220  decode.d5.loss_dice: 0.1774  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.1772  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 0.2208  decode.d7.loss_dice: 0.1782  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1772
09/30 20:28:26 - mmengine - INFO - Iter(train) [ 94050/320000]  base_lr: 7.3110e-05 lr: 7.3110e-06  eta: 1 day, 3:22:54  time: 0.4413  data_time: 0.0097  memory: 5145  grad_norm: 61.3919  loss: 7.8247  decode.loss_cls: 0.1740  decode.loss_mask: 0.2846  decode.loss_dice: 0.2579  decode.d0.loss_cls: 0.9759  decode.d0.loss_mask: 0.3084  decode.d0.loss_dice: 0.2483  decode.d1.loss_cls: 0.1199  decode.d1.loss_mask: 0.2888  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.1804  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.2565  decode.d3.loss_cls: 0.2286  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.2622  decode.d4.loss_cls: 0.1646  decode.d4.loss_mask: 0.2817  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.1661  decode.d5.loss_mask: 0.2849  decode.d5.loss_dice: 0.2198  decode.d6.loss_cls: 0.1608  decode.d6.loss_mask: 0.2882  decode.d6.loss_dice: 0.2290  decode.d7.loss_cls: 0.1497  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.2253  decode.d8.loss_cls: 0.1738  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.2575
09/30 20:28:48 - mmengine - INFO - Iter(train) [ 94100/320000]  base_lr: 7.3096e-05 lr: 7.3096e-06  eta: 1 day, 3:22:32  time: 0.4410  data_time: 0.0098  memory: 5129  grad_norm: 52.5346  loss: 5.6021  decode.loss_cls: 0.0242  decode.loss_mask: 0.2270  decode.loss_dice: 0.2215  decode.d0.loss_cls: 0.9326  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1910  decode.d1.loss_cls: 0.0340  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.1889  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.2332  decode.d2.loss_dice: 0.1748  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.2271  decode.d3.loss_dice: 0.1878  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.2193  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.1995  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2328  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.2364  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.0272  decode.d8.loss_mask: 0.2337  decode.d8.loss_dice: 0.2370
09/30 20:29:10 - mmengine - INFO - Iter(train) [ 94150/320000]  base_lr: 7.3081e-05 lr: 7.3081e-06  eta: 1 day, 3:22:11  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 78.1509  loss: 6.1319  decode.loss_cls: 0.0345  decode.loss_mask: 0.2518  decode.loss_dice: 0.2400  decode.d0.loss_cls: 0.8799  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.2529  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2211  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.2614  decode.d2.loss_dice: 0.2312  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.2584  decode.d3.loss_dice: 0.2459  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.2597  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.2428  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.2554  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.2591  decode.d8.loss_dice: 0.2468
09/30 20:29:32 - mmengine - INFO - Iter(train) [ 94200/320000]  base_lr: 7.3066e-05 lr: 7.3066e-06  eta: 1 day, 3:21:50  time: 0.4408  data_time: 0.0096  memory: 5145  grad_norm: 21.2424  loss: 5.2217  decode.loss_cls: 0.0562  decode.loss_mask: 0.1814  decode.loss_dice: 0.2183  decode.d0.loss_cls: 0.8220  decode.d0.loss_mask: 0.1812  decode.d0.loss_dice: 0.2278  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.1808  decode.d1.loss_dice: 0.2350  decode.d2.loss_cls: 0.0494  decode.d2.loss_mask: 0.1796  decode.d2.loss_dice: 0.2328  decode.d3.loss_cls: 0.0344  decode.d3.loss_mask: 0.1803  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.0357  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.2097  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.1800  decode.d5.loss_dice: 0.2479  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.1794  decode.d6.loss_dice: 0.2099  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.1800  decode.d7.loss_dice: 0.2348  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.1791  decode.d8.loss_dice: 0.2258
09/30 20:29:54 - mmengine - INFO - Iter(train) [ 94250/320000]  base_lr: 7.3052e-05 lr: 7.3052e-06  eta: 1 day, 3:21:29  time: 0.4410  data_time: 0.0095  memory: 5145  grad_norm: 20.9244  loss: 3.8390  decode.loss_cls: 0.0053  decode.loss_mask: 0.1555  decode.loss_dice: 0.1395  decode.d0.loss_cls: 0.8439  decode.d0.loss_mask: 0.1573  decode.d0.loss_dice: 0.1469  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.1552  decode.d1.loss_dice: 0.1421  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.1574  decode.d2.loss_dice: 0.1374  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.1586  decode.d3.loss_dice: 0.1336  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.1555  decode.d4.loss_dice: 0.1326  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.1571  decode.d5.loss_dice: 0.1506  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.1562  decode.d6.loss_dice: 0.1309  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.1579  decode.d7.loss_dice: 0.1420  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1552  decode.d8.loss_dice: 0.1406
09/30 20:30:16 - mmengine - INFO - Iter(train) [ 94300/320000]  base_lr: 7.3037e-05 lr: 7.3037e-06  eta: 1 day, 3:21:07  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 92.5319  loss: 6.4889  decode.loss_cls: 0.1250  decode.loss_mask: 0.2517  decode.loss_dice: 0.2347  decode.d0.loss_cls: 0.9205  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.1800  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.2087  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.2518  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.0979  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2325  decode.d4.loss_cls: 0.1021  decode.d4.loss_mask: 0.2493  decode.d4.loss_dice: 0.2024  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 0.2482  decode.d5.loss_dice: 0.2081  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2312  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.2470  decode.d7.loss_dice: 0.2265  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.2502  decode.d8.loss_dice: 0.2346
09/30 20:30:39 - mmengine - INFO - Iter(train) [ 94350/320000]  base_lr: 7.3023e-05 lr: 7.3023e-06  eta: 1 day, 3:20:46  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 44.6934  loss: 5.3005  decode.loss_cls: 0.0038  decode.loss_mask: 0.2586  decode.loss_dice: 0.1985  decode.d0.loss_cls: 0.6515  decode.d0.loss_mask: 0.2620  decode.d0.loss_dice: 0.1883  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.2073  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.2583  decode.d2.loss_dice: 0.2126  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.2070  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.2545  decode.d4.loss_dice: 0.1715  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.2578  decode.d5.loss_dice: 0.2077  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2564  decode.d6.loss_dice: 0.1959  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2567  decode.d7.loss_dice: 0.2105  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.2564  decode.d8.loss_dice: 0.2106
09/30 20:31:01 - mmengine - INFO - Iter(train) [ 94400/320000]  base_lr: 7.3008e-05 lr: 7.3008e-06  eta: 1 day, 3:20:25  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 22.4326  loss: 4.6706  decode.loss_cls: 0.0196  decode.loss_mask: 0.1884  decode.loss_dice: 0.1675  decode.d0.loss_cls: 0.8964  decode.d0.loss_mask: 0.1859  decode.d0.loss_dice: 0.1725  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.1867  decode.d1.loss_dice: 0.1755  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.1863  decode.d2.loss_dice: 0.1741  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.1851  decode.d3.loss_dice: 0.1752  decode.d4.loss_cls: 0.0171  decode.d4.loss_mask: 0.1854  decode.d4.loss_dice: 0.1730  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.1866  decode.d5.loss_dice: 0.1807  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.1858  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.1839  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0181  decode.d8.loss_mask: 0.1881  decode.d8.loss_dice: 0.1795
09/30 20:31:23 - mmengine - INFO - Iter(train) [ 94450/320000]  base_lr: 7.2994e-05 lr: 7.2994e-06  eta: 1 day, 3:20:03  time: 0.4416  data_time: 0.0098  memory: 5145  grad_norm: 121.1896  loss: 7.6426  decode.loss_cls: 0.1741  decode.loss_mask: 0.2766  decode.loss_dice: 0.2546  decode.d0.loss_cls: 0.8339  decode.d0.loss_mask: 0.2812  decode.d0.loss_dice: 0.2612  decode.d1.loss_cls: 0.2018  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.2439  decode.d2.loss_cls: 0.2125  decode.d2.loss_mask: 0.2767  decode.d2.loss_dice: 0.2369  decode.d3.loss_cls: 0.1721  decode.d3.loss_mask: 0.2766  decode.d3.loss_dice: 0.2284  decode.d4.loss_cls: 0.1711  decode.d4.loss_mask: 0.2727  decode.d4.loss_dice: 0.2290  decode.d5.loss_cls: 0.1810  decode.d5.loss_mask: 0.2770  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.1384  decode.d6.loss_mask: 0.2760  decode.d6.loss_dice: 0.2489  decode.d7.loss_cls: 0.1773  decode.d7.loss_mask: 0.2745  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.1968  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.2398
09/30 20:31:45 - mmengine - INFO - Iter(train) [ 94500/320000]  base_lr: 7.2979e-05 lr: 7.2979e-06  eta: 1 day, 3:19:42  time: 0.4407  data_time: 0.0097  memory: 5145  grad_norm: 19.2539  loss: 4.9450  decode.loss_cls: 0.0062  decode.loss_mask: 0.2029  decode.loss_dice: 0.1799  decode.d0.loss_cls: 0.9171  decode.d0.loss_mask: 0.2010  decode.d0.loss_dice: 0.1705  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.2049  decode.d1.loss_dice: 0.1788  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.2022  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.2026  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.2046  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2027  decode.d5.loss_dice: 0.1873  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2040  decode.d6.loss_dice: 0.1910  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1853  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.1883
09/30 20:32:07 - mmengine - INFO - Iter(train) [ 94550/320000]  base_lr: 7.2964e-05 lr: 7.2964e-06  eta: 1 day, 3:19:21  time: 0.4400  data_time: 0.0098  memory: 5129  grad_norm: 31.6586  loss: 6.3118  decode.loss_cls: 0.0450  decode.loss_mask: 0.2266  decode.loss_dice: 0.2758  decode.d0.loss_cls: 0.7671  decode.d0.loss_mask: 0.2280  decode.d0.loss_dice: 0.2620  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.2969  decode.d2.loss_cls: 0.0859  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.2711  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.2236  decode.d3.loss_dice: 0.2862  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.2223  decode.d4.loss_dice: 0.2803  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.2223  decode.d5.loss_dice: 0.2684  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.2240  decode.d6.loss_dice: 0.2865  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.2830  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.2861
09/30 20:32:29 - mmengine - INFO - Iter(train) [ 94600/320000]  base_lr: 7.2950e-05 lr: 7.2950e-06  eta: 1 day, 3:19:00  time: 0.4401  data_time: 0.0097  memory: 5145  grad_norm: 65.1553  loss: 5.6109  decode.loss_cls: 0.1035  decode.loss_mask: 0.1971  decode.loss_dice: 0.1812  decode.d0.loss_cls: 0.8067  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.1732  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.1769  decode.d2.loss_cls: 0.0932  decode.d2.loss_mask: 0.1948  decode.d2.loss_dice: 0.1692  decode.d3.loss_cls: 0.1099  decode.d3.loss_mask: 0.1941  decode.d3.loss_dice: 0.1771  decode.d4.loss_cls: 0.1601  decode.d4.loss_mask: 0.1956  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.1409  decode.d5.loss_mask: 0.1952  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0901  decode.d6.loss_mask: 0.1945  decode.d6.loss_dice: 0.1767  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.1942  decode.d7.loss_dice: 0.1806  decode.d8.loss_cls: 0.1488  decode.d8.loss_mask: 0.1945  decode.d8.loss_dice: 0.1771
09/30 20:32:51 - mmengine - INFO - Iter(train) [ 94650/320000]  base_lr: 7.2935e-05 lr: 7.2935e-06  eta: 1 day, 3:18:38  time: 0.4410  data_time: 0.0099  memory: 5129  grad_norm: 30.6700  loss: 5.1014  decode.loss_cls: 0.0103  decode.loss_mask: 0.2286  decode.loss_dice: 0.1924  decode.d0.loss_cls: 0.8323  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.1877  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.1929  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.1944  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.2258  decode.d3.loss_dice: 0.1948  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1887  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.1933  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.2309  decode.d7.loss_dice: 0.1953  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.1905
09/30 20:33:13 - mmengine - INFO - Iter(train) [ 94700/320000]  base_lr: 7.2921e-05 lr: 7.2921e-06  eta: 1 day, 3:18:17  time: 0.4413  data_time: 0.0099  memory: 5129  grad_norm: 74.7080  loss: 5.5632  decode.loss_cls: 0.0347  decode.loss_mask: 0.2122  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.8308  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.2075  decode.d1.loss_dice: 0.1981  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.2075  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.1941  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.1977  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.2064  decode.d5.loss_dice: 0.2065  decode.d6.loss_cls: 0.0727  decode.d6.loss_mask: 0.2083  decode.d6.loss_dice: 0.1997  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.2073  decode.d7.loss_dice: 0.2130  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.2097  decode.d8.loss_dice: 0.1929
09/30 20:33:35 - mmengine - INFO - Iter(train) [ 94750/320000]  base_lr: 7.2906e-05 lr: 7.2906e-06  eta: 1 day, 3:17:56  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 43.2660  loss: 5.0489  decode.loss_cls: 0.0368  decode.loss_mask: 0.1947  decode.loss_dice: 0.1949  decode.d0.loss_cls: 0.7740  decode.d0.loss_mask: 0.1970  decode.d0.loss_dice: 0.2050  decode.d1.loss_cls: 0.0260  decode.d1.loss_mask: 0.1970  decode.d1.loss_dice: 0.2032  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.1944  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.0380  decode.d3.loss_mask: 0.1943  decode.d3.loss_dice: 0.1933  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.1992  decode.d4.loss_dice: 0.2167  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.1947  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.0339  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2068  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.1947  decode.d8.loss_dice: 0.2105
09/30 20:33:57 - mmengine - INFO - Iter(train) [ 94800/320000]  base_lr: 7.2892e-05 lr: 7.2892e-06  eta: 1 day, 3:17:35  time: 0.4414  data_time: 0.0097  memory: 5145  grad_norm: 26.3804  loss: 4.7850  decode.loss_cls: 0.0040  decode.loss_mask: 0.2199  decode.loss_dice: 0.1813  decode.d0.loss_cls: 0.7001  decode.d0.loss_mask: 0.2282  decode.d0.loss_dice: 0.1791  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.1775  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.2222  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.2195  decode.d3.loss_dice: 0.1809  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.1797  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.2251  decode.d5.loss_dice: 0.1925  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2196  decode.d6.loss_dice: 0.1816  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.2221  decode.d7.loss_dice: 0.1819  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.1820
09/30 20:34:19 - mmengine - INFO - Iter(train) [ 94850/320000]  base_lr: 7.2877e-05 lr: 7.2877e-06  eta: 1 day, 3:17:13  time: 0.4409  data_time: 0.0099  memory: 5129  grad_norm: 65.3051  loss: 6.1952  decode.loss_cls: 0.1541  decode.loss_mask: 0.2202  decode.loss_dice: 0.2125  decode.d0.loss_cls: 0.8057  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.1118  decode.d1.loss_mask: 0.2219  decode.d1.loss_dice: 0.2192  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 0.2215  decode.d2.loss_dice: 0.2030  decode.d3.loss_cls: 0.1114  decode.d3.loss_mask: 0.2195  decode.d3.loss_dice: 0.2136  decode.d4.loss_cls: 0.1136  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.2220  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.2088  decode.d6.loss_cls: 0.1080  decode.d6.loss_mask: 0.2255  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.1966  decode.d8.loss_cls: 0.1506  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.2031
09/30 20:34:41 - mmengine - INFO - Iter(train) [ 94900/320000]  base_lr: 7.2863e-05 lr: 7.2863e-06  eta: 1 day, 3:16:52  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 44.3387  loss: 6.6434  decode.loss_cls: 0.1493  decode.loss_mask: 0.2210  decode.loss_dice: 0.2845  decode.d0.loss_cls: 0.7782  decode.d0.loss_mask: 0.2206  decode.d0.loss_dice: 0.2634  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.2544  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.2767  decode.d3.loss_cls: 0.1403  decode.d3.loss_mask: 0.2222  decode.d3.loss_dice: 0.2911  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.2764  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.2766  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.2707  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2202  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.1339  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.2897
09/30 20:35:03 - mmengine - INFO - Iter(train) [ 94950/320000]  base_lr: 7.2848e-05 lr: 7.2848e-06  eta: 1 day, 3:16:31  time: 0.4415  data_time: 0.0099  memory: 5130  grad_norm: 58.0535  loss: 4.0981  decode.loss_cls: 0.0130  decode.loss_mask: 0.1837  decode.loss_dice: 0.1365  decode.d0.loss_cls: 0.7508  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.1392  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.1372  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.1866  decode.d2.loss_dice: 0.1360  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.1840  decode.d3.loss_dice: 0.1343  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.1836  decode.d4.loss_dice: 0.1370  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.1824  decode.d5.loss_dice: 0.1350  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.1842  decode.d6.loss_dice: 0.1370  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.1841  decode.d7.loss_dice: 0.1361  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.1837  decode.d8.loss_dice: 0.1377
09/30 20:35:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:35:25 - mmengine - INFO - Iter(train) [ 95000/320000]  base_lr: 7.2833e-05 lr: 7.2833e-06  eta: 1 day, 3:16:09  time: 0.4410  data_time: 0.0096  memory: 5119  grad_norm: 39.0463  loss: 7.0279  decode.loss_cls: 0.1390  decode.loss_mask: 0.2277  decode.loss_dice: 0.2037  decode.d0.loss_cls: 1.0350  decode.d0.loss_mask: 0.2354  decode.d0.loss_dice: 0.2135  decode.d1.loss_cls: 0.1788  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.1699  decode.d2.loss_mask: 0.2419  decode.d2.loss_dice: 0.2178  decode.d3.loss_cls: 0.1769  decode.d3.loss_mask: 0.2892  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.1704  decode.d4.loss_mask: 0.2463  decode.d4.loss_dice: 0.2313  decode.d5.loss_cls: 0.1625  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2309  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.1541  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.1958  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.2094
09/30 20:35:47 - mmengine - INFO - Iter(train) [ 95050/320000]  base_lr: 7.2819e-05 lr: 7.2819e-06  eta: 1 day, 3:15:48  time: 0.4426  data_time: 0.0100  memory: 5129  grad_norm: 24.2161  loss: 5.5128  decode.loss_cls: 0.0584  decode.loss_mask: 0.2242  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.7027  decode.d0.loss_mask: 0.2238  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1998  decode.d2.loss_cls: 0.0767  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.1760  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.2225  decode.d4.loss_dice: 0.1795  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.1759  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1786  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.2178
09/30 20:36:09 - mmengine - INFO - Iter(train) [ 95100/320000]  base_lr: 7.2804e-05 lr: 7.2804e-06  eta: 1 day, 3:15:27  time: 0.4410  data_time: 0.0099  memory: 5129  grad_norm: 359.0682  loss: 7.9721  decode.loss_cls: 0.1214  decode.loss_mask: 0.5195  decode.loss_dice: 0.3102  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.2761  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.3871  decode.d1.loss_dice: 0.2680  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.3964  decode.d2.loss_dice: 0.2818  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.3773  decode.d3.loss_dice: 0.2645  decode.d4.loss_cls: 0.0722  decode.d4.loss_mask: 0.3084  decode.d4.loss_dice: 0.2856  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 0.3016  decode.d5.loss_dice: 0.2811  decode.d6.loss_cls: 0.1183  decode.d6.loss_mask: 0.3075  decode.d6.loss_dice: 0.2499  decode.d7.loss_cls: 0.1366  decode.d7.loss_mask: 0.3029  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.3504  decode.d8.loss_dice: 0.2726
09/30 20:36:31 - mmengine - INFO - Iter(train) [ 95150/320000]  base_lr: 7.2790e-05 lr: 7.2790e-06  eta: 1 day, 3:15:06  time: 0.4425  data_time: 0.0097  memory: 5145  grad_norm: 22.8964  loss: 4.5302  decode.loss_cls: 0.0076  decode.loss_mask: 0.2046  decode.loss_dice: 0.1680  decode.d0.loss_cls: 0.7318  decode.d0.loss_mask: 0.2071  decode.d0.loss_dice: 0.1686  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.2051  decode.d1.loss_dice: 0.1721  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.2049  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.1697  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.2038  decode.d4.loss_dice: 0.1680  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2047  decode.d5.loss_dice: 0.1708  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.1686  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.2051  decode.d7.loss_dice: 0.1711  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.1644
09/30 20:36:54 - mmengine - INFO - Iter(train) [ 95200/320000]  base_lr: 7.2775e-05 lr: 7.2775e-06  eta: 1 day, 3:14:44  time: 0.4407  data_time: 0.0097  memory: 5129  grad_norm: 23.9703  loss: 4.5700  decode.loss_cls: 0.0020  decode.loss_mask: 0.1921  decode.loss_dice: 0.1707  decode.d0.loss_cls: 0.9065  decode.d0.loss_mask: 0.1942  decode.d0.loss_dice: 0.1613  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.1954  decode.d1.loss_dice: 0.1725  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.1927  decode.d2.loss_dice: 0.1701  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1931  decode.d3.loss_dice: 0.1745  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1948  decode.d4.loss_dice: 0.1766  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.1936  decode.d5.loss_dice: 0.1744  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1906  decode.d6.loss_dice: 0.1701  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.1923  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1922  decode.d8.loss_dice: 0.1697
09/30 20:37:16 - mmengine - INFO - Iter(train) [ 95250/320000]  base_lr: 7.2761e-05 lr: 7.2761e-06  eta: 1 day, 3:14:23  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 59.9032  loss: 5.7142  decode.loss_cls: 0.0765  decode.loss_mask: 0.2141  decode.loss_dice: 0.2008  decode.d0.loss_cls: 0.7525  decode.d0.loss_mask: 0.2185  decode.d0.loss_dice: 0.2058  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.2138  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.2131  decode.d2.loss_dice: 0.2096  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.1002  decode.d4.loss_mask: 0.2142  decode.d4.loss_dice: 0.2119  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2136  decode.d5.loss_dice: 0.2110  decode.d6.loss_cls: 0.0789  decode.d6.loss_mask: 0.2168  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.2156  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2006
09/30 20:37:38 - mmengine - INFO - Iter(train) [ 95300/320000]  base_lr: 7.2746e-05 lr: 7.2746e-06  eta: 1 day, 3:14:02  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 19.0600  loss: 4.4518  decode.loss_cls: 0.0063  decode.loss_mask: 0.1968  decode.loss_dice: 0.1607  decode.d0.loss_cls: 0.6960  decode.d0.loss_mask: 0.2060  decode.d0.loss_dice: 0.1685  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.2019  decode.d1.loss_dice: 0.1640  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.1725  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.2021  decode.d3.loss_dice: 0.1639  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.2043  decode.d4.loss_dice: 0.1687  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.1995  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.2006  decode.d6.loss_dice: 0.1684  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.2020  decode.d8.loss_dice: 0.1695
09/30 20:38:00 - mmengine - INFO - Iter(train) [ 95350/320000]  base_lr: 7.2731e-05 lr: 7.2731e-06  eta: 1 day, 3:13:41  time: 0.4401  data_time: 0.0096  memory: 5120  grad_norm: 61.2225  loss: 6.0344  decode.loss_cls: 0.0810  decode.loss_mask: 0.1984  decode.loss_dice: 0.2357  decode.d0.loss_cls: 0.8764  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.2012  decode.d1.loss_cls: 0.1145  decode.d1.loss_mask: 0.1972  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.2128  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.1980  decode.d3.loss_dice: 0.2316  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 0.1947  decode.d4.loss_dice: 0.2354  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.1967  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.1056  decode.d6.loss_mask: 0.1972  decode.d6.loss_dice: 0.2245  decode.d7.loss_cls: 0.1087  decode.d7.loss_mask: 0.1981  decode.d7.loss_dice: 0.2246  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 0.1953  decode.d8.loss_dice: 0.2269
09/30 20:38:22 - mmengine - INFO - Iter(train) [ 95400/320000]  base_lr: 7.2717e-05 lr: 7.2717e-06  eta: 1 day, 3:13:19  time: 0.4399  data_time: 0.0097  memory: 5145  grad_norm: 74.5421  loss: 7.9494  decode.loss_cls: 0.2233  decode.loss_mask: 0.2369  decode.loss_dice: 0.2658  decode.d0.loss_cls: 0.8374  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.2917  decode.d1.loss_cls: 0.2529  decode.d1.loss_mask: 0.2391  decode.d1.loss_dice: 0.2722  decode.d2.loss_cls: 0.2659  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2892  decode.d3.loss_cls: 0.2017  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.2799  decode.d4.loss_cls: 0.1996  decode.d4.loss_mask: 0.2351  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.1921  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.2790  decode.d6.loss_cls: 0.2246  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.2097  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.2548  decode.d8.loss_cls: 0.2332  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.2653
09/30 20:38:44 - mmengine - INFO - Iter(train) [ 95450/320000]  base_lr: 7.2702e-05 lr: 7.2702e-06  eta: 1 day, 3:12:58  time: 0.4405  data_time: 0.0095  memory: 5120  grad_norm: 56.2371  loss: 5.1405  decode.loss_cls: 0.0665  decode.loss_mask: 0.2078  decode.loss_dice: 0.1646  decode.d0.loss_cls: 0.9380  decode.d0.loss_mask: 0.2103  decode.d0.loss_dice: 0.1662  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.1592  decode.d2.loss_cls: 0.0684  decode.d2.loss_mask: 0.2111  decode.d2.loss_dice: 0.1667  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.1659  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.1698  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.2104  decode.d5.loss_dice: 0.1682  decode.d6.loss_cls: 0.0437  decode.d6.loss_mask: 0.2105  decode.d6.loss_dice: 0.1700  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.1576  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.1745
09/30 20:39:06 - mmengine - INFO - Iter(train) [ 95500/320000]  base_lr: 7.2688e-05 lr: 7.2688e-06  eta: 1 day, 3:12:37  time: 0.4408  data_time: 0.0097  memory: 5129  grad_norm: 18.9632  loss: 4.2795  decode.loss_cls: 0.0019  decode.loss_mask: 0.1830  decode.loss_dice: 0.1635  decode.d0.loss_cls: 0.7741  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.1575  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.1851  decode.d1.loss_dice: 0.1691  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.1809  decode.d2.loss_dice: 0.1634  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.1831  decode.d3.loss_dice: 0.1634  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.1830  decode.d4.loss_dice: 0.1662  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.1668  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.1829  decode.d6.loss_dice: 0.1648  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.1844  decode.d7.loss_dice: 0.1686  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.1830  decode.d8.loss_dice: 0.1677
09/30 20:39:28 - mmengine - INFO - Iter(train) [ 95550/320000]  base_lr: 7.2673e-05 lr: 7.2673e-06  eta: 1 day, 3:12:16  time: 0.4407  data_time: 0.0096  memory: 5120  grad_norm: 52.8854  loss: 5.9637  decode.loss_cls: 0.0237  decode.loss_mask: 0.2336  decode.loss_dice: 0.2294  decode.d0.loss_cls: 0.8699  decode.d0.loss_mask: 0.2370  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.2404  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.2329  decode.d3.loss_dice: 0.2142  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.2289  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.2149  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.2347  decode.d7.loss_dice: 0.2327  decode.d8.loss_cls: 0.0301  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.2273
09/30 20:39:50 - mmengine - INFO - Iter(train) [ 95600/320000]  base_lr: 7.2659e-05 lr: 7.2659e-06  eta: 1 day, 3:11:55  time: 0.4402  data_time: 0.0097  memory: 5129  grad_norm: 50.0339  loss: 6.4332  decode.loss_cls: 0.1173  decode.loss_mask: 0.2425  decode.loss_dice: 0.2279  decode.d0.loss_cls: 0.8062  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2417  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2266  decode.d3.loss_cls: 0.1252  decode.d3.loss_mask: 0.2414  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.1305  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.1109  decode.d5.loss_mask: 0.2407  decode.d5.loss_dice: 0.2439  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2371  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.2419  decode.d8.loss_dice: 0.2341
09/30 20:40:12 - mmengine - INFO - Iter(train) [ 95650/320000]  base_lr: 7.2644e-05 lr: 7.2644e-06  eta: 1 day, 3:11:33  time: 0.4406  data_time: 0.0097  memory: 5145  grad_norm: 25.1280  loss: 4.1113  decode.loss_cls: 0.0040  decode.loss_mask: 0.1808  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.7601  decode.d0.loss_mask: 0.1849  decode.d0.loss_dice: 0.1500  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.1828  decode.d1.loss_dice: 0.1491  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.1813  decode.d2.loss_dice: 0.1484  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.1792  decode.d3.loss_dice: 0.1464  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.1821  decode.d4.loss_dice: 0.1466  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.1822  decode.d5.loss_dice: 0.1440  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.1805  decode.d6.loss_dice: 0.1477  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.1519  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.1820  decode.d8.loss_dice: 0.1481
09/30 20:40:34 - mmengine - INFO - Iter(train) [ 95700/320000]  base_lr: 7.2629e-05 lr: 7.2629e-06  eta: 1 day, 3:11:12  time: 0.4404  data_time: 0.0098  memory: 5129  grad_norm: 94.7561  loss: 5.4097  decode.loss_cls: 0.0411  decode.loss_mask: 0.2558  decode.loss_dice: 0.1847  decode.d0.loss_cls: 0.6761  decode.d0.loss_mask: 0.2559  decode.d0.loss_dice: 0.1833  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.1849  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.1866  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.1852  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.2586  decode.d5.loss_dice: 0.1880  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.1874  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.2595  decode.d7.loss_dice: 0.1906  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.2572  decode.d8.loss_dice: 0.1877
09/30 20:40:56 - mmengine - INFO - Iter(train) [ 95750/320000]  base_lr: 7.2615e-05 lr: 7.2615e-06  eta: 1 day, 3:10:51  time: 0.4413  data_time: 0.0097  memory: 5129  grad_norm: 65.0199  loss: 5.9842  decode.loss_cls: 0.0206  decode.loss_mask: 0.2739  decode.loss_dice: 0.1997  decode.d0.loss_cls: 0.8109  decode.d0.loss_mask: 0.2705  decode.d0.loss_dice: 0.1951  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.1972  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.2720  decode.d2.loss_dice: 0.1913  decode.d3.loss_cls: 0.1129  decode.d3.loss_mask: 0.2748  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.2740  decode.d4.loss_dice: 0.1938  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.1978  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.1943  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.2708  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.2763  decode.d8.loss_dice: 0.1976
09/30 20:41:18 - mmengine - INFO - Iter(train) [ 95800/320000]  base_lr: 7.2600e-05 lr: 7.2600e-06  eta: 1 day, 3:10:29  time: 0.4401  data_time: 0.0096  memory: 5120  grad_norm: 39.2510  loss: 5.2200  decode.loss_cls: 0.0904  decode.loss_mask: 0.1823  decode.loss_dice: 0.1663  decode.d0.loss_cls: 0.8915  decode.d0.loss_mask: 0.1879  decode.d0.loss_dice: 0.1817  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 0.1833  decode.d1.loss_dice: 0.1680  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 0.1853  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.1823  decode.d3.loss_dice: 0.2057  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.1866  decode.d4.loss_dice: 0.1660  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.1844  decode.d5.loss_dice: 0.1747  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.2047  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.1826  decode.d7.loss_dice: 0.1776  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.1832  decode.d8.loss_dice: 0.1991
09/30 20:41:40 - mmengine - INFO - Iter(train) [ 95850/320000]  base_lr: 7.2586e-05 lr: 7.2586e-06  eta: 1 day, 3:10:08  time: 0.4419  data_time: 0.0101  memory: 5145  grad_norm: 33.9507  loss: 5.2481  decode.loss_cls: 0.0112  decode.loss_mask: 0.2398  decode.loss_dice: 0.1797  decode.d0.loss_cls: 0.9187  decode.d0.loss_mask: 0.2445  decode.d0.loss_dice: 0.1871  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.1896  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.2410  decode.d3.loss_dice: 0.1894  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.2382  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2386  decode.d6.loss_dice: 0.1784  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2392  decode.d7.loss_dice: 0.1867  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.1804
09/30 20:42:02 - mmengine - INFO - Iter(train) [ 95900/320000]  base_lr: 7.2571e-05 lr: 7.2571e-06  eta: 1 day, 3:09:47  time: 0.4405  data_time: 0.0096  memory: 5129  grad_norm: 15.8409  loss: 4.1300  decode.loss_cls: 0.0013  decode.loss_mask: 0.1778  decode.loss_dice: 0.1591  decode.d0.loss_cls: 0.7752  decode.d0.loss_mask: 0.1819  decode.d0.loss_dice: 0.1451  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.1785  decode.d1.loss_dice: 0.1565  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.1754  decode.d2.loss_dice: 0.1560  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.1790  decode.d3.loss_dice: 0.1632  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.1758  decode.d4.loss_dice: 0.1538  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1795  decode.d5.loss_dice: 0.1538  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.1782  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1789  decode.d7.loss_dice: 0.1580  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1781  decode.d8.loss_dice: 0.1543
09/30 20:42:24 - mmengine - INFO - Iter(train) [ 95950/320000]  base_lr: 7.2557e-05 lr: 7.2557e-06  eta: 1 day, 3:09:25  time: 0.4406  data_time: 0.0097  memory: 5120  grad_norm: 54.8359  loss: 5.7653  decode.loss_cls: 0.0113  decode.loss_mask: 0.2686  decode.loss_dice: 0.1993  decode.d0.loss_cls: 0.8201  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.1979  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.2731  decode.d2.loss_dice: 0.2083  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.1820  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 0.2676  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.2693  decode.d5.loss_dice: 0.2029  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.2104  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.1960  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.2065
09/30 20:42:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:42:47 - mmengine - INFO - Iter(train) [ 96000/320000]  base_lr: 7.2542e-05 lr: 7.2542e-06  eta: 1 day, 3:09:04  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 28.5718  loss: 5.3414  decode.loss_cls: 0.0353  decode.loss_mask: 0.2017  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.8228  decode.d0.loss_mask: 0.2036  decode.d0.loss_dice: 0.1972  decode.d1.loss_cls: 0.0315  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.2174  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.2015  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.2054  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.1995  decode.d4.loss_dice: 0.1853  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.1984  decode.d5.loss_dice: 0.2096  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.2005  decode.d6.loss_dice: 0.2008  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.1996  decode.d8.loss_dice: 0.2082
09/30 20:43:09 - mmengine - INFO - Iter(train) [ 96050/320000]  base_lr: 7.2527e-05 lr: 7.2527e-06  eta: 1 day, 3:08:43  time: 0.4406  data_time: 0.0097  memory: 5120  grad_norm: 95.2647  loss: 4.4356  decode.loss_cls: 0.0348  decode.loss_mask: 0.1644  decode.loss_dice: 0.1529  decode.d0.loss_cls: 0.8958  decode.d0.loss_mask: 0.1660  decode.d0.loss_dice: 0.1493  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.1623  decode.d1.loss_dice: 0.1535  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.1657  decode.d2.loss_dice: 0.1489  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.1657  decode.d3.loss_dice: 0.1511  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.1653  decode.d4.loss_dice: 0.1533  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.1661  decode.d5.loss_dice: 0.1534  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.1654  decode.d6.loss_dice: 0.1486  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.1651  decode.d7.loss_dice: 0.1517  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.1635  decode.d8.loss_dice: 0.1513
09/30 20:43:31 - mmengine - INFO - Iter(train) [ 96100/320000]  base_lr: 7.2513e-05 lr: 7.2513e-06  eta: 1 day, 3:08:21  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 38.4225  loss: 5.5852  decode.loss_cls: 0.0639  decode.loss_mask: 0.1989  decode.loss_dice: 0.1858  decode.d0.loss_cls: 0.9463  decode.d0.loss_mask: 0.2044  decode.d0.loss_dice: 0.1894  decode.d1.loss_cls: 0.0957  decode.d1.loss_mask: 0.2015  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.0717  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.1878  decode.d3.loss_cls: 0.0813  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.1955  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.1885  decode.d5.loss_cls: 0.0932  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.1892  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.1952  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.2048  decode.d7.loss_dice: 0.1982  decode.d8.loss_cls: 0.0992  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.1859
09/30 20:43:53 - mmengine - INFO - Iter(train) [ 96150/320000]  base_lr: 7.2498e-05 lr: 7.2498e-06  eta: 1 day, 3:08:00  time: 0.4419  data_time: 0.0100  memory: 5129  grad_norm: 20.8867  loss: 4.6602  decode.loss_cls: 0.0022  decode.loss_mask: 0.1931  decode.loss_dice: 0.1709  decode.d0.loss_cls: 0.9799  decode.d0.loss_mask: 0.1902  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.1933  decode.d1.loss_dice: 0.1763  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.1913  decode.d2.loss_dice: 0.1750  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1941  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.1927  decode.d4.loss_dice: 0.1762  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.1699  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.1930  decode.d7.loss_dice: 0.1696  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.1916  decode.d8.loss_dice: 0.1696
09/30 20:44:15 - mmengine - INFO - Iter(train) [ 96200/320000]  base_lr: 7.2484e-05 lr: 7.2484e-06  eta: 1 day, 3:07:39  time: 0.4417  data_time: 0.0100  memory: 5145  grad_norm: 86.3188  loss: 8.8642  decode.loss_cls: 0.2978  decode.loss_mask: 0.2887  decode.loss_dice: 0.2385  decode.d0.loss_cls: 1.0583  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2569  decode.d1.loss_cls: 0.3588  decode.d1.loss_mask: 0.2312  decode.d1.loss_dice: 0.2252  decode.d2.loss_cls: 0.3341  decode.d2.loss_mask: 0.2390  decode.d2.loss_dice: 0.2198  decode.d3.loss_cls: 0.3118  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.2298  decode.d4.loss_cls: 0.2698  decode.d4.loss_mask: 0.2371  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.2798  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.2844  decode.d6.loss_cls: 0.3128  decode.d6.loss_mask: 0.2425  decode.d6.loss_dice: 0.2606  decode.d7.loss_cls: 0.3164  decode.d7.loss_mask: 0.2626  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.3199  decode.d8.loss_mask: 0.2341  decode.d8.loss_dice: 0.2383
09/30 20:44:37 - mmengine - INFO - Iter(train) [ 96250/320000]  base_lr: 7.2469e-05 lr: 7.2469e-06  eta: 1 day, 3:07:18  time: 0.4412  data_time: 0.0098  memory: 5146  grad_norm: 59.3800  loss: 5.7196  decode.loss_cls: 0.0709  decode.loss_mask: 0.2194  decode.loss_dice: 0.1916  decode.d0.loss_cls: 0.8945  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1956  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.2209  decode.d1.loss_dice: 0.1921  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.1867  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.2163  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.2221  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.2194  decode.d5.loss_dice: 0.1830  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.2201  decode.d6.loss_dice: 0.1900  decode.d7.loss_cls: 0.0912  decode.d7.loss_mask: 0.2194  decode.d7.loss_dice: 0.1985  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.1815
09/30 20:44:59 - mmengine - INFO - Iter(train) [ 96300/320000]  base_lr: 7.2455e-05 lr: 7.2455e-06  eta: 1 day, 3:06:57  time: 0.4415  data_time: 0.0097  memory: 5145  grad_norm: 77.5190  loss: 6.9917  decode.loss_cls: 0.1297  decode.loss_mask: 0.2457  decode.loss_dice: 0.2567  decode.d0.loss_cls: 0.7045  decode.d0.loss_mask: 0.2490  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.1510  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.1098  decode.d2.loss_mask: 0.2424  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.1239  decode.d3.loss_mask: 0.2439  decode.d3.loss_dice: 0.2575  decode.d4.loss_cls: 0.1471  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.1348  decode.d5.loss_mask: 0.2426  decode.d5.loss_dice: 0.2632  decode.d6.loss_cls: 0.1533  decode.d6.loss_mask: 0.2466  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.1205  decode.d7.loss_mask: 0.2460  decode.d7.loss_dice: 0.2626  decode.d8.loss_cls: 0.1354  decode.d8.loss_mask: 0.2421  decode.d8.loss_dice: 0.2637
09/30 20:45:21 - mmengine - INFO - Iter(train) [ 96350/320000]  base_lr: 7.2440e-05 lr: 7.2440e-06  eta: 1 day, 3:06:35  time: 0.4414  data_time: 0.0099  memory: 5145  grad_norm: 65.5475  loss: 6.3532  decode.loss_cls: 0.1663  decode.loss_mask: 0.2332  decode.loss_dice: 0.1848  decode.d0.loss_cls: 0.8204  decode.d0.loss_mask: 0.2358  decode.d0.loss_dice: 0.1734  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.1826  decode.d2.loss_cls: 0.1299  decode.d2.loss_mask: 0.2296  decode.d2.loss_dice: 0.1791  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 0.2311  decode.d3.loss_dice: 0.1836  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 0.2300  decode.d4.loss_dice: 0.1810  decode.d5.loss_cls: 0.2022  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.1737  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.1727  decode.d7.loss_cls: 0.1524  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.1776  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 0.3229  decode.d8.loss_dice: 0.1931
09/30 20:45:43 - mmengine - INFO - Iter(train) [ 96400/320000]  base_lr: 7.2425e-05 lr: 7.2425e-06  eta: 1 day, 3:06:14  time: 0.4411  data_time: 0.0099  memory: 5129  grad_norm: 47.6210  loss: 5.7337  decode.loss_cls: 0.1239  decode.loss_mask: 0.1899  decode.loss_dice: 0.1985  decode.d0.loss_cls: 0.9353  decode.d0.loss_mask: 0.1928  decode.d0.loss_dice: 0.1911  decode.d1.loss_cls: 0.1354  decode.d1.loss_mask: 0.1893  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.1137  decode.d2.loss_mask: 0.1899  decode.d2.loss_dice: 0.1782  decode.d3.loss_cls: 0.1166  decode.d3.loss_mask: 0.1887  decode.d3.loss_dice: 0.1721  decode.d4.loss_cls: 0.1303  decode.d4.loss_mask: 0.1894  decode.d4.loss_dice: 0.1719  decode.d5.loss_cls: 0.1221  decode.d5.loss_mask: 0.1878  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.1123  decode.d6.loss_mask: 0.1909  decode.d6.loss_dice: 0.1693  decode.d7.loss_cls: 0.1154  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.1714  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.1903  decode.d8.loss_dice: 0.1726
09/30 20:46:05 - mmengine - INFO - Iter(train) [ 96450/320000]  base_lr: 7.2411e-05 lr: 7.2411e-06  eta: 1 day, 3:05:53  time: 0.4427  data_time: 0.0102  memory: 5129  grad_norm: 245.7592  loss: 5.2720  decode.loss_cls: 0.0944  decode.loss_mask: 0.2240  decode.loss_dice: 0.1882  decode.d0.loss_cls: 0.7569  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1847  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.2264  decode.d2.loss_dice: 0.1885  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.2238  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.2276  decode.d4.loss_dice: 0.1862  decode.d5.loss_cls: 0.0265  decode.d5.loss_mask: 0.2262  decode.d5.loss_dice: 0.1868  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.2260  decode.d6.loss_dice: 0.1867  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.1855  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.1844
09/30 20:46:27 - mmengine - INFO - Iter(train) [ 96500/320000]  base_lr: 7.2396e-05 lr: 7.2396e-06  eta: 1 day, 3:05:32  time: 0.4411  data_time: 0.0102  memory: 5145  grad_norm: 30.3005  loss: 5.3588  decode.loss_cls: 0.0317  decode.loss_mask: 0.2230  decode.loss_dice: 0.1972  decode.d0.loss_cls: 0.8677  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.2217  decode.d1.loss_dice: 0.1976  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.1934  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.1922  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.2197  decode.d4.loss_dice: 0.1964  decode.d5.loss_cls: 0.0336  decode.d5.loss_mask: 0.2215  decode.d5.loss_dice: 0.1936  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.1955  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.2213  decode.d8.loss_dice: 0.2012
09/30 20:46:49 - mmengine - INFO - Iter(train) [ 96550/320000]  base_lr: 7.2382e-05 lr: 7.2382e-06  eta: 1 day, 3:05:11  time: 0.4412  data_time: 0.0101  memory: 5145  grad_norm: 47.3811  loss: 5.4156  decode.loss_cls: 0.0423  decode.loss_mask: 0.2256  decode.loss_dice: 0.1904  decode.d0.loss_cls: 0.7988  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1769  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.2239  decode.d1.loss_dice: 0.1902  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.2253  decode.d2.loss_dice: 0.1661  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.1978  decode.d4.loss_cls: 0.0861  decode.d4.loss_mask: 0.2221  decode.d4.loss_dice: 0.1533  decode.d5.loss_cls: 0.0836  decode.d5.loss_mask: 0.2208  decode.d5.loss_dice: 0.1646  decode.d6.loss_cls: 0.1017  decode.d6.loss_mask: 0.2212  decode.d6.loss_dice: 0.1693  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.1477  decode.d8.loss_cls: 0.0933  decode.d8.loss_mask: 0.2224  decode.d8.loss_dice: 0.1744
09/30 20:47:12 - mmengine - INFO - Iter(train) [ 96600/320000]  base_lr: 7.2367e-05 lr: 7.2367e-06  eta: 1 day, 3:04:49  time: 0.4421  data_time: 0.0098  memory: 5145  grad_norm: 35.9392  loss: 5.0743  decode.loss_cls: 0.0090  decode.loss_mask: 0.2119  decode.loss_dice: 0.1846  decode.d0.loss_cls: 0.8375  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.0513  decode.d1.loss_mask: 0.2133  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.1876  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.1828  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.2158  decode.d4.loss_dice: 0.1888  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.2128  decode.d5.loss_dice: 0.1835  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2140  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.2137  decode.d7.loss_dice: 0.1881  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.2161  decode.d8.loss_dice: 0.1891
09/30 20:47:34 - mmengine - INFO - Iter(train) [ 96650/320000]  base_lr: 7.2353e-05 lr: 7.2353e-06  eta: 1 day, 3:04:28  time: 0.4424  data_time: 0.0099  memory: 5129  grad_norm: 30.2069  loss: 4.9555  decode.loss_cls: 0.0037  decode.loss_mask: 0.2339  decode.loss_dice: 0.1707  decode.d0.loss_cls: 0.8556  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.1676  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.1696  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.1726  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2327  decode.d4.loss_dice: 0.1686  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2358  decode.d5.loss_dice: 0.1717  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.1692  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.2335  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.2336  decode.d8.loss_dice: 0.1677
09/30 20:47:56 - mmengine - INFO - Iter(train) [ 96700/320000]  base_lr: 7.2338e-05 lr: 7.2338e-06  eta: 1 day, 3:04:07  time: 0.4439  data_time: 0.0104  memory: 5145  grad_norm: 39.4737  loss: 5.5683  decode.loss_cls: 0.0738  decode.loss_mask: 0.2287  decode.loss_dice: 0.2168  decode.d0.loss_cls: 0.6958  decode.d0.loss_mask: 0.2283  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.1891  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.2043  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.2253  decode.d3.loss_dice: 0.1865  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.2288  decode.d4.loss_dice: 0.1977  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.2085  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.2275  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.2101  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.1992
09/30 20:48:18 - mmengine - INFO - Iter(train) [ 96750/320000]  base_lr: 7.2323e-05 lr: 7.2323e-06  eta: 1 day, 3:03:46  time: 0.4414  data_time: 0.0100  memory: 5145  grad_norm: 29.3869  loss: 5.5695  decode.loss_cls: 0.0785  decode.loss_mask: 0.2349  decode.loss_dice: 0.1765  decode.d0.loss_cls: 0.8054  decode.d0.loss_mask: 0.2377  decode.d0.loss_dice: 0.1944  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.1837  decode.d2.loss_cls: 0.0684  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.1844  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.1810  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.1730  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1726  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.1755  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.2323  decode.d8.loss_dice: 0.1749
09/30 20:48:40 - mmengine - INFO - Iter(train) [ 96800/320000]  base_lr: 7.2309e-05 lr: 7.2309e-06  eta: 1 day, 3:03:24  time: 0.4432  data_time: 0.0100  memory: 5129  grad_norm: 39.9986  loss: 5.3952  decode.loss_cls: 0.0598  decode.loss_mask: 0.1642  decode.loss_dice: 0.2269  decode.d0.loss_cls: 0.8899  decode.d0.loss_mask: 0.1636  decode.d0.loss_dice: 0.2059  decode.d1.loss_cls: 0.1320  decode.d1.loss_mask: 0.1640  decode.d1.loss_dice: 0.2161  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.1668  decode.d2.loss_dice: 0.2348  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.2240  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.1689  decode.d4.loss_dice: 0.2474  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.1629  decode.d5.loss_dice: 0.1957  decode.d6.loss_cls: 0.0543  decode.d6.loss_mask: 0.1666  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.1668  decode.d7.loss_dice: 0.2225  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.1645  decode.d8.loss_dice: 0.2241
09/30 20:49:02 - mmengine - INFO - Iter(train) [ 96850/320000]  base_lr: 7.2294e-05 lr: 7.2294e-06  eta: 1 day, 3:03:03  time: 0.4395  data_time: 0.0099  memory: 5129  grad_norm: 64.9228  loss: 5.0946  decode.loss_cls: 0.0445  decode.loss_mask: 0.1737  decode.loss_dice: 0.2453  decode.d0.loss_cls: 0.6916  decode.d0.loss_mask: 0.1779  decode.d0.loss_dice: 0.2202  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.1712  decode.d1.loss_dice: 0.1764  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.1719  decode.d2.loss_dice: 0.1720  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.1725  decode.d3.loss_dice: 0.2022  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.1735  decode.d4.loss_dice: 0.2079  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.1710  decode.d5.loss_dice: 0.2044  decode.d6.loss_cls: 0.1014  decode.d6.loss_mask: 0.1749  decode.d6.loss_dice: 0.2016  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.1709  decode.d7.loss_dice: 0.1993  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.1709  decode.d8.loss_dice: 0.2083
09/30 20:49:24 - mmengine - INFO - Iter(train) [ 96900/320000]  base_lr: 7.2280e-05 lr: 7.2280e-06  eta: 1 day, 3:02:42  time: 0.4406  data_time: 0.0099  memory: 5129  grad_norm: 91.8404  loss: 7.5775  decode.loss_cls: 0.1476  decode.loss_mask: 0.2797  decode.loss_dice: 0.2431  decode.d0.loss_cls: 0.8362  decode.d0.loss_mask: 0.2883  decode.d0.loss_dice: 0.2234  decode.d1.loss_cls: 0.2025  decode.d1.loss_mask: 0.2758  decode.d1.loss_dice: 0.2640  decode.d2.loss_cls: 0.1840  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.1724  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.2578  decode.d4.loss_cls: 0.1606  decode.d4.loss_mask: 0.2837  decode.d4.loss_dice: 0.2357  decode.d5.loss_cls: 0.1721  decode.d5.loss_mask: 0.2760  decode.d5.loss_dice: 0.2430  decode.d6.loss_cls: 0.1612  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.2446  decode.d7.loss_cls: 0.1568  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 0.2836  decode.d8.loss_dice: 0.2450
09/30 20:49:46 - mmengine - INFO - Iter(train) [ 96950/320000]  base_lr: 7.2265e-05 lr: 7.2265e-06  eta: 1 day, 3:02:21  time: 0.4412  data_time: 0.0101  memory: 5120  grad_norm: 38.0278  loss: 5.7265  decode.loss_cls: 0.0168  decode.loss_mask: 0.2586  decode.loss_dice: 0.2079  decode.d0.loss_cls: 0.8064  decode.d0.loss_mask: 0.2847  decode.d0.loss_dice: 0.2150  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.2582  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.2630  decode.d2.loss_dice: 0.2094  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.2633  decode.d3.loss_dice: 0.2107  decode.d4.loss_cls: 0.0193  decode.d4.loss_mask: 0.2682  decode.d4.loss_dice: 0.2112  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.2677  decode.d5.loss_dice: 0.2114  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.2731  decode.d6.loss_dice: 0.2131  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.2043  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2099
09/30 20:50:08 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:50:08 - mmengine - INFO - Iter(train) [ 97000/320000]  base_lr: 7.2250e-05 lr: 7.2250e-06  eta: 1 day, 3:01:59  time: 0.4411  data_time: 0.0100  memory: 5104  grad_norm: 40.5073  loss: 4.6164  decode.loss_cls: 0.0101  decode.loss_mask: 0.1883  decode.loss_dice: 0.1772  decode.d0.loss_cls: 0.7991  decode.d0.loss_mask: 0.2037  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.2073  decode.d1.loss_dice: 0.1849  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.1917  decode.d2.loss_dice: 0.1779  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.1942  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.1905  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.1904  decode.d5.loss_dice: 0.1826  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.1877  decode.d6.loss_dice: 0.1786  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.1758  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.1891  decode.d8.loss_dice: 0.1769
09/30 20:50:30 - mmengine - INFO - Iter(train) [ 97050/320000]  base_lr: 7.2236e-05 lr: 7.2236e-06  eta: 1 day, 3:01:38  time: 0.4417  data_time: 0.0102  memory: 5129  grad_norm: 44.0002  loss: 5.6962  decode.loss_cls: 0.0237  decode.loss_mask: 0.2381  decode.loss_dice: 0.2436  decode.d0.loss_cls: 0.7650  decode.d0.loss_mask: 0.2457  decode.d0.loss_dice: 0.2006  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.2322  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.2392  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.2341  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.2351  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.2406  decode.d5.loss_dice: 0.2433  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.2359  decode.d7.loss_cls: 0.0195  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.2390  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.2412  decode.d8.loss_dice: 0.2371
09/30 20:50:52 - mmengine - INFO - Iter(train) [ 97100/320000]  base_lr: 7.2221e-05 lr: 7.2221e-06  eta: 1 day, 3:01:17  time: 0.4425  data_time: 0.0102  memory: 5145  grad_norm: 21.8266  loss: 4.7955  decode.loss_cls: 0.0017  decode.loss_mask: 0.2309  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.7578  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.1705  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.2251  decode.d1.loss_dice: 0.1729  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2318  decode.d2.loss_dice: 0.1734  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.1705  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.1720  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.1699  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.1705  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.1701  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.1724
09/30 20:51:15 - mmengine - INFO - Iter(train) [ 97150/320000]  base_lr: 7.2207e-05 lr: 7.2207e-06  eta: 1 day, 3:00:56  time: 0.4427  data_time: 0.0102  memory: 5130  grad_norm: 32.7060  loss: 6.3208  decode.loss_cls: 0.1114  decode.loss_mask: 0.2219  decode.loss_dice: 0.2331  decode.d0.loss_cls: 0.8430  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.2282  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.2291  decode.d2.loss_cls: 0.1156  decode.d2.loss_mask: 0.2270  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.2321  decode.d4.loss_cls: 0.1075  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.2219  decode.d5.loss_dice: 0.2334  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.2352  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2284  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.2277  decode.d8.loss_dice: 0.2299
09/30 20:51:37 - mmengine - INFO - Iter(train) [ 97200/320000]  base_lr: 7.2192e-05 lr: 7.2192e-06  eta: 1 day, 3:00:35  time: 0.4423  data_time: 0.0098  memory: 5120  grad_norm: 36.1849  loss: 5.2592  decode.loss_cls: 0.0854  decode.loss_mask: 0.2215  decode.loss_dice: 0.1613  decode.d0.loss_cls: 0.7146  decode.d0.loss_mask: 0.2183  decode.d0.loss_dice: 0.1622  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.1637  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.2178  decode.d2.loss_dice: 0.1581  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.1591  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.2182  decode.d4.loss_dice: 0.1622  decode.d5.loss_cls: 0.0757  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.1615  decode.d6.loss_cls: 0.0810  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.1591  decode.d7.loss_cls: 0.0798  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.1617  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.1614
09/30 20:51:59 - mmengine - INFO - Iter(train) [ 97250/320000]  base_lr: 7.2178e-05 lr: 7.2178e-06  eta: 1 day, 3:00:14  time: 0.4417  data_time: 0.0100  memory: 5129  grad_norm: 49.0205  loss: 5.4603  decode.loss_cls: 0.0877  decode.loss_mask: 0.2087  decode.loss_dice: 0.1497  decode.d0.loss_cls: 0.8980  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.1519  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1463  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.2102  decode.d2.loss_dice: 0.1526  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.2292  decode.d3.loss_dice: 0.1607  decode.d4.loss_cls: 0.0928  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2368  decode.d5.loss_dice: 0.1610  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.1072  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.1521  decode.d8.loss_cls: 0.0995  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.1502
09/30 20:52:21 - mmengine - INFO - Iter(train) [ 97300/320000]  base_lr: 7.2163e-05 lr: 7.2163e-06  eta: 1 day, 2:59:53  time: 0.4419  data_time: 0.0099  memory: 5129  grad_norm: 44.9670  loss: 4.3228  decode.loss_cls: 0.0177  decode.loss_mask: 0.1797  decode.loss_dice: 0.1572  decode.d0.loss_cls: 0.7443  decode.d0.loss_mask: 0.1780  decode.d0.loss_dice: 0.1582  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.1786  decode.d1.loss_dice: 0.1581  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.1770  decode.d2.loss_dice: 0.1524  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.1760  decode.d3.loss_dice: 0.1530  decode.d4.loss_cls: 0.0346  decode.d4.loss_mask: 0.1787  decode.d4.loss_dice: 0.1551  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.1763  decode.d5.loss_dice: 0.1511  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.1785  decode.d6.loss_dice: 0.1507  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.1779  decode.d7.loss_dice: 0.1566  decode.d8.loss_cls: 0.0234  decode.d8.loss_mask: 0.1768  decode.d8.loss_dice: 0.1499
09/30 20:52:43 - mmengine - INFO - Iter(train) [ 97350/320000]  base_lr: 7.2148e-05 lr: 7.2148e-06  eta: 1 day, 2:59:32  time: 0.4432  data_time: 0.0101  memory: 5129  grad_norm: 28.6880  loss: 5.3280  decode.loss_cls: 0.0088  decode.loss_mask: 0.2026  decode.loss_dice: 0.2053  decode.d0.loss_cls: 0.9088  decode.d0.loss_mask: 0.2074  decode.d0.loss_dice: 0.1993  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.0527  decode.d2.loss_mask: 0.2050  decode.d2.loss_dice: 0.1941  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.2043  decode.d3.loss_dice: 0.1987  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.2166  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.2052  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.2008  decode.d8.loss_dice: 0.2033
09/30 20:53:05 - mmengine - INFO - Iter(train) [ 97400/320000]  base_lr: 7.2134e-05 lr: 7.2134e-06  eta: 1 day, 2:59:10  time: 0.4416  data_time: 0.0099  memory: 5120  grad_norm: 252.6253  loss: 8.3792  decode.loss_cls: 0.1696  decode.loss_mask: 0.2554  decode.loss_dice: 0.2175  decode.d0.loss_cls: 0.8959  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.2266  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.2278  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.2624  decode.d2.loss_dice: 0.2191  decode.d3.loss_cls: 0.1610  decode.d3.loss_mask: 0.5066  decode.d3.loss_dice: 0.2395  decode.d4.loss_cls: 0.1641  decode.d4.loss_mask: 0.5549  decode.d4.loss_dice: 0.2417  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2545  decode.d6.loss_cls: 0.1942  decode.d6.loss_mask: 0.7165  decode.d6.loss_dice: 0.2528  decode.d7.loss_cls: 0.1718  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.1507  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.2254
09/30 20:53:27 - mmengine - INFO - Iter(train) [ 97450/320000]  base_lr: 7.2119e-05 lr: 7.2119e-06  eta: 1 day, 2:58:49  time: 0.4417  data_time: 0.0099  memory: 5130  grad_norm: 50.6190  loss: 4.7003  decode.loss_cls: 0.0142  decode.loss_mask: 0.1964  decode.loss_dice: 0.1732  decode.d0.loss_cls: 0.8501  decode.d0.loss_mask: 0.1955  decode.d0.loss_dice: 0.1730  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.1999  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.1957  decode.d2.loss_dice: 0.1716  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.1964  decode.d3.loss_dice: 0.1720  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.1725  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.1968  decode.d5.loss_dice: 0.1763  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.1756  decode.d7.loss_cls: 0.0237  decode.d7.loss_mask: 0.1994  decode.d7.loss_dice: 0.1737  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.1966  decode.d8.loss_dice: 0.1717
09/30 20:53:50 - mmengine - INFO - Iter(train) [ 97500/320000]  base_lr: 7.2105e-05 lr: 7.2105e-06  eta: 1 day, 2:58:28  time: 0.4416  data_time: 0.0100  memory: 5129  grad_norm: 91.4408  loss: 5.3315  decode.loss_cls: 0.0754  decode.loss_mask: 0.2334  decode.loss_dice: 0.1689  decode.d0.loss_cls: 0.8159  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.1709  decode.d1.loss_cls: 0.0230  decode.d1.loss_mask: 0.2436  decode.d1.loss_dice: 0.1865  decode.d2.loss_cls: 0.0749  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.1731  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.2384  decode.d4.loss_dice: 0.1923  decode.d5.loss_cls: 0.0189  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.1834  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.2365  decode.d6.loss_dice: 0.1825  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.2340  decode.d7.loss_dice: 0.1763  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.2389  decode.d8.loss_dice: 0.1852
09/30 20:54:12 - mmengine - INFO - Iter(train) [ 97550/320000]  base_lr: 7.2090e-05 lr: 7.2090e-06  eta: 1 day, 2:58:07  time: 0.4414  data_time: 0.0099  memory: 5120  grad_norm: 100.0583  loss: 4.3279  decode.loss_cls: 0.0091  decode.loss_mask: 0.1809  decode.loss_dice: 0.1427  decode.d0.loss_cls: 0.8456  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1469  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.1467  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.1776  decode.d2.loss_dice: 0.1425  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.1786  decode.d3.loss_dice: 0.1446  decode.d4.loss_cls: 0.0394  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.1452  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.1790  decode.d5.loss_dice: 0.1422  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.1782  decode.d6.loss_dice: 0.1444  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.1781  decode.d7.loss_dice: 0.1445  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.1771  decode.d8.loss_dice: 0.1443
09/30 20:54:34 - mmengine - INFO - Iter(train) [ 97600/320000]  base_lr: 7.2075e-05 lr: 7.2075e-06  eta: 1 day, 2:57:46  time: 0.4396  data_time: 0.0097  memory: 5120  grad_norm: 63.6747  loss: 5.2899  decode.loss_cls: 0.0552  decode.loss_mask: 0.2274  decode.loss_dice: 0.1534  decode.d0.loss_cls: 0.8377  decode.d0.loss_mask: 0.2295  decode.d0.loss_dice: 0.1547  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.2260  decode.d1.loss_dice: 0.1580  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.2244  decode.d2.loss_dice: 0.1540  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.2260  decode.d3.loss_dice: 0.1568  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.1535  decode.d5.loss_cls: 0.0749  decode.d5.loss_mask: 0.2238  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0636  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.1535  decode.d7.loss_cls: 0.0653  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.1538  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.2241  decode.d8.loss_dice: 0.1507
09/30 20:54:56 - mmengine - INFO - Iter(train) [ 97650/320000]  base_lr: 7.2061e-05 lr: 7.2061e-06  eta: 1 day, 2:57:24  time: 0.4395  data_time: 0.0097  memory: 5129  grad_norm: 29.1233  loss: 4.6241  decode.loss_cls: 0.0144  decode.loss_mask: 0.2125  decode.loss_dice: 0.1624  decode.d0.loss_cls: 0.7720  decode.d0.loss_mask: 0.2140  decode.d0.loss_dice: 0.1646  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.1662  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.2112  decode.d2.loss_dice: 0.1624  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.1606  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.2142  decode.d4.loss_dice: 0.1650  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.2132  decode.d5.loss_dice: 0.1643  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.1658  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.1633  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.1638
09/30 20:55:18 - mmengine - INFO - Iter(train) [ 97700/320000]  base_lr: 7.2046e-05 lr: 7.2046e-06  eta: 1 day, 2:57:03  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 68.6181  loss: 5.9101  decode.loss_cls: 0.0816  decode.loss_mask: 0.1988  decode.loss_dice: 0.2247  decode.d0.loss_cls: 0.8294  decode.d0.loss_mask: 0.2027  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.1156  decode.d1.loss_mask: 0.1985  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.2197  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.1971  decode.d3.loss_dice: 0.2237  decode.d4.loss_cls: 0.1099  decode.d4.loss_mask: 0.2000  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2306  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.2305  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 0.1975  decode.d7.loss_dice: 0.2292  decode.d8.loss_cls: 0.1061  decode.d8.loss_mask: 0.1974  decode.d8.loss_dice: 0.2171
09/30 20:55:40 - mmengine - INFO - Iter(train) [ 97750/320000]  base_lr: 7.2032e-05 lr: 7.2032e-06  eta: 1 day, 2:56:41  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 27.6050  loss: 4.9363  decode.loss_cls: 0.0473  decode.loss_mask: 0.2042  decode.loss_dice: 0.1638  decode.d0.loss_cls: 0.8995  decode.d0.loss_mask: 0.2046  decode.d0.loss_dice: 0.1558  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.1558  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.2039  decode.d2.loss_dice: 0.1576  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.2053  decode.d3.loss_dice: 0.1569  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.2053  decode.d4.loss_dice: 0.1609  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.2026  decode.d5.loss_dice: 0.1568  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.2029  decode.d7.loss_dice: 0.1624  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.2002  decode.d8.loss_dice: 0.1554
09/30 20:56:02 - mmengine - INFO - Iter(train) [ 97800/320000]  base_lr: 7.2017e-05 lr: 7.2017e-06  eta: 1 day, 2:56:20  time: 0.4398  data_time: 0.0095  memory: 5129  grad_norm: 23.4425  loss: 4.3933  decode.loss_cls: 0.0043  decode.loss_mask: 0.1823  decode.loss_dice: 0.1562  decode.d0.loss_cls: 0.7812  decode.d0.loss_mask: 0.1886  decode.d0.loss_dice: 0.1636  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.1863  decode.d1.loss_dice: 0.1817  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.1850  decode.d2.loss_dice: 0.1786  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.1850  decode.d3.loss_dice: 0.1742  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1817  decode.d4.loss_dice: 0.1818  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.1813  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.1821  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.1836  decode.d7.loss_dice: 0.1721  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1841  decode.d8.loss_dice: 0.1707
09/30 20:56:24 - mmengine - INFO - Iter(train) [ 97850/320000]  base_lr: 7.2003e-05 lr: 7.2003e-06  eta: 1 day, 2:55:59  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 19.4498  loss: 5.0053  decode.loss_cls: 0.0855  decode.loss_mask: 0.1727  decode.loss_dice: 0.1842  decode.d0.loss_cls: 0.9016  decode.d0.loss_mask: 0.1756  decode.d0.loss_dice: 0.1715  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.1751  decode.d1.loss_dice: 0.1748  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.1696  decode.d2.loss_dice: 0.1641  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.1723  decode.d3.loss_dice: 0.1749  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.1714  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.1734  decode.d5.loss_dice: 0.1739  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.1741  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.1723  decode.d7.loss_dice: 0.1683  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 0.1713  decode.d8.loss_dice: 0.1718
09/30 20:56:46 - mmengine - INFO - Iter(train) [ 97900/320000]  base_lr: 7.1988e-05 lr: 7.1988e-06  eta: 1 day, 2:55:37  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 138.7193  loss: 6.3741  decode.loss_cls: 0.1807  decode.loss_mask: 0.1999  decode.loss_dice: 0.2021  decode.d0.loss_cls: 0.7383  decode.d0.loss_mask: 0.2030  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.1592  decode.d1.loss_mask: 0.2013  decode.d1.loss_dice: 0.2133  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.2066  decode.d2.loss_dice: 0.2078  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.1979  decode.d3.loss_dice: 0.2031  decode.d4.loss_cls: 0.1536  decode.d4.loss_mask: 0.2004  decode.d4.loss_dice: 0.2075  decode.d5.loss_cls: 0.1775  decode.d5.loss_mask: 0.2023  decode.d5.loss_dice: 0.2077  decode.d6.loss_cls: 0.1942  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.2054  decode.d7.loss_cls: 0.1835  decode.d7.loss_mask: 0.2012  decode.d7.loss_dice: 0.2115  decode.d8.loss_cls: 0.1371  decode.d8.loss_mask: 0.2047  decode.d8.loss_dice: 0.2026
09/30 20:57:08 - mmengine - INFO - Iter(train) [ 97950/320000]  base_lr: 7.1973e-05 lr: 7.1973e-06  eta: 1 day, 2:55:16  time: 0.4418  data_time: 0.0098  memory: 5120  grad_norm: 39.1992  loss: 6.4689  decode.loss_cls: 0.1448  decode.loss_mask: 0.2363  decode.loss_dice: 0.1994  decode.d0.loss_cls: 0.8895  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.2044  decode.d1.loss_cls: 0.1483  decode.d1.loss_mask: 0.2218  decode.d1.loss_dice: 0.1886  decode.d2.loss_cls: 0.1443  decode.d2.loss_mask: 0.2385  decode.d2.loss_dice: 0.1922  decode.d3.loss_cls: 0.0785  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.1968  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.3083  decode.d4.loss_dice: 0.2003  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.2983  decode.d5.loss_dice: 0.2023  decode.d6.loss_cls: 0.1190  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.3088  decode.d7.loss_dice: 0.2036  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.1864
09/30 20:57:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 20:57:30 - mmengine - INFO - Iter(train) [ 98000/320000]  base_lr: 7.1959e-05 lr: 7.1959e-06  eta: 1 day, 2:54:55  time: 0.4418  data_time: 0.0097  memory: 5145  grad_norm: 44.7851  loss: 4.8966  decode.loss_cls: 0.0127  decode.loss_mask: 0.2264  decode.loss_dice: 0.1741  decode.d0.loss_cls: 0.7467  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.1686  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.2297  decode.d1.loss_dice: 0.1748  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.2267  decode.d2.loss_dice: 0.1748  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.2258  decode.d3.loss_dice: 0.1783  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.2282  decode.d4.loss_dice: 0.1753  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.2320  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.1779  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.2257  decode.d7.loss_dice: 0.1707  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.2287  decode.d8.loss_dice: 0.1730
09/30 20:57:52 - mmengine - INFO - Iter(train) [ 98050/320000]  base_lr: 7.1944e-05 lr: 7.1944e-06  eta: 1 day, 2:54:34  time: 0.4417  data_time: 0.0101  memory: 5120  grad_norm: 20.6873  loss: 4.7078  decode.loss_cls: 0.0059  decode.loss_mask: 0.2151  decode.loss_dice: 0.1702  decode.d0.loss_cls: 0.8330  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.1646  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.1634  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.1659  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.2107  decode.d3.loss_dice: 0.1627  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.1634  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.1652  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.2138  decode.d6.loss_dice: 0.1640  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.2152  decode.d7.loss_dice: 0.1664  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.2149  decode.d8.loss_dice: 0.1648
09/30 20:58:14 - mmengine - INFO - Iter(train) [ 98100/320000]  base_lr: 7.1930e-05 lr: 7.1930e-06  eta: 1 day, 2:54:12  time: 0.4411  data_time: 0.0101  memory: 5129  grad_norm: 91.1061  loss: 5.4155  decode.loss_cls: 0.0034  decode.loss_mask: 0.2495  decode.loss_dice: 0.1958  decode.d0.loss_cls: 0.9087  decode.d0.loss_mask: 0.2507  decode.d0.loss_dice: 0.1957  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.2489  decode.d1.loss_dice: 0.1964  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.1912  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.2511  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.1937  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.2536  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.1965  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.2472  decode.d8.loss_dice: 0.2040
09/30 20:58:36 - mmengine - INFO - Iter(train) [ 98150/320000]  base_lr: 7.1915e-05 lr: 7.1915e-06  eta: 1 day, 2:53:51  time: 0.4429  data_time: 0.0101  memory: 5129  grad_norm: 99.8934  loss: 9.3325  decode.loss_cls: 0.3100  decode.loss_mask: 0.2459  decode.loss_dice: 0.2636  decode.d0.loss_cls: 0.9593  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.2650  decode.d1.loss_cls: 0.4005  decode.d1.loss_mask: 0.2497  decode.d1.loss_dice: 0.2742  decode.d2.loss_cls: 0.3080  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.2909  decode.d3.loss_cls: 0.3847  decode.d3.loss_mask: 0.2515  decode.d3.loss_dice: 0.2611  decode.d4.loss_cls: 0.3934  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.3734  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.2609  decode.d6.loss_cls: 0.3670  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.2567  decode.d7.loss_cls: 0.3545  decode.d7.loss_mask: 0.2514  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.3089  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2567
09/30 20:58:59 - mmengine - INFO - Iter(train) [ 98200/320000]  base_lr: 7.1900e-05 lr: 7.1900e-06  eta: 1 day, 2:53:30  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 80.7883  loss: 5.8855  decode.loss_cls: 0.0710  decode.loss_mask: 0.2283  decode.loss_dice: 0.2197  decode.d0.loss_cls: 0.8469  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2037  decode.d1.loss_cls: 0.1370  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2178  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.0986  decode.d3.loss_mask: 0.2258  decode.d3.loss_dice: 0.2165  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.2082  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2212  decode.d6.loss_cls: 0.0303  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.2149
09/30 20:59:21 - mmengine - INFO - Iter(train) [ 98250/320000]  base_lr: 7.1886e-05 lr: 7.1886e-06  eta: 1 day, 2:53:09  time: 0.4423  data_time: 0.0100  memory: 5120  grad_norm: 33.0572  loss: 5.8057  decode.loss_cls: 0.0682  decode.loss_mask: 0.2344  decode.loss_dice: 0.2015  decode.d0.loss_cls: 0.9813  decode.d0.loss_mask: 0.2345  decode.d0.loss_dice: 0.1975  decode.d1.loss_cls: 0.0281  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2130  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.1881  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.2348  decode.d3.loss_dice: 0.2199  decode.d4.loss_cls: 0.0761  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.2307  decode.d5.loss_dice: 0.2024  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.2330  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.0824  decode.d7.loss_mask: 0.2337  decode.d7.loss_dice: 0.1991  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.2282  decode.d8.loss_dice: 0.1885
09/30 20:59:43 - mmengine - INFO - Iter(train) [ 98300/320000]  base_lr: 7.1871e-05 lr: 7.1871e-06  eta: 1 day, 2:52:47  time: 0.4414  data_time: 0.0100  memory: 5129  grad_norm: 40.0386  loss: 4.6171  decode.loss_cls: 0.0022  decode.loss_mask: 0.2050  decode.loss_dice: 0.1706  decode.d0.loss_cls: 0.7576  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.1839  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.2091  decode.d2.loss_dice: 0.1741  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1711  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.1686  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.1646  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.2045  decode.d7.loss_dice: 0.1711  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2087  decode.d8.loss_dice: 0.1717
09/30 21:00:05 - mmengine - INFO - Iter(train) [ 98350/320000]  base_lr: 7.1857e-05 lr: 7.1857e-06  eta: 1 day, 2:52:26  time: 0.4444  data_time: 0.0100  memory: 5120  grad_norm: 36.4391  loss: 4.1586  decode.loss_cls: 0.0098  decode.loss_mask: 0.1616  decode.loss_dice: 0.1510  decode.d0.loss_cls: 0.8936  decode.d0.loss_mask: 0.1649  decode.d0.loss_dice: 0.1542  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.1649  decode.d1.loss_dice: 0.1543  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.1644  decode.d2.loss_dice: 0.1661  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.1633  decode.d3.loss_dice: 0.1558  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.1619  decode.d4.loss_dice: 0.1498  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.1637  decode.d5.loss_dice: 0.1485  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.1611  decode.d6.loss_dice: 0.1525  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.1607  decode.d7.loss_dice: 0.1504  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.1633  decode.d8.loss_dice: 0.1525
09/30 21:00:27 - mmengine - INFO - Iter(train) [ 98400/320000]  base_lr: 7.1842e-05 lr: 7.1842e-06  eta: 1 day, 2:52:05  time: 0.4425  data_time: 0.0100  memory: 5129  grad_norm: 37.5513  loss: 4.7105  decode.loss_cls: 0.0023  decode.loss_mask: 0.2079  decode.loss_dice: 0.1812  decode.d0.loss_cls: 0.8018  decode.d0.loss_mask: 0.2141  decode.d0.loss_dice: 0.1852  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.1868  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.2111  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2082  decode.d3.loss_dice: 0.1732  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.2087  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2101  decode.d5.loss_dice: 0.1758  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.2076  decode.d6.loss_dice: 0.1746  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2092  decode.d7.loss_dice: 0.1751  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.2076  decode.d8.loss_dice: 0.1822
09/30 21:00:49 - mmengine - INFO - Iter(train) [ 98450/320000]  base_lr: 7.1828e-05 lr: 7.1828e-06  eta: 1 day, 2:51:44  time: 0.4452  data_time: 0.0100  memory: 5145  grad_norm: 34.4889  loss: 5.8185  decode.loss_cls: 0.0051  decode.loss_mask: 0.2865  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.7237  decode.d0.loss_mask: 0.2890  decode.d0.loss_dice: 0.2166  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.2832  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.2086  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.2875  decode.d3.loss_dice: 0.2030  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2854  decode.d4.loss_dice: 0.2177  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.2839  decode.d5.loss_dice: 0.2050  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.2839  decode.d6.loss_dice: 0.2056  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.2114  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2839  decode.d8.loss_dice: 0.2021
09/30 21:01:11 - mmengine - INFO - Iter(train) [ 98500/320000]  base_lr: 7.1813e-05 lr: 7.1813e-06  eta: 1 day, 2:51:23  time: 0.4437  data_time: 0.0100  memory: 5120  grad_norm: 36.2441  loss: 5.4935  decode.loss_cls: 0.0352  decode.loss_mask: 0.2070  decode.loss_dice: 0.2293  decode.d0.loss_cls: 0.8447  decode.d0.loss_mask: 0.2051  decode.d0.loss_dice: 0.2391  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.2081  decode.d1.loss_dice: 0.2091  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.2091  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.2070  decode.d3.loss_dice: 0.2377  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.2034  decode.d4.loss_dice: 0.2336  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.2059  decode.d5.loss_dice: 0.2186  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.2072  decode.d7.loss_dice: 0.2372  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.2074  decode.d8.loss_dice: 0.2246
09/30 21:01:34 - mmengine - INFO - Iter(train) [ 98550/320000]  base_lr: 7.1798e-05 lr: 7.1798e-06  eta: 1 day, 2:51:02  time: 0.4433  data_time: 0.0102  memory: 5145  grad_norm: 130.2677  loss: 6.1822  decode.loss_cls: 0.1108  decode.loss_mask: 0.2241  decode.loss_dice: 0.2163  decode.d0.loss_cls: 0.8249  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.2261  decode.d1.loss_cls: 0.1060  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.1060  decode.d2.loss_mask: 0.2133  decode.d2.loss_dice: 0.2170  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2126  decode.d3.loss_dice: 0.2141  decode.d4.loss_cls: 0.1144  decode.d4.loss_mask: 0.2242  decode.d4.loss_dice: 0.2053  decode.d5.loss_cls: 0.1035  decode.d5.loss_mask: 0.2193  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.2070  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 0.2219  decode.d7.loss_dice: 0.1928  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 0.2427  decode.d8.loss_dice: 0.2009
09/30 21:01:56 - mmengine - INFO - Iter(train) [ 98600/320000]  base_lr: 7.1784e-05 lr: 7.1784e-06  eta: 1 day, 2:50:41  time: 0.4419  data_time: 0.0100  memory: 5120  grad_norm: 44.3125  loss: 5.4921  decode.loss_cls: 0.0339  decode.loss_mask: 0.2169  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 0.2195  decode.d0.loss_dice: 0.2177  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.2168  decode.d1.loss_dice: 0.2125  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.0981  decode.d3.loss_mask: 0.2140  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.2457  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.2322  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.2161  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.2178
09/30 21:02:18 - mmengine - INFO - Iter(train) [ 98650/320000]  base_lr: 7.1769e-05 lr: 7.1769e-06  eta: 1 day, 2:50:20  time: 0.4402  data_time: 0.0096  memory: 5145  grad_norm: 60.5299  loss: 5.5783  decode.loss_cls: 0.0582  decode.loss_mask: 0.2536  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.8425  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.1855  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.1784  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.1667  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.1881  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.1675  decode.d5.loss_cls: 0.0276  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.1980  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.1851  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.1701  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.1669
09/30 21:02:40 - mmengine - INFO - Iter(train) [ 98700/320000]  base_lr: 7.1755e-05 lr: 7.1755e-06  eta: 1 day, 2:49:58  time: 0.4408  data_time: 0.0097  memory: 5120  grad_norm: 34.2837  loss: 5.3827  decode.loss_cls: 0.0579  decode.loss_mask: 0.2289  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.8302  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.1794  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.1766  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.1774  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2279  decode.d3.loss_dice: 0.1856  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.2275  decode.d4.loss_dice: 0.1835  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.2248  decode.d5.loss_dice: 0.1775  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1865  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 0.2272  decode.d7.loss_dice: 0.1807  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.2291  decode.d8.loss_dice: 0.1824
09/30 21:03:02 - mmengine - INFO - Iter(train) [ 98750/320000]  base_lr: 7.1740e-05 lr: 7.1740e-06  eta: 1 day, 2:49:37  time: 0.4398  data_time: 0.0098  memory: 5129  grad_norm: 39.5982  loss: 4.7757  decode.loss_cls: 0.0286  decode.loss_mask: 0.2011  decode.loss_dice: 0.1715  decode.d0.loss_cls: 0.8538  decode.d0.loss_mask: 0.2045  decode.d0.loss_dice: 0.1659  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.2008  decode.d1.loss_dice: 0.1707  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.2008  decode.d2.loss_dice: 0.1624  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0253  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.1646  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.2002  decode.d5.loss_dice: 0.1631  decode.d6.loss_cls: 0.0315  decode.d6.loss_mask: 0.2043  decode.d6.loss_dice: 0.1717  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.2039  decode.d7.loss_dice: 0.1727  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.2027  decode.d8.loss_dice: 0.1700
09/30 21:03:24 - mmengine - INFO - Iter(train) [ 98800/320000]  base_lr: 7.1725e-05 lr: 7.1725e-06  eta: 1 day, 2:49:15  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 166.9854  loss: 6.5952  decode.loss_cls: 0.0281  decode.loss_mask: 0.2932  decode.loss_dice: 0.2496  decode.d0.loss_cls: 0.6793  decode.d0.loss_mask: 0.3014  decode.d0.loss_dice: 0.2509  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.2511  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.2973  decode.d2.loss_dice: 0.2388  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 0.3001  decode.d3.loss_dice: 0.2499  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.2910  decode.d4.loss_dice: 0.2529  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.3007  decode.d5.loss_dice: 0.2600  decode.d6.loss_cls: 0.0815  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 0.2961  decode.d7.loss_dice: 0.2500  decode.d8.loss_cls: 0.0292  decode.d8.loss_mask: 0.2965  decode.d8.loss_dice: 0.2528
09/30 21:03:46 - mmengine - INFO - Iter(train) [ 98850/320000]  base_lr: 7.1711e-05 lr: 7.1711e-06  eta: 1 day, 2:48:54  time: 0.4413  data_time: 0.0097  memory: 5145  grad_norm: 27.7603  loss: 4.8906  decode.loss_cls: 0.0205  decode.loss_mask: 0.2201  decode.loss_dice: 0.1528  decode.d0.loss_cls: 0.7752  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.1638  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.2525  decode.d1.loss_dice: 0.1545  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.1584  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.1622  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.1579  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.1598  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.1584  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.1569  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.2276  decode.d8.loss_dice: 0.1573
09/30 21:04:08 - mmengine - INFO - Iter(train) [ 98900/320000]  base_lr: 7.1696e-05 lr: 7.1696e-06  eta: 1 day, 2:48:33  time: 0.4403  data_time: 0.0096  memory: 5145  grad_norm: 66.7324  loss: 4.6273  decode.loss_cls: 0.0337  decode.loss_mask: 0.1992  decode.loss_dice: 0.1562  decode.d0.loss_cls: 0.7787  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.1660  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.2041  decode.d1.loss_dice: 0.1570  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.1581  decode.d3.loss_cls: 0.0319  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.1582  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.1539  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.2004  decode.d5.loss_dice: 0.1574  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.2036  decode.d6.loss_dice: 0.1541  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.1564  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.2011  decode.d8.loss_dice: 0.1563
09/30 21:04:30 - mmengine - INFO - Iter(train) [ 98950/320000]  base_lr: 7.1682e-05 lr: 7.1682e-06  eta: 1 day, 2:48:12  time: 0.4409  data_time: 0.0095  memory: 5120  grad_norm: 66.7837  loss: 4.8777  decode.loss_cls: 0.0178  decode.loss_mask: 0.2037  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.8535  decode.d0.loss_mask: 0.2036  decode.d0.loss_dice: 0.1750  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.2054  decode.d1.loss_dice: 0.1922  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.1687  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.2036  decode.d3.loss_dice: 0.1686  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.2042  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.2029  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.2025  decode.d6.loss_dice: 0.1808  decode.d7.loss_cls: 0.0215  decode.d7.loss_mask: 0.2043  decode.d7.loss_dice: 0.1916  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.2033  decode.d8.loss_dice: 0.1788
09/30 21:04:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:04:52 - mmengine - INFO - Iter(train) [ 99000/320000]  base_lr: 7.1667e-05 lr: 7.1667e-06  eta: 1 day, 2:47:50  time: 0.4402  data_time: 0.0098  memory: 5129  grad_norm: 89.4282  loss: 7.6306  decode.loss_cls: 0.0591  decode.loss_mask: 0.2503  decode.loss_dice: 0.2564  decode.d0.loss_cls: 0.9422  decode.d0.loss_mask: 0.2867  decode.d0.loss_dice: 0.3081  decode.d1.loss_cls: 0.1680  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.3081  decode.d2.loss_cls: 0.2071  decode.d2.loss_mask: 0.2506  decode.d2.loss_dice: 0.2802  decode.d3.loss_cls: 0.1699  decode.d3.loss_mask: 0.2580  decode.d3.loss_dice: 0.2766  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 0.2574  decode.d4.loss_dice: 0.3012  decode.d5.loss_cls: 0.1503  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.2599  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.2549  decode.d6.loss_dice: 0.2751  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.2857  decode.d8.loss_cls: 0.1076  decode.d8.loss_mask: 0.2561  decode.d8.loss_dice: 0.2811
09/30 21:05:14 - mmengine - INFO - Iter(train) [ 99050/320000]  base_lr: 7.1652e-05 lr: 7.1652e-06  eta: 1 day, 2:47:29  time: 0.4408  data_time: 0.0100  memory: 5129  grad_norm: 55.0159  loss: 6.0190  decode.loss_cls: 0.0698  decode.loss_mask: 0.2641  decode.loss_dice: 0.1907  decode.d0.loss_cls: 0.8606  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.1923  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.2652  decode.d1.loss_dice: 0.1887  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.2644  decode.d2.loss_dice: 0.1950  decode.d3.loss_cls: 0.0864  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.1882  decode.d4.loss_cls: 0.0705  decode.d4.loss_mask: 0.2667  decode.d4.loss_dice: 0.1900  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.2707  decode.d5.loss_dice: 0.1942  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.1986  decode.d7.loss_cls: 0.0343  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.1913  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.2665  decode.d8.loss_dice: 0.1902
09/30 21:05:36 - mmengine - INFO - Iter(train) [ 99100/320000]  base_lr: 7.1638e-05 lr: 7.1638e-06  eta: 1 day, 2:47:08  time: 0.4409  data_time: 0.0099  memory: 5145  grad_norm: 45.6669  loss: 5.4177  decode.loss_cls: 0.0820  decode.loss_mask: 0.1906  decode.loss_dice: 0.1743  decode.d0.loss_cls: 0.8682  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.1741  decode.d1.loss_cls: 0.1359  decode.d1.loss_mask: 0.1930  decode.d1.loss_dice: 0.1858  decode.d2.loss_cls: 0.1094  decode.d2.loss_mask: 0.1917  decode.d2.loss_dice: 0.1726  decode.d3.loss_cls: 0.1057  decode.d3.loss_mask: 0.1907  decode.d3.loss_dice: 0.1756  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.1701  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.1909  decode.d5.loss_dice: 0.1744  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.1766  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.1925  decode.d7.loss_dice: 0.1794  decode.d8.loss_cls: 0.1022  decode.d8.loss_mask: 0.1930  decode.d8.loss_dice: 0.1726
09/30 21:05:58 - mmengine - INFO - Iter(train) [ 99150/320000]  base_lr: 7.1623e-05 lr: 7.1623e-06  eta: 1 day, 2:46:46  time: 0.4401  data_time: 0.0096  memory: 5129  grad_norm: 38.5432  loss: 4.9074  decode.loss_cls: 0.0070  decode.loss_mask: 0.2267  decode.loss_dice: 0.1795  decode.d0.loss_cls: 0.7354  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.1841  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2274  decode.d5.loss_dice: 0.1839  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2262  decode.d6.loss_dice: 0.1828  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2266  decode.d8.loss_dice: 0.1850
09/30 21:06:20 - mmengine - INFO - Iter(train) [ 99200/320000]  base_lr: 7.1609e-05 lr: 7.1609e-06  eta: 1 day, 2:46:25  time: 0.4399  data_time: 0.0096  memory: 5120  grad_norm: 48.6647  loss: 6.1225  decode.loss_cls: 0.0457  decode.loss_mask: 0.2704  decode.loss_dice: 0.2089  decode.d0.loss_cls: 0.8600  decode.d0.loss_mask: 0.2554  decode.d0.loss_dice: 0.2005  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.2691  decode.d1.loss_dice: 0.2035  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.2727  decode.d2.loss_dice: 0.2048  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.2679  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.2714  decode.d4.loss_dice: 0.2097  decode.d5.loss_cls: 0.0878  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0942  decode.d6.loss_mask: 0.2711  decode.d6.loss_dice: 0.2080  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.2118  decode.d8.loss_cls: 0.0354  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.2222
09/30 21:06:42 - mmengine - INFO - Iter(train) [ 99250/320000]  base_lr: 7.1594e-05 lr: 7.1594e-06  eta: 1 day, 2:46:03  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 31.5967  loss: 4.8814  decode.loss_cls: 0.0627  decode.loss_mask: 0.1643  decode.loss_dice: 0.1684  decode.d0.loss_cls: 0.9707  decode.d0.loss_mask: 0.1642  decode.d0.loss_dice: 0.1611  decode.d1.loss_cls: 0.0849  decode.d1.loss_mask: 0.1624  decode.d1.loss_dice: 0.1564  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.1649  decode.d2.loss_dice: 0.1633  decode.d3.loss_cls: 0.0847  decode.d3.loss_mask: 0.1623  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0448  decode.d4.loss_mask: 0.1652  decode.d4.loss_dice: 0.1646  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.1658  decode.d5.loss_dice: 0.1555  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.1631  decode.d6.loss_dice: 0.1599  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.1631  decode.d7.loss_dice: 0.1639  decode.d8.loss_cls: 0.0805  decode.d8.loss_mask: 0.1648  decode.d8.loss_dice: 0.1689
09/30 21:07:05 - mmengine - INFO - Iter(train) [ 99300/320000]  base_lr: 7.1579e-05 lr: 7.1579e-06  eta: 1 day, 2:45:42  time: 0.4408  data_time: 0.0100  memory: 5129  grad_norm: 71.0336  loss: 4.9706  decode.loss_cls: 0.0084  decode.loss_mask: 0.2360  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.7732  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.1668  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2417  decode.d1.loss_dice: 0.1799  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.1779  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2391  decode.d3.loss_dice: 0.1793  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.1757  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.1769  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.1753  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.1752
09/30 21:07:27 - mmengine - INFO - Iter(train) [ 99350/320000]  base_lr: 7.1565e-05 lr: 7.1565e-06  eta: 1 day, 2:45:21  time: 0.4402  data_time: 0.0097  memory: 5145  grad_norm: 199.8284  loss: 8.0336  decode.loss_cls: 0.2916  decode.loss_mask: 0.2466  decode.loss_dice: 0.2308  decode.d0.loss_cls: 1.0500  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.1667  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.2295  decode.d2.loss_cls: 0.1966  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.2320  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 0.2447  decode.d3.loss_dice: 0.2411  decode.d4.loss_cls: 0.2395  decode.d4.loss_mask: 0.2450  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.2198  decode.d5.loss_mask: 0.2450  decode.d5.loss_dice: 0.2341  decode.d6.loss_cls: 0.2596  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2362  decode.d7.loss_cls: 0.2804  decode.d7.loss_mask: 0.2467  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.2931  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.2467
09/30 21:07:49 - mmengine - INFO - Iter(train) [ 99400/320000]  base_lr: 7.1550e-05 lr: 7.1550e-06  eta: 1 day, 2:44:59  time: 0.4397  data_time: 0.0097  memory: 5119  grad_norm: 34.0844  loss: 4.7696  decode.loss_cls: 0.0149  decode.loss_mask: 0.2234  decode.loss_dice: 0.1580  decode.d0.loss_cls: 0.7895  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.1685  decode.d1.loss_cls: 0.0268  decode.d1.loss_mask: 0.2208  decode.d1.loss_dice: 0.1694  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.1600  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.2240  decode.d3.loss_dice: 0.1533  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.1574  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.2232  decode.d5.loss_dice: 0.1639  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.1664  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2240  decode.d7.loss_dice: 0.1603  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.2213  decode.d8.loss_dice: 0.1591
09/30 21:08:11 - mmengine - INFO - Iter(train) [ 99450/320000]  base_lr: 7.1536e-05 lr: 7.1536e-06  eta: 1 day, 2:44:38  time: 0.4403  data_time: 0.0097  memory: 5120  grad_norm: 70.1903  loss: 5.0561  decode.loss_cls: 0.0554  decode.loss_mask: 0.2205  decode.loss_dice: 0.1509  decode.d0.loss_cls: 0.8190  decode.d0.loss_mask: 0.1755  decode.d0.loss_dice: 0.1529  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 0.1866  decode.d1.loss_dice: 0.1528  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.1917  decode.d2.loss_dice: 0.1509  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.2106  decode.d3.loss_dice: 0.1459  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.1483  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.1497  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.1532  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.1549  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.1911  decode.d8.loss_dice: 0.1509
09/30 21:08:33 - mmengine - INFO - Iter(train) [ 99500/320000]  base_lr: 7.1521e-05 lr: 7.1521e-06  eta: 1 day, 2:44:17  time: 0.4411  data_time: 0.0096  memory: 5145  grad_norm: 29.0437  loss: 5.1199  decode.loss_cls: 0.0648  decode.loss_mask: 0.1869  decode.loss_dice: 0.1744  decode.d0.loss_cls: 0.8272  decode.d0.loss_mask: 0.1845  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.1852  decode.d1.loss_dice: 0.1814  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.1877  decode.d2.loss_dice: 0.1864  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.1861  decode.d3.loss_dice: 0.1883  decode.d4.loss_cls: 0.0723  decode.d4.loss_mask: 0.1844  decode.d4.loss_dice: 0.1892  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.1865  decode.d5.loss_dice: 0.1826  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.1863  decode.d6.loss_dice: 0.1940  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.1850  decode.d7.loss_dice: 0.1832  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.1867  decode.d8.loss_dice: 0.1850
09/30 21:08:55 - mmengine - INFO - Iter(train) [ 99550/320000]  base_lr: 7.1506e-05 lr: 7.1506e-06  eta: 1 day, 2:43:55  time: 0.4410  data_time: 0.0100  memory: 5145  grad_norm: 32.3236  loss: 4.6871  decode.loss_cls: 0.0078  decode.loss_mask: 0.1981  decode.loss_dice: 0.1751  decode.d0.loss_cls: 0.8684  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.1698  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.1981  decode.d1.loss_dice: 0.1767  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.1939  decode.d2.loss_dice: 0.1757  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.1957  decode.d3.loss_dice: 0.1737  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.1974  decode.d4.loss_dice: 0.1753  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.1975  decode.d5.loss_dice: 0.1761  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.1766  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.1975  decode.d7.loss_dice: 0.1781  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.1961  decode.d8.loss_dice: 0.1771
09/30 21:09:17 - mmengine - INFO - Iter(train) [ 99600/320000]  base_lr: 7.1492e-05 lr: 7.1492e-06  eta: 1 day, 2:43:34  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 37.4070  loss: 4.8880  decode.loss_cls: 0.0543  decode.loss_mask: 0.1908  decode.loss_dice: 0.1889  decode.d0.loss_cls: 0.8247  decode.d0.loss_mask: 0.1853  decode.d0.loss_dice: 0.1894  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.1861  decode.d1.loss_dice: 0.1790  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.1861  decode.d2.loss_dice: 0.1768  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.1870  decode.d3.loss_dice: 0.1843  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.1925  decode.d4.loss_dice: 0.1821  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.2058  decode.d5.loss_dice: 0.1882  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.1955  decode.d6.loss_dice: 0.2003  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.1913  decode.d8.loss_dice: 0.1745
09/30 21:09:39 - mmengine - INFO - Iter(train) [ 99650/320000]  base_lr: 7.1477e-05 lr: 7.1477e-06  eta: 1 day, 2:43:13  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 68.2728  loss: 8.8460  decode.loss_cls: 0.2683  decode.loss_mask: 0.3489  decode.loss_dice: 0.2215  decode.d0.loss_cls: 0.7528  decode.d0.loss_mask: 0.3817  decode.d0.loss_dice: 0.2167  decode.d1.loss_cls: 0.2702  decode.d1.loss_mask: 0.3670  decode.d1.loss_dice: 0.2362  decode.d2.loss_cls: 0.2289  decode.d2.loss_mask: 0.3574  decode.d2.loss_dice: 0.2251  decode.d3.loss_cls: 0.2448  decode.d3.loss_mask: 0.3586  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.2357  decode.d4.loss_mask: 0.3609  decode.d4.loss_dice: 0.2087  decode.d5.loss_cls: 0.2415  decode.d5.loss_mask: 0.3552  decode.d5.loss_dice: 0.2181  decode.d6.loss_cls: 0.2686  decode.d6.loss_mask: 0.3580  decode.d6.loss_dice: 0.2136  decode.d7.loss_cls: 0.2460  decode.d7.loss_mask: 0.3590  decode.d7.loss_dice: 0.2217  decode.d8.loss_cls: 0.2368  decode.d8.loss_mask: 0.3838  decode.d8.loss_dice: 0.2410
09/30 21:10:01 - mmengine - INFO - Iter(train) [ 99700/320000]  base_lr: 7.1463e-05 lr: 7.1463e-06  eta: 1 day, 2:42:51  time: 0.4428  data_time: 0.0101  memory: 5145  grad_norm: 48.2852  loss: 5.8820  decode.loss_cls: 0.0831  decode.loss_mask: 0.2203  decode.loss_dice: 0.2149  decode.d0.loss_cls: 0.8930  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.1935  decode.d1.loss_cls: 0.1096  decode.d1.loss_mask: 0.2092  decode.d1.loss_dice: 0.2062  decode.d2.loss_cls: 0.1124  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.2000  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.2053  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.2075  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 0.2092  decode.d5.loss_dice: 0.2035  decode.d6.loss_cls: 0.0847  decode.d6.loss_mask: 0.2117  decode.d6.loss_dice: 0.2083  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.2153  decode.d7.loss_dice: 0.2103  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.2165  decode.d8.loss_dice: 0.2075
09/30 21:10:23 - mmengine - INFO - Iter(train) [ 99750/320000]  base_lr: 7.1448e-05 lr: 7.1448e-06  eta: 1 day, 2:42:30  time: 0.4398  data_time: 0.0099  memory: 5129  grad_norm: 57.8398  loss: 6.2439  decode.loss_cls: 0.1175  decode.loss_mask: 0.2534  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.9236  decode.d0.loss_mask: 0.2541  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.1923  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.2540  decode.d2.loss_dice: 0.1831  decode.d3.loss_cls: 0.1008  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.1828  decode.d4.loss_cls: 0.1155  decode.d4.loss_mask: 0.2490  decode.d4.loss_dice: 0.1808  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 0.2512  decode.d5.loss_dice: 0.1846  decode.d6.loss_cls: 0.0853  decode.d6.loss_mask: 0.2506  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.1882  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.1888
09/30 21:10:45 - mmengine - INFO - Iter(train) [ 99800/320000]  base_lr: 7.1433e-05 lr: 7.1433e-06  eta: 1 day, 2:42:09  time: 0.4424  data_time: 0.0102  memory: 5119  grad_norm: 29.6116  loss: 4.9484  decode.loss_cls: 0.0547  decode.loss_mask: 0.2053  decode.loss_dice: 0.1486  decode.d0.loss_cls: 0.8004  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.1516  decode.d1.loss_cls: 0.0769  decode.d1.loss_mask: 0.2073  decode.d1.loss_dice: 0.1505  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.1510  decode.d3.loss_cls: 0.0681  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.1519  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.2070  decode.d4.loss_dice: 0.1538  decode.d5.loss_cls: 0.0536  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.2041  decode.d6.loss_dice: 0.1513  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.1490  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.2054  decode.d8.loss_dice: 0.1494
09/30 21:11:07 - mmengine - INFO - Iter(train) [ 99850/320000]  base_lr: 7.1419e-05 lr: 7.1419e-06  eta: 1 day, 2:41:47  time: 0.4427  data_time: 0.0100  memory: 5129  grad_norm: 66.6511  loss: 5.5946  decode.loss_cls: 0.0942  decode.loss_mask: 0.2255  decode.loss_dice: 0.1862  decode.d0.loss_cls: 0.7856  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.1839  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.2195  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.2138  decode.d3.loss_cls: 0.0504  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.1864  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.1967  decode.d5.loss_cls: 0.0753  decode.d5.loss_mask: 0.2270  decode.d5.loss_dice: 0.2250  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.2215  decode.d6.loss_dice: 0.1808  decode.d7.loss_cls: 0.0895  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.1812
09/30 21:11:29 - mmengine - INFO - Iter(train) [ 99900/320000]  base_lr: 7.1404e-05 lr: 7.1404e-06  eta: 1 day, 2:41:26  time: 0.4431  data_time: 0.0101  memory: 5129  grad_norm: 52.7981  loss: 7.3200  decode.loss_cls: 0.1418  decode.loss_mask: 0.2195  decode.loss_dice: 0.3052  decode.d0.loss_cls: 1.1150  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.2942  decode.d1.loss_cls: 0.1108  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.3005  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.2169  decode.d2.loss_dice: 0.3358  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.3269  decode.d4.loss_cls: 0.1197  decode.d4.loss_mask: 0.2163  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.2150  decode.d5.loss_dice: 0.3058  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 0.2162  decode.d6.loss_dice: 0.3153  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.2208  decode.d7.loss_dice: 0.3036  decode.d8.loss_cls: 0.0848  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.3166
09/30 21:11:51 - mmengine - INFO - Iter(train) [ 99950/320000]  base_lr: 7.1390e-05 lr: 7.1390e-06  eta: 1 day, 2:41:05  time: 0.4426  data_time: 0.0100  memory: 5129  grad_norm: 88.2687  loss: 6.3390  decode.loss_cls: 0.1012  decode.loss_mask: 0.2132  decode.loss_dice: 0.2151  decode.d0.loss_cls: 0.8740  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.2124  decode.d1.loss_mask: 0.2154  decode.d1.loss_dice: 0.2077  decode.d2.loss_cls: 0.1526  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2190  decode.d3.loss_cls: 0.1640  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.2073  decode.d4.loss_cls: 0.1096  decode.d4.loss_mask: 0.2107  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.2145  decode.d5.loss_dice: 0.2167  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.1568  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.2159  decode.d8.loss_cls: 0.1154  decode.d8.loss_mask: 0.2134  decode.d8.loss_dice: 0.2136
09/30 21:12:13 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:12:13 - mmengine - INFO - Iter(train) [100000/320000]  base_lr: 7.1375e-05 lr: 7.1375e-06  eta: 1 day, 2:40:44  time: 0.4432  data_time: 0.0101  memory: 5129  grad_norm: 105.9800  loss: 5.9690  decode.loss_cls: 0.0432  decode.loss_mask: 0.2594  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.8002  decode.d0.loss_mask: 0.2684  decode.d0.loss_dice: 0.2033  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.1981  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.2684  decode.d2.loss_dice: 0.2078  decode.d3.loss_cls: 0.0591  decode.d3.loss_mask: 0.2635  decode.d3.loss_dice: 0.2068  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.2629  decode.d4.loss_dice: 0.2102  decode.d5.loss_cls: 0.0229  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.2149  decode.d6.loss_cls: 0.0541  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.2220  decode.d7.loss_cls: 0.0308  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.2164  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.2643  decode.d8.loss_dice: 0.2201
09/30 21:12:36 - mmengine - INFO - Iter(train) [100050/320000]  base_lr: 7.1360e-05 lr: 7.1360e-06  eta: 1 day, 2:40:22  time: 0.4419  data_time: 0.0100  memory: 5129  grad_norm: 120.9624  loss: 5.6092  decode.loss_cls: 0.0743  decode.loss_mask: 0.2379  decode.loss_dice: 0.1704  decode.d0.loss_cls: 0.8343  decode.d0.loss_mask: 0.2385  decode.d0.loss_dice: 0.1637  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.1766  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.2375  decode.d2.loss_dice: 0.1745  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.2367  decode.d3.loss_dice: 0.1724  decode.d4.loss_cls: 0.0838  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.1893  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.1667  decode.d6.loss_cls: 0.0903  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.1674  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.2345  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.1680
09/30 21:12:58 - mmengine - INFO - Iter(train) [100100/320000]  base_lr: 7.1346e-05 lr: 7.1346e-06  eta: 1 day, 2:40:01  time: 0.4389  data_time: 0.0097  memory: 5129  grad_norm: 127.2873  loss: 6.6073  decode.loss_cls: 0.1555  decode.loss_mask: 0.2909  decode.loss_dice: 0.1646  decode.d0.loss_cls: 0.7508  decode.d0.loss_mask: 0.2927  decode.d0.loss_dice: 0.1758  decode.d1.loss_cls: 0.0938  decode.d1.loss_mask: 0.2893  decode.d1.loss_dice: 0.2010  decode.d2.loss_cls: 0.1323  decode.d2.loss_mask: 0.2846  decode.d2.loss_dice: 0.1643  decode.d3.loss_cls: 0.1276  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.1685  decode.d4.loss_cls: 0.0940  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.1674  decode.d5.loss_cls: 0.1642  decode.d5.loss_mask: 0.2840  decode.d5.loss_dice: 0.2078  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.1661  decode.d7.loss_cls: 0.1839  decode.d7.loss_mask: 0.2879  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 0.2853  decode.d8.loss_dice: 0.1683
09/30 21:13:20 - mmengine - INFO - Iter(train) [100150/320000]  base_lr: 7.1331e-05 lr: 7.1331e-06  eta: 1 day, 2:39:39  time: 0.4395  data_time: 0.0096  memory: 5129  grad_norm: 36.5762  loss: 4.9854  decode.loss_cls: 0.0737  decode.loss_mask: 0.1939  decode.loss_dice: 0.1545  decode.d0.loss_cls: 0.8913  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.1837  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.1932  decode.d1.loss_dice: 0.1639  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.1927  decode.d2.loss_dice: 0.1585  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.1955  decode.d3.loss_dice: 0.1563  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.1578  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.1945  decode.d5.loss_dice: 0.1579  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.1940  decode.d6.loss_dice: 0.1629  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.1954  decode.d7.loss_dice: 0.1642  decode.d8.loss_cls: 0.0721  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.1585
09/30 21:13:42 - mmengine - INFO - Iter(train) [100200/320000]  base_lr: 7.1317e-05 lr: 7.1317e-06  eta: 1 day, 2:39:18  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 27.5881  loss: 5.2970  decode.loss_cls: 0.0457  decode.loss_mask: 0.2371  decode.loss_dice: 0.1594  decode.d0.loss_cls: 0.8577  decode.d0.loss_mask: 0.2449  decode.d0.loss_dice: 0.1570  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.2408  decode.d1.loss_dice: 0.1646  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.1610  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.2399  decode.d4.loss_dice: 0.1621  decode.d5.loss_cls: 0.0402  decode.d5.loss_mask: 0.2423  decode.d5.loss_dice: 0.1620  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.2396  decode.d6.loss_dice: 0.1613  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.1585  decode.d8.loss_cls: 0.0483  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.1600
09/30 21:14:04 - mmengine - INFO - Iter(train) [100250/320000]  base_lr: 7.1302e-05 lr: 7.1302e-06  eta: 1 day, 2:38:57  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 69.9989  loss: 5.2935  decode.loss_cls: 0.0794  decode.loss_mask: 0.1826  decode.loss_dice: 0.1975  decode.d0.loss_cls: 0.8891  decode.d0.loss_mask: 0.1857  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.0201  decode.d1.loss_mask: 0.1826  decode.d1.loss_dice: 0.2107  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.1819  decode.d2.loss_dice: 0.2053  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.2018  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.1829  decode.d4.loss_dice: 0.2005  decode.d5.loss_cls: 0.0390  decode.d5.loss_mask: 0.1790  decode.d5.loss_dice: 0.1984  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.1814  decode.d6.loss_dice: 0.2060  decode.d7.loss_cls: 0.1336  decode.d7.loss_mask: 0.1826  decode.d7.loss_dice: 0.1943  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.1816  decode.d8.loss_dice: 0.2113
09/30 21:14:26 - mmengine - INFO - Iter(train) [100300/320000]  base_lr: 7.1287e-05 lr: 7.1287e-06  eta: 1 day, 2:38:35  time: 0.4422  data_time: 0.0101  memory: 5120  grad_norm: 20.9354  loss: 5.0258  decode.loss_cls: 0.0180  decode.loss_mask: 0.2262  decode.loss_dice: 0.1689  decode.d0.loss_cls: 0.8452  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.1828  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.1701  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.2261  decode.d2.loss_dice: 0.1678  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.2240  decode.d3.loss_dice: 0.1675  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.1692  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.2246  decode.d5.loss_dice: 0.1729  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.2273  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.2262  decode.d7.loss_dice: 0.1677  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.1697
09/30 21:14:48 - mmengine - INFO - Iter(train) [100350/320000]  base_lr: 7.1273e-05 lr: 7.1273e-06  eta: 1 day, 2:38:14  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 65.7671  loss: 4.8320  decode.loss_cls: 0.0267  decode.loss_mask: 0.2040  decode.loss_dice: 0.1780  decode.d0.loss_cls: 0.7101  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.1837  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.2027  decode.d1.loss_dice: 0.1782  decode.d2.loss_cls: 0.0232  decode.d2.loss_mask: 0.2048  decode.d2.loss_dice: 0.1759  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2052  decode.d3.loss_dice: 0.1766  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.2061  decode.d4.loss_dice: 0.1800  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.2065  decode.d6.loss_dice: 0.1848  decode.d7.loss_cls: 0.0318  decode.d7.loss_mask: 0.2098  decode.d7.loss_dice: 0.1865  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.2062  decode.d8.loss_dice: 0.1807
09/30 21:15:10 - mmengine - INFO - Iter(train) [100400/320000]  base_lr: 7.1258e-05 lr: 7.1258e-06  eta: 1 day, 2:37:53  time: 0.4413  data_time: 0.0099  memory: 5129  grad_norm: 60.1250  loss: 5.9700  decode.loss_cls: 0.0898  decode.loss_mask: 0.2282  decode.loss_dice: 0.2007  decode.d0.loss_cls: 0.6817  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.1784  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2172  decode.d2.loss_cls: 0.1302  decode.d2.loss_mask: 0.2319  decode.d2.loss_dice: 0.2150  decode.d3.loss_cls: 0.1272  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.1635  decode.d5.loss_mask: 0.2288  decode.d5.loss_dice: 0.1953  decode.d6.loss_cls: 0.1521  decode.d6.loss_mask: 0.2267  decode.d6.loss_dice: 0.2073  decode.d7.loss_cls: 0.1186  decode.d7.loss_mask: 0.2286  decode.d7.loss_dice: 0.1694  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.1702
09/30 21:15:32 - mmengine - INFO - Iter(train) [100450/320000]  base_lr: 7.1244e-05 lr: 7.1244e-06  eta: 1 day, 2:37:31  time: 0.4407  data_time: 0.0099  memory: 5129  grad_norm: 36.8961  loss: 5.2640  decode.loss_cls: 0.0261  decode.loss_mask: 0.2385  decode.loss_dice: 0.1625  decode.d0.loss_cls: 0.7874  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.1594  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.1642  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.2397  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.2386  decode.d3.loss_dice: 0.1931  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.2000  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.2384  decode.d5.loss_dice: 0.1815  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.2400  decode.d6.loss_dice: 0.1865  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.2393  decode.d7.loss_dice: 0.1907  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.2376  decode.d8.loss_dice: 0.1629
09/30 21:15:54 - mmengine - INFO - Iter(train) [100500/320000]  base_lr: 7.1229e-05 lr: 7.1229e-06  eta: 1 day, 2:37:10  time: 0.4403  data_time: 0.0099  memory: 5120  grad_norm: 77.9889  loss: 6.0368  decode.loss_cls: 0.0717  decode.loss_mask: 0.2492  decode.loss_dice: 0.1860  decode.d0.loss_cls: 0.7149  decode.d0.loss_mask: 0.2536  decode.d0.loss_dice: 0.2008  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.1844  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.1884  decode.d3.loss_cls: 0.1464  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.1889  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.1893  decode.d5.loss_cls: 0.0939  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.1884  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.2546  decode.d6.loss_dice: 0.1913  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.2539  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.1931
09/30 21:16:16 - mmengine - INFO - Iter(train) [100550/320000]  base_lr: 7.1214e-05 lr: 7.1214e-06  eta: 1 day, 2:36:49  time: 0.4408  data_time: 0.0100  memory: 5120  grad_norm: 62.8319  loss: 6.9806  decode.loss_cls: 0.1637  decode.loss_mask: 0.2091  decode.loss_dice: 0.2480  decode.d0.loss_cls: 0.9714  decode.d0.loss_mask: 0.2092  decode.d0.loss_dice: 0.2220  decode.d1.loss_cls: 0.1922  decode.d1.loss_mask: 0.2061  decode.d1.loss_dice: 0.2309  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.2408  decode.d3.loss_cls: 0.1461  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.2297  decode.d4.loss_cls: 0.1470  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.1758  decode.d5.loss_mask: 0.2089  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.1654  decode.d6.loss_mask: 0.2060  decode.d6.loss_dice: 0.2370  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 0.2103  decode.d7.loss_dice: 0.2501  decode.d8.loss_cls: 0.1764  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.2466
09/30 21:16:38 - mmengine - INFO - Iter(train) [100600/320000]  base_lr: 7.1200e-05 lr: 7.1200e-06  eta: 1 day, 2:36:28  time: 0.4416  data_time: 0.0100  memory: 5145  grad_norm: 14.9295  loss: 4.4176  decode.loss_cls: 0.0038  decode.loss_mask: 0.1538  decode.loss_dice: 0.2005  decode.d0.loss_cls: 0.7760  decode.d0.loss_mask: 0.1553  decode.d0.loss_dice: 0.2108  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.1556  decode.d1.loss_dice: 0.2104  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.1530  decode.d2.loss_dice: 0.2072  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.1538  decode.d3.loss_dice: 0.2080  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1518  decode.d4.loss_dice: 0.2046  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.1529  decode.d5.loss_dice: 0.2061  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1540  decode.d6.loss_dice: 0.2047  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.1536  decode.d7.loss_dice: 0.2061  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.1544  decode.d8.loss_dice: 0.2095
09/30 21:17:00 - mmengine - INFO - Iter(train) [100650/320000]  base_lr: 7.1185e-05 lr: 7.1185e-06  eta: 1 day, 2:36:06  time: 0.4419  data_time: 0.0102  memory: 5129  grad_norm: 46.6682  loss: 5.7989  decode.loss_cls: 0.1380  decode.loss_mask: 0.2016  decode.loss_dice: 0.1857  decode.d0.loss_cls: 0.9268  decode.d0.loss_mask: 0.1989  decode.d0.loss_dice: 0.2220  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 0.1979  decode.d1.loss_dice: 0.1929  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.1815  decode.d3.loss_cls: 0.1155  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.1961  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.1977  decode.d4.loss_dice: 0.2137  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.0719  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.1892  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.2089  decode.d8.loss_cls: 0.0972  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.1787
09/30 21:17:23 - mmengine - INFO - Iter(train) [100700/320000]  base_lr: 7.1171e-05 lr: 7.1171e-06  eta: 1 day, 2:35:45  time: 0.4417  data_time: 0.0098  memory: 5129  grad_norm: 61.1639  loss: 6.3394  decode.loss_cls: 0.1355  decode.loss_mask: 0.2042  decode.loss_dice: 0.2518  decode.d0.loss_cls: 0.7713  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.2606  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.2045  decode.d1.loss_dice: 0.2784  decode.d2.loss_cls: 0.1118  decode.d2.loss_mask: 0.2059  decode.d2.loss_dice: 0.2570  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1911  decode.d4.loss_cls: 0.1470  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.2305  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.2047  decode.d5.loss_dice: 0.2757  decode.d6.loss_cls: 0.0919  decode.d6.loss_mask: 0.2056  decode.d6.loss_dice: 0.2768  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.2052  decode.d7.loss_dice: 0.2781  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.2033  decode.d8.loss_dice: 0.2837
09/30 21:17:45 - mmengine - INFO - Iter(train) [100750/320000]  base_lr: 7.1156e-05 lr: 7.1156e-06  eta: 1 day, 2:35:24  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 48.8404  loss: 5.1570  decode.loss_cls: 0.0644  decode.loss_mask: 0.1980  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.8591  decode.d0.loss_mask: 0.1967  decode.d0.loss_dice: 0.1583  decode.d1.loss_cls: 0.0969  decode.d1.loss_mask: 0.1969  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.1581  decode.d3.loss_cls: 0.0798  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.1588  decode.d4.loss_cls: 0.0726  decode.d4.loss_mask: 0.1950  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.1979  decode.d5.loss_dice: 0.1572  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.1942  decode.d6.loss_dice: 0.1536  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 0.1982  decode.d7.loss_dice: 0.1577  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.1980  decode.d8.loss_dice: 0.1595
09/30 21:18:07 - mmengine - INFO - Iter(train) [100800/320000]  base_lr: 7.1141e-05 lr: 7.1141e-06  eta: 1 day, 2:35:02  time: 0.4411  data_time: 0.0099  memory: 5129  grad_norm: 702.5353  loss: 5.3117  decode.loss_cls: 0.0136  decode.loss_mask: 0.2506  decode.loss_dice: 0.1843  decode.d0.loss_cls: 0.8058  decode.d0.loss_mask: 0.2466  decode.d0.loss_dice: 0.1926  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.1869  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.1933  decode.d3.loss_cls: 0.0156  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.1850  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.2493  decode.d4.loss_dice: 0.1835  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.1912  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.1840  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.1800
09/30 21:18:29 - mmengine - INFO - Iter(train) [100850/320000]  base_lr: 7.1127e-05 lr: 7.1127e-06  eta: 1 day, 2:34:41  time: 0.4418  data_time: 0.0100  memory: 5129  grad_norm: 51.8936  loss: 5.1270  decode.loss_cls: 0.0504  decode.loss_mask: 0.2111  decode.loss_dice: 0.1806  decode.d0.loss_cls: 0.7795  decode.d0.loss_mask: 0.2098  decode.d0.loss_dice: 0.1782  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.2120  decode.d2.loss_dice: 0.1785  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.1832  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.2122  decode.d5.loss_dice: 0.1764  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.2096  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1789  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.2089  decode.d8.loss_dice: 0.1816
09/30 21:18:51 - mmengine - INFO - Iter(train) [100900/320000]  base_lr: 7.1112e-05 lr: 7.1112e-06  eta: 1 day, 2:34:20  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 47.1308  loss: 4.6668  decode.loss_cls: 0.0173  decode.loss_mask: 0.1879  decode.loss_dice: 0.1886  decode.d0.loss_cls: 0.8083  decode.d0.loss_mask: 0.1873  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.1916  decode.d1.loss_dice: 0.1901  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.1931  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.1878  decode.d3.loss_dice: 0.1891  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.1880  decode.d4.loss_dice: 0.1857  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.1872  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.1847  decode.d6.loss_dice: 0.1905  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.1844  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.1869  decode.d8.loss_dice: 0.1903
09/30 21:19:13 - mmengine - INFO - Iter(train) [100950/320000]  base_lr: 7.1098e-05 lr: 7.1098e-06  eta: 1 day, 2:33:59  time: 0.4403  data_time: 0.0100  memory: 5129  grad_norm: 44.6802  loss: 4.9925  decode.loss_cls: 0.0356  decode.loss_mask: 0.2095  decode.loss_dice: 0.1647  decode.d0.loss_cls: 0.7604  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.1633  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.2134  decode.d1.loss_dice: 0.1667  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.2115  decode.d2.loss_dice: 0.1647  decode.d3.loss_cls: 0.0665  decode.d3.loss_mask: 0.2117  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.1633  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.1634  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.2119  decode.d7.loss_dice: 0.1658  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.1630
09/30 21:19:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:19:35 - mmengine - INFO - Iter(train) [101000/320000]  base_lr: 7.1083e-05 lr: 7.1083e-06  eta: 1 day, 2:33:37  time: 0.4402  data_time: 0.0099  memory: 5145  grad_norm: 151.7784  loss: 9.2316  decode.loss_cls: 0.1950  decode.loss_mask: 0.3087  decode.loss_dice: 0.3463  decode.d0.loss_cls: 0.9265  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3286  decode.d1.loss_cls: 0.2433  decode.d1.loss_mask: 0.3095  decode.d1.loss_dice: 0.3596  decode.d2.loss_cls: 0.1895  decode.d2.loss_mask: 0.3064  decode.d2.loss_dice: 0.3409  decode.d3.loss_cls: 0.1652  decode.d3.loss_mask: 0.3052  decode.d3.loss_dice: 0.3374  decode.d4.loss_cls: 0.1729  decode.d4.loss_mask: 0.3075  decode.d4.loss_dice: 0.3293  decode.d5.loss_cls: 0.1984  decode.d5.loss_mask: 0.3087  decode.d5.loss_dice: 0.3420  decode.d6.loss_cls: 0.2045  decode.d6.loss_mask: 0.3066  decode.d6.loss_dice: 0.3568  decode.d7.loss_cls: 0.1889  decode.d7.loss_mask: 0.3005  decode.d7.loss_dice: 0.3440  decode.d8.loss_cls: 0.2358  decode.d8.loss_mask: 0.3079  decode.d8.loss_dice: 0.3607
09/30 21:19:57 - mmengine - INFO - Iter(train) [101050/320000]  base_lr: 7.1068e-05 lr: 7.1068e-06  eta: 1 day, 2:33:16  time: 0.4414  data_time: 0.0099  memory: 5129  grad_norm: 22.4319  loss: 4.5477  decode.loss_cls: 0.0084  decode.loss_mask: 0.1950  decode.loss_dice: 0.1721  decode.d0.loss_cls: 0.7681  decode.d0.loss_mask: 0.1916  decode.d0.loss_dice: 0.1762  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.1763  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.1960  decode.d2.loss_dice: 0.1697  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.1729  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.1952  decode.d4.loss_dice: 0.1811  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.1944  decode.d5.loss_dice: 0.1702  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.1957  decode.d6.loss_dice: 0.1789  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.1937  decode.d7.loss_dice: 0.1719  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.1936  decode.d8.loss_dice: 0.1716
09/30 21:20:19 - mmengine - INFO - Iter(train) [101100/320000]  base_lr: 7.1054e-05 lr: 7.1054e-06  eta: 1 day, 2:32:55  time: 0.4414  data_time: 0.0100  memory: 5129  grad_norm: 281.4454  loss: 7.2332  decode.loss_cls: 0.1702  decode.loss_mask: 0.2537  decode.loss_dice: 0.2353  decode.d0.loss_cls: 0.7773  decode.d0.loss_mask: 0.2548  decode.d0.loss_dice: 0.2731  decode.d1.loss_cls: 0.1799  decode.d1.loss_mask: 0.2507  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.2367  decode.d2.loss_mask: 0.2512  decode.d2.loss_dice: 0.2352  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 0.2486  decode.d3.loss_dice: 0.2348  decode.d4.loss_cls: 0.1794  decode.d4.loss_mask: 0.2480  decode.d4.loss_dice: 0.2511  decode.d5.loss_cls: 0.1465  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2411  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2510  decode.d7.loss_cls: 0.1507  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.1600  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.2276
09/30 21:20:41 - mmengine - INFO - Iter(train) [101150/320000]  base_lr: 7.1039e-05 lr: 7.1039e-06  eta: 1 day, 2:32:33  time: 0.4425  data_time: 0.0099  memory: 5145  grad_norm: 93.9850  loss: 5.6554  decode.loss_cls: 0.1233  decode.loss_mask: 0.1887  decode.loss_dice: 0.1695  decode.d0.loss_cls: 0.8304  decode.d0.loss_mask: 0.1922  decode.d0.loss_dice: 0.1859  decode.d1.loss_cls: 0.1247  decode.d1.loss_mask: 0.1909  decode.d1.loss_dice: 0.1748  decode.d2.loss_cls: 0.1545  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.2016  decode.d3.loss_cls: 0.0839  decode.d3.loss_mask: 0.1914  decode.d3.loss_dice: 0.1838  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.1768  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 0.1898  decode.d5.loss_dice: 0.1783  decode.d6.loss_cls: 0.1383  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.1772  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.1913  decode.d7.loss_dice: 0.1833  decode.d8.loss_cls: 0.1452  decode.d8.loss_mask: 0.1878  decode.d8.loss_dice: 0.1861
09/30 21:21:03 - mmengine - INFO - Iter(train) [101200/320000]  base_lr: 7.1025e-05 lr: 7.1025e-06  eta: 1 day, 2:32:12  time: 0.4413  data_time: 0.0099  memory: 5145  grad_norm: 26.3219  loss: 4.1447  decode.loss_cls: 0.0033  decode.loss_mask: 0.1801  decode.loss_dice: 0.1484  decode.d0.loss_cls: 0.8087  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.1495  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.1414  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.1844  decode.d2.loss_dice: 0.1472  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.1804  decode.d3.loss_dice: 0.1440  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.1835  decode.d4.loss_dice: 0.1433  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.1813  decode.d5.loss_dice: 0.1469  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.1825  decode.d6.loss_dice: 0.1468  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1835  decode.d7.loss_dice: 0.1465  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1821  decode.d8.loss_dice: 0.1522
09/30 21:21:25 - mmengine - INFO - Iter(train) [101250/320000]  base_lr: 7.1010e-05 lr: 7.1010e-06  eta: 1 day, 2:31:51  time: 0.4430  data_time: 0.0101  memory: 5129  grad_norm: 22.4035  loss: 4.1585  decode.loss_cls: 0.0006  decode.loss_mask: 0.2066  decode.loss_dice: 0.1377  decode.d0.loss_cls: 0.7113  decode.d0.loss_mask: 0.2090  decode.d0.loss_dice: 0.1398  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.1380  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.1361  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.1363  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2059  decode.d4.loss_dice: 0.1368  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2055  decode.d5.loss_dice: 0.1392  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.1381  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.1390  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.1365
09/30 21:21:48 - mmengine - INFO - Iter(train) [101300/320000]  base_lr: 7.0995e-05 lr: 7.0995e-06  eta: 1 day, 2:31:29  time: 0.4405  data_time: 0.0100  memory: 5120  grad_norm: 44.1270  loss: 5.5723  decode.loss_cls: 0.0589  decode.loss_mask: 0.2499  decode.loss_dice: 0.1820  decode.d0.loss_cls: 0.7654  decode.d0.loss_mask: 0.2544  decode.d0.loss_dice: 0.1646  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.2438  decode.d1.loss_dice: 0.1752  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.2492  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.2479  decode.d5.loss_dice: 0.1833  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.2471  decode.d6.loss_dice: 0.1811  decode.d7.loss_cls: 0.0629  decode.d7.loss_mask: 0.2460  decode.d7.loss_dice: 0.1819  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.2489  decode.d8.loss_dice: 0.1788
09/30 21:22:10 - mmengine - INFO - Iter(train) [101350/320000]  base_lr: 7.0981e-05 lr: 7.0981e-06  eta: 1 day, 2:31:08  time: 0.4409  data_time: 0.0099  memory: 5145  grad_norm: 51.5418  loss: 6.4160  decode.loss_cls: 0.1270  decode.loss_mask: 0.2150  decode.loss_dice: 0.2240  decode.d0.loss_cls: 0.9221  decode.d0.loss_mask: 0.2124  decode.d0.loss_dice: 0.2217  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 0.2142  decode.d1.loss_dice: 0.2397  decode.d2.loss_cls: 0.1528  decode.d2.loss_mask: 0.2127  decode.d2.loss_dice: 0.1924  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 0.2137  decode.d3.loss_dice: 0.1948  decode.d4.loss_cls: 0.1300  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.2185  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.2133  decode.d5.loss_dice: 0.2042  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.2153  decode.d6.loss_dice: 0.2403  decode.d7.loss_cls: 0.1271  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.2280  decode.d8.loss_cls: 0.1161  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.2037
09/30 21:22:32 - mmengine - INFO - Iter(train) [101400/320000]  base_lr: 7.0966e-05 lr: 7.0966e-06  eta: 1 day, 2:30:47  time: 0.4406  data_time: 0.0099  memory: 5129  grad_norm: 160.9565  loss: 6.4506  decode.loss_cls: 0.1282  decode.loss_mask: 0.2460  decode.loss_dice: 0.2138  decode.d0.loss_cls: 0.8649  decode.d0.loss_mask: 0.2436  decode.d0.loss_dice: 0.2209  decode.d1.loss_cls: 0.1294  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.1979  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.2409  decode.d3.loss_dice: 0.2163  decode.d4.loss_cls: 0.1091  decode.d4.loss_mask: 0.2449  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.1070  decode.d5.loss_mask: 0.2519  decode.d5.loss_dice: 0.2131  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.1370  decode.d7.loss_mask: 0.2436  decode.d7.loss_dice: 0.2071  decode.d8.loss_cls: 0.1384  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.1916
09/30 21:22:54 - mmengine - INFO - Iter(train) [101450/320000]  base_lr: 7.0952e-05 lr: 7.0952e-06  eta: 1 day, 2:30:25  time: 0.4419  data_time: 0.0100  memory: 5129  grad_norm: 227.1578  loss: 7.5363  decode.loss_cls: 0.1323  decode.loss_mask: 0.2690  decode.loss_dice: 0.2508  decode.d0.loss_cls: 0.9719  decode.d0.loss_mask: 0.2745  decode.d0.loss_dice: 0.2398  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.2702  decode.d1.loss_dice: 0.2506  decode.d2.loss_cls: 0.1256  decode.d2.loss_mask: 0.2776  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.1518  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.2759  decode.d4.loss_cls: 0.1369  decode.d4.loss_mask: 0.2719  decode.d4.loss_dice: 0.2611  decode.d5.loss_cls: 0.1368  decode.d5.loss_mask: 0.2689  decode.d5.loss_dice: 0.2692  decode.d6.loss_cls: 0.1247  decode.d6.loss_mask: 0.2840  decode.d6.loss_dice: 0.2856  decode.d7.loss_cls: 0.1662  decode.d7.loss_mask: 0.2875  decode.d7.loss_dice: 0.2834  decode.d8.loss_cls: 0.1357  decode.d8.loss_mask: 0.2685  decode.d8.loss_dice: 0.2507
09/30 21:23:16 - mmengine - INFO - Iter(train) [101500/320000]  base_lr: 7.0937e-05 lr: 7.0937e-06  eta: 1 day, 2:30:04  time: 0.4410  data_time: 0.0099  memory: 5129  grad_norm: 57.7126  loss: 5.2989  decode.loss_cls: 0.0382  decode.loss_mask: 0.2153  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.8612  decode.d0.loss_mask: 0.2137  decode.d0.loss_dice: 0.1668  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.1797  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.1808  decode.d3.loss_cls: 0.0903  decode.d3.loss_mask: 0.2183  decode.d3.loss_dice: 0.1843  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.2089  decode.d4.loss_dice: 0.1833  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.1818  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.1781  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.1791  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.2101  decode.d8.loss_dice: 0.1809
09/30 21:23:38 - mmengine - INFO - Iter(train) [101550/320000]  base_lr: 7.0922e-05 lr: 7.0922e-06  eta: 1 day, 2:29:43  time: 0.4408  data_time: 0.0099  memory: 5129  grad_norm: 71.9057  loss: 5.4711  decode.loss_cls: 0.0921  decode.loss_mask: 0.1849  decode.loss_dice: 0.2089  decode.d0.loss_cls: 0.8684  decode.d0.loss_mask: 0.1885  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.1880  decode.d1.loss_dice: 0.2096  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.1819  decode.d2.loss_dice: 0.1924  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.1835  decode.d3.loss_dice: 0.1911  decode.d4.loss_cls: 0.0847  decode.d4.loss_mask: 0.1827  decode.d4.loss_dice: 0.1790  decode.d5.loss_cls: 0.0991  decode.d5.loss_mask: 0.1835  decode.d5.loss_dice: 0.2007  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.1818  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.1171  decode.d7.loss_mask: 0.1827  decode.d7.loss_dice: 0.1818  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.1836  decode.d8.loss_dice: 0.1909
09/30 21:24:00 - mmengine - INFO - Iter(train) [101600/320000]  base_lr: 7.0908e-05 lr: 7.0908e-06  eta: 1 day, 2:29:21  time: 0.4415  data_time: 0.0099  memory: 5129  grad_norm: 195.1432  loss: 6.5426  decode.loss_cls: 0.0328  decode.loss_mask: 0.2876  decode.loss_dice: 0.2352  decode.d0.loss_cls: 0.8297  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.2458  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.2982  decode.d1.loss_dice: 0.2623  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.2935  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.2902  decode.d3.loss_dice: 0.2504  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.2922  decode.d4.loss_dice: 0.2346  decode.d5.loss_cls: 0.0373  decode.d5.loss_mask: 0.2891  decode.d5.loss_dice: 0.2522  decode.d6.loss_cls: 0.0456  decode.d6.loss_mask: 0.2905  decode.d6.loss_dice: 0.2365  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.2906  decode.d7.loss_dice: 0.2438  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.2909  decode.d8.loss_dice: 0.2333
09/30 21:24:22 - mmengine - INFO - Iter(train) [101650/320000]  base_lr: 7.0893e-05 lr: 7.0893e-06  eta: 1 day, 2:29:00  time: 0.4398  data_time: 0.0097  memory: 5129  grad_norm: 59.7461  loss: 5.3322  decode.loss_cls: 0.0171  decode.loss_mask: 0.2471  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.8468  decode.d0.loss_mask: 0.2478  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.1891  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.1880  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.2429  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.1881  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2483  decode.d5.loss_dice: 0.1877  decode.d6.loss_cls: 0.0096  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.1906  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.1935
09/30 21:24:44 - mmengine - INFO - Iter(train) [101700/320000]  base_lr: 7.0879e-05 lr: 7.0879e-06  eta: 1 day, 2:28:39  time: 0.4407  data_time: 0.0099  memory: 5129  grad_norm: 20.1520  loss: 4.0396  decode.loss_cls: 0.0142  decode.loss_mask: 0.1705  decode.loss_dice: 0.1349  decode.d0.loss_cls: 0.8312  decode.d0.loss_mask: 0.1709  decode.d0.loss_dice: 0.1398  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.1699  decode.d1.loss_dice: 0.1381  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.1720  decode.d2.loss_dice: 0.1365  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.1712  decode.d3.loss_dice: 0.1371  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.1700  decode.d4.loss_dice: 0.1344  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.1701  decode.d5.loss_dice: 0.1340  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.1711  decode.d6.loss_dice: 0.1367  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.1725  decode.d7.loss_dice: 0.1381  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.1703  decode.d8.loss_dice: 0.1360
09/30 21:25:06 - mmengine - INFO - Iter(train) [101750/320000]  base_lr: 7.0864e-05 lr: 7.0864e-06  eta: 1 day, 2:28:17  time: 0.4399  data_time: 0.0100  memory: 5129  grad_norm: 74.1217  loss: 6.0083  decode.loss_cls: 0.1337  decode.loss_mask: 0.2192  decode.loss_dice: 0.1965  decode.d0.loss_cls: 0.6930  decode.d0.loss_mask: 0.2218  decode.d0.loss_dice: 0.1931  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.2205  decode.d1.loss_dice: 0.1977  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.1986  decode.d3.loss_cls: 0.1204  decode.d3.loss_mask: 0.2195  decode.d3.loss_dice: 0.2018  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.1885  decode.d5.loss_cls: 0.1336  decode.d5.loss_mask: 0.2195  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.1115  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.2037  decode.d7.loss_cls: 0.1590  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.1905  decode.d8.loss_cls: 0.2057  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.2133
09/30 21:25:28 - mmengine - INFO - Iter(train) [101800/320000]  base_lr: 7.0849e-05 lr: 7.0849e-06  eta: 1 day, 2:27:56  time: 0.4403  data_time: 0.0098  memory: 5145  grad_norm: 42.3031  loss: 4.9153  decode.loss_cls: 0.0485  decode.loss_mask: 0.1705  decode.loss_dice: 0.1839  decode.d0.loss_cls: 0.9340  decode.d0.loss_mask: 0.1729  decode.d0.loss_dice: 0.1775  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.1730  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.1080  decode.d2.loss_mask: 0.1698  decode.d2.loss_dice: 0.1803  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 0.1678  decode.d3.loss_dice: 0.1631  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.1733  decode.d4.loss_dice: 0.1643  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.1713  decode.d5.loss_dice: 0.1670  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.1701  decode.d6.loss_dice: 0.1658  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.1701  decode.d7.loss_dice: 0.1635  decode.d8.loss_cls: 0.0569  decode.d8.loss_mask: 0.1717  decode.d8.loss_dice: 0.1724
09/30 21:25:50 - mmengine - INFO - Iter(train) [101850/320000]  base_lr: 7.0835e-05 lr: 7.0835e-06  eta: 1 day, 2:27:34  time: 0.4409  data_time: 0.0099  memory: 5120  grad_norm: 26.8426  loss: 4.8666  decode.loss_cls: 0.0019  decode.loss_mask: 0.2141  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.7765  decode.d0.loss_mask: 0.2222  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.2153  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.1866  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.2160  decode.d3.loss_dice: 0.1997  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.1941  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.1964  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.1893  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.2174  decode.d8.loss_dice: 0.1815
09/30 21:26:12 - mmengine - INFO - Iter(train) [101900/320000]  base_lr: 7.0820e-05 lr: 7.0820e-06  eta: 1 day, 2:27:13  time: 0.4418  data_time: 0.0099  memory: 5129  grad_norm: 125.2346  loss: 6.2910  decode.loss_cls: 0.1623  decode.loss_mask: 0.1692  decode.loss_dice: 0.2263  decode.d0.loss_cls: 0.9462  decode.d0.loss_mask: 0.1734  decode.d0.loss_dice: 0.2189  decode.d1.loss_cls: 0.2069  decode.d1.loss_mask: 0.1680  decode.d1.loss_dice: 0.2163  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.1691  decode.d2.loss_dice: 0.2168  decode.d3.loss_cls: 0.1677  decode.d3.loss_mask: 0.1716  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 0.1716  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 0.1734  decode.d5.loss_dice: 0.2190  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.1710  decode.d6.loss_dice: 0.2280  decode.d7.loss_cls: 0.1459  decode.d7.loss_mask: 0.1705  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.1460  decode.d8.loss_mask: 0.1681  decode.d8.loss_dice: 0.2287
09/30 21:26:34 - mmengine - INFO - Iter(train) [101950/320000]  base_lr: 7.0805e-05 lr: 7.0805e-06  eta: 1 day, 2:26:52  time: 0.4420  data_time: 0.0100  memory: 5129  grad_norm: 30.7723  loss: 4.6481  decode.loss_cls: 0.0038  decode.loss_mask: 0.2175  decode.loss_dice: 0.1668  decode.d0.loss_cls: 0.7580  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.1682  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.2164  decode.d1.loss_dice: 0.1640  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2186  decode.d2.loss_dice: 0.1662  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.2187  decode.d3.loss_dice: 0.1670  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1637  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.1677  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.2140  decode.d6.loss_dice: 0.1652  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.2203  decode.d7.loss_dice: 0.1648  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2187  decode.d8.loss_dice: 0.1684
09/30 21:26:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:26:57 - mmengine - INFO - Iter(train) [102000/320000]  base_lr: 7.0791e-05 lr: 7.0791e-06  eta: 1 day, 2:26:30  time: 0.4416  data_time: 0.0099  memory: 5145  grad_norm: 25.2039  loss: 4.7378  decode.loss_cls: 0.0080  decode.loss_mask: 0.2027  decode.loss_dice: 0.1876  decode.d0.loss_cls: 0.7259  decode.d0.loss_mask: 0.2070  decode.d0.loss_dice: 0.1813  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.2013  decode.d1.loss_dice: 0.1898  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.2051  decode.d2.loss_dice: 0.1885  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.2020  decode.d4.loss_dice: 0.1851  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.1859  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.1864  decode.d7.loss_cls: 0.0099  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.1845  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.1868
09/30 21:27:19 - mmengine - INFO - Iter(train) [102050/320000]  base_lr: 7.0776e-05 lr: 7.0776e-06  eta: 1 day, 2:26:09  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 232.7176  loss: 5.3120  decode.loss_cls: 0.0711  decode.loss_mask: 0.2085  decode.loss_dice: 0.1593  decode.d0.loss_cls: 0.8840  decode.d0.loss_mask: 0.2193  decode.d0.loss_dice: 0.1648  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.2160  decode.d1.loss_dice: 0.1679  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.2122  decode.d2.loss_dice: 0.1639  decode.d3.loss_cls: 0.0747  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.2088  decode.d4.loss_dice: 0.1622  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.2067  decode.d5.loss_dice: 0.1582  decode.d6.loss_cls: 0.1187  decode.d6.loss_mask: 0.2065  decode.d6.loss_dice: 0.1634  decode.d7.loss_cls: 0.0526  decode.d7.loss_mask: 0.2073  decode.d7.loss_dice: 0.1667  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.2050  decode.d8.loss_dice: 0.1623
09/30 21:27:41 - mmengine - INFO - Iter(train) [102100/320000]  base_lr: 7.0762e-05 lr: 7.0762e-06  eta: 1 day, 2:25:48  time: 0.4409  data_time: 0.0100  memory: 5129  grad_norm: 64.6058  loss: 5.1790  decode.loss_cls: 0.0769  decode.loss_mask: 0.1779  decode.loss_dice: 0.1952  decode.d0.loss_cls: 0.7565  decode.d0.loss_mask: 0.1770  decode.d0.loss_dice: 0.1990  decode.d1.loss_cls: 0.1168  decode.d1.loss_mask: 0.1782  decode.d1.loss_dice: 0.1900  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.1883  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.1792  decode.d3.loss_dice: 0.1961  decode.d4.loss_cls: 0.0758  decode.d4.loss_mask: 0.1783  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.1784  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.1811  decode.d6.loss_dice: 0.1998  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.1771  decode.d8.loss_dice: 0.1913
09/30 21:28:03 - mmengine - INFO - Iter(train) [102150/320000]  base_lr: 7.0747e-05 lr: 7.0747e-06  eta: 1 day, 2:25:27  time: 0.4414  data_time: 0.0100  memory: 5145  grad_norm: 43.6434  loss: 5.6610  decode.loss_cls: 0.0203  decode.loss_mask: 0.2635  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.7607  decode.d0.loss_mask: 0.2639  decode.d0.loss_dice: 0.2069  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.2623  decode.d2.loss_dice: 0.2136  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.2623  decode.d3.loss_dice: 0.2144  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.2112  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.2621  decode.d5.loss_dice: 0.2047  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.2613  decode.d6.loss_dice: 0.2102  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.2631  decode.d7.loss_dice: 0.2094  decode.d8.loss_cls: 0.0188  decode.d8.loss_mask: 0.2620  decode.d8.loss_dice: 0.2103
09/30 21:28:25 - mmengine - INFO - Iter(train) [102200/320000]  base_lr: 7.0732e-05 lr: 7.0732e-06  eta: 1 day, 2:25:05  time: 0.4412  data_time: 0.0099  memory: 5145  grad_norm: 21.9955  loss: 4.5623  decode.loss_cls: 0.0538  decode.loss_mask: 0.1657  decode.loss_dice: 0.1842  decode.d0.loss_cls: 0.8174  decode.d0.loss_mask: 0.1646  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.1656  decode.d1.loss_dice: 0.1735  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.1653  decode.d2.loss_dice: 0.1795  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.1661  decode.d3.loss_dice: 0.1983  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.1646  decode.d4.loss_dice: 0.1954  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.1678  decode.d5.loss_dice: 0.1728  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.1666  decode.d6.loss_dice: 0.1833  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.1671  decode.d7.loss_dice: 0.1540  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.1689  decode.d8.loss_dice: 0.1809
09/30 21:28:47 - mmengine - INFO - Iter(train) [102250/320000]  base_lr: 7.0718e-05 lr: 7.0718e-06  eta: 1 day, 2:24:44  time: 0.4408  data_time: 0.0099  memory: 5120  grad_norm: 33.8326  loss: 5.0484  decode.loss_cls: 0.0131  decode.loss_mask: 0.1930  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.9257  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.1965  decode.d1.loss_cls: 0.0162  decode.d1.loss_mask: 0.1936  decode.d1.loss_dice: 0.1870  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.1936  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.1928  decode.d3.loss_dice: 0.1995  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.1943  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.1945  decode.d5.loss_dice: 0.1920  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.1953  decode.d6.loss_dice: 0.2020  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2126  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.1940  decode.d8.loss_dice: 0.1883
09/30 21:29:09 - mmengine - INFO - Iter(train) [102300/320000]  base_lr: 7.0703e-05 lr: 7.0703e-06  eta: 1 day, 2:24:23  time: 0.4412  data_time: 0.0100  memory: 5129  grad_norm: 82.5464  loss: 4.5587  decode.loss_cls: 0.0087  decode.loss_mask: 0.1926  decode.loss_dice: 0.1689  decode.d0.loss_cls: 0.7400  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.1957  decode.d1.loss_dice: 0.1743  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.1947  decode.d2.loss_dice: 0.1683  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.1946  decode.d3.loss_dice: 0.1672  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.1956  decode.d4.loss_dice: 0.1692  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.1732  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.1694  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.1935  decode.d7.loss_dice: 0.1676  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.1729
09/30 21:29:31 - mmengine - INFO - Iter(train) [102350/320000]  base_lr: 7.0689e-05 lr: 7.0689e-06  eta: 1 day, 2:24:01  time: 0.4406  data_time: 0.0100  memory: 5145  grad_norm: 37.2441  loss: 4.6440  decode.loss_cls: 0.0059  decode.loss_mask: 0.1995  decode.loss_dice: 0.1725  decode.d0.loss_cls: 0.7842  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.1765  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.1802  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.2026  decode.d2.loss_dice: 0.1754  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.2035  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.2004  decode.d4.loss_dice: 0.1706  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2013  decode.d5.loss_dice: 0.1734  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.1983  decode.d6.loss_dice: 0.1618  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.2006  decode.d7.loss_dice: 0.1753  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2009  decode.d8.loss_dice: 0.1713
09/30 21:29:53 - mmengine - INFO - Iter(train) [102400/320000]  base_lr: 7.0674e-05 lr: 7.0674e-06  eta: 1 day, 2:23:40  time: 0.4405  data_time: 0.0101  memory: 5129  grad_norm: 72.1840  loss: 6.6801  decode.loss_cls: 0.1080  decode.loss_mask: 0.2958  decode.loss_dice: 0.1931  decode.d0.loss_cls: 0.9077  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.1940  decode.d1.loss_cls: 0.1426  decode.d1.loss_mask: 0.2924  decode.d1.loss_dice: 0.1907  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.2953  decode.d2.loss_dice: 0.1959  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.2005  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2968  decode.d4.loss_dice: 0.1960  decode.d5.loss_cls: 0.0920  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.1947  decode.d6.loss_cls: 0.0991  decode.d6.loss_mask: 0.2974  decode.d6.loss_dice: 0.1964  decode.d7.loss_cls: 0.1128  decode.d7.loss_mask: 0.3062  decode.d7.loss_dice: 0.1954  decode.d8.loss_cls: 0.1171  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.1924
09/30 21:30:15 - mmengine - INFO - Iter(train) [102450/320000]  base_lr: 7.0659e-05 lr: 7.0659e-06  eta: 1 day, 2:23:19  time: 0.4417  data_time: 0.0100  memory: 5145  grad_norm: 62.4224  loss: 9.3581  decode.loss_cls: 0.2831  decode.loss_mask: 0.2429  decode.loss_dice: 0.3227  decode.d0.loss_cls: 1.0412  decode.d0.loss_mask: 0.2510  decode.d0.loss_dice: 0.3083  decode.d1.loss_cls: 0.3274  decode.d1.loss_mask: 0.2497  decode.d1.loss_dice: 0.2806  decode.d2.loss_cls: 0.3497  decode.d2.loss_mask: 0.2464  decode.d2.loss_dice: 0.2749  decode.d3.loss_cls: 0.2778  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2805  decode.d4.loss_cls: 0.2941  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.2874  decode.d5.loss_cls: 0.3267  decode.d5.loss_mask: 0.2514  decode.d5.loss_dice: 0.3062  decode.d6.loss_cls: 0.3188  decode.d6.loss_mask: 0.2439  decode.d6.loss_dice: 0.3468  decode.d7.loss_cls: 0.3318  decode.d7.loss_mask: 0.2476  decode.d7.loss_dice: 0.2994  decode.d8.loss_cls: 0.3185  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.3068
09/30 21:30:38 - mmengine - INFO - Iter(train) [102500/320000]  base_lr: 7.0645e-05 lr: 7.0645e-06  eta: 1 day, 2:22:57  time: 0.4415  data_time: 0.0100  memory: 5129  grad_norm: 85.7782  loss: 7.2364  decode.loss_cls: 0.1332  decode.loss_mask: 0.2892  decode.loss_dice: 0.2583  decode.d0.loss_cls: 0.8496  decode.d0.loss_mask: 0.2632  decode.d0.loss_dice: 0.2405  decode.d1.loss_cls: 0.1211  decode.d1.loss_mask: 0.2537  decode.d1.loss_dice: 0.2535  decode.d2.loss_cls: 0.1468  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2558  decode.d3.loss_cls: 0.1729  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.1410  decode.d4.loss_mask: 0.2504  decode.d4.loss_dice: 0.2328  decode.d5.loss_cls: 0.1487  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.2332  decode.d6.loss_cls: 0.1502  decode.d6.loss_mask: 0.2497  decode.d6.loss_dice: 0.2384  decode.d7.loss_cls: 0.1647  decode.d7.loss_mask: 0.2557  decode.d7.loss_dice: 0.2500  decode.d8.loss_cls: 0.1793  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2524
09/30 21:31:00 - mmengine - INFO - Iter(train) [102550/320000]  base_lr: 7.0630e-05 lr: 7.0630e-06  eta: 1 day, 2:22:36  time: 0.4414  data_time: 0.0101  memory: 5120  grad_norm: 139.6615  loss: 5.1531  decode.loss_cls: 0.1142  decode.loss_mask: 0.2020  decode.loss_dice: 0.1623  decode.d0.loss_cls: 0.8750  decode.d0.loss_mask: 0.2097  decode.d0.loss_dice: 0.1800  decode.d1.loss_cls: 0.0890  decode.d1.loss_mask: 0.2009  decode.d1.loss_dice: 0.1635  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.2018  decode.d2.loss_dice: 0.1663  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.1926  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.2025  decode.d5.loss_dice: 0.1889  decode.d6.loss_cls: 0.0201  decode.d6.loss_mask: 0.2021  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.2016  decode.d7.loss_dice: 0.1875  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.2015  decode.d8.loss_dice: 0.1791
09/30 21:31:22 - mmengine - INFO - Iter(train) [102600/320000]  base_lr: 7.0615e-05 lr: 7.0615e-06  eta: 1 day, 2:22:15  time: 0.4406  data_time: 0.0100  memory: 5129  grad_norm: 38.3322  loss: 4.9952  decode.loss_cls: 0.0314  decode.loss_mask: 0.1748  decode.loss_dice: 0.2008  decode.d0.loss_cls: 0.9768  decode.d0.loss_mask: 0.1767  decode.d0.loss_dice: 0.2048  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.1788  decode.d1.loss_dice: 0.1940  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 0.1779  decode.d2.loss_dice: 0.2124  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.1764  decode.d3.loss_dice: 0.1975  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.1780  decode.d4.loss_dice: 0.1929  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.1764  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.1769  decode.d6.loss_dice: 0.1984  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.1748  decode.d7.loss_dice: 0.2036  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.1741  decode.d8.loss_dice: 0.2006
09/30 21:31:44 - mmengine - INFO - Iter(train) [102650/320000]  base_lr: 7.0601e-05 lr: 7.0601e-06  eta: 1 day, 2:21:53  time: 0.4414  data_time: 0.0099  memory: 5129  grad_norm: 56.8691  loss: 5.9484  decode.loss_cls: 0.1272  decode.loss_mask: 0.1920  decode.loss_dice: 0.2403  decode.d0.loss_cls: 0.9260  decode.d0.loss_mask: 0.1939  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.1522  decode.d1.loss_mask: 0.1931  decode.d1.loss_dice: 0.2132  decode.d2.loss_cls: 0.1282  decode.d2.loss_mask: 0.1908  decode.d2.loss_dice: 0.2055  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.1915  decode.d3.loss_dice: 0.2214  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.1899  decode.d4.loss_dice: 0.2158  decode.d5.loss_cls: 0.1081  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.2067  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.1904  decode.d6.loss_dice: 0.2156  decode.d7.loss_cls: 0.1336  decode.d7.loss_mask: 0.1905  decode.d7.loss_dice: 0.2125  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.2098
09/30 21:32:06 - mmengine - INFO - Iter(train) [102700/320000]  base_lr: 7.0586e-05 lr: 7.0586e-06  eta: 1 day, 2:21:32  time: 0.4422  data_time: 0.0100  memory: 5129  grad_norm: 40.3140  loss: 4.9179  decode.loss_cls: 0.0545  decode.loss_mask: 0.2054  decode.loss_dice: 0.1702  decode.d0.loss_cls: 0.7469  decode.d0.loss_mask: 0.2093  decode.d0.loss_dice: 0.1694  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2090  decode.d1.loss_dice: 0.1622  decode.d2.loss_cls: 0.0288  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.1746  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.2080  decode.d3.loss_dice: 0.1654  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.2063  decode.d4.loss_dice: 0.1691  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.2063  decode.d5.loss_dice: 0.1679  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.2068  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.1646  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.1755
09/30 21:32:28 - mmengine - INFO - Iter(train) [102750/320000]  base_lr: 7.0572e-05 lr: 7.0572e-06  eta: 1 day, 2:21:11  time: 0.4423  data_time: 0.0100  memory: 5145  grad_norm: 24.5388  loss: 4.5246  decode.loss_cls: 0.0162  decode.loss_mask: 0.1941  decode.loss_dice: 0.1490  decode.d0.loss_cls: 0.9054  decode.d0.loss_mask: 0.1959  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.1492  decode.d2.loss_cls: 0.0295  decode.d2.loss_mask: 0.1950  decode.d2.loss_dice: 0.1544  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.1517  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.1937  decode.d4.loss_dice: 0.1499  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.1935  decode.d5.loss_dice: 0.1508  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.1939  decode.d6.loss_dice: 0.1501  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.1507  decode.d8.loss_cls: 0.0177  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.1469
09/30 21:32:50 - mmengine - INFO - Iter(train) [102800/320000]  base_lr: 7.0557e-05 lr: 7.0557e-06  eta: 1 day, 2:20:50  time: 0.4411  data_time: 0.0099  memory: 5119  grad_norm: 20.1070  loss: 4.4492  decode.loss_cls: 0.0012  decode.loss_mask: 0.2071  decode.loss_dice: 0.1645  decode.d0.loss_cls: 0.7622  decode.d0.loss_mask: 0.2072  decode.d0.loss_dice: 0.1550  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.1593  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2078  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.2085  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.1593  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2079  decode.d5.loss_dice: 0.1621  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2066  decode.d6.loss_dice: 0.1603  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2055  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2074  decode.d8.loss_dice: 0.1616
09/30 21:33:12 - mmengine - INFO - Iter(train) [102850/320000]  base_lr: 7.0542e-05 lr: 7.0542e-06  eta: 1 day, 2:20:28  time: 0.4415  data_time: 0.0101  memory: 5129  grad_norm: 30.9144  loss: 5.4044  decode.loss_cls: 0.0889  decode.loss_mask: 0.2052  decode.loss_dice: 0.1617  decode.d0.loss_cls: 0.8106  decode.d0.loss_mask: 0.2092  decode.d0.loss_dice: 0.1836  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.1701  decode.d2.loss_cls: 0.0797  decode.d2.loss_mask: 0.2064  decode.d2.loss_dice: 0.1645  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2099  decode.d3.loss_dice: 0.1846  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.1704  decode.d5.loss_cls: 0.1078  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.1783  decode.d6.loss_cls: 0.0959  decode.d6.loss_mask: 0.2048  decode.d6.loss_dice: 0.1709  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.1679  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1732
09/30 21:33:34 - mmengine - INFO - Iter(train) [102900/320000]  base_lr: 7.0528e-05 lr: 7.0528e-06  eta: 1 day, 2:20:07  time: 0.4429  data_time: 0.0101  memory: 5120  grad_norm: 33.1990  loss: 5.0626  decode.loss_cls: 0.0086  decode.loss_mask: 0.2356  decode.loss_dice: 0.1729  decode.d0.loss_cls: 0.7705  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.1924  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.1984  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.2334  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.1982  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.2346  decode.d6.loss_dice: 0.1814  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.1800  decode.d8.loss_cls: 0.0211  decode.d8.loss_mask: 0.2351  decode.d8.loss_dice: 0.1906
09/30 21:33:56 - mmengine - INFO - Iter(train) [102950/320000]  base_lr: 7.0513e-05 lr: 7.0513e-06  eta: 1 day, 2:19:46  time: 0.4410  data_time: 0.0099  memory: 5129  grad_norm: 46.1857  loss: 4.6060  decode.loss_cls: 0.0253  decode.loss_mask: 0.1678  decode.loss_dice: 0.1612  decode.d0.loss_cls: 0.9407  decode.d0.loss_mask: 0.1708  decode.d0.loss_dice: 0.1504  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 0.1707  decode.d1.loss_dice: 0.1709  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.1700  decode.d2.loss_dice: 0.1459  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.1701  decode.d3.loss_dice: 0.1679  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.1685  decode.d4.loss_dice: 0.1728  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.1677  decode.d5.loss_dice: 0.1535  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.1695  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.1697  decode.d7.loss_dice: 0.1594  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.1673  decode.d8.loss_dice: 0.1455
09/30 21:34:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:34:18 - mmengine - INFO - Iter(train) [103000/320000]  base_lr: 7.0499e-05 lr: 7.0499e-06  eta: 1 day, 2:19:24  time: 0.4427  data_time: 0.0099  memory: 5129  grad_norm: 25.3478  loss: 5.0424  decode.loss_cls: 0.0062  decode.loss_mask: 0.2263  decode.loss_dice: 0.1917  decode.d0.loss_cls: 0.7813  decode.d0.loss_mask: 0.2379  decode.d0.loss_dice: 0.1830  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.1890  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.1922  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.1932  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.1909  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.2263  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2240  decode.d7.loss_dice: 0.1905  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.2239  decode.d8.loss_dice: 0.1939
09/30 21:34:41 - mmengine - INFO - Iter(train) [103050/320000]  base_lr: 7.0484e-05 lr: 7.0484e-06  eta: 1 day, 2:19:03  time: 0.4418  data_time: 0.0100  memory: 5129  grad_norm: 72.6982  loss: 6.1291  decode.loss_cls: 0.0238  decode.loss_mask: 0.2951  decode.loss_dice: 0.2190  decode.d0.loss_cls: 0.7203  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.2263  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.2952  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.2990  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.2937  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.2937  decode.d4.loss_dice: 0.2013  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.2944  decode.d5.loss_dice: 0.2029  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.2898  decode.d6.loss_dice: 0.2003  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.2958  decode.d7.loss_dice: 0.2017  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.2932  decode.d8.loss_dice: 0.2200
09/30 21:35:03 - mmengine - INFO - Iter(train) [103100/320000]  base_lr: 7.0469e-05 lr: 7.0469e-06  eta: 1 day, 2:18:42  time: 0.4439  data_time: 0.0099  memory: 5129  grad_norm: 29.8976  loss: 5.7031  decode.loss_cls: 0.0882  decode.loss_mask: 0.1910  decode.loss_dice: 0.2051  decode.d0.loss_cls: 0.8795  decode.d0.loss_mask: 0.1954  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.0894  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.0963  decode.d2.loss_mask: 0.1909  decode.d2.loss_dice: 0.2100  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.1923  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.1917  decode.d4.loss_dice: 0.2015  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.1927  decode.d5.loss_dice: 0.1886  decode.d6.loss_cls: 0.0950  decode.d6.loss_mask: 0.1927  decode.d6.loss_dice: 0.2075  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 0.1930  decode.d7.loss_dice: 0.2023  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.1946  decode.d8.loss_dice: 0.2097
09/30 21:35:25 - mmengine - INFO - Iter(train) [103150/320000]  base_lr: 7.0455e-05 lr: 7.0455e-06  eta: 1 day, 2:18:20  time: 0.4420  data_time: 0.0100  memory: 5120  grad_norm: 62.7862  loss: 5.2346  decode.loss_cls: 0.0228  decode.loss_mask: 0.2025  decode.loss_dice: 0.2199  decode.d0.loss_cls: 0.7650  decode.d0.loss_mask: 0.2020  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.1986  decode.d1.loss_dice: 0.2131  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.2031  decode.d3.loss_dice: 0.2177  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.1985  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.2024  decode.d5.loss_dice: 0.2236  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.2026  decode.d6.loss_dice: 0.2214  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.2205  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.2011  decode.d8.loss_dice: 0.2262
09/30 21:35:47 - mmengine - INFO - Iter(train) [103200/320000]  base_lr: 7.0440e-05 lr: 7.0440e-06  eta: 1 day, 2:17:59  time: 0.4402  data_time: 0.0099  memory: 5120  grad_norm: 245.0498  loss: 6.1007  decode.loss_cls: 0.1039  decode.loss_mask: 0.1990  decode.loss_dice: 0.2050  decode.d0.loss_cls: 0.9210  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.2335  decode.d1.loss_cls: 0.1393  decode.d1.loss_mask: 0.2101  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.2010  decode.d2.loss_dice: 0.2064  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.2018  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.2304  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.2010  decode.d5.loss_dice: 0.2297  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2017  decode.d6.loss_dice: 0.2267  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.2198  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.2066  decode.d8.loss_dice: 0.2346
09/30 21:36:09 - mmengine - INFO - Iter(train) [103250/320000]  base_lr: 7.0425e-05 lr: 7.0425e-06  eta: 1 day, 2:17:38  time: 0.4419  data_time: 0.0101  memory: 5145  grad_norm: 51.6493  loss: 5.3322  decode.loss_cls: 0.0211  decode.loss_mask: 0.2551  decode.loss_dice: 0.1805  decode.d0.loss_cls: 0.7701  decode.d0.loss_mask: 0.2528  decode.d0.loss_dice: 0.1784  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.1788  decode.d2.loss_cls: 0.0308  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.1807  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.1817  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.2511  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.1815  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.2582  decode.d8.loss_dice: 0.1807
09/30 21:36:31 - mmengine - INFO - Iter(train) [103300/320000]  base_lr: 7.0411e-05 lr: 7.0411e-06  eta: 1 day, 2:17:16  time: 0.4409  data_time: 0.0099  memory: 5129  grad_norm: 40.6295  loss: 5.5663  decode.loss_cls: 0.1180  decode.loss_mask: 0.1899  decode.loss_dice: 0.1833  decode.d0.loss_cls: 0.9464  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.2249  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.1907  decode.d2.loss_dice: 0.2029  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.1903  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.1893  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.1026  decode.d5.loss_mask: 0.1911  decode.d5.loss_dice: 0.1869  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.2315  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.1899  decode.d7.loss_dice: 0.2114  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.1883  decode.d8.loss_dice: 0.2231
09/30 21:36:53 - mmengine - INFO - Iter(train) [103350/320000]  base_lr: 7.0396e-05 lr: 7.0396e-06  eta: 1 day, 2:16:55  time: 0.4414  data_time: 0.0099  memory: 5120  grad_norm: 16.2261  loss: 3.9599  decode.loss_cls: 0.0021  decode.loss_mask: 0.1819  decode.loss_dice: 0.1350  decode.d0.loss_cls: 0.7637  decode.d0.loss_mask: 0.1852  decode.d0.loss_dice: 0.1425  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.1784  decode.d1.loss_dice: 0.1342  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.1825  decode.d2.loss_dice: 0.1379  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.1808  decode.d3.loss_dice: 0.1350  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.1821  decode.d4.loss_dice: 0.1335  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.1822  decode.d5.loss_dice: 0.1380  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.1799  decode.d6.loss_dice: 0.1337  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.1354  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1826  decode.d8.loss_dice: 0.1362
09/30 21:37:15 - mmengine - INFO - Iter(train) [103400/320000]  base_lr: 7.0382e-05 lr: 7.0382e-06  eta: 1 day, 2:16:34  time: 0.4425  data_time: 0.0101  memory: 5129  grad_norm: 52.9822  loss: 6.0752  decode.loss_cls: 0.1190  decode.loss_mask: 0.1976  decode.loss_dice: 0.2065  decode.d0.loss_cls: 0.8824  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.1338  decode.d1.loss_mask: 0.2029  decode.d1.loss_dice: 0.1976  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.1910  decode.d3.loss_cls: 0.1516  decode.d3.loss_mask: 0.1960  decode.d3.loss_dice: 0.1997  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.1972  decode.d4.loss_dice: 0.1981  decode.d5.loss_cls: 0.1261  decode.d5.loss_mask: 0.1947  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.2017  decode.d7.loss_cls: 0.1385  decode.d7.loss_mask: 0.1961  decode.d7.loss_dice: 0.2362  decode.d8.loss_cls: 0.1125  decode.d8.loss_mask: 0.1974  decode.d8.loss_dice: 0.2121
09/30 21:37:37 - mmengine - INFO - Iter(train) [103450/320000]  base_lr: 7.0367e-05 lr: 7.0367e-06  eta: 1 day, 2:16:13  time: 0.4425  data_time: 0.0097  memory: 5120  grad_norm: 41.6321  loss: 5.2553  decode.loss_cls: 0.0044  decode.loss_mask: 0.2674  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.6502  decode.d0.loss_mask: 0.2698  decode.d0.loss_dice: 0.1845  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.2679  decode.d1.loss_dice: 0.1849  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.2664  decode.d2.loss_dice: 0.1876  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.2700  decode.d3.loss_dice: 0.1957  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.1907  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.2672  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.1890  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.2629  decode.d7.loss_dice: 0.1889  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.1991
09/30 21:38:00 - mmengine - INFO - Iter(train) [103500/320000]  base_lr: 7.0352e-05 lr: 7.0352e-06  eta: 1 day, 2:15:51  time: 0.4407  data_time: 0.0097  memory: 5129  grad_norm: 162.6202  loss: 6.6073  decode.loss_cls: 0.1055  decode.loss_mask: 0.2422  decode.loss_dice: 0.2233  decode.d0.loss_cls: 0.8644  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2220  decode.d1.loss_cls: 0.0935  decode.d1.loss_mask: 0.2377  decode.d1.loss_dice: 0.2088  decode.d2.loss_cls: 0.1326  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.2171  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.2191  decode.d4.loss_cls: 0.1374  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.2092  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2110  decode.d6.loss_cls: 0.1432  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.2167  decode.d7.loss_cls: 0.1505  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.2149  decode.d8.loss_cls: 0.1327  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.2141
09/30 21:38:22 - mmengine - INFO - Iter(train) [103550/320000]  base_lr: 7.0338e-05 lr: 7.0338e-06  eta: 1 day, 2:15:30  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 49.9574  loss: 5.8515  decode.loss_cls: 0.0878  decode.loss_mask: 0.2283  decode.loss_dice: 0.1889  decode.d0.loss_cls: 0.9536  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.1889  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.1943  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.2246  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.1001  decode.d3.loss_mask: 0.2297  decode.d3.loss_dice: 0.1959  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1894  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.2292  decode.d5.loss_dice: 0.1872  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.1868  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0769  decode.d8.loss_mask: 0.2307  decode.d8.loss_dice: 0.1902
09/30 21:38:44 - mmengine - INFO - Iter(train) [103600/320000]  base_lr: 7.0323e-05 lr: 7.0323e-06  eta: 1 day, 2:15:09  time: 0.4421  data_time: 0.0096  memory: 5159  grad_norm: 18.0973  loss: 4.1620  decode.loss_cls: 0.0023  decode.loss_mask: 0.1503  decode.loss_dice: 0.1660  decode.d0.loss_cls: 0.9525  decode.d0.loss_mask: 0.1484  decode.d0.loss_dice: 0.1703  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.1456  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.1483  decode.d2.loss_dice: 0.1594  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.1470  decode.d3.loss_dice: 0.1585  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1473  decode.d4.loss_dice: 0.1598  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.1487  decode.d5.loss_dice: 0.1582  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.1479  decode.d6.loss_dice: 0.1567  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.1473  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.1475  decode.d8.loss_dice: 0.1579
09/30 21:39:06 - mmengine - INFO - Iter(train) [103650/320000]  base_lr: 7.0308e-05 lr: 7.0308e-06  eta: 1 day, 2:14:47  time: 0.4417  data_time: 0.0096  memory: 5129  grad_norm: 22.2587  loss: 4.7269  decode.loss_cls: 0.0131  decode.loss_mask: 0.2111  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.7198  decode.d0.loss_mask: 0.2120  decode.d0.loss_dice: 0.1857  decode.d1.loss_cls: 0.0283  decode.d1.loss_mask: 0.2130  decode.d1.loss_dice: 0.1747  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.1746  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.1798  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.2087  decode.d4.loss_dice: 0.1747  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.1816  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.1901  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.1752
09/30 21:39:28 - mmengine - INFO - Iter(train) [103700/320000]  base_lr: 7.0294e-05 lr: 7.0294e-06  eta: 1 day, 2:14:26  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 81.9820  loss: 6.6029  decode.loss_cls: 0.1430  decode.loss_mask: 0.2879  decode.loss_dice: 0.1982  decode.d0.loss_cls: 0.7800  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.1986  decode.d2.loss_cls: 0.1131  decode.d2.loss_mask: 0.2865  decode.d2.loss_dice: 0.2005  decode.d3.loss_cls: 0.0998  decode.d3.loss_mask: 0.2880  decode.d3.loss_dice: 0.1977  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.1961  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.2873  decode.d5.loss_dice: 0.2111  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.2869  decode.d6.loss_dice: 0.2024  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.2029  decode.d8.loss_cls: 0.1345  decode.d8.loss_mask: 0.2838  decode.d8.loss_dice: 0.1973
09/30 21:39:50 - mmengine - INFO - Iter(train) [103750/320000]  base_lr: 7.0279e-05 lr: 7.0279e-06  eta: 1 day, 2:14:05  time: 0.4416  data_time: 0.0096  memory: 5145  grad_norm: 61.5181  loss: 5.4309  decode.loss_cls: 0.0727  decode.loss_mask: 0.2187  decode.loss_dice: 0.1708  decode.d0.loss_cls: 0.7381  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.1949  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 0.2230  decode.d1.loss_dice: 0.2037  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 0.2213  decode.d2.loss_dice: 0.1755  decode.d3.loss_cls: 0.0787  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.1848  decode.d4.loss_cls: 0.0845  decode.d4.loss_mask: 0.2177  decode.d4.loss_dice: 0.1843  decode.d5.loss_cls: 0.0807  decode.d5.loss_mask: 0.2177  decode.d5.loss_dice: 0.1740  decode.d6.loss_cls: 0.0772  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.1991  decode.d7.loss_cls: 0.0693  decode.d7.loss_mask: 0.2190  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.1892
09/30 21:40:12 - mmengine - INFO - Iter(train) [103800/320000]  base_lr: 7.0265e-05 lr: 7.0265e-06  eta: 1 day, 2:13:44  time: 0.4407  data_time: 0.0097  memory: 5145  grad_norm: 36.1768  loss: 5.3145  decode.loss_cls: 0.0100  decode.loss_mask: 0.2630  decode.loss_dice: 0.1888  decode.d0.loss_cls: 0.7583  decode.d0.loss_mask: 0.2209  decode.d0.loss_dice: 0.1900  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 0.2634  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.1886  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.2590  decode.d3.loss_dice: 0.1880  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.2580  decode.d4.loss_dice: 0.1911  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.2578  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.2590  decode.d8.loss_dice: 0.1882
09/30 21:40:34 - mmengine - INFO - Iter(train) [103850/320000]  base_lr: 7.0250e-05 lr: 7.0250e-06  eta: 1 day, 2:13:22  time: 0.4405  data_time: 0.0096  memory: 5129  grad_norm: 21.8126  loss: 4.3837  decode.loss_cls: 0.0024  decode.loss_mask: 0.2069  decode.loss_dice: 0.1481  decode.d0.loss_cls: 0.7888  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.1463  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.2113  decode.d1.loss_dice: 0.1497  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2095  decode.d2.loss_dice: 0.1498  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.1501  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.1474  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.1449  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.2082  decode.d6.loss_dice: 0.1472  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.1484  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.2100  decode.d8.loss_dice: 0.1466
09/30 21:40:56 - mmengine - INFO - Iter(train) [103900/320000]  base_lr: 7.0235e-05 lr: 7.0235e-06  eta: 1 day, 2:13:01  time: 0.4408  data_time: 0.0098  memory: 5120  grad_norm: 53.8697  loss: 5.5942  decode.loss_cls: 0.1151  decode.loss_mask: 0.1783  decode.loss_dice: 0.1839  decode.d0.loss_cls: 0.9537  decode.d0.loss_mask: 0.1844  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.1273  decode.d1.loss_mask: 0.1887  decode.d1.loss_dice: 0.1972  decode.d2.loss_cls: 0.1060  decode.d2.loss_mask: 0.1831  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.1069  decode.d3.loss_mask: 0.1797  decode.d3.loss_dice: 0.1775  decode.d4.loss_cls: 0.1118  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.1763  decode.d5.loss_cls: 0.1044  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.1789  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.1817  decode.d6.loss_dice: 0.1815  decode.d7.loss_cls: 0.1020  decode.d7.loss_mask: 0.1818  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.1004  decode.d8.loss_mask: 0.1749  decode.d8.loss_dice: 0.1803
09/30 21:41:18 - mmengine - INFO - Iter(train) [103950/320000]  base_lr: 7.0221e-05 lr: 7.0221e-06  eta: 1 day, 2:12:39  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 26.9197  loss: 4.2537  decode.loss_cls: 0.0085  decode.loss_mask: 0.1737  decode.loss_dice: 0.1604  decode.d0.loss_cls: 0.8279  decode.d0.loss_mask: 0.1763  decode.d0.loss_dice: 0.1672  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.1745  decode.d1.loss_dice: 0.1562  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.1782  decode.d2.loss_dice: 0.1574  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.1737  decode.d3.loss_dice: 0.1555  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.1728  decode.d4.loss_dice: 0.1503  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.1740  decode.d5.loss_dice: 0.1523  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.1748  decode.d6.loss_dice: 0.1545  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.1725  decode.d7.loss_dice: 0.1570  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.1738  decode.d8.loss_dice: 0.1530
09/30 21:41:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:41:40 - mmengine - INFO - Iter(train) [104000/320000]  base_lr: 7.0206e-05 lr: 7.0206e-06  eta: 1 day, 2:12:18  time: 0.4401  data_time: 0.0096  memory: 5120  grad_norm: 80.0987  loss: 5.3099  decode.loss_cls: 0.0171  decode.loss_mask: 0.2271  decode.loss_dice: 0.2027  decode.d0.loss_cls: 0.7778  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.2051  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.2023  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.2054  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.2033  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.1989  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.1978  decode.d6.loss_cls: 0.0317  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2021  decode.d7.loss_cls: 0.0308  decode.d7.loss_mask: 0.2249  decode.d7.loss_dice: 0.2047  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.2276  decode.d8.loss_dice: 0.2012
09/30 21:42:03 - mmengine - INFO - Iter(train) [104050/320000]  base_lr: 7.0191e-05 lr: 7.0191e-06  eta: 1 day, 2:11:57  time: 0.4406  data_time: 0.0098  memory: 5129  grad_norm: 222.9732  loss: 7.2813  decode.loss_cls: 0.1263  decode.loss_mask: 0.3226  decode.loss_dice: 0.2540  decode.d0.loss_cls: 0.8809  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.2138  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.2394  decode.d1.loss_dice: 0.2246  decode.d2.loss_cls: 0.1090  decode.d2.loss_mask: 0.3270  decode.d2.loss_dice: 0.2504  decode.d3.loss_cls: 0.0408  decode.d3.loss_mask: 0.3061  decode.d3.loss_dice: 0.2379  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.1494  decode.d5.loss_mask: 0.3142  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 0.3071  decode.d6.loss_dice: 0.2358  decode.d7.loss_cls: 0.1203  decode.d7.loss_mask: 0.3114  decode.d7.loss_dice: 0.2424  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 0.3249  decode.d8.loss_dice: 0.2436
09/30 21:42:25 - mmengine - INFO - Iter(train) [104100/320000]  base_lr: 7.0177e-05 lr: 7.0177e-06  eta: 1 day, 2:11:35  time: 0.4403  data_time: 0.0098  memory: 5129  grad_norm: 163.1650  loss: 8.1905  decode.loss_cls: 0.2184  decode.loss_mask: 0.5067  decode.loss_dice: 0.2696  decode.d0.loss_cls: 1.0213  decode.d0.loss_mask: 0.1949  decode.d0.loss_dice: 0.2596  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 0.2795  decode.d1.loss_dice: 0.2825  decode.d2.loss_cls: 0.2421  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.2616  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.2737  decode.d3.loss_dice: 0.2826  decode.d4.loss_cls: 0.2116  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2653  decode.d5.loss_cls: 0.2457  decode.d5.loss_mask: 0.1895  decode.d5.loss_dice: 0.2422  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 0.2058  decode.d6.loss_dice: 0.2601  decode.d7.loss_cls: 0.2414  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.2536  decode.d8.loss_cls: 0.2438  decode.d8.loss_mask: 0.1863  decode.d8.loss_dice: 0.2250
09/30 21:42:47 - mmengine - INFO - Iter(train) [104150/320000]  base_lr: 7.0162e-05 lr: 7.0162e-06  eta: 1 day, 2:11:14  time: 0.4412  data_time: 0.0097  memory: 5129  grad_norm: 154.6481  loss: 7.0399  decode.loss_cls: 0.0713  decode.loss_mask: 0.3214  decode.loss_dice: 0.1953  decode.d0.loss_cls: 0.9734  decode.d0.loss_mask: 0.3231  decode.d0.loss_dice: 0.2253  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.3255  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.3280  decode.d2.loss_dice: 0.1970  decode.d3.loss_cls: 0.0687  decode.d3.loss_mask: 0.3391  decode.d3.loss_dice: 0.2025  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.3873  decode.d4.loss_dice: 0.2308  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.3111  decode.d5.loss_dice: 0.1971  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.4304  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.3259  decode.d8.loss_dice: 0.2020
09/30 21:43:09 - mmengine - INFO - Iter(train) [104200/320000]  base_lr: 7.0148e-05 lr: 7.0148e-06  eta: 1 day, 2:10:52  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 22.1800  loss: 4.5576  decode.loss_cls: 0.0097  decode.loss_mask: 0.2007  decode.loss_dice: 0.1662  decode.d0.loss_cls: 0.7815  decode.d0.loss_mask: 0.2031  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.1999  decode.d1.loss_dice: 0.1636  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.2011  decode.d2.loss_dice: 0.1724  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.2037  decode.d3.loss_dice: 0.1693  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.1645  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.2007  decode.d5.loss_dice: 0.1619  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.1675  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.1695  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.1980  decode.d8.loss_dice: 0.1697
09/30 21:43:31 - mmengine - INFO - Iter(train) [104250/320000]  base_lr: 7.0133e-05 lr: 7.0133e-06  eta: 1 day, 2:10:31  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 103.7439  loss: 6.4983  decode.loss_cls: 0.1419  decode.loss_mask: 0.2150  decode.loss_dice: 0.2166  decode.d0.loss_cls: 0.8938  decode.d0.loss_mask: 0.2137  decode.d0.loss_dice: 0.2306  decode.d1.loss_cls: 0.1096  decode.d1.loss_mask: 0.2103  decode.d1.loss_dice: 0.2232  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.2192  decode.d3.loss_cls: 0.1381  decode.d3.loss_mask: 0.2096  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.1214  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2131  decode.d5.loss_cls: 0.1125  decode.d5.loss_mask: 0.2110  decode.d5.loss_dice: 0.2248  decode.d6.loss_cls: 0.1546  decode.d6.loss_mask: 0.2098  decode.d6.loss_dice: 0.2272  decode.d7.loss_cls: 0.1927  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2275  decode.d8.loss_cls: 0.1544  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.2189
09/30 21:43:53 - mmengine - INFO - Iter(train) [104300/320000]  base_lr: 7.0118e-05 lr: 7.0118e-06  eta: 1 day, 2:10:09  time: 0.4408  data_time: 0.0097  memory: 5145  grad_norm: 52.2676  loss: 7.3397  decode.loss_cls: 0.2200  decode.loss_mask: 0.2456  decode.loss_dice: 0.2248  decode.d0.loss_cls: 0.9297  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.2393  decode.d1.loss_cls: 0.1961  decode.d1.loss_mask: 0.2390  decode.d1.loss_dice: 0.2204  decode.d2.loss_cls: 0.1862  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.1992  decode.d3.loss_cls: 0.1658  decode.d3.loss_mask: 0.2378  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.2386  decode.d5.loss_cls: 0.2065  decode.d5.loss_mask: 0.2375  decode.d5.loss_dice: 0.1997  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2267  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 0.2487  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.1984  decode.d8.loss_mask: 0.2470  decode.d8.loss_dice: 0.2295
09/30 21:44:15 - mmengine - INFO - Iter(train) [104350/320000]  base_lr: 7.0104e-05 lr: 7.0104e-06  eta: 1 day, 2:09:48  time: 0.4428  data_time: 0.0095  memory: 5129  grad_norm: 26.9604  loss: 4.6869  decode.loss_cls: 0.0069  decode.loss_mask: 0.1963  decode.loss_dice: 0.1783  decode.d0.loss_cls: 0.8695  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.1760  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.1963  decode.d1.loss_dice: 0.1798  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.1954  decode.d2.loss_dice: 0.1818  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.1947  decode.d4.loss_dice: 0.1842  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.1743  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1951  decode.d6.loss_dice: 0.1837  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.1953  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.1850
09/30 21:44:37 - mmengine - INFO - Iter(train) [104400/320000]  base_lr: 7.0089e-05 lr: 7.0089e-06  eta: 1 day, 2:09:27  time: 0.4409  data_time: 0.0096  memory: 5145  grad_norm: 28.8836  loss: 5.7637  decode.loss_cls: 0.0960  decode.loss_mask: 0.1983  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.8764  decode.d0.loss_mask: 0.1978  decode.d0.loss_dice: 0.2166  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.2248  decode.d2.loss_cls: 0.1142  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.0940  decode.d3.loss_mask: 0.1949  decode.d3.loss_dice: 0.2058  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.1913  decode.d5.loss_dice: 0.2109  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.1963  decode.d6.loss_dice: 0.2266  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.1922  decode.d7.loss_dice: 0.2233  decode.d8.loss_cls: 0.1003  decode.d8.loss_mask: 0.1936  decode.d8.loss_dice: 0.2069
09/30 21:44:59 - mmengine - INFO - Iter(train) [104450/320000]  base_lr: 7.0074e-05 lr: 7.0074e-06  eta: 1 day, 2:09:05  time: 0.4421  data_time: 0.0096  memory: 5129  grad_norm: 45.7481  loss: 5.3135  decode.loss_cls: 0.0305  decode.loss_mask: 0.2009  decode.loss_dice: 0.2078  decode.d0.loss_cls: 0.8295  decode.d0.loss_mask: 0.2017  decode.d0.loss_dice: 0.2311  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.2110  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.1987  decode.d2.loss_dice: 0.2174  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.2002  decode.d3.loss_dice: 0.2019  decode.d4.loss_cls: 0.0461  decode.d4.loss_mask: 0.1979  decode.d4.loss_dice: 0.2076  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2078  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.2003  decode.d6.loss_dice: 0.2035  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.2074  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.2154
09/30 21:45:21 - mmengine - INFO - Iter(train) [104500/320000]  base_lr: 7.0060e-05 lr: 7.0060e-06  eta: 1 day, 2:08:44  time: 0.4439  data_time: 0.0100  memory: 5120  grad_norm: 52.8888  loss: 6.5907  decode.loss_cls: 0.0973  decode.loss_mask: 0.2677  decode.loss_dice: 0.2376  decode.d0.loss_cls: 0.8175  decode.d0.loss_mask: 0.2751  decode.d0.loss_dice: 0.2511  decode.d1.loss_cls: 0.0936  decode.d1.loss_mask: 0.2703  decode.d1.loss_dice: 0.2393  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.2679  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.0882  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2227  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.2393  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.2356  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.2676  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.2695  decode.d8.loss_dice: 0.2252
09/30 21:45:43 - mmengine - INFO - Iter(train) [104550/320000]  base_lr: 7.0045e-05 lr: 7.0045e-06  eta: 1 day, 2:08:23  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 75.5638  loss: 5.0082  decode.loss_cls: 0.0490  decode.loss_mask: 0.1945  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.7572  decode.d0.loss_mask: 0.1960  decode.d0.loss_dice: 0.2151  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.0505  decode.d2.loss_mask: 0.1932  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.1959  decode.d3.loss_dice: 0.1968  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.1938  decode.d4.loss_dice: 0.1984  decode.d5.loss_cls: 0.0397  decode.d5.loss_mask: 0.1921  decode.d5.loss_dice: 0.1862  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.1934  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.1924  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.1946  decode.d8.loss_dice: 0.1918
09/30 21:46:05 - mmengine - INFO - Iter(train) [104600/320000]  base_lr: 7.0031e-05 lr: 7.0031e-06  eta: 1 day, 2:08:01  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 57.5992  loss: 4.7161  decode.loss_cls: 0.0693  decode.loss_mask: 0.1892  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.7848  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.1527  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.1894  decode.d1.loss_dice: 0.1435  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.1502  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.1440  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.1908  decode.d4.loss_dice: 0.1468  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.1903  decode.d5.loss_dice: 0.1462  decode.d6.loss_cls: 0.0733  decode.d6.loss_mask: 0.1888  decode.d6.loss_dice: 0.1444  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.1467  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.1910  decode.d8.loss_dice: 0.1452
09/30 21:46:27 - mmengine - INFO - Iter(train) [104650/320000]  base_lr: 7.0016e-05 lr: 7.0016e-06  eta: 1 day, 2:07:40  time: 0.4421  data_time: 0.0097  memory: 5120  grad_norm: 28.5284  loss: 4.4201  decode.loss_cls: 0.0043  decode.loss_mask: 0.1959  decode.loss_dice: 0.1592  decode.d0.loss_cls: 0.7843  decode.d0.loss_mask: 0.1988  decode.d0.loss_dice: 0.1598  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.2020  decode.d1.loss_dice: 0.1677  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.1992  decode.d2.loss_dice: 0.1622  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.1965  decode.d3.loss_dice: 0.1634  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.1622  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.1642  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1975  decode.d6.loss_dice: 0.1608  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.1640  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.1968  decode.d8.loss_dice: 0.1546
09/30 21:46:50 - mmengine - INFO - Iter(train) [104700/320000]  base_lr: 7.0001e-05 lr: 7.0001e-06  eta: 1 day, 2:07:19  time: 0.4424  data_time: 0.0098  memory: 5145  grad_norm: 82.9376  loss: 7.9180  decode.loss_cls: 0.0764  decode.loss_mask: 0.4112  decode.loss_dice: 0.2378  decode.d0.loss_cls: 0.8475  decode.d0.loss_mask: 0.2734  decode.d0.loss_dice: 0.2421  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.3368  decode.d1.loss_dice: 0.2331  decode.d2.loss_cls: 0.1598  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.2294  decode.d3.loss_cls: 0.1858  decode.d3.loss_mask: 0.2774  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 0.3396  decode.d4.loss_dice: 0.2683  decode.d5.loss_cls: 0.1821  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.2769  decode.d6.loss_cls: 0.1248  decode.d6.loss_mask: 0.3782  decode.d6.loss_dice: 0.2488  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.3755  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.1555  decode.d8.loss_mask: 0.2719  decode.d8.loss_dice: 0.2535
09/30 21:47:12 - mmengine - INFO - Iter(train) [104750/320000]  base_lr: 6.9987e-05 lr: 6.9987e-06  eta: 1 day, 2:06:58  time: 0.4421  data_time: 0.0094  memory: 5145  grad_norm: 32.7861  loss: 4.8772  decode.loss_cls: 0.0843  decode.loss_mask: 0.1591  decode.loss_dice: 0.1568  decode.d0.loss_cls: 0.8884  decode.d0.loss_mask: 0.1609  decode.d0.loss_dice: 0.1860  decode.d1.loss_cls: 0.1150  decode.d1.loss_mask: 0.1576  decode.d1.loss_dice: 0.1631  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.1580  decode.d2.loss_dice: 0.1635  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.1575  decode.d3.loss_dice: 0.1588  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.1546  decode.d4.loss_dice: 0.1728  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 0.1577  decode.d5.loss_dice: 0.1662  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.1570  decode.d6.loss_dice: 0.1671  decode.d7.loss_cls: 0.0815  decode.d7.loss_mask: 0.1557  decode.d7.loss_dice: 0.1660  decode.d8.loss_cls: 0.0804  decode.d8.loss_mask: 0.1563  decode.d8.loss_dice: 0.1667
09/30 21:47:34 - mmengine - INFO - Iter(train) [104800/320000]  base_lr: 6.9972e-05 lr: 6.9972e-06  eta: 1 day, 2:06:36  time: 0.4425  data_time: 0.0097  memory: 5119  grad_norm: 21.6859  loss: 4.2081  decode.loss_cls: 0.0135  decode.loss_mask: 0.1836  decode.loss_dice: 0.1439  decode.d0.loss_cls: 0.8371  decode.d0.loss_mask: 0.1849  decode.d0.loss_dice: 0.1415  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.1838  decode.d1.loss_dice: 0.1439  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.1824  decode.d2.loss_dice: 0.1419  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.1820  decode.d3.loss_dice: 0.1432  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.1825  decode.d4.loss_dice: 0.1410  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.1832  decode.d5.loss_dice: 0.1412  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.1850  decode.d6.loss_dice: 0.1417  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.1842  decode.d7.loss_dice: 0.1429  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.1809  decode.d8.loss_dice: 0.1420
09/30 21:47:56 - mmengine - INFO - Iter(train) [104850/320000]  base_lr: 6.9957e-05 lr: 6.9957e-06  eta: 1 day, 2:06:15  time: 0.4419  data_time: 0.0097  memory: 5145  grad_norm: 24.9144  loss: 4.3662  decode.loss_cls: 0.0148  decode.loss_mask: 0.1904  decode.loss_dice: 0.1541  decode.d0.loss_cls: 0.7994  decode.d0.loss_mask: 0.1912  decode.d0.loss_dice: 0.1607  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.1910  decode.d1.loss_dice: 0.1518  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.1506  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.1910  decode.d3.loss_dice: 0.1532  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.1898  decode.d4.loss_dice: 0.1515  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.1892  decode.d5.loss_dice: 0.1510  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.1927  decode.d6.loss_dice: 0.1549  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.1907  decode.d7.loss_dice: 0.1539  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.1899  decode.d8.loss_dice: 0.1525
09/30 21:48:18 - mmengine - INFO - Iter(train) [104900/320000]  base_lr: 6.9943e-05 lr: 6.9943e-06  eta: 1 day, 2:05:54  time: 0.4408  data_time: 0.0096  memory: 5145  grad_norm: 118.4943  loss: 5.6624  decode.loss_cls: 0.1093  decode.loss_mask: 0.2082  decode.loss_dice: 0.1582  decode.d0.loss_cls: 0.8144  decode.d0.loss_mask: 0.2106  decode.d0.loss_dice: 0.1675  decode.d1.loss_cls: 0.2363  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1551  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.2062  decode.d2.loss_dice: 0.1584  decode.d3.loss_cls: 0.1163  decode.d3.loss_mask: 0.2051  decode.d3.loss_dice: 0.1649  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.2044  decode.d4.loss_dice: 0.1589  decode.d5.loss_cls: 0.1219  decode.d5.loss_mask: 0.2094  decode.d5.loss_dice: 0.1561  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.1551  decode.d7.loss_cls: 0.1240  decode.d7.loss_mask: 0.2063  decode.d7.loss_dice: 0.1601  decode.d8.loss_cls: 0.1185  decode.d8.loss_mask: 0.2028  decode.d8.loss_dice: 0.1582
09/30 21:48:40 - mmengine - INFO - Iter(train) [104950/320000]  base_lr: 6.9928e-05 lr: 6.9928e-06  eta: 1 day, 2:05:32  time: 0.4404  data_time: 0.0098  memory: 5145  grad_norm: 29.8380  loss: 5.0727  decode.loss_cls: 0.0880  decode.loss_mask: 0.2086  decode.loss_dice: 0.1558  decode.d0.loss_cls: 0.6886  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.1603  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.1574  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.1577  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.1581  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.1562  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.1598  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2101  decode.d7.loss_dice: 0.1580  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.1587
09/30 21:49:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:49:02 - mmengine - INFO - Iter(train) [105000/320000]  base_lr: 6.9913e-05 lr: 6.9913e-06  eta: 1 day, 2:05:11  time: 0.4428  data_time: 0.0099  memory: 5120  grad_norm: 27.9941  loss: 5.1098  decode.loss_cls: 0.0076  decode.loss_mask: 0.2489  decode.loss_dice: 0.1704  decode.d0.loss_cls: 0.8932  decode.d0.loss_mask: 0.2530  decode.d0.loss_dice: 0.1644  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.2460  decode.d1.loss_dice: 0.1638  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.2480  decode.d2.loss_dice: 0.1684  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.1634  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.2497  decode.d4.loss_dice: 0.1660  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.2468  decode.d5.loss_dice: 0.1648  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2481  decode.d6.loss_dice: 0.1672  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2469  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.1635
09/30 21:49:24 - mmengine - INFO - Iter(train) [105050/320000]  base_lr: 6.9899e-05 lr: 6.9899e-06  eta: 1 day, 2:04:50  time: 0.4413  data_time: 0.0098  memory: 5145  grad_norm: 33.6181  loss: 5.4091  decode.loss_cls: 0.0561  decode.loss_mask: 0.2180  decode.loss_dice: 0.1993  decode.d0.loss_cls: 0.7507  decode.d0.loss_mask: 0.2165  decode.d0.loss_dice: 0.2011  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.2025  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.2160  decode.d2.loss_dice: 0.1943  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.2177  decode.d4.loss_dice: 0.1879  decode.d5.loss_cls: 0.0905  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.1880  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.1987  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.2151  decode.d8.loss_dice: 0.1887
09/30 21:49:47 - mmengine - INFO - Iter(train) [105100/320000]  base_lr: 6.9884e-05 lr: 6.9884e-06  eta: 1 day, 2:04:28  time: 0.4421  data_time: 0.0098  memory: 5129  grad_norm: 42.7816  loss: 5.9670  decode.loss_cls: 0.0631  decode.loss_mask: 0.2331  decode.loss_dice: 0.2110  decode.d0.loss_cls: 0.8244  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.2237  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.2323  decode.d1.loss_dice: 0.2183  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.2364  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.2370  decode.d4.loss_dice: 0.2213  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.2356  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.2349  decode.d6.loss_dice: 0.2262  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.2318  decode.d7.loss_dice: 0.2128  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.2216
09/30 21:50:09 - mmengine - INFO - Iter(train) [105150/320000]  base_lr: 6.9870e-05 lr: 6.9870e-06  eta: 1 day, 2:04:07  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 24.1636  loss: 4.1855  decode.loss_cls: 0.0039  decode.loss_mask: 0.1714  decode.loss_dice: 0.1497  decode.d0.loss_cls: 0.8632  decode.d0.loss_mask: 0.1779  decode.d0.loss_dice: 0.1633  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.1724  decode.d1.loss_dice: 0.1551  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.1757  decode.d2.loss_dice: 0.1535  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.1741  decode.d3.loss_dice: 0.1515  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.1708  decode.d4.loss_dice: 0.1531  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.1723  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.1745  decode.d6.loss_dice: 0.1498  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1724  decode.d7.loss_dice: 0.1497  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.1722  decode.d8.loss_dice: 0.1507
09/30 21:50:31 - mmengine - INFO - Iter(train) [105200/320000]  base_lr: 6.9855e-05 lr: 6.9855e-06  eta: 1 day, 2:03:46  time: 0.4411  data_time: 0.0099  memory: 5145  grad_norm: 40.7724  loss: 4.7078  decode.loss_cls: 0.0370  decode.loss_mask: 0.1781  decode.loss_dice: 0.1660  decode.d0.loss_cls: 0.8424  decode.d0.loss_mask: 0.1922  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.1843  decode.d1.loss_dice: 0.1656  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.1848  decode.d2.loss_dice: 0.1615  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.1658  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.1788  decode.d4.loss_dice: 0.1604  decode.d5.loss_cls: 0.0307  decode.d5.loss_mask: 0.1786  decode.d5.loss_dice: 0.1772  decode.d6.loss_cls: 0.0353  decode.d6.loss_mask: 0.1821  decode.d6.loss_dice: 0.1599  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.1810  decode.d7.loss_dice: 0.1693  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.1812  decode.d8.loss_dice: 0.1676
09/30 21:50:53 - mmengine - INFO - Iter(train) [105250/320000]  base_lr: 6.9840e-05 lr: 6.9840e-06  eta: 1 day, 2:03:24  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 59.2357  loss: 5.8964  decode.loss_cls: 0.0874  decode.loss_mask: 0.2154  decode.loss_dice: 0.2076  decode.d0.loss_cls: 0.7937  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.1950  decode.d1.loss_cls: 0.1507  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.1837  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 0.2162  decode.d2.loss_dice: 0.2204  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.2012  decode.d4.loss_cls: 0.0953  decode.d4.loss_mask: 0.2124  decode.d4.loss_dice: 0.2418  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.2058  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2112  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.2058
09/30 21:51:15 - mmengine - INFO - Iter(train) [105300/320000]  base_lr: 6.9826e-05 lr: 6.9826e-06  eta: 1 day, 2:03:03  time: 0.4404  data_time: 0.0098  memory: 5145  grad_norm: 32.3327  loss: 5.1978  decode.loss_cls: 0.0729  decode.loss_mask: 0.1977  decode.loss_dice: 0.1668  decode.d0.loss_cls: 0.9321  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.1640  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.1978  decode.d1.loss_dice: 0.1649  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.1708  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.1973  decode.d3.loss_dice: 0.1668  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.1963  decode.d4.loss_dice: 0.1646  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.1979  decode.d6.loss_dice: 0.1683  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.1971  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0787  decode.d8.loss_mask: 0.1963  decode.d8.loss_dice: 0.1648
09/30 21:51:37 - mmengine - INFO - Iter(train) [105350/320000]  base_lr: 6.9811e-05 lr: 6.9811e-06  eta: 1 day, 2:02:41  time: 0.4399  data_time: 0.0096  memory: 5129  grad_norm: 32.4866  loss: 4.7103  decode.loss_cls: 0.0065  decode.loss_mask: 0.2046  decode.loss_dice: 0.1804  decode.d0.loss_cls: 0.8117  decode.d0.loss_mask: 0.2088  decode.d0.loss_dice: 0.1738  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.2051  decode.d1.loss_dice: 0.1792  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.1768  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.1762  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.1827  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.2060  decode.d5.loss_dice: 0.1785  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2069  decode.d6.loss_dice: 0.1788  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2081  decode.d7.loss_dice: 0.1780  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.2069  decode.d8.loss_dice: 0.1797
09/30 21:51:59 - mmengine - INFO - Iter(train) [105400/320000]  base_lr: 6.9796e-05 lr: 6.9796e-06  eta: 1 day, 2:02:20  time: 0.4407  data_time: 0.0097  memory: 5145  grad_norm: 145.0867  loss: 8.7991  decode.loss_cls: 0.1718  decode.loss_mask: 0.3676  decode.loss_dice: 0.2362  decode.d0.loss_cls: 1.1057  decode.d0.loss_mask: 0.3685  decode.d0.loss_dice: 0.2667  decode.d1.loss_cls: 0.1803  decode.d1.loss_mask: 0.3865  decode.d1.loss_dice: 0.2933  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.3721  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 0.3664  decode.d3.loss_dice: 0.2554  decode.d4.loss_cls: 0.1593  decode.d4.loss_mask: 0.3680  decode.d4.loss_dice: 0.2360  decode.d5.loss_cls: 0.1647  decode.d5.loss_mask: 0.3671  decode.d5.loss_dice: 0.2355  decode.d6.loss_cls: 0.1596  decode.d6.loss_mask: 0.3710  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.3787  decode.d7.loss_dice: 0.2863  decode.d8.loss_cls: 0.1633  decode.d8.loss_mask: 0.3685  decode.d8.loss_dice: 0.2447
09/30 21:52:21 - mmengine - INFO - Iter(train) [105450/320000]  base_lr: 6.9782e-05 lr: 6.9782e-06  eta: 1 day, 2:01:59  time: 0.4406  data_time: 0.0098  memory: 5145  grad_norm: 56.8971  loss: 7.2294  decode.loss_cls: 0.1275  decode.loss_mask: 0.2448  decode.loss_dice: 0.2670  decode.d0.loss_cls: 0.8586  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.2844  decode.d1.loss_cls: 0.1557  decode.d1.loss_mask: 0.2374  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.2421  decode.d2.loss_dice: 0.2673  decode.d3.loss_cls: 0.1133  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.2760  decode.d4.loss_cls: 0.1243  decode.d4.loss_mask: 0.2439  decode.d4.loss_dice: 0.2850  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 0.2445  decode.d5.loss_dice: 0.2960  decode.d6.loss_cls: 0.1241  decode.d6.loss_mask: 0.2423  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 0.2433  decode.d7.loss_dice: 0.2741  decode.d8.loss_cls: 0.1331  decode.d8.loss_mask: 0.2372  decode.d8.loss_dice: 0.2772
09/30 21:52:43 - mmengine - INFO - Iter(train) [105500/320000]  base_lr: 6.9767e-05 lr: 6.9767e-06  eta: 1 day, 2:01:37  time: 0.4400  data_time: 0.0099  memory: 5129  grad_norm: 72.6004  loss: 5.8450  decode.loss_cls: 0.1271  decode.loss_mask: 0.2049  decode.loss_dice: 0.1691  decode.d0.loss_cls: 0.8152  decode.d0.loss_mask: 0.2038  decode.d0.loss_dice: 0.1619  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.1719  decode.d2.loss_cls: 0.0932  decode.d2.loss_mask: 0.2036  decode.d2.loss_dice: 0.1621  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.2057  decode.d3.loss_dice: 0.1682  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 0.2064  decode.d4.loss_dice: 0.1598  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 0.2042  decode.d5.loss_dice: 0.1669  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.1797  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 0.2069  decode.d7.loss_dice: 0.1737  decode.d8.loss_cls: 0.1602  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.1739
09/30 21:53:05 - mmengine - INFO - Iter(train) [105550/320000]  base_lr: 6.9752e-05 lr: 6.9752e-06  eta: 1 day, 2:01:16  time: 0.4411  data_time: 0.0097  memory: 5145  grad_norm: 27.1665  loss: 5.0453  decode.loss_cls: 0.0229  decode.loss_mask: 0.2033  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.8440  decode.d0.loss_mask: 0.2041  decode.d0.loss_dice: 0.1871  decode.d1.loss_cls: 0.0386  decode.d1.loss_mask: 0.2058  decode.d1.loss_dice: 0.1927  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.2026  decode.d2.loss_dice: 0.1916  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.2055  decode.d3.loss_dice: 0.1846  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.2046  decode.d4.loss_dice: 0.1879  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.2056  decode.d5.loss_dice: 0.1878  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.1859  decode.d7.loss_cls: 0.0277  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.0290  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.1916
09/30 21:53:27 - mmengine - INFO - Iter(train) [105600/320000]  base_lr: 6.9738e-05 lr: 6.9738e-06  eta: 1 day, 2:00:54  time: 0.4426  data_time: 0.0099  memory: 5129  grad_norm: 100.4949  loss: 7.8293  decode.loss_cls: 0.2424  decode.loss_mask: 0.2425  decode.loss_dice: 0.1993  decode.d0.loss_cls: 0.8833  decode.d0.loss_mask: 0.2535  decode.d0.loss_dice: 0.2250  decode.d1.loss_cls: 0.2425  decode.d1.loss_mask: 0.2620  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.2403  decode.d2.loss_mask: 0.2360  decode.d2.loss_dice: 0.1937  decode.d3.loss_cls: 0.2247  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.1855  decode.d4.loss_cls: 0.2671  decode.d4.loss_mask: 0.2758  decode.d4.loss_dice: 0.2299  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 0.2627  decode.d5.loss_dice: 0.2177  decode.d6.loss_cls: 0.2687  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.1907  decode.d7.loss_cls: 0.2677  decode.d7.loss_mask: 0.2854  decode.d7.loss_dice: 0.2552  decode.d8.loss_cls: 0.2300  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.2218
09/30 21:53:49 - mmengine - INFO - Iter(train) [105650/320000]  base_lr: 6.9723e-05 lr: 6.9723e-06  eta: 1 day, 2:00:33  time: 0.4411  data_time: 0.0097  memory: 5145  grad_norm: 130.8987  loss: 4.7111  decode.loss_cls: 0.0209  decode.loss_mask: 0.1971  decode.loss_dice: 0.1844  decode.d0.loss_cls: 0.7722  decode.d0.loss_mask: 0.2015  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.1985  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.1831  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.1960  decode.d3.loss_dice: 0.1749  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.1965  decode.d4.loss_dice: 0.1847  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.1973  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.1970  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.1836  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.1958  decode.d8.loss_dice: 0.1836
09/30 21:54:11 - mmengine - INFO - Iter(train) [105700/320000]  base_lr: 6.9709e-05 lr: 6.9709e-06  eta: 1 day, 2:00:11  time: 0.4429  data_time: 0.0097  memory: 5129  grad_norm: 18.4393  loss: 3.9357  decode.loss_cls: 0.0017  decode.loss_mask: 0.1576  decode.loss_dice: 0.1595  decode.d0.loss_cls: 0.7453  decode.d0.loss_mask: 0.1578  decode.d0.loss_dice: 0.1503  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.1558  decode.d1.loss_dice: 0.1616  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1573  decode.d2.loss_dice: 0.1641  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.1559  decode.d3.loss_dice: 0.1605  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1580  decode.d4.loss_dice: 0.1633  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.1568  decode.d5.loss_dice: 0.1568  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.1574  decode.d6.loss_dice: 0.1589  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.1546  decode.d7.loss_dice: 0.1609  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.1559  decode.d8.loss_dice: 0.1603
09/30 21:54:33 - mmengine - INFO - Iter(train) [105750/320000]  base_lr: 6.9694e-05 lr: 6.9694e-06  eta: 1 day, 1:59:50  time: 0.4410  data_time: 0.0098  memory: 5129  grad_norm: 77.4284  loss: 6.3620  decode.loss_cls: 0.0993  decode.loss_mask: 0.2572  decode.loss_dice: 0.1893  decode.d0.loss_cls: 1.0531  decode.d0.loss_mask: 0.2763  decode.d0.loss_dice: 0.1994  decode.d1.loss_cls: 0.0858  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.1818  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.1845  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.1811  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.2639  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.2654  decode.d5.loss_dice: 0.1974  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.2594  decode.d6.loss_dice: 0.1801  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.1794  decode.d8.loss_cls: 0.1016  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.1789
09/30 21:54:56 - mmengine - INFO - Iter(train) [105800/320000]  base_lr: 6.9679e-05 lr: 6.9679e-06  eta: 1 day, 1:59:29  time: 0.4417  data_time: 0.0096  memory: 5129  grad_norm: 34.5022  loss: 4.4167  decode.loss_cls: 0.0185  decode.loss_mask: 0.1778  decode.loss_dice: 0.1561  decode.d0.loss_cls: 0.7731  decode.d0.loss_mask: 0.1832  decode.d0.loss_dice: 0.1547  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.1799  decode.d1.loss_dice: 0.1596  decode.d2.loss_cls: 0.0350  decode.d2.loss_mask: 0.1779  decode.d2.loss_dice: 0.1490  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.1790  decode.d3.loss_dice: 0.1551  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 0.1773  decode.d4.loss_dice: 0.1569  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 0.1792  decode.d5.loss_dice: 0.1539  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.1788  decode.d6.loss_dice: 0.1608  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.1764  decode.d7.loss_dice: 0.1585  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.1778  decode.d8.loss_dice: 0.1565
09/30 21:55:18 - mmengine - INFO - Iter(train) [105850/320000]  base_lr: 6.9665e-05 lr: 6.9665e-06  eta: 1 day, 1:59:07  time: 0.4420  data_time: 0.0098  memory: 5120  grad_norm: 34.5810  loss: 5.5092  decode.loss_cls: 0.1363  decode.loss_mask: 0.1997  decode.loss_dice: 0.1634  decode.d0.loss_cls: 0.7260  decode.d0.loss_mask: 0.1978  decode.d0.loss_dice: 0.1679  decode.d1.loss_cls: 0.1293  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.1272  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1564  decode.d3.loss_cls: 0.1395  decode.d3.loss_mask: 0.2005  decode.d3.loss_dice: 0.1579  decode.d4.loss_cls: 0.1269  decode.d4.loss_mask: 0.1979  decode.d4.loss_dice: 0.1595  decode.d5.loss_cls: 0.1426  decode.d5.loss_mask: 0.1978  decode.d5.loss_dice: 0.1576  decode.d6.loss_cls: 0.1468  decode.d6.loss_mask: 0.1984  decode.d6.loss_dice: 0.1621  decode.d7.loss_cls: 0.1089  decode.d7.loss_mask: 0.1994  decode.d7.loss_dice: 0.1634  decode.d8.loss_cls: 0.1242  decode.d8.loss_mask: 0.1978  decode.d8.loss_dice: 0.1619
09/30 21:55:40 - mmengine - INFO - Iter(train) [105900/320000]  base_lr: 6.9650e-05 lr: 6.9650e-06  eta: 1 day, 1:58:46  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 24.3069  loss: 5.7888  decode.loss_cls: 0.0047  decode.loss_mask: 0.2261  decode.loss_dice: 0.2652  decode.d0.loss_cls: 0.7913  decode.d0.loss_mask: 0.2269  decode.d0.loss_dice: 0.2633  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2633  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.2726  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.2545  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2272  decode.d4.loss_dice: 0.2543  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.2284  decode.d8.loss_dice: 0.2654
09/30 21:56:02 - mmengine - INFO - Iter(train) [105950/320000]  base_lr: 6.9635e-05 lr: 6.9635e-06  eta: 1 day, 1:58:24  time: 0.4403  data_time: 0.0095  memory: 5129  grad_norm: 30.5302  loss: 4.4278  decode.loss_cls: 0.0044  decode.loss_mask: 0.2071  decode.loss_dice: 0.1545  decode.d0.loss_cls: 0.7548  decode.d0.loss_mask: 0.2066  decode.d0.loss_dice: 0.1569  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.1579  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.1546  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.2090  decode.d3.loss_dice: 0.1539  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.2065  decode.d4.loss_dice: 0.1533  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.2068  decode.d5.loss_dice: 0.1532  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.1562  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2084  decode.d7.loss_dice: 0.1557  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.2107  decode.d8.loss_dice: 0.1570
09/30 21:56:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 21:56:24 - mmengine - INFO - Iter(train) [106000/320000]  base_lr: 6.9621e-05 lr: 6.9621e-06  eta: 1 day, 1:58:03  time: 0.4403  data_time: 0.0097  memory: 5120  grad_norm: 31.1373  loss: 5.2588  decode.loss_cls: 0.0114  decode.loss_mask: 0.2354  decode.loss_dice: 0.1804  decode.d0.loss_cls: 1.0206  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.1810  decode.d1.loss_cls: 0.0202  decode.d1.loss_mask: 0.2344  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.1909  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.1725  decode.d3.loss_dice: 0.1655  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.2314  decode.d4.loss_dice: 0.1856  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.1824  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.2321  decode.d7.loss_dice: 0.1815  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.1787
09/30 21:56:46 - mmengine - INFO - Iter(train) [106050/320000]  base_lr: 6.9606e-05 lr: 6.9606e-06  eta: 1 day, 1:57:42  time: 0.4416  data_time: 0.0099  memory: 5145  grad_norm: 27.8219  loss: 4.5677  decode.loss_cls: 0.0054  decode.loss_mask: 0.1924  decode.loss_dice: 0.1658  decode.d0.loss_cls: 0.8758  decode.d0.loss_mask: 0.1920  decode.d0.loss_dice: 0.1681  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.1940  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.1934  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.1931  decode.d3.loss_dice: 0.1705  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.1923  decode.d4.loss_dice: 0.1664  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.1637  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.1710  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.1624  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.1929  decode.d8.loss_dice: 0.1709
09/30 21:57:08 - mmengine - INFO - Iter(train) [106100/320000]  base_lr: 6.9591e-05 lr: 6.9591e-06  eta: 1 day, 1:57:20  time: 0.4426  data_time: 0.0097  memory: 5145  grad_norm: 60.5735  loss: 5.1094  decode.loss_cls: 0.0114  decode.loss_mask: 0.2155  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.8316  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.1981  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.2224  decode.d1.loss_dice: 0.2012  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.2179  decode.d2.loss_dice: 0.1951  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.2190  decode.d3.loss_dice: 0.2019  decode.d4.loss_cls: 0.0156  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.1999  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2175  decode.d5.loss_dice: 0.1957  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.2133  decode.d6.loss_dice: 0.1978  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.1967  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.2130  decode.d8.loss_dice: 0.1931
09/30 21:57:30 - mmengine - INFO - Iter(train) [106150/320000]  base_lr: 6.9577e-05 lr: 6.9577e-06  eta: 1 day, 1:56:59  time: 0.4417  data_time: 0.0099  memory: 5129  grad_norm: 47.0286  loss: 5.9012  decode.loss_cls: 0.0926  decode.loss_mask: 0.2417  decode.loss_dice: 0.2097  decode.d0.loss_cls: 0.8676  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.1988  decode.d1.loss_cls: 0.1025  decode.d1.loss_mask: 0.2446  decode.d1.loss_dice: 0.2141  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.2416  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.2396  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.2411  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.2373  decode.d5.loss_dice: 0.2163  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.2405  decode.d6.loss_dice: 0.2232  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.2419  decode.d7.loss_dice: 0.2170  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.2375  decode.d8.loss_dice: 0.2049
09/30 21:57:52 - mmengine - INFO - Iter(train) [106200/320000]  base_lr: 6.9562e-05 lr: 6.9562e-06  eta: 1 day, 1:56:38  time: 0.4425  data_time: 0.0098  memory: 5129  grad_norm: 29.9477  loss: 5.0134  decode.loss_cls: 0.0091  decode.loss_mask: 0.2131  decode.loss_dice: 0.1971  decode.d0.loss_cls: 0.7023  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.2109  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1971  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.2121  decode.d2.loss_dice: 0.1963  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.1853  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.2097  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.2110  decode.d5.loss_dice: 0.1906  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2136  decode.d6.loss_dice: 0.1904  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.2126  decode.d7.loss_dice: 0.2044  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1932
09/30 21:58:14 - mmengine - INFO - Iter(train) [106250/320000]  base_lr: 6.9548e-05 lr: 6.9548e-06  eta: 1 day, 1:56:16  time: 0.4413  data_time: 0.0099  memory: 5129  grad_norm: 59.6696  loss: 5.6790  decode.loss_cls: 0.0403  decode.loss_mask: 0.2274  decode.loss_dice: 0.2059  decode.d0.loss_cls: 0.7741  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2098  decode.d1.loss_cls: 0.0288  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.0951  decode.d2.loss_mask: 0.2289  decode.d2.loss_dice: 0.2012  decode.d3.loss_cls: 0.0373  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2037  decode.d4.loss_cls: 0.0986  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.2000  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.2307  decode.d5.loss_dice: 0.2111  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.2124  decode.d7.loss_cls: 0.0453  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.2103  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2104
09/30 21:58:36 - mmengine - INFO - Iter(train) [106300/320000]  base_lr: 6.9533e-05 lr: 6.9533e-06  eta: 1 day, 1:55:55  time: 0.4418  data_time: 0.0097  memory: 5145  grad_norm: 67.6963  loss: 5.6993  decode.loss_cls: 0.0660  decode.loss_mask: 0.2426  decode.loss_dice: 0.1864  decode.d0.loss_cls: 0.8469  decode.d0.loss_mask: 0.2454  decode.d0.loss_dice: 0.1846  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.2417  decode.d1.loss_dice: 0.1907  decode.d2.loss_cls: 0.0382  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.1901  decode.d3.loss_cls: 0.0862  decode.d3.loss_mask: 0.2426  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.2412  decode.d4.loss_dice: 0.1848  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.2388  decode.d5.loss_dice: 0.1868  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.1849  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.1863
09/30 21:58:58 - mmengine - INFO - Iter(train) [106350/320000]  base_lr: 6.9518e-05 lr: 6.9518e-06  eta: 1 day, 1:55:33  time: 0.4400  data_time: 0.0096  memory: 5129  grad_norm: 63.3378  loss: 8.0102  decode.loss_cls: 0.1475  decode.loss_mask: 0.2880  decode.loss_dice: 0.2614  decode.d0.loss_cls: 1.0087  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.2467  decode.d1.loss_cls: 0.2569  decode.d1.loss_mask: 0.2920  decode.d1.loss_dice: 0.2535  decode.d2.loss_cls: 0.1586  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.1623  decode.d3.loss_mask: 0.3227  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.2491  decode.d5.loss_cls: 0.1506  decode.d5.loss_mask: 0.2811  decode.d5.loss_dice: 0.2453  decode.d6.loss_cls: 0.1744  decode.d6.loss_mask: 0.3001  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.1590  decode.d8.loss_mask: 0.2894  decode.d8.loss_dice: 0.2511
09/30 21:59:20 - mmengine - INFO - Iter(train) [106400/320000]  base_lr: 6.9504e-05 lr: 6.9504e-06  eta: 1 day, 1:55:12  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 22.7592  loss: 4.4976  decode.loss_cls: 0.0016  decode.loss_mask: 0.1959  decode.loss_dice: 0.1751  decode.d0.loss_cls: 0.7888  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.1725  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.1960  decode.d1.loss_dice: 0.1738  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.1966  decode.d2.loss_dice: 0.1696  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.1694  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.1941  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.1961  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.1933  decode.d6.loss_dice: 0.1718  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.1727  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.1948  decode.d8.loss_dice: 0.1743
09/30 21:59:43 - mmengine - INFO - Iter(train) [106450/320000]  base_lr: 6.9489e-05 lr: 6.9489e-06  eta: 1 day, 1:54:51  time: 0.4413  data_time: 0.0099  memory: 5145  grad_norm: 71.4836  loss: 6.3747  decode.loss_cls: 0.0780  decode.loss_mask: 0.1916  decode.loss_dice: 0.2588  decode.d0.loss_cls: 1.0990  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.2786  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.1936  decode.d1.loss_dice: 0.2750  decode.d2.loss_cls: 0.1108  decode.d2.loss_mask: 0.1909  decode.d2.loss_dice: 0.2619  decode.d3.loss_cls: 0.1036  decode.d3.loss_mask: 0.1925  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.0718  decode.d4.loss_mask: 0.1906  decode.d4.loss_dice: 0.2220  decode.d5.loss_cls: 0.0894  decode.d5.loss_mask: 0.1907  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.1925  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.1913  decode.d7.loss_dice: 0.2547  decode.d8.loss_cls: 0.0915  decode.d8.loss_mask: 0.1906  decode.d8.loss_dice: 0.2507
09/30 22:00:05 - mmengine - INFO - Iter(train) [106500/320000]  base_lr: 6.9474e-05 lr: 6.9474e-06  eta: 1 day, 1:54:29  time: 0.4410  data_time: 0.0099  memory: 5145  grad_norm: 163.1976  loss: 8.6907  decode.loss_cls: 0.1454  decode.loss_mask: 0.3503  decode.loss_dice: 0.3028  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.3566  decode.d0.loss_dice: 0.3105  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.3526  decode.d1.loss_dice: 0.2959  decode.d2.loss_cls: 0.0952  decode.d2.loss_mask: 0.3538  decode.d2.loss_dice: 0.3104  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 0.3454  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.2041  decode.d4.loss_mask: 0.3522  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.1598  decode.d5.loss_mask: 0.3497  decode.d5.loss_dice: 0.3037  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.3576  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 0.3566  decode.d7.loss_dice: 0.2785  decode.d8.loss_cls: 0.1628  decode.d8.loss_mask: 0.3625  decode.d8.loss_dice: 0.2968
09/30 22:00:27 - mmengine - INFO - Iter(train) [106550/320000]  base_lr: 6.9460e-05 lr: 6.9460e-06  eta: 1 day, 1:54:08  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 48.5901  loss: 4.8834  decode.loss_cls: 0.0877  decode.loss_mask: 0.1909  decode.loss_dice: 0.1581  decode.d0.loss_cls: 0.7373  decode.d0.loss_mask: 0.1906  decode.d0.loss_dice: 0.1542  decode.d1.loss_cls: 0.0820  decode.d1.loss_mask: 0.1912  decode.d1.loss_dice: 0.1575  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.1576  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.1883  decode.d3.loss_dice: 0.1559  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.1903  decode.d4.loss_dice: 0.1539  decode.d5.loss_cls: 0.0918  decode.d5.loss_mask: 0.1915  decode.d5.loss_dice: 0.1600  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.1906  decode.d6.loss_dice: 0.1600  decode.d7.loss_cls: 0.0709  decode.d7.loss_mask: 0.1879  decode.d7.loss_dice: 0.1589  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 0.1912  decode.d8.loss_dice: 0.1578
09/30 22:00:49 - mmengine - INFO - Iter(train) [106600/320000]  base_lr: 6.9445e-05 lr: 6.9445e-06  eta: 1 day, 1:53:46  time: 0.4413  data_time: 0.0100  memory: 5129  grad_norm: 32.6981  loss: 4.6514  decode.loss_cls: 0.0067  decode.loss_mask: 0.2211  decode.loss_dice: 0.1513  decode.d0.loss_cls: 0.8471  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.1482  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.2198  decode.d1.loss_dice: 0.1534  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.2239  decode.d2.loss_dice: 0.1498  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.2224  decode.d3.loss_dice: 0.1553  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2239  decode.d4.loss_dice: 0.1528  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.2225  decode.d5.loss_dice: 0.1508  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.2199  decode.d6.loss_dice: 0.1514  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.1520  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.2222  decode.d8.loss_dice: 0.1506
09/30 22:01:11 - mmengine - INFO - Iter(train) [106650/320000]  base_lr: 6.9430e-05 lr: 6.9430e-06  eta: 1 day, 1:53:25  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 52.8700  loss: 6.3321  decode.loss_cls: 0.1077  decode.loss_mask: 0.2178  decode.loss_dice: 0.2659  decode.d0.loss_cls: 0.7690  decode.d0.loss_mask: 0.2194  decode.d0.loss_dice: 0.2202  decode.d1.loss_cls: 0.1198  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.2527  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.2190  decode.d3.loss_dice: 0.2677  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.2199  decode.d4.loss_dice: 0.2519  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.2202  decode.d5.loss_dice: 0.2552  decode.d6.loss_cls: 0.0946  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.2209  decode.d7.loss_cls: 0.0998  decode.d7.loss_mask: 0.2156  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.2619
09/30 22:01:33 - mmengine - INFO - Iter(train) [106700/320000]  base_lr: 6.9416e-05 lr: 6.9416e-06  eta: 1 day, 1:53:04  time: 0.4415  data_time: 0.0097  memory: 5129  grad_norm: 110.3028  loss: 7.0498  decode.loss_cls: 0.1246  decode.loss_mask: 0.2238  decode.loss_dice: 0.2561  decode.d0.loss_cls: 1.0475  decode.d0.loss_mask: 0.2409  decode.d0.loss_dice: 0.2572  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.2265  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.1427  decode.d2.loss_mask: 0.2300  decode.d2.loss_dice: 0.2440  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.2260  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1383  decode.d4.loss_mask: 0.2215  decode.d4.loss_dice: 0.2588  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 0.2216  decode.d5.loss_dice: 0.2219  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.2237  decode.d6.loss_dice: 0.2673  decode.d7.loss_cls: 0.1153  decode.d7.loss_mask: 0.2194  decode.d7.loss_dice: 0.2778  decode.d8.loss_cls: 0.2093  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.2600
09/30 22:01:55 - mmengine - INFO - Iter(train) [106750/320000]  base_lr: 6.9401e-05 lr: 6.9401e-06  eta: 1 day, 1:52:42  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 20.9110  loss: 4.2449  decode.loss_cls: 0.0053  decode.loss_mask: 0.1891  decode.loss_dice: 0.1507  decode.d0.loss_cls: 0.7856  decode.d0.loss_mask: 0.1945  decode.d0.loss_dice: 0.1570  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.1883  decode.d1.loss_dice: 0.1502  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.1894  decode.d2.loss_dice: 0.1479  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1893  decode.d3.loss_dice: 0.1503  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.1529  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.1909  decode.d5.loss_dice: 0.1522  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.1904  decode.d6.loss_dice: 0.1491  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.1895  decode.d7.loss_dice: 0.1479  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.1914  decode.d8.loss_dice: 0.1504
09/30 22:02:17 - mmengine - INFO - Iter(train) [106800/320000]  base_lr: 6.9386e-05 lr: 6.9386e-06  eta: 1 day, 1:52:21  time: 0.4408  data_time: 0.0099  memory: 5129  grad_norm: 71.6950  loss: 5.2348  decode.loss_cls: 0.0414  decode.loss_mask: 0.2248  decode.loss_dice: 0.1818  decode.d0.loss_cls: 0.7789  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.1820  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.1761  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.1710  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.2239  decode.d3.loss_dice: 0.1733  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.2230  decode.d4.loss_dice: 0.1774  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.2253  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.1770  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.1837
09/30 22:02:39 - mmengine - INFO - Iter(train) [106850/320000]  base_lr: 6.9372e-05 lr: 6.9372e-06  eta: 1 day, 1:51:59  time: 0.4418  data_time: 0.0098  memory: 5159  grad_norm: 27.6474  loss: 5.8347  decode.loss_cls: 0.0712  decode.loss_mask: 0.2473  decode.loss_dice: 0.1882  decode.d0.loss_cls: 0.9100  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.1909  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.2395  decode.d1.loss_dice: 0.1931  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.2502  decode.d2.loss_dice: 0.1906  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.1912  decode.d4.loss_cls: 0.0684  decode.d4.loss_mask: 0.2382  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.2389  decode.d5.loss_dice: 0.1843  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.2379  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.1883  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.1902
09/30 22:03:01 - mmengine - INFO - Iter(train) [106900/320000]  base_lr: 6.9357e-05 lr: 6.9357e-06  eta: 1 day, 1:51:38  time: 0.4401  data_time: 0.0097  memory: 5145  grad_norm: 64.1085  loss: 6.3375  decode.loss_cls: 0.0626  decode.loss_mask: 0.2495  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.7617  decode.d0.loss_mask: 0.2697  decode.d0.loss_dice: 0.2479  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.2531  decode.d1.loss_dice: 0.2450  decode.d2.loss_cls: 0.0928  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.2424  decode.d3.loss_cls: 0.0729  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2415  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.2556  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.0706  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.2451  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.2546  decode.d6.loss_dice: 0.2441  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.2541  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.2500  decode.d8.loss_dice: 0.2459
09/30 22:03:23 - mmengine - INFO - Iter(train) [106950/320000]  base_lr: 6.9343e-05 lr: 6.9343e-06  eta: 1 day, 1:51:17  time: 0.4404  data_time: 0.0095  memory: 5145  grad_norm: 31.1922  loss: 5.1813  decode.loss_cls: 0.0135  decode.loss_mask: 0.2509  decode.loss_dice: 0.1794  decode.d0.loss_cls: 0.7266  decode.d0.loss_mask: 0.2549  decode.d0.loss_dice: 0.1910  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.2486  decode.d1.loss_dice: 0.1816  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.1839  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.2493  decode.d5.loss_dice: 0.1885  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.2510  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.1834
09/30 22:03:45 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:03:45 - mmengine - INFO - Iter(train) [107000/320000]  base_lr: 6.9328e-05 lr: 6.9328e-06  eta: 1 day, 1:50:55  time: 0.4416  data_time: 0.0097  memory: 5145  grad_norm: 53.8253  loss: 4.7072  decode.loss_cls: 0.0241  decode.loss_mask: 0.1882  decode.loss_dice: 0.1714  decode.d0.loss_cls: 0.8368  decode.d0.loss_mask: 0.1935  decode.d0.loss_dice: 0.1678  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.1930  decode.d1.loss_dice: 0.1744  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.1888  decode.d2.loss_dice: 0.1697  decode.d3.loss_cls: 0.0279  decode.d3.loss_mask: 0.1877  decode.d3.loss_dice: 0.1680  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.1896  decode.d5.loss_dice: 0.1655  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.1890  decode.d6.loss_dice: 0.1653  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.1909  decode.d7.loss_dice: 0.1715  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.1883  decode.d8.loss_dice: 0.1684
09/30 22:04:07 - mmengine - INFO - Iter(train) [107050/320000]  base_lr: 6.9313e-05 lr: 6.9313e-06  eta: 1 day, 1:50:34  time: 0.4409  data_time: 0.0097  memory: 5129  grad_norm: 44.6599  loss: 5.6014  decode.loss_cls: 0.0971  decode.loss_mask: 0.2004  decode.loss_dice: 0.2027  decode.d0.loss_cls: 0.8190  decode.d0.loss_mask: 0.2024  decode.d0.loss_dice: 0.1853  decode.d1.loss_cls: 0.1155  decode.d1.loss_mask: 0.2034  decode.d1.loss_dice: 0.1606  decode.d2.loss_cls: 0.1478  decode.d2.loss_mask: 0.2031  decode.d2.loss_dice: 0.1679  decode.d3.loss_cls: 0.0971  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.2069  decode.d4.loss_cls: 0.1068  decode.d4.loss_mask: 0.2009  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.1148  decode.d5.loss_mask: 0.2017  decode.d5.loss_dice: 0.1924  decode.d6.loss_cls: 0.0831  decode.d6.loss_mask: 0.2002  decode.d6.loss_dice: 0.1563  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.2032  decode.d7.loss_dice: 0.1731  decode.d8.loss_cls: 0.1123  decode.d8.loss_mask: 0.2015  decode.d8.loss_dice: 0.1733
09/30 22:04:30 - mmengine - INFO - Iter(train) [107100/320000]  base_lr: 6.9299e-05 lr: 6.9299e-06  eta: 1 day, 1:50:13  time: 0.4569  data_time: 0.0095  memory: 5159  grad_norm: 32.1299  loss: 5.1991  decode.loss_cls: 0.0783  decode.loss_mask: 0.2032  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.7645  decode.d0.loss_mask: 0.2090  decode.d0.loss_dice: 0.1631  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.2049  decode.d1.loss_dice: 0.1692  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.2060  decode.d2.loss_dice: 0.1682  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.2055  decode.d3.loss_dice: 0.1680  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.2064  decode.d4.loss_dice: 0.1696  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.1656  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.2065  decode.d6.loss_dice: 0.1702  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 0.2043  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.2066  decode.d8.loss_dice: 0.1684
09/30 22:04:52 - mmengine - INFO - Iter(train) [107150/320000]  base_lr: 6.9284e-05 lr: 6.9284e-06  eta: 1 day, 1:49:51  time: 0.4409  data_time: 0.0097  memory: 5129  grad_norm: 45.0870  loss: 5.6300  decode.loss_cls: 0.0399  decode.loss_mask: 0.2168  decode.loss_dice: 0.2377  decode.d0.loss_cls: 0.8533  decode.d0.loss_mask: 0.2196  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.2187  decode.d2.loss_cls: 0.0403  decode.d2.loss_mask: 0.2131  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.2119  decode.d3.loss_dice: 0.2271  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 0.2130  decode.d4.loss_dice: 0.2355  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1901  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.2169  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.2116  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.2249
09/30 22:05:14 - mmengine - INFO - Iter(train) [107200/320000]  base_lr: 6.9269e-05 lr: 6.9269e-06  eta: 1 day, 1:49:30  time: 0.4419  data_time: 0.0100  memory: 5129  grad_norm: 27.6231  loss: 4.2158  decode.loss_cls: 0.0044  decode.loss_mask: 0.1847  decode.loss_dice: 0.1701  decode.d0.loss_cls: 0.7333  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.1528  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.1867  decode.d1.loss_dice: 0.1600  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.1579  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.1817  decode.d3.loss_dice: 0.1617  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1835  decode.d4.loss_dice: 0.1651  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.1825  decode.d5.loss_dice: 0.1524  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.1822  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.1854  decode.d7.loss_dice: 0.1559  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.1874  decode.d8.loss_dice: 0.1616
09/30 22:05:36 - mmengine - INFO - Iter(train) [107250/320000]  base_lr: 6.9255e-05 lr: 6.9255e-06  eta: 1 day, 1:49:08  time: 0.4440  data_time: 0.0099  memory: 5120  grad_norm: 80.2404  loss: 5.9554  decode.loss_cls: 0.0246  decode.loss_mask: 0.2949  decode.loss_dice: 0.1981  decode.d0.loss_cls: 0.7878  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.1960  decode.d1.loss_cls: 0.0283  decode.d1.loss_mask: 0.2980  decode.d1.loss_dice: 0.1996  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.2958  decode.d2.loss_dice: 0.2031  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.2026  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.2970  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.2918  decode.d5.loss_dice: 0.1963  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.2938  decode.d6.loss_dice: 0.1986  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.2971  decode.d7.loss_dice: 0.2007  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.2915  decode.d8.loss_dice: 0.1962
09/30 22:05:58 - mmengine - INFO - Iter(train) [107300/320000]  base_lr: 6.9240e-05 lr: 6.9240e-06  eta: 1 day, 1:48:47  time: 0.4415  data_time: 0.0097  memory: 5145  grad_norm: 37.8388  loss: 5.5982  decode.loss_cls: 0.0171  decode.loss_mask: 0.2616  decode.loss_dice: 0.1905  decode.d0.loss_cls: 0.8553  decode.d0.loss_mask: 0.2698  decode.d0.loss_dice: 0.1916  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.1899  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.1914  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.2643  decode.d3.loss_dice: 0.1909  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2644  decode.d4.loss_dice: 0.1920  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.2633  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.1956  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.2630  decode.d8.loss_dice: 0.1962
09/30 22:06:20 - mmengine - INFO - Iter(train) [107350/320000]  base_lr: 6.9225e-05 lr: 6.9225e-06  eta: 1 day, 1:48:26  time: 0.4432  data_time: 0.0098  memory: 5129  grad_norm: 86.2961  loss: 5.4219  decode.loss_cls: 0.0371  decode.loss_mask: 0.2315  decode.loss_dice: 0.1724  decode.d0.loss_cls: 0.9185  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.1636  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0409  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.1864  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.2317  decode.d3.loss_dice: 0.1820  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.1825  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.1792  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.1857  decode.d7.loss_cls: 0.0558  decode.d7.loss_mask: 0.2330  decode.d7.loss_dice: 0.1763  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.1807
09/30 22:06:42 - mmengine - INFO - Iter(train) [107400/320000]  base_lr: 6.9211e-05 lr: 6.9211e-06  eta: 1 day, 1:48:04  time: 0.4416  data_time: 0.0099  memory: 5129  grad_norm: 42.3400  loss: 4.6864  decode.loss_cls: 0.0163  decode.loss_mask: 0.1927  decode.loss_dice: 0.1912  decode.d0.loss_cls: 0.7854  decode.d0.loss_mask: 0.1973  decode.d0.loss_dice: 0.1828  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.1969  decode.d1.loss_dice: 0.1980  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.1952  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.1929  decode.d3.loss_dice: 0.1962  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.1948  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.1934  decode.d5.loss_dice: 0.1867  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.1933  decode.d6.loss_dice: 0.1862  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.1945  decode.d7.loss_dice: 0.1822  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.1916  decode.d8.loss_dice: 0.1735
09/30 22:07:04 - mmengine - INFO - Iter(train) [107450/320000]  base_lr: 6.9196e-05 lr: 6.9196e-06  eta: 1 day, 1:47:43  time: 0.4437  data_time: 0.0099  memory: 5145  grad_norm: 587.8523  loss: 9.2968  decode.loss_cls: 0.0675  decode.loss_mask: 0.4600  decode.loss_dice: 0.2969  decode.d0.loss_cls: 0.9470  decode.d0.loss_mask: 0.4263  decode.d0.loss_dice: 0.3195  decode.d1.loss_cls: 0.2067  decode.d1.loss_mask: 0.4082  decode.d1.loss_dice: 0.2801  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.4703  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.4654  decode.d3.loss_dice: 0.3098  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.4664  decode.d4.loss_dice: 0.3126  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.4663  decode.d5.loss_dice: 0.2991  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.4625  decode.d6.loss_dice: 0.3129  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.4636  decode.d7.loss_dice: 0.3092  decode.d8.loss_cls: 0.1745  decode.d8.loss_mask: 0.4166  decode.d8.loss_dice: 0.3120
09/30 22:07:26 - mmengine - INFO - Iter(train) [107500/320000]  base_lr: 6.9181e-05 lr: 6.9181e-06  eta: 1 day, 1:47:21  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 74.1156  loss: 4.7594  decode.loss_cls: 0.0247  decode.loss_mask: 0.2100  decode.loss_dice: 0.1558  decode.d0.loss_cls: 0.7846  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.1783  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.2200  decode.d1.loss_dice: 0.1866  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.1585  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.2152  decode.d3.loss_dice: 0.1700  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.2155  decode.d4.loss_dice: 0.1701  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.1613  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2116  decode.d6.loss_dice: 0.1565  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.2138  decode.d7.loss_dice: 0.1817  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.2138  decode.d8.loss_dice: 0.1599
09/30 22:07:48 - mmengine - INFO - Iter(train) [107550/320000]  base_lr: 6.9167e-05 lr: 6.9167e-06  eta: 1 day, 1:47:00  time: 0.4407  data_time: 0.0097  memory: 5129  grad_norm: 42.3213  loss: 5.4106  decode.loss_cls: 0.0815  decode.loss_mask: 0.1858  decode.loss_dice: 0.1822  decode.d0.loss_cls: 0.8324  decode.d0.loss_mask: 0.1915  decode.d0.loss_dice: 0.2084  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.1824  decode.d1.loss_dice: 0.1738  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1833  decode.d3.loss_cls: 0.0903  decode.d3.loss_mask: 0.1855  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.1849  decode.d4.loss_dice: 0.1919  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.2020  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.1853  decode.d6.loss_dice: 0.1810  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.1855  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.0924  decode.d8.loss_mask: 0.1860  decode.d8.loss_dice: 0.2004
09/30 22:08:11 - mmengine - INFO - Iter(train) [107600/320000]  base_lr: 6.9152e-05 lr: 6.9152e-06  eta: 1 day, 1:46:39  time: 0.4406  data_time: 0.0097  memory: 5120  grad_norm: 123.9315  loss: 4.7054  decode.loss_cls: 0.0097  decode.loss_mask: 0.2388  decode.loss_dice: 0.1586  decode.d0.loss_cls: 0.7992  decode.d0.loss_mask: 0.2098  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.1579  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.1558  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.1513  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2144  decode.d4.loss_dice: 0.1539  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.2192  decode.d5.loss_dice: 0.1529  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1554  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.1634  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.2406  decode.d8.loss_dice: 0.1619
09/30 22:08:33 - mmengine - INFO - Iter(train) [107650/320000]  base_lr: 6.9137e-05 lr: 6.9137e-06  eta: 1 day, 1:46:17  time: 0.4428  data_time: 0.0097  memory: 5129  grad_norm: 100.3749  loss: 5.0690  decode.loss_cls: 0.0118  decode.loss_mask: 0.2071  decode.loss_dice: 0.1948  decode.d0.loss_cls: 0.8811  decode.d0.loss_mask: 0.2126  decode.d0.loss_dice: 0.2007  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.2066  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.1942  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.2088  decode.d3.loss_dice: 0.1987  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.2083  decode.d4.loss_dice: 0.1948  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.2086  decode.d5.loss_dice: 0.1937  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.1943  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.2068  decode.d7.loss_dice: 0.1954  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.2095  decode.d8.loss_dice: 0.1944
09/30 22:08:55 - mmengine - INFO - Iter(train) [107700/320000]  base_lr: 6.9123e-05 lr: 6.9123e-06  eta: 1 day, 1:45:56  time: 0.4416  data_time: 0.0096  memory: 5129  grad_norm: 49.3463  loss: 5.6796  decode.loss_cls: 0.0220  decode.loss_mask: 0.2774  decode.loss_dice: 0.1762  decode.d0.loss_cls: 0.9089  decode.d0.loss_mask: 0.2886  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.2841  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.2874  decode.d2.loss_dice: 0.1754  decode.d3.loss_cls: 0.0144  decode.d3.loss_mask: 0.2799  decode.d3.loss_dice: 0.1798  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.2783  decode.d4.loss_dice: 0.1800  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.1800  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.2808  decode.d6.loss_dice: 0.1796  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.2803  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.1829
09/30 22:09:17 - mmengine - INFO - Iter(train) [107750/320000]  base_lr: 6.9108e-05 lr: 6.9108e-06  eta: 1 day, 1:45:35  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 63.7813  loss: 6.1825  decode.loss_cls: 0.1022  decode.loss_mask: 0.2088  decode.loss_dice: 0.2127  decode.d0.loss_cls: 0.8295  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.2180  decode.d1.loss_cls: 0.1620  decode.d1.loss_mask: 0.2086  decode.d1.loss_dice: 0.2018  decode.d2.loss_cls: 0.1150  decode.d2.loss_mask: 0.2157  decode.d2.loss_dice: 0.2140  decode.d3.loss_cls: 0.1346  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.2204  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.2079  decode.d4.loss_dice: 0.2109  decode.d5.loss_cls: 0.1077  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.2212  decode.d6.loss_cls: 0.1159  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2218  decode.d7.loss_cls: 0.0911  decode.d7.loss_mask: 0.2145  decode.d7.loss_dice: 0.2214  decode.d8.loss_cls: 0.1132  decode.d8.loss_mask: 0.2205  decode.d8.loss_dice: 0.2192
09/30 22:09:39 - mmengine - INFO - Iter(train) [107800/320000]  base_lr: 6.9093e-05 lr: 6.9093e-06  eta: 1 day, 1:45:13  time: 0.4419  data_time: 0.0100  memory: 5129  grad_norm: 48.0883  loss: 5.5493  decode.loss_cls: 0.0615  decode.loss_mask: 0.2414  decode.loss_dice: 0.1801  decode.d0.loss_cls: 0.8461  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.1864  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.2461  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.2459  decode.d2.loss_dice: 0.1792  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.2009  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.2409  decode.d5.loss_dice: 0.1882  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.2425  decode.d6.loss_dice: 0.1773  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.2449  decode.d7.loss_dice: 0.1823  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.1833
09/30 22:10:01 - mmengine - INFO - Iter(train) [107850/320000]  base_lr: 6.9079e-05 lr: 6.9079e-06  eta: 1 day, 1:44:52  time: 0.4410  data_time: 0.0098  memory: 5129  grad_norm: 25.2190  loss: 4.3579  decode.loss_cls: 0.0023  decode.loss_mask: 0.2025  decode.loss_dice: 0.1500  decode.d0.loss_cls: 0.7704  decode.d0.loss_mask: 0.2080  decode.d0.loss_dice: 0.1650  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.1987  decode.d1.loss_dice: 0.1508  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.1540  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.1491  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.2039  decode.d4.loss_dice: 0.1522  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.2016  decode.d5.loss_dice: 0.1532  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.1990  decode.d6.loss_dice: 0.1485  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.1492  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.1515
09/30 22:10:23 - mmengine - INFO - Iter(train) [107900/320000]  base_lr: 6.9064e-05 lr: 6.9064e-06  eta: 1 day, 1:44:30  time: 0.4409  data_time: 0.0097  memory: 5129  grad_norm: 27.3234  loss: 4.9359  decode.loss_cls: 0.0091  decode.loss_mask: 0.1980  decode.loss_dice: 0.1990  decode.d0.loss_cls: 0.8611  decode.d0.loss_mask: 0.2000  decode.d0.loss_dice: 0.1907  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.1984  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.1971  decode.d2.loss_dice: 0.1993  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.1976  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.1976  decode.d4.loss_dice: 0.1980  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.1961  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.1982  decode.d6.loss_dice: 0.2020  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.1985  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.1984  decode.d8.loss_dice: 0.1999
09/30 22:10:45 - mmengine - INFO - Iter(train) [107950/320000]  base_lr: 6.9050e-05 lr: 6.9050e-06  eta: 1 day, 1:44:09  time: 0.4410  data_time: 0.0097  memory: 5120  grad_norm: 37.4634  loss: 4.7164  decode.loss_cls: 0.0165  decode.loss_mask: 0.2143  decode.loss_dice: 0.1734  decode.d0.loss_cls: 0.7268  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.1642  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.1701  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.2132  decode.d2.loss_dice: 0.1694  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.2144  decode.d3.loss_dice: 0.1707  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.2143  decode.d4.loss_dice: 0.1702  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.1702  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.2125  decode.d6.loss_dice: 0.1693  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.2138  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.1693
09/30 22:11:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:11:07 - mmengine - INFO - Iter(train) [108000/320000]  base_lr: 6.9035e-05 lr: 6.9035e-06  eta: 1 day, 1:43:48  time: 0.4409  data_time: 0.0097  memory: 5145  grad_norm: 27.6538  loss: 4.4992  decode.loss_cls: 0.0017  decode.loss_mask: 0.2083  decode.loss_dice: 0.1581  decode.d0.loss_cls: 0.7653  decode.d0.loss_mask: 0.2103  decode.d0.loss_dice: 0.1541  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2099  decode.d1.loss_dice: 0.1604  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.2092  decode.d2.loss_dice: 0.1569  decode.d3.loss_cls: 0.0397  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.1577  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2116  decode.d4.loss_dice: 0.1600  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2094  decode.d5.loss_dice: 0.1558  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2069  decode.d6.loss_dice: 0.1542  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1585  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.2083  decode.d8.loss_dice: 0.1587
09/30 22:11:29 - mmengine - INFO - Iter(train) [108050/320000]  base_lr: 6.9020e-05 lr: 6.9020e-06  eta: 1 day, 1:43:26  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 42.6225  loss: 6.5275  decode.loss_cls: 0.0584  decode.loss_mask: 0.2449  decode.loss_dice: 0.2296  decode.d0.loss_cls: 1.0492  decode.d0.loss_mask: 0.2482  decode.d0.loss_dice: 0.2420  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 0.2452  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2329  decode.d3.loss_cls: 0.0755  decode.d3.loss_mask: 0.2400  decode.d3.loss_dice: 0.2423  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.2437  decode.d4.loss_dice: 0.2333  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.2429  decode.d5.loss_dice: 0.2389  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.2324
09/30 22:11:51 - mmengine - INFO - Iter(train) [108100/320000]  base_lr: 6.9006e-05 lr: 6.9006e-06  eta: 1 day, 1:43:05  time: 0.4403  data_time: 0.0096  memory: 5120  grad_norm: 139.1785  loss: 6.3853  decode.loss_cls: 0.0703  decode.loss_mask: 0.3398  decode.loss_dice: 0.2050  decode.d0.loss_cls: 0.9000  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.1844  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.2707  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.2739  decode.d3.loss_dice: 0.1859  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.3061  decode.d4.loss_dice: 0.2088  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.1808  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.1946  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.2930  decode.d7.loss_dice: 0.1936  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.3190  decode.d8.loss_dice: 0.2094
09/30 22:12:13 - mmengine - INFO - Iter(train) [108150/320000]  base_lr: 6.8991e-05 lr: 6.8991e-06  eta: 1 day, 1:42:43  time: 0.4414  data_time: 0.0096  memory: 5129  grad_norm: 207.9864  loss: 5.6003  decode.loss_cls: 0.0538  decode.loss_mask: 0.2099  decode.loss_dice: 0.2119  decode.d0.loss_cls: 0.8931  decode.d0.loss_mask: 0.2092  decode.d0.loss_dice: 0.1865  decode.d1.loss_cls: 0.0419  decode.d1.loss_mask: 0.2056  decode.d1.loss_dice: 0.1959  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.2066  decode.d2.loss_dice: 0.1822  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.2065  decode.d3.loss_dice: 0.1992  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.2069  decode.d4.loss_dice: 0.2079  decode.d5.loss_cls: 0.0810  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1989  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.1976  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.2074  decode.d7.loss_dice: 0.2018  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.2076  decode.d8.loss_dice: 0.2112
09/30 22:12:36 - mmengine - INFO - Iter(train) [108200/320000]  base_lr: 6.8976e-05 lr: 6.8976e-06  eta: 1 day, 1:42:22  time: 0.4413  data_time: 0.0099  memory: 5120  grad_norm: 176.0018  loss: 9.1887  decode.loss_cls: 0.1820  decode.loss_mask: 0.3005  decode.loss_dice: 0.3558  decode.d0.loss_cls: 0.8775  decode.d0.loss_mask: 0.2980  decode.d0.loss_dice: 0.2473  decode.d1.loss_cls: 0.1578  decode.d1.loss_mask: 0.2990  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.1974  decode.d2.loss_mask: 0.2994  decode.d2.loss_dice: 0.3158  decode.d3.loss_cls: 0.2611  decode.d3.loss_mask: 0.2981  decode.d3.loss_dice: 0.3369  decode.d4.loss_cls: 0.2871  decode.d4.loss_mask: 0.3003  decode.d4.loss_dice: 0.3681  decode.d5.loss_cls: 0.2765  decode.d5.loss_mask: 0.3068  decode.d5.loss_dice: 0.3376  decode.d6.loss_cls: 0.2636  decode.d6.loss_mask: 0.2897  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 0.2053  decode.d7.loss_mask: 0.2985  decode.d7.loss_dice: 0.3503  decode.d8.loss_cls: 0.1678  decode.d8.loss_mask: 0.3082  decode.d8.loss_dice: 0.3070
09/30 22:12:58 - mmengine - INFO - Iter(train) [108250/320000]  base_lr: 6.8962e-05 lr: 6.8962e-06  eta: 1 day, 1:42:00  time: 0.4407  data_time: 0.0097  memory: 5120  grad_norm: 55.1149  loss: 6.5763  decode.loss_cls: 0.1191  decode.loss_mask: 0.2702  decode.loss_dice: 0.2171  decode.d0.loss_cls: 0.8235  decode.d0.loss_mask: 0.2782  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.0594  decode.d1.loss_mask: 0.2688  decode.d1.loss_dice: 0.2266  decode.d2.loss_cls: 0.0852  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.2168  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.2737  decode.d3.loss_dice: 0.2182  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 0.2718  decode.d4.loss_dice: 0.2193  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.2707  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 0.2696  decode.d6.loss_dice: 0.2385  decode.d7.loss_cls: 0.1435  decode.d7.loss_mask: 0.2709  decode.d7.loss_dice: 0.2153  decode.d8.loss_cls: 0.0805  decode.d8.loss_mask: 0.2713  decode.d8.loss_dice: 0.2387
09/30 22:13:20 - mmengine - INFO - Iter(train) [108300/320000]  base_lr: 6.8947e-05 lr: 6.8947e-06  eta: 1 day, 1:41:39  time: 0.4406  data_time: 0.0098  memory: 5145  grad_norm: 46.6291  loss: 5.7806  decode.loss_cls: 0.0436  decode.loss_mask: 0.2127  decode.loss_dice: 0.2381  decode.d0.loss_cls: 0.7918  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.2239  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.2393  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.2109  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.2128  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.2143  decode.d4.loss_dice: 0.2555  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.2183  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.2226  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.2142  decode.d7.loss_dice: 0.2269  decode.d8.loss_cls: 0.0367  decode.d8.loss_mask: 0.2112  decode.d8.loss_dice: 0.2349
09/30 22:13:42 - mmengine - INFO - Iter(train) [108350/320000]  base_lr: 6.8932e-05 lr: 6.8932e-06  eta: 1 day, 1:41:17  time: 0.4416  data_time: 0.0096  memory: 5129  grad_norm: 88.9485  loss: 5.7905  decode.loss_cls: 0.0778  decode.loss_mask: 0.1980  decode.loss_dice: 0.1794  decode.d0.loss_cls: 0.8157  decode.d0.loss_mask: 0.2167  decode.d0.loss_dice: 0.2608  decode.d1.loss_cls: 0.1370  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.2204  decode.d2.loss_cls: 0.1224  decode.d2.loss_mask: 0.2018  decode.d2.loss_dice: 0.2097  decode.d3.loss_cls: 0.1213  decode.d3.loss_mask: 0.2023  decode.d3.loss_dice: 0.2045  decode.d4.loss_cls: 0.1022  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.2003  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.1804  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.2070  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.2007  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.1996  decode.d8.loss_dice: 0.2100
09/30 22:14:04 - mmengine - INFO - Iter(train) [108400/320000]  base_lr: 6.8918e-05 lr: 6.8918e-06  eta: 1 day, 1:40:56  time: 0.4416  data_time: 0.0097  memory: 5129  grad_norm: 40.4757  loss: 5.7813  decode.loss_cls: 0.0742  decode.loss_mask: 0.2565  decode.loss_dice: 0.1820  decode.d0.loss_cls: 0.7586  decode.d0.loss_mask: 0.2591  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.2582  decode.d1.loss_dice: 0.2060  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.1872  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.2563  decode.d3.loss_dice: 0.1827  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.2526  decode.d4.loss_dice: 0.1782  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.2580  decode.d5.loss_dice: 0.1835  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.2536  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.2536  decode.d7.loss_dice: 0.1936  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.2559  decode.d8.loss_dice: 0.1833
09/30 22:14:26 - mmengine - INFO - Iter(train) [108450/320000]  base_lr: 6.8903e-05 lr: 6.8903e-06  eta: 1 day, 1:40:35  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 39.2272  loss: 5.2489  decode.loss_cls: 0.0469  decode.loss_mask: 0.2099  decode.loss_dice: 0.1873  decode.d0.loss_cls: 0.8034  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.1971  decode.d1.loss_cls: 0.0490  decode.d1.loss_mask: 0.2187  decode.d1.loss_dice: 0.1881  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.2172  decode.d2.loss_dice: 0.1893  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.2116  decode.d3.loss_dice: 0.1851  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.1871  decode.d5.loss_cls: 0.0394  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.1864  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.2105  decode.d6.loss_dice: 0.1858  decode.d7.loss_cls: 0.0491  decode.d7.loss_mask: 0.2094  decode.d7.loss_dice: 0.1859  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.2082  decode.d8.loss_dice: 0.1853
09/30 22:14:48 - mmengine - INFO - Iter(train) [108500/320000]  base_lr: 6.8888e-05 lr: 6.8888e-06  eta: 1 day, 1:40:13  time: 0.4417  data_time: 0.0099  memory: 5120  grad_norm: 60.8983  loss: 5.7315  decode.loss_cls: 0.0844  decode.loss_mask: 0.2179  decode.loss_dice: 0.1985  decode.d0.loss_cls: 0.8943  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.2090  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.2224  decode.d1.loss_dice: 0.1910  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.2182  decode.d3.loss_dice: 0.2035  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.1070  decode.d5.loss_mask: 0.2132  decode.d5.loss_dice: 0.1526  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.2175  decode.d6.loss_dice: 0.2084  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.2163  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0816  decode.d8.loss_mask: 0.2170  decode.d8.loss_dice: 0.1976
09/30 22:15:10 - mmengine - INFO - Iter(train) [108550/320000]  base_lr: 6.8874e-05 lr: 6.8874e-06  eta: 1 day, 1:39:52  time: 0.4422  data_time: 0.0099  memory: 5129  grad_norm: 44.7293  loss: 6.6666  decode.loss_cls: 0.1045  decode.loss_mask: 0.2320  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.8712  decode.d0.loss_mask: 0.2329  decode.d0.loss_dice: 0.2192  decode.d1.loss_cls: 0.2543  decode.d1.loss_mask: 0.2346  decode.d1.loss_dice: 0.2254  decode.d2.loss_cls: 0.1425  decode.d2.loss_mask: 0.2303  decode.d2.loss_dice: 0.2180  decode.d3.loss_cls: 0.1064  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2177  decode.d4.loss_cls: 0.1640  decode.d4.loss_mask: 0.2354  decode.d4.loss_dice: 0.2110  decode.d5.loss_cls: 0.1639  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.2174  decode.d6.loss_cls: 0.1113  decode.d6.loss_mask: 0.2321  decode.d6.loss_dice: 0.2082  decode.d7.loss_cls: 0.1126  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 0.2344  decode.d8.loss_dice: 0.2352
09/30 22:15:32 - mmengine - INFO - Iter(train) [108600/320000]  base_lr: 6.8859e-05 lr: 6.8859e-06  eta: 1 day, 1:39:31  time: 0.4419  data_time: 0.0096  memory: 5129  grad_norm: 20.3645  loss: 4.4145  decode.loss_cls: 0.0039  decode.loss_mask: 0.2071  decode.loss_dice: 0.1498  decode.d0.loss_cls: 0.7769  decode.d0.loss_mask: 0.2105  decode.d0.loss_dice: 0.1514  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.2094  decode.d1.loss_dice: 0.1486  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.2093  decode.d2.loss_dice: 0.1525  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.2117  decode.d3.loss_dice: 0.1504  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.2074  decode.d4.loss_dice: 0.1454  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.2080  decode.d5.loss_dice: 0.1526  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.2117  decode.d6.loss_dice: 0.1536  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.1506  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2073  decode.d8.loss_dice: 0.1528
09/30 22:15:54 - mmengine - INFO - Iter(train) [108650/320000]  base_lr: 6.8844e-05 lr: 6.8844e-06  eta: 1 day, 1:39:09  time: 0.4420  data_time: 0.0098  memory: 5120  grad_norm: 39.3654  loss: 5.7131  decode.loss_cls: 0.0580  decode.loss_mask: 0.2368  decode.loss_dice: 0.2075  decode.d0.loss_cls: 0.8136  decode.d0.loss_mask: 0.2374  decode.d0.loss_dice: 0.1955  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.1993  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.1978  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2020  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.1911  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.1952  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.2018  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.2372  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.2362  decode.d8.loss_dice: 0.2066
09/30 22:16:17 - mmengine - INFO - Iter(train) [108700/320000]  base_lr: 6.8830e-05 lr: 6.8830e-06  eta: 1 day, 1:38:48  time: 0.4417  data_time: 0.0097  memory: 5129  grad_norm: 28.6344  loss: 4.9788  decode.loss_cls: 0.0097  decode.loss_mask: 0.1795  decode.loss_dice: 0.2044  decode.d0.loss_cls: 0.9894  decode.d0.loss_mask: 0.1802  decode.d0.loss_dice: 0.1910  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.1798  decode.d1.loss_dice: 0.2015  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.1770  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.1785  decode.d3.loss_dice: 0.2006  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.1797  decode.d4.loss_dice: 0.1944  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.1794  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.0429  decode.d6.loss_mask: 0.1815  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.2108  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.1790  decode.d8.loss_dice: 0.2100
09/30 22:16:39 - mmengine - INFO - Iter(train) [108750/320000]  base_lr: 6.8815e-05 lr: 6.8815e-06  eta: 1 day, 1:38:27  time: 0.4607  data_time: 0.0098  memory: 5129  grad_norm: 68.9190  loss: 4.6234  decode.loss_cls: 0.0022  decode.loss_mask: 0.2186  decode.loss_dice: 0.1581  decode.d0.loss_cls: 0.7800  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.1556  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.1631  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.2243  decode.d2.loss_dice: 0.1649  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.2196  decode.d3.loss_dice: 0.1617  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.2198  decode.d4.loss_dice: 0.1581  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.2171  decode.d5.loss_dice: 0.1565  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2189  decode.d6.loss_dice: 0.1576  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.1559  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2206  decode.d8.loss_dice: 0.1565
09/30 22:17:01 - mmengine - INFO - Iter(train) [108800/320000]  base_lr: 6.8800e-05 lr: 6.8800e-06  eta: 1 day, 1:38:06  time: 0.4420  data_time: 0.0098  memory: 5129  grad_norm: 56.9070  loss: 7.2194  decode.loss_cls: 0.0586  decode.loss_mask: 0.3082  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.8095  decode.d0.loss_mask: 0.3154  decode.d0.loss_dice: 0.2400  decode.d1.loss_cls: 0.1369  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.2384  decode.d2.loss_cls: 0.1437  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.2308  decode.d3.loss_cls: 0.1357  decode.d3.loss_mask: 0.2738  decode.d3.loss_dice: 0.2481  decode.d4.loss_cls: 0.1409  decode.d4.loss_mask: 0.2679  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.1398  decode.d5.loss_mask: 0.2671  decode.d5.loss_dice: 0.2420  decode.d6.loss_cls: 0.1392  decode.d6.loss_mask: 0.2794  decode.d6.loss_dice: 0.2289  decode.d7.loss_cls: 0.1183  decode.d7.loss_mask: 0.3670  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.1312  decode.d8.loss_mask: 0.2592  decode.d8.loss_dice: 0.2341
09/30 22:17:23 - mmengine - INFO - Iter(train) [108850/320000]  base_lr: 6.8786e-05 lr: 6.8786e-06  eta: 1 day, 1:37:44  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 116.8331  loss: 5.7425  decode.loss_cls: 0.0805  decode.loss_mask: 0.2465  decode.loss_dice: 0.2300  decode.d0.loss_cls: 0.7375  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.2316  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.2259  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.2047  decode.d3.loss_cls: 0.0419  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.2463  decode.d4.loss_dice: 0.1908  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.2472  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.2463  decode.d6.loss_dice: 0.2061  decode.d7.loss_cls: 0.0264  decode.d7.loss_mask: 0.2479  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.2451  decode.d8.loss_dice: 0.2159
09/30 22:17:45 - mmengine - INFO - Iter(train) [108900/320000]  base_lr: 6.8771e-05 lr: 6.8771e-06  eta: 1 day, 1:37:23  time: 0.4410  data_time: 0.0096  memory: 5129  grad_norm: 21.3324  loss: 4.3997  decode.loss_cls: 0.0044  decode.loss_mask: 0.1959  decode.loss_dice: 0.1406  decode.d0.loss_cls: 0.9138  decode.d0.loss_mask: 0.1993  decode.d0.loss_dice: 0.1444  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.2015  decode.d1.loss_dice: 0.1426  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.2003  decode.d2.loss_dice: 0.1417  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.1432  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.1439  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.2006  decode.d5.loss_dice: 0.1433  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.2008  decode.d6.loss_dice: 0.1413  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2008  decode.d7.loss_dice: 0.1441  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.2015  decode.d8.loss_dice: 0.1422
09/30 22:18:07 - mmengine - INFO - Iter(train) [108950/320000]  base_lr: 6.8756e-05 lr: 6.8756e-06  eta: 1 day, 1:37:01  time: 0.4417  data_time: 0.0098  memory: 5145  grad_norm: 29.3666  loss: 4.3513  decode.loss_cls: 0.0024  decode.loss_mask: 0.2074  decode.loss_dice: 0.1412  decode.d0.loss_cls: 0.8155  decode.d0.loss_mask: 0.2131  decode.d0.loss_dice: 0.1433  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1428  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.1430  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.1406  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.1410  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.2077  decode.d5.loss_dice: 0.1419  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.2087  decode.d6.loss_dice: 0.1432  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.1460  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.2100  decode.d8.loss_dice: 0.1455
09/30 22:18:29 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:18:29 - mmengine - INFO - Iter(train) [109000/320000]  base_lr: 6.8742e-05 lr: 6.8742e-06  eta: 1 day, 1:36:40  time: 0.4436  data_time: 0.0098  memory: 5104  grad_norm: 31.8019  loss: 4.3998  decode.loss_cls: 0.0026  decode.loss_mask: 0.2053  decode.loss_dice: 0.1458  decode.d0.loss_cls: 0.7989  decode.d0.loss_mask: 0.2218  decode.d0.loss_dice: 0.1688  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.2045  decode.d1.loss_dice: 0.1456  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.1480  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.2004  decode.d3.loss_dice: 0.1447  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.2033  decode.d4.loss_dice: 0.1464  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.2066  decode.d5.loss_dice: 0.1483  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.1508  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2035  decode.d7.loss_dice: 0.1473  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.1507
09/30 22:18:51 - mmengine - INFO - Iter(train) [109050/320000]  base_lr: 6.8727e-05 lr: 6.8727e-06  eta: 1 day, 1:36:19  time: 0.4434  data_time: 0.0097  memory: 5129  grad_norm: 27.3334  loss: 5.4886  decode.loss_cls: 0.0350  decode.loss_mask: 0.2089  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.7824  decode.d0.loss_mask: 0.2080  decode.d0.loss_dice: 0.2222  decode.d1.loss_cls: 0.1193  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.2197  decode.d3.loss_cls: 0.0276  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.2213  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.2065  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.2068  decode.d5.loss_dice: 0.2206  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2187  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 0.2088  decode.d7.loss_dice: 0.2256  decode.d8.loss_cls: 0.0239  decode.d8.loss_mask: 0.2092  decode.d8.loss_dice: 0.2194
09/30 22:19:14 - mmengine - INFO - Iter(train) [109100/320000]  base_lr: 6.8712e-05 lr: 6.8712e-06  eta: 1 day, 1:35:57  time: 0.4435  data_time: 0.0097  memory: 5129  grad_norm: 86.9081  loss: 8.0969  decode.loss_cls: 0.2283  decode.loss_mask: 0.2560  decode.loss_dice: 0.2245  decode.d0.loss_cls: 1.0080  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.2123  decode.d1.loss_cls: 0.1373  decode.d1.loss_mask: 0.2888  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.2199  decode.d2.loss_mask: 0.2645  decode.d2.loss_dice: 0.2415  decode.d3.loss_cls: 0.2245  decode.d3.loss_mask: 0.2602  decode.d3.loss_dice: 0.2328  decode.d4.loss_cls: 0.2204  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.2337  decode.d5.loss_mask: 0.3452  decode.d5.loss_dice: 0.2343  decode.d6.loss_cls: 0.1606  decode.d6.loss_mask: 0.3370  decode.d6.loss_dice: 0.2437  decode.d7.loss_cls: 0.1551  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.2355  decode.d8.loss_cls: 0.3066  decode.d8.loss_mask: 0.2533  decode.d8.loss_dice: 0.2302
09/30 22:19:36 - mmengine - INFO - Iter(train) [109150/320000]  base_lr: 6.8698e-05 lr: 6.8698e-06  eta: 1 day, 1:35:36  time: 0.4420  data_time: 0.0099  memory: 5129  grad_norm: 68.1653  loss: 5.5859  decode.loss_cls: 0.0926  decode.loss_mask: 0.1907  decode.loss_dice: 0.1861  decode.d0.loss_cls: 0.9112  decode.d0.loss_mask: 0.1974  decode.d0.loss_dice: 0.1811  decode.d1.loss_cls: 0.1072  decode.d1.loss_mask: 0.1962  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.1872  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.1930  decode.d3.loss_dice: 0.1822  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.1942  decode.d4.loss_dice: 0.1831  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 0.1922  decode.d5.loss_dice: 0.1972  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.1933  decode.d6.loss_dice: 0.1979  decode.d7.loss_cls: 0.0969  decode.d7.loss_mask: 0.1915  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.1948  decode.d8.loss_dice: 0.1902
09/30 22:19:58 - mmengine - INFO - Iter(train) [109200/320000]  base_lr: 6.8683e-05 lr: 6.8683e-06  eta: 1 day, 1:35:15  time: 0.4418  data_time: 0.0099  memory: 5129  grad_norm: 62.7902  loss: 5.6740  decode.loss_cls: 0.0859  decode.loss_mask: 0.2020  decode.loss_dice: 0.2056  decode.d0.loss_cls: 0.8389  decode.d0.loss_mask: 0.2013  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.1117  decode.d1.loss_mask: 0.2091  decode.d1.loss_dice: 0.2054  decode.d2.loss_cls: 0.0943  decode.d2.loss_mask: 0.1980  decode.d2.loss_dice: 0.1941  decode.d3.loss_cls: 0.0977  decode.d3.loss_mask: 0.2077  decode.d3.loss_dice: 0.2011  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.1997  decode.d4.loss_dice: 0.2160  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.1998  decode.d5.loss_dice: 0.2072  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.1968  decode.d6.loss_dice: 0.1851  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.2004  decode.d7.loss_dice: 0.2586  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.1983  decode.d8.loss_dice: 0.1807
09/30 22:20:20 - mmengine - INFO - Iter(train) [109250/320000]  base_lr: 6.8668e-05 lr: 6.8668e-06  eta: 1 day, 1:34:53  time: 0.4416  data_time: 0.0099  memory: 5145  grad_norm: 77.7795  loss: 5.6774  decode.loss_cls: 0.0216  decode.loss_mask: 0.2478  decode.loss_dice: 0.2126  decode.d0.loss_cls: 0.7197  decode.d0.loss_mask: 0.2452  decode.d0.loss_dice: 0.2188  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.2433  decode.d1.loss_dice: 0.2091  decode.d2.loss_cls: 0.0699  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.2148  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.2456  decode.d3.loss_dice: 0.2055  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.2470  decode.d4.loss_dice: 0.2070  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.2475  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.2453  decode.d6.loss_dice: 0.2107  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2064
09/30 22:20:42 - mmengine - INFO - Iter(train) [109300/320000]  base_lr: 6.8654e-05 lr: 6.8654e-06  eta: 1 day, 1:34:32  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 31.4491  loss: 4.8425  decode.loss_cls: 0.0118  decode.loss_mask: 0.2443  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.6817  decode.d0.loss_mask: 0.2449  decode.d0.loss_dice: 0.1565  decode.d1.loss_cls: 0.0179  decode.d1.loss_mask: 0.2420  decode.d1.loss_dice: 0.1588  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2452  decode.d2.loss_dice: 0.1587  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.1582  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.1697  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2435  decode.d5.loss_dice: 0.1596  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.1645  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.1640  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.2437  decode.d8.loss_dice: 0.1626
09/30 22:21:04 - mmengine - INFO - Iter(train) [109350/320000]  base_lr: 6.8639e-05 lr: 6.8639e-06  eta: 1 day, 1:34:11  time: 0.4420  data_time: 0.0100  memory: 5145  grad_norm: 36.7020  loss: 4.6956  decode.loss_cls: 0.0083  decode.loss_mask: 0.1865  decode.loss_dice: 0.1921  decode.d0.loss_cls: 0.8486  decode.d0.loss_mask: 0.1886  decode.d0.loss_dice: 0.1775  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.1892  decode.d1.loss_dice: 0.2043  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.1878  decode.d2.loss_dice: 0.1888  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.1855  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.1853  decode.d4.loss_dice: 0.1902  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.1846  decode.d5.loss_dice: 0.1760  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.1847  decode.d6.loss_dice: 0.1754  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.1844  decode.d7.loss_dice: 0.1841  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.1858  decode.d8.loss_dice: 0.1862
09/30 22:21:26 - mmengine - INFO - Iter(train) [109400/320000]  base_lr: 6.8624e-05 lr: 6.8624e-06  eta: 1 day, 1:33:49  time: 0.4443  data_time: 0.0102  memory: 5129  grad_norm: 56.7443  loss: 7.7506  decode.loss_cls: 0.1505  decode.loss_mask: 0.2248  decode.loss_dice: 0.3063  decode.d0.loss_cls: 0.9150  decode.d0.loss_mask: 0.2211  decode.d0.loss_dice: 0.2886  decode.d1.loss_cls: 0.1770  decode.d1.loss_mask: 0.2185  decode.d1.loss_dice: 0.2890  decode.d2.loss_cls: 0.1730  decode.d2.loss_mask: 0.2179  decode.d2.loss_dice: 0.2785  decode.d3.loss_cls: 0.1307  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.3075  decode.d4.loss_cls: 0.1780  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.3182  decode.d5.loss_cls: 0.1626  decode.d5.loss_mask: 0.2187  decode.d5.loss_dice: 0.3412  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.2712  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 0.2186  decode.d7.loss_dice: 0.2665  decode.d8.loss_cls: 0.2425  decode.d8.loss_mask: 0.2170  decode.d8.loss_dice: 0.2918
09/30 22:21:49 - mmengine - INFO - Iter(train) [109450/320000]  base_lr: 6.8610e-05 lr: 6.8610e-06  eta: 1 day, 1:33:28  time: 0.4435  data_time: 0.0101  memory: 5120  grad_norm: 24.1976  loss: 4.4842  decode.loss_cls: 0.0032  decode.loss_mask: 0.1983  decode.loss_dice: 0.1693  decode.d0.loss_cls: 0.7690  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1637  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.1970  decode.d1.loss_dice: 0.1675  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.2008  decode.d2.loss_dice: 0.1691  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.1998  decode.d3.loss_dice: 0.1683  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.2000  decode.d4.loss_dice: 0.1721  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.1705  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1962  decode.d6.loss_dice: 0.1697  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.1991  decode.d8.loss_dice: 0.1673
09/30 22:22:11 - mmengine - INFO - Iter(train) [109500/320000]  base_lr: 6.8595e-05 lr: 6.8595e-06  eta: 1 day, 1:33:07  time: 0.4433  data_time: 0.0103  memory: 5129  grad_norm: 89.0033  loss: 5.5298  decode.loss_cls: 0.0245  decode.loss_mask: 0.2766  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.6638  decode.d0.loss_mask: 0.2800  decode.d0.loss_dice: 0.1808  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.2759  decode.d1.loss_dice: 0.1851  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.2737  decode.d2.loss_dice: 0.1826  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.2765  decode.d3.loss_dice: 0.1909  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.2739  decode.d5.loss_dice: 0.1976  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.2741  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0192  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.1969  decode.d8.loss_cls: 0.0276  decode.d8.loss_mask: 0.2777  decode.d8.loss_dice: 0.1970
09/30 22:22:33 - mmengine - INFO - Iter(train) [109550/320000]  base_lr: 6.8580e-05 lr: 6.8580e-06  eta: 1 day, 1:32:46  time: 0.4427  data_time: 0.0101  memory: 5120  grad_norm: 40.0188  loss: 5.3864  decode.loss_cls: 0.0079  decode.loss_mask: 0.2490  decode.loss_dice: 0.1891  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.2543  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0270  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.1952  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.1968  decode.d3.loss_cls: 0.0185  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.1849  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.1940  decode.d5.loss_cls: 0.0285  decode.d5.loss_mask: 0.2517  decode.d5.loss_dice: 0.2149  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.2050  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.1968  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.2030
09/30 22:22:55 - mmengine - INFO - Iter(train) [109600/320000]  base_lr: 6.8566e-05 lr: 6.8566e-06  eta: 1 day, 1:32:25  time: 0.4445  data_time: 0.0101  memory: 5145  grad_norm: 87.1702  loss: 7.3638  decode.loss_cls: 0.0916  decode.loss_mask: 0.2967  decode.loss_dice: 0.2494  decode.d0.loss_cls: 0.7591  decode.d0.loss_mask: 0.3038  decode.d0.loss_dice: 0.2444  decode.d1.loss_cls: 0.1461  decode.d1.loss_mask: 0.3002  decode.d1.loss_dice: 0.2579  decode.d2.loss_cls: 0.1366  decode.d2.loss_mask: 0.2989  decode.d2.loss_dice: 0.2535  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 0.3046  decode.d3.loss_dice: 0.2540  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.1300  decode.d5.loss_mask: 0.2990  decode.d5.loss_dice: 0.2617  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.3000  decode.d6.loss_dice: 0.2547  decode.d7.loss_cls: 0.1211  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.2627  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.3007  decode.d8.loss_dice: 0.2595
09/30 22:23:17 - mmengine - INFO - Iter(train) [109650/320000]  base_lr: 6.8551e-05 lr: 6.8551e-06  eta: 1 day, 1:32:03  time: 0.4437  data_time: 0.0100  memory: 5120  grad_norm: 26.3628  loss: 4.6460  decode.loss_cls: 0.0167  decode.loss_mask: 0.2110  decode.loss_dice: 0.1425  decode.d0.loss_cls: 0.9124  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.1431  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.2104  decode.d1.loss_dice: 0.1397  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.1415  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.2088  decode.d3.loss_dice: 0.1414  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.2080  decode.d4.loss_dice: 0.1408  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.2114  decode.d5.loss_dice: 0.1414  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.2102  decode.d6.loss_dice: 0.1456  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.2110  decode.d7.loss_dice: 0.1424  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.2103  decode.d8.loss_dice: 0.1451
09/30 22:23:40 - mmengine - INFO - Iter(train) [109700/320000]  base_lr: 6.8536e-05 lr: 6.8536e-06  eta: 1 day, 1:31:42  time: 0.4412  data_time: 0.0099  memory: 5145  grad_norm: 29.0404  loss: 5.2451  decode.loss_cls: 0.0166  decode.loss_mask: 0.2320  decode.loss_dice: 0.2051  decode.d0.loss_cls: 0.8276  decode.d0.loss_mask: 0.2360  decode.d0.loss_dice: 0.1798  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.2357  decode.d1.loss_dice: 0.1990  decode.d2.loss_cls: 0.0172  decode.d2.loss_mask: 0.2380  decode.d2.loss_dice: 0.1933  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.2304  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.1989  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.1972  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.2334  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.1958
09/30 22:24:02 - mmengine - INFO - Iter(train) [109750/320000]  base_lr: 6.8522e-05 lr: 6.8522e-06  eta: 1 day, 1:31:21  time: 0.4436  data_time: 0.0100  memory: 5145  grad_norm: 42.6267  loss: 6.6267  decode.loss_cls: 0.1564  decode.loss_mask: 0.2295  decode.loss_dice: 0.2347  decode.d0.loss_cls: 0.7877  decode.d0.loss_mask: 0.2309  decode.d0.loss_dice: 0.2058  decode.d1.loss_cls: 0.1273  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.1444  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2239  decode.d3.loss_cls: 0.1756  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.2063  decode.d4.loss_cls: 0.1595  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.2028  decode.d5.loss_cls: 0.1719  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2229  decode.d6.loss_cls: 0.1778  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.2044  decode.d7.loss_cls: 0.1877  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.1864  decode.d8.loss_cls: 0.1937  decode.d8.loss_mask: 0.2273  decode.d8.loss_dice: 0.1617
09/30 22:24:24 - mmengine - INFO - Iter(train) [109800/320000]  base_lr: 6.8507e-05 lr: 6.8507e-06  eta: 1 day, 1:30:59  time: 0.4414  data_time: 0.0098  memory: 5129  grad_norm: 31.6849  loss: 4.9090  decode.loss_cls: 0.0909  decode.loss_mask: 0.1831  decode.loss_dice: 0.1517  decode.d0.loss_cls: 0.7985  decode.d0.loss_mask: 0.1926  decode.d0.loss_dice: 0.1619  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.1822  decode.d1.loss_dice: 0.1502  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.1818  decode.d2.loss_dice: 0.1507  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.1831  decode.d3.loss_dice: 0.1461  decode.d4.loss_cls: 0.0839  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.1503  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.1806  decode.d5.loss_dice: 0.1472  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.2135  decode.d6.loss_dice: 0.1698  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.1898  decode.d7.loss_dice: 0.1575  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.1826  decode.d8.loss_dice: 0.1552
09/30 22:24:46 - mmengine - INFO - Iter(train) [109850/320000]  base_lr: 6.8492e-05 lr: 6.8492e-06  eta: 1 day, 1:30:38  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 53.8619  loss: 5.1085  decode.loss_cls: 0.0303  decode.loss_mask: 0.2110  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.7147  decode.d0.loss_mask: 0.2131  decode.d0.loss_dice: 0.1889  decode.d1.loss_cls: 0.0352  decode.d1.loss_mask: 0.2125  decode.d1.loss_dice: 0.1852  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.1898  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.2127  decode.d3.loss_dice: 0.1749  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1875  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.2114  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.2133  decode.d6.loss_dice: 0.1816  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.2111  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.2127  decode.d8.loss_dice: 0.1739
09/30 22:25:08 - mmengine - INFO - Iter(train) [109900/320000]  base_lr: 6.8478e-05 lr: 6.8478e-06  eta: 1 day, 1:30:17  time: 0.4444  data_time: 0.0102  memory: 5129  grad_norm: 48.9840  loss: 7.1533  decode.loss_cls: 0.1121  decode.loss_mask: 0.2780  decode.loss_dice: 0.2931  decode.d0.loss_cls: 0.8969  decode.d0.loss_mask: 0.2860  decode.d0.loss_dice: 0.2580  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.2788  decode.d1.loss_dice: 0.2764  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.2798  decode.d2.loss_dice: 0.2696  decode.d3.loss_cls: 0.0678  decode.d3.loss_mask: 0.2801  decode.d3.loss_dice: 0.2517  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.2779  decode.d4.loss_dice: 0.2990  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.3093  decode.d6.loss_cls: 0.1003  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.2926  decode.d7.loss_cls: 0.0930  decode.d7.loss_mask: 0.2792  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.0713  decode.d8.loss_mask: 0.2806  decode.d8.loss_dice: 0.2428
09/30 22:25:30 - mmengine - INFO - Iter(train) [109950/320000]  base_lr: 6.8463e-05 lr: 6.8463e-06  eta: 1 day, 1:29:56  time: 0.4435  data_time: 0.0099  memory: 5129  grad_norm: 107.3062  loss: 5.4921  decode.loss_cls: 0.0132  decode.loss_mask: 0.2214  decode.loss_dice: 0.2047  decode.d0.loss_cls: 0.9768  decode.d0.loss_mask: 0.2195  decode.d0.loss_dice: 0.1984  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.2190  decode.d1.loss_dice: 0.2066  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.2134  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.2012  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.2049  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.2009
09/30 22:25:53 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:25:53 - mmengine - INFO - Iter(train) [110000/320000]  base_lr: 6.8448e-05 lr: 6.8448e-06  eta: 1 day, 1:29:34  time: 0.4435  data_time: 0.0099  memory: 5145  grad_norm: 62.3673  loss: 5.9682  decode.loss_cls: 0.0714  decode.loss_mask: 0.2548  decode.loss_dice: 0.1939  decode.d0.loss_cls: 0.8208  decode.d0.loss_mask: 0.2589  decode.d0.loss_dice: 0.2009  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2055  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.2066  decode.d3.loss_cls: 0.0844  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.1842  decode.d5.loss_cls: 0.0965  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.1827  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.2003  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.1976  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.2549  decode.d8.loss_dice: 0.1999
09/30 22:26:15 - mmengine - INFO - Iter(train) [110050/320000]  base_lr: 6.8434e-05 lr: 6.8434e-06  eta: 1 day, 1:29:13  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 135.6129  loss: 7.2591  decode.loss_cls: 0.1096  decode.loss_mask: 0.2676  decode.loss_dice: 0.2879  decode.d0.loss_cls: 0.9278  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.2714  decode.d1.loss_cls: 0.1444  decode.d1.loss_mask: 0.2653  decode.d1.loss_dice: 0.2643  decode.d2.loss_cls: 0.1219  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2836  decode.d3.loss_cls: 0.1002  decode.d3.loss_mask: 0.2648  decode.d3.loss_dice: 0.2669  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.2732  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.1471  decode.d5.loss_mask: 0.2625  decode.d5.loss_dice: 0.2650  decode.d6.loss_cls: 0.0878  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2665  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.2796  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.2661  decode.d8.loss_dice: 0.2508
09/30 22:26:37 - mmengine - INFO - Iter(train) [110100/320000]  base_lr: 6.8419e-05 lr: 6.8419e-06  eta: 1 day, 1:28:52  time: 0.4423  data_time: 0.0098  memory: 5129  grad_norm: 36.3220  loss: 5.2339  decode.loss_cls: 0.0245  decode.loss_mask: 0.2276  decode.loss_dice: 0.1957  decode.d0.loss_cls: 0.7301  decode.d0.loss_mask: 0.2322  decode.d0.loss_dice: 0.1967  decode.d1.loss_cls: 0.0221  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.2304  decode.d2.loss_dice: 0.1887  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.1913  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.1989  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.1951  decode.d7.loss_cls: 0.0238  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.1984
09/30 22:26:59 - mmengine - INFO - Iter(train) [110150/320000]  base_lr: 6.8404e-05 lr: 6.8404e-06  eta: 1 day, 1:28:30  time: 0.4438  data_time: 0.0100  memory: 5129  grad_norm: 36.3640  loss: 3.9431  decode.loss_cls: 0.0115  decode.loss_mask: 0.1680  decode.loss_dice: 0.1307  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 0.1723  decode.d0.loss_dice: 0.1337  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.1698  decode.d1.loss_dice: 0.1290  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.1696  decode.d2.loss_dice: 0.1316  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.1691  decode.d3.loss_dice: 0.1323  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.1689  decode.d4.loss_dice: 0.1320  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.1689  decode.d5.loss_dice: 0.1316  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.1691  decode.d6.loss_dice: 0.1299  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.1692  decode.d7.loss_dice: 0.1317  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.1711  decode.d8.loss_dice: 0.1330
09/30 22:27:21 - mmengine - INFO - Iter(train) [110200/320000]  base_lr: 6.8390e-05 lr: 6.8390e-06  eta: 1 day, 1:28:09  time: 0.4417  data_time: 0.0100  memory: 5129  grad_norm: 62.7734  loss: 5.1959  decode.loss_cls: 0.0169  decode.loss_mask: 0.2244  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.8757  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.1757  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.1818  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.2283  decode.d2.loss_dice: 0.1802  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.1819  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.2284  decode.d4.loss_dice: 0.1845  decode.d5.loss_cls: 0.0259  decode.d5.loss_mask: 0.2302  decode.d5.loss_dice: 0.1819  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.1806  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.2261  decode.d7.loss_dice: 0.1821  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.2269  decode.d8.loss_dice: 0.1833
09/30 22:27:43 - mmengine - INFO - Iter(train) [110250/320000]  base_lr: 6.8375e-05 lr: 6.8375e-06  eta: 1 day, 1:27:48  time: 0.4438  data_time: 0.0101  memory: 5129  grad_norm: 125.6696  loss: 7.6439  decode.loss_cls: 0.1572  decode.loss_mask: 0.3158  decode.loss_dice: 0.2266  decode.d0.loss_cls: 0.9243  decode.d0.loss_mask: 0.3204  decode.d0.loss_dice: 0.2288  decode.d1.loss_cls: 0.1523  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.2155  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.4823  decode.d2.loss_dice: 0.2295  decode.d3.loss_cls: 0.1646  decode.d3.loss_mask: 0.2755  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 0.2807  decode.d4.loss_dice: 0.2097  decode.d5.loss_cls: 0.2128  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.2001  decode.d6.loss_cls: 0.1531  decode.d6.loss_mask: 0.2773  decode.d6.loss_dice: 0.2180  decode.d7.loss_cls: 0.1558  decode.d7.loss_mask: 0.2778  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.1462  decode.d8.loss_mask: 0.2931  decode.d8.loss_dice: 0.2196
09/30 22:28:05 - mmengine - INFO - Iter(train) [110300/320000]  base_lr: 6.8360e-05 lr: 6.8360e-06  eta: 1 day, 1:27:26  time: 0.4428  data_time: 0.0100  memory: 5129  grad_norm: 75.0188  loss: 5.5645  decode.loss_cls: 0.0144  decode.loss_mask: 0.2745  decode.loss_dice: 0.1876  decode.d0.loss_cls: 0.8269  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.2736  decode.d1.loss_dice: 0.1906  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.2795  decode.d2.loss_dice: 0.1896  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.2770  decode.d3.loss_dice: 0.1879  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.2807  decode.d4.loss_dice: 0.1851  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.1870  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.1873  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.2744  decode.d8.loss_dice: 0.1841
09/30 22:28:28 - mmengine - INFO - Iter(train) [110350/320000]  base_lr: 6.8346e-05 lr: 6.8346e-06  eta: 1 day, 1:27:05  time: 0.4439  data_time: 0.0100  memory: 5120  grad_norm: 86.2383  loss: 6.8989  decode.loss_cls: 0.1577  decode.loss_mask: 0.1997  decode.loss_dice: 0.2231  decode.d0.loss_cls: 0.8350  decode.d0.loss_mask: 0.2046  decode.d0.loss_dice: 0.2519  decode.d1.loss_cls: 0.1930  decode.d1.loss_mask: 0.2018  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.2196  decode.d2.loss_mask: 0.2006  decode.d2.loss_dice: 0.2238  decode.d3.loss_cls: 0.1868  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.2220  decode.d4.loss_cls: 0.1899  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2317  decode.d5.loss_cls: 0.2188  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.2298  decode.d6.loss_cls: 0.2275  decode.d6.loss_mask: 0.1988  decode.d6.loss_dice: 0.2361  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.2231  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.2020  decode.d8.loss_dice: 0.2299
09/30 22:28:50 - mmengine - INFO - Iter(train) [110400/320000]  base_lr: 6.8331e-05 lr: 6.8331e-06  eta: 1 day, 1:26:44  time: 0.4611  data_time: 0.0102  memory: 5145  grad_norm: 96.6270  loss: 4.7698  decode.loss_cls: 0.0163  decode.loss_mask: 0.1990  decode.loss_dice: 0.1624  decode.d0.loss_cls: 0.7960  decode.d0.loss_mask: 0.1998  decode.d0.loss_dice: 0.1812  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.1827  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 0.1998  decode.d2.loss_dice: 0.1690  decode.d3.loss_cls: 0.0273  decode.d3.loss_mask: 0.1983  decode.d3.loss_dice: 0.1774  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.1989  decode.d4.loss_dice: 0.1810  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.1993  decode.d5.loss_dice: 0.1665  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.1986  decode.d6.loss_dice: 0.1675  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.1696  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.1999  decode.d8.loss_dice: 0.1705
09/30 22:29:12 - mmengine - INFO - Iter(train) [110450/320000]  base_lr: 6.8316e-05 lr: 6.8316e-06  eta: 1 day, 1:26:23  time: 0.4434  data_time: 0.0099  memory: 5145  grad_norm: 49.2763  loss: 4.8346  decode.loss_cls: 0.0215  decode.loss_mask: 0.1922  decode.loss_dice: 0.1787  decode.d0.loss_cls: 0.8210  decode.d0.loss_mask: 0.1900  decode.d0.loss_dice: 0.1704  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.1920  decode.d1.loss_dice: 0.1745  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.1933  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.1929  decode.d3.loss_dice: 0.1931  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.1943  decode.d4.loss_dice: 0.1979  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 0.1912  decode.d5.loss_dice: 0.1722  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.1924  decode.d6.loss_dice: 0.1765  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.1907  decode.d7.loss_dice: 0.1807  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.1916  decode.d8.loss_dice: 0.1773
09/30 22:29:34 - mmengine - INFO - Iter(train) [110500/320000]  base_lr: 6.8302e-05 lr: 6.8302e-06  eta: 1 day, 1:26:01  time: 0.4416  data_time: 0.0099  memory: 5129  grad_norm: 55.8088  loss: 5.7675  decode.loss_cls: 0.0306  decode.loss_mask: 0.1945  decode.loss_dice: 0.2058  decode.d0.loss_cls: 1.1817  decode.d0.loss_mask: 0.1945  decode.d0.loss_dice: 0.2140  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 0.2038  decode.d1.loss_dice: 0.2078  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.2055  decode.d2.loss_dice: 0.2147  decode.d3.loss_cls: 0.0189  decode.d3.loss_mask: 0.1991  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.2029  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.2156  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.1935  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.1936  decode.d8.loss_dice: 0.2068
09/30 22:29:56 - mmengine - INFO - Iter(train) [110550/320000]  base_lr: 6.8287e-05 lr: 6.8287e-06  eta: 1 day, 1:25:40  time: 0.4417  data_time: 0.0101  memory: 5145  grad_norm: 70.1539  loss: 8.4193  decode.loss_cls: 0.2017  decode.loss_mask: 0.2973  decode.loss_dice: 0.2459  decode.d0.loss_cls: 0.8993  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.2540  decode.d1.loss_cls: 0.2516  decode.d1.loss_mask: 0.2860  decode.d1.loss_dice: 0.2480  decode.d2.loss_cls: 0.2516  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.2197  decode.d3.loss_cls: 0.2482  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.2014  decode.d4.loss_mask: 0.2877  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.2342  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.2466  decode.d6.loss_cls: 0.2532  decode.d6.loss_mask: 0.3205  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.2467  decode.d7.loss_mask: 0.2908  decode.d7.loss_dice: 0.2704  decode.d8.loss_cls: 0.2224  decode.d8.loss_mask: 0.3013  decode.d8.loss_dice: 0.2516
09/30 22:30:18 - mmengine - INFO - Iter(train) [110600/320000]  base_lr: 6.8272e-05 lr: 6.8272e-06  eta: 1 day, 1:25:18  time: 0.4414  data_time: 0.0100  memory: 5129  grad_norm: 24.7288  loss: 4.8887  decode.loss_cls: 0.0367  decode.loss_mask: 0.1747  decode.loss_dice: 0.1912  decode.d0.loss_cls: 0.8354  decode.d0.loss_mask: 0.1767  decode.d0.loss_dice: 0.2083  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.1762  decode.d1.loss_dice: 0.2083  decode.d2.loss_cls: 0.0340  decode.d2.loss_mask: 0.1758  decode.d2.loss_dice: 0.2038  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.1781  decode.d3.loss_dice: 0.1783  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.1771  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.1772  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0345  decode.d6.loss_mask: 0.1774  decode.d6.loss_dice: 0.2001  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.1747  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.1743  decode.d8.loss_dice: 0.1766
09/30 22:30:40 - mmengine - INFO - Iter(train) [110650/320000]  base_lr: 6.8258e-05 lr: 6.8258e-06  eta: 1 day, 1:24:57  time: 0.4418  data_time: 0.0100  memory: 5120  grad_norm: 81.8339  loss: 6.0495  decode.loss_cls: 0.0758  decode.loss_mask: 0.2088  decode.loss_dice: 0.2155  decode.d0.loss_cls: 0.9299  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.2105  decode.d1.loss_dice: 0.2285  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.2056  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.0294  decode.d3.loss_mask: 0.2117  decode.d3.loss_dice: 0.2456  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.2448  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.2434  decode.d6.loss_cls: 0.0580  decode.d6.loss_mask: 0.2106  decode.d6.loss_dice: 0.2570  decode.d7.loss_cls: 0.1231  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2788
09/30 22:31:03 - mmengine - INFO - Iter(train) [110700/320000]  base_lr: 6.8243e-05 lr: 6.8243e-06  eta: 1 day, 1:24:36  time: 0.4417  data_time: 0.0100  memory: 5129  grad_norm: 64.1896  loss: 4.5161  decode.loss_cls: 0.0210  decode.loss_mask: 0.2027  decode.loss_dice: 0.1677  decode.d0.loss_cls: 0.6895  decode.d0.loss_mask: 0.2045  decode.d0.loss_dice: 0.1588  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.1684  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.2022  decode.d2.loss_dice: 0.1688  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.2023  decode.d3.loss_dice: 0.1686  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.1696  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.2041  decode.d5.loss_dice: 0.1696  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.2008  decode.d6.loss_dice: 0.1633  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.2017  decode.d7.loss_dice: 0.1651  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.2012  decode.d8.loss_dice: 0.1653
09/30 22:31:25 - mmengine - INFO - Iter(train) [110750/320000]  base_lr: 6.8228e-05 lr: 6.8228e-06  eta: 1 day, 1:24:14  time: 0.4431  data_time: 0.0101  memory: 5129  grad_norm: 35.8521  loss: 5.2636  decode.loss_cls: 0.0737  decode.loss_mask: 0.2042  decode.loss_dice: 0.1662  decode.d0.loss_cls: 0.8323  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.1659  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.1745  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.2073  decode.d2.loss_dice: 0.1689  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.2049  decode.d3.loss_dice: 0.1680  decode.d4.loss_cls: 0.0699  decode.d4.loss_mask: 0.2056  decode.d4.loss_dice: 0.1691  decode.d5.loss_cls: 0.0757  decode.d5.loss_mask: 0.2061  decode.d5.loss_dice: 0.1691  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.2071  decode.d6.loss_dice: 0.1686  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.2069  decode.d7.loss_dice: 0.1707  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.1736
09/30 22:31:47 - mmengine - INFO - Iter(train) [110800/320000]  base_lr: 6.8214e-05 lr: 6.8214e-06  eta: 1 day, 1:23:53  time: 0.4419  data_time: 0.0100  memory: 5129  grad_norm: 35.4125  loss: 5.4304  decode.loss_cls: 0.0146  decode.loss_mask: 0.2212  decode.loss_dice: 0.2083  decode.d0.loss_cls: 0.8139  decode.d0.loss_mask: 0.2202  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0908  decode.d1.loss_mask: 0.2195  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2061  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.2054  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.2167  decode.d4.loss_dice: 0.1982  decode.d5.loss_cls: 0.0245  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.2142  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.2176  decode.d6.loss_dice: 0.2033  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.2074  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.2178  decode.d8.loss_dice: 0.2107
09/30 22:32:09 - mmengine - INFO - Iter(train) [110850/320000]  base_lr: 6.8199e-05 lr: 6.8199e-06  eta: 1 day, 1:23:32  time: 0.4432  data_time: 0.0101  memory: 5129  grad_norm: 69.0163  loss: 7.6658  decode.loss_cls: 0.1691  decode.loss_mask: 0.2420  decode.loss_dice: 0.2022  decode.d0.loss_cls: 1.0345  decode.d0.loss_mask: 0.3001  decode.d0.loss_dice: 0.2674  decode.d1.loss_cls: 0.1645  decode.d1.loss_mask: 0.2753  decode.d1.loss_dice: 0.2845  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.3265  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.1600  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.2695  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 0.2461  decode.d4.loss_dice: 0.2722  decode.d5.loss_cls: 0.1838  decode.d5.loss_mask: 0.2502  decode.d5.loss_dice: 0.1984  decode.d6.loss_cls: 0.1684  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.2710  decode.d7.loss_cls: 0.1707  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.1819  decode.d8.loss_mask: 0.2443  decode.d8.loss_dice: 0.2458
09/30 22:32:31 - mmengine - INFO - Iter(train) [110900/320000]  base_lr: 6.8184e-05 lr: 6.8184e-06  eta: 1 day, 1:23:10  time: 0.4418  data_time: 0.0101  memory: 5120  grad_norm: 29.0626  loss: 5.0394  decode.loss_cls: 0.0034  decode.loss_mask: 0.2401  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.7625  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.1897  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.1789  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.1764  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.2436  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.1790  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.2397  decode.d8.loss_dice: 0.1773
09/30 22:32:53 - mmengine - INFO - Iter(train) [110950/320000]  base_lr: 6.8170e-05 lr: 6.8170e-06  eta: 1 day, 1:22:49  time: 0.4422  data_time: 0.0101  memory: 5120  grad_norm: 37.7421  loss: 4.6762  decode.loss_cls: 0.0027  decode.loss_mask: 0.2006  decode.loss_dice: 0.1723  decode.d0.loss_cls: 0.8640  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.1933  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.1983  decode.d1.loss_dice: 0.1727  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.1734  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.2021  decode.d3.loss_dice: 0.1747  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1991  decode.d4.loss_dice: 0.1727  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.1829  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2012  decode.d6.loss_dice: 0.1719  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2006  decode.d7.loss_dice: 0.1730  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2030  decode.d8.loss_dice: 0.1698
09/30 22:33:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:33:15 - mmengine - INFO - Iter(train) [111000/320000]  base_lr: 6.8155e-05 lr: 6.8155e-06  eta: 1 day, 1:22:27  time: 0.4424  data_time: 0.0100  memory: 5129  grad_norm: 55.1883  loss: 4.0647  decode.loss_cls: 0.0563  decode.loss_mask: 0.1370  decode.loss_dice: 0.1373  decode.d0.loss_cls: 0.7876  decode.d0.loss_mask: 0.1390  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.1382  decode.d1.loss_dice: 0.1499  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.1372  decode.d2.loss_dice: 0.1563  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.1370  decode.d3.loss_dice: 0.1381  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.1379  decode.d4.loss_dice: 0.1401  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.1375  decode.d5.loss_dice: 0.1359  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.1369  decode.d6.loss_dice: 0.1347  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.1383  decode.d7.loss_dice: 0.1386  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.1381  decode.d8.loss_dice: 0.1351
09/30 22:33:37 - mmengine - INFO - Iter(train) [111050/320000]  base_lr: 6.8140e-05 lr: 6.8140e-06  eta: 1 day, 1:22:06  time: 0.4425  data_time: 0.0101  memory: 5129  grad_norm: 60.9995  loss: 4.4701  decode.loss_cls: 0.0088  decode.loss_mask: 0.2006  decode.loss_dice: 0.1486  decode.d0.loss_cls: 0.8600  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1557  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.1992  decode.d1.loss_dice: 0.1465  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.1494  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.2007  decode.d3.loss_dice: 0.1466  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.1499  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2033  decode.d5.loss_dice: 0.1498  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.1511  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.1526  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.1488
09/30 22:34:00 - mmengine - INFO - Iter(train) [111100/320000]  base_lr: 6.8126e-05 lr: 6.8126e-06  eta: 1 day, 1:21:45  time: 0.4422  data_time: 0.0100  memory: 5120  grad_norm: 48.9813  loss: 7.0681  decode.loss_cls: 0.1152  decode.loss_mask: 0.2715  decode.loss_dice: 0.2158  decode.d0.loss_cls: 0.9855  decode.d0.loss_mask: 0.2760  decode.d0.loss_dice: 0.2191  decode.d1.loss_cls: 0.1384  decode.d1.loss_mask: 0.2740  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.1328  decode.d2.loss_mask: 0.2744  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2107  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 0.2732  decode.d4.loss_dice: 0.2189  decode.d5.loss_cls: 0.1546  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.1301  decode.d6.loss_mask: 0.2721  decode.d6.loss_dice: 0.2215  decode.d7.loss_cls: 0.1013  decode.d7.loss_mask: 0.2758  decode.d7.loss_dice: 0.2215  decode.d8.loss_cls: 0.1091  decode.d8.loss_mask: 0.2743  decode.d8.loss_dice: 0.2203
09/30 22:34:22 - mmengine - INFO - Iter(train) [111150/320000]  base_lr: 6.8111e-05 lr: 6.8111e-06  eta: 1 day, 1:21:23  time: 0.4424  data_time: 0.0102  memory: 5120  grad_norm: 47.5736  loss: 5.0833  decode.loss_cls: 0.0181  decode.loss_mask: 0.2166  decode.loss_dice: 0.1934  decode.d0.loss_cls: 0.8435  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.2029  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.1815  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1868  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.1779  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.2149  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.1833  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.2158  decode.d6.loss_dice: 0.1817  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.2126  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.2169  decode.d8.loss_dice: 0.1875
09/30 22:34:44 - mmengine - INFO - Iter(train) [111200/320000]  base_lr: 6.8096e-05 lr: 6.8096e-06  eta: 1 day, 1:21:02  time: 0.4412  data_time: 0.0102  memory: 5145  grad_norm: 68.7444  loss: 5.6773  decode.loss_cls: 0.0076  decode.loss_mask: 0.2949  decode.loss_dice: 0.1908  decode.d0.loss_cls: 0.7599  decode.d0.loss_mask: 0.3020  decode.d0.loss_dice: 0.1913  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.1910  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.2962  decode.d2.loss_dice: 0.1913  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2944  decode.d3.loss_dice: 0.1915  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.2942  decode.d4.loss_dice: 0.1918  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.1902  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.2949  decode.d6.loss_dice: 0.1925  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.1927  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2951  decode.d8.loss_dice: 0.1912
09/30 22:35:06 - mmengine - INFO - Iter(train) [111250/320000]  base_lr: 6.8082e-05 lr: 6.8082e-06  eta: 1 day, 1:20:41  time: 0.4425  data_time: 0.0100  memory: 5129  grad_norm: 30.1475  loss: 4.9633  decode.loss_cls: 0.0181  decode.loss_mask: 0.2020  decode.loss_dice: 0.1933  decode.d0.loss_cls: 0.7805  decode.d0.loss_mask: 0.2036  decode.d0.loss_dice: 0.1857  decode.d1.loss_cls: 0.1060  decode.d1.loss_mask: 0.2024  decode.d1.loss_dice: 0.1877  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.1974  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.2006  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.2038  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.2015  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.2041  decode.d6.loss_dice: 0.1901  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.2019  decode.d8.loss_dice: 0.1881
09/30 22:35:28 - mmengine - INFO - Iter(train) [111300/320000]  base_lr: 6.8067e-05 lr: 6.8067e-06  eta: 1 day, 1:20:19  time: 0.4419  data_time: 0.0103  memory: 5129  grad_norm: 128.5769  loss: 9.4436  decode.loss_cls: 0.2297  decode.loss_mask: 0.3167  decode.loss_dice: 0.3332  decode.d0.loss_cls: 1.0933  decode.d0.loss_mask: 0.2962  decode.d0.loss_dice: 0.3093  decode.d1.loss_cls: 0.2456  decode.d1.loss_mask: 0.2847  decode.d1.loss_dice: 0.3045  decode.d2.loss_cls: 0.2466  decode.d2.loss_mask: 0.3781  decode.d2.loss_dice: 0.3172  decode.d3.loss_cls: 0.2106  decode.d3.loss_mask: 0.3109  decode.d3.loss_dice: 0.2953  decode.d4.loss_cls: 0.2726  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.2919  decode.d5.loss_cls: 0.2742  decode.d5.loss_mask: 0.2965  decode.d5.loss_dice: 0.3177  decode.d6.loss_cls: 0.2744  decode.d6.loss_mask: 0.3128  decode.d6.loss_dice: 0.2954  decode.d7.loss_cls: 0.2451  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.3096  decode.d8.loss_cls: 0.2299  decode.d8.loss_mask: 0.2806  decode.d8.loss_dice: 0.2944
09/30 22:35:50 - mmengine - INFO - Iter(train) [111350/320000]  base_lr: 6.8052e-05 lr: 6.8052e-06  eta: 1 day, 1:19:58  time: 0.4425  data_time: 0.0099  memory: 5129  grad_norm: 50.8632  loss: 5.8284  decode.loss_cls: 0.1059  decode.loss_mask: 0.1773  decode.loss_dice: 0.2206  decode.d0.loss_cls: 0.8177  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.2188  decode.d1.loss_cls: 0.1209  decode.d1.loss_mask: 0.1800  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.1175  decode.d2.loss_mask: 0.1781  decode.d2.loss_dice: 0.2354  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.1800  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.1802  decode.d4.loss_dice: 0.2384  decode.d5.loss_cls: 0.0781  decode.d5.loss_mask: 0.1798  decode.d5.loss_dice: 0.2323  decode.d6.loss_cls: 0.1050  decode.d6.loss_mask: 0.1831  decode.d6.loss_dice: 0.2323  decode.d7.loss_cls: 0.1166  decode.d7.loss_mask: 0.1793  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.1285  decode.d8.loss_mask: 0.1747  decode.d8.loss_dice: 0.2250
09/30 22:36:12 - mmengine - INFO - Iter(train) [111400/320000]  base_lr: 6.8038e-05 lr: 6.8038e-06  eta: 1 day, 1:19:37  time: 0.4425  data_time: 0.0100  memory: 5129  grad_norm: 50.1319  loss: 6.1461  decode.loss_cls: 0.0658  decode.loss_mask: 0.2560  decode.loss_dice: 0.2241  decode.d0.loss_cls: 0.7137  decode.d0.loss_mask: 0.2598  decode.d0.loss_dice: 0.2159  decode.d1.loss_cls: 0.1090  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2225  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.2550  decode.d2.loss_dice: 0.2286  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2075  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.2584  decode.d4.loss_dice: 0.2168  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.2559  decode.d5.loss_dice: 0.2252  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.2521  decode.d6.loss_dice: 0.2114  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.2551  decode.d7.loss_dice: 0.2200  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.2213
09/30 22:36:34 - mmengine - INFO - Iter(train) [111450/320000]  base_lr: 6.8023e-05 lr: 6.8023e-06  eta: 1 day, 1:19:15  time: 0.4418  data_time: 0.0098  memory: 5129  grad_norm: 47.7773  loss: 6.1782  decode.loss_cls: 0.1403  decode.loss_mask: 0.1808  decode.loss_dice: 0.2526  decode.d0.loss_cls: 0.9056  decode.d0.loss_mask: 0.1790  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.1437  decode.d1.loss_mask: 0.1813  decode.d1.loss_dice: 0.2373  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.1792  decode.d2.loss_dice: 0.2449  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.1810  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.1236  decode.d4.loss_mask: 0.1809  decode.d4.loss_dice: 0.2471  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.2174  decode.d6.loss_cls: 0.1078  decode.d6.loss_mask: 0.1783  decode.d6.loss_dice: 0.2445  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.1821  decode.d7.loss_dice: 0.2734  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.1819  decode.d8.loss_dice: 0.2347
09/30 22:36:57 - mmengine - INFO - Iter(train) [111500/320000]  base_lr: 6.8008e-05 lr: 6.8008e-06  eta: 1 day, 1:18:54  time: 0.4435  data_time: 0.0102  memory: 5145  grad_norm: 20.9663  loss: 4.7517  decode.loss_cls: 0.0012  decode.loss_mask: 0.2131  decode.loss_dice: 0.1816  decode.d0.loss_cls: 0.8219  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2156  decode.d1.loss_dice: 0.1787  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2102  decode.d2.loss_dice: 0.1765  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2116  decode.d3.loss_dice: 0.1792  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.1767  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2138  decode.d5.loss_dice: 0.1802  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2123  decode.d8.loss_dice: 0.1777
09/30 22:37:19 - mmengine - INFO - Iter(train) [111550/320000]  base_lr: 6.7994e-05 lr: 6.7994e-06  eta: 1 day, 1:18:33  time: 0.4429  data_time: 0.0100  memory: 5120  grad_norm: 25.4309  loss: 4.7738  decode.loss_cls: 0.0550  decode.loss_mask: 0.2041  decode.loss_dice: 0.1737  decode.d0.loss_cls: 0.7212  decode.d0.loss_mask: 0.2028  decode.d0.loss_dice: 0.1793  decode.d1.loss_cls: 0.0182  decode.d1.loss_mask: 0.2065  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.2054  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.2085  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.2070  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.1867  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.1712  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2070  decode.d7.loss_dice: 0.1796  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.2030  decode.d8.loss_dice: 0.1669
09/30 22:37:41 - mmengine - INFO - Iter(train) [111600/320000]  base_lr: 6.7979e-05 lr: 6.7979e-06  eta: 1 day, 1:18:11  time: 0.4428  data_time: 0.0099  memory: 5129  grad_norm: 42.4434  loss: 4.6314  decode.loss_cls: 0.0378  decode.loss_mask: 0.1643  decode.loss_dice: 0.1536  decode.d0.loss_cls: 0.9025  decode.d0.loss_mask: 0.1644  decode.d0.loss_dice: 0.1581  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.1632  decode.d1.loss_dice: 0.1432  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 0.1635  decode.d2.loss_dice: 0.1452  decode.d3.loss_cls: 0.1064  decode.d3.loss_mask: 0.1607  decode.d3.loss_dice: 0.1428  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.1629  decode.d4.loss_dice: 0.1483  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.1638  decode.d5.loss_dice: 0.1448  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.1643  decode.d6.loss_dice: 0.1503  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.1655  decode.d7.loss_dice: 0.1558  decode.d8.loss_cls: 0.1020  decode.d8.loss_mask: 0.1650  decode.d8.loss_dice: 0.1458
09/30 22:38:03 - mmengine - INFO - Iter(train) [111650/320000]  base_lr: 6.7964e-05 lr: 6.7964e-06  eta: 1 day, 1:17:50  time: 0.4429  data_time: 0.0099  memory: 5145  grad_norm: 57.2781  loss: 6.8586  decode.loss_cls: 0.1286  decode.loss_mask: 0.2099  decode.loss_dice: 0.2945  decode.d0.loss_cls: 0.8650  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.2837  decode.d1.loss_cls: 0.1486  decode.d1.loss_mask: 0.2075  decode.d1.loss_dice: 0.2615  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.2077  decode.d2.loss_dice: 0.2746  decode.d3.loss_cls: 0.1147  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.2676  decode.d4.loss_cls: 0.1250  decode.d4.loss_mask: 0.2094  decode.d4.loss_dice: 0.2794  decode.d5.loss_cls: 0.1242  decode.d5.loss_mask: 0.2094  decode.d5.loss_dice: 0.2802  decode.d6.loss_cls: 0.1103  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.2729  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.2071  decode.d7.loss_dice: 0.2730  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 0.2169  decode.d8.loss_dice: 0.3058
09/30 22:38:25 - mmengine - INFO - Iter(train) [111700/320000]  base_lr: 6.7950e-05 lr: 6.7950e-06  eta: 1 day, 1:17:29  time: 0.4426  data_time: 0.0098  memory: 5129  grad_norm: 27.8591  loss: 4.6775  decode.loss_cls: 0.0060  decode.loss_mask: 0.2183  decode.loss_dice: 0.1697  decode.d0.loss_cls: 0.7693  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1710  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2170  decode.d1.loss_dice: 0.1656  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.2188  decode.d2.loss_dice: 0.1666  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2198  decode.d3.loss_dice: 0.1678  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.1668  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.1698  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.2187  decode.d6.loss_dice: 0.1690  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.1641  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2192  decode.d8.loss_dice: 0.1661
09/30 22:38:47 - mmengine - INFO - Iter(train) [111750/320000]  base_lr: 6.7935e-05 lr: 6.7935e-06  eta: 1 day, 1:17:07  time: 0.4436  data_time: 0.0100  memory: 5145  grad_norm: 38.3005  loss: 6.2470  decode.loss_cls: 0.1868  decode.loss_mask: 0.1997  decode.loss_dice: 0.1917  decode.d0.loss_cls: 0.9228  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.1682  decode.d1.loss_cls: 0.1683  decode.d1.loss_mask: 0.2026  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.1642  decode.d3.loss_cls: 0.1658  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.1676  decode.d4.loss_cls: 0.1689  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.1755  decode.d5.loss_cls: 0.1540  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.1601  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.1755  decode.d7.loss_cls: 0.1840  decode.d7.loss_mask: 0.2018  decode.d7.loss_dice: 0.1811  decode.d8.loss_cls: 0.2050  decode.d8.loss_mask: 0.2000  decode.d8.loss_dice: 0.1680
09/30 22:39:10 - mmengine - INFO - Iter(train) [111800/320000]  base_lr: 6.7920e-05 lr: 6.7920e-06  eta: 1 day, 1:16:46  time: 0.4418  data_time: 0.0099  memory: 5145  grad_norm: 120.8641  loss: 7.9738  decode.loss_cls: 0.1505  decode.loss_mask: 0.3075  decode.loss_dice: 0.2543  decode.d0.loss_cls: 1.0925  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.2291  decode.d1.loss_cls: 0.2200  decode.d1.loss_mask: 0.3051  decode.d1.loss_dice: 0.2632  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 0.3126  decode.d2.loss_dice: 0.2569  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 0.3139  decode.d3.loss_dice: 0.2389  decode.d4.loss_cls: 0.1928  decode.d4.loss_mask: 0.2742  decode.d4.loss_dice: 0.2124  decode.d5.loss_cls: 0.1300  decode.d5.loss_mask: 0.3102  decode.d5.loss_dice: 0.2397  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.3101  decode.d6.loss_dice: 0.2334  decode.d7.loss_cls: 0.1588  decode.d7.loss_mask: 0.3102  decode.d7.loss_dice: 0.2500  decode.d8.loss_cls: 0.1358  decode.d8.loss_mask: 0.3081  decode.d8.loss_dice: 0.2694
09/30 22:39:32 - mmengine - INFO - Iter(train) [111850/320000]  base_lr: 6.7906e-05 lr: 6.7906e-06  eta: 1 day, 1:16:25  time: 0.4417  data_time: 0.0101  memory: 5129  grad_norm: 34.8706  loss: 4.6791  decode.loss_cls: 0.0037  decode.loss_mask: 0.2101  decode.loss_dice: 0.1742  decode.d0.loss_cls: 0.7744  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.1793  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.1735  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.1780  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.2111  decode.d3.loss_dice: 0.1739  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.2142  decode.d4.loss_dice: 0.1757  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.2129  decode.d5.loss_dice: 0.1749  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.2089  decode.d6.loss_dice: 0.1733  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2118  decode.d8.loss_dice: 0.1746
09/30 22:39:54 - mmengine - INFO - Iter(train) [111900/320000]  base_lr: 6.7891e-05 lr: 6.7891e-06  eta: 1 day, 1:16:03  time: 0.4427  data_time: 0.0101  memory: 5129  grad_norm: 55.5276  loss: 7.2343  decode.loss_cls: 0.1565  decode.loss_mask: 0.2689  decode.loss_dice: 0.2420  decode.d0.loss_cls: 0.8109  decode.d0.loss_mask: 0.3181  decode.d0.loss_dice: 0.2316  decode.d1.loss_cls: 0.1769  decode.d1.loss_mask: 0.2352  decode.d1.loss_dice: 0.2306  decode.d2.loss_cls: 0.1709  decode.d2.loss_mask: 0.2383  decode.d2.loss_dice: 0.2257  decode.d3.loss_cls: 0.2086  decode.d3.loss_mask: 0.2433  decode.d3.loss_dice: 0.2270  decode.d4.loss_cls: 0.1640  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2284  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2308  decode.d7.loss_cls: 0.1765  decode.d7.loss_mask: 0.2592  decode.d7.loss_dice: 0.2320  decode.d8.loss_cls: 0.1578  decode.d8.loss_mask: 0.2555  decode.d8.loss_dice: 0.2374
09/30 22:40:16 - mmengine - INFO - Iter(train) [111950/320000]  base_lr: 6.7876e-05 lr: 6.7876e-06  eta: 1 day, 1:15:42  time: 0.4439  data_time: 0.0101  memory: 5129  grad_norm: 41.4085  loss: 4.5586  decode.loss_cls: 0.0371  decode.loss_mask: 0.1985  decode.loss_dice: 0.1543  decode.d0.loss_cls: 0.7671  decode.d0.loss_mask: 0.2022  decode.d0.loss_dice: 0.1551  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.1533  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.1520  decode.d3.loss_cls: 0.0238  decode.d3.loss_mask: 0.2014  decode.d3.loss_dice: 0.1537  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.2020  decode.d4.loss_dice: 0.1567  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.1562  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.1976  decode.d6.loss_dice: 0.1510  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.1558  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.1573
09/30 22:40:38 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:40:38 - mmengine - INFO - Iter(train) [112000/320000]  base_lr: 6.7861e-05 lr: 6.7861e-06  eta: 1 day, 1:15:21  time: 0.4445  data_time: 0.0102  memory: 5129  grad_norm: 65.4932  loss: 4.6858  decode.loss_cls: 0.0023  decode.loss_mask: 0.2050  decode.loss_dice: 0.1755  decode.d0.loss_cls: 0.8220  decode.d0.loss_mask: 0.2077  decode.d0.loss_dice: 0.1698  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1715  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.2121  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.1820  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.2057  decode.d4.loss_dice: 0.1796  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.2080  decode.d5.loss_dice: 0.1756  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2070  decode.d8.loss_dice: 0.1781
09/30 22:41:01 - mmengine - INFO - Iter(train) [112050/320000]  base_lr: 6.7847e-05 lr: 6.7847e-06  eta: 1 day, 1:15:00  time: 0.4585  data_time: 0.0101  memory: 5104  grad_norm: 64.9776  loss: 6.8486  decode.loss_cls: 0.0395  decode.loss_mask: 0.2991  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.9448  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.2385  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.3047  decode.d1.loss_dice: 0.2494  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.2470  decode.d3.loss_cls: 0.0536  decode.d3.loss_mask: 0.3017  decode.d3.loss_dice: 0.2444  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.2364  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.0359  decode.d8.loss_mask: 0.2980  decode.d8.loss_dice: 0.2432
09/30 22:41:23 - mmengine - INFO - Iter(train) [112100/320000]  base_lr: 6.7832e-05 lr: 6.7832e-06  eta: 1 day, 1:14:38  time: 0.4422  data_time: 0.0095  memory: 5120  grad_norm: 174.3050  loss: 6.2958  decode.loss_cls: 0.0572  decode.loss_mask: 0.2099  decode.loss_dice: 0.2482  decode.d0.loss_cls: 0.9783  decode.d0.loss_mask: 0.2112  decode.d0.loss_dice: 0.2038  decode.d1.loss_cls: 0.1972  decode.d1.loss_mask: 0.2123  decode.d1.loss_dice: 0.2115  decode.d2.loss_cls: 0.1462  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.2045  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.2111  decode.d4.loss_dice: 0.2021  decode.d5.loss_cls: 0.1013  decode.d5.loss_mask: 0.2126  decode.d5.loss_dice: 0.2033  decode.d6.loss_cls: 0.0961  decode.d6.loss_mask: 0.2132  decode.d6.loss_dice: 0.2166  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.2240  decode.d8.loss_cls: 0.0940  decode.d8.loss_mask: 0.2093  decode.d8.loss_dice: 0.2369
09/30 22:41:45 - mmengine - INFO - Iter(train) [112150/320000]  base_lr: 6.7817e-05 lr: 6.7817e-06  eta: 1 day, 1:14:17  time: 0.4411  data_time: 0.0096  memory: 5145  grad_norm: 74.7357  loss: 5.9803  decode.loss_cls: 0.0168  decode.loss_mask: 0.3194  decode.loss_dice: 0.2033  decode.d0.loss_cls: 0.6078  decode.d0.loss_mask: 0.3336  decode.d0.loss_dice: 0.2014  decode.d1.loss_cls: 0.0205  decode.d1.loss_mask: 0.3261  decode.d1.loss_dice: 0.2058  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.2046  decode.d3.loss_cls: 0.0102  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.2050  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.3217  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.3152  decode.d5.loss_dice: 0.2006  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.3194  decode.d6.loss_dice: 0.2025  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.3222  decode.d7.loss_dice: 0.2006  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.3230  decode.d8.loss_dice: 0.2027
09/30 22:42:07 - mmengine - INFO - Iter(train) [112200/320000]  base_lr: 6.7803e-05 lr: 6.7803e-06  eta: 1 day, 1:13:56  time: 0.4453  data_time: 0.0100  memory: 5129  grad_norm: 73.2467  loss: 6.7893  decode.loss_cls: 0.1005  decode.loss_mask: 0.2378  decode.loss_dice: 0.2506  decode.d0.loss_cls: 0.6196  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.3111  decode.d1.loss_cls: 0.1797  decode.d1.loss_mask: 0.2374  decode.d1.loss_dice: 0.2781  decode.d2.loss_cls: 0.1480  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.2321  decode.d3.loss_cls: 0.1387  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.2376  decode.d4.loss_cls: 0.1410  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2606  decode.d5.loss_cls: 0.1584  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.2573  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 0.2404  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.2382  decode.d8.loss_cls: 0.1331  decode.d8.loss_mask: 0.2388  decode.d8.loss_dice: 0.2620
09/30 22:42:29 - mmengine - INFO - Iter(train) [112250/320000]  base_lr: 6.7788e-05 lr: 6.7788e-06  eta: 1 day, 1:13:34  time: 0.4431  data_time: 0.0097  memory: 5145  grad_norm: 72.9222  loss: 7.5531  decode.loss_cls: 0.1534  decode.loss_mask: 0.2401  decode.loss_dice: 0.3173  decode.d0.loss_cls: 0.8237  decode.d0.loss_mask: 0.2368  decode.d0.loss_dice: 0.3107  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 0.2370  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.1675  decode.d2.loss_mask: 0.2360  decode.d2.loss_dice: 0.2836  decode.d3.loss_cls: 0.1568  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.3213  decode.d4.loss_cls: 0.1169  decode.d4.loss_mask: 0.2394  decode.d4.loss_dice: 0.3047  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.2382  decode.d5.loss_dice: 0.3362  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.2374  decode.d7.loss_dice: 0.3056  decode.d8.loss_cls: 0.1187  decode.d8.loss_mask: 0.2400  decode.d8.loss_dice: 0.3190
09/30 22:42:51 - mmengine - INFO - Iter(train) [112300/320000]  base_lr: 6.7773e-05 lr: 6.7773e-06  eta: 1 day, 1:13:13  time: 0.4452  data_time: 0.0102  memory: 5129  grad_norm: 56.8637  loss: 5.7475  decode.loss_cls: 0.0222  decode.loss_mask: 0.2664  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.8599  decode.d0.loss_mask: 0.2702  decode.d0.loss_dice: 0.1982  decode.d1.loss_cls: 0.0439  decode.d1.loss_mask: 0.2666  decode.d1.loss_dice: 0.2037  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.2646  decode.d2.loss_dice: 0.1925  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.2692  decode.d3.loss_dice: 0.1967  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.2659  decode.d4.loss_dice: 0.1972  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.2650  decode.d5.loss_dice: 0.1971  decode.d6.loss_cls: 0.0247  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.1937  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.2669  decode.d7.loss_dice: 0.1954  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.1953
09/30 22:43:14 - mmengine - INFO - Iter(train) [112350/320000]  base_lr: 6.7759e-05 lr: 6.7759e-06  eta: 1 day, 1:12:52  time: 0.4431  data_time: 0.0097  memory: 5129  grad_norm: 27.1434  loss: 4.7122  decode.loss_cls: 0.0084  decode.loss_mask: 0.2126  decode.loss_dice: 0.1711  decode.d0.loss_cls: 0.7735  decode.d0.loss_mask: 0.2172  decode.d0.loss_dice: 0.1670  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.2138  decode.d1.loss_dice: 0.1723  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.1668  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.1723  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.2136  decode.d4.loss_dice: 0.1727  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1739  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2150  decode.d6.loss_dice: 0.1733  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2108  decode.d7.loss_dice: 0.1697  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.1711
09/30 22:43:36 - mmengine - INFO - Iter(train) [112400/320000]  base_lr: 6.7744e-05 lr: 6.7744e-06  eta: 1 day, 1:12:31  time: 0.4442  data_time: 0.0098  memory: 5120  grad_norm: 46.4149  loss: 5.7397  decode.loss_cls: 0.0268  decode.loss_mask: 0.2648  decode.loss_dice: 0.2124  decode.d0.loss_cls: 0.6967  decode.d0.loss_mask: 0.2672  decode.d0.loss_dice: 0.2069  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.2096  decode.d2.loss_cls: 0.0298  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.1973  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.2646  decode.d3.loss_dice: 0.2039  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.2644  decode.d4.loss_dice: 0.2104  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.2046  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 0.2662  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.0256  decode.d8.loss_mask: 0.2635  decode.d8.loss_dice: 0.2121
09/30 22:43:58 - mmengine - INFO - Iter(train) [112450/320000]  base_lr: 6.7729e-05 lr: 6.7729e-06  eta: 1 day, 1:12:09  time: 0.4430  data_time: 0.0098  memory: 5145  grad_norm: 38.4713  loss: 5.6719  decode.loss_cls: 0.0308  decode.loss_mask: 0.2514  decode.loss_dice: 0.1989  decode.d0.loss_cls: 0.7497  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.2058  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2135  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.2058  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.2558  decode.d4.loss_dice: 0.2097  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.2519  decode.d5.loss_dice: 0.2025  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.2493  decode.d6.loss_dice: 0.2051  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.2141  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.2514  decode.d8.loss_dice: 0.2129
09/30 22:44:20 - mmengine - INFO - Iter(train) [112500/320000]  base_lr: 6.7715e-05 lr: 6.7715e-06  eta: 1 day, 1:11:48  time: 0.4437  data_time: 0.0097  memory: 5145  grad_norm: 59.8149  loss: 5.7470  decode.loss_cls: 0.0530  decode.loss_mask: 0.2288  decode.loss_dice: 0.2152  decode.d0.loss_cls: 0.7414  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.2244  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.2178  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.2298  decode.d4.loss_dice: 0.2255  decode.d5.loss_cls: 0.0556  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.2123  decode.d6.loss_cls: 0.0364  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2230  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.2295  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.2284  decode.d8.loss_dice: 0.2223
09/30 22:44:42 - mmengine - INFO - Iter(train) [112550/320000]  base_lr: 6.7700e-05 lr: 6.7700e-06  eta: 1 day, 1:11:27  time: 0.4417  data_time: 0.0096  memory: 5119  grad_norm: 37.9940  loss: 4.9163  decode.loss_cls: 0.0211  decode.loss_mask: 0.1834  decode.loss_dice: 0.1686  decode.d0.loss_cls: 0.9176  decode.d0.loss_mask: 0.1831  decode.d0.loss_dice: 0.1567  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.1596  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.1840  decode.d2.loss_dice: 0.1623  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.1821  decode.d3.loss_dice: 0.1632  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.1610  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.1818  decode.d5.loss_dice: 0.1595  decode.d6.loss_cls: 0.0851  decode.d6.loss_mask: 0.1802  decode.d6.loss_dice: 0.1647  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.1842  decode.d7.loss_dice: 0.1641  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.1820  decode.d8.loss_dice: 0.1674
09/30 22:45:04 - mmengine - INFO - Iter(train) [112600/320000]  base_lr: 6.7685e-05 lr: 6.7685e-06  eta: 1 day, 1:11:05  time: 0.4417  data_time: 0.0098  memory: 5129  grad_norm: 39.8187  loss: 4.9427  decode.loss_cls: 0.0020  decode.loss_mask: 0.2361  decode.loss_dice: 0.1785  decode.d0.loss_cls: 0.7091  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.2404  decode.d1.loss_dice: 0.1862  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.1816  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.1793  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1832  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2358  decode.d7.loss_dice: 0.1767  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.1778
09/30 22:45:27 - mmengine - INFO - Iter(train) [112650/320000]  base_lr: 6.7671e-05 lr: 6.7671e-06  eta: 1 day, 1:10:44  time: 0.4423  data_time: 0.0098  memory: 5129  grad_norm: 46.5177  loss: 5.1407  decode.loss_cls: 0.0596  decode.loss_mask: 0.2028  decode.loss_dice: 0.1862  decode.d0.loss_cls: 0.7570  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.1837  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2095  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.2069  decode.d2.loss_dice: 0.1797  decode.d3.loss_cls: 0.0404  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.1951  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.2057  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.2067  decode.d5.loss_dice: 0.1956  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.2024  decode.d6.loss_dice: 0.1839  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.2068  decode.d7.loss_dice: 0.1838  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.2041  decode.d8.loss_dice: 0.1861
09/30 22:45:49 - mmengine - INFO - Iter(train) [112700/320000]  base_lr: 6.7656e-05 lr: 6.7656e-06  eta: 1 day, 1:10:23  time: 0.4413  data_time: 0.0097  memory: 5145  grad_norm: 41.7097  loss: 4.7731  decode.loss_cls: 0.0023  decode.loss_mask: 0.2019  decode.loss_dice: 0.1865  decode.d0.loss_cls: 0.8260  decode.d0.loss_mask: 0.2039  decode.d0.loss_dice: 0.1838  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.1927  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.2015  decode.d2.loss_dice: 0.1872  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.1882  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.1880  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2033  decode.d5.loss_dice: 0.1872  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2032  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.1782  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.1891
09/30 22:46:11 - mmengine - INFO - Iter(train) [112750/320000]  base_lr: 6.7641e-05 lr: 6.7641e-06  eta: 1 day, 1:10:01  time: 0.4423  data_time: 0.0099  memory: 5129  grad_norm: 19.4300  loss: 3.9031  decode.loss_cls: 0.0103  decode.loss_mask: 0.1590  decode.loss_dice: 0.1383  decode.d0.loss_cls: 0.8454  decode.d0.loss_mask: 0.1603  decode.d0.loss_dice: 0.1360  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.1573  decode.d1.loss_dice: 0.1378  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.1598  decode.d2.loss_dice: 0.1379  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.1596  decode.d3.loss_dice: 0.1370  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.1586  decode.d4.loss_dice: 0.1367  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.1586  decode.d5.loss_dice: 0.1351  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.1572  decode.d6.loss_dice: 0.1370  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.1584  decode.d7.loss_dice: 0.1386  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.1564  decode.d8.loss_dice: 0.1339
09/30 22:46:33 - mmengine - INFO - Iter(train) [112800/320000]  base_lr: 6.7627e-05 lr: 6.7627e-06  eta: 1 day, 1:09:40  time: 0.4404  data_time: 0.0095  memory: 5120  grad_norm: 24.8486  loss: 4.1015  decode.loss_cls: 0.0036  decode.loss_mask: 0.1799  decode.loss_dice: 0.1591  decode.d0.loss_cls: 0.7017  decode.d0.loss_mask: 0.1817  decode.d0.loss_dice: 0.1489  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.1787  decode.d1.loss_dice: 0.1543  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.1807  decode.d2.loss_dice: 0.1545  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1799  decode.d3.loss_dice: 0.1564  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.1826  decode.d4.loss_dice: 0.1616  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.1581  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.1797  decode.d6.loss_dice: 0.1551  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.1793  decode.d7.loss_dice: 0.1551  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1791  decode.d8.loss_dice: 0.1547
09/30 22:46:55 - mmengine - INFO - Iter(train) [112850/320000]  base_lr: 6.7612e-05 lr: 6.7612e-06  eta: 1 day, 1:09:18  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 54.0443  loss: 5.2593  decode.loss_cls: 0.0922  decode.loss_mask: 0.1844  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.8191  decode.d0.loss_mask: 0.1842  decode.d0.loss_dice: 0.1756  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.1859  decode.d1.loss_dice: 0.1859  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.1868  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.1850  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.1913  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1889  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.1853  decode.d6.loss_dice: 0.1938  decode.d7.loss_cls: 0.1061  decode.d7.loss_mask: 0.1846  decode.d7.loss_dice: 0.1866  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.1847  decode.d8.loss_dice: 0.1885
09/30 22:47:17 - mmengine - INFO - Iter(train) [112900/320000]  base_lr: 6.7597e-05 lr: 6.7597e-06  eta: 1 day, 1:08:57  time: 0.4427  data_time: 0.0098  memory: 5129  grad_norm: 45.9931  loss: 4.7391  decode.loss_cls: 0.0033  decode.loss_mask: 0.2256  decode.loss_dice: 0.1628  decode.d0.loss_cls: 0.7096  decode.d0.loss_mask: 0.2249  decode.d0.loss_dice: 0.1677  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.2267  decode.d1.loss_dice: 0.1579  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.2261  decode.d2.loss_dice: 0.1654  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2252  decode.d3.loss_dice: 0.1615  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.1665  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.1821  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.2250  decode.d6.loss_dice: 0.1619  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2252  decode.d7.loss_dice: 0.1805  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.1606
09/30 22:47:39 - mmengine - INFO - Iter(train) [112950/320000]  base_lr: 6.7582e-05 lr: 6.7582e-06  eta: 1 day, 1:08:35  time: 0.4412  data_time: 0.0098  memory: 5129  grad_norm: 43.5645  loss: 7.1267  decode.loss_cls: 0.1074  decode.loss_mask: 0.2285  decode.loss_dice: 0.2956  decode.d0.loss_cls: 0.8803  decode.d0.loss_mask: 0.2422  decode.d0.loss_dice: 0.2927  decode.d1.loss_cls: 0.1555  decode.d1.loss_mask: 0.2271  decode.d1.loss_dice: 0.3036  decode.d2.loss_cls: 0.1301  decode.d2.loss_mask: 0.2263  decode.d2.loss_dice: 0.2687  decode.d3.loss_cls: 0.1345  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.2665  decode.d4.loss_cls: 0.1450  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.2788  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.2291  decode.d5.loss_dice: 0.3070  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.2990  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.2266  decode.d7.loss_dice: 0.2857  decode.d8.loss_cls: 0.1549  decode.d8.loss_mask: 0.2273  decode.d8.loss_dice: 0.2781
09/30 22:48:01 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:48:01 - mmengine - INFO - Iter(train) [113000/320000]  base_lr: 6.7568e-05 lr: 6.7568e-06  eta: 1 day, 1:08:14  time: 0.4409  data_time: 0.0095  memory: 5145  grad_norm: 46.3794  loss: 6.5399  decode.loss_cls: 0.2387  decode.loss_mask: 0.1787  decode.loss_dice: 0.1780  decode.d0.loss_cls: 0.8618  decode.d0.loss_mask: 0.1815  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.1810  decode.d1.loss_dice: 0.1954  decode.d2.loss_cls: 0.2274  decode.d2.loss_mask: 0.1804  decode.d2.loss_dice: 0.1693  decode.d3.loss_cls: 0.2435  decode.d3.loss_mask: 0.1785  decode.d3.loss_dice: 0.1865  decode.d4.loss_cls: 0.2193  decode.d4.loss_mask: 0.1772  decode.d4.loss_dice: 0.1833  decode.d5.loss_cls: 0.2500  decode.d5.loss_mask: 0.1804  decode.d5.loss_dice: 0.1647  decode.d6.loss_cls: 0.2237  decode.d6.loss_mask: 0.1788  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.2310  decode.d7.loss_mask: 0.1811  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.2646  decode.d8.loss_mask: 0.1780  decode.d8.loss_dice: 0.1605
09/30 22:48:23 - mmengine - INFO - Iter(train) [113050/320000]  base_lr: 6.7553e-05 lr: 6.7553e-06  eta: 1 day, 1:07:52  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 25.3768  loss: 4.2408  decode.loss_cls: 0.0051  decode.loss_mask: 0.1933  decode.loss_dice: 0.1539  decode.d0.loss_cls: 0.7395  decode.d0.loss_mask: 0.1932  decode.d0.loss_dice: 0.1535  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.1930  decode.d1.loss_dice: 0.1519  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.1901  decode.d2.loss_dice: 0.1513  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.1917  decode.d3.loss_dice: 0.1536  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1932  decode.d4.loss_dice: 0.1548  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.1528  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1922  decode.d6.loss_dice: 0.1539  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1918  decode.d7.loss_dice: 0.1542  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.1910  decode.d8.loss_dice: 0.1534
09/30 22:48:45 - mmengine - INFO - Iter(train) [113100/320000]  base_lr: 6.7538e-05 lr: 6.7538e-06  eta: 1 day, 1:07:31  time: 0.4410  data_time: 0.0096  memory: 5120  grad_norm: 26.7336  loss: 5.5761  decode.loss_cls: 0.0350  decode.loss_mask: 0.2001  decode.loss_dice: 0.2241  decode.d0.loss_cls: 0.9495  decode.d0.loss_mask: 0.2021  decode.d0.loss_dice: 0.2261  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.2258  decode.d2.loss_cls: 0.0375  decode.d2.loss_mask: 0.2018  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.2260  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.2038  decode.d4.loss_dice: 0.2255  decode.d5.loss_cls: 0.0376  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2208  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.2248  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.1993  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.2230
09/30 22:49:08 - mmengine - INFO - Iter(train) [113150/320000]  base_lr: 6.7524e-05 lr: 6.7524e-06  eta: 1 day, 1:07:09  time: 0.4406  data_time: 0.0096  memory: 5145  grad_norm: 104.0874  loss: 6.1638  decode.loss_cls: 0.0122  decode.loss_mask: 0.2993  decode.loss_dice: 0.2009  decode.d0.loss_cls: 0.9494  decode.d0.loss_mask: 0.2936  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.1952  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.3172  decode.d2.loss_dice: 0.2082  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.1953  decode.d4.loss_cls: 0.0259  decode.d4.loss_mask: 0.2928  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.3010  decode.d5.loss_dice: 0.2037  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.2080  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.1951
09/30 22:49:30 - mmengine - INFO - Iter(train) [113200/320000]  base_lr: 6.7509e-05 lr: 6.7509e-06  eta: 1 day, 1:06:48  time: 0.4410  data_time: 0.0097  memory: 5145  grad_norm: 92.7106  loss: 7.4906  decode.loss_cls: 0.1681  decode.loss_mask: 0.2493  decode.loss_dice: 0.2600  decode.d0.loss_cls: 0.8765  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.2618  decode.d1.loss_cls: 0.2334  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.1899  decode.d2.loss_mask: 0.2478  decode.d2.loss_dice: 0.2407  decode.d3.loss_cls: 0.1916  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.2376  decode.d4.loss_cls: 0.2076  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.2211  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.2636  decode.d6.loss_cls: 0.1410  decode.d6.loss_mask: 0.2448  decode.d6.loss_dice: 0.2686  decode.d7.loss_cls: 0.1623  decode.d7.loss_mask: 0.2491  decode.d7.loss_dice: 0.2624  decode.d8.loss_cls: 0.1524  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.2666
09/30 22:49:52 - mmengine - INFO - Iter(train) [113250/320000]  base_lr: 6.7494e-05 lr: 6.7494e-06  eta: 1 day, 1:06:27  time: 0.4422  data_time: 0.0098  memory: 5129  grad_norm: 20.9746  loss: 4.2163  decode.loss_cls: 0.0026  decode.loss_mask: 0.1864  decode.loss_dice: 0.1627  decode.d0.loss_cls: 0.7213  decode.d0.loss_mask: 0.1865  decode.d0.loss_dice: 0.1531  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.1864  decode.d1.loss_dice: 0.1644  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.1858  decode.d2.loss_dice: 0.1641  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1865  decode.d3.loss_dice: 0.1632  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.1595  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.1842  decode.d5.loss_dice: 0.1656  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.1631  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.1853  decode.d7.loss_dice: 0.1603  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.1855  decode.d8.loss_dice: 0.1584
09/30 22:50:14 - mmengine - INFO - Iter(train) [113300/320000]  base_lr: 6.7480e-05 lr: 6.7480e-06  eta: 1 day, 1:06:05  time: 0.4418  data_time: 0.0098  memory: 5145  grad_norm: 30.7415  loss: 4.6543  decode.loss_cls: 0.0062  decode.loss_mask: 0.2272  decode.loss_dice: 0.1642  decode.d0.loss_cls: 0.7108  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.1622  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.2291  decode.d1.loss_dice: 0.1605  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.2252  decode.d2.loss_dice: 0.1633  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1591  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.2255  decode.d5.loss_dice: 0.1621  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.2293  decode.d6.loss_dice: 0.1629  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.1603  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.2245  decode.d8.loss_dice: 0.1579
09/30 22:50:36 - mmengine - INFO - Iter(train) [113350/320000]  base_lr: 6.7465e-05 lr: 6.7465e-06  eta: 1 day, 1:05:44  time: 0.4433  data_time: 0.0097  memory: 5119  grad_norm: 44.7882  loss: 5.7168  decode.loss_cls: 0.0856  decode.loss_mask: 0.2124  decode.loss_dice: 0.1936  decode.d0.loss_cls: 1.0317  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.2122  decode.d1.loss_dice: 0.1813  decode.d2.loss_cls: 0.0656  decode.d2.loss_mask: 0.2162  decode.d2.loss_dice: 0.1919  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.1869  decode.d4.loss_cls: 0.0723  decode.d4.loss_mask: 0.2126  decode.d4.loss_dice: 0.1818  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.1807  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.2126  decode.d6.loss_dice: 0.1924  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.1914  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.2122  decode.d8.loss_dice: 0.1851
09/30 22:50:58 - mmengine - INFO - Iter(train) [113400/320000]  base_lr: 6.7450e-05 lr: 6.7450e-06  eta: 1 day, 1:05:22  time: 0.4429  data_time: 0.0100  memory: 5129  grad_norm: 32.0915  loss: 5.2680  decode.loss_cls: 0.0361  decode.loss_mask: 0.2115  decode.loss_dice: 0.2053  decode.d0.loss_cls: 0.7954  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.1982  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.2023  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.2115  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.2112  decode.d3.loss_dice: 0.1969  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.2153  decode.d5.loss_dice: 0.1884  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.2132  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.2040  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1934
09/30 22:51:20 - mmengine - INFO - Iter(train) [113450/320000]  base_lr: 6.7436e-05 lr: 6.7436e-06  eta: 1 day, 1:05:01  time: 0.4425  data_time: 0.0099  memory: 5120  grad_norm: 48.1943  loss: 5.9283  decode.loss_cls: 0.1004  decode.loss_mask: 0.2156  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.8556  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.2184  decode.d1.loss_cls: 0.1195  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.1997  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.2196  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.2148  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0956  decode.d4.loss_mask: 0.2162  decode.d4.loss_dice: 0.2177  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.2162  decode.d6.loss_cls: 0.1303  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.0487  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.2178  decode.d8.loss_dice: 0.2252
09/30 22:51:42 - mmengine - INFO - Iter(train) [113500/320000]  base_lr: 6.7421e-05 lr: 6.7421e-06  eta: 1 day, 1:04:40  time: 0.4420  data_time: 0.0101  memory: 5129  grad_norm: 49.5316  loss: 5.7898  decode.loss_cls: 0.0142  decode.loss_mask: 0.3117  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.6744  decode.d0.loss_mask: 0.3146  decode.d0.loss_dice: 0.1891  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.3117  decode.d1.loss_dice: 0.1855  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.3140  decode.d2.loss_dice: 0.1859  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.3100  decode.d3.loss_dice: 0.1852  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.3121  decode.d4.loss_dice: 0.1817  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.3129  decode.d5.loss_dice: 0.1868  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.3102  decode.d6.loss_dice: 0.1856  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.3136  decode.d7.loss_dice: 0.1873  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.3115  decode.d8.loss_dice: 0.1821
09/30 22:52:04 - mmengine - INFO - Iter(train) [113550/320000]  base_lr: 6.7406e-05 lr: 6.7406e-06  eta: 1 day, 1:04:18  time: 0.4434  data_time: 0.0098  memory: 5129  grad_norm: 56.4309  loss: 4.6622  decode.loss_cls: 0.0225  decode.loss_mask: 0.2050  decode.loss_dice: 0.1728  decode.d0.loss_cls: 0.7947  decode.d0.loss_mask: 0.2056  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.2064  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.2072  decode.d2.loss_dice: 0.1760  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2044  decode.d3.loss_dice: 0.1736  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2041  decode.d4.loss_dice: 0.1739  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.2062  decode.d5.loss_dice: 0.1715  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.2048  decode.d6.loss_dice: 0.1748  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.1743  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.2047  decode.d8.loss_dice: 0.1713
09/30 22:52:27 - mmengine - INFO - Iter(train) [113600/320000]  base_lr: 6.7391e-05 lr: 6.7391e-06  eta: 1 day, 1:03:57  time: 0.4415  data_time: 0.0098  memory: 5146  grad_norm: 51.5826  loss: 5.5440  decode.loss_cls: 0.0262  decode.loss_mask: 0.2402  decode.loss_dice: 0.1842  decode.d0.loss_cls: 0.8983  decode.d0.loss_mask: 0.2483  decode.d0.loss_dice: 0.1948  decode.d1.loss_cls: 0.0338  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.2496  decode.d2.loss_dice: 0.1826  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.1985  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.2432  decode.d4.loss_dice: 0.1881  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.2454  decode.d5.loss_dice: 0.1910  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.1846
09/30 22:52:49 - mmengine - INFO - Iter(train) [113650/320000]  base_lr: 6.7377e-05 lr: 6.7377e-06  eta: 1 day, 1:03:35  time: 0.4437  data_time: 0.0096  memory: 5145  grad_norm: 26.3655  loss: 4.3733  decode.loss_cls: 0.0113  decode.loss_mask: 0.2008  decode.loss_dice: 0.1460  decode.d0.loss_cls: 0.7693  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.1535  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.1507  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.1492  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.2046  decode.d3.loss_dice: 0.1464  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2055  decode.d4.loss_dice: 0.1533  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.2034  decode.d5.loss_dice: 0.1470  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.1465  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.2018  decode.d7.loss_dice: 0.1457  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2037  decode.d8.loss_dice: 0.1462
09/30 22:53:11 - mmengine - INFO - Iter(train) [113700/320000]  base_lr: 6.7362e-05 lr: 6.7362e-06  eta: 1 day, 1:03:14  time: 0.4599  data_time: 0.0101  memory: 5145  grad_norm: 56.6470  loss: 6.2992  decode.loss_cls: 0.0413  decode.loss_mask: 0.2495  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.8071  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.2719  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.2429  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.2466  decode.d3.loss_dice: 0.2535  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.2498  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.0282  decode.d6.loss_mask: 0.2483  decode.d6.loss_dice: 0.2480  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.2422  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 0.2474  decode.d8.loss_dice: 0.2518
09/30 22:53:33 - mmengine - INFO - Iter(train) [113750/320000]  base_lr: 6.7347e-05 lr: 6.7347e-06  eta: 1 day, 1:02:53  time: 0.4423  data_time: 0.0098  memory: 5120  grad_norm: 121.6224  loss: 7.1294  decode.loss_cls: 0.1571  decode.loss_mask: 0.1842  decode.loss_dice: 0.2531  decode.d0.loss_cls: 1.0897  decode.d0.loss_mask: 0.1854  decode.d0.loss_dice: 0.2272  decode.d1.loss_cls: 0.1429  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.2437  decode.d2.loss_cls: 0.1686  decode.d2.loss_mask: 0.1802  decode.d2.loss_dice: 0.2401  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.1840  decode.d3.loss_dice: 0.2447  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 0.1819  decode.d4.loss_dice: 0.2543  decode.d5.loss_cls: 0.2754  decode.d5.loss_mask: 0.1829  decode.d5.loss_dice: 0.2467  decode.d6.loss_cls: 0.2364  decode.d6.loss_mask: 0.1802  decode.d6.loss_dice: 0.2443  decode.d7.loss_cls: 0.2194  decode.d7.loss_mask: 0.1825  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.2334  decode.d8.loss_mask: 0.1852  decode.d8.loss_dice: 0.2486
09/30 22:53:55 - mmengine - INFO - Iter(train) [113800/320000]  base_lr: 6.7333e-05 lr: 6.7333e-06  eta: 1 day, 1:02:31  time: 0.4439  data_time: 0.0098  memory: 5145  grad_norm: 56.2052  loss: 5.0182  decode.loss_cls: 0.0669  decode.loss_mask: 0.2265  decode.loss_dice: 0.1523  decode.d0.loss_cls: 0.8117  decode.d0.loss_mask: 0.2267  decode.d0.loss_dice: 0.1483  decode.d1.loss_cls: 0.0489  decode.d1.loss_mask: 0.2242  decode.d1.loss_dice: 0.1486  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.2228  decode.d2.loss_dice: 0.1503  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.1547  decode.d4.loss_cls: 0.0346  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.1513  decode.d5.loss_cls: 0.0489  decode.d5.loss_mask: 0.2248  decode.d5.loss_dice: 0.1502  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.2262  decode.d6.loss_dice: 0.1518  decode.d7.loss_cls: 0.0385  decode.d7.loss_mask: 0.2291  decode.d7.loss_dice: 0.1525  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.1523
09/30 22:54:17 - mmengine - INFO - Iter(train) [113850/320000]  base_lr: 6.7318e-05 lr: 6.7318e-06  eta: 1 day, 1:02:10  time: 0.4423  data_time: 0.0098  memory: 5145  grad_norm: 74.2719  loss: 6.0913  decode.loss_cls: 0.1136  decode.loss_mask: 0.2261  decode.loss_dice: 0.2198  decode.d0.loss_cls: 0.7722  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.2231  decode.d1.loss_dice: 0.2049  decode.d2.loss_cls: 0.1020  decode.d2.loss_mask: 0.2214  decode.d2.loss_dice: 0.2009  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.2237  decode.d3.loss_dice: 0.2067  decode.d4.loss_cls: 0.0858  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.2247  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.1956  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.1014  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.2137  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.2241  decode.d8.loss_dice: 0.2403
09/30 22:54:40 - mmengine - INFO - Iter(train) [113900/320000]  base_lr: 6.7303e-05 lr: 6.7303e-06  eta: 1 day, 1:01:49  time: 0.4412  data_time: 0.0096  memory: 5129  grad_norm: 40.3779  loss: 5.8077  decode.loss_cls: 0.0226  decode.loss_mask: 0.2640  decode.loss_dice: 0.2264  decode.d0.loss_cls: 0.7981  decode.d0.loss_mask: 0.2647  decode.d0.loss_dice: 0.2167  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.2211  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.2636  decode.d2.loss_dice: 0.2272  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.2622  decode.d3.loss_dice: 0.2162  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.2662  decode.d4.loss_dice: 0.2202  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.2658  decode.d5.loss_dice: 0.2214  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.2233  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.2246  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2249
09/30 22:55:02 - mmengine - INFO - Iter(train) [113950/320000]  base_lr: 6.7289e-05 lr: 6.7289e-06  eta: 1 day, 1:01:27  time: 0.4416  data_time: 0.0097  memory: 5120  grad_norm: 44.1849  loss: 5.8360  decode.loss_cls: 0.0886  decode.loss_mask: 0.1990  decode.loss_dice: 0.2145  decode.d0.loss_cls: 0.9224  decode.d0.loss_mask: 0.2017  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.2114  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.1995  decode.d2.loss_dice: 0.2116  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.2007  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.2001  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2076  decode.d6.loss_cls: 0.0910  decode.d6.loss_mask: 0.2000  decode.d6.loss_dice: 0.2149  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2139  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2189
09/30 22:55:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 22:55:24 - mmengine - INFO - Iter(train) [114000/320000]  base_lr: 6.7274e-05 lr: 6.7274e-06  eta: 1 day, 1:01:06  time: 0.4426  data_time: 0.0101  memory: 5129  grad_norm: 52.5171  loss: 6.3037  decode.loss_cls: 0.1486  decode.loss_mask: 0.2286  decode.loss_dice: 0.2230  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.2053  decode.d1.loss_cls: 0.1292  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.2114  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2185  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.2236  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2347  decode.d5.loss_cls: 0.1374  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.2171  decode.d6.loss_cls: 0.1232  decode.d6.loss_mask: 0.2257  decode.d6.loss_dice: 0.1893  decode.d7.loss_cls: 0.1467  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2056  decode.d8.loss_cls: 0.1392  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.1815
09/30 22:55:46 - mmengine - INFO - Iter(train) [114050/320000]  base_lr: 6.7259e-05 lr: 6.7259e-06  eta: 1 day, 1:00:45  time: 0.4424  data_time: 0.0098  memory: 5119  grad_norm: 64.0966  loss: 8.1747  decode.loss_cls: 0.1240  decode.loss_mask: 0.4104  decode.loss_dice: 0.2162  decode.d0.loss_cls: 0.9324  decode.d0.loss_mask: 0.2373  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.2006  decode.d1.loss_mask: 0.2374  decode.d1.loss_dice: 0.1936  decode.d2.loss_cls: 0.1786  decode.d2.loss_mask: 0.3963  decode.d2.loss_dice: 0.2372  decode.d3.loss_cls: 0.1661  decode.d3.loss_mask: 0.3977  decode.d3.loss_dice: 0.2202  decode.d4.loss_cls: 0.1263  decode.d4.loss_mask: 0.4049  decode.d4.loss_dice: 0.2109  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.4119  decode.d5.loss_dice: 0.2324  decode.d6.loss_cls: 0.1710  decode.d6.loss_mask: 0.4007  decode.d6.loss_dice: 0.2178  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.4124  decode.d7.loss_dice: 0.2268  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.3997  decode.d8.loss_dice: 0.2214
09/30 22:56:08 - mmengine - INFO - Iter(train) [114100/320000]  base_lr: 6.7245e-05 lr: 6.7245e-06  eta: 1 day, 1:00:23  time: 0.4420  data_time: 0.0098  memory: 5145  grad_norm: 90.6974  loss: 6.0803  decode.loss_cls: 0.1526  decode.loss_mask: 0.1899  decode.loss_dice: 0.2449  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 0.2043  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.1932  decode.d1.loss_dice: 0.2293  decode.d2.loss_cls: 0.0531  decode.d2.loss_mask: 0.1878  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.1944  decode.d3.loss_dice: 0.2534  decode.d4.loss_cls: 0.0787  decode.d4.loss_mask: 0.1886  decode.d4.loss_dice: 0.2460  decode.d5.loss_cls: 0.0966  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.2304  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.2675  decode.d7.loss_cls: 0.0977  decode.d7.loss_mask: 0.1929  decode.d7.loss_dice: 0.2595  decode.d8.loss_cls: 0.1096  decode.d8.loss_mask: 0.1896  decode.d8.loss_dice: 0.2146
09/30 22:56:30 - mmengine - INFO - Iter(train) [114150/320000]  base_lr: 6.7230e-05 lr: 6.7230e-06  eta: 1 day, 1:00:02  time: 0.4426  data_time: 0.0097  memory: 5129  grad_norm: 28.5730  loss: 4.5691  decode.loss_cls: 0.0067  decode.loss_mask: 0.1657  decode.loss_dice: 0.2019  decode.d0.loss_cls: 0.8705  decode.d0.loss_mask: 0.1659  decode.d0.loss_dice: 0.1994  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.1627  decode.d1.loss_dice: 0.1905  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.1647  decode.d2.loss_dice: 0.2068  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.1659  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.1672  decode.d4.loss_dice: 0.1973  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.1624  decode.d5.loss_dice: 0.1889  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.1667  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.1650  decode.d7.loss_dice: 0.1968  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.1646  decode.d8.loss_dice: 0.2024
09/30 22:56:52 - mmengine - INFO - Iter(train) [114200/320000]  base_lr: 6.7215e-05 lr: 6.7215e-06  eta: 1 day, 0:59:40  time: 0.4426  data_time: 0.0098  memory: 5120  grad_norm: 48.1849  loss: 5.1038  decode.loss_cls: 0.0035  decode.loss_mask: 0.2616  decode.loss_dice: 0.1715  decode.d0.loss_cls: 0.7711  decode.d0.loss_mask: 0.2643  decode.d0.loss_dice: 0.1698  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.2575  decode.d1.loss_dice: 0.1692  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2563  decode.d2.loss_dice: 0.1715  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.2559  decode.d3.loss_dice: 0.1699  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.1711  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.1756  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.2595  decode.d6.loss_dice: 0.1740  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2570  decode.d7.loss_dice: 0.1730  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.1707
09/30 22:57:15 - mmengine - INFO - Iter(train) [114250/320000]  base_lr: 6.7200e-05 lr: 6.7200e-06  eta: 1 day, 0:59:19  time: 0.4428  data_time: 0.0096  memory: 5145  grad_norm: 51.8673  loss: 4.9816  decode.loss_cls: 0.0619  decode.loss_mask: 0.2032  decode.loss_dice: 0.1660  decode.d0.loss_cls: 0.7936  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.1799  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.2021  decode.d1.loss_dice: 0.1578  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.2037  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.2050  decode.d3.loss_dice: 0.1571  decode.d4.loss_cls: 0.0627  decode.d4.loss_mask: 0.2023  decode.d4.loss_dice: 0.1636  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.1567  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.1743  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.2020  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.1614
09/30 22:57:37 - mmengine - INFO - Iter(train) [114300/320000]  base_lr: 6.7186e-05 lr: 6.7186e-06  eta: 1 day, 0:58:58  time: 0.4430  data_time: 0.0097  memory: 5120  grad_norm: 43.1333  loss: 4.8414  decode.loss_cls: 0.0019  decode.loss_mask: 0.2103  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.7405  decode.d0.loss_mask: 0.2099  decode.d0.loss_dice: 0.1673  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.2109  decode.d1.loss_dice: 0.1850  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.2105  decode.d2.loss_dice: 0.1959  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.1726  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2110  decode.d4.loss_dice: 0.1833  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.2116  decode.d6.loss_dice: 0.1928  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2098  decode.d7.loss_dice: 0.1929  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.1996
09/30 22:57:59 - mmengine - INFO - Iter(train) [114350/320000]  base_lr: 6.7171e-05 lr: 6.7171e-06  eta: 1 day, 0:58:36  time: 0.4418  data_time: 0.0097  memory: 5145  grad_norm: 38.7792  loss: 5.1350  decode.loss_cls: 0.0483  decode.loss_mask: 0.2139  decode.loss_dice: 0.1761  decode.d0.loss_cls: 0.7533  decode.d0.loss_mask: 0.2198  decode.d0.loss_dice: 0.1823  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.2208  decode.d1.loss_dice: 0.1934  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.1854  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 0.2145  decode.d3.loss_dice: 0.1775  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.1843  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.1787  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.1708  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.2164  decode.d7.loss_dice: 0.1737  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.2149  decode.d8.loss_dice: 0.1748
09/30 22:58:21 - mmengine - INFO - Iter(train) [114400/320000]  base_lr: 6.7156e-05 lr: 6.7156e-06  eta: 1 day, 0:58:15  time: 0.4412  data_time: 0.0098  memory: 5129  grad_norm: 35.7051  loss: 4.9521  decode.loss_cls: 0.0544  decode.loss_mask: 0.2092  decode.loss_dice: 0.1610  decode.d0.loss_cls: 0.7793  decode.d0.loss_mask: 0.2161  decode.d0.loss_dice: 0.1705  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.2081  decode.d1.loss_dice: 0.1651  decode.d2.loss_cls: 0.0299  decode.d2.loss_mask: 0.2090  decode.d2.loss_dice: 0.1666  decode.d3.loss_cls: 0.0380  decode.d3.loss_mask: 0.2077  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.1674  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.1624  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 0.2123  decode.d7.loss_dice: 0.1661  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.2122  decode.d8.loss_dice: 0.1748
09/30 22:58:43 - mmengine - INFO - Iter(train) [114450/320000]  base_lr: 6.7142e-05 lr: 6.7142e-06  eta: 1 day, 0:57:54  time: 0.4420  data_time: 0.0097  memory: 5129  grad_norm: 30.9443  loss: 4.5835  decode.loss_cls: 0.0472  decode.loss_mask: 0.1665  decode.loss_dice: 0.1578  decode.d0.loss_cls: 0.8161  decode.d0.loss_mask: 0.1672  decode.d0.loss_dice: 0.1669  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.1678  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.1645  decode.d2.loss_dice: 0.1556  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.1665  decode.d3.loss_dice: 0.1577  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.1645  decode.d4.loss_dice: 0.1544  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.1649  decode.d5.loss_dice: 0.1525  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.1650  decode.d6.loss_dice: 0.1615  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.1660  decode.d7.loss_dice: 0.1590  decode.d8.loss_cls: 0.0500  decode.d8.loss_mask: 0.1663  decode.d8.loss_dice: 0.1622
09/30 22:59:05 - mmengine - INFO - Iter(train) [114500/320000]  base_lr: 6.7127e-05 lr: 6.7127e-06  eta: 1 day, 0:57:32  time: 0.4440  data_time: 0.0097  memory: 5120  grad_norm: 73.1182  loss: 5.4254  decode.loss_cls: 0.0280  decode.loss_mask: 0.2216  decode.loss_dice: 0.2004  decode.d0.loss_cls: 0.9537  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.1851  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.2202  decode.d1.loss_dice: 0.2055  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.2242  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.1972  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.2232  decode.d5.loss_dice: 0.2184  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.2225  decode.d6.loss_dice: 0.2139  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.2208  decode.d7.loss_dice: 0.2054  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.1990
09/30 22:59:28 - mmengine - INFO - Iter(train) [114550/320000]  base_lr: 6.7112e-05 lr: 6.7112e-06  eta: 1 day, 0:57:11  time: 0.4427  data_time: 0.0101  memory: 5129  grad_norm: 31.0052  loss: 4.5014  decode.loss_cls: 0.0460  decode.loss_mask: 0.1694  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 0.1655  decode.d0.loss_dice: 0.1718  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.1691  decode.d1.loss_dice: 0.1488  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.1676  decode.d2.loss_dice: 0.1745  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.1694  decode.d3.loss_dice: 0.1853  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.1670  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.1675  decode.d5.loss_dice: 0.1647  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.1675  decode.d6.loss_dice: 0.1597  decode.d7.loss_cls: 0.0159  decode.d7.loss_mask: 0.1676  decode.d7.loss_dice: 0.1576  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.1683  decode.d8.loss_dice: 0.1373
09/30 22:59:50 - mmengine - INFO - Iter(train) [114600/320000]  base_lr: 6.7098e-05 lr: 6.7098e-06  eta: 1 day, 0:56:50  time: 0.4429  data_time: 0.0101  memory: 5120  grad_norm: 36.7087  loss: 4.7420  decode.loss_cls: 0.0652  decode.loss_mask: 0.2018  decode.loss_dice: 0.1395  decode.d0.loss_cls: 0.8490  decode.d0.loss_mask: 0.2098  decode.d0.loss_dice: 0.1478  decode.d1.loss_cls: 0.0573  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.1379  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.1976  decode.d2.loss_dice: 0.1374  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.1974  decode.d3.loss_dice: 0.1377  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.2000  decode.d4.loss_dice: 0.1348  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.2031  decode.d5.loss_dice: 0.1384  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.1987  decode.d6.loss_dice: 0.1351  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.1383  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.1400
09/30 23:00:12 - mmengine - INFO - Iter(train) [114650/320000]  base_lr: 6.7083e-05 lr: 6.7083e-06  eta: 1 day, 0:56:28  time: 0.4438  data_time: 0.0101  memory: 5129  grad_norm: 51.4300  loss: 5.0213  decode.loss_cls: 0.0109  decode.loss_mask: 0.2230  decode.loss_dice: 0.2166  decode.d0.loss_cls: 0.7765  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.1822  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.2187  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.2193  decode.d3.loss_dice: 0.1884  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.1865  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.2191  decode.d6.loss_dice: 0.1851  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.2098  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2213  decode.d8.loss_dice: 0.2117
09/30 23:00:34 - mmengine - INFO - Iter(train) [114700/320000]  base_lr: 6.7068e-05 lr: 6.7068e-06  eta: 1 day, 0:56:07  time: 0.4424  data_time: 0.0100  memory: 5145  grad_norm: 89.1214  loss: 5.7022  decode.loss_cls: 0.0644  decode.loss_mask: 0.1885  decode.loss_dice: 0.2171  decode.d0.loss_cls: 0.8422  decode.d0.loss_mask: 0.1867  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.1881  decode.d1.loss_dice: 0.2374  decode.d2.loss_cls: 0.0944  decode.d2.loss_mask: 0.1882  decode.d2.loss_dice: 0.2396  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.1888  decode.d3.loss_dice: 0.2439  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 0.1861  decode.d4.loss_dice: 0.2389  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.1871  decode.d5.loss_dice: 0.2371  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.1911  decode.d6.loss_dice: 0.2344  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.1877  decode.d7.loss_dice: 0.2086  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.1892  decode.d8.loss_dice: 0.2327
09/30 23:00:56 - mmengine - INFO - Iter(train) [114750/320000]  base_lr: 6.7053e-05 lr: 6.7053e-06  eta: 1 day, 0:55:46  time: 0.4425  data_time: 0.0098  memory: 5129  grad_norm: 40.3178  loss: 5.6110  decode.loss_cls: 0.1389  decode.loss_mask: 0.1817  decode.loss_dice: 0.1582  decode.d0.loss_cls: 0.9017  decode.d0.loss_mask: 0.1897  decode.d0.loss_dice: 0.1632  decode.d1.loss_cls: 0.1119  decode.d1.loss_mask: 0.1850  decode.d1.loss_dice: 0.1651  decode.d2.loss_cls: 0.1059  decode.d2.loss_mask: 0.1823  decode.d2.loss_dice: 0.1554  decode.d3.loss_cls: 0.1062  decode.d3.loss_mask: 0.1909  decode.d3.loss_dice: 0.1614  decode.d4.loss_cls: 0.1299  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.1616  decode.d5.loss_cls: 0.1185  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.1638  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.1852  decode.d6.loss_dice: 0.1726  decode.d7.loss_cls: 0.1060  decode.d7.loss_mask: 0.2382  decode.d7.loss_dice: 0.2007  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.2033
09/30 23:01:18 - mmengine - INFO - Iter(train) [114800/320000]  base_lr: 6.7039e-05 lr: 6.7039e-06  eta: 1 day, 0:55:24  time: 0.4422  data_time: 0.0101  memory: 5129  grad_norm: 70.1475  loss: 5.6860  decode.loss_cls: 0.0488  decode.loss_mask: 0.2268  decode.loss_dice: 0.1815  decode.d0.loss_cls: 0.8331  decode.d0.loss_mask: 0.2733  decode.d0.loss_dice: 0.2146  decode.d1.loss_cls: 0.0190  decode.d1.loss_mask: 0.2496  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.0844  decode.d2.loss_mask: 0.2394  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.2307  decode.d3.loss_dice: 0.1935  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.2247  decode.d4.loss_dice: 0.1878  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.2324  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.2359  decode.d6.loss_dice: 0.1915  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.2286  decode.d7.loss_dice: 0.1912  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.1867
09/30 23:01:41 - mmengine - INFO - Iter(train) [114850/320000]  base_lr: 6.7024e-05 lr: 6.7024e-06  eta: 1 day, 0:55:03  time: 0.4425  data_time: 0.0100  memory: 5145  grad_norm: 43.8749  loss: 5.1383  decode.loss_cls: 0.0087  decode.loss_mask: 0.2445  decode.loss_dice: 0.1780  decode.d0.loss_cls: 0.7639  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.1830  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.1835  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.2470  decode.d2.loss_dice: 0.1838  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.1809  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2459  decode.d4.loss_dice: 0.1825  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.1832  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.2426  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.0103  decode.d8.loss_mask: 0.2471  decode.d8.loss_dice: 0.1800
09/30 23:02:03 - mmengine - INFO - Iter(train) [114900/320000]  base_lr: 6.7009e-05 lr: 6.7009e-06  eta: 1 day, 0:54:42  time: 0.4428  data_time: 0.0100  memory: 5129  grad_norm: 221.9903  loss: 5.2011  decode.loss_cls: 0.0520  decode.loss_mask: 0.2168  decode.loss_dice: 0.1701  decode.d0.loss_cls: 0.9182  decode.d0.loss_mask: 0.2201  decode.d0.loss_dice: 0.1712  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.1671  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.1671  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.2159  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.2148  decode.d4.loss_dice: 0.1650  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.2171  decode.d5.loss_dice: 0.1760  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.2175  decode.d6.loss_dice: 0.1714  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.1690  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.2152  decode.d8.loss_dice: 0.1727
09/30 23:02:25 - mmengine - INFO - Iter(train) [114950/320000]  base_lr: 6.6995e-05 lr: 6.6995e-06  eta: 1 day, 0:54:20  time: 0.4432  data_time: 0.0100  memory: 5129  grad_norm: 40.1210  loss: 5.8318  decode.loss_cls: 0.0100  decode.loss_mask: 0.2571  decode.loss_dice: 0.2445  decode.d0.loss_cls: 0.8327  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.2214  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.2456  decode.d1.loss_dice: 0.2446  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.2461  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2425  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.2408  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.2539  decode.d5.loss_dice: 0.2372  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.2580  decode.d6.loss_dice: 0.2418  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.2384  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.2387
09/30 23:02:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:02:47 - mmengine - INFO - Iter(train) [115000/320000]  base_lr: 6.6980e-05 lr: 6.6980e-06  eta: 1 day, 0:53:59  time: 0.4427  data_time: 0.0101  memory: 5129  grad_norm: 39.5202  loss: 5.1004  decode.loss_cls: 0.0408  decode.loss_mask: 0.2086  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.8933  decode.d0.loss_mask: 0.2142  decode.d0.loss_dice: 0.1843  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.2112  decode.d1.loss_dice: 0.1777  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.1732  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.2055  decode.d3.loss_dice: 0.1788  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.2075  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.1749  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.2072  decode.d7.loss_dice: 0.1759  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.2096  decode.d8.loss_dice: 0.1809
09/30 23:03:09 - mmengine - INFO - Iter(train) [115050/320000]  base_lr: 6.6965e-05 lr: 6.6965e-06  eta: 1 day, 0:53:38  time: 0.4441  data_time: 0.0099  memory: 5129  grad_norm: 26.9317  loss: 3.7224  decode.loss_cls: 0.0037  decode.loss_mask: 0.1676  decode.loss_dice: 0.1276  decode.d0.loss_cls: 0.7518  decode.d0.loss_mask: 0.1676  decode.d0.loss_dice: 0.1254  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.1670  decode.d1.loss_dice: 0.1257  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.1687  decode.d2.loss_dice: 0.1263  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.1672  decode.d3.loss_dice: 0.1270  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.1664  decode.d4.loss_dice: 0.1253  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.1667  decode.d5.loss_dice: 0.1262  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1663  decode.d6.loss_dice: 0.1275  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.1651  decode.d7.loss_dice: 0.1254  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.1672  decode.d8.loss_dice: 0.1261
09/30 23:03:31 - mmengine - INFO - Iter(train) [115100/320000]  base_lr: 6.6951e-05 lr: 6.6951e-06  eta: 1 day, 0:53:16  time: 0.4430  data_time: 0.0099  memory: 5129  grad_norm: 43.5877  loss: 5.1504  decode.loss_cls: 0.0711  decode.loss_mask: 0.1923  decode.loss_dice: 0.1578  decode.d0.loss_cls: 1.0039  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.1664  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.1940  decode.d1.loss_dice: 0.1551  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.1928  decode.d2.loss_dice: 0.1568  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.1948  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.1510  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.1563  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 0.1989  decode.d6.loss_dice: 0.1591  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.1946  decode.d7.loss_dice: 0.1535  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.1562
09/30 23:03:54 - mmengine - INFO - Iter(train) [115150/320000]  base_lr: 6.6936e-05 lr: 6.6936e-06  eta: 1 day, 0:52:55  time: 0.4427  data_time: 0.0100  memory: 5129  grad_norm: 36.2299  loss: 4.5414  decode.loss_cls: 0.0068  decode.loss_mask: 0.1723  decode.loss_dice: 0.1847  decode.d0.loss_cls: 0.8047  decode.d0.loss_mask: 0.1711  decode.d0.loss_dice: 0.1895  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.1695  decode.d1.loss_dice: 0.1812  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.1724  decode.d2.loss_dice: 0.1760  decode.d3.loss_cls: 0.0100  decode.d3.loss_mask: 0.1706  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.1706  decode.d4.loss_dice: 0.2022  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.1724  decode.d5.loss_dice: 0.1926  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.1864  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1715  decode.d7.loss_dice: 0.1954  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.1695  decode.d8.loss_dice: 0.1736
09/30 23:04:16 - mmengine - INFO - Iter(train) [115200/320000]  base_lr: 6.6921e-05 lr: 6.6921e-06  eta: 1 day, 0:52:33  time: 0.4438  data_time: 0.0099  memory: 5145  grad_norm: 22.6072  loss: 4.3384  decode.loss_cls: 0.0026  decode.loss_mask: 0.1980  decode.loss_dice: 0.1610  decode.d0.loss_cls: 0.6675  decode.d0.loss_mask: 0.2001  decode.d0.loss_dice: 0.1689  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.1746  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.1992  decode.d2.loss_dice: 0.1675  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1976  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1966  decode.d4.loss_dice: 0.1587  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.1993  decode.d5.loss_dice: 0.1612  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.1993  decode.d6.loss_dice: 0.1683  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.1995  decode.d7.loss_dice: 0.1668  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.1962  decode.d8.loss_dice: 0.1676
09/30 23:04:38 - mmengine - INFO - Iter(train) [115250/320000]  base_lr: 6.6906e-05 lr: 6.6906e-06  eta: 1 day, 0:52:12  time: 0.4424  data_time: 0.0101  memory: 5145  grad_norm: 33.1619  loss: 5.8324  decode.loss_cls: 0.0432  decode.loss_mask: 0.2515  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.8809  decode.d0.loss_mask: 0.2503  decode.d0.loss_dice: 0.1753  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.1803  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.1805  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.1785  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.2589  decode.d4.loss_dice: 0.1851  decode.d5.loss_cls: 0.0353  decode.d5.loss_mask: 0.2567  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.1830  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.2538  decode.d7.loss_dice: 0.1845  decode.d8.loss_cls: 0.1073  decode.d8.loss_mask: 0.2516  decode.d8.loss_dice: 0.1840
09/30 23:05:00 - mmengine - INFO - Iter(train) [115300/320000]  base_lr: 6.6892e-05 lr: 6.6892e-06  eta: 1 day, 0:51:51  time: 0.4443  data_time: 0.0102  memory: 5129  grad_norm: 42.8589  loss: 4.8639  decode.loss_cls: 0.0052  decode.loss_mask: 0.2200  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.8981  decode.d0.loss_mask: 0.2226  decode.d0.loss_dice: 0.1721  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.1701  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.1722  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2172  decode.d3.loss_dice: 0.1728  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.1693  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.1770  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.1680  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.1690  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.1715
09/30 23:05:22 - mmengine - INFO - Iter(train) [115350/320000]  base_lr: 6.6877e-05 lr: 6.6877e-06  eta: 1 day, 0:51:30  time: 0.4623  data_time: 0.0101  memory: 5129  grad_norm: 123.6475  loss: 5.5177  decode.loss_cls: 0.0752  decode.loss_mask: 0.2165  decode.loss_dice: 0.1723  decode.d0.loss_cls: 0.8705  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.1820  decode.d1.loss_cls: 0.1137  decode.d1.loss_mask: 0.2195  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.1761  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 0.2172  decode.d3.loss_dice: 0.1737  decode.d4.loss_cls: 0.0769  decode.d4.loss_mask: 0.2159  decode.d4.loss_dice: 0.1734  decode.d5.loss_cls: 0.0676  decode.d5.loss_mask: 0.2161  decode.d5.loss_dice: 0.1690  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.2171  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.1741  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.2185  decode.d8.loss_dice: 0.1782
09/30 23:05:45 - mmengine - INFO - Iter(train) [115400/320000]  base_lr: 6.6862e-05 lr: 6.6862e-06  eta: 1 day, 0:51:08  time: 0.4448  data_time: 0.0102  memory: 5129  grad_norm: 27.9025  loss: 4.9173  decode.loss_cls: 0.0272  decode.loss_mask: 0.1899  decode.loss_dice: 0.1775  decode.d0.loss_cls: 0.8213  decode.d0.loss_mask: 0.1910  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.1928  decode.d1.loss_dice: 0.2027  decode.d2.loss_cls: 0.0352  decode.d2.loss_mask: 0.1899  decode.d2.loss_dice: 0.1785  decode.d3.loss_cls: 0.0390  decode.d3.loss_mask: 0.1917  decode.d3.loss_dice: 0.1935  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.1911  decode.d4.loss_dice: 0.1848  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.1922  decode.d5.loss_dice: 0.1647  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.1911  decode.d6.loss_dice: 0.1866  decode.d7.loss_cls: 0.0278  decode.d7.loss_mask: 0.1910  decode.d7.loss_dice: 0.1732  decode.d8.loss_cls: 0.0370  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.1922
09/30 23:06:07 - mmengine - INFO - Iter(train) [115450/320000]  base_lr: 6.6848e-05 lr: 6.6848e-06  eta: 1 day, 0:50:47  time: 0.4433  data_time: 0.0101  memory: 5119  grad_norm: 124.5518  loss: 4.8419  decode.loss_cls: 0.0374  decode.loss_mask: 0.1981  decode.loss_dice: 0.1573  decode.d0.loss_cls: 0.8042  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.1618  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.2017  decode.d1.loss_dice: 0.1585  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 0.2034  decode.d2.loss_dice: 0.1559  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.2026  decode.d3.loss_dice: 0.1590  decode.d4.loss_cls: 0.0513  decode.d4.loss_mask: 0.2005  decode.d4.loss_dice: 0.1582  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.2013  decode.d5.loss_dice: 0.1539  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.1551  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.1564  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.1596
09/30 23:06:29 - mmengine - INFO - Iter(train) [115500/320000]  base_lr: 6.6833e-05 lr: 6.6833e-06  eta: 1 day, 0:50:26  time: 0.4444  data_time: 0.0100  memory: 5129  grad_norm: 24.3431  loss: 4.2595  decode.loss_cls: 0.0136  decode.loss_mask: 0.1664  decode.loss_dice: 0.1693  decode.d0.loss_cls: 0.7985  decode.d0.loss_mask: 0.1696  decode.d0.loss_dice: 0.1766  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.1673  decode.d1.loss_dice: 0.1698  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.1681  decode.d2.loss_dice: 0.1605  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.1681  decode.d3.loss_dice: 0.1698  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.1686  decode.d4.loss_dice: 0.1707  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.1677  decode.d5.loss_dice: 0.1539  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.1674  decode.d6.loss_dice: 0.1542  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.1694  decode.d7.loss_dice: 0.1677  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.1664  decode.d8.loss_dice: 0.1650
09/30 23:06:51 - mmengine - INFO - Iter(train) [115550/320000]  base_lr: 6.6818e-05 lr: 6.6818e-06  eta: 1 day, 0:50:04  time: 0.4422  data_time: 0.0101  memory: 5129  grad_norm: 22.6117  loss: 4.6001  decode.loss_cls: 0.0139  decode.loss_mask: 0.2182  decode.loss_dice: 0.1555  decode.d0.loss_cls: 0.7591  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.1503  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.1568  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.2201  decode.d2.loss_dice: 0.1552  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.2182  decode.d3.loss_dice: 0.1564  decode.d4.loss_cls: 0.0171  decode.d4.loss_mask: 0.2193  decode.d4.loss_dice: 0.1516  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.2202  decode.d5.loss_dice: 0.1561  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.2201  decode.d6.loss_dice: 0.1524  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.1538  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.1538
09/30 23:07:13 - mmengine - INFO - Iter(train) [115600/320000]  base_lr: 6.6803e-05 lr: 6.6803e-06  eta: 1 day, 0:49:43  time: 0.4429  data_time: 0.0099  memory: 5129  grad_norm: 69.5506  loss: 5.9811  decode.loss_cls: 0.0612  decode.loss_mask: 0.2409  decode.loss_dice: 0.1977  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 0.2408  decode.d0.loss_dice: 0.2333  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.2443  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.2391  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.0864  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.2414  decode.d4.loss_dice: 0.2345  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2093  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 0.2399  decode.d8.loss_dice: 0.1871
09/30 23:07:35 - mmengine - INFO - Iter(train) [115650/320000]  base_lr: 6.6789e-05 lr: 6.6789e-06  eta: 1 day, 0:49:21  time: 0.4427  data_time: 0.0101  memory: 5129  grad_norm: 65.7943  loss: 7.8139  decode.loss_cls: 0.2013  decode.loss_mask: 0.2449  decode.loss_dice: 0.2091  decode.d0.loss_cls: 1.1309  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.2062  decode.d1.loss_cls: 0.2081  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.2150  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 0.2579  decode.d2.loss_dice: 0.2285  decode.d3.loss_cls: 0.2076  decode.d3.loss_mask: 0.2704  decode.d3.loss_dice: 0.2235  decode.d4.loss_cls: 0.2034  decode.d4.loss_mask: 0.2636  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 0.2979  decode.d5.loss_dice: 0.2276  decode.d6.loss_cls: 0.2213  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.2231  decode.d7.loss_mask: 0.2529  decode.d7.loss_dice: 0.2131  decode.d8.loss_cls: 0.2109  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.2129
09/30 23:07:58 - mmengine - INFO - Iter(train) [115700/320000]  base_lr: 6.6774e-05 lr: 6.6774e-06  eta: 1 day, 0:49:00  time: 0.4416  data_time: 0.0101  memory: 5145  grad_norm: 65.1228  loss: 6.2625  decode.loss_cls: 0.1559  decode.loss_mask: 0.2021  decode.loss_dice: 0.2450  decode.d0.loss_cls: 0.8630  decode.d0.loss_mask: 0.2085  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.1259  decode.d1.loss_mask: 0.2055  decode.d1.loss_dice: 0.2010  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.2006  decode.d2.loss_dice: 0.2442  decode.d3.loss_cls: 0.1502  decode.d3.loss_mask: 0.2023  decode.d3.loss_dice: 0.2461  decode.d4.loss_cls: 0.1266  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.1961  decode.d5.loss_cls: 0.1225  decode.d5.loss_mask: 0.1999  decode.d5.loss_dice: 0.2022  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.2321  decode.d7.loss_cls: 0.1870  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.1877  decode.d8.loss_cls: 0.1144  decode.d8.loss_mask: 0.2022  decode.d8.loss_dice: 0.1999
09/30 23:08:20 - mmengine - INFO - Iter(train) [115750/320000]  base_lr: 6.6759e-05 lr: 6.6759e-06  eta: 1 day, 0:48:39  time: 0.4421  data_time: 0.0099  memory: 5120  grad_norm: 22.2151  loss: 4.6614  decode.loss_cls: 0.0056  decode.loss_mask: 0.2138  decode.loss_dice: 0.1588  decode.d0.loss_cls: 0.8131  decode.d0.loss_mask: 0.2147  decode.d0.loss_dice: 0.1595  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.2178  decode.d1.loss_dice: 0.1580  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.1588  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.2092  decode.d3.loss_dice: 0.1540  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.2122  decode.d4.loss_dice: 0.1572  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.2084  decode.d5.loss_dice: 0.1578  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.1600  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2153  decode.d7.loss_dice: 0.1581  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.1576
09/30 23:08:42 - mmengine - INFO - Iter(train) [115800/320000]  base_lr: 6.6745e-05 lr: 6.6745e-06  eta: 1 day, 0:48:17  time: 0.4421  data_time: 0.0102  memory: 5145  grad_norm: 65.6958  loss: 5.5689  decode.loss_cls: 0.0489  decode.loss_mask: 0.2320  decode.loss_dice: 0.1983  decode.d0.loss_cls: 0.7804  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.1934  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1821  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.1946  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.1977  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.2282  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.1899
09/30 23:09:04 - mmengine - INFO - Iter(train) [115850/320000]  base_lr: 6.6730e-05 lr: 6.6730e-06  eta: 1 day, 0:47:56  time: 0.4421  data_time: 0.0098  memory: 5145  grad_norm: 20.6945  loss: 4.8354  decode.loss_cls: 0.0569  decode.loss_mask: 0.1784  decode.loss_dice: 0.1646  decode.d0.loss_cls: 0.8740  decode.d0.loss_mask: 0.1809  decode.d0.loss_dice: 0.1629  decode.d1.loss_cls: 0.0567  decode.d1.loss_mask: 0.1807  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.1802  decode.d2.loss_dice: 0.1686  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.1806  decode.d3.loss_dice: 0.1717  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.1804  decode.d4.loss_dice: 0.1667  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.1810  decode.d5.loss_dice: 0.1666  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.1807  decode.d6.loss_dice: 0.1630  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.1798  decode.d7.loss_dice: 0.1659  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.1793  decode.d8.loss_dice: 0.1630
09/30 23:09:26 - mmengine - INFO - Iter(train) [115900/320000]  base_lr: 6.6715e-05 lr: 6.6715e-06  eta: 1 day, 0:47:34  time: 0.4434  data_time: 0.0101  memory: 5129  grad_norm: 22.0541  loss: 6.4867  decode.loss_cls: 0.1912  decode.loss_mask: 0.1831  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.8989  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.2235  decode.d1.loss_cls: 0.1862  decode.d1.loss_mask: 0.1794  decode.d1.loss_dice: 0.2159  decode.d2.loss_cls: 0.1683  decode.d2.loss_mask: 0.1795  decode.d2.loss_dice: 0.2192  decode.d3.loss_cls: 0.1682  decode.d3.loss_mask: 0.1824  decode.d3.loss_dice: 0.2172  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.2163  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 0.1808  decode.d5.loss_dice: 0.2197  decode.d6.loss_cls: 0.1820  decode.d6.loss_mask: 0.1792  decode.d6.loss_dice: 0.2190  decode.d7.loss_cls: 0.1550  decode.d7.loss_mask: 0.1783  decode.d7.loss_dice: 0.2055  decode.d8.loss_cls: 0.1825  decode.d8.loss_mask: 0.1792  decode.d8.loss_dice: 0.2206
09/30 23:09:48 - mmengine - INFO - Iter(train) [115950/320000]  base_lr: 6.6701e-05 lr: 6.6701e-06  eta: 1 day, 0:47:13  time: 0.4422  data_time: 0.0101  memory: 5104  grad_norm: 66.2736  loss: 5.7826  decode.loss_cls: 0.0885  decode.loss_mask: 0.2062  decode.loss_dice: 0.2081  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.2087  decode.d0.loss_dice: 0.1961  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.2117  decode.d1.loss_dice: 0.2263  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.2361  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.2406  decode.d4.loss_cls: 0.1257  decode.d4.loss_mask: 0.2070  decode.d4.loss_dice: 0.2038  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.2077  decode.d5.loss_dice: 0.2345  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.2205  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.2069  decode.d7.loss_dice: 0.2236  decode.d8.loss_cls: 0.0851  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2079
09/30 23:10:10 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:10:10 - mmengine - INFO - Iter(train) [116000/320000]  base_lr: 6.6686e-05 lr: 6.6686e-06  eta: 1 day, 0:46:52  time: 0.4432  data_time: 0.0101  memory: 5119  grad_norm: 105.9741  loss: 4.4599  decode.loss_cls: 0.0033  decode.loss_mask: 0.1908  decode.loss_dice: 0.1902  decode.d0.loss_cls: 0.7662  decode.d0.loss_mask: 0.1779  decode.d0.loss_dice: 0.1640  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.1753  decode.d1.loss_dice: 0.1566  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.1823  decode.d2.loss_dice: 0.1600  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.1826  decode.d3.loss_dice: 0.1692  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.2023  decode.d4.loss_dice: 0.1476  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.1937  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.1592  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.1672  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.2002  decode.d8.loss_dice: 0.1581
09/30 23:10:33 - mmengine - INFO - Iter(train) [116050/320000]  base_lr: 6.6671e-05 lr: 6.6671e-06  eta: 1 day, 0:46:30  time: 0.4422  data_time: 0.0100  memory: 5129  grad_norm: 27.4622  loss: 4.4686  decode.loss_cls: 0.0016  decode.loss_mask: 0.2112  decode.loss_dice: 0.1563  decode.d0.loss_cls: 0.7132  decode.d0.loss_mask: 0.2185  decode.d0.loss_dice: 0.1641  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.1587  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2165  decode.d2.loss_dice: 0.1661  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2155  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.1634  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.1564  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2118  decode.d6.loss_dice: 0.1581  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.2146  decode.d7.loss_dice: 0.1570  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.1573
09/30 23:10:55 - mmengine - INFO - Iter(train) [116100/320000]  base_lr: 6.6656e-05 lr: 6.6656e-06  eta: 1 day, 0:46:09  time: 0.4422  data_time: 0.0099  memory: 5129  grad_norm: 42.0044  loss: 5.0064  decode.loss_cls: 0.0239  decode.loss_mask: 0.2172  decode.loss_dice: 0.1734  decode.d0.loss_cls: 0.7015  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.1768  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.1715  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.1740  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.2159  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.2163  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.1719  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.1723  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.1815  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.2173  decode.d8.loss_dice: 0.1713
09/30 23:11:17 - mmengine - INFO - Iter(train) [116150/320000]  base_lr: 6.6642e-05 lr: 6.6642e-06  eta: 1 day, 0:45:47  time: 0.4429  data_time: 0.0101  memory: 5120  grad_norm: 56.2937  loss: 5.9581  decode.loss_cls: 0.1276  decode.loss_mask: 0.1762  decode.loss_dice: 0.2224  decode.d0.loss_cls: 0.8537  decode.d0.loss_mask: 0.1785  decode.d0.loss_dice: 0.2441  decode.d1.loss_cls: 0.1055  decode.d1.loss_mask: 0.1758  decode.d1.loss_dice: 0.2252  decode.d2.loss_cls: 0.1412  decode.d2.loss_mask: 0.1770  decode.d2.loss_dice: 0.2127  decode.d3.loss_cls: 0.1351  decode.d3.loss_mask: 0.1763  decode.d3.loss_dice: 0.2249  decode.d4.loss_cls: 0.1119  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.2326  decode.d5.loss_cls: 0.1213  decode.d5.loss_mask: 0.1774  decode.d5.loss_dice: 0.2293  decode.d6.loss_cls: 0.1611  decode.d6.loss_mask: 0.1755  decode.d6.loss_dice: 0.1939  decode.d7.loss_cls: 0.1030  decode.d7.loss_mask: 0.1758  decode.d7.loss_dice: 0.2238  decode.d8.loss_cls: 0.1025  decode.d8.loss_mask: 0.1773  decode.d8.loss_dice: 0.2176
09/30 23:11:39 - mmengine - INFO - Iter(train) [116200/320000]  base_lr: 6.6627e-05 lr: 6.6627e-06  eta: 1 day, 0:45:26  time: 0.4437  data_time: 0.0100  memory: 5129  grad_norm: 219.9118  loss: 7.5177  decode.loss_cls: 0.2851  decode.loss_mask: 0.2080  decode.loss_dice: 0.1831  decode.d0.loss_cls: 1.0148  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.1900  decode.d1.loss_cls: 0.3081  decode.d1.loss_mask: 0.2086  decode.d1.loss_dice: 0.1691  decode.d2.loss_cls: 0.2912  decode.d2.loss_mask: 0.2332  decode.d2.loss_dice: 0.1909  decode.d3.loss_cls: 0.2975  decode.d3.loss_mask: 0.2113  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.2742  decode.d4.loss_mask: 0.2151  decode.d4.loss_dice: 0.1823  decode.d5.loss_cls: 0.2478  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.1863  decode.d6.loss_cls: 0.2492  decode.d6.loss_mask: 0.2049  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.3105  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.1678  decode.d8.loss_cls: 0.2681  decode.d8.loss_mask: 0.2238  decode.d8.loss_dice: 0.2000
09/30 23:12:01 - mmengine - INFO - Iter(train) [116250/320000]  base_lr: 6.6612e-05 lr: 6.6612e-06  eta: 1 day, 0:45:05  time: 0.4426  data_time: 0.0100  memory: 5120  grad_norm: 51.2408  loss: 4.8415  decode.loss_cls: 0.0668  decode.loss_mask: 0.1590  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.7721  decode.d0.loss_mask: 0.1563  decode.d0.loss_dice: 0.1789  decode.d1.loss_cls: 0.0824  decode.d1.loss_mask: 0.1586  decode.d1.loss_dice: 0.2039  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.1607  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.1603  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.1597  decode.d4.loss_dice: 0.1845  decode.d5.loss_cls: 0.0647  decode.d5.loss_mask: 0.1583  decode.d5.loss_dice: 0.1880  decode.d6.loss_cls: 0.0678  decode.d6.loss_mask: 0.1589  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.1601  decode.d7.loss_dice: 0.1912  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.1601  decode.d8.loss_dice: 0.1513
09/30 23:12:23 - mmengine - INFO - Iter(train) [116300/320000]  base_lr: 6.6598e-05 lr: 6.6598e-06  eta: 1 day, 0:44:43  time: 0.4423  data_time: 0.0100  memory: 5145  grad_norm: 73.0956  loss: 5.8735  decode.loss_cls: 0.0311  decode.loss_mask: 0.2337  decode.loss_dice: 0.2074  decode.d0.loss_cls: 0.9518  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.2066  decode.d1.loss_cls: 0.0769  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2094  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.2131  decode.d3.loss_cls: 0.0573  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2144  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2112  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.2184  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.2353  decode.d7.loss_dice: 0.2102  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2167
09/30 23:12:46 - mmengine - INFO - Iter(train) [116350/320000]  base_lr: 6.6583e-05 lr: 6.6583e-06  eta: 1 day, 0:44:22  time: 0.4432  data_time: 0.0102  memory: 5129  grad_norm: 49.2589  loss: 5.1506  decode.loss_cls: 0.0140  decode.loss_mask: 0.2297  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.8611  decode.d0.loss_mask: 0.2366  decode.d0.loss_dice: 0.1775  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.1728  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.1736  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.2328  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.1720  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.2319  decode.d6.loss_dice: 0.1742  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.1778  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.1741
09/30 23:13:08 - mmengine - INFO - Iter(train) [116400/320000]  base_lr: 6.6568e-05 lr: 6.6568e-06  eta: 1 day, 0:44:01  time: 0.4426  data_time: 0.0101  memory: 5145  grad_norm: 27.7869  loss: 4.3918  decode.loss_cls: 0.0285  decode.loss_mask: 0.1811  decode.loss_dice: 0.1474  decode.d0.loss_cls: 0.8124  decode.d0.loss_mask: 0.1807  decode.d0.loss_dice: 0.1444  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.1784  decode.d1.loss_dice: 0.1468  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.1764  decode.d2.loss_dice: 0.1488  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.1763  decode.d3.loss_dice: 0.1445  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.1782  decode.d4.loss_dice: 0.1493  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.1781  decode.d5.loss_dice: 0.1466  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.1793  decode.d6.loss_dice: 0.1506  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.1776  decode.d7.loss_dice: 0.1476  decode.d8.loss_cls: 0.0310  decode.d8.loss_mask: 0.1762  decode.d8.loss_dice: 0.1463
09/30 23:13:30 - mmengine - INFO - Iter(train) [116450/320000]  base_lr: 6.6553e-05 lr: 6.6553e-06  eta: 1 day, 0:43:39  time: 0.4430  data_time: 0.0101  memory: 5129  grad_norm: 34.9868  loss: 6.4712  decode.loss_cls: 0.0794  decode.loss_mask: 0.2524  decode.loss_dice: 0.2504  decode.d0.loss_cls: 0.8214  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.2428  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.2434  decode.d1.loss_dice: 0.2446  decode.d2.loss_cls: 0.0798  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.2452  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.2396  decode.d3.loss_dice: 0.2473  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.2467  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.2420  decode.d5.loss_dice: 0.2438  decode.d6.loss_cls: 0.0886  decode.d6.loss_mask: 0.2385  decode.d6.loss_dice: 0.2426  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.2429  decode.d7.loss_dice: 0.2484  decode.d8.loss_cls: 0.0787  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.2537
09/30 23:13:52 - mmengine - INFO - Iter(train) [116500/320000]  base_lr: 6.6539e-05 lr: 6.6539e-06  eta: 1 day, 0:43:18  time: 0.4428  data_time: 0.0101  memory: 5129  grad_norm: 22.4972  loss: 3.8604  decode.loss_cls: 0.0100  decode.loss_mask: 0.1550  decode.loss_dice: 0.1325  decode.d0.loss_cls: 0.8685  decode.d0.loss_mask: 0.1589  decode.d0.loss_dice: 0.1321  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.1575  decode.d1.loss_dice: 0.1344  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.1543  decode.d2.loss_dice: 0.1338  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.1570  decode.d3.loss_dice: 0.1371  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.1545  decode.d4.loss_dice: 0.1353  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.1566  decode.d5.loss_dice: 0.1376  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.1551  decode.d6.loss_dice: 0.1355  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.1547  decode.d7.loss_dice: 0.1344  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.1554  decode.d8.loss_dice: 0.1352
09/30 23:14:14 - mmengine - INFO - Iter(train) [116550/320000]  base_lr: 6.6524e-05 lr: 6.6524e-06  eta: 1 day, 0:42:57  time: 0.4428  data_time: 0.0100  memory: 5129  grad_norm: 29.6517  loss: 5.2505  decode.loss_cls: 0.0628  decode.loss_mask: 0.1737  decode.loss_dice: 0.2194  decode.d0.loss_cls: 0.8863  decode.d0.loss_mask: 0.1748  decode.d0.loss_dice: 0.2120  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.1717  decode.d1.loss_dice: 0.1983  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.1685  decode.d2.loss_dice: 0.1806  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.1740  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.1710  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.1712  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.1746  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.1725  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.1726  decode.d8.loss_dice: 0.1940
09/30 23:14:36 - mmengine - INFO - Iter(train) [116600/320000]  base_lr: 6.6509e-05 lr: 6.6509e-06  eta: 1 day, 0:42:35  time: 0.4426  data_time: 0.0099  memory: 5129  grad_norm: 37.0440  loss: 4.9975  decode.loss_cls: 0.0554  decode.loss_mask: 0.1704  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.9216  decode.d0.loss_mask: 0.1739  decode.d0.loss_dice: 0.1612  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.1725  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.1718  decode.d2.loss_dice: 0.1878  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.1723  decode.d3.loss_dice: 0.1911  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.1705  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.1699  decode.d5.loss_dice: 0.1804  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.1727  decode.d6.loss_dice: 0.1839  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 0.1703  decode.d7.loss_dice: 0.1631  decode.d8.loss_cls: 0.0940  decode.d8.loss_mask: 0.1709  decode.d8.loss_dice: 0.1652
09/30 23:14:59 - mmengine - INFO - Iter(train) [116650/320000]  base_lr: 6.6495e-05 lr: 6.6495e-06  eta: 1 day, 0:42:14  time: 0.4424  data_time: 0.0099  memory: 5120  grad_norm: 123.5484  loss: 7.4676  decode.loss_cls: 0.1739  decode.loss_mask: 0.2418  decode.loss_dice: 0.2494  decode.d0.loss_cls: 0.8900  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2540  decode.d1.loss_cls: 0.1933  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2557  decode.d2.loss_cls: 0.2071  decode.d2.loss_mask: 0.2387  decode.d2.loss_dice: 0.2624  decode.d3.loss_cls: 0.2180  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.1471  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2436  decode.d5.loss_cls: 0.1701  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2624  decode.d6.loss_cls: 0.1892  decode.d6.loss_mask: 0.2409  decode.d6.loss_dice: 0.2566  decode.d7.loss_cls: 0.1308  decode.d7.loss_mask: 0.2686  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.1769  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.2416
09/30 23:15:21 - mmengine - INFO - Iter(train) [116700/320000]  base_lr: 6.6480e-05 lr: 6.6480e-06  eta: 1 day, 0:41:52  time: 0.4431  data_time: 0.0101  memory: 5130  grad_norm: 107.3377  loss: 6.7521  decode.loss_cls: 0.0205  decode.loss_mask: 0.2861  decode.loss_dice: 0.2254  decode.d0.loss_cls: 0.8647  decode.d0.loss_mask: 0.2169  decode.d0.loss_dice: 0.2250  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.3423  decode.d1.loss_dice: 0.2463  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 0.3764  decode.d2.loss_dice: 0.2480  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.3748  decode.d3.loss_dice: 0.2485  decode.d4.loss_cls: 0.0271  decode.d4.loss_mask: 0.2914  decode.d4.loss_dice: 0.2331  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.3924  decode.d5.loss_dice: 0.2417  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.3954  decode.d6.loss_dice: 0.2483  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.2661  decode.d7.loss_dice: 0.2436  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.3232  decode.d8.loss_dice: 0.2404
09/30 23:15:43 - mmengine - INFO - Iter(train) [116750/320000]  base_lr: 6.6465e-05 lr: 6.6465e-06  eta: 1 day, 0:41:31  time: 0.4430  data_time: 0.0099  memory: 5129  grad_norm: 17.8073  loss: 4.5016  decode.loss_cls: 0.0045  decode.loss_mask: 0.1885  decode.loss_dice: 0.1744  decode.d0.loss_cls: 0.7630  decode.d0.loss_mask: 0.1885  decode.d0.loss_dice: 0.1858  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.1890  decode.d1.loss_dice: 0.1781  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.1874  decode.d2.loss_dice: 0.1776  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.1789  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1872  decode.d4.loss_dice: 0.1764  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.1898  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.1870  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.1892  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.1860  decode.d8.loss_dice: 0.1795
09/30 23:16:05 - mmengine - INFO - Iter(train) [116800/320000]  base_lr: 6.6450e-05 lr: 6.6450e-06  eta: 1 day, 0:41:10  time: 0.4426  data_time: 0.0100  memory: 5129  grad_norm: 27.5309  loss: 5.1142  decode.loss_cls: 0.0052  decode.loss_mask: 0.2195  decode.loss_dice: 0.2055  decode.d0.loss_cls: 0.8350  decode.d0.loss_mask: 0.2205  decode.d0.loss_dice: 0.1887  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.2174  decode.d1.loss_dice: 0.1928  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.1995  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.2216  decode.d3.loss_dice: 0.2105  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.2017  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.1917  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.1974  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.2174  decode.d7.loss_dice: 0.1929  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.1976
09/30 23:16:27 - mmengine - INFO - Iter(train) [116850/320000]  base_lr: 6.6436e-05 lr: 6.6436e-06  eta: 1 day, 0:40:48  time: 0.4421  data_time: 0.0097  memory: 5120  grad_norm: 19.5968  loss: 4.5279  decode.loss_cls: 0.0269  decode.loss_mask: 0.1640  decode.loss_dice: 0.1769  decode.d0.loss_cls: 0.7843  decode.d0.loss_mask: 0.1661  decode.d0.loss_dice: 0.1789  decode.d1.loss_cls: 0.0681  decode.d1.loss_mask: 0.1635  decode.d1.loss_dice: 0.1744  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.1630  decode.d2.loss_dice: 0.1728  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.1646  decode.d3.loss_dice: 0.1771  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.1633  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0286  decode.d5.loss_mask: 0.1621  decode.d5.loss_dice: 0.1740  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.1630  decode.d6.loss_dice: 0.1750  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.1624  decode.d7.loss_dice: 0.1774  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.1629  decode.d8.loss_dice: 0.1732
09/30 23:16:49 - mmengine - INFO - Iter(train) [116900/320000]  base_lr: 6.6421e-05 lr: 6.6421e-06  eta: 1 day, 0:40:27  time: 0.4437  data_time: 0.0100  memory: 5145  grad_norm: 54.1055  loss: 5.0392  decode.loss_cls: 0.0947  decode.loss_mask: 0.1696  decode.loss_dice: 0.1809  decode.d0.loss_cls: 0.8196  decode.d0.loss_mask: 0.1745  decode.d0.loss_dice: 0.2033  decode.d1.loss_cls: 0.1020  decode.d1.loss_mask: 0.1711  decode.d1.loss_dice: 0.1717  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.1663  decode.d2.loss_dice: 0.1778  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.1679  decode.d3.loss_dice: 0.1796  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.1695  decode.d4.loss_dice: 0.1786  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.1681  decode.d5.loss_dice: 0.1805  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.1692  decode.d6.loss_dice: 0.1730  decode.d7.loss_cls: 0.0801  decode.d7.loss_mask: 0.1655  decode.d7.loss_dice: 0.1803  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.1690  decode.d8.loss_dice: 0.1816
09/30 23:17:12 - mmengine - INFO - Iter(train) [116950/320000]  base_lr: 6.6406e-05 lr: 6.6406e-06  eta: 1 day, 0:40:06  time: 0.4427  data_time: 0.0099  memory: 5129  grad_norm: 263.5063  loss: 6.2613  decode.loss_cls: 0.0538  decode.loss_mask: 0.2495  decode.loss_dice: 0.2267  decode.d0.loss_cls: 0.8674  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.2364  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.2496  decode.d1.loss_dice: 0.2310  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.2550  decode.d2.loss_dice: 0.2250  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.2441  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.0611  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.2302  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.2548  decode.d6.loss_dice: 0.2628  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.2298
09/30 23:17:34 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:17:34 - mmengine - INFO - Iter(train) [117000/320000]  base_lr: 6.6392e-05 lr: 6.6392e-06  eta: 1 day, 0:39:44  time: 0.4418  data_time: 0.0097  memory: 5129  grad_norm: 95.6977  loss: 6.7975  decode.loss_cls: 0.1052  decode.loss_mask: 0.2856  decode.loss_dice: 0.1862  decode.d0.loss_cls: 0.8233  decode.d0.loss_mask: 0.2843  decode.d0.loss_dice: 0.2295  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.1215  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.2027  decode.d3.loss_cls: 0.1293  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.2280  decode.d4.loss_cls: 0.1187  decode.d4.loss_mask: 0.2828  decode.d4.loss_dice: 0.2125  decode.d5.loss_cls: 0.1312  decode.d5.loss_mask: 0.2843  decode.d5.loss_dice: 0.1945  decode.d6.loss_cls: 0.1197  decode.d6.loss_mask: 0.2814  decode.d6.loss_dice: 0.1748  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.2025  decode.d8.loss_cls: 0.1177  decode.d8.loss_mask: 0.2826  decode.d8.loss_dice: 0.2040
09/30 23:17:56 - mmengine - INFO - Iter(train) [117050/320000]  base_lr: 6.6377e-05 lr: 6.6377e-06  eta: 1 day, 0:39:23  time: 0.4439  data_time: 0.0097  memory: 5129  grad_norm: 29.3872  loss: 4.8690  decode.loss_cls: 0.0440  decode.loss_mask: 0.1962  decode.loss_dice: 0.1447  decode.d0.loss_cls: 0.8068  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.1586  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.1410  decode.d2.loss_cls: 0.0990  decode.d2.loss_mask: 0.1936  decode.d2.loss_dice: 0.1380  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.1904  decode.d3.loss_dice: 0.1449  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.1392  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.1884  decode.d5.loss_dice: 0.1422  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.1919  decode.d6.loss_dice: 0.1464  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.1898  decode.d7.loss_dice: 0.1437  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.1933  decode.d8.loss_dice: 0.1408
09/30 23:18:18 - mmengine - INFO - Iter(train) [117100/320000]  base_lr: 6.6362e-05 lr: 6.6362e-06  eta: 1 day, 0:39:01  time: 0.4428  data_time: 0.0098  memory: 5129  grad_norm: 63.8854  loss: 5.9052  decode.loss_cls: 0.0628  decode.loss_mask: 0.1807  decode.loss_dice: 0.2460  decode.d0.loss_cls: 0.7948  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.2500  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.1832  decode.d1.loss_dice: 0.2384  decode.d2.loss_cls: 0.1215  decode.d2.loss_mask: 0.1806  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.1811  decode.d3.loss_dice: 0.2246  decode.d4.loss_cls: 0.1441  decode.d4.loss_mask: 0.1815  decode.d4.loss_dice: 0.2024  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.2292  decode.d6.loss_cls: 0.1072  decode.d6.loss_mask: 0.1803  decode.d6.loss_dice: 0.2062  decode.d7.loss_cls: 0.1105  decode.d7.loss_mask: 0.1804  decode.d7.loss_dice: 0.2333  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 0.1790  decode.d8.loss_dice: 0.2381
09/30 23:18:40 - mmengine - INFO - Iter(train) [117150/320000]  base_lr: 6.6347e-05 lr: 6.6347e-06  eta: 1 day, 0:38:40  time: 0.4445  data_time: 0.0097  memory: 5129  grad_norm: 58.2115  loss: 5.0149  decode.loss_cls: 0.0117  decode.loss_mask: 0.2126  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.8490  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.1879  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.1860  decode.d2.loss_cls: 0.0258  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.1884  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.1915  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.2124  decode.d4.loss_dice: 0.1832  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.2133  decode.d5.loss_dice: 0.1803  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.2092  decode.d6.loss_dice: 0.1865  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.1976  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.2125  decode.d8.loss_dice: 0.1894
09/30 23:19:02 - mmengine - INFO - Iter(train) [117200/320000]  base_lr: 6.6333e-05 lr: 6.6333e-06  eta: 1 day, 0:38:19  time: 0.4418  data_time: 0.0095  memory: 5129  grad_norm: 33.0688  loss: 4.3133  decode.loss_cls: 0.0487  decode.loss_mask: 0.1411  decode.loss_dice: 0.1550  decode.d0.loss_cls: 0.8209  decode.d0.loss_mask: 0.1427  decode.d0.loss_dice: 0.1464  decode.d1.loss_cls: 0.0691  decode.d1.loss_mask: 0.1416  decode.d1.loss_dice: 0.1489  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.1441  decode.d2.loss_dice: 0.1497  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.1413  decode.d3.loss_dice: 0.1438  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.1409  decode.d4.loss_dice: 0.1428  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.1435  decode.d5.loss_dice: 0.1481  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.1429  decode.d6.loss_dice: 0.1428  decode.d7.loss_cls: 0.0558  decode.d7.loss_mask: 0.1446  decode.d7.loss_dice: 0.1485  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.1412  decode.d8.loss_dice: 0.1416
09/30 23:19:24 - mmengine - INFO - Iter(train) [117250/320000]  base_lr: 6.6318e-05 lr: 6.6318e-06  eta: 1 day, 0:37:57  time: 0.4461  data_time: 0.0100  memory: 5129  grad_norm: 52.5907  loss: 5.3355  decode.loss_cls: 0.0359  decode.loss_mask: 0.2051  decode.loss_dice: 0.2032  decode.d0.loss_cls: 0.8723  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.1920  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.1962  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.2079  decode.d3.loss_cls: 0.0513  decode.d3.loss_mask: 0.1999  decode.d3.loss_dice: 0.1988  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.2035  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.2066  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.2081  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.2070
09/30 23:19:47 - mmengine - INFO - Iter(train) [117300/320000]  base_lr: 6.6303e-05 lr: 6.6303e-06  eta: 1 day, 0:37:36  time: 0.4428  data_time: 0.0098  memory: 5159  grad_norm: 61.2000  loss: 6.9930  decode.loss_cls: 0.1213  decode.loss_mask: 0.2556  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.9699  decode.d0.loss_mask: 0.2558  decode.d0.loss_dice: 0.2111  decode.d1.loss_cls: 0.1697  decode.d1.loss_mask: 0.2554  decode.d1.loss_dice: 0.2028  decode.d2.loss_cls: 0.1561  decode.d2.loss_mask: 0.2550  decode.d2.loss_dice: 0.2229  decode.d3.loss_cls: 0.1508  decode.d3.loss_mask: 0.2557  decode.d3.loss_dice: 0.2177  decode.d4.loss_cls: 0.1513  decode.d4.loss_mask: 0.2536  decode.d4.loss_dice: 0.2136  decode.d5.loss_cls: 0.1582  decode.d5.loss_mask: 0.2505  decode.d5.loss_dice: 0.2041  decode.d6.loss_cls: 0.1543  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 0.2533  decode.d7.loss_dice: 0.2082  decode.d8.loss_cls: 0.1402  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.2254
09/30 23:20:09 - mmengine - INFO - Iter(train) [117350/320000]  base_lr: 6.6288e-05 lr: 6.6288e-06  eta: 1 day, 0:37:15  time: 0.4443  data_time: 0.0099  memory: 5129  grad_norm: 47.4432  loss: 4.7208  decode.loss_cls: 0.0054  decode.loss_mask: 0.2065  decode.loss_dice: 0.1818  decode.d0.loss_cls: 0.7420  decode.d0.loss_mask: 0.2114  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.2073  decode.d1.loss_dice: 0.1895  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.1858  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.2079  decode.d3.loss_dice: 0.1871  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.1852  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.1752  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.1755  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.2082  decode.d8.loss_dice: 0.1833
09/30 23:20:31 - mmengine - INFO - Iter(train) [117400/320000]  base_lr: 6.6274e-05 lr: 6.6274e-06  eta: 1 day, 0:36:53  time: 0.4450  data_time: 0.0099  memory: 5129  grad_norm: 48.5887  loss: 5.4031  decode.loss_cls: 0.0624  decode.loss_mask: 0.2128  decode.loss_dice: 0.1871  decode.d0.loss_cls: 0.7937  decode.d0.loss_mask: 0.2170  decode.d0.loss_dice: 0.1870  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.2142  decode.d1.loss_dice: 0.1857  decode.d2.loss_cls: 0.0882  decode.d2.loss_mask: 0.2135  decode.d2.loss_dice: 0.1882  decode.d3.loss_cls: 0.0635  decode.d3.loss_mask: 0.2121  decode.d3.loss_dice: 0.1776  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.1866  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.1811  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.2132  decode.d6.loss_dice: 0.1820  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.2115  decode.d7.loss_dice: 0.1771  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.1813
09/30 23:20:53 - mmengine - INFO - Iter(train) [117450/320000]  base_lr: 6.6259e-05 lr: 6.6259e-06  eta: 1 day, 0:36:32  time: 0.4441  data_time: 0.0098  memory: 5129  grad_norm: 135.3170  loss: 5.9775  decode.loss_cls: 0.0972  decode.loss_mask: 0.2438  decode.loss_dice: 0.1702  decode.d0.loss_cls: 0.8595  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.0452  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.1797  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.2469  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.1650  decode.d4.loss_mask: 0.2393  decode.d4.loss_dice: 0.1673  decode.d5.loss_cls: 0.1672  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.1730  decode.d6.loss_cls: 0.1127  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.1714  decode.d7.loss_cls: 0.1038  decode.d7.loss_mask: 0.2428  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.1023  decode.d8.loss_mask: 0.2422  decode.d8.loss_dice: 0.1746
09/30 23:21:16 - mmengine - INFO - Iter(train) [117500/320000]  base_lr: 6.6244e-05 lr: 6.6244e-06  eta: 1 day, 0:36:11  time: 0.4441  data_time: 0.0098  memory: 5145  grad_norm: 54.4300  loss: 4.7125  decode.loss_cls: 0.0061  decode.loss_mask: 0.2036  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.7727  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.1750  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.2080  decode.d1.loss_dice: 0.1831  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2073  decode.d2.loss_dice: 0.1835  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.2075  decode.d3.loss_dice: 0.1826  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.1847  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.2054  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.2056  decode.d6.loss_dice: 0.1848  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.2085  decode.d7.loss_dice: 0.1838  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.2053  decode.d8.loss_dice: 0.1837
09/30 23:21:38 - mmengine - INFO - Iter(train) [117550/320000]  base_lr: 6.6230e-05 lr: 6.6230e-06  eta: 1 day, 0:35:49  time: 0.4411  data_time: 0.0098  memory: 5145  grad_norm: 31.2248  loss: 4.2923  decode.loss_cls: 0.0040  decode.loss_mask: 0.1990  decode.loss_dice: 0.1445  decode.d0.loss_cls: 0.7726  decode.d0.loss_mask: 0.2020  decode.d0.loss_dice: 0.1482  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.1985  decode.d1.loss_dice: 0.1490  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.1941  decode.d2.loss_dice: 0.1420  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.1974  decode.d3.loss_dice: 0.1472  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.1476  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.1954  decode.d5.loss_dice: 0.1562  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.1964  decode.d6.loss_dice: 0.1531  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.1586  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.1471
09/30 23:22:00 - mmengine - INFO - Iter(train) [117600/320000]  base_lr: 6.6215e-05 lr: 6.6215e-06  eta: 1 day, 0:35:28  time: 0.4417  data_time: 0.0098  memory: 5129  grad_norm: 71.9971  loss: 6.0097  decode.loss_cls: 0.0592  decode.loss_mask: 0.2122  decode.loss_dice: 0.2352  decode.d0.loss_cls: 0.9125  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.1972  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.2211  decode.d2.loss_cls: 0.1068  decode.d2.loss_mask: 0.2112  decode.d2.loss_dice: 0.2014  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.2128  decode.d3.loss_dice: 0.2219  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.2337  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.2229  decode.d6.loss_cls: 0.0676  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.2212  decode.d7.loss_cls: 0.0826  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.2228  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.2407
09/30 23:22:22 - mmengine - INFO - Iter(train) [117650/320000]  base_lr: 6.6200e-05 lr: 6.6200e-06  eta: 1 day, 0:35:07  time: 0.4437  data_time: 0.0099  memory: 5120  grad_norm: 87.8543  loss: 5.3673  decode.loss_cls: 0.0580  decode.loss_mask: 0.1799  decode.loss_dice: 0.2027  decode.d0.loss_cls: 0.8383  decode.d0.loss_mask: 0.1868  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.1345  decode.d1.loss_mask: 0.1803  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.1822  decode.d2.loss_dice: 0.2112  decode.d3.loss_cls: 0.0295  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.2100  decode.d4.loss_cls: 0.0626  decode.d4.loss_mask: 0.1816  decode.d4.loss_dice: 0.2141  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.1807  decode.d5.loss_dice: 0.2027  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.1825  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.1786  decode.d7.loss_dice: 0.2007  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.1805  decode.d8.loss_dice: 0.2052
09/30 23:22:44 - mmengine - INFO - Iter(train) [117700/320000]  base_lr: 6.6185e-05 lr: 6.6185e-06  eta: 1 day, 0:34:45  time: 0.4422  data_time: 0.0098  memory: 5129  grad_norm: 44.0575  loss: 5.7102  decode.loss_cls: 0.0318  decode.loss_mask: 0.2144  decode.loss_dice: 0.2126  decode.d0.loss_cls: 0.8315  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.2236  decode.d1.loss_cls: 0.0914  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.1873  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.2467  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.1850  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.2120  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.2120  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.1386  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.1948  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.2122  decode.d8.loss_dice: 0.2299
09/30 23:23:06 - mmengine - INFO - Iter(train) [117750/320000]  base_lr: 6.6171e-05 lr: 6.6171e-06  eta: 1 day, 0:34:24  time: 0.4419  data_time: 0.0097  memory: 5120  grad_norm: 46.1102  loss: 6.9681  decode.loss_cls: 0.0755  decode.loss_mask: 0.2933  decode.loss_dice: 0.2335  decode.d0.loss_cls: 0.7095  decode.d0.loss_mask: 0.2887  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.1879  decode.d1.loss_mask: 0.2820  decode.d1.loss_dice: 0.2365  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.2940  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.1171  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.2345  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.2914  decode.d5.loss_dice: 0.2263  decode.d6.loss_cls: 0.1422  decode.d6.loss_mask: 0.2887  decode.d6.loss_dice: 0.2266  decode.d7.loss_cls: 0.0972  decode.d7.loss_mask: 0.2860  decode.d7.loss_dice: 0.2242  decode.d8.loss_cls: 0.1002  decode.d8.loss_mask: 0.2929  decode.d8.loss_dice: 0.2273
09/30 23:23:29 - mmengine - INFO - Iter(train) [117800/320000]  base_lr: 6.6156e-05 lr: 6.6156e-06  eta: 1 day, 0:34:02  time: 0.4425  data_time: 0.0098  memory: 5119  grad_norm: 41.4492  loss: 5.1095  decode.loss_cls: 0.0065  decode.loss_mask: 0.2261  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.7552  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.1910  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.2140  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.2028  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.1975  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.2293  decode.d4.loss_dice: 0.1981  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.2024  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.2332  decode.d7.loss_dice: 0.2126  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.1981
09/30 23:23:51 - mmengine - INFO - Iter(train) [117850/320000]  base_lr: 6.6141e-05 lr: 6.6141e-06  eta: 1 day, 0:33:41  time: 0.4418  data_time: 0.0096  memory: 5104  grad_norm: 45.8615  loss: 5.2192  decode.loss_cls: 0.0302  decode.loss_mask: 0.1915  decode.loss_dice: 0.1864  decode.d0.loss_cls: 1.0563  decode.d0.loss_mask: 0.1887  decode.d0.loss_dice: 0.1746  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.1899  decode.d1.loss_dice: 0.2035  decode.d2.loss_cls: 0.0375  decode.d2.loss_mask: 0.1877  decode.d2.loss_dice: 0.2051  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.1888  decode.d3.loss_dice: 0.2202  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.1862  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.1872  decode.d5.loss_dice: 0.2108  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.1883  decode.d6.loss_dice: 0.2122  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.1872  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0413  decode.d8.loss_mask: 0.1881  decode.d8.loss_dice: 0.1996
09/30 23:24:13 - mmengine - INFO - Iter(train) [117900/320000]  base_lr: 6.6127e-05 lr: 6.6127e-06  eta: 1 day, 0:33:20  time: 0.4430  data_time: 0.0098  memory: 5129  grad_norm: 70.5853  loss: 6.4171  decode.loss_cls: 0.2109  decode.loss_mask: 0.2199  decode.loss_dice: 0.1643  decode.d0.loss_cls: 0.8991  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.1804  decode.d1.loss_cls: 0.2239  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.1829  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 0.2192  decode.d2.loss_dice: 0.1656  decode.d3.loss_cls: 0.1106  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.1749  decode.d4.loss_cls: 0.1528  decode.d4.loss_mask: 0.2155  decode.d4.loss_dice: 0.1641  decode.d5.loss_cls: 0.1661  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.1664  decode.d6.loss_cls: 0.1815  decode.d6.loss_mask: 0.2136  decode.d6.loss_dice: 0.1656  decode.d7.loss_cls: 0.2013  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.1908  decode.d8.loss_cls: 0.1665  decode.d8.loss_mask: 0.2318  decode.d8.loss_dice: 0.1720
09/30 23:24:35 - mmengine - INFO - Iter(train) [117950/320000]  base_lr: 6.6112e-05 lr: 6.6112e-06  eta: 1 day, 0:32:58  time: 0.4422  data_time: 0.0097  memory: 5120  grad_norm: 98.8376  loss: 7.5568  decode.loss_cls: 0.1603  decode.loss_mask: 0.3804  decode.loss_dice: 0.2146  decode.d0.loss_cls: 0.9903  decode.d0.loss_mask: 0.2400  decode.d0.loss_dice: 0.2011  decode.d1.loss_cls: 0.2137  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.1990  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.2324  decode.d3.loss_dice: 0.1853  decode.d4.loss_cls: 0.2197  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.1375  decode.d5.loss_mask: 0.3672  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.1714  decode.d6.loss_mask: 0.3677  decode.d6.loss_dice: 0.1948  decode.d7.loss_cls: 0.1666  decode.d7.loss_mask: 0.3769  decode.d7.loss_dice: 0.2039  decode.d8.loss_cls: 0.2263  decode.d8.loss_mask: 0.2380  decode.d8.loss_dice: 0.1905
09/30 23:24:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:24:57 - mmengine - INFO - Iter(train) [118000/320000]  base_lr: 6.6097e-05 lr: 6.6097e-06  eta: 1 day, 0:32:37  time: 0.4422  data_time: 0.0097  memory: 5145  grad_norm: 37.0167  loss: 4.8110  decode.loss_cls: 0.0194  decode.loss_mask: 0.2043  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.8146  decode.d0.loss_mask: 0.2041  decode.d0.loss_dice: 0.1725  decode.d1.loss_cls: 0.0197  decode.d1.loss_mask: 0.2040  decode.d1.loss_dice: 0.1817  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.2033  decode.d2.loss_dice: 0.1849  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2024  decode.d3.loss_dice: 0.1808  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.2052  decode.d4.loss_dice: 0.1776  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.2022  decode.d5.loss_dice: 0.1750  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.2021  decode.d6.loss_dice: 0.1773  decode.d7.loss_cls: 0.0149  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.1819  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.1804
09/30 23:25:19 - mmengine - INFO - Iter(train) [118050/320000]  base_lr: 6.6082e-05 lr: 6.6082e-06  eta: 1 day, 0:32:15  time: 0.4418  data_time: 0.0098  memory: 5129  grad_norm: 89.3611  loss: 5.7405  decode.loss_cls: 0.0937  decode.loss_mask: 0.2188  decode.loss_dice: 0.1609  decode.d0.loss_cls: 0.8399  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.1020  decode.d1.loss_mask: 0.2207  decode.d1.loss_dice: 0.1682  decode.d2.loss_cls: 0.1156  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.1073  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.1695  decode.d4.loss_cls: 0.1217  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.1740  decode.d5.loss_cls: 0.1106  decode.d5.loss_mask: 0.2299  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.1127  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.1655  decode.d7.loss_cls: 0.1140  decode.d7.loss_mask: 0.2183  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.1209  decode.d8.loss_mask: 0.2197  decode.d8.loss_dice: 0.1657
09/30 23:25:41 - mmengine - INFO - Iter(train) [118100/320000]  base_lr: 6.6068e-05 lr: 6.6068e-06  eta: 1 day, 0:31:54  time: 0.4410  data_time: 0.0098  memory: 5120  grad_norm: 33.8893  loss: 5.4118  decode.loss_cls: 0.0586  decode.loss_mask: 0.2233  decode.loss_dice: 0.1963  decode.d0.loss_cls: 0.9022  decode.d0.loss_mask: 0.2288  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.2250  decode.d1.loss_dice: 0.2138  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.2256  decode.d2.loss_dice: 0.2122  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.2242  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.2254  decode.d4.loss_dice: 0.2117  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.2121  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.2174  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.2076  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.2043
09/30 23:26:03 - mmengine - INFO - Iter(train) [118150/320000]  base_lr: 6.6053e-05 lr: 6.6053e-06  eta: 1 day, 0:31:32  time: 0.4412  data_time: 0.0098  memory: 5129  grad_norm: 39.5522  loss: 4.4885  decode.loss_cls: 0.0096  decode.loss_mask: 0.2124  decode.loss_dice: 0.1560  decode.d0.loss_cls: 0.7777  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.1527  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.2119  decode.d1.loss_dice: 0.1572  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.2140  decode.d2.loss_dice: 0.1561  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.2109  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.2110  decode.d4.loss_dice: 0.1515  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.1556  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.2137  decode.d6.loss_dice: 0.1546  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.2103  decode.d7.loss_dice: 0.1549  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2103  decode.d8.loss_dice: 0.1545
09/30 23:26:25 - mmengine - INFO - Iter(train) [118200/320000]  base_lr: 6.6038e-05 lr: 6.6038e-06  eta: 1 day, 0:31:10  time: 0.4413  data_time: 0.0097  memory: 5159  grad_norm: 173.0844  loss: 5.8691  decode.loss_cls: 0.0792  decode.loss_mask: 0.2378  decode.loss_dice: 0.2332  decode.d0.loss_cls: 0.7789  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2065  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2227  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.2390  decode.d3.loss_dice: 0.2043  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.2372  decode.d4.loss_dice: 0.2245  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.1851  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.2382  decode.d6.loss_dice: 0.2160  decode.d7.loss_cls: 0.0994  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.1888  decode.d8.loss_cls: 0.0935  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.1926
09/30 23:26:48 - mmengine - INFO - Iter(train) [118250/320000]  base_lr: 6.6023e-05 lr: 6.6023e-06  eta: 1 day, 0:30:49  time: 0.4415  data_time: 0.0097  memory: 5104  grad_norm: 58.7025  loss: 5.0671  decode.loss_cls: 0.0146  decode.loss_mask: 0.2345  decode.loss_dice: 0.1759  decode.d0.loss_cls: 0.8275  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.1764  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.1736  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.2393  decode.d2.loss_dice: 0.1786  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.2309  decode.d3.loss_dice: 0.1767  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.1746  decode.d5.loss_cls: 0.0197  decode.d5.loss_mask: 0.2305  decode.d5.loss_dice: 0.1732  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.1753  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.2343  decode.d7.loss_dice: 0.1772  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.2310  decode.d8.loss_dice: 0.1724
09/30 23:27:10 - mmengine - INFO - Iter(train) [118300/320000]  base_lr: 6.6009e-05 lr: 6.6009e-06  eta: 1 day, 0:30:27  time: 0.4420  data_time: 0.0096  memory: 5120  grad_norm: 38.7649  loss: 5.0348  decode.loss_cls: 0.0285  decode.loss_mask: 0.2171  decode.loss_dice: 0.1658  decode.d0.loss_cls: 0.8693  decode.d0.loss_mask: 0.2199  decode.d0.loss_dice: 0.1725  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 0.2182  decode.d1.loss_dice: 0.1666  decode.d2.loss_cls: 0.0293  decode.d2.loss_mask: 0.2144  decode.d2.loss_dice: 0.1635  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 0.2145  decode.d3.loss_dice: 0.1616  decode.d4.loss_cls: 0.0414  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.1652  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.1648  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.2153  decode.d6.loss_dice: 0.1633  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.2156  decode.d8.loss_dice: 0.1616
09/30 23:27:32 - mmengine - INFO - Iter(train) [118350/320000]  base_lr: 6.5994e-05 lr: 6.5994e-06  eta: 1 day, 0:30:06  time: 0.4415  data_time: 0.0095  memory: 5129  grad_norm: 32.5904  loss: 4.2731  decode.loss_cls: 0.0065  decode.loss_mask: 0.1964  decode.loss_dice: 0.1411  decode.d0.loss_cls: 0.8149  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.1424  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.1971  decode.d1.loss_dice: 0.1382  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.2007  decode.d2.loss_dice: 0.1398  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.1412  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.2006  decode.d4.loss_dice: 0.1402  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.1961  decode.d5.loss_dice: 0.1380  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.1965  decode.d6.loss_dice: 0.1411  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.1913  decode.d7.loss_dice: 0.1412  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.1956  decode.d8.loss_dice: 0.1417
09/30 23:27:54 - mmengine - INFO - Iter(train) [118400/320000]  base_lr: 6.5979e-05 lr: 6.5979e-06  eta: 1 day, 0:29:45  time: 0.4414  data_time: 0.0096  memory: 5129  grad_norm: 40.9674  loss: 5.7744  decode.loss_cls: 0.0985  decode.loss_mask: 0.1983  decode.loss_dice: 0.2279  decode.d0.loss_cls: 0.7918  decode.d0.loss_mask: 0.1995  decode.d0.loss_dice: 0.2332  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.1990  decode.d1.loss_dice: 0.2409  decode.d2.loss_cls: 0.0202  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.1985  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.0826  decode.d4.loss_mask: 0.1978  decode.d4.loss_dice: 0.2290  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.1967  decode.d5.loss_dice: 0.2303  decode.d6.loss_cls: 0.0938  decode.d6.loss_mask: 0.1971  decode.d6.loss_dice: 0.2262  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.1958  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2336
09/30 23:28:16 - mmengine - INFO - Iter(train) [118450/320000]  base_lr: 6.5965e-05 lr: 6.5965e-06  eta: 1 day, 0:29:23  time: 0.4412  data_time: 0.0096  memory: 5129  grad_norm: 246.5104  loss: 5.9739  decode.loss_cls: 0.0108  decode.loss_mask: 0.3151  decode.loss_dice: 0.2127  decode.d0.loss_cls: 0.5973  decode.d0.loss_mask: 0.3281  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.3201  decode.d1.loss_dice: 0.2082  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.3149  decode.d2.loss_dice: 0.2072  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.3147  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.3143  decode.d4.loss_dice: 0.2155  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.3142  decode.d5.loss_dice: 0.2176  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.3107  decode.d6.loss_dice: 0.2076  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.3133  decode.d7.loss_dice: 0.2166  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.3191  decode.d8.loss_dice: 0.2117
09/30 23:28:38 - mmengine - INFO - Iter(train) [118500/320000]  base_lr: 6.5950e-05 lr: 6.5950e-06  eta: 1 day, 0:29:02  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 45.1775  loss: 5.7654  decode.loss_cls: 0.0676  decode.loss_mask: 0.2546  decode.loss_dice: 0.1654  decode.d0.loss_cls: 0.8242  decode.d0.loss_mask: 0.2594  decode.d0.loss_dice: 0.1636  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.1697  decode.d2.loss_cls: 0.1059  decode.d2.loss_mask: 0.2619  decode.d2.loss_dice: 0.1733  decode.d3.loss_cls: 0.0811  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.1690  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.2543  decode.d4.loss_dice: 0.1639  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.2587  decode.d5.loss_dice: 0.1654  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.1664  decode.d7.loss_cls: 0.0705  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.1641  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.1690
09/30 23:29:00 - mmengine - INFO - Iter(train) [118550/320000]  base_lr: 6.5935e-05 lr: 6.5935e-06  eta: 1 day, 0:28:40  time: 0.4427  data_time: 0.0099  memory: 5145  grad_norm: 44.8234  loss: 4.6981  decode.loss_cls: 0.0072  decode.loss_mask: 0.2291  decode.loss_dice: 0.1657  decode.d0.loss_cls: 0.7684  decode.d0.loss_mask: 0.2295  decode.d0.loss_dice: 0.1561  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.2254  decode.d1.loss_dice: 0.1567  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.2254  decode.d2.loss_dice: 0.1591  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.1600  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1613  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.2271  decode.d6.loss_dice: 0.1561  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.1618  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2283  decode.d8.loss_dice: 0.1606
09/30 23:29:22 - mmengine - INFO - Iter(train) [118600/320000]  base_lr: 6.5920e-05 lr: 6.5920e-06  eta: 1 day, 0:28:19  time: 0.4425  data_time: 0.0098  memory: 5129  grad_norm: 27.1066  loss: 4.1963  decode.loss_cls: 0.0130  decode.loss_mask: 0.1838  decode.loss_dice: 0.1387  decode.d0.loss_cls: 0.8062  decode.d0.loss_mask: 0.1834  decode.d0.loss_dice: 0.1364  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.1432  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.1834  decode.d2.loss_dice: 0.1398  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.1850  decode.d3.loss_dice: 0.1428  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.1822  decode.d4.loss_dice: 0.1405  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.1809  decode.d5.loss_dice: 0.1376  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.1838  decode.d6.loss_dice: 0.1394  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.1805  decode.d7.loss_dice: 0.1392  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.1838  decode.d8.loss_dice: 0.1399
09/30 23:29:45 - mmengine - INFO - Iter(train) [118650/320000]  base_lr: 6.5906e-05 lr: 6.5906e-06  eta: 1 day, 0:27:57  time: 0.4415  data_time: 0.0097  memory: 5129  grad_norm: 24.4726  loss: 4.6230  decode.loss_cls: 0.0224  decode.loss_mask: 0.1955  decode.loss_dice: 0.1624  decode.d0.loss_cls: 0.8961  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.1497  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.1959  decode.d1.loss_dice: 0.1595  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.1958  decode.d2.loss_dice: 0.1615  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.1968  decode.d3.loss_dice: 0.1634  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.1946  decode.d4.loss_dice: 0.1561  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.1943  decode.d5.loss_dice: 0.1667  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.1591  decode.d7.loss_cls: 0.0149  decode.d7.loss_mask: 0.1951  decode.d7.loss_dice: 0.1603  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.1634
09/30 23:30:07 - mmengine - INFO - Iter(train) [118700/320000]  base_lr: 6.5891e-05 lr: 6.5891e-06  eta: 1 day, 0:27:36  time: 0.4432  data_time: 0.0099  memory: 5129  grad_norm: 64.0615  loss: 6.4986  decode.loss_cls: 0.1102  decode.loss_mask: 0.2348  decode.loss_dice: 0.2334  decode.d0.loss_cls: 0.8696  decode.d0.loss_mask: 0.2355  decode.d0.loss_dice: 0.2612  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.2163  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.2355  decode.d2.loss_dice: 0.2497  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.2482  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2547  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.2347  decode.d5.loss_dice: 0.2513  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.2323  decode.d7.loss_cls: 0.1100  decode.d7.loss_mask: 0.2340  decode.d7.loss_dice: 0.2440  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.2359  decode.d8.loss_dice: 0.2554
09/30 23:30:29 - mmengine - INFO - Iter(train) [118750/320000]  base_lr: 6.5876e-05 lr: 6.5876e-06  eta: 1 day, 0:27:15  time: 0.4422  data_time: 0.0097  memory: 5129  grad_norm: 18.9603  loss: 4.1189  decode.loss_cls: 0.0347  decode.loss_mask: 0.1604  decode.loss_dice: 0.1396  decode.d0.loss_cls: 0.8307  decode.d0.loss_mask: 0.1603  decode.d0.loss_dice: 0.1297  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.1597  decode.d1.loss_dice: 0.1434  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.1594  decode.d2.loss_dice: 0.1442  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.1604  decode.d3.loss_dice: 0.1382  decode.d4.loss_cls: 0.0299  decode.d4.loss_mask: 0.1602  decode.d4.loss_dice: 0.1423  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.1602  decode.d5.loss_dice: 0.1367  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.1607  decode.d6.loss_dice: 0.1370  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.1590  decode.d7.loss_dice: 0.1393  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.1592  decode.d8.loss_dice: 0.1431
09/30 23:30:51 - mmengine - INFO - Iter(train) [118800/320000]  base_lr: 6.5861e-05 lr: 6.5861e-06  eta: 1 day, 0:26:53  time: 0.4439  data_time: 0.0096  memory: 5129  grad_norm: 115.3424  loss: 5.0687  decode.loss_cls: 0.0779  decode.loss_mask: 0.1844  decode.loss_dice: 0.1695  decode.d0.loss_cls: 0.7887  decode.d0.loss_mask: 0.1900  decode.d0.loss_dice: 0.1691  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.1814  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.2144  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.1922  decode.d3.loss_dice: 0.1787  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.1914  decode.d4.loss_dice: 0.1662  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.1880  decode.d5.loss_dice: 0.1816  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.1902  decode.d6.loss_dice: 0.1713  decode.d7.loss_cls: 0.0888  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.1715  decode.d8.loss_cls: 0.0941  decode.d8.loss_mask: 0.1863  decode.d8.loss_dice: 0.1766
09/30 23:31:13 - mmengine - INFO - Iter(train) [118850/320000]  base_lr: 6.5847e-05 lr: 6.5847e-06  eta: 1 day, 0:26:32  time: 0.4424  data_time: 0.0099  memory: 5129  grad_norm: 68.4835  loss: 4.4648  decode.loss_cls: 0.0323  decode.loss_mask: 0.1889  decode.loss_dice: 0.1407  decode.d0.loss_cls: 0.8848  decode.d0.loss_mask: 0.1881  decode.d0.loss_dice: 0.1422  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.1897  decode.d1.loss_dice: 0.1391  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.1892  decode.d2.loss_dice: 0.1413  decode.d3.loss_cls: 0.0386  decode.d3.loss_mask: 0.1869  decode.d3.loss_dice: 0.1396  decode.d4.loss_cls: 0.0374  decode.d4.loss_mask: 0.1886  decode.d4.loss_dice: 0.1405  decode.d5.loss_cls: 0.0479  decode.d5.loss_mask: 0.1868  decode.d5.loss_dice: 0.1390  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.1893  decode.d6.loss_dice: 0.1422  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.1400  decode.d8.loss_cls: 0.0370  decode.d8.loss_mask: 0.1894  decode.d8.loss_dice: 0.1408
09/30 23:31:35 - mmengine - INFO - Iter(train) [118900/320000]  base_lr: 6.5832e-05 lr: 6.5832e-06  eta: 1 day, 0:26:10  time: 0.4444  data_time: 0.0099  memory: 5145  grad_norm: 31.5926  loss: 4.4767  decode.loss_cls: 0.0012  decode.loss_mask: 0.2105  decode.loss_dice: 0.1646  decode.d0.loss_cls: 0.7049  decode.d0.loss_mask: 0.2154  decode.d0.loss_dice: 0.1625  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1673  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2116  decode.d2.loss_dice: 0.1624  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2145  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.1608  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2126  decode.d5.loss_dice: 0.1615  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.1651  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2124  decode.d7.loss_dice: 0.1645  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2122  decode.d8.loss_dice: 0.1620
09/30 23:31:58 - mmengine - INFO - Iter(train) [118950/320000]  base_lr: 6.5817e-05 lr: 6.5817e-06  eta: 1 day, 0:25:49  time: 0.4414  data_time: 0.0098  memory: 5145  grad_norm: 29.0178  loss: 5.0135  decode.loss_cls: 0.0428  decode.loss_mask: 0.1791  decode.loss_dice: 0.2202  decode.d0.loss_cls: 0.8717  decode.d0.loss_mask: 0.1813  decode.d0.loss_dice: 0.2052  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.1780  decode.d1.loss_dice: 0.1535  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.1755  decode.d2.loss_dice: 0.1689  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.1779  decode.d3.loss_dice: 0.2166  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.1768  decode.d4.loss_dice: 0.2031  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.1786  decode.d5.loss_dice: 0.1988  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.1780  decode.d6.loss_dice: 0.2021  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.1810  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.1778  decode.d8.loss_dice: 0.1815
09/30 23:32:20 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:32:20 - mmengine - INFO - Iter(train) [119000/320000]  base_lr: 6.5803e-05 lr: 6.5803e-06  eta: 1 day, 0:25:27  time: 0.4424  data_time: 0.0100  memory: 5129  grad_norm: 58.3100  loss: 5.0342  decode.loss_cls: 0.0110  decode.loss_mask: 0.2360  decode.loss_dice: 0.1660  decode.d0.loss_cls: 0.8318  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.1699  decode.d1.loss_cls: 0.0269  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.1725  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.1720  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.1722  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.2373  decode.d4.loss_dice: 0.1668  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2386  decode.d5.loss_dice: 0.1694  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.2351  decode.d7.loss_dice: 0.1647  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.1652
09/30 23:32:42 - mmengine - INFO - Iter(train) [119050/320000]  base_lr: 6.5788e-05 lr: 6.5788e-06  eta: 1 day, 0:25:06  time: 0.4433  data_time: 0.0101  memory: 5129  grad_norm: 31.2309  loss: 4.9630  decode.loss_cls: 0.0525  decode.loss_mask: 0.2008  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.8023  decode.d0.loss_mask: 0.2036  decode.d0.loss_dice: 0.1663  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.2061  decode.d1.loss_dice: 0.1671  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.2053  decode.d2.loss_dice: 0.1657  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.2046  decode.d4.loss_dice: 0.1685  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.2006  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.2041  decode.d6.loss_dice: 0.1666  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.2025  decode.d7.loss_dice: 0.1677  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.2045  decode.d8.loss_dice: 0.1686
09/30 23:33:04 - mmengine - INFO - Iter(train) [119100/320000]  base_lr: 6.5773e-05 lr: 6.5773e-06  eta: 1 day, 0:24:45  time: 0.4427  data_time: 0.0101  memory: 5129  grad_norm: 101.9546  loss: 7.5158  decode.loss_cls: 0.1912  decode.loss_mask: 0.2606  decode.loss_dice: 0.2366  decode.d0.loss_cls: 0.9493  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.2422  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.1980  decode.d2.loss_cls: 0.1829  decode.d2.loss_mask: 0.2332  decode.d2.loss_dice: 0.2217  decode.d3.loss_cls: 0.2104  decode.d3.loss_mask: 0.2465  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.2765  decode.d4.loss_dice: 0.2357  decode.d5.loss_cls: 0.1976  decode.d5.loss_mask: 0.2436  decode.d5.loss_dice: 0.2424  decode.d6.loss_cls: 0.1769  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.2248  decode.d7.loss_cls: 0.2005  decode.d7.loss_mask: 0.2461  decode.d7.loss_dice: 0.2359  decode.d8.loss_cls: 0.2040  decode.d8.loss_mask: 0.2480  decode.d8.loss_dice: 0.2343
09/30 23:33:26 - mmengine - INFO - Iter(train) [119150/320000]  base_lr: 6.5758e-05 lr: 6.5758e-06  eta: 1 day, 0:24:23  time: 0.4430  data_time: 0.0102  memory: 5119  grad_norm: 65.5773  loss: 5.8261  decode.loss_cls: 0.0742  decode.loss_mask: 0.2320  decode.loss_dice: 0.1961  decode.d0.loss_cls: 0.8735  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.1986  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 0.2324  decode.d1.loss_dice: 0.1999  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.1912  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.2290  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.2345  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.2281  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.1932
09/30 23:33:48 - mmengine - INFO - Iter(train) [119200/320000]  base_lr: 6.5744e-05 lr: 6.5744e-06  eta: 1 day, 0:24:02  time: 0.4433  data_time: 0.0102  memory: 5129  grad_norm: 141.1282  loss: 5.6923  decode.loss_cls: 0.0509  decode.loss_mask: 0.2723  decode.loss_dice: 0.1862  decode.d0.loss_cls: 0.7430  decode.d0.loss_mask: 0.2766  decode.d0.loss_dice: 0.1747  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.2742  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.2696  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.2731  decode.d4.loss_dice: 0.1899  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.2719  decode.d5.loss_dice: 0.1898  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.2714  decode.d6.loss_dice: 0.1868  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.1852  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.1834
09/30 23:34:11 - mmengine - INFO - Iter(train) [119250/320000]  base_lr: 6.5729e-05 lr: 6.5729e-06  eta: 1 day, 0:23:40  time: 0.4432  data_time: 0.0101  memory: 5129  grad_norm: 79.1804  loss: 5.1184  decode.loss_cls: 0.0733  decode.loss_mask: 0.1765  decode.loss_dice: 0.1774  decode.d0.loss_cls: 0.9195  decode.d0.loss_mask: 0.1766  decode.d0.loss_dice: 0.1607  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.1747  decode.d1.loss_dice: 0.1967  decode.d2.loss_cls: 0.0335  decode.d2.loss_mask: 0.1781  decode.d2.loss_dice: 0.1692  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.1768  decode.d3.loss_dice: 0.1802  decode.d4.loss_cls: 0.0855  decode.d4.loss_mask: 0.1774  decode.d4.loss_dice: 0.1762  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.1757  decode.d5.loss_dice: 0.1805  decode.d6.loss_cls: 0.0711  decode.d6.loss_mask: 0.1772  decode.d6.loss_dice: 0.1750  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.1784  decode.d7.loss_dice: 0.1715  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.1780  decode.d8.loss_dice: 0.1798
09/30 23:34:33 - mmengine - INFO - Iter(train) [119300/320000]  base_lr: 6.5714e-05 lr: 6.5714e-06  eta: 1 day, 0:23:19  time: 0.4436  data_time: 0.0103  memory: 5145  grad_norm: 37.1134  loss: 5.1427  decode.loss_cls: 0.0658  decode.loss_mask: 0.2107  decode.loss_dice: 0.1640  decode.d0.loss_cls: 0.8648  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.1755  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.2103  decode.d1.loss_dice: 0.1743  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.1816  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.1730  decode.d4.loss_cls: 0.0156  decode.d4.loss_mask: 0.2085  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.2052  decode.d5.loss_dice: 0.1721  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.2094  decode.d6.loss_dice: 0.1757  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.0811  decode.d8.loss_mask: 0.2075  decode.d8.loss_dice: 0.1646
09/30 23:34:55 - mmengine - INFO - Iter(train) [119350/320000]  base_lr: 6.5699e-05 lr: 6.5699e-06  eta: 1 day, 0:22:58  time: 0.4448  data_time: 0.0103  memory: 5145  grad_norm: 90.4423  loss: 7.7003  decode.loss_cls: 0.1500  decode.loss_mask: 0.2757  decode.loss_dice: 0.2341  decode.d0.loss_cls: 1.0734  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2424  decode.d1.loss_cls: 0.1858  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.1876  decode.d3.loss_mask: 0.2639  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.1466  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.2553  decode.d5.loss_cls: 0.2052  decode.d5.loss_mask: 0.2656  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.1791  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.1716  decode.d7.loss_mask: 0.2595  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.1871  decode.d8.loss_mask: 0.2634  decode.d8.loss_dice: 0.2306
09/30 23:35:17 - mmengine - INFO - Iter(train) [119400/320000]  base_lr: 6.5685e-05 lr: 6.5685e-06  eta: 1 day, 0:22:36  time: 0.4431  data_time: 0.0101  memory: 5129  grad_norm: 77.1915  loss: 7.2022  decode.loss_cls: 0.0511  decode.loss_mask: 0.2248  decode.loss_dice: 0.3356  decode.d0.loss_cls: 1.0776  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.3247  decode.d1.loss_cls: 0.0392  decode.d1.loss_mask: 0.2297  decode.d1.loss_dice: 0.3221  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.3261  decode.d3.loss_cls: 0.0789  decode.d3.loss_mask: 0.2281  decode.d3.loss_dice: 0.3182  decode.d4.loss_cls: 0.0787  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.3337  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.3238  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.3247  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.3479  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.2266  decode.d8.loss_dice: 0.3199
09/30 23:35:39 - mmengine - INFO - Iter(train) [119450/320000]  base_lr: 6.5670e-05 lr: 6.5670e-06  eta: 1 day, 0:22:15  time: 0.4434  data_time: 0.0103  memory: 5129  grad_norm: 45.8503  loss: 6.2923  decode.loss_cls: 0.1132  decode.loss_mask: 0.2239  decode.loss_dice: 0.1805  decode.d0.loss_cls: 1.0941  decode.d0.loss_mask: 0.2240  decode.d0.loss_dice: 0.1867  decode.d1.loss_cls: 0.1571  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.1831  decode.d2.loss_cls: 0.1122  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.1873  decode.d3.loss_cls: 0.1370  decode.d3.loss_mask: 0.2260  decode.d3.loss_dice: 0.1866  decode.d4.loss_cls: 0.0903  decode.d4.loss_mask: 0.2237  decode.d4.loss_dice: 0.1796  decode.d5.loss_cls: 0.1231  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.1824  decode.d6.loss_cls: 0.1610  decode.d6.loss_mask: 0.2239  decode.d6.loss_dice: 0.1841  decode.d7.loss_cls: 0.1046  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.1832  decode.d8.loss_cls: 0.1107  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.1873
09/30 23:36:01 - mmengine - INFO - Iter(train) [119500/320000]  base_lr: 6.5655e-05 lr: 6.5655e-06  eta: 1 day, 0:21:53  time: 0.4422  data_time: 0.0102  memory: 5104  grad_norm: 49.9204  loss: 5.9491  decode.loss_cls: 0.0179  decode.loss_mask: 0.2522  decode.loss_dice: 0.2186  decode.d0.loss_cls: 0.9476  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.2239  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.2540  decode.d1.loss_dice: 0.2168  decode.d2.loss_cls: 0.0352  decode.d2.loss_mask: 0.2562  decode.d2.loss_dice: 0.2167  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.2547  decode.d3.loss_dice: 0.2180  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.2537  decode.d4.loss_dice: 0.2184  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.2557  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.2533  decode.d6.loss_dice: 0.2136  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.2189  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2155
09/30 23:36:24 - mmengine - INFO - Iter(train) [119550/320000]  base_lr: 6.5640e-05 lr: 6.5640e-06  eta: 1 day, 0:21:32  time: 0.4433  data_time: 0.0100  memory: 5129  grad_norm: 95.4946  loss: 5.0379  decode.loss_cls: 0.0281  decode.loss_mask: 0.2162  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.7370  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.1695  decode.d1.loss_cls: 0.0460  decode.d1.loss_mask: 0.2212  decode.d1.loss_dice: 0.1734  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.2204  decode.d2.loss_dice: 0.1686  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.1678  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.1717  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.2191  decode.d5.loss_dice: 0.1685  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.2195  decode.d6.loss_dice: 0.1658  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.2205  decode.d7.loss_dice: 0.1670  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.2195  decode.d8.loss_dice: 0.1661
09/30 23:36:46 - mmengine - INFO - Iter(train) [119600/320000]  base_lr: 6.5626e-05 lr: 6.5626e-06  eta: 1 day, 0:21:11  time: 0.4430  data_time: 0.0101  memory: 5145  grad_norm: 107.4704  loss: 7.7320  decode.loss_cls: 0.1645  decode.loss_mask: 0.2788  decode.loss_dice: 0.2617  decode.d0.loss_cls: 0.8747  decode.d0.loss_mask: 0.2800  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.1310  decode.d1.loss_mask: 0.2806  decode.d1.loss_dice: 0.2698  decode.d2.loss_cls: 0.1381  decode.d2.loss_mask: 0.2825  decode.d2.loss_dice: 0.2685  decode.d3.loss_cls: 0.1447  decode.d3.loss_mask: 0.2834  decode.d3.loss_dice: 0.2851  decode.d4.loss_cls: 0.1433  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.2790  decode.d5.loss_cls: 0.1291  decode.d5.loss_mask: 0.2833  decode.d5.loss_dice: 0.2787  decode.d6.loss_cls: 0.1606  decode.d6.loss_mask: 0.2806  decode.d6.loss_dice: 0.2760  decode.d7.loss_cls: 0.1763  decode.d7.loss_mask: 0.2832  decode.d7.loss_dice: 0.2674  decode.d8.loss_cls: 0.1486  decode.d8.loss_mask: 0.2794  decode.d8.loss_dice: 0.2477
09/30 23:37:08 - mmengine - INFO - Iter(train) [119650/320000]  base_lr: 6.5611e-05 lr: 6.5611e-06  eta: 1 day, 0:20:49  time: 0.4426  data_time: 0.0098  memory: 5145  grad_norm: 28.4868  loss: 4.6627  decode.loss_cls: 0.0354  decode.loss_mask: 0.2022  decode.loss_dice: 0.1529  decode.d0.loss_cls: 0.7113  decode.d0.loss_mask: 0.1999  decode.d0.loss_dice: 0.1587  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.1986  decode.d1.loss_dice: 0.1533  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.1548  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.1982  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.1969  decode.d4.loss_dice: 0.1545  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.1979  decode.d5.loss_dice: 0.1599  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.1990  decode.d6.loss_dice: 0.1562  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.1982  decode.d7.loss_dice: 0.1481  decode.d8.loss_cls: 0.0442  decode.d8.loss_mask: 0.1995  decode.d8.loss_dice: 0.1531
09/30 23:37:30 - mmengine - INFO - Iter(train) [119700/320000]  base_lr: 6.5596e-05 lr: 6.5596e-06  eta: 1 day, 0:20:28  time: 0.4414  data_time: 0.0096  memory: 5129  grad_norm: 30.9388  loss: 5.3477  decode.loss_cls: 0.0190  decode.loss_mask: 0.2143  decode.loss_dice: 0.2125  decode.d0.loss_cls: 0.8737  decode.d0.loss_mask: 0.2159  decode.d0.loss_dice: 0.2003  decode.d1.loss_cls: 0.0384  decode.d1.loss_mask: 0.2155  decode.d1.loss_dice: 0.2110  decode.d2.loss_cls: 0.0377  decode.d2.loss_mask: 0.2110  decode.d2.loss_dice: 0.2066  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.2148  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.2146  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2065  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.2129  decode.d6.loss_dice: 0.2083  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.2109  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.2141  decode.d8.loss_dice: 0.2032
09/30 23:37:52 - mmengine - INFO - Iter(train) [119750/320000]  base_lr: 6.5582e-05 lr: 6.5582e-06  eta: 1 day, 0:20:06  time: 0.4416  data_time: 0.0098  memory: 5129  grad_norm: 58.1848  loss: 5.5015  decode.loss_cls: 0.0240  decode.loss_mask: 0.2334  decode.loss_dice: 0.1925  decode.d0.loss_cls: 0.7577  decode.d0.loss_mask: 0.2362  decode.d0.loss_dice: 0.2139  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.2363  decode.d1.loss_dice: 0.1869  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.2327  decode.d2.loss_dice: 0.1906  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.2360  decode.d3.loss_dice: 0.1919  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.1875  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.1874  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1916  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.1889  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.2321  decode.d8.loss_dice: 0.1985
09/30 23:38:14 - mmengine - INFO - Iter(train) [119800/320000]  base_lr: 6.5567e-05 lr: 6.5567e-06  eta: 1 day, 0:19:45  time: 0.4417  data_time: 0.0096  memory: 5129  grad_norm: 116.8035  loss: 8.4338  decode.loss_cls: 0.1530  decode.loss_mask: 0.3076  decode.loss_dice: 0.2968  decode.d0.loss_cls: 0.8131  decode.d0.loss_mask: 0.3212  decode.d0.loss_dice: 0.3014  decode.d1.loss_cls: 0.2180  decode.d1.loss_mask: 0.3057  decode.d1.loss_dice: 0.3057  decode.d2.loss_cls: 0.1488  decode.d2.loss_mask: 0.3021  decode.d2.loss_dice: 0.3072  decode.d3.loss_cls: 0.1527  decode.d3.loss_mask: 0.3017  decode.d3.loss_dice: 0.3153  decode.d4.loss_cls: 0.1828  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.3153  decode.d5.loss_cls: 0.1889  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.3131  decode.d6.loss_cls: 0.1502  decode.d6.loss_mask: 0.3126  decode.d6.loss_dice: 0.3292  decode.d7.loss_cls: 0.1255  decode.d7.loss_mask: 0.3095  decode.d7.loss_dice: 0.2842  decode.d8.loss_cls: 0.1422  decode.d8.loss_mask: 0.3115  decode.d8.loss_dice: 0.3074
09/30 23:38:37 - mmengine - INFO - Iter(train) [119850/320000]  base_lr: 6.5552e-05 lr: 6.5552e-06  eta: 1 day, 0:19:24  time: 0.4431  data_time: 0.0099  memory: 5120  grad_norm: 199.6383  loss: 6.4555  decode.loss_cls: 0.0650  decode.loss_mask: 0.2770  decode.loss_dice: 0.2255  decode.d0.loss_cls: 0.8809  decode.d0.loss_mask: 0.2642  decode.d0.loss_dice: 0.2115  decode.d1.loss_cls: 0.0831  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2189  decode.d2.loss_cls: 0.0707  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.2197  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.2400  decode.d3.loss_dice: 0.2102  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.2734  decode.d4.loss_dice: 0.2209  decode.d5.loss_cls: 0.1479  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.2096  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.2604  decode.d6.loss_dice: 0.2170  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.2699  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.2879  decode.d8.loss_dice: 0.2122
09/30 23:38:59 - mmengine - INFO - Iter(train) [119900/320000]  base_lr: 6.5537e-05 lr: 6.5537e-06  eta: 1 day, 0:19:02  time: 0.4423  data_time: 0.0097  memory: 5129  grad_norm: 31.0183  loss: 4.7745  decode.loss_cls: 0.0039  decode.loss_mask: 0.2092  decode.loss_dice: 0.1766  decode.d0.loss_cls: 0.8608  decode.d0.loss_mask: 0.2161  decode.d0.loss_dice: 0.1727  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.1720  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.1794  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.2113  decode.d4.loss_dice: 0.1768  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2129  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2102  decode.d6.loss_dice: 0.1756  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.2108  decode.d7.loss_dice: 0.1738  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.1734
09/30 23:39:21 - mmengine - INFO - Iter(train) [119950/320000]  base_lr: 6.5523e-05 lr: 6.5523e-06  eta: 1 day, 0:18:41  time: 0.4418  data_time: 0.0097  memory: 5145  grad_norm: 74.3991  loss: 6.2900  decode.loss_cls: 0.0457  decode.loss_mask: 0.2460  decode.loss_dice: 0.2470  decode.d0.loss_cls: 0.7417  decode.d0.loss_mask: 0.2546  decode.d0.loss_dice: 0.2508  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.2496  decode.d1.loss_dice: 0.2212  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.2415  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2363  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.2459  decode.d4.loss_dice: 0.2479  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.2481  decode.d5.loss_dice: 0.2443  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.2294  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.2477  decode.d7.loss_dice: 0.2346  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.2469  decode.d8.loss_dice: 0.2351
09/30 23:39:43 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:39:43 - mmengine - INFO - Iter(train) [120000/320000]  base_lr: 6.5508e-05 lr: 6.5508e-06  eta: 1 day, 0:18:19  time: 0.4420  data_time: 0.0097  memory: 5129  grad_norm: 88.2075  loss: 4.8204  decode.loss_cls: 0.0364  decode.loss_mask: 0.1828  decode.loss_dice: 0.1710  decode.d0.loss_cls: 0.8395  decode.d0.loss_mask: 0.1871  decode.d0.loss_dice: 0.1674  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.1834  decode.d1.loss_dice: 0.1625  decode.d2.loss_cls: 0.0849  decode.d2.loss_mask: 0.1833  decode.d2.loss_dice: 0.1671  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.1619  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.1861  decode.d4.loss_dice: 0.1650  decode.d5.loss_cls: 0.0398  decode.d5.loss_mask: 0.1845  decode.d5.loss_dice: 0.1698  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.1853  decode.d6.loss_dice: 0.1741  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.1854  decode.d7.loss_dice: 0.1633  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1769
09/30 23:39:43 - mmengine - INFO - Saving checkpoint at 120000 iterations
09/30 23:39:53 - mmengine - INFO - Iter(val) [ 50/206]    eta: 0:00:25  time: 0.1775  data_time: 0.0047  memory: 2997  
09/30 23:40:02 - mmengine - INFO - Iter(val) [100/206]    eta: 0:00:17  time: 0.1773  data_time: 0.0046  memory: 2997  
09/30 23:40:11 - mmengine - INFO - Iter(val) [150/206]    eta: 0:00:09  time: 0.1776  data_time: 0.0047  memory: 2997  
09/30 23:40:20 - mmengine - INFO - Iter(val) [200/206]    eta: 0:00:01  time: 0.1760  data_time: 0.0041  memory: 2997  
09/30 23:40:21 - mmengine - INFO - per class results:
09/30 23:40:21 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|      background     |  98.6 |  99.4 |
|   beetroot-poriyal  | 98.01 | 99.11 |
|        bhindi       | 94.89 | 98.14 |
| capsicum-green-peas | 95.93 | 98.79 |
|     dosakay-dal     | 82.36 | 92.46 |
|    dosakaya-curry   | 95.69 | 97.72 |
|    jaipuri-sabji    | 97.62 | 98.72 |
|  ladiesfinger-curry | 97.73 | 98.73 |
|    lobiya-masala    |  96.1 | 98.94 |
|        pongal       |  0.0  |  0.0  |
|    pumpkin-gravy    |  98.4 | 99.21 |
|     pumpkin-dry     | 95.15 | 96.56 |
|     rajma-masala    | 97.94 | 98.47 |
|      tomato-dal     | 96.81 | 97.66 |
|     turai-moong     | 91.49 | 99.29 |
|     turai-tomato    | 96.49 |  98.3 |
|    beerakay-curry   | 97.48 | 98.48 |
|   cabbage-poriyal   | 97.33 | 98.37 |
|    capsicum-gravy   | 97.79 | 98.51 |
|     chana-masala    | 96.46 | 97.88 |
|      chow-chow      | 97.06 | 98.43 |
|       chutney       | 88.45 | 89.23 |
|      curd-rice      | 89.91 | 92.62 |
|         dal         | 93.51 | 94.46 |
|      dal-tadka      | 97.19 | 98.17 |
|        daliya       | 97.82 | 98.81 |
|     daliya-upma     | 91.19 | 97.95 |
|     donda-curry     | 97.41 | 98.17 |
|    dosakaya-gravy   | 95.81 | 97.44 |
|      egg-white      | 90.17 | 94.17 |
|         idly        | 86.37 | 87.44 |
|       khichdi       |  95.1 | 98.23 |
| ladies-finger-gravy | 97.55 | 98.58 |
|      methi-dal      | 97.44 | 98.47 |
|  mixed-veg-poriyal  | 95.34 | 97.74 |
|   palak-soya-curry  | 96.93 | 98.32 |
|     paneer-gravy    | 97.14 |  97.8 |
|         poha        | 95.37 |  96.1 |
|    pumpkin-masala   | 92.82 | 98.27 |
|    raw-banana-dry   |  96.7 | 98.17 |
|         rice        | 96.11 | 98.07 |
|         roti        | 94.93 | 97.86 |
|        sambar       | 89.85 | 90.84 |
|    snakegourd-dry   | 95.71 | 97.75 |
|   snakeguard-curry  |  97.7 | 98.56 |
|      soya-gravy     | 97.28 | 98.03 |
|   thotakura-pappu   | 96.81 | 98.57 |
|         upma        | 95.63 | 97.95 |
|       uttapam       |  0.0  |  0.0  |
+---------------------+-------+-------+
09/30 23:40:21 - mmengine - INFO - Iter(val) [206/206]    aAcc: 98.7800  mIoU: 91.3400  mAcc: 93.2800  data_time: 0.0048  time: 0.1735
09/30 23:40:21 - mmengine - INFO - The previous best checkpoint /scratch/segmentation_benchmark/mmseg_work_dir/AR_mask2former/best_mIoU_iter_40000.pth is removed
09/30 23:40:22 - mmengine - INFO - The best checkpoint with 91.3400 mIoU at 120000 iter is saved to best_mIoU_iter_120000.pth.
09/30 23:40:50 - mmengine - INFO - Iter(train) [120050/320000]  base_lr: 6.5493e-05 lr: 6.5493e-06  eta: 1 day, 0:18:09  time: 0.4408  data_time: 0.0099  memory: 5120  grad_norm: 74.1910  loss: 5.8328  decode.loss_cls: 0.0506  decode.loss_mask: 0.2179  decode.loss_dice: 0.2422  decode.d0.loss_cls: 0.8401  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.2602  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.2159  decode.d1.loss_dice: 0.2300  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2400  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.2158  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.0329  decode.d4.loss_mask: 0.2143  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.0332  decode.d5.loss_mask: 0.2160  decode.d5.loss_dice: 0.2430  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.2169  decode.d6.loss_dice: 0.2373  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.2288  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.2141  decode.d8.loss_dice: 0.2410
09/30 23:41:12 - mmengine - INFO - Iter(train) [120100/320000]  base_lr: 6.5478e-05 lr: 6.5478e-06  eta: 1 day, 0:17:47  time: 0.4430  data_time: 0.0100  memory: 5145  grad_norm: 50.3673  loss: 6.0044  decode.loss_cls: 0.0781  decode.loss_mask: 0.2435  decode.loss_dice: 0.2158  decode.d0.loss_cls: 0.8108  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.2056  decode.d1.loss_cls: 0.0891  decode.d1.loss_mask: 0.2448  decode.d1.loss_dice: 0.2113  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2071  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.2430  decode.d3.loss_dice: 0.2005  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.2459  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.0458  decode.d5.loss_mask: 0.2426  decode.d5.loss_dice: 0.2151  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.2480  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.2495  decode.d8.loss_dice: 0.2149
09/30 23:41:34 - mmengine - INFO - Iter(train) [120150/320000]  base_lr: 6.5464e-05 lr: 6.5464e-06  eta: 1 day, 0:17:26  time: 0.4429  data_time: 0.0101  memory: 5129  grad_norm: 39.1006  loss: 6.2000  decode.loss_cls: 0.1413  decode.loss_mask: 0.1837  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.9217  decode.d0.loss_mask: 0.1911  decode.d0.loss_dice: 0.2147  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.1856  decode.d1.loss_dice: 0.2252  decode.d2.loss_cls: 0.1255  decode.d2.loss_mask: 0.1831  decode.d2.loss_dice: 0.2193  decode.d3.loss_cls: 0.1180  decode.d3.loss_mask: 0.1851  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.1126  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.1204  decode.d5.loss_mask: 0.1845  decode.d5.loss_dice: 0.2209  decode.d6.loss_cls: 0.1613  decode.d6.loss_mask: 0.1829  decode.d6.loss_dice: 0.2161  decode.d7.loss_cls: 0.1610  decode.d7.loss_mask: 0.1838  decode.d7.loss_dice: 0.2216  decode.d8.loss_cls: 0.1167  decode.d8.loss_mask: 0.1844  decode.d8.loss_dice: 0.2278
09/30 23:41:56 - mmengine - INFO - Iter(train) [120200/320000]  base_lr: 6.5449e-05 lr: 6.5449e-06  eta: 1 day, 0:17:04  time: 0.4449  data_time: 0.0101  memory: 5120  grad_norm: 56.9954  loss: 6.6069  decode.loss_cls: 0.0922  decode.loss_mask: 0.2512  decode.loss_dice: 0.2347  decode.d0.loss_cls: 0.9447  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2225  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.2354  decode.d1.loss_dice: 0.2150  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.1155  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.2290  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.2320  decode.d5.loss_cls: 0.0960  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2289  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.2254  decode.d7.loss_cls: 0.0993  decode.d7.loss_mask: 0.2461  decode.d7.loss_dice: 0.2278  decode.d8.loss_cls: 0.0994  decode.d8.loss_mask: 0.2719  decode.d8.loss_dice: 0.2423
09/30 23:42:18 - mmengine - INFO - Iter(train) [120250/320000]  base_lr: 6.5434e-05 lr: 6.5434e-06  eta: 1 day, 0:16:43  time: 0.4431  data_time: 0.0101  memory: 5129  grad_norm: 42.6161  loss: 5.5229  decode.loss_cls: 0.0122  decode.loss_mask: 0.2182  decode.loss_dice: 0.2540  decode.d0.loss_cls: 0.8447  decode.d0.loss_mask: 0.2206  decode.d0.loss_dice: 0.2356  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.2344  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.2147  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.2193  decode.d3.loss_dice: 0.2405  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.2194  decode.d5.loss_dice: 0.2348  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.2353  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.2165  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.2274
09/30 23:42:41 - mmengine - INFO - Iter(train) [120300/320000]  base_lr: 6.5419e-05 lr: 6.5419e-06  eta: 1 day, 0:16:22  time: 0.4448  data_time: 0.0100  memory: 5129  grad_norm: 24.3584  loss: 3.9868  decode.loss_cls: 0.0035  decode.loss_mask: 0.1500  decode.loss_dice: 0.1479  decode.d0.loss_cls: 0.8778  decode.d0.loss_mask: 0.1521  decode.d0.loss_dice: 0.1487  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.1507  decode.d1.loss_dice: 0.1469  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.1521  decode.d2.loss_dice: 0.1507  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.1522  decode.d3.loss_dice: 0.1501  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.1508  decode.d4.loss_dice: 0.1529  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.1516  decode.d5.loss_dice: 0.1606  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.1504  decode.d6.loss_dice: 0.1504  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.1488  decode.d7.loss_dice: 0.1514  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.1475  decode.d8.loss_dice: 0.1491
09/30 23:43:03 - mmengine - INFO - Iter(train) [120350/320000]  base_lr: 6.5405e-05 lr: 6.5405e-06  eta: 1 day, 0:16:00  time: 0.4429  data_time: 0.0100  memory: 5129  grad_norm: 51.9688  loss: 7.1293  decode.loss_cls: 0.1497  decode.loss_mask: 0.2670  decode.loss_dice: 0.2920  decode.d0.loss_cls: 0.9242  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.2304  decode.d1.loss_cls: 0.1025  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.2427  decode.d2.loss_cls: 0.1164  decode.d2.loss_mask: 0.2319  decode.d2.loss_dice: 0.2627  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2319  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.2329  decode.d4.loss_dice: 0.2349  decode.d5.loss_cls: 0.1452  decode.d5.loss_mask: 0.2869  decode.d5.loss_dice: 0.3068  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 0.2531  decode.d6.loss_dice: 0.2503  decode.d7.loss_cls: 0.0962  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2872  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.2599  decode.d8.loss_dice: 0.2731
09/30 23:43:25 - mmengine - INFO - Iter(train) [120400/320000]  base_lr: 6.5390e-05 lr: 6.5390e-06  eta: 1 day, 0:15:39  time: 0.4428  data_time: 0.0099  memory: 5145  grad_norm: 58.1999  loss: 6.2294  decode.loss_cls: 0.0852  decode.loss_mask: 0.2163  decode.loss_dice: 0.2470  decode.d0.loss_cls: 0.8152  decode.d0.loss_mask: 0.2204  decode.d0.loss_dice: 0.2269  decode.d1.loss_cls: 0.1360  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.2319  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2325  decode.d3.loss_cls: 0.0991  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.0826  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.2399  decode.d5.loss_cls: 0.0948  decode.d5.loss_mask: 0.2149  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.2176  decode.d6.loss_dice: 0.2339  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.2451  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.2371
09/30 23:43:47 - mmengine - INFO - Iter(train) [120450/320000]  base_lr: 6.5375e-05 lr: 6.5375e-06  eta: 1 day, 0:15:17  time: 0.4433  data_time: 0.0102  memory: 5120  grad_norm: 80.7454  loss: 6.4338  decode.loss_cls: 0.1071  decode.loss_mask: 0.2249  decode.loss_dice: 0.2093  decode.d0.loss_cls: 0.8540  decode.d0.loss_mask: 0.2257  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.1396  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.2193  decode.d2.loss_cls: 0.1293  decode.d2.loss_mask: 0.2317  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.2295  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.2297  decode.d4.loss_dice: 0.2093  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 0.2268  decode.d5.loss_dice: 0.2156  decode.d6.loss_cls: 0.1391  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.2161  decode.d7.loss_cls: 0.1345  decode.d7.loss_mask: 0.2250  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.1366  decode.d8.loss_mask: 0.2235  decode.d8.loss_dice: 0.2098
09/30 23:44:09 - mmengine - INFO - Iter(train) [120500/320000]  base_lr: 6.5360e-05 lr: 6.5360e-06  eta: 1 day, 0:14:56  time: 0.4435  data_time: 0.0103  memory: 5129  grad_norm: 37.1577  loss: 5.7997  decode.loss_cls: 0.0085  decode.loss_mask: 0.2798  decode.loss_dice: 0.2029  decode.d0.loss_cls: 0.9024  decode.d0.loss_mask: 0.2804  decode.d0.loss_dice: 0.1873  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.2826  decode.d1.loss_dice: 0.2002  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.2842  decode.d2.loss_dice: 0.2027  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.2052  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.2830  decode.d4.loss_dice: 0.1999  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.2805  decode.d5.loss_dice: 0.2080  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.2795  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2827  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.1980
09/30 23:44:32 - mmengine - INFO - Iter(train) [120550/320000]  base_lr: 6.5346e-05 lr: 6.5346e-06  eta: 1 day, 0:14:35  time: 0.4430  data_time: 0.0101  memory: 5129  grad_norm: 60.2471  loss: 5.1216  decode.loss_cls: 0.0255  decode.loss_mask: 0.1955  decode.loss_dice: 0.1915  decode.d0.loss_cls: 0.8068  decode.d0.loss_mask: 0.1964  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.1925  decode.d1.loss_dice: 0.1830  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.1910  decode.d2.loss_dice: 0.1896  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.1852  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.1910  decode.d4.loss_dice: 0.1960  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.1905  decode.d5.loss_dice: 0.1948  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.1937  decode.d6.loss_dice: 0.2004  decode.d7.loss_cls: 0.0343  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.1836  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 0.1918  decode.d8.loss_dice: 0.1887
09/30 23:44:54 - mmengine - INFO - Iter(train) [120600/320000]  base_lr: 6.5331e-05 lr: 6.5331e-06  eta: 1 day, 0:14:13  time: 0.4439  data_time: 0.0103  memory: 5120  grad_norm: 63.7060  loss: 5.7743  decode.loss_cls: 0.0366  decode.loss_mask: 0.2438  decode.loss_dice: 0.2059  decode.d0.loss_cls: 0.8005  decode.d0.loss_mask: 0.2470  decode.d0.loss_dice: 0.2115  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.2458  decode.d1.loss_dice: 0.2103  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.2075  decode.d3.loss_cls: 0.0397  decode.d3.loss_mask: 0.2459  decode.d3.loss_dice: 0.2171  decode.d4.loss_cls: 0.0311  decode.d4.loss_mask: 0.2469  decode.d4.loss_dice: 0.2151  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.0468  decode.d6.loss_mask: 0.2486  decode.d6.loss_dice: 0.2151  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.2466  decode.d7.loss_dice: 0.2229  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.2460  decode.d8.loss_dice: 0.2203
09/30 23:45:16 - mmengine - INFO - Iter(train) [120650/320000]  base_lr: 6.5316e-05 lr: 6.5316e-06  eta: 1 day, 0:13:52  time: 0.4443  data_time: 0.0104  memory: 5120  grad_norm: 33.0375  loss: 5.3792  decode.loss_cls: 0.1157  decode.loss_mask: 0.2018  decode.loss_dice: 0.1596  decode.d0.loss_cls: 0.6973  decode.d0.loss_mask: 0.1994  decode.d0.loss_dice: 0.1774  decode.d1.loss_cls: 0.1122  decode.d1.loss_mask: 0.2038  decode.d1.loss_dice: 0.1700  decode.d2.loss_cls: 0.1093  decode.d2.loss_mask: 0.2038  decode.d2.loss_dice: 0.1723  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2026  decode.d3.loss_dice: 0.1584  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.1872  decode.d5.loss_cls: 0.1401  decode.d5.loss_mask: 0.2023  decode.d5.loss_dice: 0.1573  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.1997  decode.d6.loss_dice: 0.1646  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.2000  decode.d7.loss_dice: 0.1774  decode.d8.loss_cls: 0.0981  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.1925
09/30 23:45:38 - mmengine - INFO - Iter(train) [120700/320000]  base_lr: 6.5301e-05 lr: 6.5301e-06  eta: 1 day, 0:13:31  time: 0.4434  data_time: 0.0101  memory: 5145  grad_norm: 20.9554  loss: 5.5550  decode.loss_cls: 0.0814  decode.loss_mask: 0.2014  decode.loss_dice: 0.2174  decode.d0.loss_cls: 0.6682  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.2124  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.1991  decode.d2.loss_dice: 0.2155  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.2017  decode.d3.loss_dice: 0.2203  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.0744  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.2194  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.2024  decode.d6.loss_dice: 0.2178  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.2026  decode.d7.loss_dice: 0.2217  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.2007  decode.d8.loss_dice: 0.2241
09/30 23:46:00 - mmengine - INFO - Iter(train) [120750/320000]  base_lr: 6.5287e-05 lr: 6.5287e-06  eta: 1 day, 0:13:09  time: 0.4429  data_time: 0.0102  memory: 5145  grad_norm: 32.5950  loss: 4.9696  decode.loss_cls: 0.0037  decode.loss_mask: 0.2275  decode.loss_dice: 0.1837  decode.d0.loss_cls: 0.8243  decode.d0.loss_mask: 0.2282  decode.d0.loss_dice: 0.1825  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.1843  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.1824  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.1822  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.1809  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.1819  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.1813  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.1835  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1855
09/30 23:46:23 - mmengine - INFO - Iter(train) [120800/320000]  base_lr: 6.5272e-05 lr: 6.5272e-06  eta: 1 day, 0:12:48  time: 0.4433  data_time: 0.0101  memory: 5129  grad_norm: 75.9010  loss: 5.8666  decode.loss_cls: 0.0991  decode.loss_mask: 0.2422  decode.loss_dice: 0.1896  decode.d0.loss_cls: 0.9488  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.1939  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.1873  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.2478  decode.d2.loss_dice: 0.1830  decode.d3.loss_cls: 0.0479  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.1889  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.1924  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.1826  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.2530  decode.d8.loss_dice: 0.1960
09/30 23:46:45 - mmengine - INFO - Iter(train) [120850/320000]  base_lr: 6.5257e-05 lr: 6.5257e-06  eta: 1 day, 0:12:27  time: 0.4445  data_time: 0.0100  memory: 5129  grad_norm: 144.5575  loss: 9.4340  decode.loss_cls: 0.2709  decode.loss_mask: 0.2973  decode.loss_dice: 0.3401  decode.d0.loss_cls: 0.9343  decode.d0.loss_mask: 0.2555  decode.d0.loss_dice: 0.2899  decode.d1.loss_cls: 0.3294  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.3177  decode.d2.loss_cls: 0.3160  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.2669  decode.d3.loss_mask: 0.2673  decode.d3.loss_dice: 0.3329  decode.d4.loss_cls: 0.2530  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.3189  decode.d5.loss_cls: 0.2048  decode.d5.loss_mask: 0.3445  decode.d5.loss_dice: 0.2863  decode.d6.loss_cls: 0.3592  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.3055  decode.d7.loss_cls: 0.2950  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.3479  decode.d8.loss_cls: 0.3026  decode.d8.loss_mask: 0.2391  decode.d8.loss_dice: 0.3455
09/30 23:47:07 - mmengine - INFO - Iter(train) [120900/320000]  base_lr: 6.5242e-05 lr: 6.5242e-06  eta: 1 day, 0:12:05  time: 0.4442  data_time: 0.0101  memory: 5129  grad_norm: 62.2914  loss: 6.4093  decode.loss_cls: 0.0454  decode.loss_mask: 0.2270  decode.loss_dice: 0.2513  decode.d0.loss_cls: 0.8266  decode.d0.loss_mask: 0.2309  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2290  decode.d2.loss_cls: 0.1273  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2456  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.2264  decode.d3.loss_dice: 0.2467  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.2237  decode.d4.loss_dice: 0.2679  decode.d5.loss_cls: 0.1243  decode.d5.loss_mask: 0.2242  decode.d5.loss_dice: 0.2367  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.2502  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.2251  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2608
09/30 23:47:29 - mmengine - INFO - Iter(train) [120950/320000]  base_lr: 6.5228e-05 lr: 6.5228e-06  eta: 1 day, 0:11:44  time: 0.4438  data_time: 0.0101  memory: 5129  grad_norm: 37.0307  loss: 5.4837  decode.loss_cls: 0.0457  decode.loss_mask: 0.2099  decode.loss_dice: 0.1948  decode.d0.loss_cls: 0.8972  decode.d0.loss_mask: 0.2078  decode.d0.loss_dice: 0.2011  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.1923  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.1987  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.2107  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 0.2126  decode.d5.loss_dice: 0.1984  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.2094  decode.d6.loss_dice: 0.1899  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.2085  decode.d7.loss_dice: 0.1939  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.1974
09/30 23:47:51 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:47:52 - mmengine - INFO - Iter(train) [121000/320000]  base_lr: 6.5213e-05 lr: 6.5213e-06  eta: 1 day, 0:11:22  time: 0.4433  data_time: 0.0102  memory: 5120  grad_norm: 23.5905  loss: 4.9276  decode.loss_cls: 0.0037  decode.loss_mask: 0.2166  decode.loss_dice: 0.1725  decode.d0.loss_cls: 0.9062  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.1801  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.2186  decode.d1.loss_dice: 0.1788  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.1791  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.1831  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.2155  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2173  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.1790  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.2178  decode.d8.loss_dice: 0.1804
09/30 23:48:14 - mmengine - INFO - Iter(train) [121050/320000]  base_lr: 6.5198e-05 lr: 6.5198e-06  eta: 1 day, 0:11:01  time: 0.4425  data_time: 0.0101  memory: 5129  grad_norm: 52.9343  loss: 5.4065  decode.loss_cls: 0.1077  decode.loss_mask: 0.1849  decode.loss_dice: 0.1770  decode.d0.loss_cls: 0.7990  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1644  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 0.1838  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.1848  decode.d2.loss_dice: 0.1475  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.1483  decode.d4.loss_cls: 0.1454  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.1124  decode.d5.loss_mask: 0.1829  decode.d5.loss_dice: 0.1534  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 0.1869  decode.d6.loss_dice: 0.1744  decode.d7.loss_cls: 0.1131  decode.d7.loss_mask: 0.1864  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.1170  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1802
09/30 23:48:36 - mmengine - INFO - Iter(train) [121100/320000]  base_lr: 6.5183e-05 lr: 6.5183e-06  eta: 1 day, 0:10:40  time: 0.4433  data_time: 0.0102  memory: 5104  grad_norm: 61.6092  loss: 5.4788  decode.loss_cls: 0.0045  decode.loss_mask: 0.2201  decode.loss_dice: 0.2517  decode.d0.loss_cls: 0.7839  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.2219  decode.d1.loss_dice: 0.2454  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2195  decode.d2.loss_dice: 0.2678  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2254  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.2200  decode.d4.loss_dice: 0.2313  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.2249  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2204  decode.d6.loss_dice: 0.2358  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.2353  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.2434
09/30 23:48:58 - mmengine - INFO - Iter(train) [121150/320000]  base_lr: 6.5169e-05 lr: 6.5169e-06  eta: 1 day, 0:10:18  time: 0.4424  data_time: 0.0101  memory: 5120  grad_norm: 136.4441  loss: 5.0327  decode.loss_cls: 0.0308  decode.loss_mask: 0.2210  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.8138  decode.d0.loss_mask: 0.2244  decode.d0.loss_dice: 0.1641  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1689  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.1718  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.2187  decode.d3.loss_dice: 0.1704  decode.d4.loss_cls: 0.0391  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.1728  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.2192  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.2207  decode.d6.loss_dice: 0.1681  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.1725  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.1711
09/30 23:49:20 - mmengine - INFO - Iter(train) [121200/320000]  base_lr: 6.5154e-05 lr: 6.5154e-06  eta: 1 day, 0:09:57  time: 0.4425  data_time: 0.0099  memory: 5129  grad_norm: 24.6537  loss: 5.0297  decode.loss_cls: 0.0959  decode.loss_mask: 0.1609  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.7970  decode.d0.loss_mask: 0.1638  decode.d0.loss_dice: 0.1676  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.1642  decode.d1.loss_dice: 0.1829  decode.d2.loss_cls: 0.1408  decode.d2.loss_mask: 0.1619  decode.d2.loss_dice: 0.1656  decode.d3.loss_cls: 0.1021  decode.d3.loss_mask: 0.1606  decode.d3.loss_dice: 0.1880  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.1619  decode.d4.loss_dice: 0.1829  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.1624  decode.d5.loss_dice: 0.1947  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.1620  decode.d6.loss_dice: 0.1801  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.1608  decode.d7.loss_dice: 0.1909  decode.d8.loss_cls: 0.1118  decode.d8.loss_mask: 0.1582  decode.d8.loss_dice: 0.1856
09/30 23:49:42 - mmengine - INFO - Iter(train) [121250/320000]  base_lr: 6.5139e-05 lr: 6.5139e-06  eta: 1 day, 0:09:35  time: 0.4438  data_time: 0.0102  memory: 5129  grad_norm: 46.8119  loss: 4.9541  decode.loss_cls: 0.0437  decode.loss_mask: 0.1990  decode.loss_dice: 0.1696  decode.d0.loss_cls: 0.8188  decode.d0.loss_mask: 0.2013  decode.d0.loss_dice: 0.1674  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.2019  decode.d1.loss_dice: 0.1704  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.2008  decode.d2.loss_dice: 0.1718  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.2004  decode.d3.loss_dice: 0.1679  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.1691  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.1982  decode.d5.loss_dice: 0.1699  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1676  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.2015  decode.d7.loss_dice: 0.1719  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.1737
09/30 23:50:05 - mmengine - INFO - Iter(train) [121300/320000]  base_lr: 6.5124e-05 lr: 6.5124e-06  eta: 1 day, 0:09:14  time: 0.4438  data_time: 0.0102  memory: 5129  grad_norm: 51.1841  loss: 5.1043  decode.loss_cls: 0.0674  decode.loss_mask: 0.1859  decode.loss_dice: 0.1676  decode.d0.loss_cls: 0.8111  decode.d0.loss_mask: 0.1892  decode.d0.loss_dice: 0.1747  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.1873  decode.d1.loss_dice: 0.1794  decode.d2.loss_cls: 0.0865  decode.d2.loss_mask: 0.1854  decode.d2.loss_dice: 0.1734  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.1864  decode.d3.loss_dice: 0.1829  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.1869  decode.d4.loss_dice: 0.1787  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.1883  decode.d5.loss_dice: 0.1800  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.1854  decode.d6.loss_dice: 0.1771  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.1855  decode.d7.loss_dice: 0.1673  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.1845  decode.d8.loss_dice: 0.1763
09/30 23:50:27 - mmengine - INFO - Iter(train) [121350/320000]  base_lr: 6.5110e-05 lr: 6.5110e-06  eta: 1 day, 0:08:53  time: 0.4438  data_time: 0.0101  memory: 5145  grad_norm: 38.1263  loss: 4.3945  decode.loss_cls: 0.0368  decode.loss_mask: 0.1724  decode.loss_dice: 0.1599  decode.d0.loss_cls: 0.7337  decode.d0.loss_mask: 0.1741  decode.d0.loss_dice: 0.1643  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.1711  decode.d1.loss_dice: 0.1316  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.1726  decode.d2.loss_dice: 0.1610  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.1738  decode.d3.loss_dice: 0.1679  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.1725  decode.d4.loss_dice: 0.1633  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.1726  decode.d5.loss_dice: 0.1605  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.1742  decode.d6.loss_dice: 0.1308  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.1739  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.1744  decode.d8.loss_dice: 0.1762
09/30 23:50:49 - mmengine - INFO - Iter(train) [121400/320000]  base_lr: 6.5095e-05 lr: 6.5095e-06  eta: 1 day, 0:08:31  time: 0.4430  data_time: 0.0100  memory: 5129  grad_norm: 83.5148  loss: 6.7722  decode.loss_cls: 0.2091  decode.loss_mask: 0.2074  decode.loss_dice: 0.2292  decode.d0.loss_cls: 0.8615  decode.d0.loss_mask: 0.2111  decode.d0.loss_dice: 0.2079  decode.d1.loss_cls: 0.1702  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.2409  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.2395  decode.d3.loss_cls: 0.1607  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.1774  decode.d4.loss_mask: 0.2054  decode.d4.loss_dice: 0.2382  decode.d5.loss_cls: 0.1441  decode.d5.loss_mask: 0.2092  decode.d5.loss_dice: 0.2202  decode.d6.loss_cls: 0.1951  decode.d6.loss_mask: 0.2121  decode.d6.loss_dice: 0.2141  decode.d7.loss_cls: 0.1860  decode.d7.loss_mask: 0.2088  decode.d7.loss_dice: 0.2402  decode.d8.loss_cls: 0.1782  decode.d8.loss_mask: 0.2083  decode.d8.loss_dice: 0.2466
09/30 23:51:11 - mmengine - INFO - Iter(train) [121450/320000]  base_lr: 6.5080e-05 lr: 6.5080e-06  eta: 1 day, 0:08:10  time: 0.4433  data_time: 0.0103  memory: 5146  grad_norm: 81.1843  loss: 6.9020  decode.loss_cls: 0.1833  decode.loss_mask: 0.2525  decode.loss_dice: 0.2313  decode.d0.loss_cls: 0.8856  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.2477  decode.d1.loss_cls: 0.1671  decode.d1.loss_mask: 0.2463  decode.d1.loss_dice: 0.2031  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2075  decode.d3.loss_cls: 0.1376  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.1432  decode.d4.loss_mask: 0.2446  decode.d4.loss_dice: 0.2012  decode.d5.loss_cls: 0.1621  decode.d5.loss_mask: 0.2474  decode.d5.loss_dice: 0.2070  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2154  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.2233  decode.d8.loss_cls: 0.1891  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2155
09/30 23:51:33 - mmengine - INFO - Iter(train) [121500/320000]  base_lr: 6.5065e-05 lr: 6.5065e-06  eta: 1 day, 0:07:48  time: 0.4433  data_time: 0.0102  memory: 5145  grad_norm: 46.5324  loss: 5.0046  decode.loss_cls: 0.0110  decode.loss_mask: 0.2037  decode.loss_dice: 0.1926  decode.d0.loss_cls: 0.9105  decode.d0.loss_mask: 0.1990  decode.d0.loss_dice: 0.1790  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.2021  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.1890  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.2035  decode.d3.loss_dice: 0.1908  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.2036  decode.d4.loss_dice: 0.1782  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.2033  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.1894  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.1902
09/30 23:51:56 - mmengine - INFO - Iter(train) [121550/320000]  base_lr: 6.5051e-05 lr: 6.5051e-06  eta: 1 day, 0:07:27  time: 0.4436  data_time: 0.0101  memory: 5129  grad_norm: 28.3551  loss: 4.6346  decode.loss_cls: 0.0324  decode.loss_mask: 0.1755  decode.loss_dice: 0.1628  decode.d0.loss_cls: 0.8154  decode.d0.loss_mask: 0.1789  decode.d0.loss_dice: 0.1838  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.1745  decode.d1.loss_dice: 0.1670  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.1646  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.1778  decode.d3.loss_dice: 0.1603  decode.d4.loss_cls: 0.0401  decode.d4.loss_mask: 0.1763  decode.d4.loss_dice: 0.1611  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.1735  decode.d5.loss_dice: 0.1662  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.1757  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.1751  decode.d7.loss_dice: 0.1988  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.1736  decode.d8.loss_dice: 0.1597
09/30 23:52:18 - mmengine - INFO - Iter(train) [121600/320000]  base_lr: 6.5036e-05 lr: 6.5036e-06  eta: 1 day, 0:07:06  time: 0.4436  data_time: 0.0100  memory: 5145  grad_norm: 24.5372  loss: 4.7783  decode.loss_cls: 0.0559  decode.loss_mask: 0.1924  decode.loss_dice: 0.1493  decode.d0.loss_cls: 0.8434  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.1424  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.1916  decode.d1.loss_dice: 0.1503  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.1906  decode.d2.loss_dice: 0.1539  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.1916  decode.d3.loss_dice: 0.1482  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.1896  decode.d4.loss_dice: 0.1450  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.1480  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.1906  decode.d6.loss_dice: 0.1518  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.1903  decode.d7.loss_dice: 0.1466  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.1912  decode.d8.loss_dice: 0.1485
09/30 23:52:40 - mmengine - INFO - Iter(train) [121650/320000]  base_lr: 6.5021e-05 lr: 6.5021e-06  eta: 1 day, 0:06:44  time: 0.4432  data_time: 0.0100  memory: 5129  grad_norm: 86.0344  loss: 6.8990  decode.loss_cls: 0.1244  decode.loss_mask: 0.2261  decode.loss_dice: 0.2692  decode.d0.loss_cls: 0.8374  decode.d0.loss_mask: 0.2622  decode.d0.loss_dice: 0.2718  decode.d1.loss_cls: 0.1503  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.2493  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.2264  decode.d2.loss_dice: 0.2618  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2745  decode.d4.loss_cls: 0.0790  decode.d4.loss_mask: 0.2619  decode.d4.loss_dice: 0.2785  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.2263  decode.d5.loss_dice: 0.2683  decode.d6.loss_cls: 0.1281  decode.d6.loss_mask: 0.2308  decode.d6.loss_dice: 0.2821  decode.d7.loss_cls: 0.1321  decode.d7.loss_mask: 0.2260  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.0988  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2736
09/30 23:53:02 - mmengine - INFO - Iter(train) [121700/320000]  base_lr: 6.5006e-05 lr: 6.5006e-06  eta: 1 day, 0:06:23  time: 0.4423  data_time: 0.0097  memory: 5129  grad_norm: 66.8619  loss: 7.8190  decode.loss_cls: 0.2272  decode.loss_mask: 0.2291  decode.loss_dice: 0.2155  decode.d0.loss_cls: 1.0770  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.1905  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.2473  decode.d3.loss_cls: 0.2342  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2158  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 0.2509  decode.d4.loss_dice: 0.2480  decode.d5.loss_cls: 0.2406  decode.d5.loss_mask: 0.3217  decode.d5.loss_dice: 0.2569  decode.d6.loss_cls: 0.2735  decode.d6.loss_mask: 0.2277  decode.d6.loss_dice: 0.2120  decode.d7.loss_cls: 0.2575  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.2115  decode.d8.loss_cls: 0.2357  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2028
09/30 23:53:25 - mmengine - INFO - Iter(train) [121750/320000]  base_lr: 6.4992e-05 lr: 6.4992e-06  eta: 1 day, 0:06:02  time: 0.4429  data_time: 0.0099  memory: 5145  grad_norm: 20.4442  loss: 4.8865  decode.loss_cls: 0.1172  decode.loss_mask: 0.1492  decode.loss_dice: 0.1822  decode.d0.loss_cls: 0.8093  decode.d0.loss_mask: 0.1510  decode.d0.loss_dice: 0.1509  decode.d1.loss_cls: 0.1150  decode.d1.loss_mask: 0.1499  decode.d1.loss_dice: 0.2055  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 0.1494  decode.d2.loss_dice: 0.1693  decode.d3.loss_cls: 0.1167  decode.d3.loss_mask: 0.1495  decode.d3.loss_dice: 0.1655  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.1480  decode.d4.loss_dice: 0.1424  decode.d5.loss_cls: 0.1329  decode.d5.loss_mask: 0.1502  decode.d5.loss_dice: 0.1608  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.1485  decode.d6.loss_dice: 0.1633  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.1496  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.1510  decode.d8.loss_dice: 0.1506
09/30 23:53:47 - mmengine - INFO - Iter(train) [121800/320000]  base_lr: 6.4977e-05 lr: 6.4977e-06  eta: 1 day, 0:05:40  time: 0.4431  data_time: 0.0102  memory: 5120  grad_norm: 355.6742  loss: 7.9273  decode.loss_cls: 0.1361  decode.loss_mask: 0.3786  decode.loss_dice: 0.2364  decode.d0.loss_cls: 0.8473  decode.d0.loss_mask: 0.3428  decode.d0.loss_dice: 0.2177  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.4006  decode.d1.loss_dice: 0.2116  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.3943  decode.d2.loss_dice: 0.2310  decode.d3.loss_cls: 0.1175  decode.d3.loss_mask: 0.3821  decode.d3.loss_dice: 0.2249  decode.d4.loss_cls: 0.1171  decode.d4.loss_mask: 0.3842  decode.d4.loss_dice: 0.2213  decode.d5.loss_cls: 0.1217  decode.d5.loss_mask: 0.3914  decode.d5.loss_dice: 0.2316  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.3862  decode.d6.loss_dice: 0.2292  decode.d7.loss_cls: 0.1217  decode.d7.loss_mask: 0.3876  decode.d7.loss_dice: 0.2241  decode.d8.loss_cls: 0.1254  decode.d8.loss_mask: 0.3974  decode.d8.loss_dice: 0.2299
09/30 23:54:09 - mmengine - INFO - Iter(train) [121850/320000]  base_lr: 6.4962e-05 lr: 6.4962e-06  eta: 1 day, 0:05:19  time: 0.4444  data_time: 0.0099  memory: 5120  grad_norm: 25.2857  loss: 4.5402  decode.loss_cls: 0.0398  decode.loss_mask: 0.1595  decode.loss_dice: 0.1824  decode.d0.loss_cls: 0.7883  decode.d0.loss_mask: 0.1587  decode.d0.loss_dice: 0.1852  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.1585  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 0.1591  decode.d2.loss_dice: 0.1908  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.1591  decode.d3.loss_dice: 0.1869  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.1579  decode.d4.loss_dice: 0.1884  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.1584  decode.d5.loss_dice: 0.1928  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.1584  decode.d6.loss_dice: 0.1872  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.1608  decode.d7.loss_dice: 0.1889  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.1591  decode.d8.loss_dice: 0.1876
09/30 23:54:31 - mmengine - INFO - Iter(train) [121900/320000]  base_lr: 6.4947e-05 lr: 6.4947e-06  eta: 1 day, 0:04:58  time: 0.4427  data_time: 0.0100  memory: 5129  grad_norm: 27.6369  loss: 4.8959  decode.loss_cls: 0.0044  decode.loss_mask: 0.2253  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.7998  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.1700  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.1776  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.1772  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.1743  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.1831  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.2259  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.1763
09/30 23:54:53 - mmengine - INFO - Iter(train) [121950/320000]  base_lr: 6.4933e-05 lr: 6.4933e-06  eta: 1 day, 0:04:36  time: 0.4430  data_time: 0.0102  memory: 5129  grad_norm: 16.2571  loss: 3.9296  decode.loss_cls: 0.0017  decode.loss_mask: 0.1674  decode.loss_dice: 0.1444  decode.d0.loss_cls: 0.7941  decode.d0.loss_mask: 0.1674  decode.d0.loss_dice: 0.1387  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.1661  decode.d1.loss_dice: 0.1459  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.1670  decode.d2.loss_dice: 0.1474  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.1667  decode.d3.loss_dice: 0.1424  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.1701  decode.d4.loss_dice: 0.1419  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1645  decode.d5.loss_dice: 0.1431  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.1687  decode.d6.loss_dice: 0.1460  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.1673  decode.d7.loss_dice: 0.1436  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1684  decode.d8.loss_dice: 0.1450
09/30 23:55:16 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
09/30 23:55:16 - mmengine - INFO - Iter(train) [122000/320000]  base_lr: 6.4918e-05 lr: 6.4918e-06  eta: 1 day, 0:04:15  time: 0.4421  data_time: 0.0101  memory: 5129  grad_norm: 53.5190  loss: 6.0583  decode.loss_cls: 0.0956  decode.loss_mask: 0.2788  decode.loss_dice: 0.1840  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.2790  decode.d0.loss_dice: 0.1746  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.1772  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.2750  decode.d2.loss_dice: 0.1765  decode.d3.loss_cls: 0.0633  decode.d3.loss_mask: 0.2752  decode.d3.loss_dice: 0.1800  decode.d4.loss_cls: 0.0876  decode.d4.loss_mask: 0.2787  decode.d4.loss_dice: 0.1793  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.2779  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0851  decode.d6.loss_mask: 0.2780  decode.d6.loss_dice: 0.1805  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.2730  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.0845  decode.d8.loss_mask: 0.2800  decode.d8.loss_dice: 0.1812
09/30 23:55:38 - mmengine - INFO - Iter(train) [122050/320000]  base_lr: 6.4903e-05 lr: 6.4903e-06  eta: 1 day, 0:03:53  time: 0.4459  data_time: 0.0102  memory: 5145  grad_norm: 65.2392  loss: 7.0971  decode.loss_cls: 0.1044  decode.loss_mask: 0.2586  decode.loss_dice: 0.2520  decode.d0.loss_cls: 1.1062  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2836  decode.d1.loss_cls: 0.1079  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.2344  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.1059  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.0843  decode.d5.loss_mask: 0.2499  decode.d5.loss_dice: 0.2330  decode.d6.loss_cls: 0.0867  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2369  decode.d7.loss_cls: 0.1265  decode.d7.loss_mask: 0.2538  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.1654  decode.d8.loss_mask: 0.2613  decode.d8.loss_dice: 0.2340
09/30 23:56:00 - mmengine - INFO - Iter(train) [122100/320000]  base_lr: 6.4888e-05 lr: 6.4888e-06  eta: 1 day, 0:03:32  time: 0.4435  data_time: 0.0103  memory: 5120  grad_norm: 156.8763  loss: 6.9616  decode.loss_cls: 0.0912  decode.loss_mask: 0.3194  decode.loss_dice: 0.2190  decode.d0.loss_cls: 0.7738  decode.d0.loss_mask: 0.3424  decode.d0.loss_dice: 0.2329  decode.d1.loss_cls: 0.0966  decode.d1.loss_mask: 0.3257  decode.d1.loss_dice: 0.2198  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 0.3326  decode.d2.loss_dice: 0.2227  decode.d3.loss_cls: 0.0614  decode.d3.loss_mask: 0.3233  decode.d3.loss_dice: 0.2183  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.3221  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.3332  decode.d5.loss_dice: 0.2176  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.2163  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.3170  decode.d7.loss_dice: 0.2189  decode.d8.loss_cls: 0.0855  decode.d8.loss_mask: 0.3270  decode.d8.loss_dice: 0.2214
09/30 23:56:22 - mmengine - INFO - Iter(train) [122150/320000]  base_lr: 6.4874e-05 lr: 6.4874e-06  eta: 1 day, 0:03:11  time: 0.4461  data_time: 0.0102  memory: 5120  grad_norm: 43.3212  loss: 5.3308  decode.loss_cls: 0.0709  decode.loss_mask: 0.1765  decode.loss_dice: 0.1803  decode.d0.loss_cls: 0.7801  decode.d0.loss_mask: 0.1796  decode.d0.loss_dice: 0.2484  decode.d1.loss_cls: 0.0496  decode.d1.loss_mask: 0.1788  decode.d1.loss_dice: 0.2034  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.1803  decode.d2.loss_dice: 0.2215  decode.d3.loss_cls: 0.1179  decode.d3.loss_mask: 0.1788  decode.d3.loss_dice: 0.2062  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.1795  decode.d4.loss_dice: 0.2094  decode.d5.loss_cls: 0.1058  decode.d5.loss_mask: 0.1779  decode.d5.loss_dice: 0.2110  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.1796  decode.d6.loss_dice: 0.1962  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.1780  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.1786  decode.d8.loss_dice: 0.1934
09/30 23:56:44 - mmengine - INFO - Iter(train) [122200/320000]  base_lr: 6.4859e-05 lr: 6.4859e-06  eta: 1 day, 0:02:49  time: 0.4434  data_time: 0.0103  memory: 5129  grad_norm: 26.3301  loss: 4.3112  decode.loss_cls: 0.0071  decode.loss_mask: 0.1640  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.8278  decode.d0.loss_mask: 0.1634  decode.d0.loss_dice: 0.1797  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.1647  decode.d1.loss_dice: 0.1792  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.1630  decode.d2.loss_dice: 0.1736  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.1630  decode.d3.loss_dice: 0.1864  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.1612  decode.d4.loss_dice: 0.1768  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.1634  decode.d5.loss_dice: 0.1793  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.1615  decode.d6.loss_dice: 0.1678  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.1630  decode.d7.loss_dice: 0.1754  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.1644  decode.d8.loss_dice: 0.1796
09/30 23:57:07 - mmengine - INFO - Iter(train) [122250/320000]  base_lr: 6.4844e-05 lr: 6.4844e-06  eta: 1 day, 0:02:28  time: 0.4464  data_time: 0.0102  memory: 5129  grad_norm: 108.1077  loss: 5.1060  decode.loss_cls: 0.0644  decode.loss_mask: 0.2093  decode.loss_dice: 0.1800  decode.d0.loss_cls: 0.8112  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.1836  decode.d1.loss_cls: 0.0363  decode.d1.loss_mask: 0.2074  decode.d1.loss_dice: 0.1799  decode.d2.loss_cls: 0.0444  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.1859  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.1759  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.1806  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1792  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.2102  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.1812  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.2102  decode.d8.loss_dice: 0.1759
09/30 23:57:29 - mmengine - INFO - Iter(train) [122300/320000]  base_lr: 6.4829e-05 lr: 6.4829e-06  eta: 1 day, 0:02:07  time: 0.4435  data_time: 0.0102  memory: 5120  grad_norm: 47.2256  loss: 6.0331  decode.loss_cls: 0.1075  decode.loss_mask: 0.2095  decode.loss_dice: 0.2193  decode.d0.loss_cls: 0.8514  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2289  decode.d1.loss_cls: 0.1048  decode.d1.loss_mask: 0.2053  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.2066  decode.d2.loss_dice: 0.2149  decode.d3.loss_cls: 0.1089  decode.d3.loss_mask: 0.2052  decode.d3.loss_dice: 0.2080  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.2073  decode.d4.loss_dice: 0.2189  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.2072  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.2180
09/30 23:57:51 - mmengine - INFO - Iter(train) [122350/320000]  base_lr: 6.4815e-05 lr: 6.4815e-06  eta: 1 day, 0:01:45  time: 0.4459  data_time: 0.0101  memory: 5129  grad_norm: 21.6417  loss: 4.0194  decode.loss_cls: 0.0086  decode.loss_mask: 0.1543  decode.loss_dice: 0.1466  decode.d0.loss_cls: 0.8262  decode.d0.loss_mask: 0.1546  decode.d0.loss_dice: 0.1431  decode.d1.loss_cls: 0.0278  decode.d1.loss_mask: 0.1532  decode.d1.loss_dice: 0.1465  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.1527  decode.d2.loss_dice: 0.1382  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.1554  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.1530  decode.d4.loss_dice: 0.1391  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.1545  decode.d5.loss_dice: 0.1483  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.1543  decode.d6.loss_dice: 0.1419  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.1552  decode.d7.loss_dice: 0.1464  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.1569  decode.d8.loss_dice: 0.1530
09/30 23:58:13 - mmengine - INFO - Iter(train) [122400/320000]  base_lr: 6.4800e-05 lr: 6.4800e-06  eta: 1 day, 0:01:24  time: 0.4451  data_time: 0.0101  memory: 5120  grad_norm: 123.3031  loss: 7.2501  decode.loss_cls: 0.1871  decode.loss_mask: 0.2808  decode.loss_dice: 0.2189  decode.d0.loss_cls: 0.9887  decode.d0.loss_mask: 0.2093  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.1836  decode.d2.loss_cls: 0.1753  decode.d2.loss_mask: 0.2824  decode.d2.loss_dice: 0.1943  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.2835  decode.d3.loss_dice: 0.2110  decode.d4.loss_cls: 0.1580  decode.d4.loss_mask: 0.2914  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.1463  decode.d5.loss_mask: 0.3014  decode.d5.loss_dice: 0.2216  decode.d6.loss_cls: 0.2158  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2025  decode.d7.loss_cls: 0.2049  decode.d7.loss_mask: 0.2541  decode.d7.loss_dice: 0.2194  decode.d8.loss_cls: 0.1519  decode.d8.loss_mask: 0.2439  decode.d8.loss_dice: 0.2075
09/30 23:58:36 - mmengine - INFO - Iter(train) [122450/320000]  base_lr: 6.4785e-05 lr: 6.4785e-06  eta: 1 day, 0:01:03  time: 0.4441  data_time: 0.0101  memory: 5119  grad_norm: 113.0437  loss: 7.9506  decode.loss_cls: 0.1439  decode.loss_mask: 0.3142  decode.loss_dice: 0.2479  decode.d0.loss_cls: 1.0015  decode.d0.loss_mask: 0.2853  decode.d0.loss_dice: 0.2277  decode.d1.loss_cls: 0.1511  decode.d1.loss_mask: 0.3077  decode.d1.loss_dice: 0.2573  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.2284  decode.d3.loss_cls: 0.1866  decode.d3.loss_mask: 0.3583  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1899  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.1410  decode.d5.loss_mask: 0.3003  decode.d5.loss_dice: 0.2374  decode.d6.loss_cls: 0.1752  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.2249  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 0.3064  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.4223  decode.d8.loss_dice: 0.2519
09/30 23:58:58 - mmengine - INFO - Iter(train) [122500/320000]  base_lr: 6.4770e-05 lr: 6.4770e-06  eta: 1 day, 0:00:41  time: 0.4436  data_time: 0.0100  memory: 5145  grad_norm: 25.6995  loss: 4.4911  decode.loss_cls: 0.0141  decode.loss_mask: 0.1913  decode.loss_dice: 0.1645  decode.d0.loss_cls: 0.7700  decode.d0.loss_mask: 0.1921  decode.d0.loss_dice: 0.1665  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.1904  decode.d1.loss_dice: 0.1663  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.1883  decode.d2.loss_dice: 0.1640  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.1906  decode.d3.loss_dice: 0.1611  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.1583  decode.d5.loss_cls: 0.0664  decode.d5.loss_mask: 0.1892  decode.d5.loss_dice: 0.1628  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.1897  decode.d6.loss_dice: 0.1642  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.1885  decode.d8.loss_dice: 0.1639
09/30 23:59:20 - mmengine - INFO - Iter(train) [122550/320000]  base_lr: 6.4756e-05 lr: 6.4756e-06  eta: 1 day, 0:00:20  time: 0.4432  data_time: 0.0100  memory: 5119  grad_norm: 453.4951  loss: 7.4604  decode.loss_cls: 0.1411  decode.loss_mask: 0.2485  decode.loss_dice: 0.2432  decode.d0.loss_cls: 0.9553  decode.d0.loss_mask: 0.2496  decode.d0.loss_dice: 0.2685  decode.d1.loss_cls: 0.1222  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.2438  decode.d2.loss_dice: 0.2391  decode.d3.loss_cls: 0.2068  decode.d3.loss_mask: 0.2575  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 0.2560  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.2031  decode.d5.loss_mask: 0.2575  decode.d5.loss_dice: 0.2487  decode.d6.loss_cls: 0.1982  decode.d6.loss_mask: 0.2478  decode.d6.loss_dice: 0.2389  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.1543  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.2366
09/30 23:59:42 - mmengine - INFO - Iter(train) [122600/320000]  base_lr: 6.4741e-05 lr: 6.4741e-06  eta: 23:59:58  time: 0.4437  data_time: 0.0100  memory: 5120  grad_norm: 64.7843  loss: 4.9119  decode.loss_cls: 0.1228  decode.loss_mask: 0.1765  decode.loss_dice: 0.1611  decode.d0.loss_cls: 0.9219  decode.d0.loss_mask: 0.1738  decode.d0.loss_dice: 0.1714  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.1764  decode.d1.loss_dice: 0.1620  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.1757  decode.d2.loss_dice: 0.1653  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.1787  decode.d3.loss_dice: 0.1621  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.1778  decode.d4.loss_dice: 0.1647  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.1765  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0985  decode.d6.loss_mask: 0.1770  decode.d6.loss_dice: 0.1652  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.1785  decode.d7.loss_dice: 0.1582  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.1751  decode.d8.loss_dice: 0.1622
10/01 00:00:04 - mmengine - INFO - Iter(train) [122650/320000]  base_lr: 6.4726e-05 lr: 6.4726e-06  eta: 23:59:37  time: 0.4441  data_time: 0.0102  memory: 5145  grad_norm: 43.6718  loss: 5.0562  decode.loss_cls: 0.0124  decode.loss_mask: 0.2416  decode.loss_dice: 0.1677  decode.d0.loss_cls: 0.8050  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.1721  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.2403  decode.d1.loss_dice: 0.1732  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.1700  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.2421  decode.d3.loss_dice: 0.1756  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.2408  decode.d4.loss_dice: 0.1738  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.2443  decode.d5.loss_dice: 0.1696  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2414  decode.d6.loss_dice: 0.1648  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.1694  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.2448  decode.d8.loss_dice: 0.1691
10/01 00:00:27 - mmengine - INFO - Iter(train) [122700/320000]  base_lr: 6.4711e-05 lr: 6.4711e-06  eta: 23:59:16  time: 0.4439  data_time: 0.0104  memory: 5129  grad_norm: 20.9655  loss: 4.9971  decode.loss_cls: 0.0006  decode.loss_mask: 0.2253  decode.loss_dice: 0.1891  decode.d0.loss_cls: 0.8717  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.1890  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.1894  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.2210  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.1913  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.1918  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2202  decode.d6.loss_dice: 0.1817  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2248  decode.d7.loss_dice: 0.1908  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2210  decode.d8.loss_dice: 0.1895
10/01 00:00:49 - mmengine - INFO - Iter(train) [122750/320000]  base_lr: 6.4697e-05 lr: 6.4697e-06  eta: 23:58:54  time: 0.4446  data_time: 0.0100  memory: 5129  grad_norm: 33.6201  loss: 4.3491  decode.loss_cls: 0.0042  decode.loss_mask: 0.1654  decode.loss_dice: 0.1809  decode.d0.loss_cls: 0.8794  decode.d0.loss_mask: 0.1688  decode.d0.loss_dice: 0.1736  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.1659  decode.d1.loss_dice: 0.1787  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.1639  decode.d2.loss_dice: 0.1772  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.1652  decode.d3.loss_dice: 0.1761  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1645  decode.d4.loss_dice: 0.1708  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.1656  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1635  decode.d6.loss_dice: 0.1771  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.1656  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.1645  decode.d8.loss_dice: 0.1726
10/01 00:01:11 - mmengine - INFO - Iter(train) [122800/320000]  base_lr: 6.4682e-05 lr: 6.4682e-06  eta: 23:58:33  time: 0.4444  data_time: 0.0102  memory: 5120  grad_norm: 32.4085  loss: 5.0569  decode.loss_cls: 0.0404  decode.loss_mask: 0.2139  decode.loss_dice: 0.1636  decode.d0.loss_cls: 0.8590  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.2124  decode.d1.loss_dice: 0.1638  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.2138  decode.d2.loss_dice: 0.1669  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.2135  decode.d3.loss_dice: 0.1648  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.2150  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.1653  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.1625  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.2105  decode.d7.loss_dice: 0.1655  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.1648
10/01 00:01:33 - mmengine - INFO - Iter(train) [122850/320000]  base_lr: 6.4667e-05 lr: 6.4667e-06  eta: 23:58:12  time: 0.4444  data_time: 0.0103  memory: 5130  grad_norm: 104.8805  loss: 6.4323  decode.loss_cls: 0.0644  decode.loss_mask: 0.2765  decode.loss_dice: 0.2367  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 0.2803  decode.d0.loss_dice: 0.2454  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.2918  decode.d1.loss_dice: 0.2369  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.2840  decode.d2.loss_dice: 0.2357  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.2400  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.2837  decode.d4.loss_dice: 0.2535  decode.d5.loss_cls: 0.0452  decode.d5.loss_mask: 0.2751  decode.d5.loss_dice: 0.2320  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.2812  decode.d7.loss_dice: 0.2598  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.2711  decode.d8.loss_dice: 0.2329
10/01 00:01:55 - mmengine - INFO - Iter(train) [122900/320000]  base_lr: 6.4652e-05 lr: 6.4652e-06  eta: 23:57:50  time: 0.4396  data_time: 0.0095  memory: 5120  grad_norm: 22.9169  loss: 3.8960  decode.loss_cls: 0.0038  decode.loss_mask: 0.1586  decode.loss_dice: 0.1393  decode.d0.loss_cls: 0.8534  decode.d0.loss_mask: 0.1613  decode.d0.loss_dice: 0.1411  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.1618  decode.d1.loss_dice: 0.1451  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.1578  decode.d2.loss_dice: 0.1433  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.1583  decode.d3.loss_dice: 0.1401  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.1583  decode.d4.loss_dice: 0.1409  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.1596  decode.d5.loss_dice: 0.1413  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1602  decode.d6.loss_dice: 0.1398  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.1593  decode.d7.loss_dice: 0.1396  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.1607  decode.d8.loss_dice: 0.1419
10/01 00:02:17 - mmengine - INFO - Iter(train) [122950/320000]  base_lr: 6.4638e-05 lr: 6.4638e-06  eta: 23:57:28  time: 0.4399  data_time: 0.0096  memory: 5129  grad_norm: 52.9296  loss: 4.7522  decode.loss_cls: 0.0023  decode.loss_mask: 0.2223  decode.loss_dice: 0.1640  decode.d0.loss_cls: 0.7997  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.1671  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.2271  decode.d1.loss_dice: 0.1654  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2257  decode.d2.loss_dice: 0.1683  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.2263  decode.d3.loss_dice: 0.1670  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1650  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2264  decode.d5.loss_dice: 0.1675  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2261  decode.d6.loss_dice: 0.1664  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.1665  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.2244  decode.d8.loss_dice: 0.1679
10/01 00:02:39 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:02:39 - mmengine - INFO - Iter(train) [123000/320000]  base_lr: 6.4623e-05 lr: 6.4623e-06  eta: 23:57:06  time: 0.4383  data_time: 0.0094  memory: 5120  grad_norm: 19.4692  loss: 4.1016  decode.loss_cls: 0.0012  decode.loss_mask: 0.1762  decode.loss_dice: 0.1555  decode.d0.loss_cls: 0.7733  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.1467  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.1753  decode.d1.loss_dice: 0.1530  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.1762  decode.d2.loss_dice: 0.1533  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.1772  decode.d3.loss_dice: 0.1510  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1776  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1797  decode.d5.loss_dice: 0.1566  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.1785  decode.d6.loss_dice: 0.1529  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1787  decode.d7.loss_dice: 0.1550  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1761  decode.d8.loss_dice: 0.1592
10/01 00:03:01 - mmengine - INFO - Iter(train) [123050/320000]  base_lr: 6.4608e-05 lr: 6.4608e-06  eta: 23:56:45  time: 0.4394  data_time: 0.0097  memory: 5129  grad_norm: 119.3102  loss: 6.4101  decode.loss_cls: 0.1092  decode.loss_mask: 0.2415  decode.loss_dice: 0.2039  decode.d0.loss_cls: 0.8523  decode.d0.loss_mask: 0.2530  decode.d0.loss_dice: 0.2406  decode.d1.loss_cls: 0.1486  decode.d1.loss_mask: 0.2433  decode.d1.loss_dice: 0.2331  decode.d2.loss_cls: 0.1461  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.2148  decode.d3.loss_cls: 0.1216  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.2351  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.2053  decode.d5.loss_cls: 0.0987  decode.d5.loss_mask: 0.2449  decode.d5.loss_dice: 0.2115  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.2083  decode.d7.loss_cls: 0.0835  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.1932  decode.d8.loss_cls: 0.0919  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.2036
10/01 00:03:23 - mmengine - INFO - Iter(train) [123100/320000]  base_lr: 6.4593e-05 lr: 6.4593e-06  eta: 23:56:23  time: 0.4390  data_time: 0.0096  memory: 5129  grad_norm: 49.7347  loss: 6.3484  decode.loss_cls: 0.1187  decode.loss_mask: 0.2214  decode.loss_dice: 0.2250  decode.d0.loss_cls: 0.8999  decode.d0.loss_mask: 0.2306  decode.d0.loss_dice: 0.2519  decode.d1.loss_cls: 0.0975  decode.d1.loss_mask: 0.2231  decode.d1.loss_dice: 0.2357  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.0789  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2240  decode.d7.loss_cls: 0.1462  decode.d7.loss_mask: 0.2256  decode.d7.loss_dice: 0.2404  decode.d8.loss_cls: 0.1169  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.2230
10/01 00:03:45 - mmengine - INFO - Iter(train) [123150/320000]  base_lr: 6.4579e-05 lr: 6.4579e-06  eta: 23:56:01  time: 0.4397  data_time: 0.0095  memory: 5145  grad_norm: 50.1767  loss: 7.1666  decode.loss_cls: 0.1616  decode.loss_mask: 0.2862  decode.loss_dice: 0.2336  decode.d0.loss_cls: 0.8295  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2249  decode.d1.loss_cls: 0.1201  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.2119  decode.d2.loss_cls: 0.1499  decode.d2.loss_mask: 0.2549  decode.d2.loss_dice: 0.2273  decode.d3.loss_cls: 0.1522  decode.d3.loss_mask: 0.2772  decode.d3.loss_dice: 0.2371  decode.d4.loss_cls: 0.1448  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2423  decode.d5.loss_cls: 0.1527  decode.d5.loss_mask: 0.2530  decode.d5.loss_dice: 0.2461  decode.d6.loss_cls: 0.1420  decode.d6.loss_mask: 0.2860  decode.d6.loss_dice: 0.2446  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.2691  decode.d7.loss_dice: 0.2458  decode.d8.loss_cls: 0.1583  decode.d8.loss_mask: 0.2534  decode.d8.loss_dice: 0.2319
10/01 00:04:07 - mmengine - INFO - Iter(train) [123200/320000]  base_lr: 6.4564e-05 lr: 6.4564e-06  eta: 23:55:40  time: 0.4388  data_time: 0.0096  memory: 5145  grad_norm: 25.9358  loss: 6.1038  decode.loss_cls: 0.0419  decode.loss_mask: 0.1789  decode.loss_dice: 0.2961  decode.d0.loss_cls: 1.0477  decode.d0.loss_mask: 0.1793  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.0446  decode.d1.loss_mask: 0.1776  decode.d1.loss_dice: 0.2867  decode.d2.loss_cls: 0.0373  decode.d2.loss_mask: 0.1800  decode.d2.loss_dice: 0.2866  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.1796  decode.d3.loss_dice: 0.2628  decode.d4.loss_cls: 0.0327  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.2871  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.1790  decode.d5.loss_dice: 0.3026  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.1767  decode.d6.loss_dice: 0.2895  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.1783  decode.d7.loss_dice: 0.3053  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.1789  decode.d8.loss_dice: 0.3000
10/01 00:04:29 - mmengine - INFO - Iter(train) [123250/320000]  base_lr: 6.4549e-05 lr: 6.4549e-06  eta: 23:55:18  time: 0.4397  data_time: 0.0096  memory: 5129  grad_norm: 49.8972  loss: 5.5316  decode.loss_cls: 0.0215  decode.loss_mask: 0.2463  decode.loss_dice: 0.1940  decode.d0.loss_cls: 0.9341  decode.d0.loss_mask: 0.2606  decode.d0.loss_dice: 0.1961  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.2445  decode.d1.loss_dice: 0.1910  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.1890  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.2473  decode.d3.loss_dice: 0.1876  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.1888  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.2438  decode.d5.loss_dice: 0.1866  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.2447  decode.d6.loss_dice: 0.1897  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.2438  decode.d7.loss_dice: 0.1919  decode.d8.loss_cls: 0.0241  decode.d8.loss_mask: 0.2438  decode.d8.loss_dice: 0.1916
10/01 00:04:51 - mmengine - INFO - Iter(train) [123300/320000]  base_lr: 6.4534e-05 lr: 6.4534e-06  eta: 23:54:56  time: 0.4396  data_time: 0.0096  memory: 5129  grad_norm: 47.0504  loss: 5.4415  decode.loss_cls: 0.0767  decode.loss_mask: 0.2245  decode.loss_dice: 0.1533  decode.d0.loss_cls: 0.9050  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.1515  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.1580  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.2271  decode.d2.loss_dice: 0.1531  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.2257  decode.d3.loss_dice: 0.1570  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 0.2233  decode.d4.loss_dice: 0.1516  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.2249  decode.d5.loss_dice: 0.1536  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2241  decode.d6.loss_dice: 0.1522  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.2275  decode.d7.loss_dice: 0.1521  decode.d8.loss_cls: 0.0856  decode.d8.loss_mask: 0.2293  decode.d8.loss_dice: 0.1660
10/01 00:05:13 - mmengine - INFO - Iter(train) [123350/320000]  base_lr: 6.4519e-05 lr: 6.4519e-06  eta: 23:54:35  time: 0.4392  data_time: 0.0096  memory: 5129  grad_norm: 26.5563  loss: 4.7527  decode.loss_cls: 0.0080  decode.loss_mask: 0.2192  decode.loss_dice: 0.1661  decode.d0.loss_cls: 0.7982  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.1658  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.2205  decode.d1.loss_dice: 0.1661  decode.d2.loss_cls: 0.0100  decode.d2.loss_mask: 0.2218  decode.d2.loss_dice: 0.1658  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.1626  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.2225  decode.d4.loss_dice: 0.1674  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.1657  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.1631  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.1634  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.2207  decode.d8.loss_dice: 0.1606
10/01 00:05:35 - mmengine - INFO - Iter(train) [123400/320000]  base_lr: 6.4505e-05 lr: 6.4505e-06  eta: 23:54:13  time: 0.4398  data_time: 0.0094  memory: 5145  grad_norm: 56.7528  loss: 6.3032  decode.loss_cls: 0.0718  decode.loss_mask: 0.2082  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.9759  decode.d0.loss_mask: 0.2005  decode.d0.loss_dice: 0.2425  decode.d1.loss_cls: 0.1170  decode.d1.loss_mask: 0.1990  decode.d1.loss_dice: 0.2500  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.2049  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.2423  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.2530  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.2531  decode.d7.loss_cls: 0.0902  decode.d7.loss_mask: 0.1999  decode.d7.loss_dice: 0.2561  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.2175  decode.d8.loss_dice: 0.2364
10/01 00:05:57 - mmengine - INFO - Iter(train) [123450/320000]  base_lr: 6.4490e-05 lr: 6.4490e-06  eta: 23:53:51  time: 0.4394  data_time: 0.0094  memory: 5129  grad_norm: 47.2549  loss: 4.9603  decode.loss_cls: 0.0267  decode.loss_mask: 0.1930  decode.loss_dice: 0.1708  decode.d0.loss_cls: 0.8749  decode.d0.loss_mask: 0.2010  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 0.1939  decode.d1.loss_dice: 0.1750  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 0.1928  decode.d2.loss_dice: 0.1688  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.1935  decode.d3.loss_dice: 0.1773  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.1696  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 0.1963  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.1694  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.1962  decode.d7.loss_dice: 0.1751  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.1966  decode.d8.loss_dice: 0.1713
10/01 00:06:19 - mmengine - INFO - Iter(train) [123500/320000]  base_lr: 6.4475e-05 lr: 6.4475e-06  eta: 23:53:29  time: 0.4389  data_time: 0.0095  memory: 5129  grad_norm: 57.3049  loss: 6.2775  decode.loss_cls: 0.0980  decode.loss_mask: 0.1892  decode.loss_dice: 0.2407  decode.d0.loss_cls: 0.8683  decode.d0.loss_mask: 0.1901  decode.d0.loss_dice: 0.2380  decode.d1.loss_cls: 0.1051  decode.d1.loss_mask: 0.1880  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.1885  decode.d2.loss_dice: 0.2388  decode.d3.loss_cls: 0.1576  decode.d3.loss_mask: 0.1856  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.1595  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.2303  decode.d5.loss_cls: 0.1118  decode.d5.loss_mask: 0.1899  decode.d5.loss_dice: 0.2336  decode.d6.loss_cls: 0.1810  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.1963  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.1108  decode.d8.loss_mask: 0.2005  decode.d8.loss_dice: 0.2526
10/01 00:06:41 - mmengine - INFO - Iter(train) [123550/320000]  base_lr: 6.4460e-05 lr: 6.4460e-06  eta: 23:53:08  time: 0.4387  data_time: 0.0095  memory: 5129  grad_norm: 34.0776  loss: 5.0925  decode.loss_cls: 0.0097  decode.loss_mask: 0.2349  decode.loss_dice: 0.1840  decode.d0.loss_cls: 0.8049  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.1867  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.1811  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.1836  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.2373  decode.d4.loss_dice: 0.1798  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.2340  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.2330  decode.d7.loss_dice: 0.1791  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.2336  decode.d8.loss_dice: 0.1785
10/01 00:07:03 - mmengine - INFO - Iter(train) [123600/320000]  base_lr: 6.4446e-05 lr: 6.4446e-06  eta: 23:52:46  time: 0.4392  data_time: 0.0096  memory: 5129  grad_norm: 129.9487  loss: 5.4532  decode.loss_cls: 0.1037  decode.loss_mask: 0.1861  decode.loss_dice: 0.1727  decode.d0.loss_cls: 0.7996  decode.d0.loss_mask: 0.1889  decode.d0.loss_dice: 0.1771  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 0.1856  decode.d1.loss_dice: 0.1731  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.1826  decode.d2.loss_dice: 0.1689  decode.d3.loss_cls: 0.1729  decode.d3.loss_mask: 0.1873  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.1841  decode.d4.loss_dice: 0.1716  decode.d5.loss_cls: 0.1757  decode.d5.loss_mask: 0.1842  decode.d5.loss_dice: 0.1719  decode.d6.loss_cls: 0.0953  decode.d6.loss_mask: 0.1822  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.1859  decode.d7.loss_dice: 0.1751  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.1854  decode.d8.loss_dice: 0.1703
10/01 00:07:25 - mmengine - INFO - Iter(train) [123650/320000]  base_lr: 6.4431e-05 lr: 6.4431e-06  eta: 23:52:24  time: 0.4394  data_time: 0.0094  memory: 5129  grad_norm: 26.1847  loss: 5.3728  decode.loss_cls: 0.0750  decode.loss_mask: 0.1935  decode.loss_dice: 0.1876  decode.d0.loss_cls: 0.9124  decode.d0.loss_mask: 0.1923  decode.d0.loss_dice: 0.1871  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.1741  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.1925  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.0893  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.1929  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.1948  decode.d4.loss_dice: 0.1875  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1943  decode.d5.loss_dice: 0.2126  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.1952  decode.d6.loss_dice: 0.1880  decode.d7.loss_cls: 0.0933  decode.d7.loss_mask: 0.1929  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.0834  decode.d8.loss_mask: 0.1920  decode.d8.loss_dice: 0.1823
10/01 00:07:47 - mmengine - INFO - Iter(train) [123700/320000]  base_lr: 6.4416e-05 lr: 6.4416e-06  eta: 23:52:02  time: 0.4403  data_time: 0.0096  memory: 5120  grad_norm: 55.9194  loss: 5.5118  decode.loss_cls: 0.1163  decode.loss_mask: 0.2016  decode.loss_dice: 0.1630  decode.d0.loss_cls: 0.7705  decode.d0.loss_mask: 0.2066  decode.d0.loss_dice: 0.1644  decode.d1.loss_cls: 0.1162  decode.d1.loss_mask: 0.2046  decode.d1.loss_dice: 0.1645  decode.d2.loss_cls: 0.1162  decode.d2.loss_mask: 0.2062  decode.d2.loss_dice: 0.1723  decode.d3.loss_cls: 0.1168  decode.d3.loss_mask: 0.2046  decode.d3.loss_dice: 0.1749  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 0.2063  decode.d4.loss_dice: 0.1684  decode.d5.loss_cls: 0.1001  decode.d5.loss_mask: 0.2052  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.1047  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.2088  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.1041  decode.d8.loss_mask: 0.2056  decode.d8.loss_dice: 0.1610
10/01 00:08:09 - mmengine - INFO - Iter(train) [123750/320000]  base_lr: 6.4401e-05 lr: 6.4401e-06  eta: 23:51:41  time: 0.4396  data_time: 0.0096  memory: 5120  grad_norm: 71.1056  loss: 4.8924  decode.loss_cls: 0.0211  decode.loss_mask: 0.2211  decode.loss_dice: 0.1720  decode.d0.loss_cls: 0.8250  decode.d0.loss_mask: 0.2098  decode.d0.loss_dice: 0.1762  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.2199  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.2192  decode.d2.loss_dice: 0.1669  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.2160  decode.d3.loss_dice: 0.1533  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.2215  decode.d4.loss_dice: 0.1763  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.2205  decode.d5.loss_dice: 0.1812  decode.d6.loss_cls: 0.0161  decode.d6.loss_mask: 0.2203  decode.d6.loss_dice: 0.1529  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.2189  decode.d7.loss_dice: 0.1540  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.1666
10/01 00:08:31 - mmengine - INFO - Iter(train) [123800/320000]  base_lr: 6.4387e-05 lr: 6.4387e-06  eta: 23:51:19  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 34.0574  loss: 4.9073  decode.loss_cls: 0.0021  decode.loss_mask: 0.2164  decode.loss_dice: 0.1953  decode.d0.loss_cls: 0.8458  decode.d0.loss_mask: 0.2218  decode.d0.loss_dice: 0.2016  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.2164  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.1837  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.2162  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.1828  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2134  decode.d5.loss_dice: 0.1839  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.1864  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.1887
10/01 00:08:53 - mmengine - INFO - Iter(train) [123850/320000]  base_lr: 6.4372e-05 lr: 6.4372e-06  eta: 23:50:57  time: 0.4400  data_time: 0.0096  memory: 5129  grad_norm: 40.2678  loss: 3.8213  decode.loss_cls: 0.0066  decode.loss_mask: 0.1650  decode.loss_dice: 0.1308  decode.d0.loss_cls: 0.8366  decode.d0.loss_mask: 0.1639  decode.d0.loss_dice: 0.1348  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.1612  decode.d1.loss_dice: 0.1275  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.1622  decode.d2.loss_dice: 0.1254  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.1641  decode.d3.loss_dice: 0.1274  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.1619  decode.d4.loss_dice: 0.1253  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.1635  decode.d5.loss_dice: 0.1259  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.1639  decode.d6.loss_dice: 0.1288  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.1355  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.1649  decode.d8.loss_dice: 0.1306
10/01 00:09:15 - mmengine - INFO - Iter(train) [123900/320000]  base_lr: 6.4357e-05 lr: 6.4357e-06  eta: 23:50:35  time: 0.4413  data_time: 0.0098  memory: 5145  grad_norm: 51.3412  loss: 5.4419  decode.loss_cls: 0.0891  decode.loss_mask: 0.2115  decode.loss_dice: 0.1670  decode.d0.loss_cls: 0.7780  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.1665  decode.d1.loss_cls: 0.1079  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.1639  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.2108  decode.d2.loss_dice: 0.1601  decode.d3.loss_cls: 0.0994  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0887  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1676  decode.d5.loss_cls: 0.0906  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.1595  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.2098  decode.d6.loss_dice: 0.1815  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.2111  decode.d7.loss_dice: 0.1915  decode.d8.loss_cls: 0.0919  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.1898
10/01 00:09:37 - mmengine - INFO - Iter(train) [123950/320000]  base_lr: 6.4342e-05 lr: 6.4342e-06  eta: 23:50:14  time: 0.4394  data_time: 0.0097  memory: 5120  grad_norm: 36.4568  loss: 4.4057  decode.loss_cls: 0.0327  decode.loss_mask: 0.1795  decode.loss_dice: 0.1422  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 0.1777  decode.d0.loss_dice: 0.1499  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.1898  decode.d1.loss_dice: 0.1678  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.1786  decode.d2.loss_dice: 0.1415  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.1774  decode.d3.loss_dice: 0.1416  decode.d4.loss_cls: 0.0259  decode.d4.loss_mask: 0.1808  decode.d4.loss_dice: 0.1468  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.1798  decode.d5.loss_dice: 0.1463  decode.d6.loss_cls: 0.0317  decode.d6.loss_mask: 0.1792  decode.d6.loss_dice: 0.1469  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.1773  decode.d7.loss_dice: 0.1452  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.1792  decode.d8.loss_dice: 0.1448
10/01 00:09:59 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:09:59 - mmengine - INFO - Iter(train) [124000/320000]  base_lr: 6.4328e-05 lr: 6.4328e-06  eta: 23:49:52  time: 0.4399  data_time: 0.0094  memory: 5145  grad_norm: 57.7475  loss: 7.3314  decode.loss_cls: 0.1346  decode.loss_mask: 0.2718  decode.loss_dice: 0.2281  decode.d0.loss_cls: 0.9086  decode.d0.loss_mask: 0.2487  decode.d0.loss_dice: 0.2439  decode.d1.loss_cls: 0.1521  decode.d1.loss_mask: 0.2617  decode.d1.loss_dice: 0.2522  decode.d2.loss_cls: 0.1324  decode.d2.loss_mask: 0.2638  decode.d2.loss_dice: 0.2412  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.2458  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.1684  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.1254  decode.d6.loss_mask: 0.3672  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.1453  decode.d7.loss_mask: 0.2700  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.1420  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2229
10/01 00:10:21 - mmengine - INFO - Iter(train) [124050/320000]  base_lr: 6.4313e-05 lr: 6.4313e-06  eta: 23:49:30  time: 0.4390  data_time: 0.0093  memory: 5129  grad_norm: 102.8510  loss: 5.8622  decode.loss_cls: 0.1041  decode.loss_mask: 0.2234  decode.loss_dice: 0.2357  decode.d0.loss_cls: 0.7685  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2098  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.1999  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.1073  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.1930  decode.d4.loss_cls: 0.0974  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2023  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 0.2233  decode.d6.loss_dice: 0.1873  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.2248  decode.d7.loss_dice: 0.1901  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.2261  decode.d8.loss_dice: 0.1919
10/01 00:10:43 - mmengine - INFO - Iter(train) [124100/320000]  base_lr: 6.4298e-05 lr: 6.4298e-06  eta: 23:49:09  time: 0.4392  data_time: 0.0093  memory: 5145  grad_norm: 77.3487  loss: 4.9936  decode.loss_cls: 0.0552  decode.loss_mask: 0.1629  decode.loss_dice: 0.1807  decode.d0.loss_cls: 0.8616  decode.d0.loss_mask: 0.1638  decode.d0.loss_dice: 0.2111  decode.d1.loss_cls: 0.0831  decode.d1.loss_mask: 0.1622  decode.d1.loss_dice: 0.1716  decode.d2.loss_cls: 0.0989  decode.d2.loss_mask: 0.1596  decode.d2.loss_dice: 0.1871  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.1607  decode.d3.loss_dice: 0.2108  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.1594  decode.d4.loss_dice: 0.1834  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.1601  decode.d5.loss_dice: 0.1761  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.1602  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.1616  decode.d7.loss_dice: 0.1855  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.1598  decode.d8.loss_dice: 0.1889
10/01 00:11:05 - mmengine - INFO - Iter(train) [124150/320000]  base_lr: 6.4283e-05 lr: 6.4283e-06  eta: 23:48:47  time: 0.4401  data_time: 0.0094  memory: 5129  grad_norm: 97.8596  loss: 5.4358  decode.loss_cls: 0.0847  decode.loss_mask: 0.1830  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.8515  decode.d0.loss_mask: 0.1809  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.1804  decode.d1.loss_dice: 0.2014  decode.d2.loss_cls: 0.1091  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.1732  decode.d3.loss_cls: 0.1301  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.1712  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.1844  decode.d4.loss_dice: 0.2010  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.1843  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0902  decode.d6.loss_mask: 0.1878  decode.d6.loss_dice: 0.1915  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.1888  decode.d7.loss_dice: 0.1727  decode.d8.loss_cls: 0.0840  decode.d8.loss_mask: 0.1847  decode.d8.loss_dice: 0.2119
10/01 00:11:27 - mmengine - INFO - Iter(train) [124200/320000]  base_lr: 6.4268e-05 lr: 6.4268e-06  eta: 23:48:25  time: 0.4392  data_time: 0.0094  memory: 5129  grad_norm: 26.0963  loss: 4.8497  decode.loss_cls: 0.0163  decode.loss_mask: 0.1950  decode.loss_dice: 0.1826  decode.d0.loss_cls: 0.9143  decode.d0.loss_mask: 0.1944  decode.d0.loss_dice: 0.1803  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.1936  decode.d1.loss_dice: 0.1825  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.1965  decode.d2.loss_dice: 0.1837  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.1844  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.1985  decode.d4.loss_dice: 0.1746  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.1922  decode.d5.loss_dice: 0.1769  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.1958  decode.d6.loss_dice: 0.1776  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.1950  decode.d7.loss_dice: 0.1792  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.1872
10/01 00:11:49 - mmengine - INFO - Iter(train) [124250/320000]  base_lr: 6.4254e-05 lr: 6.4254e-06  eta: 23:48:03  time: 0.4386  data_time: 0.0094  memory: 5120  grad_norm: 64.8099  loss: 5.2325  decode.loss_cls: 0.0601  decode.loss_mask: 0.2080  decode.loss_dice: 0.1698  decode.d0.loss_cls: 0.7489  decode.d0.loss_mask: 0.2073  decode.d0.loss_dice: 0.1860  decode.d1.loss_cls: 0.0888  decode.d1.loss_mask: 0.2097  decode.d1.loss_dice: 0.1740  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.2072  decode.d2.loss_dice: 0.1772  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.2087  decode.d3.loss_dice: 0.1878  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.2086  decode.d5.loss_dice: 0.1854  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.2109  decode.d6.loss_dice: 0.1909  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.2083  decode.d8.loss_dice: 0.1879
10/01 00:12:11 - mmengine - INFO - Iter(train) [124300/320000]  base_lr: 6.4239e-05 lr: 6.4239e-06  eta: 23:47:41  time: 0.4393  data_time: 0.0095  memory: 5145  grad_norm: 48.2213  loss: 5.1584  decode.loss_cls: 0.0096  decode.loss_mask: 0.2650  decode.loss_dice: 0.1760  decode.d0.loss_cls: 0.6828  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.1782  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.1734  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.2619  decode.d2.loss_dice: 0.1760  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.1752  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2616  decode.d4.loss_dice: 0.1775  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.1771  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2612  decode.d6.loss_dice: 0.1748  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2630  decode.d7.loss_dice: 0.1759  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.2633  decode.d8.loss_dice: 0.1761
10/01 00:12:33 - mmengine - INFO - Iter(train) [124350/320000]  base_lr: 6.4224e-05 lr: 6.4224e-06  eta: 23:47:20  time: 0.4388  data_time: 0.0092  memory: 5145  grad_norm: 55.6133  loss: 5.2352  decode.loss_cls: 0.0600  decode.loss_mask: 0.2130  decode.loss_dice: 0.1693  decode.d0.loss_cls: 0.8356  decode.d0.loss_mask: 0.2165  decode.d0.loss_dice: 0.1702  decode.d1.loss_cls: 0.0693  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1705  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.1710  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.2126  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.2152  decode.d4.loss_dice: 0.1692  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.1684  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.2141  decode.d6.loss_dice: 0.1639  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.2117  decode.d7.loss_dice: 0.1678  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.2143  decode.d8.loss_dice: 0.1694
10/01 00:12:55 - mmengine - INFO - Iter(train) [124400/320000]  base_lr: 6.4209e-05 lr: 6.4209e-06  eta: 23:46:58  time: 0.4387  data_time: 0.0091  memory: 5120  grad_norm: 95.5576  loss: 6.0288  decode.loss_cls: 0.1326  decode.loss_mask: 0.1988  decode.loss_dice: 0.1779  decode.d0.loss_cls: 0.8527  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.2128  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.1978  decode.d1.loss_dice: 0.2101  decode.d2.loss_cls: 0.1587  decode.d2.loss_mask: 0.1968  decode.d2.loss_dice: 0.1876  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.1963  decode.d3.loss_dice: 0.2092  decode.d4.loss_cls: 0.1215  decode.d4.loss_mask: 0.1991  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.1628  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.1861  decode.d6.loss_cls: 0.1399  decode.d6.loss_mask: 0.1993  decode.d6.loss_dice: 0.2165  decode.d7.loss_cls: 0.1415  decode.d7.loss_mask: 0.1988  decode.d7.loss_dice: 0.1756  decode.d8.loss_cls: 0.1402  decode.d8.loss_mask: 0.1979  decode.d8.loss_dice: 0.1854
10/01 00:13:17 - mmengine - INFO - Iter(train) [124450/320000]  base_lr: 6.4195e-05 lr: 6.4195e-06  eta: 23:46:36  time: 0.4386  data_time: 0.0093  memory: 5129  grad_norm: 84.8729  loss: 5.8358  decode.loss_cls: 0.1038  decode.loss_mask: 0.1997  decode.loss_dice: 0.2055  decode.d0.loss_cls: 0.8367  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.1990  decode.d1.loss_dice: 0.2351  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.1998  decode.d2.loss_dice: 0.2239  decode.d3.loss_cls: 0.0817  decode.d3.loss_mask: 0.1982  decode.d3.loss_dice: 0.1994  decode.d4.loss_cls: 0.1819  decode.d4.loss_mask: 0.2002  decode.d4.loss_dice: 0.1909  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.2151  decode.d6.loss_cls: 0.1103  decode.d6.loss_mask: 0.1985  decode.d6.loss_dice: 0.2047  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.2003  decode.d7.loss_dice: 0.2328  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.2004
10/01 00:13:39 - mmengine - INFO - Iter(train) [124500/320000]  base_lr: 6.4180e-05 lr: 6.4180e-06  eta: 23:46:14  time: 0.4391  data_time: 0.0093  memory: 5129  grad_norm: 48.9688  loss: 5.0152  decode.loss_cls: 0.0664  decode.loss_mask: 0.2015  decode.loss_dice: 0.1508  decode.d0.loss_cls: 0.9546  decode.d0.loss_mask: 0.2032  decode.d0.loss_dice: 0.1603  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.1539  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.2010  decode.d2.loss_dice: 0.1549  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.1523  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.1520  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.1964  decode.d5.loss_dice: 0.1459  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.1985  decode.d6.loss_dice: 0.1507  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.1981  decode.d7.loss_dice: 0.1493  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.2024  decode.d8.loss_dice: 0.1516
10/01 00:14:01 - mmengine - INFO - Iter(train) [124550/320000]  base_lr: 6.4165e-05 lr: 6.4165e-06  eta: 23:45:53  time: 0.4385  data_time: 0.0092  memory: 5129  grad_norm: 82.6026  loss: 5.1547  decode.loss_cls: 0.0129  decode.loss_mask: 0.2392  decode.loss_dice: 0.1979  decode.d0.loss_cls: 0.7148  decode.d0.loss_mask: 0.2417  decode.d0.loss_dice: 0.1951  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.1955  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.1916  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.2395  decode.d3.loss_dice: 0.1889  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.1956  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2408  decode.d5.loss_dice: 0.1920  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.2397  decode.d6.loss_dice: 0.1887  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.1911  decode.d8.loss_cls: 0.0106  decode.d8.loss_mask: 0.2419  decode.d8.loss_dice: 0.1911
10/01 00:14:23 - mmengine - INFO - Iter(train) [124600/320000]  base_lr: 6.4150e-05 lr: 6.4150e-06  eta: 23:45:31  time: 0.4380  data_time: 0.0092  memory: 5129  grad_norm: 21.2400  loss: 4.0723  decode.loss_cls: 0.0032  decode.loss_mask: 0.1820  decode.loss_dice: 0.1346  decode.d0.loss_cls: 0.8509  decode.d0.loss_mask: 0.1866  decode.d0.loss_dice: 0.1330  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.1850  decode.d1.loss_dice: 0.1333  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.1833  decode.d2.loss_dice: 0.1359  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.1852  decode.d3.loss_dice: 0.1367  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.1811  decode.d4.loss_dice: 0.1351  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.1828  decode.d5.loss_dice: 0.1378  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1831  decode.d6.loss_dice: 0.1338  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.1839  decode.d7.loss_dice: 0.1333  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.1824  decode.d8.loss_dice: 0.1317
10/01 00:14:45 - mmengine - INFO - Iter(train) [124650/320000]  base_lr: 6.4135e-05 lr: 6.4135e-06  eta: 23:45:09  time: 0.4389  data_time: 0.0090  memory: 5120  grad_norm: 16.5036  loss: 3.5475  decode.loss_cls: 0.0037  decode.loss_mask: 0.1487  decode.loss_dice: 0.1252  decode.d0.loss_cls: 0.7629  decode.d0.loss_mask: 0.1497  decode.d0.loss_dice: 0.1246  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.1487  decode.d1.loss_dice: 0.1275  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.1505  decode.d2.loss_dice: 0.1255  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.1486  decode.d3.loss_dice: 0.1259  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.1479  decode.d4.loss_dice: 0.1252  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.1477  decode.d5.loss_dice: 0.1240  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.1495  decode.d6.loss_dice: 0.1276  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.1480  decode.d7.loss_dice: 0.1266  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.1496  decode.d8.loss_dice: 0.1259
10/01 00:15:07 - mmengine - INFO - Iter(train) [124700/320000]  base_lr: 6.4121e-05 lr: 6.4121e-06  eta: 23:44:47  time: 0.4391  data_time: 0.0091  memory: 5146  grad_norm: 69.8837  loss: 4.8779  decode.loss_cls: 0.0414  decode.loss_mask: 0.1990  decode.loss_dice: 0.1657  decode.d0.loss_cls: 0.9178  decode.d0.loss_mask: 0.1978  decode.d0.loss_dice: 0.1613  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.1651  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.1799  decode.d4.loss_cls: 0.0262  decode.d4.loss_mask: 0.1975  decode.d4.loss_dice: 0.1615  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.1979  decode.d5.loss_dice: 0.1824  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.1986  decode.d6.loss_dice: 0.1815  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.1993  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.1953  decode.d8.loss_dice: 0.1734
10/01 00:15:29 - mmengine - INFO - Iter(train) [124750/320000]  base_lr: 6.4106e-05 lr: 6.4106e-06  eta: 23:44:25  time: 0.4387  data_time: 0.0093  memory: 5119  grad_norm: 215.1823  loss: 7.9496  decode.loss_cls: 0.1801  decode.loss_mask: 0.4739  decode.loss_dice: 0.3009  decode.d0.loss_cls: 0.7477  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.1630  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.3042  decode.d2.loss_cls: 0.1299  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.2617  decode.d3.loss_cls: 0.1363  decode.d3.loss_mask: 0.2672  decode.d3.loss_dice: 0.2949  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.1624  decode.d5.loss_mask: 0.2827  decode.d5.loss_dice: 0.2987  decode.d6.loss_cls: 0.1829  decode.d6.loss_mask: 0.2645  decode.d6.loss_dice: 0.2767  decode.d7.loss_cls: 0.1906  decode.d7.loss_mask: 0.2668  decode.d7.loss_dice: 0.2876  decode.d8.loss_cls: 0.1411  decode.d8.loss_mask: 0.4048  decode.d8.loss_dice: 0.3302
10/01 00:15:51 - mmengine - INFO - Iter(train) [124800/320000]  base_lr: 6.4091e-05 lr: 6.4091e-06  eta: 23:44:04  time: 0.4385  data_time: 0.0091  memory: 5145  grad_norm: 17.2895  loss: 3.5041  decode.loss_cls: 0.0015  decode.loss_mask: 0.1412  decode.loss_dice: 0.1274  decode.d0.loss_cls: 0.8298  decode.d0.loss_mask: 0.1421  decode.d0.loss_dice: 0.1229  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.1410  decode.d1.loss_dice: 0.1261  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.1415  decode.d2.loss_dice: 0.1217  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.1409  decode.d3.loss_dice: 0.1231  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1405  decode.d4.loss_dice: 0.1254  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.1414  decode.d5.loss_dice: 0.1266  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1403  decode.d6.loss_dice: 0.1247  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.1419  decode.d7.loss_dice: 0.1250  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1405  decode.d8.loss_dice: 0.1236
10/01 00:16:13 - mmengine - INFO - Iter(train) [124850/320000]  base_lr: 6.4076e-05 lr: 6.4076e-06  eta: 23:43:42  time: 0.4402  data_time: 0.0094  memory: 5129  grad_norm: 31.9300  loss: 4.1848  decode.loss_cls: 0.0117  decode.loss_mask: 0.1779  decode.loss_dice: 0.1417  decode.d0.loss_cls: 0.8298  decode.d0.loss_mask: 0.1851  decode.d0.loss_dice: 0.1367  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.1804  decode.d1.loss_dice: 0.1503  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.1808  decode.d2.loss_dice: 0.1561  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.1801  decode.d3.loss_dice: 0.1453  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.1786  decode.d4.loss_dice: 0.1526  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.1790  decode.d5.loss_dice: 0.1454  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.1780  decode.d6.loss_dice: 0.1476  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.1804  decode.d7.loss_dice: 0.1470  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.1824  decode.d8.loss_dice: 0.1464
10/01 00:16:35 - mmengine - INFO - Iter(train) [124900/320000]  base_lr: 6.4062e-05 lr: 6.4062e-06  eta: 23:43:20  time: 0.4389  data_time: 0.0092  memory: 5145  grad_norm: 47.2390  loss: 5.5609  decode.loss_cls: 0.0519  decode.loss_mask: 0.2398  decode.loss_dice: 0.1928  decode.d0.loss_cls: 0.7477  decode.d0.loss_mask: 0.2465  decode.d0.loss_dice: 0.1833  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.1892  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0292  decode.d4.loss_mask: 0.2451  decode.d4.loss_dice: 0.1860  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.2439  decode.d5.loss_dice: 0.1857  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.2418  decode.d6.loss_dice: 0.1891  decode.d7.loss_cls: 0.0916  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.1852  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.1848
10/01 00:16:57 - mmengine - INFO - Iter(train) [124950/320000]  base_lr: 6.4047e-05 lr: 6.4047e-06  eta: 23:42:58  time: 0.4384  data_time: 0.0092  memory: 5120  grad_norm: 41.7117  loss: 4.4604  decode.loss_cls: 0.0140  decode.loss_mask: 0.1802  decode.loss_dice: 0.1403  decode.d0.loss_cls: 0.8783  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1457  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.1768  decode.d1.loss_dice: 0.1403  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.1803  decode.d2.loss_dice: 0.1398  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.1838  decode.d3.loss_dice: 0.1403  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.1822  decode.d4.loss_dice: 0.1421  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.1831  decode.d5.loss_dice: 0.1405  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.1821  decode.d6.loss_dice: 0.1398  decode.d7.loss_cls: 0.0204  decode.d7.loss_mask: 0.1810  decode.d7.loss_dice: 0.1394  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.1825  decode.d8.loss_dice: 0.1404
10/01 00:17:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:17:19 - mmengine - INFO - Iter(train) [125000/320000]  base_lr: 6.4032e-05 lr: 6.4032e-06  eta: 23:42:37  time: 0.4394  data_time: 0.0093  memory: 5129  grad_norm: 128.8738  loss: 4.8685  decode.loss_cls: 0.0042  decode.loss_mask: 0.2304  decode.loss_dice: 0.1689  decode.d0.loss_cls: 0.7677  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.1765  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.2334  decode.d1.loss_dice: 0.1734  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.2349  decode.d2.loss_dice: 0.1788  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.1689  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.1668  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.1721  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.2319  decode.d6.loss_dice: 0.1777  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.1714  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.1694
10/01 00:17:41 - mmengine - INFO - Iter(train) [125050/320000]  base_lr: 6.4017e-05 lr: 6.4017e-06  eta: 23:42:15  time: 0.4388  data_time: 0.0093  memory: 5129  grad_norm: 63.4835  loss: 5.8176  decode.loss_cls: 0.1301  decode.loss_mask: 0.1906  decode.loss_dice: 0.2185  decode.d0.loss_cls: 0.6848  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.2199  decode.d1.loss_cls: 0.1328  decode.d1.loss_mask: 0.1886  decode.d1.loss_dice: 0.2390  decode.d2.loss_cls: 0.1406  decode.d2.loss_mask: 0.1928  decode.d2.loss_dice: 0.2507  decode.d3.loss_cls: 0.1164  decode.d3.loss_mask: 0.1919  decode.d3.loss_dice: 0.2476  decode.d4.loss_cls: 0.0891  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.2298  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.1929  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.1929  decode.d6.loss_dice: 0.2463  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.1913  decode.d7.loss_dice: 0.2281  decode.d8.loss_cls: 0.0906  decode.d8.loss_mask: 0.1900  decode.d8.loss_dice: 0.1820
10/01 00:18:03 - mmengine - INFO - Iter(train) [125100/320000]  base_lr: 6.4002e-05 lr: 6.4002e-06  eta: 23:41:53  time: 0.4388  data_time: 0.0092  memory: 5129  grad_norm: 37.4917  loss: 5.1563  decode.loss_cls: 0.0768  decode.loss_mask: 0.1882  decode.loss_dice: 0.1815  decode.d0.loss_cls: 0.7356  decode.d0.loss_mask: 0.1916  decode.d0.loss_dice: 0.1783  decode.d1.loss_cls: 0.0814  decode.d1.loss_mask: 0.1889  decode.d1.loss_dice: 0.1729  decode.d2.loss_cls: 0.1069  decode.d2.loss_mask: 0.1885  decode.d2.loss_dice: 0.1500  decode.d3.loss_cls: 0.1199  decode.d3.loss_mask: 0.1900  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0945  decode.d4.loss_mask: 0.1860  decode.d4.loss_dice: 0.1754  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.1883  decode.d5.loss_dice: 0.1833  decode.d6.loss_cls: 0.0711  decode.d6.loss_mask: 0.1884  decode.d6.loss_dice: 0.1821  decode.d7.loss_cls: 0.0828  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.1570  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.1908  decode.d8.loss_dice: 0.1641
10/01 00:18:25 - mmengine - INFO - Iter(train) [125150/320000]  base_lr: 6.3988e-05 lr: 6.3988e-06  eta: 23:41:32  time: 0.4417  data_time: 0.0093  memory: 5129  grad_norm: 47.3864  loss: 5.3826  decode.loss_cls: 0.0294  decode.loss_mask: 0.2149  decode.loss_dice: 0.2053  decode.d0.loss_cls: 0.8141  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.2198  decode.d1.loss_cls: 0.0461  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1772  decode.d2.loss_cls: 0.0494  decode.d2.loss_mask: 0.2114  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.2155  decode.d3.loss_dice: 0.2164  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.2129  decode.d4.loss_dice: 0.2002  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.2143  decode.d5.loss_dice: 0.2092  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.2164  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0350  decode.d7.loss_mask: 0.2145  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.2142  decode.d8.loss_dice: 0.2234
10/01 00:18:47 - mmengine - INFO - Iter(train) [125200/320000]  base_lr: 6.3973e-05 lr: 6.3973e-06  eta: 23:41:10  time: 0.4400  data_time: 0.0090  memory: 5129  grad_norm: 37.2649  loss: 5.9198  decode.loss_cls: 0.1657  decode.loss_mask: 0.1979  decode.loss_dice: 0.1596  decode.d0.loss_cls: 0.9596  decode.d0.loss_mask: 0.2020  decode.d0.loss_dice: 0.1638  decode.d1.loss_cls: 0.1921  decode.d1.loss_mask: 0.2000  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.1962  decode.d2.loss_dice: 0.1543  decode.d3.loss_cls: 0.1518  decode.d3.loss_mask: 0.1981  decode.d3.loss_dice: 0.1573  decode.d4.loss_cls: 0.1638  decode.d4.loss_mask: 0.1968  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.1455  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.1530  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 0.2002  decode.d6.loss_dice: 0.1577  decode.d7.loss_cls: 0.1581  decode.d7.loss_mask: 0.1988  decode.d7.loss_dice: 0.1581  decode.d8.loss_cls: 0.1354  decode.d8.loss_mask: 0.1989  decode.d8.loss_dice: 0.1578
10/01 00:19:09 - mmengine - INFO - Iter(train) [125250/320000]  base_lr: 6.3958e-05 lr: 6.3958e-06  eta: 23:40:48  time: 0.4412  data_time: 0.0095  memory: 5129  grad_norm: 28.5508  loss: 5.0939  decode.loss_cls: 0.0069  decode.loss_mask: 0.2458  decode.loss_dice: 0.1881  decode.d0.loss_cls: 0.7322  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.1893  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2445  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.2468  decode.d2.loss_dice: 0.1897  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.1819  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2448  decode.d4.loss_dice: 0.1822  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2455  decode.d5.loss_dice: 0.1827  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.2473  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.2436  decode.d7.loss_dice: 0.1863  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.2467  decode.d8.loss_dice: 0.1860
10/01 00:19:31 - mmengine - INFO - Iter(train) [125300/320000]  base_lr: 6.3943e-05 lr: 6.3943e-06  eta: 23:40:26  time: 0.4396  data_time: 0.0095  memory: 5145  grad_norm: 103.0979  loss: 5.8465  decode.loss_cls: 0.0673  decode.loss_mask: 0.2868  decode.loss_dice: 0.1985  decode.d0.loss_cls: 0.8624  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1754  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.2213  decode.d1.loss_dice: 0.1809  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.1785  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.2218  decode.d3.loss_dice: 0.1758  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.2276  decode.d4.loss_dice: 0.1816  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.3198  decode.d5.loss_dice: 0.2030  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.1789  decode.d7.loss_cls: 0.0610  decode.d7.loss_mask: 0.2353  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.4266  decode.d8.loss_dice: 0.2001
10/01 00:19:53 - mmengine - INFO - Iter(train) [125350/320000]  base_lr: 6.3929e-05 lr: 6.3929e-06  eta: 23:40:05  time: 0.4411  data_time: 0.0092  memory: 5145  grad_norm: 39.2637  loss: 4.5385  decode.loss_cls: 0.0239  decode.loss_mask: 0.1555  decode.loss_dice: 0.1812  decode.d0.loss_cls: 0.9403  decode.d0.loss_mask: 0.1569  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.1580  decode.d1.loss_dice: 0.1690  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.1551  decode.d2.loss_dice: 0.1657  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.1555  decode.d3.loss_dice: 0.1694  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.1551  decode.d4.loss_dice: 0.1664  decode.d5.loss_cls: 0.0394  decode.d5.loss_mask: 0.1546  decode.d5.loss_dice: 0.1683  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.1553  decode.d6.loss_dice: 0.1702  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.1537  decode.d7.loss_dice: 0.1659  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 0.1562  decode.d8.loss_dice: 0.1767
10/01 00:20:15 - mmengine - INFO - Iter(train) [125400/320000]  base_lr: 6.3914e-05 lr: 6.3914e-06  eta: 23:39:43  time: 0.4392  data_time: 0.0093  memory: 5129  grad_norm: 104.8731  loss: 6.4946  decode.loss_cls: 0.1531  decode.loss_mask: 0.2233  decode.loss_dice: 0.1508  decode.d0.loss_cls: 0.8129  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.1546  decode.d1.loss_cls: 0.1071  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.1564  decode.d2.loss_cls: 0.1202  decode.d2.loss_mask: 0.2244  decode.d2.loss_dice: 0.1528  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.4285  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0407  decode.d4.loss_mask: 0.4284  decode.d4.loss_dice: 0.1694  decode.d5.loss_cls: 0.1383  decode.d5.loss_mask: 0.2253  decode.d5.loss_dice: 0.1557  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.4187  decode.d6.loss_dice: 0.1678  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.4275  decode.d7.loss_dice: 0.1674  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.4283  decode.d8.loss_dice: 0.1688
10/01 00:20:37 - mmengine - INFO - Iter(train) [125450/320000]  base_lr: 6.3899e-05 lr: 6.3899e-06  eta: 23:39:21  time: 0.4386  data_time: 0.0090  memory: 5129  grad_norm: 17.8444  loss: 3.8670  decode.loss_cls: 0.0063  decode.loss_mask: 0.1530  decode.loss_dice: 0.1466  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 0.1551  decode.d0.loss_dice: 0.1489  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.1510  decode.d1.loss_dice: 0.1379  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.1529  decode.d2.loss_dice: 0.1448  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.1531  decode.d3.loss_dice: 0.1370  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.1538  decode.d4.loss_dice: 0.1388  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.1529  decode.d5.loss_dice: 0.1372  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.1540  decode.d6.loss_dice: 0.1472  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.1538  decode.d7.loss_dice: 0.1393  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.1527  decode.d8.loss_dice: 0.1395
10/01 00:20:59 - mmengine - INFO - Iter(train) [125500/320000]  base_lr: 6.3884e-05 lr: 6.3884e-06  eta: 23:38:59  time: 0.4393  data_time: 0.0095  memory: 5129  grad_norm: 42.0884  loss: 5.0925  decode.loss_cls: 0.0050  decode.loss_mask: 0.1919  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.9316  decode.d0.loss_mask: 0.1960  decode.d0.loss_dice: 0.1953  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.1900  decode.d1.loss_dice: 0.2055  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.2093  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.1934  decode.d5.loss_dice: 0.2062  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.1957  decode.d6.loss_dice: 0.2081  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.1931  decode.d7.loss_dice: 0.2084  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.1916  decode.d8.loss_dice: 0.2093
10/01 00:21:21 - mmengine - INFO - Iter(train) [125550/320000]  base_lr: 6.3869e-05 lr: 6.3869e-06  eta: 23:38:38  time: 0.4399  data_time: 0.0095  memory: 5129  grad_norm: 92.7289  loss: 6.3747  decode.loss_cls: 0.0711  decode.loss_mask: 0.2450  decode.loss_dice: 0.2327  decode.d0.loss_cls: 0.8868  decode.d0.loss_mask: 0.2523  decode.d0.loss_dice: 0.2501  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.2472  decode.d1.loss_dice: 0.2427  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.2445  decode.d2.loss_dice: 0.2243  decode.d3.loss_cls: 0.0600  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.2349  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.2491  decode.d6.loss_dice: 0.2350  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.2458  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.2341
10/01 00:21:43 - mmengine - INFO - Iter(train) [125600/320000]  base_lr: 6.3855e-05 lr: 6.3855e-06  eta: 23:38:16  time: 0.4390  data_time: 0.0092  memory: 5145  grad_norm: 40.3329  loss: 4.5034  decode.loss_cls: 0.0031  decode.loss_mask: 0.1865  decode.loss_dice: 0.1778  decode.d0.loss_cls: 0.8142  decode.d0.loss_mask: 0.1888  decode.d0.loss_dice: 0.1567  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.1871  decode.d1.loss_dice: 0.1764  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.1926  decode.d2.loss_dice: 0.1801  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.1950  decode.d3.loss_dice: 0.1722  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1917  decode.d4.loss_dice: 0.1854  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1899  decode.d5.loss_dice: 0.1812  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1891  decode.d6.loss_dice: 0.1748  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.1871  decode.d7.loss_dice: 0.1731  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.1913  decode.d8.loss_dice: 0.1792
10/01 00:22:05 - mmengine - INFO - Iter(train) [125650/320000]  base_lr: 6.3840e-05 lr: 6.3840e-06  eta: 23:37:54  time: 0.4394  data_time: 0.0093  memory: 5129  grad_norm: 30.5614  loss: 5.4679  decode.loss_cls: 0.0958  decode.loss_mask: 0.1717  decode.loss_dice: 0.1731  decode.d0.loss_cls: 0.8193  decode.d0.loss_mask: 0.1771  decode.d0.loss_dice: 0.1604  decode.d1.loss_cls: 0.1745  decode.d1.loss_mask: 0.1656  decode.d1.loss_dice: 0.1725  decode.d2.loss_cls: 0.1597  decode.d2.loss_mask: 0.1676  decode.d2.loss_dice: 0.1738  decode.d3.loss_cls: 0.1061  decode.d3.loss_mask: 0.1741  decode.d3.loss_dice: 0.1733  decode.d4.loss_cls: 0.1990  decode.d4.loss_mask: 0.1707  decode.d4.loss_dice: 0.1752  decode.d5.loss_cls: 0.1355  decode.d5.loss_mask: 0.1714  decode.d5.loss_dice: 0.1689  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.1718  decode.d6.loss_dice: 0.1715  decode.d7.loss_cls: 0.1405  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.1738  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.1733  decode.d8.loss_dice: 0.1698
10/01 00:22:27 - mmengine - INFO - Iter(train) [125700/320000]  base_lr: 6.3825e-05 lr: 6.3825e-06  eta: 23:37:32  time: 0.4400  data_time: 0.0096  memory: 5129  grad_norm: 49.0374  loss: 6.8603  decode.loss_cls: 0.1311  decode.loss_mask: 0.2684  decode.loss_dice: 0.2182  decode.d0.loss_cls: 0.8715  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.2117  decode.d1.loss_cls: 0.1355  decode.d1.loss_mask: 0.2773  decode.d1.loss_dice: 0.2176  decode.d2.loss_cls: 0.1162  decode.d2.loss_mask: 0.2676  decode.d2.loss_dice: 0.2162  decode.d3.loss_cls: 0.1261  decode.d3.loss_mask: 0.2688  decode.d3.loss_dice: 0.2161  decode.d4.loss_cls: 0.1328  decode.d4.loss_mask: 0.2650  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.2730  decode.d5.loss_dice: 0.2146  decode.d6.loss_cls: 0.1217  decode.d6.loss_mask: 0.2640  decode.d6.loss_dice: 0.2108  decode.d7.loss_cls: 0.1295  decode.d7.loss_mask: 0.2645  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.1464  decode.d8.loss_mask: 0.2700  decode.d8.loss_dice: 0.2111
10/01 00:22:49 - mmengine - INFO - Iter(train) [125750/320000]  base_lr: 6.3810e-05 lr: 6.3810e-06  eta: 23:37:11  time: 0.4391  data_time: 0.0092  memory: 5145  grad_norm: 64.3692  loss: 5.3390  decode.loss_cls: 0.0237  decode.loss_mask: 0.2154  decode.loss_dice: 0.1882  decode.d0.loss_cls: 0.7749  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.2072  decode.d1.loss_cls: 0.1345  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1954  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.2156  decode.d2.loss_dice: 0.2002  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.2134  decode.d3.loss_dice: 0.2053  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.2152  decode.d4.loss_dice: 0.1998  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.2135  decode.d6.loss_cls: 0.0315  decode.d6.loss_mask: 0.2144  decode.d6.loss_dice: 0.1992  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.0253  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.2054
10/01 00:23:11 - mmengine - INFO - Iter(train) [125800/320000]  base_lr: 6.3796e-05 lr: 6.3796e-06  eta: 23:36:49  time: 0.4384  data_time: 0.0094  memory: 5120  grad_norm: 72.8737  loss: 6.3023  decode.loss_cls: 0.0164  decode.loss_mask: 0.3121  decode.loss_dice: 0.2059  decode.d0.loss_cls: 0.8958  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.2044  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.3181  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.3250  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.3136  decode.d3.loss_dice: 0.2116  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.3155  decode.d4.loss_dice: 0.2069  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.3199  decode.d5.loss_dice: 0.2081  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.3116  decode.d6.loss_dice: 0.2061  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.3217  decode.d7.loss_dice: 0.2086  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.3169  decode.d8.loss_dice: 0.2086
10/01 00:23:33 - mmengine - INFO - Iter(train) [125850/320000]  base_lr: 6.3781e-05 lr: 6.3781e-06  eta: 23:36:27  time: 0.4390  data_time: 0.0094  memory: 5120  grad_norm: 110.1843  loss: 8.8890  decode.loss_cls: 0.1615  decode.loss_mask: 0.2980  decode.loss_dice: 0.2366  decode.d0.loss_cls: 0.9946  decode.d0.loss_mask: 0.3168  decode.d0.loss_dice: 0.2201  decode.d1.loss_cls: 0.1719  decode.d1.loss_mask: 0.2957  decode.d1.loss_dice: 0.2205  decode.d2.loss_cls: 0.1945  decode.d2.loss_mask: 0.3086  decode.d2.loss_dice: 0.2027  decode.d3.loss_cls: 0.0867  decode.d3.loss_mask: 0.5815  decode.d3.loss_dice: 0.2488  decode.d4.loss_cls: 0.1244  decode.d4.loss_mask: 0.6371  decode.d4.loss_dice: 0.2529  decode.d5.loss_cls: 0.0676  decode.d5.loss_mask: 0.5448  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.4950  decode.d6.loss_dice: 0.2275  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.5280  decode.d7.loss_dice: 0.2264  decode.d8.loss_cls: 0.1352  decode.d8.loss_mask: 0.4846  decode.d8.loss_dice: 0.2266
10/01 00:23:55 - mmengine - INFO - Iter(train) [125900/320000]  base_lr: 6.3766e-05 lr: 6.3766e-06  eta: 23:36:05  time: 0.4384  data_time: 0.0091  memory: 5129  grad_norm: 27.2266  loss: 5.0269  decode.loss_cls: 0.0431  decode.loss_mask: 0.1986  decode.loss_dice: 0.1756  decode.d0.loss_cls: 0.8882  decode.d0.loss_mask: 0.2049  decode.d0.loss_dice: 0.1902  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.1974  decode.d1.loss_dice: 0.1796  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.2002  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.1999  decode.d3.loss_dice: 0.1725  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.1959  decode.d4.loss_dice: 0.1640  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.1671  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.1953  decode.d6.loss_dice: 0.1701  decode.d7.loss_cls: 0.0454  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0399  decode.d8.loss_mask: 0.1990  decode.d8.loss_dice: 0.1713
10/01 00:24:17 - mmengine - INFO - Iter(train) [125950/320000]  base_lr: 6.3751e-05 lr: 6.3751e-06  eta: 23:35:44  time: 0.4396  data_time: 0.0095  memory: 5129  grad_norm: 120.4309  loss: 7.0480  decode.loss_cls: 0.0667  decode.loss_mask: 0.3271  decode.loss_dice: 0.2198  decode.d0.loss_cls: 0.9371  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.2182  decode.d1.loss_cls: 0.0953  decode.d1.loss_mask: 0.3277  decode.d1.loss_dice: 0.2214  decode.d2.loss_cls: 0.0934  decode.d2.loss_mask: 0.3272  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.3364  decode.d3.loss_dice: 0.2296  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.3315  decode.d4.loss_dice: 0.2179  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.3394  decode.d5.loss_dice: 0.2121  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.3287  decode.d6.loss_dice: 0.2036  decode.d7.loss_cls: 0.0775  decode.d7.loss_mask: 0.3303  decode.d7.loss_dice: 0.2161  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.3332  decode.d8.loss_dice: 0.2203
10/01 00:24:39 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:24:39 - mmengine - INFO - Iter(train) [126000/320000]  base_lr: 6.3736e-05 lr: 6.3736e-06  eta: 23:35:22  time: 0.4396  data_time: 0.0098  memory: 5129  grad_norm: 37.7626  loss: 5.5240  decode.loss_cls: 0.0056  decode.loss_mask: 0.2580  decode.loss_dice: 0.1996  decode.d0.loss_cls: 0.8664  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.1750  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.2642  decode.d1.loss_dice: 0.2003  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2617  decode.d2.loss_dice: 0.1993  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2648  decode.d3.loss_dice: 0.2067  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.2621  decode.d4.loss_dice: 0.1981  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.2013  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2604  decode.d6.loss_dice: 0.1935  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.2615  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2626  decode.d8.loss_dice: 0.2048
10/01 00:25:01 - mmengine - INFO - Iter(train) [126050/320000]  base_lr: 6.3722e-05 lr: 6.3722e-06  eta: 23:35:00  time: 0.4399  data_time: 0.0096  memory: 5129  grad_norm: 27.9916  loss: 4.1771  decode.loss_cls: 0.0072  decode.loss_mask: 0.1917  decode.loss_dice: 0.1386  decode.d0.loss_cls: 0.8168  decode.d0.loss_mask: 0.1959  decode.d0.loss_dice: 0.1424  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.1370  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.1898  decode.d2.loss_dice: 0.1347  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.1898  decode.d3.loss_dice: 0.1384  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.1904  decode.d4.loss_dice: 0.1383  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.1895  decode.d5.loss_dice: 0.1417  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.1901  decode.d6.loss_dice: 0.1387  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.1919  decode.d7.loss_dice: 0.1377  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.1916  decode.d8.loss_dice: 0.1378
10/01 00:25:23 - mmengine - INFO - Iter(train) [126100/320000]  base_lr: 6.3707e-05 lr: 6.3707e-06  eta: 23:34:38  time: 0.4384  data_time: 0.0094  memory: 5130  grad_norm: 48.1761  loss: 5.0101  decode.loss_cls: 0.0202  decode.loss_mask: 0.2078  decode.loss_dice: 0.1887  decode.d0.loss_cls: 0.8451  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.1859  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.2079  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.2088  decode.d2.loss_dice: 0.1880  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.2076  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.2083  decode.d4.loss_dice: 0.1906  decode.d5.loss_cls: 0.0214  decode.d5.loss_mask: 0.2062  decode.d5.loss_dice: 0.1863  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.1854  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.1879  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.2001
10/01 00:25:45 - mmengine - INFO - Iter(train) [126150/320000]  base_lr: 6.3692e-05 lr: 6.3692e-06  eta: 23:34:17  time: 0.4397  data_time: 0.0097  memory: 5120  grad_norm: 34.4833  loss: 4.7727  decode.loss_cls: 0.0367  decode.loss_mask: 0.1633  decode.loss_dice: 0.1691  decode.d0.loss_cls: 0.8826  decode.d0.loss_mask: 0.1643  decode.d0.loss_dice: 0.1537  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.1638  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.1648  decode.d2.loss_dice: 0.1953  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 0.1634  decode.d3.loss_dice: 0.1643  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.1653  decode.d4.loss_dice: 0.1763  decode.d5.loss_cls: 0.1163  decode.d5.loss_mask: 0.1629  decode.d5.loss_dice: 0.1401  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.1631  decode.d6.loss_dice: 0.1731  decode.d7.loss_cls: 0.0968  decode.d7.loss_mask: 0.1636  decode.d7.loss_dice: 0.1489  decode.d8.loss_cls: 0.0855  decode.d8.loss_mask: 0.1639  decode.d8.loss_dice: 0.1514
10/01 00:26:07 - mmengine - INFO - Iter(train) [126200/320000]  base_lr: 6.3677e-05 lr: 6.3677e-06  eta: 23:33:55  time: 0.4398  data_time: 0.0098  memory: 5120  grad_norm: 66.1325  loss: 6.9133  decode.loss_cls: 0.1564  decode.loss_mask: 0.2414  decode.loss_dice: 0.1818  decode.d0.loss_cls: 0.8545  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.1832  decode.d1.loss_cls: 0.1729  decode.d1.loss_mask: 0.2525  decode.d1.loss_dice: 0.1709  decode.d2.loss_cls: 0.1666  decode.d2.loss_mask: 0.2335  decode.d2.loss_dice: 0.1675  decode.d3.loss_cls: 0.1324  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.2081  decode.d4.loss_cls: 0.1400  decode.d4.loss_mask: 0.3455  decode.d4.loss_dice: 0.2186  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 0.3529  decode.d5.loss_dice: 0.2185  decode.d6.loss_cls: 0.1365  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.2263  decode.d7.loss_cls: 0.1493  decode.d7.loss_mask: 0.2692  decode.d7.loss_dice: 0.1780  decode.d8.loss_cls: 0.1640  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.1797
10/01 00:26:29 - mmengine - INFO - Iter(train) [126250/320000]  base_lr: 6.3663e-05 lr: 6.3663e-06  eta: 23:33:33  time: 0.4400  data_time: 0.0096  memory: 5146  grad_norm: 26.7331  loss: 4.8860  decode.loss_cls: 0.0097  decode.loss_mask: 0.1994  decode.loss_dice: 0.1963  decode.d0.loss_cls: 0.8768  decode.d0.loss_mask: 0.1971  decode.d0.loss_dice: 0.1980  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.1984  decode.d1.loss_dice: 0.1902  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.1934  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.1996  decode.d3.loss_dice: 0.1921  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.1922  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.1922  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.1993  decode.d7.loss_dice: 0.1886  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.1897
10/01 00:26:51 - mmengine - INFO - Iter(train) [126300/320000]  base_lr: 6.3648e-05 lr: 6.3648e-06  eta: 23:33:11  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 72.5609  loss: 5.6764  decode.loss_cls: 0.0562  decode.loss_mask: 0.2186  decode.loss_dice: 0.2135  decode.d0.loss_cls: 0.7357  decode.d0.loss_mask: 0.2219  decode.d0.loss_dice: 0.2194  decode.d1.loss_cls: 0.0798  decode.d1.loss_mask: 0.2219  decode.d1.loss_dice: 0.2077  decode.d2.loss_cls: 0.1212  decode.d2.loss_mask: 0.2176  decode.d2.loss_dice: 0.1917  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.2207  decode.d3.loss_dice: 0.1994  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.2146  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.2203  decode.d5.loss_dice: 0.2043  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.1987  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.2206  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.2181  decode.d8.loss_dice: 0.2084
10/01 00:27:13 - mmengine - INFO - Iter(train) [126350/320000]  base_lr: 6.3633e-05 lr: 6.3633e-06  eta: 23:32:50  time: 0.4393  data_time: 0.0095  memory: 5120  grad_norm: 90.1218  loss: 5.6321  decode.loss_cls: 0.0527  decode.loss_mask: 0.2139  decode.loss_dice: 0.2185  decode.d0.loss_cls: 0.8916  decode.d0.loss_mask: 0.2129  decode.d0.loss_dice: 0.2174  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.2132  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.0769  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.2159  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.2141  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2090  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.2114  decode.d8.loss_dice: 0.2191
10/01 00:27:35 - mmengine - INFO - Iter(train) [126400/320000]  base_lr: 6.3618e-05 lr: 6.3618e-06  eta: 23:32:28  time: 0.4401  data_time: 0.0096  memory: 5145  grad_norm: 58.7306  loss: 4.8911  decode.loss_cls: 0.0421  decode.loss_mask: 0.1626  decode.loss_dice: 0.1770  decode.d0.loss_cls: 0.7797  decode.d0.loss_mask: 0.1591  decode.d0.loss_dice: 0.1672  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 0.1612  decode.d1.loss_dice: 0.1625  decode.d2.loss_cls: 0.1232  decode.d2.loss_mask: 0.1628  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.0964  decode.d3.loss_mask: 0.1607  decode.d3.loss_dice: 0.1856  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.1621  decode.d4.loss_dice: 0.1687  decode.d5.loss_cls: 0.1021  decode.d5.loss_mask: 0.1601  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.1583  decode.d6.loss_dice: 0.1876  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.1608  decode.d7.loss_dice: 0.1608  decode.d8.loss_cls: 0.1292  decode.d8.loss_mask: 0.1618  decode.d8.loss_dice: 0.1659
10/01 00:27:57 - mmengine - INFO - Iter(train) [126450/320000]  base_lr: 6.3603e-05 lr: 6.3603e-06  eta: 23:32:06  time: 0.4399  data_time: 0.0098  memory: 5129  grad_norm: 51.2130  loss: 5.1096  decode.loss_cls: 0.0081  decode.loss_mask: 0.2224  decode.loss_dice: 0.1999  decode.d0.loss_cls: 0.7876  decode.d0.loss_mask: 0.2249  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.2219  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.1993  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.2226  decode.d3.loss_dice: 0.2017  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.2213  decode.d4.loss_dice: 0.2029  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.2009  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2209  decode.d7.loss_dice: 0.2015  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2026
10/01 00:28:19 - mmengine - INFO - Iter(train) [126500/320000]  base_lr: 6.3589e-05 lr: 6.3589e-06  eta: 23:31:45  time: 0.4388  data_time: 0.0095  memory: 5129  grad_norm: 36.1983  loss: 5.8976  decode.loss_cls: 0.0372  decode.loss_mask: 0.2607  decode.loss_dice: 0.2263  decode.d0.loss_cls: 0.7912  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.0355  decode.d1.loss_mask: 0.2636  decode.d1.loss_dice: 0.1994  decode.d2.loss_cls: 0.0403  decode.d2.loss_mask: 0.2633  decode.d2.loss_dice: 0.1787  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.2589  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.2611  decode.d4.loss_dice: 0.2013  decode.d5.loss_cls: 0.0319  decode.d5.loss_mask: 0.2643  decode.d5.loss_dice: 0.2265  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.2107  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.2642  decode.d7.loss_dice: 0.2243  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.2621  decode.d8.loss_dice: 0.2274
10/01 00:28:41 - mmengine - INFO - Iter(train) [126550/320000]  base_lr: 6.3574e-05 lr: 6.3574e-06  eta: 23:31:23  time: 0.4398  data_time: 0.0095  memory: 5129  grad_norm: 30.7436  loss: 5.3286  decode.loss_cls: 0.0237  decode.loss_mask: 0.2312  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.7577  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.2041  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.2344  decode.d1.loss_dice: 0.2129  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.2328  decode.d2.loss_dice: 0.1970  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.2324  decode.d3.loss_dice: 0.1965  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2342  decode.d4.loss_dice: 0.2067  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.2004  decode.d6.loss_cls: 0.0282  decode.d6.loss_mask: 0.2329  decode.d6.loss_dice: 0.2005  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.2352  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.2345  decode.d8.loss_dice: 0.2125
10/01 00:29:03 - mmengine - INFO - Iter(train) [126600/320000]  base_lr: 6.3559e-05 lr: 6.3559e-06  eta: 23:31:01  time: 0.4388  data_time: 0.0098  memory: 5104  grad_norm: 218.4198  loss: 7.6250  decode.loss_cls: 0.0975  decode.loss_mask: 0.3217  decode.loss_dice: 0.2658  decode.d0.loss_cls: 0.9078  decode.d0.loss_mask: 0.3284  decode.d0.loss_dice: 0.2236  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.3135  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.3267  decode.d2.loss_dice: 0.2610  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.3196  decode.d3.loss_dice: 0.2729  decode.d4.loss_cls: 0.1102  decode.d4.loss_mask: 0.3229  decode.d4.loss_dice: 0.2470  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.3168  decode.d5.loss_dice: 0.2702  decode.d6.loss_cls: 0.1198  decode.d6.loss_mask: 0.3200  decode.d6.loss_dice: 0.2685  decode.d7.loss_cls: 0.1224  decode.d7.loss_mask: 0.3202  decode.d7.loss_dice: 0.2342  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.3182  decode.d8.loss_dice: 0.2792
10/01 00:29:25 - mmengine - INFO - Iter(train) [126650/320000]  base_lr: 6.3544e-05 lr: 6.3544e-06  eta: 23:30:40  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 79.4762  loss: 7.5314  decode.loss_cls: 0.0649  decode.loss_mask: 0.3446  decode.loss_dice: 0.2627  decode.d0.loss_cls: 0.6788  decode.d0.loss_mask: 0.3563  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.0861  decode.d1.loss_mask: 0.3475  decode.d1.loss_dice: 0.2663  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.3460  decode.d2.loss_dice: 0.2742  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.3448  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.3505  decode.d4.loss_dice: 0.2828  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.3459  decode.d5.loss_dice: 0.2528  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.3401  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.0705  decode.d7.loss_mask: 0.3460  decode.d7.loss_dice: 0.2766  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.3413  decode.d8.loss_dice: 0.2608
10/01 00:29:47 - mmengine - INFO - Iter(train) [126700/320000]  base_lr: 6.3529e-05 lr: 6.3529e-06  eta: 23:30:18  time: 0.4415  data_time: 0.0096  memory: 5129  grad_norm: 128.5327  loss: 5.2224  decode.loss_cls: 0.0196  decode.loss_mask: 0.2272  decode.loss_dice: 0.1686  decode.d0.loss_cls: 0.8679  decode.d0.loss_mask: 0.2215  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.0142  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.1929  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.1867  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.1864  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.1868  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.1784  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.1785  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.2274  decode.d8.loss_dice: 0.1690
10/01 00:30:09 - mmengine - INFO - Iter(train) [126750/320000]  base_lr: 6.3515e-05 lr: 6.3515e-06  eta: 23:29:56  time: 0.4392  data_time: 0.0094  memory: 5129  grad_norm: 78.8925  loss: 6.2509  decode.loss_cls: 0.1325  decode.loss_mask: 0.2338  decode.loss_dice: 0.1836  decode.d0.loss_cls: 0.8085  decode.d0.loss_mask: 0.2423  decode.d0.loss_dice: 0.1910  decode.d1.loss_cls: 0.0965  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.1210  decode.d2.loss_mask: 0.2342  decode.d2.loss_dice: 0.1866  decode.d3.loss_cls: 0.1520  decode.d3.loss_mask: 0.2351  decode.d3.loss_dice: 0.1928  decode.d4.loss_cls: 0.1363  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.1983  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.1887  decode.d6.loss_cls: 0.1367  decode.d6.loss_mask: 0.2381  decode.d6.loss_dice: 0.1904  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 0.2336  decode.d7.loss_dice: 0.1883  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.1833
10/01 00:30:31 - mmengine - INFO - Iter(train) [126800/320000]  base_lr: 6.3500e-05 lr: 6.3500e-06  eta: 23:29:34  time: 0.4408  data_time: 0.0092  memory: 5129  grad_norm: 43.6987  loss: 4.9861  decode.loss_cls: 0.0108  decode.loss_mask: 0.2202  decode.loss_dice: 0.1789  decode.d0.loss_cls: 0.8234  decode.d0.loss_mask: 0.2307  decode.d0.loss_dice: 0.1833  decode.d1.loss_cls: 0.0162  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.1813  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.2238  decode.d2.loss_dice: 0.1795  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.1828  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.2261  decode.d4.loss_dice: 0.1825  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.2212  decode.d6.loss_dice: 0.1758  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.1792  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1755
10/01 00:30:53 - mmengine - INFO - Iter(train) [126850/320000]  base_lr: 6.3485e-05 lr: 6.3485e-06  eta: 23:29:13  time: 0.4398  data_time: 0.0097  memory: 5145  grad_norm: 24.6377  loss: 4.4911  decode.loss_cls: 0.0832  decode.loss_mask: 0.1301  decode.loss_dice: 0.1616  decode.d0.loss_cls: 0.9399  decode.d0.loss_mask: 0.1443  decode.d0.loss_dice: 0.1480  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.1318  decode.d1.loss_dice: 0.1413  decode.d2.loss_cls: 0.1366  decode.d2.loss_mask: 0.1316  decode.d2.loss_dice: 0.1449  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.1310  decode.d3.loss_dice: 0.1496  decode.d4.loss_cls: 0.1634  decode.d4.loss_mask: 0.1292  decode.d4.loss_dice: 0.1459  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.1298  decode.d5.loss_dice: 0.1460  decode.d6.loss_cls: 0.0864  decode.d6.loss_mask: 0.1310  decode.d6.loss_dice: 0.1487  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.1328  decode.d7.loss_dice: 0.1683  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.1308  decode.d8.loss_dice: 0.1495
10/01 00:31:15 - mmengine - INFO - Iter(train) [126900/320000]  base_lr: 6.3470e-05 lr: 6.3470e-06  eta: 23:28:51  time: 0.4409  data_time: 0.0094  memory: 5129  grad_norm: 77.3740  loss: 5.2179  decode.loss_cls: 0.0161  decode.loss_mask: 0.2308  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.7577  decode.d0.loss_mask: 0.2362  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.1969  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2002  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.2289  decode.d3.loss_dice: 0.2020  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.2309  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2021  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.2307  decode.d6.loss_dice: 0.2046  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2300  decode.d7.loss_dice: 0.2045  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2045
10/01 00:31:37 - mmengine - INFO - Iter(train) [126950/320000]  base_lr: 6.3455e-05 lr: 6.3455e-06  eta: 23:28:29  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 60.7638  loss: 6.8816  decode.loss_cls: 0.1242  decode.loss_mask: 0.2626  decode.loss_dice: 0.2639  decode.d0.loss_cls: 0.7641  decode.d0.loss_mask: 0.2659  decode.d0.loss_dice: 0.2688  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.2619  decode.d1.loss_dice: 0.2525  decode.d2.loss_cls: 0.1353  decode.d2.loss_mask: 0.2680  decode.d2.loss_dice: 0.2745  decode.d3.loss_cls: 0.1122  decode.d3.loss_mask: 0.2678  decode.d3.loss_dice: 0.2703  decode.d4.loss_cls: 0.0878  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.2500  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.2621  decode.d5.loss_dice: 0.2692  decode.d6.loss_cls: 0.0831  decode.d6.loss_mask: 0.2647  decode.d6.loss_dice: 0.2588  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.2628  decode.d7.loss_dice: 0.2479  decode.d8.loss_cls: 0.0963  decode.d8.loss_mask: 0.2613  decode.d8.loss_dice: 0.2441
10/01 00:31:59 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:31:59 - mmengine - INFO - Iter(train) [127000/320000]  base_lr: 6.3441e-05 lr: 6.3441e-06  eta: 23:28:07  time: 0.4397  data_time: 0.0096  memory: 5129  grad_norm: 34.5696  loss: 4.0921  decode.loss_cls: 0.0371  decode.loss_mask: 0.1638  decode.loss_dice: 0.1382  decode.d0.loss_cls: 0.8663  decode.d0.loss_mask: 0.1619  decode.d0.loss_dice: 0.1342  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.1608  decode.d1.loss_dice: 0.1384  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.1608  decode.d2.loss_dice: 0.1339  decode.d3.loss_cls: 0.0262  decode.d3.loss_mask: 0.1622  decode.d3.loss_dice: 0.1359  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.1608  decode.d4.loss_dice: 0.1355  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.1620  decode.d5.loss_dice: 0.1345  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.1605  decode.d6.loss_dice: 0.1349  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.1620  decode.d7.loss_dice: 0.1360  decode.d8.loss_cls: 0.0266  decode.d8.loss_mask: 0.1629  decode.d8.loss_dice: 0.1331
10/01 00:32:21 - mmengine - INFO - Iter(train) [127050/320000]  base_lr: 6.3426e-05 lr: 6.3426e-06  eta: 23:27:46  time: 0.4397  data_time: 0.0095  memory: 5129  grad_norm: 25.4380  loss: 4.3046  decode.loss_cls: 0.0016  decode.loss_mask: 0.1592  decode.loss_dice: 0.1734  decode.d0.loss_cls: 0.8014  decode.d0.loss_mask: 0.1610  decode.d0.loss_dice: 0.1792  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.1615  decode.d1.loss_dice: 0.1941  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.1580  decode.d2.loss_dice: 0.1834  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.1582  decode.d3.loss_dice: 0.1737  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.1615  decode.d4.loss_dice: 0.1804  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.1614  decode.d5.loss_dice: 0.1823  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.1597  decode.d6.loss_dice: 0.1909  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.1586  decode.d7.loss_dice: 0.1700  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1612  decode.d8.loss_dice: 0.1822
10/01 00:32:43 - mmengine - INFO - Iter(train) [127100/320000]  base_lr: 6.3411e-05 lr: 6.3411e-06  eta: 23:27:24  time: 0.4389  data_time: 0.0095  memory: 5129  grad_norm: 163.2473  loss: 5.2565  decode.loss_cls: 0.0649  decode.loss_mask: 0.2047  decode.loss_dice: 0.1628  decode.d0.loss_cls: 0.8694  decode.d0.loss_mask: 0.1801  decode.d0.loss_dice: 0.1710  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.1815  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.2057  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.2105  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.2263  decode.d4.loss_dice: 0.1631  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.2205  decode.d5.loss_dice: 0.1605  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.1590  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.1588
10/01 00:33:05 - mmengine - INFO - Iter(train) [127150/320000]  base_lr: 6.3396e-05 lr: 6.3396e-06  eta: 23:27:02  time: 0.4397  data_time: 0.0098  memory: 5129  grad_norm: 103.3276  loss: 5.9502  decode.loss_cls: 0.0048  decode.loss_mask: 0.2904  decode.loss_dice: 0.2063  decode.d0.loss_cls: 0.9335  decode.d0.loss_mask: 0.2369  decode.d0.loss_dice: 0.2006  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.2390  decode.d1.loss_dice: 0.2075  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.2407  decode.d3.loss_dice: 0.1977  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.1975  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2926  decode.d5.loss_dice: 0.2046  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2972  decode.d6.loss_dice: 0.2093  decode.d7.loss_cls: 0.0777  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.2899  decode.d8.loss_dice: 0.2052
10/01 00:33:27 - mmengine - INFO - Iter(train) [127200/320000]  base_lr: 6.3382e-05 lr: 6.3382e-06  eta: 23:26:40  time: 0.4402  data_time: 0.0097  memory: 5129  grad_norm: 63.2941  loss: 5.6524  decode.loss_cls: 0.0435  decode.loss_mask: 0.2019  decode.loss_dice: 0.2065  decode.d0.loss_cls: 0.8648  decode.d0.loss_mask: 0.1973  decode.d0.loss_dice: 0.2059  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.1978  decode.d2.loss_dice: 0.2067  decode.d3.loss_cls: 0.1412  decode.d3.loss_mask: 0.1954  decode.d3.loss_dice: 0.2031  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.1968  decode.d4.loss_dice: 0.2051  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.1981  decode.d5.loss_dice: 0.2085  decode.d6.loss_cls: 0.0902  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.2038  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.2015  decode.d7.loss_dice: 0.2056  decode.d8.loss_cls: 0.0582  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.2110
10/01 00:33:49 - mmengine - INFO - Iter(train) [127250/320000]  base_lr: 6.3367e-05 lr: 6.3367e-06  eta: 23:26:19  time: 0.4390  data_time: 0.0097  memory: 5104  grad_norm: 33.6905  loss: 5.5090  decode.loss_cls: 0.0253  decode.loss_mask: 0.2269  decode.loss_dice: 0.2169  decode.d0.loss_cls: 0.8335  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2153  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.2169  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.2296  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.2147  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.2305  decode.d4.loss_dice: 0.2095  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.2152  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.0264  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2178
10/01 00:34:11 - mmengine - INFO - Iter(train) [127300/320000]  base_lr: 6.3352e-05 lr: 6.3352e-06  eta: 23:25:57  time: 0.4404  data_time: 0.0097  memory: 5129  grad_norm: 20.4957  loss: 4.6635  decode.loss_cls: 0.0020  decode.loss_mask: 0.1939  decode.loss_dice: 0.1855  decode.d0.loss_cls: 0.8557  decode.d0.loss_mask: 0.2007  decode.d0.loss_dice: 0.1771  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.1950  decode.d2.loss_dice: 0.1885  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.1834  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1939  decode.d4.loss_dice: 0.1873  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.1929  decode.d5.loss_dice: 0.1871  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.1947  decode.d7.loss_dice: 0.1833  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.1840
10/01 00:34:33 - mmengine - INFO - Iter(train) [127350/320000]  base_lr: 6.3337e-05 lr: 6.3337e-06  eta: 23:25:35  time: 0.4404  data_time: 0.0097  memory: 5120  grad_norm: 71.6818  loss: 4.9292  decode.loss_cls: 0.0065  decode.loss_mask: 0.2122  decode.loss_dice: 0.1886  decode.d0.loss_cls: 0.8201  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2019  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.2201  decode.d1.loss_dice: 0.1953  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2141  decode.d2.loss_dice: 0.1945  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.1889  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.2132  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2119  decode.d5.loss_dice: 0.1876  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2132  decode.d6.loss_dice: 0.1858  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.1916  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.2174  decode.d8.loss_dice: 0.1869
10/01 00:34:55 - mmengine - INFO - Iter(train) [127400/320000]  base_lr: 6.3322e-05 lr: 6.3322e-06  eta: 23:25:14  time: 0.4395  data_time: 0.0095  memory: 5145  grad_norm: 50.4165  loss: 5.4296  decode.loss_cls: 0.0466  decode.loss_mask: 0.2180  decode.loss_dice: 0.1928  decode.d0.loss_cls: 0.8216  decode.d0.loss_mask: 0.2210  decode.d0.loss_dice: 0.1829  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.2173  decode.d1.loss_dice: 0.1976  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.1918  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.2194  decode.d4.loss_dice: 0.1902  decode.d5.loss_cls: 0.0536  decode.d5.loss_mask: 0.2177  decode.d5.loss_dice: 0.1908  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.2212  decode.d6.loss_dice: 0.1911  decode.d7.loss_cls: 0.0657  decode.d7.loss_mask: 0.2214  decode.d7.loss_dice: 0.1952  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.2216  decode.d8.loss_dice: 0.1943
10/01 00:35:17 - mmengine - INFO - Iter(train) [127450/320000]  base_lr: 6.3308e-05 lr: 6.3308e-06  eta: 23:24:52  time: 0.4393  data_time: 0.0096  memory: 5120  grad_norm: 62.4461  loss: 5.2619  decode.loss_cls: 0.0799  decode.loss_mask: 0.2154  decode.loss_dice: 0.1607  decode.d0.loss_cls: 0.7772  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.1631  decode.d1.loss_cls: 0.0764  decode.d1.loss_mask: 0.2140  decode.d1.loss_dice: 0.1720  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.2126  decode.d2.loss_dice: 0.1647  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.2130  decode.d3.loss_dice: 0.1576  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.1644  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.2155  decode.d5.loss_dice: 0.1675  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2130  decode.d6.loss_dice: 0.1649  decode.d7.loss_cls: 0.1015  decode.d7.loss_mask: 0.2155  decode.d7.loss_dice: 0.1705  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.2135  decode.d8.loss_dice: 0.1690
10/01 00:35:39 - mmengine - INFO - Iter(train) [127500/320000]  base_lr: 6.3293e-05 lr: 6.3293e-06  eta: 23:24:30  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 40.2173  loss: 5.7057  decode.loss_cls: 0.0140  decode.loss_mask: 0.2829  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.7047  decode.d0.loss_mask: 0.2976  decode.d0.loss_dice: 0.2009  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.2863  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.1991  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.2883  decode.d5.loss_dice: 0.2005  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.2924  decode.d6.loss_dice: 0.2023  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.2039  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.2892  decode.d8.loss_dice: 0.1951
10/01 00:36:01 - mmengine - INFO - Iter(train) [127550/320000]  base_lr: 6.3278e-05 lr: 6.3278e-06  eta: 23:24:08  time: 0.4382  data_time: 0.0095  memory: 5120  grad_norm: 69.7015  loss: 5.6775  decode.loss_cls: 0.1063  decode.loss_mask: 0.2220  decode.loss_dice: 0.1571  decode.d0.loss_cls: 0.6953  decode.d0.loss_mask: 0.2592  decode.d0.loss_dice: 0.1604  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.1671  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.2328  decode.d2.loss_dice: 0.1645  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.1579  decode.d4.loss_cls: 0.1389  decode.d4.loss_mask: 0.2223  decode.d4.loss_dice: 0.1580  decode.d5.loss_cls: 0.1004  decode.d5.loss_mask: 0.2222  decode.d5.loss_dice: 0.1603  decode.d6.loss_cls: 0.1374  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.1613  decode.d7.loss_cls: 0.1135  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.1596  decode.d8.loss_cls: 0.1061  decode.d8.loss_mask: 0.2252  decode.d8.loss_dice: 0.1576
10/01 00:36:23 - mmengine - INFO - Iter(train) [127600/320000]  base_lr: 6.3263e-05 lr: 6.3263e-06  eta: 23:23:47  time: 0.4401  data_time: 0.0097  memory: 5120  grad_norm: 41.5034  loss: 5.2086  decode.loss_cls: 0.0369  decode.loss_mask: 0.1809  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.7609  decode.d0.loss_mask: 0.1801  decode.d0.loss_dice: 0.2072  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.1821  decode.d1.loss_dice: 0.2150  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.1800  decode.d2.loss_dice: 0.2116  decode.d3.loss_cls: 0.0498  decode.d3.loss_mask: 0.1801  decode.d3.loss_dice: 0.2064  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.1786  decode.d4.loss_dice: 0.2130  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.1786  decode.d5.loss_dice: 0.2106  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.1797  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.1794  decode.d7.loss_dice: 0.2145  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.1790  decode.d8.loss_dice: 0.2108
10/01 00:36:45 - mmengine - INFO - Iter(train) [127650/320000]  base_lr: 6.3248e-05 lr: 6.3248e-06  eta: 23:23:25  time: 0.4403  data_time: 0.0097  memory: 5120  grad_norm: 396.5631  loss: 7.1153  decode.loss_cls: 0.1286  decode.loss_mask: 0.2815  decode.loss_dice: 0.2332  decode.d0.loss_cls: 0.7961  decode.d0.loss_mask: 0.2861  decode.d0.loss_dice: 0.2354  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.2262  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.2517  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.2504  decode.d4.loss_cls: 0.1094  decode.d4.loss_mask: 0.2814  decode.d4.loss_dice: 0.2620  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.2838  decode.d5.loss_dice: 0.2481  decode.d6.loss_cls: 0.1136  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.2593  decode.d7.loss_cls: 0.1271  decode.d7.loss_mask: 0.2855  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.1144  decode.d8.loss_mask: 0.2863  decode.d8.loss_dice: 0.2498
10/01 00:37:07 - mmengine - INFO - Iter(train) [127700/320000]  base_lr: 6.3234e-05 lr: 6.3234e-06  eta: 23:23:03  time: 0.4392  data_time: 0.0095  memory: 5145  grad_norm: 61.1225  loss: 7.2281  decode.loss_cls: 0.2118  decode.loss_mask: 0.2418  decode.loss_dice: 0.2162  decode.d0.loss_cls: 0.8620  decode.d0.loss_mask: 0.2491  decode.d0.loss_dice: 0.2249  decode.d1.loss_cls: 0.1354  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.2496  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.2464  decode.d2.loss_dice: 0.2153  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.2389  decode.d3.loss_dice: 0.2130  decode.d4.loss_cls: 0.1823  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.2293  decode.d5.loss_cls: 0.2163  decode.d5.loss_mask: 0.2367  decode.d5.loss_dice: 0.2154  decode.d6.loss_cls: 0.2001  decode.d6.loss_mask: 0.2388  decode.d6.loss_dice: 0.2424  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.2360  decode.d8.loss_cls: 0.2133  decode.d8.loss_mask: 0.2380  decode.d8.loss_dice: 0.2460
10/01 00:37:29 - mmengine - INFO - Iter(train) [127750/320000]  base_lr: 6.3219e-05 lr: 6.3219e-06  eta: 23:22:42  time: 0.4400  data_time: 0.0094  memory: 5145  grad_norm: 35.3847  loss: 4.6033  decode.loss_cls: 0.0025  decode.loss_mask: 0.2004  decode.loss_dice: 0.1785  decode.d0.loss_cls: 0.7356  decode.d0.loss_mask: 0.2191  decode.d0.loss_dice: 0.1843  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2080  decode.d1.loss_dice: 0.1780  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.2034  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2007  decode.d4.loss_dice: 0.1784  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.1789  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.2033  decode.d6.loss_dice: 0.1789  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2025  decode.d7.loss_dice: 0.1808  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.2019  decode.d8.loss_dice: 0.1749
10/01 00:37:51 - mmengine - INFO - Iter(train) [127800/320000]  base_lr: 6.3204e-05 lr: 6.3204e-06  eta: 23:22:20  time: 0.4403  data_time: 0.0097  memory: 5129  grad_norm: 89.9826  loss: 6.8509  decode.loss_cls: 0.0289  decode.loss_mask: 0.2903  decode.loss_dice: 0.2337  decode.d0.loss_cls: 0.7577  decode.d0.loss_mask: 0.2984  decode.d0.loss_dice: 0.2323  decode.d1.loss_cls: 0.1164  decode.d1.loss_mask: 0.2881  decode.d1.loss_dice: 0.2502  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.2912  decode.d2.loss_dice: 0.2351  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.2888  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.0927  decode.d4.loss_mask: 0.2903  decode.d4.loss_dice: 0.2422  decode.d5.loss_cls: 0.1526  decode.d5.loss_mask: 0.2903  decode.d5.loss_dice: 0.2372  decode.d6.loss_cls: 0.1756  decode.d6.loss_mask: 0.2929  decode.d6.loss_dice: 0.2435  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.2901  decode.d7.loss_dice: 0.2389  decode.d8.loss_cls: 0.0364  decode.d8.loss_mask: 0.2964  decode.d8.loss_dice: 0.2281
10/01 00:38:13 - mmengine - INFO - Iter(train) [127850/320000]  base_lr: 6.3189e-05 lr: 6.3189e-06  eta: 23:21:58  time: 0.4407  data_time: 0.0098  memory: 5159  grad_norm: 66.5640  loss: 6.9018  decode.loss_cls: 0.2003  decode.loss_mask: 0.2019  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.9818  decode.d0.loss_mask: 0.2021  decode.d0.loss_dice: 0.2293  decode.d1.loss_cls: 0.1993  decode.d1.loss_mask: 0.1992  decode.d1.loss_dice: 0.2249  decode.d2.loss_cls: 0.2001  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.2177  decode.d3.loss_cls: 0.1831  decode.d3.loss_mask: 0.1981  decode.d3.loss_dice: 0.2284  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2506  decode.d5.loss_cls: 0.2188  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.2540  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 0.1990  decode.d6.loss_dice: 0.2250  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.1987  decode.d7.loss_dice: 0.2464  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.2402
10/01 00:38:35 - mmengine - INFO - Iter(train) [127900/320000]  base_lr: 6.3174e-05 lr: 6.3174e-06  eta: 23:21:36  time: 0.4409  data_time: 0.0096  memory: 5129  grad_norm: 26.7219  loss: 4.3958  decode.loss_cls: 0.0077  decode.loss_mask: 0.1671  decode.loss_dice: 0.1618  decode.d0.loss_cls: 0.8947  decode.d0.loss_mask: 0.1714  decode.d0.loss_dice: 0.1578  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.1675  decode.d1.loss_dice: 0.1739  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.1688  decode.d2.loss_dice: 0.1790  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.1659  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.1706  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.1679  decode.d5.loss_dice: 0.1621  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.1690  decode.d6.loss_dice: 0.1705  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.1677  decode.d7.loss_dice: 0.1685  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.1690  decode.d8.loss_dice: 0.1626
10/01 00:38:57 - mmengine - INFO - Iter(train) [127950/320000]  base_lr: 6.3160e-05 lr: 6.3160e-06  eta: 23:21:15  time: 0.4402  data_time: 0.0096  memory: 5145  grad_norm: 21.9856  loss: 4.0517  decode.loss_cls: 0.0033  decode.loss_mask: 0.1633  decode.loss_dice: 0.1582  decode.d0.loss_cls: 0.8230  decode.d0.loss_mask: 0.1639  decode.d0.loss_dice: 0.1515  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.1624  decode.d1.loss_dice: 0.1569  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.1623  decode.d2.loss_dice: 0.1535  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.1625  decode.d3.loss_dice: 0.1554  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.1634  decode.d4.loss_dice: 0.1591  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.1624  decode.d5.loss_dice: 0.1613  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.1620  decode.d6.loss_dice: 0.1589  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.1609  decode.d7.loss_dice: 0.1606  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.1627  decode.d8.loss_dice: 0.1585
10/01 00:39:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:39:19 - mmengine - INFO - Iter(train) [128000/320000]  base_lr: 6.3145e-05 lr: 6.3145e-06  eta: 23:20:53  time: 0.4398  data_time: 0.0096  memory: 5129  grad_norm: 83.2259  loss: 5.4217  decode.loss_cls: 0.0045  decode.loss_mask: 0.2053  decode.loss_dice: 0.1903  decode.d0.loss_cls: 0.9322  decode.d0.loss_mask: 0.2079  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.0977  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.2029  decode.d2.loss_cls: 0.0362  decode.d2.loss_mask: 0.2036  decode.d2.loss_dice: 0.1999  decode.d3.loss_cls: 0.1053  decode.d3.loss_mask: 0.2045  decode.d3.loss_dice: 0.1945  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.1984  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.2028  decode.d5.loss_dice: 0.2008  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.2011  decode.d6.loss_dice: 0.2009  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.2056  decode.d7.loss_dice: 0.2032  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.2042  decode.d8.loss_dice: 0.1925
10/01 00:39:41 - mmengine - INFO - Iter(train) [128050/320000]  base_lr: 6.3130e-05 lr: 6.3130e-06  eta: 23:20:31  time: 0.4391  data_time: 0.0095  memory: 5145  grad_norm: 58.6678  loss: 5.2603  decode.loss_cls: 0.0276  decode.loss_mask: 0.2184  decode.loss_dice: 0.2102  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 0.2237  decode.d0.loss_dice: 0.2206  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 0.2184  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.2177  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.2197  decode.d3.loss_dice: 0.2104  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.2210  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.2177  decode.d5.loss_dice: 0.2144  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.2132  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.2206  decode.d7.loss_dice: 0.2087  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.2152
10/01 00:40:03 - mmengine - INFO - Iter(train) [128100/320000]  base_lr: 6.3115e-05 lr: 6.3115e-06  eta: 23:20:10  time: 0.4407  data_time: 0.0097  memory: 5129  grad_norm: 55.2213  loss: 5.9477  decode.loss_cls: 0.1333  decode.loss_mask: 0.1995  decode.loss_dice: 0.1837  decode.d0.loss_cls: 0.8822  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.2215  decode.d1.loss_cls: 0.1100  decode.d1.loss_mask: 0.2013  decode.d1.loss_dice: 0.2127  decode.d2.loss_cls: 0.1172  decode.d2.loss_mask: 0.2033  decode.d2.loss_dice: 0.1977  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.2120  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.2042  decode.d4.loss_dice: 0.2074  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.2026  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.2471  decode.d7.loss_cls: 0.1493  decode.d7.loss_mask: 0.1982  decode.d7.loss_dice: 0.1889  decode.d8.loss_cls: 0.1322  decode.d8.loss_mask: 0.2023  decode.d8.loss_dice: 0.2162
10/01 00:40:25 - mmengine - INFO - Iter(train) [128150/320000]  base_lr: 6.3100e-05 lr: 6.3100e-06  eta: 23:19:48  time: 0.4421  data_time: 0.0097  memory: 5145  grad_norm: 30.2206  loss: 4.6401  decode.loss_cls: 0.0334  decode.loss_mask: 0.1789  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.7892  decode.d0.loss_mask: 0.1811  decode.d0.loss_dice: 0.1711  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.1811  decode.d1.loss_dice: 0.1592  decode.d2.loss_cls: 0.0401  decode.d2.loss_mask: 0.1813  decode.d2.loss_dice: 0.1580  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.1781  decode.d3.loss_dice: 0.1607  decode.d4.loss_cls: 0.0455  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.1584  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.1783  decode.d5.loss_dice: 0.1544  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.1807  decode.d6.loss_dice: 0.1709  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.1804  decode.d7.loss_dice: 0.1769  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.1801  decode.d8.loss_dice: 0.1841
10/01 00:40:47 - mmengine - INFO - Iter(train) [128200/320000]  base_lr: 6.3086e-05 lr: 6.3086e-06  eta: 23:19:26  time: 0.4403  data_time: 0.0098  memory: 5120  grad_norm: 70.3698  loss: 5.4026  decode.loss_cls: 0.0251  decode.loss_mask: 0.2376  decode.loss_dice: 0.1719  decode.d0.loss_cls: 0.8805  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.1894  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.2404  decode.d1.loss_dice: 0.1861  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.1818  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.2400  decode.d3.loss_dice: 0.1808  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.1784  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.2406  decode.d5.loss_dice: 0.1804  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.1773  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.2396  decode.d7.loss_dice: 0.1769  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.1761
10/01 00:41:09 - mmengine - INFO - Iter(train) [128250/320000]  base_lr: 6.3071e-05 lr: 6.3071e-06  eta: 23:19:05  time: 0.4408  data_time: 0.0096  memory: 5129  grad_norm: 150.3053  loss: 6.4530  decode.loss_cls: 0.0594  decode.loss_mask: 0.2350  decode.loss_dice: 0.2388  decode.d0.loss_cls: 0.9409  decode.d0.loss_mask: 0.2388  decode.d0.loss_dice: 0.2836  decode.d1.loss_cls: 0.0974  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.2397  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 0.2397  decode.d2.loss_dice: 0.2299  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.2394  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.2729  decode.d6.loss_cls: 0.0468  decode.d6.loss_mask: 0.2392  decode.d6.loss_dice: 0.2465  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2337  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.2392  decode.d8.loss_dice: 0.2761
10/01 00:41:32 - mmengine - INFO - Iter(train) [128300/320000]  base_lr: 6.3056e-05 lr: 6.3056e-06  eta: 23:18:43  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 24.2907  loss: 4.5211  decode.loss_cls: 0.0027  decode.loss_mask: 0.2173  decode.loss_dice: 0.1590  decode.d0.loss_cls: 0.7614  decode.d0.loss_mask: 0.2169  decode.d0.loss_dice: 0.1545  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.2182  decode.d1.loss_dice: 0.1593  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.1552  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2163  decode.d3.loss_dice: 0.1539  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.1582  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.2155  decode.d5.loss_dice: 0.1562  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.2154  decode.d6.loss_dice: 0.1548  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2179  decode.d7.loss_dice: 0.1561  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.2165  decode.d8.loss_dice: 0.1578
10/01 00:41:54 - mmengine - INFO - Iter(train) [128350/320000]  base_lr: 6.3041e-05 lr: 6.3041e-06  eta: 23:18:21  time: 0.4409  data_time: 0.0094  memory: 5129  grad_norm: 117.6752  loss: 5.5448  decode.loss_cls: 0.0540  decode.loss_mask: 0.2793  decode.loss_dice: 0.2080  decode.d0.loss_cls: 0.9612  decode.d0.loss_mask: 0.1757  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.2220  decode.d1.loss_dice: 0.1719  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.1808  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.2351  decode.d3.loss_dice: 0.1846  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.2408  decode.d4.loss_dice: 0.1862  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.2372  decode.d5.loss_dice: 0.1787  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.1771  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.1814  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.2298  decode.d8.loss_dice: 0.1888
10/01 00:42:16 - mmengine - INFO - Iter(train) [128400/320000]  base_lr: 6.3026e-05 lr: 6.3026e-06  eta: 23:18:00  time: 0.4405  data_time: 0.0097  memory: 5129  grad_norm: 102.3093  loss: 6.7353  decode.loss_cls: 0.1528  decode.loss_mask: 0.2304  decode.loss_dice: 0.2542  decode.d0.loss_cls: 0.8753  decode.d0.loss_mask: 0.2289  decode.d0.loss_dice: 0.2336  decode.d1.loss_cls: 0.1216  decode.d1.loss_mask: 0.2280  decode.d1.loss_dice: 0.2372  decode.d2.loss_cls: 0.1431  decode.d2.loss_mask: 0.2255  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.1581  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.2499  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 0.2283  decode.d6.loss_dice: 0.2615  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 0.2271  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.1042  decode.d8.loss_mask: 0.2252  decode.d8.loss_dice: 0.2501
10/01 00:42:38 - mmengine - INFO - Iter(train) [128450/320000]  base_lr: 6.3012e-05 lr: 6.3012e-06  eta: 23:17:38  time: 0.4400  data_time: 0.0094  memory: 5129  grad_norm: 27.1278  loss: 4.2445  decode.loss_cls: 0.0442  decode.loss_mask: 0.1488  decode.loss_dice: 0.1440  decode.d0.loss_cls: 0.8296  decode.d0.loss_mask: 0.1516  decode.d0.loss_dice: 0.1586  decode.d1.loss_cls: 0.0605  decode.d1.loss_mask: 0.1478  decode.d1.loss_dice: 0.1540  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.1478  decode.d2.loss_dice: 0.1576  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.1484  decode.d3.loss_dice: 0.1534  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.1486  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.1491  decode.d5.loss_dice: 0.1574  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.1485  decode.d6.loss_dice: 0.1510  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.1479  decode.d7.loss_dice: 0.1505  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.1497  decode.d8.loss_dice: 0.1540
10/01 00:43:00 - mmengine - INFO - Iter(train) [128500/320000]  base_lr: 6.2997e-05 lr: 6.2997e-06  eta: 23:17:16  time: 0.4401  data_time: 0.0096  memory: 5129  grad_norm: 51.3141  loss: 6.6516  decode.loss_cls: 0.1818  decode.loss_mask: 0.2140  decode.loss_dice: 0.2175  decode.d0.loss_cls: 0.8132  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.2282  decode.d1.loss_cls: 0.1367  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.2073  decode.d2.loss_cls: 0.1966  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.2076  decode.d3.loss_cls: 0.1849  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.1929  decode.d4.loss_cls: 0.1916  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.1208  decode.d5.loss_mask: 0.2413  decode.d5.loss_dice: 0.2422  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2201  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 0.2485  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.1625  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.1881
10/01 00:43:22 - mmengine - INFO - Iter(train) [128550/320000]  base_lr: 6.2982e-05 lr: 6.2982e-06  eta: 23:16:54  time: 0.4396  data_time: 0.0095  memory: 5145  grad_norm: 37.2370  loss: 4.2665  decode.loss_cls: 0.0047  decode.loss_mask: 0.1745  decode.loss_dice: 0.1596  decode.d0.loss_cls: 0.8063  decode.d0.loss_mask: 0.1733  decode.d0.loss_dice: 0.1647  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.1731  decode.d1.loss_dice: 0.1664  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.1741  decode.d2.loss_dice: 0.1629  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 0.1752  decode.d3.loss_dice: 0.1499  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.1747  decode.d4.loss_dice: 0.1584  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.1752  decode.d5.loss_dice: 0.1585  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1757  decode.d6.loss_dice: 0.1622  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.1749  decode.d7.loss_dice: 0.1642  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.1717  decode.d8.loss_dice: 0.1552
10/01 00:43:44 - mmengine - INFO - Iter(train) [128600/320000]  base_lr: 6.2967e-05 lr: 6.2967e-06  eta: 23:16:33  time: 0.4399  data_time: 0.0098  memory: 5129  grad_norm: 129.0867  loss: 9.6430  decode.loss_cls: 0.3339  decode.loss_mask: 0.2818  decode.loss_dice: 0.2848  decode.d0.loss_cls: 1.1478  decode.d0.loss_mask: 0.2803  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.3298  decode.d1.loss_mask: 0.2900  decode.d1.loss_dice: 0.2891  decode.d2.loss_cls: 0.3151  decode.d2.loss_mask: 0.2956  decode.d2.loss_dice: 0.2645  decode.d3.loss_cls: 0.3284  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.3362  decode.d4.loss_mask: 0.2919  decode.d4.loss_dice: 0.2974  decode.d5.loss_cls: 0.3521  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.2368  decode.d6.loss_cls: 0.3389  decode.d6.loss_mask: 0.2790  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.3407  decode.d7.loss_mask: 0.2797  decode.d7.loss_dice: 0.2747  decode.d8.loss_cls: 0.3137  decode.d8.loss_mask: 0.2720  decode.d8.loss_dice: 0.2762
10/01 00:44:06 - mmengine - INFO - Iter(train) [128650/320000]  base_lr: 6.2952e-05 lr: 6.2952e-06  eta: 23:16:11  time: 0.4405  data_time: 0.0096  memory: 5145  grad_norm: 28.0315  loss: 4.1846  decode.loss_cls: 0.0074  decode.loss_mask: 0.1775  decode.loss_dice: 0.1513  decode.d0.loss_cls: 0.8155  decode.d0.loss_mask: 0.1808  decode.d0.loss_dice: 0.1481  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.1782  decode.d1.loss_dice: 0.1505  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.1759  decode.d2.loss_dice: 0.1498  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.1787  decode.d3.loss_dice: 0.1532  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.1790  decode.d4.loss_dice: 0.1533  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.1772  decode.d5.loss_dice: 0.1551  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.1771  decode.d6.loss_dice: 0.1542  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.1772  decode.d7.loss_dice: 0.1583  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.1770  decode.d8.loss_dice: 0.1537
10/01 00:44:28 - mmengine - INFO - Iter(train) [128700/320000]  base_lr: 6.2938e-05 lr: 6.2938e-06  eta: 23:15:49  time: 0.4397  data_time: 0.0096  memory: 5129  grad_norm: 32.4410  loss: 4.2348  decode.loss_cls: 0.0072  decode.loss_mask: 0.1780  decode.loss_dice: 0.1463  decode.d0.loss_cls: 0.7688  decode.d0.loss_mask: 0.1777  decode.d0.loss_dice: 0.1397  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.1755  decode.d1.loss_dice: 0.1421  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.1759  decode.d2.loss_dice: 0.1455  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.1771  decode.d3.loss_dice: 0.1410  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.1771  decode.d4.loss_dice: 0.1465  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.1771  decode.d5.loss_dice: 0.1428  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.1783  decode.d6.loss_dice: 0.1424  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.1762  decode.d7.loss_dice: 0.1454  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.1763  decode.d8.loss_dice: 0.1445
10/01 00:44:50 - mmengine - INFO - Iter(train) [128750/320000]  base_lr: 6.2923e-05 lr: 6.2923e-06  eta: 23:15:28  time: 0.4411  data_time: 0.0097  memory: 5145  grad_norm: 42.4685  loss: 5.4450  decode.loss_cls: 0.0118  decode.loss_mask: 0.2477  decode.loss_dice: 0.1983  decode.d0.loss_cls: 0.8216  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2063  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.2523  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2031  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.2146  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2561  decode.d4.loss_dice: 0.2197  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.2559  decode.d5.loss_dice: 0.2033  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.2520  decode.d6.loss_dice: 0.2010  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.1984  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2517  decode.d8.loss_dice: 0.2122
10/01 00:45:12 - mmengine - INFO - Iter(train) [128800/320000]  base_lr: 6.2908e-05 lr: 6.2908e-06  eta: 23:15:06  time: 0.4397  data_time: 0.0096  memory: 5129  grad_norm: 102.4787  loss: 6.8664  decode.loss_cls: 0.1268  decode.loss_mask: 0.2309  decode.loss_dice: 0.2303  decode.d0.loss_cls: 0.9820  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2541  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.2776  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.2181  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.2229  decode.d5.loss_cls: 0.1186  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.2293  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.2507  decode.d7.loss_cls: 0.1320  decode.d7.loss_mask: 0.2329  decode.d7.loss_dice: 0.2214  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2186
10/01 00:45:34 - mmengine - INFO - Iter(train) [128850/320000]  base_lr: 6.2893e-05 lr: 6.2893e-06  eta: 23:14:44  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 72.5873  loss: 5.2039  decode.loss_cls: 0.0649  decode.loss_mask: 0.1957  decode.loss_dice: 0.1684  decode.d0.loss_cls: 0.7191  decode.d0.loss_mask: 0.1964  decode.d0.loss_dice: 0.1943  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.1942  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.1929  decode.d2.loss_dice: 0.1677  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.1738  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.1932  decode.d4.loss_dice: 0.1705  decode.d5.loss_cls: 0.1472  decode.d5.loss_mask: 0.1947  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.1935  decode.d6.loss_dice: 0.1677  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.1926  decode.d7.loss_dice: 0.1720  decode.d8.loss_cls: 0.0875  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.1732
10/01 00:45:56 - mmengine - INFO - Iter(train) [128900/320000]  base_lr: 6.2878e-05 lr: 6.2878e-06  eta: 23:14:22  time: 0.4398  data_time: 0.0095  memory: 5145  grad_norm: 29.1874  loss: 4.0064  decode.loss_cls: 0.0172  decode.loss_mask: 0.1465  decode.loss_dice: 0.1570  decode.d0.loss_cls: 0.9004  decode.d0.loss_mask: 0.1458  decode.d0.loss_dice: 0.1452  decode.d1.loss_cls: 0.0403  decode.d1.loss_mask: 0.1446  decode.d1.loss_dice: 0.1466  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.1471  decode.d2.loss_dice: 0.1531  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.1472  decode.d3.loss_dice: 0.1452  decode.d4.loss_cls: 0.0112  decode.d4.loss_mask: 0.1477  decode.d4.loss_dice: 0.1447  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.1447  decode.d5.loss_dice: 0.1398  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.1473  decode.d6.loss_dice: 0.1577  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.1460  decode.d7.loss_dice: 0.1461  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.1482  decode.d8.loss_dice: 0.1520
10/01 00:46:18 - mmengine - INFO - Iter(train) [128950/320000]  base_lr: 6.2864e-05 lr: 6.2864e-06  eta: 23:14:01  time: 0.4396  data_time: 0.0096  memory: 5145  grad_norm: 73.5138  loss: 5.6621  decode.loss_cls: 0.0265  decode.loss_mask: 0.2567  decode.loss_dice: 0.1888  decode.d0.loss_cls: 0.8849  decode.d0.loss_mask: 0.2625  decode.d0.loss_dice: 0.1788  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.2639  decode.d1.loss_dice: 0.2002  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.2085  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.2546  decode.d3.loss_dice: 0.2016  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.2571  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.2570  decode.d5.loss_dice: 0.2044  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.2584  decode.d6.loss_dice: 0.1944  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.2092  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.2635  decode.d8.loss_dice: 0.2020
10/01 00:46:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:46:40 - mmengine - INFO - Iter(train) [129000/320000]  base_lr: 6.2849e-05 lr: 6.2849e-06  eta: 23:13:39  time: 0.4392  data_time: 0.0095  memory: 5129  grad_norm: 23.0013  loss: 4.2165  decode.loss_cls: 0.0009  decode.loss_mask: 0.1899  decode.loss_dice: 0.1579  decode.d0.loss_cls: 0.7174  decode.d0.loss_mask: 0.1932  decode.d0.loss_dice: 0.1654  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.1916  decode.d1.loss_dice: 0.1583  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.1605  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.1895  decode.d3.loss_dice: 0.1593  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.1880  decode.d4.loss_dice: 0.1612  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.1564  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.1902  decode.d6.loss_dice: 0.1592  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.1873  decode.d7.loss_dice: 0.1545  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1879  decode.d8.loss_dice: 0.1570
10/01 00:47:02 - mmengine - INFO - Iter(train) [129050/320000]  base_lr: 6.2834e-05 lr: 6.2834e-06  eta: 23:13:17  time: 0.4396  data_time: 0.0097  memory: 5145  grad_norm: 49.6859  loss: 4.7798  decode.loss_cls: 0.0491  decode.loss_mask: 0.2144  decode.loss_dice: 0.1334  decode.d0.loss_cls: 0.8787  decode.d0.loss_mask: 0.2156  decode.d0.loss_dice: 0.1348  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.2115  decode.d1.loss_dice: 0.1308  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.1312  decode.d3.loss_cls: 0.0503  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.1340  decode.d4.loss_cls: 0.0391  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.1330  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.1392  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.2077  decode.d6.loss_dice: 0.1359  decode.d7.loss_cls: 0.0398  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.1315  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.1334
10/01 00:47:24 - mmengine - INFO - Iter(train) [129100/320000]  base_lr: 6.2819e-05 lr: 6.2819e-06  eta: 23:12:55  time: 0.4396  data_time: 0.0094  memory: 5129  grad_norm: 27.2314  loss: 4.4870  decode.loss_cls: 0.0427  decode.loss_mask: 0.1541  decode.loss_dice: 0.1249  decode.d0.loss_cls: 0.8025  decode.d0.loss_mask: 0.1555  decode.d0.loss_dice: 0.1682  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.1532  decode.d1.loss_dice: 0.1573  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.1510  decode.d2.loss_dice: 0.1693  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.1514  decode.d3.loss_dice: 0.1740  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.1511  decode.d4.loss_dice: 0.1707  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.1546  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.1532  decode.d6.loss_dice: 0.1869  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.1524  decode.d7.loss_dice: 0.1744  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.1545  decode.d8.loss_dice: 0.1652
10/01 00:47:46 - mmengine - INFO - Iter(train) [129150/320000]  base_lr: 6.2804e-05 lr: 6.2804e-06  eta: 23:12:34  time: 0.4384  data_time: 0.0095  memory: 5129  grad_norm: 52.3276  loss: 5.0690  decode.loss_cls: 0.0356  decode.loss_mask: 0.2208  decode.loss_dice: 0.1558  decode.d0.loss_cls: 0.8645  decode.d0.loss_mask: 0.2232  decode.d0.loss_dice: 0.1608  decode.d1.loss_cls: 0.0409  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.1599  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.1577  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.1651  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 0.2256  decode.d4.loss_dice: 0.1575  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.2259  decode.d5.loss_dice: 0.1619  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.2207  decode.d6.loss_dice: 0.1555  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.2318  decode.d7.loss_dice: 0.1611  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.2378  decode.d8.loss_dice: 0.1665
10/01 00:48:08 - mmengine - INFO - Iter(train) [129200/320000]  base_lr: 6.2789e-05 lr: 6.2789e-06  eta: 23:12:12  time: 0.4398  data_time: 0.0096  memory: 5145  grad_norm: 44.5466  loss: 4.8729  decode.loss_cls: 0.0597  decode.loss_mask: 0.1930  decode.loss_dice: 0.1434  decode.d0.loss_cls: 0.8599  decode.d0.loss_mask: 0.1963  decode.d0.loss_dice: 0.1470  decode.d1.loss_cls: 0.0950  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.1485  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.1924  decode.d2.loss_dice: 0.1485  decode.d3.loss_cls: 0.0784  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.1392  decode.d4.loss_cls: 0.0484  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.1469  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.1918  decode.d5.loss_dice: 0.1460  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.1931  decode.d6.loss_dice: 0.1405  decode.d7.loss_cls: 0.0657  decode.d7.loss_mask: 0.2165  decode.d7.loss_dice: 0.1574  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.1429
10/01 00:48:30 - mmengine - INFO - Iter(train) [129250/320000]  base_lr: 6.2775e-05 lr: 6.2775e-06  eta: 23:11:50  time: 0.4389  data_time: 0.0094  memory: 5129  grad_norm: 68.4415  loss: 4.7424  decode.loss_cls: 0.0131  decode.loss_mask: 0.1988  decode.loss_dice: 0.1762  decode.d0.loss_cls: 0.8430  decode.d0.loss_mask: 0.2025  decode.d0.loss_dice: 0.1868  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.2021  decode.d1.loss_dice: 0.1795  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.1789  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.2036  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.1727  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.1804  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.2043  decode.d6.loss_dice: 0.1867  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1730  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.1981  decode.d8.loss_dice: 0.1721
10/01 00:48:52 - mmengine - INFO - Iter(train) [129300/320000]  base_lr: 6.2760e-05 lr: 6.2760e-06  eta: 23:11:29  time: 0.4397  data_time: 0.0096  memory: 5129  grad_norm: 214.3673  loss: 5.7273  decode.loss_cls: 0.0776  decode.loss_mask: 0.2259  decode.loss_dice: 0.2303  decode.d0.loss_cls: 0.8241  decode.d0.loss_mask: 0.2254  decode.d0.loss_dice: 0.2008  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.2214  decode.d1.loss_dice: 0.1900  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.2265  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.2288  decode.d3.loss_dice: 0.2138  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2142  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.2258  decode.d5.loss_dice: 0.2125  decode.d6.loss_cls: 0.0408  decode.d6.loss_mask: 0.2248  decode.d6.loss_dice: 0.2138  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.2262  decode.d7.loss_dice: 0.2136  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.2286
10/01 00:49:14 - mmengine - INFO - Iter(train) [129350/320000]  base_lr: 6.2745e-05 lr: 6.2745e-06  eta: 23:11:07  time: 0.4387  data_time: 0.0096  memory: 5145  grad_norm: 38.8842  loss: 5.6906  decode.loss_cls: 0.0135  decode.loss_mask: 0.2768  decode.loss_dice: 0.1974  decode.d0.loss_cls: 0.7916  decode.d0.loss_mask: 0.2833  decode.d0.loss_dice: 0.1870  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.2063  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.1968  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2854  decode.d3.loss_dice: 0.1992  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.2801  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2813  decode.d5.loss_dice: 0.2044  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.2792  decode.d6.loss_dice: 0.1936  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.2813  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.2819  decode.d8.loss_dice: 0.1979
10/01 00:49:36 - mmengine - INFO - Iter(train) [129400/320000]  base_lr: 6.2730e-05 lr: 6.2730e-06  eta: 23:10:45  time: 0.4391  data_time: 0.0095  memory: 5120  grad_norm: 22.8067  loss: 4.2584  decode.loss_cls: 0.0077  decode.loss_mask: 0.1975  decode.loss_dice: 0.1551  decode.d0.loss_cls: 0.6474  decode.d0.loss_mask: 0.2010  decode.d0.loss_dice: 0.1519  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.1999  decode.d1.loss_dice: 0.1577  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.1988  decode.d2.loss_dice: 0.1569  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.1964  decode.d3.loss_dice: 0.1530  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.1986  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.1970  decode.d5.loss_dice: 0.1559  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.1978  decode.d6.loss_dice: 0.1520  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.1995  decode.d7.loss_dice: 0.1613  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.1987  decode.d8.loss_dice: 0.1574
10/01 00:49:58 - mmengine - INFO - Iter(train) [129450/320000]  base_lr: 6.2715e-05 lr: 6.2715e-06  eta: 23:10:23  time: 0.4385  data_time: 0.0091  memory: 5120  grad_norm: 25.7164  loss: 4.8313  decode.loss_cls: 0.0355  decode.loss_mask: 0.1778  decode.loss_dice: 0.2021  decode.d0.loss_cls: 0.8492  decode.d0.loss_mask: 0.1778  decode.d0.loss_dice: 0.1980  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.1772  decode.d1.loss_dice: 0.1876  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.1779  decode.d2.loss_dice: 0.1959  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.1778  decode.d3.loss_dice: 0.1944  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0307  decode.d5.loss_mask: 0.1762  decode.d5.loss_dice: 0.1548  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.1771  decode.d6.loss_dice: 0.1894  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.1752  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.1769  decode.d8.loss_dice: 0.1940
10/01 00:50:20 - mmengine - INFO - Iter(train) [129500/320000]  base_lr: 6.2701e-05 lr: 6.2701e-06  eta: 23:10:01  time: 0.4391  data_time: 0.0094  memory: 5129  grad_norm: 41.0567  loss: 5.5638  decode.loss_cls: 0.0390  decode.loss_mask: 0.2222  decode.loss_dice: 0.1875  decode.d0.loss_cls: 0.9102  decode.d0.loss_mask: 0.2267  decode.d0.loss_dice: 0.1762  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.2223  decode.d1.loss_dice: 0.1866  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.1831  decode.d3.loss_cls: 0.1311  decode.d3.loss_mask: 0.2207  decode.d3.loss_dice: 0.1774  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.2216  decode.d4.loss_dice: 0.1823  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.1839  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.2222  decode.d6.loss_dice: 0.1813  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.1808  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.1848
10/01 00:50:42 - mmengine - INFO - Iter(train) [129550/320000]  base_lr: 6.2686e-05 lr: 6.2686e-06  eta: 23:09:40  time: 0.4397  data_time: 0.0097  memory: 5129  grad_norm: 27.3927  loss: 4.5364  decode.loss_cls: 0.0135  decode.loss_mask: 0.1895  decode.loss_dice: 0.1548  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.1938  decode.d0.loss_dice: 0.1477  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.1899  decode.d1.loss_dice: 0.1517  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.1921  decode.d2.loss_dice: 0.1530  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.1917  decode.d3.loss_dice: 0.1529  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.1905  decode.d4.loss_dice: 0.1541  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.1919  decode.d5.loss_dice: 0.1541  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.1895  decode.d6.loss_dice: 0.1526  decode.d7.loss_cls: 0.0199  decode.d7.loss_mask: 0.1922  decode.d7.loss_dice: 0.1562  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.1906  decode.d8.loss_dice: 0.1576
10/01 00:51:04 - mmengine - INFO - Iter(train) [129600/320000]  base_lr: 6.2671e-05 lr: 6.2671e-06  eta: 23:09:18  time: 0.4411  data_time: 0.0097  memory: 5129  grad_norm: 29.9019  loss: 5.5696  decode.loss_cls: 0.1325  decode.loss_mask: 0.2084  decode.loss_dice: 0.1688  decode.d0.loss_cls: 0.7787  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.1800  decode.d1.loss_cls: 0.1143  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.1580  decode.d2.loss_cls: 0.1247  decode.d2.loss_mask: 0.2112  decode.d2.loss_dice: 0.1449  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 0.2118  decode.d3.loss_dice: 0.1660  decode.d4.loss_cls: 0.1094  decode.d4.loss_mask: 0.2095  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0848  decode.d5.loss_mask: 0.2106  decode.d5.loss_dice: 0.1719  decode.d6.loss_cls: 0.1273  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.1709  decode.d7.loss_cls: 0.1303  decode.d7.loss_mask: 0.2134  decode.d7.loss_dice: 0.1464  decode.d8.loss_cls: 0.1501  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1482
10/01 00:51:26 - mmengine - INFO - Iter(train) [129650/320000]  base_lr: 6.2656e-05 lr: 6.2656e-06  eta: 23:08:56  time: 0.4397  data_time: 0.0096  memory: 5146  grad_norm: 120.9222  loss: 4.5547  decode.loss_cls: 0.0464  decode.loss_mask: 0.1838  decode.loss_dice: 0.1306  decode.d0.loss_cls: 0.8721  decode.d0.loss_mask: 0.1895  decode.d0.loss_dice: 0.1321  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.1879  decode.d1.loss_dice: 0.1338  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.1815  decode.d2.loss_dice: 0.1304  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.1855  decode.d3.loss_dice: 0.1294  decode.d4.loss_cls: 0.0566  decode.d4.loss_mask: 0.1871  decode.d4.loss_dice: 0.1331  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.1341  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.1856  decode.d6.loss_dice: 0.1309  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.1366  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.1827  decode.d8.loss_dice: 0.1341
10/01 00:51:48 - mmengine - INFO - Iter(train) [129700/320000]  base_lr: 6.2641e-05 lr: 6.2641e-06  eta: 23:08:34  time: 0.4413  data_time: 0.0096  memory: 5129  grad_norm: 58.9705  loss: 4.6764  decode.loss_cls: 0.0690  decode.loss_mask: 0.1539  decode.loss_dice: 0.1722  decode.d0.loss_cls: 0.8340  decode.d0.loss_mask: 0.1555  decode.d0.loss_dice: 0.1642  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.1536  decode.d1.loss_dice: 0.1552  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.1541  decode.d2.loss_dice: 0.1750  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.1532  decode.d3.loss_dice: 0.1697  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.1510  decode.d4.loss_dice: 0.1585  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.1546  decode.d5.loss_dice: 0.1663  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.1528  decode.d6.loss_dice: 0.1699  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.1537  decode.d7.loss_dice: 0.1744  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.1533  decode.d8.loss_dice: 0.1699
10/01 00:52:10 - mmengine - INFO - Iter(train) [129750/320000]  base_lr: 6.2627e-05 lr: 6.2627e-06  eta: 23:08:13  time: 0.4388  data_time: 0.0095  memory: 5145  grad_norm: 40.9633  loss: 5.6253  decode.loss_cls: 0.0799  decode.loss_mask: 0.2463  decode.loss_dice: 0.1665  decode.d0.loss_cls: 0.8340  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.1612  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.1667  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.1645  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.1601  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.2494  decode.d4.loss_dice: 0.1689  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.1636  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.2482  decode.d6.loss_dice: 0.1644  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.2492  decode.d7.loss_dice: 0.1706  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.2434  decode.d8.loss_dice: 0.1630
10/01 00:52:32 - mmengine - INFO - Iter(train) [129800/320000]  base_lr: 6.2612e-05 lr: 6.2612e-06  eta: 23:07:51  time: 0.4418  data_time: 0.0097  memory: 5145  grad_norm: 43.4822  loss: 5.7188  decode.loss_cls: 0.0535  decode.loss_mask: 0.2002  decode.loss_dice: 0.2124  decode.d0.loss_cls: 0.9506  decode.d0.loss_mask: 0.2026  decode.d0.loss_dice: 0.1758  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.1978  decode.d1.loss_dice: 0.2128  decode.d2.loss_cls: 0.1382  decode.d2.loss_mask: 0.1981  decode.d2.loss_dice: 0.1848  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.1984  decode.d3.loss_dice: 0.1937  decode.d4.loss_cls: 0.0884  decode.d4.loss_mask: 0.2018  decode.d4.loss_dice: 0.2166  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2102  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.1973  decode.d6.loss_dice: 0.2288  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 0.1984  decode.d7.loss_dice: 0.2083  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.2006  decode.d8.loss_dice: 0.2188
10/01 00:52:54 - mmengine - INFO - Iter(train) [129850/320000]  base_lr: 6.2597e-05 lr: 6.2597e-06  eta: 23:07:29  time: 0.4395  data_time: 0.0098  memory: 5120  grad_norm: 65.5918  loss: 5.9936  decode.loss_cls: 0.0226  decode.loss_mask: 0.2739  decode.loss_dice: 0.2071  decode.d0.loss_cls: 0.8734  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.2092  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.2781  decode.d1.loss_dice: 0.2112  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.2139  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.2134  decode.d4.loss_cls: 0.0256  decode.d4.loss_mask: 0.2815  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2783  decode.d5.loss_dice: 0.2145  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.2164  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.2780  decode.d7.loss_dice: 0.2166  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.2094
10/01 00:53:16 - mmengine - INFO - Iter(train) [129900/320000]  base_lr: 6.2582e-05 lr: 6.2582e-06  eta: 23:07:07  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 52.4668  loss: 6.2118  decode.loss_cls: 0.0881  decode.loss_mask: 0.2143  decode.loss_dice: 0.2376  decode.d0.loss_cls: 0.8574  decode.d0.loss_mask: 0.2156  decode.d0.loss_dice: 0.2402  decode.d1.loss_cls: 0.1424  decode.d1.loss_mask: 0.2143  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.1702  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.2176  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.2383  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2105  decode.d6.loss_dice: 0.2164  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.2084  decode.d7.loss_dice: 0.2224  decode.d8.loss_cls: 0.0502  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.2392
10/01 00:53:38 - mmengine - INFO - Iter(train) [129950/320000]  base_lr: 6.2567e-05 lr: 6.2567e-06  eta: 23:06:46  time: 0.4398  data_time: 0.0096  memory: 5129  grad_norm: 57.3542  loss: 4.4568  decode.loss_cls: 0.0454  decode.loss_mask: 0.1610  decode.loss_dice: 0.1713  decode.d0.loss_cls: 0.7896  decode.d0.loss_mask: 0.1649  decode.d0.loss_dice: 0.1679  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.1596  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.1604  decode.d2.loss_dice: 0.1745  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.1613  decode.d3.loss_dice: 0.1750  decode.d4.loss_cls: 0.0482  decode.d4.loss_mask: 0.1585  decode.d4.loss_dice: 0.1691  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.1624  decode.d5.loss_dice: 0.1714  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.1627  decode.d6.loss_dice: 0.1715  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.1623  decode.d7.loss_dice: 0.1693  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.1636  decode.d8.loss_dice: 0.1671
10/01 00:54:00 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 00:54:00 - mmengine - INFO - Iter(train) [130000/320000]  base_lr: 6.2552e-05 lr: 6.2552e-06  eta: 23:06:24  time: 0.4394  data_time: 0.0095  memory: 5145  grad_norm: 53.2302  loss: 4.2664  decode.loss_cls: 0.0063  decode.loss_mask: 0.1895  decode.loss_dice: 0.1696  decode.d0.loss_cls: 0.6954  decode.d0.loss_mask: 0.1990  decode.d0.loss_dice: 0.1683  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.1899  decode.d1.loss_dice: 0.1580  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.1585  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.1925  decode.d3.loss_dice: 0.1556  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.1896  decode.d4.loss_dice: 0.1640  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.1905  decode.d5.loss_dice: 0.1590  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1940  decode.d6.loss_dice: 0.1581  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.1514  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.1631
10/01 00:54:22 - mmengine - INFO - Iter(train) [130050/320000]  base_lr: 6.2538e-05 lr: 6.2538e-06  eta: 23:06:02  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 53.7660  loss: 4.3273  decode.loss_cls: 0.0219  decode.loss_mask: 0.1730  decode.loss_dice: 0.1587  decode.d0.loss_cls: 0.7892  decode.d0.loss_mask: 0.1732  decode.d0.loss_dice: 0.1552  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.1732  decode.d1.loss_dice: 0.1637  decode.d2.loss_cls: 0.0202  decode.d2.loss_mask: 0.1734  decode.d2.loss_dice: 0.1561  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.1776  decode.d3.loss_dice: 0.1615  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.1702  decode.d4.loss_dice: 0.1522  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.1734  decode.d5.loss_dice: 0.1584  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.1740  decode.d6.loss_dice: 0.1553  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.1731  decode.d8.loss_dice: 0.1574
10/01 00:54:44 - mmengine - INFO - Iter(train) [130100/320000]  base_lr: 6.2523e-05 lr: 6.2523e-06  eta: 23:05:41  time: 0.4397  data_time: 0.0097  memory: 5145  grad_norm: 37.0002  loss: 4.5946  decode.loss_cls: 0.0014  decode.loss_mask: 0.1893  decode.loss_dice: 0.1696  decode.d0.loss_cls: 0.8536  decode.d0.loss_mask: 0.1895  decode.d0.loss_dice: 0.1815  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.1927  decode.d1.loss_dice: 0.1792  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.1901  decode.d2.loss_dice: 0.1727  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.1908  decode.d3.loss_dice: 0.1712  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.1904  decode.d4.loss_dice: 0.1757  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.1699  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1921  decode.d6.loss_dice: 0.1817  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1920  decode.d7.loss_dice: 0.1710  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.1893  decode.d8.loss_dice: 0.1775
10/01 00:55:06 - mmengine - INFO - Iter(train) [130150/320000]  base_lr: 6.2508e-05 lr: 6.2508e-06  eta: 23:05:19  time: 0.4398  data_time: 0.0097  memory: 5129  grad_norm: 61.1844  loss: 5.9312  decode.loss_cls: 0.0407  decode.loss_mask: 0.2808  decode.loss_dice: 0.1890  decode.d0.loss_cls: 0.7134  decode.d0.loss_mask: 0.2878  decode.d0.loss_dice: 0.1806  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.1966  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.2774  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.0495  decode.d3.loss_mask: 0.2841  decode.d3.loss_dice: 0.1905  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.2817  decode.d4.loss_dice: 0.1916  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.1908  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.2824  decode.d6.loss_dice: 0.1972  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.2816  decode.d7.loss_dice: 0.1927  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.1839
10/01 00:55:28 - mmengine - INFO - Iter(train) [130200/320000]  base_lr: 6.2493e-05 lr: 6.2493e-06  eta: 23:04:57  time: 0.4401  data_time: 0.0096  memory: 5129  grad_norm: 49.9382  loss: 5.3796  decode.loss_cls: 0.0473  decode.loss_mask: 0.2130  decode.loss_dice: 0.1906  decode.d0.loss_cls: 0.9191  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0370  decode.d1.loss_mask: 0.2149  decode.d1.loss_dice: 0.1882  decode.d2.loss_cls: 0.0527  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1837  decode.d3.loss_cls: 0.0455  decode.d3.loss_mask: 0.2144  decode.d3.loss_dice: 0.1873  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.2163  decode.d4.loss_dice: 0.1879  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.2137  decode.d5.loss_dice: 0.1876  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.1864  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.1834  decode.d8.loss_cls: 0.0533  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.1836
10/01 00:55:50 - mmengine - INFO - Iter(train) [130250/320000]  base_lr: 6.2478e-05 lr: 6.2478e-06  eta: 23:04:36  time: 0.4391  data_time: 0.0098  memory: 5129  grad_norm: 80.8002  loss: 5.9646  decode.loss_cls: 0.1127  decode.loss_mask: 0.1900  decode.loss_dice: 0.2156  decode.d0.loss_cls: 0.9897  decode.d0.loss_mask: 0.1871  decode.d0.loss_dice: 0.2444  decode.d1.loss_cls: 0.1581  decode.d1.loss_mask: 0.1883  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.1094  decode.d2.loss_mask: 0.1894  decode.d2.loss_dice: 0.2248  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.1910  decode.d3.loss_dice: 0.2176  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.1852  decode.d4.loss_dice: 0.2197  decode.d5.loss_cls: 0.0893  decode.d5.loss_mask: 0.1861  decode.d5.loss_dice: 0.2149  decode.d6.loss_cls: 0.0944  decode.d6.loss_mask: 0.1867  decode.d6.loss_dice: 0.2295  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.1870  decode.d7.loss_dice: 0.2362  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.2195
10/01 00:56:12 - mmengine - INFO - Iter(train) [130300/320000]  base_lr: 6.2464e-05 lr: 6.2464e-06  eta: 23:04:14  time: 0.4398  data_time: 0.0097  memory: 5120  grad_norm: 45.3294  loss: 4.8655  decode.loss_cls: 0.0421  decode.loss_mask: 0.1739  decode.loss_dice: 0.1540  decode.d0.loss_cls: 0.9075  decode.d0.loss_mask: 0.1685  decode.d0.loss_dice: 0.1537  decode.d1.loss_cls: 0.1769  decode.d1.loss_mask: 0.1695  decode.d1.loss_dice: 0.1438  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.1749  decode.d2.loss_dice: 0.1552  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.1722  decode.d3.loss_dice: 0.1573  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.1713  decode.d4.loss_dice: 0.1645  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.1724  decode.d5.loss_dice: 0.1492  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.1722  decode.d6.loss_dice: 0.1542  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.1720  decode.d7.loss_dice: 0.1552  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.1719  decode.d8.loss_dice: 0.1559
10/01 00:56:34 - mmengine - INFO - Iter(train) [130350/320000]  base_lr: 6.2449e-05 lr: 6.2449e-06  eta: 23:03:52  time: 0.4392  data_time: 0.0095  memory: 5120  grad_norm: 51.1974  loss: 5.7113  decode.loss_cls: 0.0369  decode.loss_mask: 0.2213  decode.loss_dice: 0.2028  decode.d0.loss_cls: 0.8672  decode.d0.loss_mask: 0.2141  decode.d0.loss_dice: 0.2108  decode.d1.loss_cls: 0.1676  decode.d1.loss_mask: 0.2123  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.2072  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.0392  decode.d4.loss_mask: 0.2206  decode.d4.loss_dice: 0.2106  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.2094  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.2212  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2097  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.2172
10/01 00:56:56 - mmengine - INFO - Iter(train) [130400/320000]  base_lr: 6.2434e-05 lr: 6.2434e-06  eta: 23:03:30  time: 0.4388  data_time: 0.0096  memory: 5129  grad_norm: 23.1026  loss: 4.4239  decode.loss_cls: 0.0058  decode.loss_mask: 0.1959  decode.loss_dice: 0.1646  decode.d0.loss_cls: 0.7704  decode.d0.loss_mask: 0.1990  decode.d0.loss_dice: 0.1700  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.1950  decode.d1.loss_dice: 0.1641  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.1609  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.1964  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.1954  decode.d4.loss_dice: 0.1624  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.1643  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.1972  decode.d6.loss_dice: 0.1633  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.1981  decode.d8.loss_dice: 0.1651
10/01 00:57:18 - mmengine - INFO - Iter(train) [130450/320000]  base_lr: 6.2419e-05 lr: 6.2419e-06  eta: 23:03:09  time: 0.4393  data_time: 0.0092  memory: 5129  grad_norm: 67.1222  loss: 5.3484  decode.loss_cls: 0.0649  decode.loss_mask: 0.1727  decode.loss_dice: 0.2138  decode.d0.loss_cls: 0.9050  decode.d0.loss_mask: 0.1686  decode.d0.loss_dice: 0.1789  decode.d1.loss_cls: 0.1059  decode.d1.loss_mask: 0.1712  decode.d1.loss_dice: 0.1999  decode.d2.loss_cls: 0.0297  decode.d2.loss_mask: 0.1680  decode.d2.loss_dice: 0.1914  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.1709  decode.d3.loss_dice: 0.1920  decode.d4.loss_cls: 0.1361  decode.d4.loss_mask: 0.1714  decode.d4.loss_dice: 0.1889  decode.d5.loss_cls: 0.1164  decode.d5.loss_mask: 0.1710  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.0709  decode.d6.loss_mask: 0.1675  decode.d6.loss_dice: 0.1990  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.1701  decode.d7.loss_dice: 0.2189  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.1697  decode.d8.loss_dice: 0.1877
10/01 00:57:40 - mmengine - INFO - Iter(train) [130500/320000]  base_lr: 6.2404e-05 lr: 6.2404e-06  eta: 23:02:47  time: 0.4397  data_time: 0.0097  memory: 5129  grad_norm: 249.4748  loss: 8.3938  decode.loss_cls: 0.1445  decode.loss_mask: 0.2969  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.9950  decode.d0.loss_mask: 0.2999  decode.d0.loss_dice: 0.2257  decode.d1.loss_cls: 0.1910  decode.d1.loss_mask: 0.3283  decode.d1.loss_dice: 0.2487  decode.d2.loss_cls: 0.2627  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.2343  decode.d3.loss_cls: 0.2776  decode.d3.loss_mask: 0.3350  decode.d3.loss_dice: 0.2413  decode.d4.loss_cls: 0.2800  decode.d4.loss_mask: 0.2955  decode.d4.loss_dice: 0.2053  decode.d5.loss_cls: 0.2609  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.2018  decode.d6.loss_cls: 0.1521  decode.d6.loss_mask: 0.3348  decode.d6.loss_dice: 0.2830  decode.d7.loss_cls: 0.1350  decode.d7.loss_mask: 0.3071  decode.d7.loss_dice: 0.2474  decode.d8.loss_cls: 0.1575  decode.d8.loss_mask: 0.3102  decode.d8.loss_dice: 0.2640
10/01 00:58:02 - mmengine - INFO - Iter(train) [130550/320000]  base_lr: 6.2389e-05 lr: 6.2389e-06  eta: 23:02:25  time: 0.4406  data_time: 0.0095  memory: 5129  grad_norm: 69.9291  loss: 5.9301  decode.loss_cls: 0.0915  decode.loss_mask: 0.1903  decode.loss_dice: 0.2496  decode.d0.loss_cls: 0.9956  decode.d0.loss_mask: 0.1952  decode.d0.loss_dice: 0.2136  decode.d1.loss_cls: 0.0535  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.1953  decode.d2.loss_dice: 0.2371  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.1884  decode.d3.loss_dice: 0.2303  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.1922  decode.d4.loss_dice: 0.2427  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.1907  decode.d5.loss_dice: 0.2409  decode.d6.loss_cls: 0.0903  decode.d6.loss_mask: 0.1904  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0920  decode.d7.loss_mask: 0.1923  decode.d7.loss_dice: 0.2235  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.1919  decode.d8.loss_dice: 0.2380
10/01 00:58:24 - mmengine - INFO - Iter(train) [130600/320000]  base_lr: 6.2375e-05 lr: 6.2375e-06  eta: 23:02:03  time: 0.4395  data_time: 0.0096  memory: 5129  grad_norm: 33.7292  loss: 5.3242  decode.loss_cls: 0.0936  decode.loss_mask: 0.1862  decode.loss_dice: 0.2095  decode.d0.loss_cls: 0.8249  decode.d0.loss_mask: 0.1894  decode.d0.loss_dice: 0.1811  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.1847  decode.d1.loss_dice: 0.1854  decode.d2.loss_cls: 0.1157  decode.d2.loss_mask: 0.1849  decode.d2.loss_dice: 0.1845  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.1885  decode.d3.loss_dice: 0.2068  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.1858  decode.d4.loss_dice: 0.2101  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.1863  decode.d5.loss_dice: 0.1843  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 0.1879  decode.d6.loss_dice: 0.2122  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.1852  decode.d7.loss_dice: 0.1991  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.1846  decode.d8.loss_dice: 0.2065
10/01 00:58:46 - mmengine - INFO - Iter(train) [130650/320000]  base_lr: 6.2360e-05 lr: 6.2360e-06  eta: 23:01:42  time: 0.4399  data_time: 0.0093  memory: 5129  grad_norm: 18.2122  loss: 3.7141  decode.loss_cls: 0.0031  decode.loss_mask: 0.1569  decode.loss_dice: 0.1244  decode.d0.loss_cls: 0.8391  decode.d0.loss_mask: 0.1563  decode.d0.loss_dice: 0.1240  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.1565  decode.d1.loss_dice: 0.1293  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.1544  decode.d2.loss_dice: 0.1276  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.1557  decode.d3.loss_dice: 0.1268  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.1601  decode.d4.loss_dice: 0.1352  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.1569  decode.d5.loss_dice: 0.1288  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.1568  decode.d6.loss_dice: 0.1245  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.1595  decode.d7.loss_dice: 0.1301  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.1575  decode.d8.loss_dice: 0.1289
10/01 00:59:08 - mmengine - INFO - Iter(train) [130700/320000]  base_lr: 6.2345e-05 lr: 6.2345e-06  eta: 23:01:20  time: 0.4403  data_time: 0.0096  memory: 5120  grad_norm: 39.5063  loss: 5.5401  decode.loss_cls: 0.0745  decode.loss_mask: 0.1761  decode.loss_dice: 0.2042  decode.d0.loss_cls: 0.8436  decode.d0.loss_mask: 0.1802  decode.d0.loss_dice: 0.2256  decode.d1.loss_cls: 0.1207  decode.d1.loss_mask: 0.1767  decode.d1.loss_dice: 0.2252  decode.d2.loss_cls: 0.1306  decode.d2.loss_mask: 0.1763  decode.d2.loss_dice: 0.1780  decode.d3.loss_cls: 0.1543  decode.d3.loss_mask: 0.1798  decode.d3.loss_dice: 0.2279  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.1808  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.2309  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.1768  decode.d6.loss_dice: 0.2199  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.1778  decode.d7.loss_dice: 0.2217  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.1749  decode.d8.loss_dice: 0.1883
10/01 00:59:30 - mmengine - INFO - Iter(train) [130750/320000]  base_lr: 6.2330e-05 lr: 6.2330e-06  eta: 23:00:58  time: 0.4393  data_time: 0.0096  memory: 5129  grad_norm: 96.4753  loss: 5.1593  decode.loss_cls: 0.0280  decode.loss_mask: 0.2332  decode.loss_dice: 0.1753  decode.d0.loss_cls: 0.8194  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.1730  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.2325  decode.d1.loss_dice: 0.1714  decode.d2.loss_cls: 0.0235  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.1764  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.1711  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.2354  decode.d4.loss_dice: 0.1806  decode.d5.loss_cls: 0.0258  decode.d5.loss_mask: 0.2361  decode.d5.loss_dice: 0.1714  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.2312  decode.d6.loss_dice: 0.1760  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.2308  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.0281  decode.d8.loss_mask: 0.2336  decode.d8.loss_dice: 0.1718
10/01 00:59:52 - mmengine - INFO - Iter(train) [130800/320000]  base_lr: 6.2315e-05 lr: 6.2315e-06  eta: 23:00:36  time: 0.4432  data_time: 0.0095  memory: 5145  grad_norm: 51.0214  loss: 5.2763  decode.loss_cls: 0.0803  decode.loss_mask: 0.1853  decode.loss_dice: 0.2036  decode.d0.loss_cls: 0.8837  decode.d0.loss_mask: 0.1848  decode.d0.loss_dice: 0.1847  decode.d1.loss_cls: 0.0704  decode.d1.loss_mask: 0.1877  decode.d1.loss_dice: 0.1941  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.1858  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.1866  decode.d3.loss_dice: 0.1873  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.1840  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.1839  decode.d5.loss_dice: 0.1792  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.1871  decode.d6.loss_dice: 0.1977  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.1877  decode.d7.loss_dice: 0.1901  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.1861  decode.d8.loss_dice: 0.1952
10/01 01:00:14 - mmengine - INFO - Iter(train) [130850/320000]  base_lr: 6.2301e-05 lr: 6.2301e-06  eta: 23:00:15  time: 0.4388  data_time: 0.0096  memory: 5129  grad_norm: 46.3417  loss: 5.8734  decode.loss_cls: 0.0481  decode.loss_mask: 0.2481  decode.loss_dice: 0.1946  decode.d0.loss_cls: 0.9086  decode.d0.loss_mask: 0.2545  decode.d0.loss_dice: 0.2043  decode.d1.loss_cls: 0.0449  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.1959  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.1978  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.2015  decode.d4.loss_cls: 0.0524  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.1958  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.1993  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.2530  decode.d6.loss_dice: 0.1987  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.2494  decode.d8.loss_dice: 0.1946
10/01 01:00:36 - mmengine - INFO - Iter(train) [130900/320000]  base_lr: 6.2286e-05 lr: 6.2286e-06  eta: 22:59:53  time: 0.4397  data_time: 0.0095  memory: 5129  grad_norm: 95.7160  loss: 7.0463  decode.loss_cls: 0.1477  decode.loss_mask: 0.2862  decode.loss_dice: 0.2165  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.2121  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 0.2832  decode.d1.loss_dice: 0.2068  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.2815  decode.d2.loss_dice: 0.2078  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.2769  decode.d3.loss_dice: 0.2025  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.2151  decode.d5.loss_cls: 0.0946  decode.d5.loss_mask: 0.3005  decode.d5.loss_dice: 0.2870  decode.d6.loss_cls: 0.1729  decode.d6.loss_mask: 0.3039  decode.d6.loss_dice: 0.2317  decode.d7.loss_cls: 0.1630  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.1212  decode.d8.loss_mask: 0.2905  decode.d8.loss_dice: 0.2533
10/01 01:00:58 - mmengine - INFO - Iter(train) [130950/320000]  base_lr: 6.2271e-05 lr: 6.2271e-06  eta: 22:59:31  time: 0.4396  data_time: 0.0094  memory: 5145  grad_norm: 24.8263  loss: 4.6144  decode.loss_cls: 0.0650  decode.loss_mask: 0.1910  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.8779  decode.d0.loss_mask: 0.1932  decode.d0.loss_dice: 0.1698  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.1902  decode.d1.loss_dice: 0.1671  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.1900  decode.d2.loss_dice: 0.1665  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.1913  decode.d3.loss_dice: 0.1632  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1921  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.1917  decode.d5.loss_dice: 0.1676  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.1934  decode.d6.loss_dice: 0.1653  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.1915  decode.d7.loss_dice: 0.1705  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.1643
10/01 01:01:20 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:01:20 - mmengine - INFO - Iter(train) [131000/320000]  base_lr: 6.2256e-05 lr: 6.2256e-06  eta: 22:59:10  time: 0.4383  data_time: 0.0095  memory: 5129  grad_norm: 80.3270  loss: 5.7138  decode.loss_cls: 0.0898  decode.loss_mask: 0.2237  decode.loss_dice: 0.1557  decode.d0.loss_cls: 1.0192  decode.d0.loss_mask: 0.2293  decode.d0.loss_dice: 0.1597  decode.d1.loss_cls: 0.1860  decode.d1.loss_mask: 0.2271  decode.d1.loss_dice: 0.1567  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.1570  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.2275  decode.d3.loss_dice: 0.1571  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.1560  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.1599  decode.d6.loss_cls: 0.0958  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.1577  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.1604  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1567
10/01 01:01:42 - mmengine - INFO - Iter(train) [131050/320000]  base_lr: 6.2241e-05 lr: 6.2241e-06  eta: 22:58:48  time: 0.4423  data_time: 0.0099  memory: 5129  grad_norm: 34.7953  loss: 4.7357  decode.loss_cls: 0.0097  decode.loss_mask: 0.2143  decode.loss_dice: 0.1670  decode.d0.loss_cls: 0.8145  decode.d0.loss_mask: 0.2128  decode.d0.loss_dice: 0.1647  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.1637  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.2121  decode.d2.loss_dice: 0.1687  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.2124  decode.d3.loss_dice: 0.1746  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2109  decode.d4.loss_dice: 0.1702  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.1638  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.2106  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.2145  decode.d8.loss_dice: 0.1634
10/01 01:02:04 - mmengine - INFO - Iter(train) [131100/320000]  base_lr: 6.2226e-05 lr: 6.2226e-06  eta: 22:58:26  time: 0.4398  data_time: 0.0095  memory: 5120  grad_norm: 72.1705  loss: 7.2610  decode.loss_cls: 0.0903  decode.loss_mask: 0.2348  decode.loss_dice: 0.2912  decode.d0.loss_cls: 0.8803  decode.d0.loss_mask: 0.2350  decode.d0.loss_dice: 0.2838  decode.d1.loss_cls: 0.1301  decode.d1.loss_mask: 0.2353  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.1898  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.2746  decode.d3.loss_cls: 0.1657  decode.d3.loss_mask: 0.2370  decode.d3.loss_dice: 0.2851  decode.d4.loss_cls: 0.1570  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.2918  decode.d6.loss_cls: 0.1268  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.2823  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.2322  decode.d7.loss_dice: 0.2902  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2894
10/01 01:02:26 - mmengine - INFO - Iter(train) [131150/320000]  base_lr: 6.2212e-05 lr: 6.2212e-06  eta: 22:58:04  time: 0.4423  data_time: 0.0095  memory: 5129  grad_norm: 77.6556  loss: 7.9852  decode.loss_cls: 0.2328  decode.loss_mask: 0.2703  decode.loss_dice: 0.1977  decode.d0.loss_cls: 0.8847  decode.d0.loss_mask: 0.3040  decode.d0.loss_dice: 0.2197  decode.d1.loss_cls: 0.2476  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.1787  decode.d2.loss_cls: 0.2210  decode.d2.loss_mask: 0.2664  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.2410  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.1790  decode.d4.loss_cls: 0.2696  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.2088  decode.d5.loss_cls: 0.2368  decode.d5.loss_mask: 0.3002  decode.d5.loss_dice: 0.2077  decode.d6.loss_cls: 0.2574  decode.d6.loss_mask: 0.2698  decode.d6.loss_dice: 0.1841  decode.d7.loss_cls: 0.2496  decode.d7.loss_mask: 0.2789  decode.d7.loss_dice: 0.2089  decode.d8.loss_cls: 0.2454  decode.d8.loss_mask: 0.3819  decode.d8.loss_dice: 0.2443
10/01 01:02:48 - mmengine - INFO - Iter(train) [131200/320000]  base_lr: 6.2197e-05 lr: 6.2197e-06  eta: 22:57:43  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 94.2873  loss: 5.3322  decode.loss_cls: 0.0507  decode.loss_mask: 0.1857  decode.loss_dice: 0.1826  decode.d0.loss_cls: 1.0527  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1938  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.1858  decode.d1.loss_dice: 0.1780  decode.d2.loss_cls: 0.0521  decode.d2.loss_mask: 0.1877  decode.d2.loss_dice: 0.1863  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.1873  decode.d3.loss_dice: 0.1827  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.1911  decode.d4.loss_dice: 0.1970  decode.d5.loss_cls: 0.0768  decode.d5.loss_mask: 0.1885  decode.d5.loss_dice: 0.1923  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.1865  decode.d6.loss_dice: 0.1854  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.1883  decode.d7.loss_dice: 0.1875  decode.d8.loss_cls: 0.0493  decode.d8.loss_mask: 0.1863  decode.d8.loss_dice: 0.1820
10/01 01:03:10 - mmengine - INFO - Iter(train) [131250/320000]  base_lr: 6.2182e-05 lr: 6.2182e-06  eta: 22:57:21  time: 0.4424  data_time: 0.0097  memory: 5129  grad_norm: 42.7152  loss: 5.8929  decode.loss_cls: 0.0541  decode.loss_mask: 0.2191  decode.loss_dice: 0.2035  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 0.2205  decode.d0.loss_dice: 0.2134  decode.d1.loss_cls: 0.1465  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.2030  decode.d2.loss_cls: 0.1286  decode.d2.loss_mask: 0.2243  decode.d2.loss_dice: 0.2160  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.2316  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.2013  decode.d5.loss_cls: 0.0710  decode.d5.loss_mask: 0.2205  decode.d5.loss_dice: 0.2022  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2255  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.2240  decode.d7.loss_dice: 0.1988  decode.d8.loss_cls: 0.0498  decode.d8.loss_mask: 0.2196  decode.d8.loss_dice: 0.2013
10/01 01:03:32 - mmengine - INFO - Iter(train) [131300/320000]  base_lr: 6.2167e-05 lr: 6.2167e-06  eta: 22:56:59  time: 0.4406  data_time: 0.0095  memory: 5145  grad_norm: 40.9336  loss: 4.8958  decode.loss_cls: 0.0512  decode.loss_mask: 0.1813  decode.loss_dice: 0.1712  decode.d0.loss_cls: 0.9255  decode.d0.loss_mask: 0.1828  decode.d0.loss_dice: 0.1687  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.1823  decode.d1.loss_dice: 0.1829  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.1843  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.1830  decode.d3.loss_dice: 0.1828  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.1815  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.1841  decode.d5.loss_dice: 0.1852  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.1828  decode.d6.loss_dice: 0.1819  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.1841  decode.d7.loss_dice: 0.1829  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.1832  decode.d8.loss_dice: 0.1678
10/01 01:03:54 - mmengine - INFO - Iter(train) [131350/320000]  base_lr: 6.2152e-05 lr: 6.2152e-06  eta: 22:56:37  time: 0.4395  data_time: 0.0093  memory: 5145  grad_norm: 62.9212  loss: 7.0086  decode.loss_cls: 0.1559  decode.loss_mask: 0.2232  decode.loss_dice: 0.2321  decode.d0.loss_cls: 0.9679  decode.d0.loss_mask: 0.2325  decode.d0.loss_dice: 0.2282  decode.d1.loss_cls: 0.1745  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.1386  decode.d2.loss_mask: 0.2247  decode.d2.loss_dice: 0.2340  decode.d3.loss_cls: 0.1478  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2517  decode.d4.loss_cls: 0.1544  decode.d4.loss_mask: 0.2326  decode.d4.loss_dice: 0.2468  decode.d5.loss_cls: 0.1409  decode.d5.loss_mask: 0.2289  decode.d5.loss_dice: 0.2281  decode.d6.loss_cls: 0.1519  decode.d6.loss_mask: 0.2253  decode.d6.loss_dice: 0.2364  decode.d7.loss_cls: 0.1586  decode.d7.loss_mask: 0.2315  decode.d7.loss_dice: 0.2366  decode.d8.loss_cls: 0.1638  decode.d8.loss_mask: 0.2256  decode.d8.loss_dice: 0.2375
10/01 01:04:16 - mmengine - INFO - Iter(train) [131400/320000]  base_lr: 6.2137e-05 lr: 6.2137e-06  eta: 22:56:16  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 24.2609  loss: 4.1943  decode.loss_cls: 0.0039  decode.loss_mask: 0.1897  decode.loss_dice: 0.1492  decode.d0.loss_cls: 0.7885  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.1467  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.1889  decode.d1.loss_dice: 0.1498  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.1887  decode.d2.loss_dice: 0.1470  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.1865  decode.d3.loss_dice: 0.1462  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.1446  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.1898  decode.d5.loss_dice: 0.1478  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.1504  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.1450  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.1897  decode.d8.loss_dice: 0.1488
10/01 01:04:38 - mmengine - INFO - Iter(train) [131450/320000]  base_lr: 6.2123e-05 lr: 6.2123e-06  eta: 22:55:54  time: 0.4392  data_time: 0.0095  memory: 5120  grad_norm: 117.9685  loss: 4.9422  decode.loss_cls: 0.0793  decode.loss_mask: 0.1803  decode.loss_dice: 0.1636  decode.d0.loss_cls: 0.8925  decode.d0.loss_mask: 0.1834  decode.d0.loss_dice: 0.1684  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.2057  decode.d1.loss_dice: 0.1895  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.1702  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.1827  decode.d3.loss_dice: 0.1647  decode.d4.loss_cls: 0.0746  decode.d4.loss_mask: 0.1847  decode.d4.loss_dice: 0.1685  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.1807  decode.d5.loss_dice: 0.1653  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.1796  decode.d6.loss_dice: 0.1664  decode.d7.loss_cls: 0.0904  decode.d7.loss_mask: 0.1801  decode.d7.loss_dice: 0.1622  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.1807  decode.d8.loss_dice: 0.1651
10/01 01:05:00 - mmengine - INFO - Iter(train) [131500/320000]  base_lr: 6.2108e-05 lr: 6.2108e-06  eta: 22:55:32  time: 0.4402  data_time: 0.0098  memory: 5129  grad_norm: 142.0693  loss: 6.9282  decode.loss_cls: 0.1228  decode.loss_mask: 0.2825  decode.loss_dice: 0.2122  decode.d0.loss_cls: 0.9263  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.2020  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.2116  decode.d2.loss_cls: 0.1156  decode.d2.loss_mask: 0.2960  decode.d2.loss_dice: 0.2080  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 0.2877  decode.d3.loss_dice: 0.2111  decode.d4.loss_cls: 0.1338  decode.d4.loss_mask: 0.2845  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.1244  decode.d5.loss_mask: 0.2860  decode.d5.loss_dice: 0.2117  decode.d6.loss_cls: 0.1204  decode.d6.loss_mask: 0.2719  decode.d6.loss_dice: 0.2094  decode.d7.loss_cls: 0.1195  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.2116  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.2859  decode.d8.loss_dice: 0.2097
10/01 01:05:22 - mmengine - INFO - Iter(train) [131550/320000]  base_lr: 6.2093e-05 lr: 6.2093e-06  eta: 22:55:10  time: 0.4411  data_time: 0.0097  memory: 5120  grad_norm: 107.4391  loss: 5.9133  decode.loss_cls: 0.0643  decode.loss_mask: 0.2373  decode.loss_dice: 0.2124  decode.d0.loss_cls: 0.8229  decode.d0.loss_mask: 0.2431  decode.d0.loss_dice: 0.2011  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.2359  decode.d1.loss_dice: 0.2106  decode.d2.loss_cls: 0.0819  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.2095  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.2386  decode.d3.loss_dice: 0.2094  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.2368  decode.d4.loss_dice: 0.2072  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.2113  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.2361  decode.d6.loss_dice: 0.2105  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.2374  decode.d7.loss_dice: 0.2098  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.2125
10/01 01:05:45 - mmengine - INFO - Iter(train) [131600/320000]  base_lr: 6.2078e-05 lr: 6.2078e-06  eta: 22:54:49  time: 0.4407  data_time: 0.0096  memory: 5120  grad_norm: 44.0978  loss: 5.3472  decode.loss_cls: 0.1131  decode.loss_mask: 0.1805  decode.loss_dice: 0.1587  decode.d0.loss_cls: 0.8481  decode.d0.loss_mask: 0.1790  decode.d0.loss_dice: 0.1599  decode.d1.loss_cls: 0.1509  decode.d1.loss_mask: 0.1773  decode.d1.loss_dice: 0.1691  decode.d2.loss_cls: 0.1581  decode.d2.loss_mask: 0.1771  decode.d2.loss_dice: 0.1579  decode.d3.loss_cls: 0.1121  decode.d3.loss_mask: 0.1782  decode.d3.loss_dice: 0.1645  decode.d4.loss_cls: 0.1304  decode.d4.loss_mask: 0.1781  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.1392  decode.d5.loss_mask: 0.1778  decode.d5.loss_dice: 0.1593  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.1794  decode.d6.loss_dice: 0.1652  decode.d7.loss_cls: 0.0922  decode.d7.loss_mask: 0.1794  decode.d7.loss_dice: 0.1624  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.1782  decode.d8.loss_dice: 0.1692
10/01 01:06:07 - mmengine - INFO - Iter(train) [131650/320000]  base_lr: 6.2063e-05 lr: 6.2063e-06  eta: 22:54:27  time: 0.4399  data_time: 0.0094  memory: 5145  grad_norm: 30.3661  loss: 5.2244  decode.loss_cls: 0.0139  decode.loss_mask: 0.2496  decode.loss_dice: 0.1751  decode.d0.loss_cls: 0.7745  decode.d0.loss_mask: 0.2549  decode.d0.loss_dice: 0.1858  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.1744  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.1763  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.1767  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.2461  decode.d4.loss_dice: 0.1738  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.1742  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.2479  decode.d6.loss_dice: 0.1732  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.2502  decode.d7.loss_dice: 0.1759  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.2480  decode.d8.loss_dice: 0.1759
10/01 01:06:29 - mmengine - INFO - Iter(train) [131700/320000]  base_lr: 6.2049e-05 lr: 6.2049e-06  eta: 22:54:06  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 22.1873  loss: 4.6546  decode.loss_cls: 0.0108  decode.loss_mask: 0.1653  decode.loss_dice: 0.2074  decode.d0.loss_cls: 0.9106  decode.d0.loss_mask: 0.1659  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.1679  decode.d1.loss_dice: 0.1887  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.1670  decode.d2.loss_dice: 0.1944  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.1670  decode.d3.loss_dice: 0.1948  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.1674  decode.d4.loss_dice: 0.1922  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.1663  decode.d5.loss_dice: 0.1910  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.1697  decode.d6.loss_dice: 0.1883  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.1685  decode.d7.loss_dice: 0.2036  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.1655  decode.d8.loss_dice: 0.1819
10/01 01:06:51 - mmengine - INFO - Iter(train) [131750/320000]  base_lr: 6.2034e-05 lr: 6.2034e-06  eta: 22:53:44  time: 0.4400  data_time: 0.0096  memory: 5129  grad_norm: 22.6621  loss: 4.2127  decode.loss_cls: 0.0008  decode.loss_mask: 0.2068  decode.loss_dice: 0.1403  decode.d0.loss_cls: 0.7166  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.1441  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2031  decode.d1.loss_dice: 0.1390  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.2065  decode.d2.loss_dice: 0.1428  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.1404  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2081  decode.d4.loss_dice: 0.1412  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.1406  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.2092  decode.d6.loss_dice: 0.1409  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.1397  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.1400
10/01 01:07:13 - mmengine - INFO - Iter(train) [131800/320000]  base_lr: 6.2019e-05 lr: 6.2019e-06  eta: 22:53:22  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 28.6509  loss: 4.2271  decode.loss_cls: 0.0366  decode.loss_mask: 0.1807  decode.loss_dice: 0.1392  decode.d0.loss_cls: 0.7387  decode.d0.loss_mask: 0.1845  decode.d0.loss_dice: 0.1543  decode.d1.loss_cls: 0.0142  decode.d1.loss_mask: 0.1793  decode.d1.loss_dice: 0.1441  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.1834  decode.d2.loss_dice: 0.1595  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1821  decode.d3.loss_dice: 0.1537  decode.d4.loss_cls: 0.0357  decode.d4.loss_mask: 0.1823  decode.d4.loss_dice: 0.1544  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.1571  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.1802  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.1826  decode.d7.loss_dice: 0.1636  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.1810  decode.d8.loss_dice: 0.1518
10/01 01:07:35 - mmengine - INFO - Iter(train) [131850/320000]  base_lr: 6.2004e-05 lr: 6.2004e-06  eta: 22:53:01  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 31.3109  loss: 4.3822  decode.loss_cls: 0.0055  decode.loss_mask: 0.2069  decode.loss_dice: 0.1503  decode.d0.loss_cls: 0.7377  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.1554  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.2052  decode.d2.loss_dice: 0.1526  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.2083  decode.d3.loss_dice: 0.1513  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.2082  decode.d4.loss_dice: 0.1485  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.2095  decode.d5.loss_dice: 0.1524  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.1500  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2046  decode.d7.loss_dice: 0.1483  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2083  decode.d8.loss_dice: 0.1470
10/01 01:07:57 - mmengine - INFO - Iter(train) [131900/320000]  base_lr: 6.1989e-05 lr: 6.1989e-06  eta: 22:52:39  time: 0.4410  data_time: 0.0097  memory: 5129  grad_norm: 92.3829  loss: 5.7237  decode.loss_cls: 0.0633  decode.loss_mask: 0.1949  decode.loss_dice: 0.2208  decode.d0.loss_cls: 0.8951  decode.d0.loss_mask: 0.1954  decode.d0.loss_dice: 0.2086  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.1918  decode.d2.loss_dice: 0.1972  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.0868  decode.d4.loss_mask: 0.1922  decode.d4.loss_dice: 0.2140  decode.d5.loss_cls: 0.1088  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.1479  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.1968  decode.d7.loss_dice: 0.2210  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.1951  decode.d8.loss_dice: 0.2119
10/01 01:08:19 - mmengine - INFO - Iter(train) [131950/320000]  base_lr: 6.1974e-05 lr: 6.1974e-06  eta: 22:52:17  time: 0.4409  data_time: 0.0098  memory: 5129  grad_norm: 65.9954  loss: 6.5744  decode.loss_cls: 0.1422  decode.loss_mask: 0.2237  decode.loss_dice: 0.2235  decode.d0.loss_cls: 0.8783  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.2634  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.2217  decode.d1.loss_dice: 0.2480  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.2238  decode.d2.loss_dice: 0.2430  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.2569  decode.d4.loss_cls: 0.0876  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.2497  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.2261  decode.d5.loss_dice: 0.2786  decode.d6.loss_cls: 0.1136  decode.d6.loss_mask: 0.2233  decode.d6.loss_dice: 0.2416  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.2252  decode.d7.loss_dice: 0.2381  decode.d8.loss_cls: 0.1221  decode.d8.loss_mask: 0.2242  decode.d8.loss_dice: 0.2381
10/01 01:08:41 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:08:41 - mmengine - INFO - Iter(train) [132000/320000]  base_lr: 6.1960e-05 lr: 6.1960e-06  eta: 22:51:56  time: 0.4406  data_time: 0.0096  memory: 5145  grad_norm: 37.0640  loss: 4.4467  decode.loss_cls: 0.0107  decode.loss_mask: 0.1966  decode.loss_dice: 0.1541  decode.d0.loss_cls: 0.8220  decode.d0.loss_mask: 0.1978  decode.d0.loss_dice: 0.1578  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.1983  decode.d1.loss_dice: 0.1568  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.1976  decode.d2.loss_dice: 0.1573  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.1967  decode.d3.loss_dice: 0.1569  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.1948  decode.d4.loss_dice: 0.1539  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2000  decode.d5.loss_dice: 0.1565  decode.d6.loss_cls: 0.0096  decode.d6.loss_mask: 0.1971  decode.d6.loss_dice: 0.1594  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.1943  decode.d7.loss_dice: 0.1596  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.1602
10/01 01:09:03 - mmengine - INFO - Iter(train) [132050/320000]  base_lr: 6.1945e-05 lr: 6.1945e-06  eta: 22:51:34  time: 0.4399  data_time: 0.0095  memory: 5129  grad_norm: 70.1944  loss: 5.4926  decode.loss_cls: 0.0458  decode.loss_mask: 0.2625  decode.loss_dice: 0.1708  decode.d0.loss_cls: 0.7928  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.1671  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.2607  decode.d1.loss_dice: 0.1719  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.2603  decode.d2.loss_dice: 0.1701  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.2626  decode.d3.loss_dice: 0.1714  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.1727  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.2604  decode.d5.loss_dice: 0.1722  decode.d6.loss_cls: 0.0387  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.1723  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.2617  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0438  decode.d8.loss_mask: 0.2645  decode.d8.loss_dice: 0.1712
10/01 01:09:25 - mmengine - INFO - Iter(train) [132100/320000]  base_lr: 6.1930e-05 lr: 6.1930e-06  eta: 22:51:12  time: 0.4405  data_time: 0.0099  memory: 5145  grad_norm: 40.5363  loss: 4.8524  decode.loss_cls: 0.0074  decode.loss_mask: 0.2210  decode.loss_dice: 0.1742  decode.d0.loss_cls: 0.8390  decode.d0.loss_mask: 0.2262  decode.d0.loss_dice: 0.1692  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.2213  decode.d1.loss_dice: 0.1656  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.1718  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.2223  decode.d3.loss_dice: 0.1761  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.1728  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.1746  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2228  decode.d7.loss_dice: 0.1738  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.2242  decode.d8.loss_dice: 0.1700
10/01 01:09:47 - mmengine - INFO - Iter(train) [132150/320000]  base_lr: 6.1915e-05 lr: 6.1915e-06  eta: 22:50:50  time: 0.4404  data_time: 0.0096  memory: 5120  grad_norm: 60.5125  loss: 5.5914  decode.loss_cls: 0.0376  decode.loss_mask: 0.2208  decode.loss_dice: 0.1960  decode.d0.loss_cls: 0.7117  decode.d0.loss_mask: 0.2260  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.2222  decode.d1.loss_dice: 0.1897  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.2208  decode.d2.loss_dice: 0.2337  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 0.2189  decode.d3.loss_dice: 0.2319  decode.d4.loss_cls: 0.0516  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.2217  decode.d5.loss_dice: 0.2314  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.2184  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.2241  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.2210
10/01 01:10:09 - mmengine - INFO - Iter(train) [132200/320000]  base_lr: 6.1900e-05 lr: 6.1900e-06  eta: 22:50:29  time: 0.4400  data_time: 0.0096  memory: 5120  grad_norm: 148.9459  loss: 8.0761  decode.loss_cls: 0.2398  decode.loss_mask: 0.2455  decode.loss_dice: 0.2278  decode.d0.loss_cls: 1.0449  decode.d0.loss_mask: 0.2271  decode.d0.loss_dice: 0.2164  decode.d1.loss_cls: 0.3433  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.1950  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2073  decode.d3.loss_cls: 0.2216  decode.d3.loss_mask: 0.2633  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.2472  decode.d5.loss_cls: 0.2554  decode.d5.loss_mask: 0.2214  decode.d5.loss_dice: 0.2385  decode.d6.loss_cls: 0.2686  decode.d6.loss_mask: 0.2319  decode.d6.loss_dice: 0.2324  decode.d7.loss_cls: 0.2751  decode.d7.loss_mask: 0.2391  decode.d7.loss_dice: 0.2300  decode.d8.loss_cls: 0.2669  decode.d8.loss_mask: 0.2503  decode.d8.loss_dice: 0.2350
10/01 01:10:31 - mmengine - INFO - Iter(train) [132250/320000]  base_lr: 6.1885e-05 lr: 6.1885e-06  eta: 22:50:07  time: 0.4402  data_time: 0.0098  memory: 5129  grad_norm: 47.8093  loss: 5.4988  decode.loss_cls: 0.0127  decode.loss_mask: 0.2243  decode.loss_dice: 0.2265  decode.d0.loss_cls: 0.7509  decode.d0.loss_mask: 0.2231  decode.d0.loss_dice: 0.2361  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.2203  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.2238  decode.d3.loss_dice: 0.2423  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.2444  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2454  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.2385  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0103  decode.d8.loss_mask: 0.2283  decode.d8.loss_dice: 0.2443
10/01 01:10:53 - mmengine - INFO - Iter(train) [132300/320000]  base_lr: 6.1871e-05 lr: 6.1871e-06  eta: 22:49:45  time: 0.4404  data_time: 0.0097  memory: 5119  grad_norm: 26.4702  loss: 4.8038  decode.loss_cls: 0.0087  decode.loss_mask: 0.1987  decode.loss_dice: 0.1808  decode.d0.loss_cls: 0.8970  decode.d0.loss_mask: 0.1979  decode.d0.loss_dice: 0.1647  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.2010  decode.d1.loss_dice: 0.1889  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.1991  decode.d2.loss_dice: 0.1688  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.1979  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.1997  decode.d4.loss_dice: 0.1838  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1996  decode.d6.loss_dice: 0.1872  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.1989  decode.d7.loss_dice: 0.1912  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.1938
10/01 01:11:15 - mmengine - INFO - Iter(train) [132350/320000]  base_lr: 6.1856e-05 lr: 6.1856e-06  eta: 22:49:24  time: 0.4389  data_time: 0.0096  memory: 5129  grad_norm: 73.8580  loss: 5.3027  decode.loss_cls: 0.0048  decode.loss_mask: 0.2591  decode.loss_dice: 0.1817  decode.d0.loss_cls: 0.7071  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.1825  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.1845  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.1891  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.2568  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0209  decode.d4.loss_mask: 0.2587  decode.d4.loss_dice: 0.1868  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 0.2617  decode.d5.loss_dice: 0.1908  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.2596  decode.d6.loss_dice: 0.1830  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.1864  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.1883
10/01 01:11:37 - mmengine - INFO - Iter(train) [132400/320000]  base_lr: 6.1841e-05 lr: 6.1841e-06  eta: 22:49:02  time: 0.4419  data_time: 0.0097  memory: 5129  grad_norm: 73.2279  loss: 5.1233  decode.loss_cls: 0.0151  decode.loss_mask: 0.2470  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.7028  decode.d0.loss_mask: 0.2566  decode.d0.loss_dice: 0.1818  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.2528  decode.d1.loss_dice: 0.1844  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.1884  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.1746  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.2470  decode.d4.loss_dice: 0.1807  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.2438  decode.d5.loss_dice: 0.1797  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.1774  decode.d7.loss_cls: 0.0125  decode.d7.loss_mask: 0.2482  decode.d7.loss_dice: 0.1785  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.1808
10/01 01:11:59 - mmengine - INFO - Iter(train) [132450/320000]  base_lr: 6.1826e-05 lr: 6.1826e-06  eta: 22:48:40  time: 0.4440  data_time: 0.0095  memory: 5129  grad_norm: 65.8788  loss: 4.9839  decode.loss_cls: 0.0514  decode.loss_mask: 0.1789  decode.loss_dice: 0.2211  decode.d0.loss_cls: 0.8473  decode.d0.loss_mask: 0.1831  decode.d0.loss_dice: 0.2394  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.1802  decode.d1.loss_dice: 0.2210  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.1815  decode.d2.loss_dice: 0.1897  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.2209  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.1774  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.2232  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.1812  decode.d6.loss_dice: 0.2348  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.1813  decode.d8.loss_dice: 0.2256
10/01 01:12:21 - mmengine - INFO - Iter(train) [132500/320000]  base_lr: 6.1811e-05 lr: 6.1811e-06  eta: 22:48:18  time: 0.4422  data_time: 0.0099  memory: 5145  grad_norm: 36.1880  loss: 4.9091  decode.loss_cls: 0.0309  decode.loss_mask: 0.2007  decode.loss_dice: 0.2032  decode.d0.loss_cls: 0.7033  decode.d0.loss_mask: 0.2012  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.2094  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.1970  decode.d3.loss_dice: 0.1971  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2029  decode.d4.loss_dice: 0.2166  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.2136  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.1997  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2008  decode.d7.loss_dice: 0.2114  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.2012  decode.d8.loss_dice: 0.2162
10/01 01:12:43 - mmengine - INFO - Iter(train) [132550/320000]  base_lr: 6.1796e-05 lr: 6.1796e-06  eta: 22:47:57  time: 0.4401  data_time: 0.0100  memory: 5129  grad_norm: 43.8322  loss: 5.2699  decode.loss_cls: 0.0720  decode.loss_mask: 0.2053  decode.loss_dice: 0.1744  decode.d0.loss_cls: 0.7835  decode.d0.loss_mask: 0.2080  decode.d0.loss_dice: 0.1791  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.2081  decode.d1.loss_dice: 0.1748  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.2064  decode.d3.loss_dice: 0.1849  decode.d4.loss_cls: 0.0905  decode.d4.loss_mask: 0.2090  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.2073  decode.d5.loss_dice: 0.1678  decode.d6.loss_cls: 0.0966  decode.d6.loss_mask: 0.2042  decode.d6.loss_dice: 0.1744  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.2045  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.1730
10/01 01:13:05 - mmengine - INFO - Iter(train) [132600/320000]  base_lr: 6.1782e-05 lr: 6.1782e-06  eta: 22:47:35  time: 0.4425  data_time: 0.0099  memory: 5145  grad_norm: 29.2523  loss: 4.4204  decode.loss_cls: 0.0325  decode.loss_mask: 0.1924  decode.loss_dice: 0.1577  decode.d0.loss_cls: 0.7937  decode.d0.loss_mask: 0.1969  decode.d0.loss_dice: 0.1494  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.1611  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.1942  decode.d2.loss_dice: 0.1683  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.1939  decode.d3.loss_dice: 0.1569  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.1927  decode.d4.loss_dice: 0.1530  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.1567  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.1926  decode.d6.loss_dice: 0.1597  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.1939  decode.d7.loss_dice: 0.1668  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.1945  decode.d8.loss_dice: 0.1584
10/01 01:13:27 - mmengine - INFO - Iter(train) [132650/320000]  base_lr: 6.1767e-05 lr: 6.1767e-06  eta: 22:47:13  time: 0.4397  data_time: 0.0096  memory: 5120  grad_norm: 150.4810  loss: 6.9407  decode.loss_cls: 0.1589  decode.loss_mask: 0.1899  decode.loss_dice: 0.2714  decode.d0.loss_cls: 0.8532  decode.d0.loss_mask: 0.1915  decode.d0.loss_dice: 0.2844  decode.d1.loss_cls: 0.1376  decode.d1.loss_mask: 0.1953  decode.d1.loss_dice: 0.2801  decode.d2.loss_cls: 0.1851  decode.d2.loss_mask: 0.1936  decode.d2.loss_dice: 0.2735  decode.d3.loss_cls: 0.1399  decode.d3.loss_mask: 0.1920  decode.d3.loss_dice: 0.2685  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 0.1916  decode.d4.loss_dice: 0.2727  decode.d5.loss_cls: 0.1899  decode.d5.loss_mask: 0.1934  decode.d5.loss_dice: 0.2630  decode.d6.loss_cls: 0.1982  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2466  decode.d7.loss_cls: 0.1484  decode.d7.loss_mask: 0.1892  decode.d7.loss_dice: 0.2615  decode.d8.loss_cls: 0.1768  decode.d8.loss_mask: 0.1917  decode.d8.loss_dice: 0.2390
10/01 01:13:49 - mmengine - INFO - Iter(train) [132700/320000]  base_lr: 6.1752e-05 lr: 6.1752e-06  eta: 22:46:51  time: 0.4396  data_time: 0.0095  memory: 5145  grad_norm: 62.5268  loss: 4.8097  decode.loss_cls: 0.0066  decode.loss_mask: 0.2245  decode.loss_dice: 0.1667  decode.d0.loss_cls: 0.8035  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.1671  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.1667  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.2264  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.2287  decode.d3.loss_dice: 0.1713  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.2271  decode.d4.loss_dice: 0.1671  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.1666  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1687  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.2250  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.1666
10/01 01:14:11 - mmengine - INFO - Iter(train) [132750/320000]  base_lr: 6.1737e-05 lr: 6.1737e-06  eta: 22:46:30  time: 0.4398  data_time: 0.0098  memory: 5129  grad_norm: 104.2269  loss: 5.3598  decode.loss_cls: 0.0636  decode.loss_mask: 0.2085  decode.loss_dice: 0.1892  decode.d0.loss_cls: 0.8631  decode.d0.loss_mask: 0.2103  decode.d0.loss_dice: 0.1782  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.1864  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0992  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.1658  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.1746  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.1760  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.2087  decode.d7.loss_dice: 0.1504  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1785
10/01 01:14:33 - mmengine - INFO - Iter(train) [132800/320000]  base_lr: 6.1722e-05 lr: 6.1722e-06  eta: 22:46:08  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 48.1259  loss: 4.8711  decode.loss_cls: 0.0106  decode.loss_mask: 0.1862  decode.loss_dice: 0.1893  decode.d0.loss_cls: 0.8722  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.1774  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.1875  decode.d1.loss_dice: 0.1692  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.1829  decode.d2.loss_dice: 0.1894  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.1848  decode.d3.loss_dice: 0.1927  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.2021  decode.d5.loss_cls: 0.0522  decode.d5.loss_mask: 0.1845  decode.d5.loss_dice: 0.1775  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 0.1827  decode.d6.loss_dice: 0.1669  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.1863  decode.d7.loss_dice: 0.1698  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.1835  decode.d8.loss_dice: 0.1707
10/01 01:14:55 - mmengine - INFO - Iter(train) [132850/320000]  base_lr: 6.1707e-05 lr: 6.1707e-06  eta: 22:45:46  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 22.8522  loss: 4.3174  decode.loss_cls: 0.0030  decode.loss_mask: 0.2046  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.7565  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.1529  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.2065  decode.d1.loss_dice: 0.1446  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.2029  decode.d2.loss_dice: 0.1468  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.2038  decode.d3.loss_dice: 0.1485  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.2032  decode.d4.loss_dice: 0.1497  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.1506  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.1469  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2025  decode.d8.loss_dice: 0.1455
10/01 01:15:17 - mmengine - INFO - Iter(train) [132900/320000]  base_lr: 6.1693e-05 lr: 6.1693e-06  eta: 22:45:25  time: 0.4400  data_time: 0.0098  memory: 5129  grad_norm: 46.6904  loss: 5.8985  decode.loss_cls: 0.0631  decode.loss_mask: 0.1936  decode.loss_dice: 0.2494  decode.d0.loss_cls: 0.7567  decode.d0.loss_mask: 0.1956  decode.d0.loss_dice: 0.2516  decode.d1.loss_cls: 0.0880  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.2314  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.1913  decode.d2.loss_dice: 0.2298  decode.d3.loss_cls: 0.0940  decode.d3.loss_mask: 0.1924  decode.d3.loss_dice: 0.2326  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.1899  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.1363  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.2327  decode.d6.loss_cls: 0.0857  decode.d6.loss_mask: 0.1883  decode.d6.loss_dice: 0.2412  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.1913  decode.d7.loss_dice: 0.2247  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.1913  decode.d8.loss_dice: 0.2455
10/01 01:15:39 - mmengine - INFO - Iter(train) [132950/320000]  base_lr: 6.1678e-05 lr: 6.1678e-06  eta: 22:45:03  time: 0.4392  data_time: 0.0097  memory: 5145  grad_norm: 147.9707  loss: 5.1533  decode.loss_cls: 0.0427  decode.loss_mask: 0.2245  decode.loss_dice: 0.1678  decode.d0.loss_cls: 0.8609  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.1692  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.1690  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.2241  decode.d2.loss_dice: 0.1660  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.1662  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.2216  decode.d4.loss_dice: 0.1672  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.2220  decode.d5.loss_dice: 0.1709  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.1710  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.2233  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.1711
10/01 01:16:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:16:02 - mmengine - INFO - Iter(train) [133000/320000]  base_lr: 6.1663e-05 lr: 6.1663e-06  eta: 22:44:41  time: 0.4406  data_time: 0.0096  memory: 5145  grad_norm: 40.7645  loss: 4.5279  decode.loss_cls: 0.0093  decode.loss_mask: 0.1919  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.7859  decode.d0.loss_mask: 0.1921  decode.d0.loss_dice: 0.1700  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.1684  decode.d2.loss_cls: 0.0149  decode.d2.loss_mask: 0.1917  decode.d2.loss_dice: 0.1777  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.1932  decode.d3.loss_dice: 0.1777  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.1905  decode.d4.loss_dice: 0.1754  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.1919  decode.d5.loss_dice: 0.1680  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.1916  decode.d6.loss_dice: 0.1693  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.1918  decode.d7.loss_dice: 0.1697  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.1926  decode.d8.loss_dice: 0.1700
10/01 01:16:24 - mmengine - INFO - Iter(train) [133050/320000]  base_lr: 6.1648e-05 lr: 6.1648e-06  eta: 22:44:19  time: 0.4404  data_time: 0.0097  memory: 5146  grad_norm: 23.3231  loss: 4.1512  decode.loss_cls: 0.0018  decode.loss_mask: 0.1995  decode.loss_dice: 0.1416  decode.d0.loss_cls: 0.7437  decode.d0.loss_mask: 0.2014  decode.d0.loss_dice: 0.1419  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.2013  decode.d1.loss_dice: 0.1382  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.1989  decode.d2.loss_dice: 0.1374  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2014  decode.d3.loss_dice: 0.1397  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.1993  decode.d4.loss_dice: 0.1379  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.1997  decode.d5.loss_dice: 0.1402  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1990  decode.d6.loss_dice: 0.1373  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1993  decode.d7.loss_dice: 0.1398  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.1383
10/01 01:16:46 - mmengine - INFO - Iter(train) [133100/320000]  base_lr: 6.1633e-05 lr: 6.1633e-06  eta: 22:43:58  time: 0.4399  data_time: 0.0097  memory: 5145  grad_norm: 19.8483  loss: 4.0382  decode.loss_cls: 0.0054  decode.loss_mask: 0.1690  decode.loss_dice: 0.1496  decode.d0.loss_cls: 0.7927  decode.d0.loss_mask: 0.1715  decode.d0.loss_dice: 0.1534  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.1713  decode.d1.loss_dice: 0.1492  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.1695  decode.d2.loss_dice: 0.1481  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.1684  decode.d3.loss_dice: 0.1481  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.1687  decode.d4.loss_dice: 0.1504  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.1690  decode.d5.loss_dice: 0.1525  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.1694  decode.d6.loss_dice: 0.1512  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.1684  decode.d7.loss_dice: 0.1507  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1685  decode.d8.loss_dice: 0.1508
10/01 01:17:08 - mmengine - INFO - Iter(train) [133150/320000]  base_lr: 6.1618e-05 lr: 6.1618e-06  eta: 22:43:36  time: 0.4399  data_time: 0.0095  memory: 5120  grad_norm: 62.6764  loss: 5.1149  decode.loss_cls: 0.0668  decode.loss_mask: 0.1905  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.8747  decode.d0.loss_mask: 0.1922  decode.d0.loss_dice: 0.1713  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.1939  decode.d1.loss_dice: 0.1789  decode.d2.loss_cls: 0.0741  decode.d2.loss_mask: 0.1927  decode.d2.loss_dice: 0.1739  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 0.1931  decode.d3.loss_dice: 0.1815  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 0.1911  decode.d4.loss_dice: 0.1806  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.1932  decode.d5.loss_dice: 0.1759  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.1910  decode.d6.loss_dice: 0.1731  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.1954  decode.d7.loss_dice: 0.1822  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.1911  decode.d8.loss_dice: 0.1712
10/01 01:17:30 - mmengine - INFO - Iter(train) [133200/320000]  base_lr: 6.1604e-05 lr: 6.1604e-06  eta: 22:43:14  time: 0.4396  data_time: 0.0096  memory: 5145  grad_norm: 30.5667  loss: 4.6146  decode.loss_cls: 0.0283  decode.loss_mask: 0.1989  decode.loss_dice: 0.1611  decode.d0.loss_cls: 0.7286  decode.d0.loss_mask: 0.1976  decode.d0.loss_dice: 0.1674  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.1955  decode.d1.loss_dice: 0.1666  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 0.1967  decode.d2.loss_dice: 0.1676  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.1958  decode.d3.loss_dice: 0.1617  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.1954  decode.d4.loss_dice: 0.1615  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.1974  decode.d5.loss_dice: 0.1648  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.1972  decode.d6.loss_dice: 0.1631  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.1958  decode.d7.loss_dice: 0.1650  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.1645
10/01 01:17:52 - mmengine - INFO - Iter(train) [133250/320000]  base_lr: 6.1589e-05 lr: 6.1589e-06  eta: 22:42:53  time: 0.4403  data_time: 0.0097  memory: 5120  grad_norm: 57.9857  loss: 5.9794  decode.loss_cls: 0.0650  decode.loss_mask: 0.2418  decode.loss_dice: 0.2168  decode.d0.loss_cls: 0.7472  decode.d0.loss_mask: 0.2469  decode.d0.loss_dice: 0.2280  decode.d1.loss_cls: 0.1354  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.2173  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.2454  decode.d2.loss_dice: 0.2167  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.2457  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.2438  decode.d4.loss_dice: 0.2142  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2181  decode.d6.loss_cls: 0.0668  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.2473  decode.d7.loss_dice: 0.2221  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.2433  decode.d8.loss_dice: 0.2289
10/01 01:18:14 - mmengine - INFO - Iter(train) [133300/320000]  base_lr: 6.1574e-05 lr: 6.1574e-06  eta: 22:42:31  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 125.5716  loss: 5.5628  decode.loss_cls: 0.0542  decode.loss_mask: 0.1981  decode.loss_dice: 0.2099  decode.d0.loss_cls: 0.8414  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.2056  decode.d1.loss_cls: 0.0913  decode.d1.loss_mask: 0.1972  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.0882  decode.d2.loss_mask: 0.1924  decode.d2.loss_dice: 0.2076  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.1972  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.2054  decode.d5.loss_dice: 0.2187  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.1952  decode.d6.loss_dice: 0.2064  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.2155  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.2255
10/01 01:18:36 - mmengine - INFO - Iter(train) [133350/320000]  base_lr: 6.1559e-05 lr: 6.1559e-06  eta: 22:42:09  time: 0.4408  data_time: 0.0097  memory: 5145  grad_norm: 36.8004  loss: 4.5335  decode.loss_cls: 0.0025  decode.loss_mask: 0.1869  decode.loss_dice: 0.1852  decode.d0.loss_cls: 0.8256  decode.d0.loss_mask: 0.1915  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.1889  decode.d1.loss_dice: 0.1574  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.1864  decode.d2.loss_dice: 0.1499  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1871  decode.d3.loss_dice: 0.1738  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.1874  decode.d4.loss_dice: 0.1565  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.1876  decode.d5.loss_dice: 0.1864  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.1738  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.2027  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.1885  decode.d8.loss_dice: 0.2013
10/01 01:18:58 - mmengine - INFO - Iter(train) [133400/320000]  base_lr: 6.1544e-05 lr: 6.1544e-06  eta: 22:41:47  time: 0.4394  data_time: 0.0095  memory: 5145  grad_norm: 60.2443  loss: 4.6182  decode.loss_cls: 0.0143  decode.loss_mask: 0.1928  decode.loss_dice: 0.1706  decode.d0.loss_cls: 0.8191  decode.d0.loss_mask: 0.2130  decode.d0.loss_dice: 0.1749  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.2060  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.1711  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.1926  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.1920  decode.d4.loss_dice: 0.1731  decode.d5.loss_cls: 0.0213  decode.d5.loss_mask: 0.1925  decode.d5.loss_dice: 0.1712  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.1935  decode.d6.loss_dice: 0.1703  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.1907  decode.d7.loss_dice: 0.1709  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.1875  decode.d8.loss_dice: 0.1687
10/01 01:19:20 - mmengine - INFO - Iter(train) [133450/320000]  base_lr: 6.1529e-05 lr: 6.1529e-06  eta: 22:41:26  time: 0.4406  data_time: 0.0099  memory: 5129  grad_norm: 42.1324  loss: 4.4404  decode.loss_cls: 0.0174  decode.loss_mask: 0.1733  decode.loss_dice: 0.1644  decode.d0.loss_cls: 0.8514  decode.d0.loss_mask: 0.1732  decode.d0.loss_dice: 0.1652  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.1749  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.1747  decode.d2.loss_dice: 0.1636  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.1728  decode.d3.loss_dice: 0.1606  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.1751  decode.d4.loss_dice: 0.1562  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.1749  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.1732  decode.d6.loss_dice: 0.1428  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.1744  decode.d7.loss_dice: 0.1610  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.1734  decode.d8.loss_dice: 0.1625
10/01 01:19:42 - mmengine - INFO - Iter(train) [133500/320000]  base_lr: 6.1514e-05 lr: 6.1514e-06  eta: 22:41:04  time: 0.4402  data_time: 0.0098  memory: 5120  grad_norm: 66.4207  loss: 4.4123  decode.loss_cls: 0.0300  decode.loss_mask: 0.1819  decode.loss_dice: 0.1493  decode.d0.loss_cls: 0.8248  decode.d0.loss_mask: 0.1815  decode.d0.loss_dice: 0.1412  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 0.1826  decode.d1.loss_dice: 0.1384  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.1796  decode.d2.loss_dice: 0.1359  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.1802  decode.d3.loss_dice: 0.1438  decode.d4.loss_cls: 0.0367  decode.d4.loss_mask: 0.1800  decode.d4.loss_dice: 0.1431  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.1814  decode.d5.loss_dice: 0.1484  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.1821  decode.d6.loss_dice: 0.1486  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.1816  decode.d7.loss_dice: 0.1417  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.1802  decode.d8.loss_dice: 0.1405
10/01 01:20:04 - mmengine - INFO - Iter(train) [133550/320000]  base_lr: 6.1500e-05 lr: 6.1500e-06  eta: 22:40:42  time: 0.4400  data_time: 0.0095  memory: 5145  grad_norm: 91.9070  loss: 5.3055  decode.loss_cls: 0.0632  decode.loss_mask: 0.1999  decode.loss_dice: 0.1965  decode.d0.loss_cls: 0.8231  decode.d0.loss_mask: 0.2189  decode.d0.loss_dice: 0.1931  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.2103  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1869  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.2001  decode.d3.loss_dice: 0.1665  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.2022  decode.d4.loss_dice: 0.1722  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.1998  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.2072  decode.d6.loss_dice: 0.2067  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.2079  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.2056  decode.d8.loss_dice: 0.2031
10/01 01:20:26 - mmengine - INFO - Iter(train) [133600/320000]  base_lr: 6.1485e-05 lr: 6.1485e-06  eta: 22:40:21  time: 0.4400  data_time: 0.0098  memory: 5129  grad_norm: 26.7983  loss: 5.1828  decode.loss_cls: 0.0102  decode.loss_mask: 0.2406  decode.loss_dice: 0.1797  decode.d0.loss_cls: 0.8141  decode.d0.loss_mask: 0.2422  decode.d0.loss_dice: 0.1865  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.2399  decode.d1.loss_dice: 0.1848  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.1871  decode.d3.loss_cls: 0.0103  decode.d3.loss_mask: 0.2398  decode.d3.loss_dice: 0.1823  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.2415  decode.d4.loss_dice: 0.1854  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.2420  decode.d5.loss_dice: 0.1975  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.1790  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.1830  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.2418  decode.d8.loss_dice: 0.1811
10/01 01:20:48 - mmengine - INFO - Iter(train) [133650/320000]  base_lr: 6.1470e-05 lr: 6.1470e-06  eta: 22:39:59  time: 0.4407  data_time: 0.0095  memory: 5145  grad_norm: 32.1206  loss: 5.0191  decode.loss_cls: 0.1033  decode.loss_mask: 0.1538  decode.loss_dice: 0.1788  decode.d0.loss_cls: 1.0297  decode.d0.loss_mask: 0.1531  decode.d0.loss_dice: 0.2146  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.1525  decode.d1.loss_dice: 0.1950  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.1535  decode.d2.loss_dice: 0.1933  decode.d3.loss_cls: 0.1019  decode.d3.loss_mask: 0.1518  decode.d3.loss_dice: 0.1859  decode.d4.loss_cls: 0.0446  decode.d4.loss_mask: 0.1530  decode.d4.loss_dice: 0.1892  decode.d5.loss_cls: 0.0546  decode.d5.loss_mask: 0.1534  decode.d5.loss_dice: 0.2118  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.1523  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.1516  decode.d7.loss_dice: 0.1968  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.1525  decode.d8.loss_dice: 0.1785
10/01 01:21:10 - mmengine - INFO - Iter(train) [133700/320000]  base_lr: 6.1455e-05 lr: 6.1455e-06  eta: 22:39:37  time: 0.4398  data_time: 0.0097  memory: 5145  grad_norm: 30.3852  loss: 4.0734  decode.loss_cls: 0.0081  decode.loss_mask: 0.1739  decode.loss_dice: 0.1448  decode.d0.loss_cls: 0.7958  decode.d0.loss_mask: 0.1756  decode.d0.loss_dice: 0.1354  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.1730  decode.d1.loss_dice: 0.1488  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.1736  decode.d2.loss_dice: 0.1481  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.1760  decode.d3.loss_dice: 0.1462  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.1756  decode.d4.loss_dice: 0.1508  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.1753  decode.d5.loss_dice: 0.1535  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.1711  decode.d6.loss_dice: 0.1404  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.1718  decode.d7.loss_dice: 0.1448  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.1750  decode.d8.loss_dice: 0.1418
10/01 01:21:32 - mmengine - INFO - Iter(train) [133750/320000]  base_lr: 6.1440e-05 lr: 6.1440e-06  eta: 22:39:15  time: 0.4395  data_time: 0.0095  memory: 5145  grad_norm: 24.1368  loss: 4.2158  decode.loss_cls: 0.0543  decode.loss_mask: 0.1468  decode.loss_dice: 0.1390  decode.d0.loss_cls: 0.9252  decode.d0.loss_mask: 0.1480  decode.d0.loss_dice: 0.1426  decode.d1.loss_cls: 0.0769  decode.d1.loss_mask: 0.1450  decode.d1.loss_dice: 0.1383  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.1450  decode.d2.loss_dice: 0.1361  decode.d3.loss_cls: 0.0419  decode.d3.loss_mask: 0.1479  decode.d3.loss_dice: 0.1407  decode.d4.loss_cls: 0.0428  decode.d4.loss_mask: 0.1473  decode.d4.loss_dice: 0.1403  decode.d5.loss_cls: 0.0445  decode.d5.loss_mask: 0.1463  decode.d5.loss_dice: 0.1351  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.1455  decode.d6.loss_dice: 0.1405  decode.d7.loss_cls: 0.0389  decode.d7.loss_mask: 0.1471  decode.d7.loss_dice: 0.1433  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.1453  decode.d8.loss_dice: 0.1376
10/01 01:21:54 - mmengine - INFO - Iter(train) [133800/320000]  base_lr: 6.1425e-05 lr: 6.1425e-06  eta: 22:38:54  time: 0.4401  data_time: 0.0096  memory: 5129  grad_norm: 27.6635  loss: 4.1169  decode.loss_cls: 0.0056  decode.loss_mask: 0.1877  decode.loss_dice: 0.1494  decode.d0.loss_cls: 0.7221  decode.d0.loss_mask: 0.1896  decode.d0.loss_dice: 0.1408  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.1877  decode.d1.loss_dice: 0.1484  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.1859  decode.d2.loss_dice: 0.1429  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.1892  decode.d3.loss_dice: 0.1488  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.1853  decode.d4.loss_dice: 0.1474  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.1880  decode.d5.loss_dice: 0.1529  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.1868  decode.d6.loss_dice: 0.1484  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.1860  decode.d7.loss_dice: 0.1437  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.1895  decode.d8.loss_dice: 0.1468
10/01 01:22:16 - mmengine - INFO - Iter(train) [133850/320000]  base_lr: 6.1411e-05 lr: 6.1411e-06  eta: 22:38:32  time: 0.4396  data_time: 0.0097  memory: 5129  grad_norm: 34.1918  loss: 5.5391  decode.loss_cls: 0.0962  decode.loss_mask: 0.1783  decode.loss_dice: 0.2051  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.1840  decode.d0.loss_dice: 0.2105  decode.d1.loss_cls: 0.0933  decode.d1.loss_mask: 0.1797  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.1791  decode.d2.loss_dice: 0.2070  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.1773  decode.d3.loss_dice: 0.2050  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.1789  decode.d4.loss_dice: 0.2033  decode.d5.loss_cls: 0.0879  decode.d5.loss_mask: 0.1757  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.1788  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 0.1802  decode.d7.loss_dice: 0.2057  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.1801  decode.d8.loss_dice: 0.2033
10/01 01:22:38 - mmengine - INFO - Iter(train) [133900/320000]  base_lr: 6.1396e-05 lr: 6.1396e-06  eta: 22:38:10  time: 0.4396  data_time: 0.0095  memory: 5129  grad_norm: 24.4076  loss: 4.1753  decode.loss_cls: 0.0020  decode.loss_mask: 0.1928  decode.loss_dice: 0.1434  decode.d0.loss_cls: 0.8035  decode.d0.loss_mask: 0.1961  decode.d0.loss_dice: 0.1511  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.1930  decode.d1.loss_dice: 0.1400  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.1398  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.1913  decode.d3.loss_dice: 0.1400  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.1912  decode.d4.loss_dice: 0.1362  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.1926  decode.d5.loss_dice: 0.1416  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.1392  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1951  decode.d7.loss_dice: 0.1413  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.1384
10/01 01:23:00 - mmengine - INFO - Iter(train) [133950/320000]  base_lr: 6.1381e-05 lr: 6.1381e-06  eta: 22:37:49  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 49.9610  loss: 5.7448  decode.loss_cls: 0.0570  decode.loss_mask: 0.2013  decode.loss_dice: 0.2181  decode.d0.loss_cls: 0.9350  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.1906  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.2196  decode.d2.loss_cls: 0.1257  decode.d2.loss_mask: 0.2017  decode.d2.loss_dice: 0.1806  decode.d3.loss_cls: 0.1115  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.1818  decode.d4.loss_cls: 0.0726  decode.d4.loss_mask: 0.2010  decode.d4.loss_dice: 0.2055  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.2060  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.2084  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.1973  decode.d7.loss_dice: 0.1843  decode.d8.loss_cls: 0.1130  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.1910
10/01 01:23:22 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:23:22 - mmengine - INFO - Iter(train) [134000/320000]  base_lr: 6.1366e-05 lr: 6.1366e-06  eta: 22:37:27  time: 0.4407  data_time: 0.0097  memory: 5145  grad_norm: 38.2906  loss: 4.7088  decode.loss_cls: 0.0580  decode.loss_mask: 0.1815  decode.loss_dice: 0.1430  decode.d0.loss_cls: 0.8073  decode.d0.loss_mask: 0.1842  decode.d0.loss_dice: 0.1407  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.1811  decode.d1.loss_dice: 0.1715  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.1806  decode.d2.loss_dice: 0.1497  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.1809  decode.d3.loss_dice: 0.1459  decode.d4.loss_cls: 0.0684  decode.d4.loss_mask: 0.1804  decode.d4.loss_dice: 0.1386  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.1794  decode.d5.loss_dice: 0.1368  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.1818  decode.d6.loss_dice: 0.1506  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.1608  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.1792  decode.d8.loss_dice: 0.1353
10/01 01:23:44 - mmengine - INFO - Iter(train) [134050/320000]  base_lr: 6.1351e-05 lr: 6.1351e-06  eta: 22:37:05  time: 0.4427  data_time: 0.0098  memory: 5129  grad_norm: 30.8964  loss: 5.1221  decode.loss_cls: 0.0047  decode.loss_mask: 0.2507  decode.loss_dice: 0.1932  decode.d0.loss_cls: 0.7569  decode.d0.loss_mask: 0.2552  decode.d0.loss_dice: 0.1882  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.2521  decode.d1.loss_dice: 0.1814  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.2485  decode.d3.loss_dice: 0.1890  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.1882  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2465  decode.d5.loss_dice: 0.1733  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.2506  decode.d6.loss_dice: 0.1758  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.1802  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.1820
10/01 01:24:06 - mmengine - INFO - Iter(train) [134100/320000]  base_lr: 6.1336e-05 lr: 6.1336e-06  eta: 22:36:43  time: 0.4452  data_time: 0.0099  memory: 5129  grad_norm: 327.3277  loss: 7.7403  decode.loss_cls: 0.2473  decode.loss_mask: 0.2693  decode.loss_dice: 0.2106  decode.d0.loss_cls: 0.8348  decode.d0.loss_mask: 0.2691  decode.d0.loss_dice: 0.2032  decode.d1.loss_cls: 0.2241  decode.d1.loss_mask: 0.2716  decode.d1.loss_dice: 0.2100  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2065  decode.d3.loss_cls: 0.2416  decode.d3.loss_mask: 0.2692  decode.d3.loss_dice: 0.2131  decode.d4.loss_cls: 0.2351  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.2047  decode.d5.loss_cls: 0.2077  decode.d5.loss_mask: 0.2696  decode.d5.loss_dice: 0.2012  decode.d6.loss_cls: 0.2450  decode.d6.loss_mask: 0.2708  decode.d6.loss_dice: 0.2078  decode.d7.loss_cls: 0.2494  decode.d7.loss_mask: 0.2731  decode.d7.loss_dice: 0.2112  decode.d8.loss_cls: 0.2527  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.2050
10/01 01:24:28 - mmengine - INFO - Iter(train) [134150/320000]  base_lr: 6.1321e-05 lr: 6.1321e-06  eta: 22:36:22  time: 0.4418  data_time: 0.0097  memory: 5145  grad_norm: 156.5495  loss: 7.9282  decode.loss_cls: 0.1591  decode.loss_mask: 0.3237  decode.loss_dice: 0.1849  decode.d0.loss_cls: 0.9664  decode.d0.loss_mask: 0.3273  decode.d0.loss_dice: 0.1772  decode.d1.loss_cls: 0.1899  decode.d1.loss_mask: 0.3426  decode.d1.loss_dice: 0.2159  decode.d2.loss_cls: 0.1808  decode.d2.loss_mask: 0.3196  decode.d2.loss_dice: 0.1880  decode.d3.loss_cls: 0.1649  decode.d3.loss_mask: 0.3222  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.1856  decode.d4.loss_mask: 0.3549  decode.d4.loss_dice: 0.2444  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 0.3828  decode.d5.loss_dice: 0.2055  decode.d6.loss_cls: 0.1774  decode.d6.loss_mask: 0.3250  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.1521  decode.d7.loss_mask: 0.3430  decode.d7.loss_dice: 0.2446  decode.d8.loss_cls: 0.1857  decode.d8.loss_mask: 0.3284  decode.d8.loss_dice: 0.2348
10/01 01:24:50 - mmengine - INFO - Iter(train) [134200/320000]  base_lr: 6.1307e-05 lr: 6.1307e-06  eta: 22:36:00  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 67.9829  loss: 7.5296  decode.loss_cls: 0.1812  decode.loss_mask: 0.2387  decode.loss_dice: 0.2428  decode.d0.loss_cls: 1.1240  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.2522  decode.d1.loss_cls: 0.2308  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.2157  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2400  decode.d3.loss_cls: 0.1546  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.2379  decode.d4.loss_cls: 0.1463  decode.d4.loss_mask: 0.2454  decode.d4.loss_dice: 0.2381  decode.d5.loss_cls: 0.1384  decode.d5.loss_mask: 0.2392  decode.d5.loss_dice: 0.2508  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.2411  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.1803  decode.d7.loss_mask: 0.2370  decode.d7.loss_dice: 0.2409  decode.d8.loss_cls: 0.1889  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.2305
10/01 01:25:12 - mmengine - INFO - Iter(train) [134250/320000]  base_lr: 6.1292e-05 lr: 6.1292e-06  eta: 22:35:38  time: 0.4404  data_time: 0.0098  memory: 5120  grad_norm: 381.0155  loss: 5.9824  decode.loss_cls: 0.0541  decode.loss_mask: 0.2223  decode.loss_dice: 0.2165  decode.d0.loss_cls: 0.8914  decode.d0.loss_mask: 0.2195  decode.d0.loss_dice: 0.2667  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.2189  decode.d2.loss_cls: 0.1196  decode.d2.loss_mask: 0.2269  decode.d2.loss_dice: 0.2720  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.2242  decode.d3.loss_dice: 0.2133  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2263  decode.d6.loss_cls: 0.0273  decode.d6.loss_mask: 0.2217  decode.d6.loss_dice: 0.2328  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.2203  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.2400
10/01 01:25:35 - mmengine - INFO - Iter(train) [134300/320000]  base_lr: 6.1277e-05 lr: 6.1277e-06  eta: 22:35:17  time: 0.4403  data_time: 0.0099  memory: 5145  grad_norm: 70.8068  loss: 5.2445  decode.loss_cls: 0.0452  decode.loss_mask: 0.1911  decode.loss_dice: 0.1912  decode.d0.loss_cls: 0.8586  decode.d0.loss_mask: 0.1918  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.1090  decode.d1.loss_mask: 0.1866  decode.d1.loss_dice: 0.1763  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 0.1902  decode.d3.loss_dice: 0.1768  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.1873  decode.d4.loss_dice: 0.1724  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.1899  decode.d5.loss_dice: 0.1856  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.1895  decode.d6.loss_dice: 0.1937  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.1651  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.1867  decode.d8.loss_dice: 0.1952
10/01 01:25:57 - mmengine - INFO - Iter(train) [134350/320000]  base_lr: 6.1262e-05 lr: 6.1262e-06  eta: 22:34:55  time: 0.4403  data_time: 0.0096  memory: 5145  grad_norm: 92.5642  loss: 6.2387  decode.loss_cls: 0.0679  decode.loss_mask: 0.2537  decode.loss_dice: 0.2174  decode.d0.loss_cls: 0.9867  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.1965  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.2660  decode.d1.loss_dice: 0.2358  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.2002  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.2008  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.2534  decode.d4.loss_dice: 0.2052  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.2037  decode.d6.loss_cls: 0.0727  decode.d6.loss_mask: 0.2541  decode.d6.loss_dice: 0.2086  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.2011  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.2050
10/01 01:26:19 - mmengine - INFO - Iter(train) [134400/320000]  base_lr: 6.1247e-05 lr: 6.1247e-06  eta: 22:34:33  time: 0.4409  data_time: 0.0098  memory: 5145  grad_norm: 25.7892  loss: 4.5879  decode.loss_cls: 0.0007  decode.loss_mask: 0.2145  decode.loss_dice: 0.1630  decode.d0.loss_cls: 0.7806  decode.d0.loss_mask: 0.2149  decode.d0.loss_dice: 0.1571  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.2152  decode.d1.loss_dice: 0.1659  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.2131  decode.d2.loss_dice: 0.1648  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2156  decode.d3.loss_dice: 0.1646  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2143  decode.d4.loss_dice: 0.1623  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.1685  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2167  decode.d6.loss_dice: 0.1625  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2157  decode.d7.loss_dice: 0.1655  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.1627
10/01 01:26:41 - mmengine - INFO - Iter(train) [134450/320000]  base_lr: 6.1232e-05 lr: 6.1232e-06  eta: 22:34:12  time: 0.4419  data_time: 0.0097  memory: 5145  grad_norm: 22.0752  loss: 4.2020  decode.loss_cls: 0.0039  decode.loss_mask: 0.1868  decode.loss_dice: 0.1549  decode.d0.loss_cls: 0.7607  decode.d0.loss_mask: 0.1867  decode.d0.loss_dice: 0.1530  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.1843  decode.d1.loss_dice: 0.1548  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1874  decode.d2.loss_dice: 0.1557  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.1563  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.1853  decode.d4.loss_dice: 0.1546  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.1844  decode.d5.loss_dice: 0.1534  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.1854  decode.d6.loss_dice: 0.1519  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1876  decode.d7.loss_dice: 0.1550  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1865  decode.d8.loss_dice: 0.1531
10/01 01:27:03 - mmengine - INFO - Iter(train) [134500/320000]  base_lr: 6.1218e-05 lr: 6.1218e-06  eta: 22:33:50  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 102.9758  loss: 5.4262  decode.loss_cls: 0.1306  decode.loss_mask: 0.1982  decode.loss_dice: 0.1780  decode.d0.loss_cls: 0.8701  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1764  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 0.1970  decode.d1.loss_dice: 0.1708  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.1979  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.1769  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.1957  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.1962  decode.d5.loss_dice: 0.1740  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.1964  decode.d6.loss_dice: 0.1780  decode.d7.loss_cls: 0.1442  decode.d7.loss_mask: 0.1976  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.1751
10/01 01:27:25 - mmengine - INFO - Iter(train) [134550/320000]  base_lr: 6.1203e-05 lr: 6.1203e-06  eta: 22:33:28  time: 0.4405  data_time: 0.0097  memory: 5145  grad_norm: 55.5020  loss: 5.1875  decode.loss_cls: 0.0432  decode.loss_mask: 0.2178  decode.loss_dice: 0.1747  decode.d0.loss_cls: 0.8089  decode.d0.loss_mask: 0.2179  decode.d0.loss_dice: 0.1830  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.2171  decode.d1.loss_dice: 0.1696  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.1738  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.2173  decode.d3.loss_dice: 0.1815  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.2202  decode.d4.loss_dice: 0.1753  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.1725  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.2178  decode.d6.loss_dice: 0.1872  decode.d7.loss_cls: 0.0461  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.1804  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.2145  decode.d8.loss_dice: 0.1769
10/01 01:27:47 - mmengine - INFO - Iter(train) [134600/320000]  base_lr: 6.1188e-05 lr: 6.1188e-06  eta: 22:33:06  time: 0.4412  data_time: 0.0096  memory: 5129  grad_norm: 24.7959  loss: 4.7683  decode.loss_cls: 0.0875  decode.loss_mask: 0.1458  decode.loss_dice: 0.1224  decode.d0.loss_cls: 0.9765  decode.d0.loss_mask: 0.1538  decode.d0.loss_dice: 0.1425  decode.d1.loss_cls: 0.1091  decode.d1.loss_mask: 0.1837  decode.d1.loss_dice: 0.1506  decode.d2.loss_cls: 0.1138  decode.d2.loss_mask: 0.1461  decode.d2.loss_dice: 0.1233  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.1502  decode.d3.loss_dice: 0.1256  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.1502  decode.d4.loss_dice: 0.1211  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 0.1444  decode.d5.loss_dice: 0.1212  decode.d6.loss_cls: 0.1149  decode.d6.loss_mask: 0.1463  decode.d6.loss_dice: 0.1255  decode.d7.loss_cls: 0.1249  decode.d7.loss_mask: 0.1439  decode.d7.loss_dice: 0.1196  decode.d8.loss_cls: 0.1311  decode.d8.loss_mask: 0.1449  decode.d8.loss_dice: 0.1220
10/01 01:28:09 - mmengine - INFO - Iter(train) [134650/320000]  base_lr: 6.1173e-05 lr: 6.1173e-06  eta: 22:32:45  time: 0.4402  data_time: 0.0097  memory: 5129  grad_norm: 56.4899  loss: 5.1952  decode.loss_cls: 0.0100  decode.loss_mask: 0.2407  decode.loss_dice: 0.1833  decode.d0.loss_cls: 0.7635  decode.d0.loss_mask: 0.2439  decode.d0.loss_dice: 0.1800  decode.d1.loss_cls: 0.0388  decode.d1.loss_mask: 0.2414  decode.d1.loss_dice: 0.1863  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.1891  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.1972  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.2516  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.2405  decode.d5.loss_dice: 0.1849  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.2412  decode.d6.loss_dice: 0.1849  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.1851  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.2405  decode.d8.loss_dice: 0.1903
10/01 01:28:31 - mmengine - INFO - Iter(train) [134700/320000]  base_lr: 6.1158e-05 lr: 6.1158e-06  eta: 22:32:23  time: 0.4397  data_time: 0.0096  memory: 5120  grad_norm: 28.1445  loss: 3.7778  decode.loss_cls: 0.0021  decode.loss_mask: 0.1597  decode.loss_dice: 0.1369  decode.d0.loss_cls: 0.7494  decode.d0.loss_mask: 0.1621  decode.d0.loss_dice: 0.1376  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.1615  decode.d1.loss_dice: 0.1386  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1623  decode.d2.loss_dice: 0.1374  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.1615  decode.d3.loss_dice: 0.1427  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.1600  decode.d4.loss_dice: 0.1386  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.1617  decode.d5.loss_dice: 0.1423  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1631  decode.d6.loss_dice: 0.1359  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1621  decode.d7.loss_dice: 0.1399  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.1610  decode.d8.loss_dice: 0.1361
10/01 01:28:53 - mmengine - INFO - Iter(train) [134750/320000]  base_lr: 6.1143e-05 lr: 6.1143e-06  eta: 22:32:01  time: 0.4397  data_time: 0.0095  memory: 5159  grad_norm: 26.9272  loss: 4.3522  decode.loss_cls: 0.0085  decode.loss_mask: 0.1672  decode.loss_dice: 0.1669  decode.d0.loss_cls: 0.7829  decode.d0.loss_mask: 0.1664  decode.d0.loss_dice: 0.1613  decode.d1.loss_cls: 0.0569  decode.d1.loss_mask: 0.1700  decode.d1.loss_dice: 0.1816  decode.d2.loss_cls: 0.0330  decode.d2.loss_mask: 0.1694  decode.d2.loss_dice: 0.1713  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.1678  decode.d3.loss_dice: 0.1679  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.1684  decode.d4.loss_dice: 0.1606  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.1677  decode.d5.loss_dice: 0.1581  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.1682  decode.d6.loss_dice: 0.1509  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.1657  decode.d7.loss_dice: 0.1804  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.1655  decode.d8.loss_dice: 0.1585
10/01 01:29:15 - mmengine - INFO - Iter(train) [134800/320000]  base_lr: 6.1128e-05 lr: 6.1128e-06  eta: 22:31:40  time: 0.4401  data_time: 0.0094  memory: 5129  grad_norm: 25.1604  loss: 4.7669  decode.loss_cls: 0.0040  decode.loss_mask: 0.2078  decode.loss_dice: 0.1820  decode.d0.loss_cls: 0.8354  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.1716  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.1796  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2073  decode.d2.loss_dice: 0.1820  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.2084  decode.d3.loss_dice: 0.1808  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.2083  decode.d4.loss_dice: 0.1836  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2087  decode.d5.loss_dice: 0.1793  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.2109  decode.d6.loss_dice: 0.1805  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.2112  decode.d7.loss_dice: 0.1821  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.2077  decode.d8.loss_dice: 0.1805
10/01 01:29:37 - mmengine - INFO - Iter(train) [134850/320000]  base_lr: 6.1114e-05 lr: 6.1114e-06  eta: 22:31:18  time: 0.4399  data_time: 0.0093  memory: 5119  grad_norm: 43.1164  loss: 4.9533  decode.loss_cls: 0.0437  decode.loss_mask: 0.2079  decode.loss_dice: 0.2163  decode.d0.loss_cls: 0.8557  decode.d0.loss_mask: 0.2065  decode.d0.loss_dice: 0.1788  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.2063  decode.d1.loss_dice: 0.1717  decode.d2.loss_cls: 0.0226  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.2057  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1908  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.1835  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.1815  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.2056  decode.d6.loss_dice: 0.1786  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.2067  decode.d8.loss_dice: 0.1871
10/01 01:29:59 - mmengine - INFO - Iter(train) [134900/320000]  base_lr: 6.1099e-05 lr: 6.1099e-06  eta: 22:30:57  time: 0.4414  data_time: 0.0095  memory: 5129  grad_norm: 37.6922  loss: 5.7757  decode.loss_cls: 0.0796  decode.loss_mask: 0.1976  decode.loss_dice: 0.2097  decode.d0.loss_cls: 1.0127  decode.d0.loss_mask: 0.2024  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.0843  decode.d1.loss_mask: 0.1993  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.1962  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.1967  decode.d3.loss_dice: 0.2050  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.1971  decode.d4.loss_dice: 0.2175  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.1972  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.1978  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0657  decode.d7.loss_mask: 0.1969  decode.d7.loss_dice: 0.2061  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.1951  decode.d8.loss_dice: 0.1997
10/01 01:30:22 - mmengine - INFO - Iter(train) [134950/320000]  base_lr: 6.1084e-05 lr: 6.1084e-06  eta: 22:30:35  time: 0.4420  data_time: 0.0098  memory: 5129  grad_norm: 17.2721  loss: 3.9522  decode.loss_cls: 0.0048  decode.loss_mask: 0.1596  decode.loss_dice: 0.1558  decode.d0.loss_cls: 0.8143  decode.d0.loss_mask: 0.1610  decode.d0.loss_dice: 0.1435  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.1597  decode.d1.loss_dice: 0.1430  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.1586  decode.d2.loss_dice: 0.1455  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.1608  decode.d3.loss_dice: 0.1511  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.1592  decode.d4.loss_dice: 0.1669  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.1590  decode.d5.loss_dice: 0.1396  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.1606  decode.d6.loss_dice: 0.1622  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.1598  decode.d7.loss_dice: 0.1449  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.1584  decode.d8.loss_dice: 0.1448
10/01 01:30:44 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:30:44 - mmengine - INFO - Iter(train) [135000/320000]  base_lr: 6.1069e-05 lr: 6.1069e-06  eta: 22:30:13  time: 0.4418  data_time: 0.0095  memory: 5145  grad_norm: 68.2318  loss: 4.4157  decode.loss_cls: 0.0503  decode.loss_mask: 0.1681  decode.loss_dice: 0.1902  decode.d0.loss_cls: 0.7480  decode.d0.loss_mask: 0.1710  decode.d0.loss_dice: 0.1776  decode.d1.loss_cls: 0.0202  decode.d1.loss_mask: 0.1707  decode.d1.loss_dice: 0.1509  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.1708  decode.d2.loss_dice: 0.1812  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.1695  decode.d3.loss_dice: 0.1743  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.1706  decode.d4.loss_dice: 0.1547  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.1676  decode.d5.loss_dice: 0.1738  decode.d6.loss_cls: 0.0294  decode.d6.loss_mask: 0.1694  decode.d6.loss_dice: 0.1486  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.1695  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.1695  decode.d8.loss_dice: 0.1685
10/01 01:31:06 - mmengine - INFO - Iter(train) [135050/320000]  base_lr: 6.1054e-05 lr: 6.1054e-06  eta: 22:29:52  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 24.3132  loss: 4.0581  decode.loss_cls: 0.0036  decode.loss_mask: 0.1801  decode.loss_dice: 0.1499  decode.d0.loss_cls: 0.7522  decode.d0.loss_mask: 0.1805  decode.d0.loss_dice: 0.1445  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.1790  decode.d1.loss_dice: 0.1549  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.1791  decode.d2.loss_dice: 0.1468  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.1763  decode.d3.loss_dice: 0.1420  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1765  decode.d4.loss_dice: 0.1542  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.1785  decode.d5.loss_dice: 0.1535  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.1783  decode.d6.loss_dice: 0.1522  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.1777  decode.d7.loss_dice: 0.1480  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.1734  decode.d8.loss_dice: 0.1431
10/01 01:31:28 - mmengine - INFO - Iter(train) [135100/320000]  base_lr: 6.1039e-05 lr: 6.1039e-06  eta: 22:29:30  time: 0.4407  data_time: 0.0092  memory: 5145  grad_norm: 58.4649  loss: 5.1178  decode.loss_cls: 0.0949  decode.loss_mask: 0.1820  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.9227  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.1897  decode.d1.loss_cls: 0.0975  decode.d1.loss_mask: 0.1823  decode.d1.loss_dice: 0.1417  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.1824  decode.d2.loss_dice: 0.1437  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.1997  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.1812  decode.d4.loss_dice: 0.1891  decode.d5.loss_cls: 0.0842  decode.d5.loss_mask: 0.1835  decode.d5.loss_dice: 0.1938  decode.d6.loss_cls: 0.0865  decode.d6.loss_mask: 0.1822  decode.d6.loss_dice: 0.1844  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.1825  decode.d7.loss_dice: 0.1751  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.1813  decode.d8.loss_dice: 0.1602
10/01 01:31:50 - mmengine - INFO - Iter(train) [135150/320000]  base_lr: 6.1024e-05 lr: 6.1024e-06  eta: 22:29:08  time: 0.4400  data_time: 0.0094  memory: 5129  grad_norm: 45.3720  loss: 4.9383  decode.loss_cls: 0.0313  decode.loss_mask: 0.2149  decode.loss_dice: 0.1720  decode.d0.loss_cls: 0.7828  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.1595  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.2145  decode.d2.loss_dice: 0.1588  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.1644  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.2138  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.2126  decode.d5.loss_dice: 0.1642  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.2143  decode.d6.loss_dice: 0.1667  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 0.2130  decode.d7.loss_dice: 0.1648  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.2127  decode.d8.loss_dice: 0.1629
10/01 01:32:12 - mmengine - INFO - Iter(train) [135200/320000]  base_lr: 6.1010e-05 lr: 6.1010e-06  eta: 22:28:47  time: 0.4388  data_time: 0.0094  memory: 5145  grad_norm: 36.2730  loss: 4.5025  decode.loss_cls: 0.0034  decode.loss_mask: 0.2009  decode.loss_dice: 0.1740  decode.d0.loss_cls: 0.6873  decode.d0.loss_mask: 0.2069  decode.d0.loss_dice: 0.1777  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.2050  decode.d1.loss_dice: 0.1737  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.1757  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2030  decode.d3.loss_dice: 0.1738  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2031  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.1708  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.2055  decode.d6.loss_dice: 0.1783  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2012  decode.d7.loss_dice: 0.1672  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1783
10/01 01:32:34 - mmengine - INFO - Iter(train) [135250/320000]  base_lr: 6.0995e-05 lr: 6.0995e-06  eta: 22:28:25  time: 0.4404  data_time: 0.0097  memory: 5120  grad_norm: 84.6823  loss: 6.4699  decode.loss_cls: 0.1173  decode.loss_mask: 0.1996  decode.loss_dice: 0.2678  decode.d0.loss_cls: 0.8178  decode.d0.loss_mask: 0.2027  decode.d0.loss_dice: 0.2914  decode.d1.loss_cls: 0.1117  decode.d1.loss_mask: 0.1993  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 0.1987  decode.d2.loss_dice: 0.2519  decode.d3.loss_cls: 0.0994  decode.d3.loss_mask: 0.2019  decode.d3.loss_dice: 0.2670  decode.d4.loss_cls: 0.1263  decode.d4.loss_mask: 0.1969  decode.d4.loss_dice: 0.2548  decode.d5.loss_cls: 0.1286  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.2617  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.2573  decode.d7.loss_cls: 0.1136  decode.d7.loss_mask: 0.1974  decode.d7.loss_dice: 0.2520  decode.d8.loss_cls: 0.1299  decode.d8.loss_mask: 0.1960  decode.d8.loss_dice: 0.2576
10/01 01:32:56 - mmengine - INFO - Iter(train) [135300/320000]  base_lr: 6.0980e-05 lr: 6.0980e-06  eta: 22:28:03  time: 0.4455  data_time: 0.0097  memory: 5129  grad_norm: 60.2873  loss: 5.1792  decode.loss_cls: 0.0602  decode.loss_mask: 0.1749  decode.loss_dice: 0.1944  decode.d0.loss_cls: 0.8818  decode.d0.loss_mask: 0.1771  decode.d0.loss_dice: 0.1665  decode.d1.loss_cls: 0.1094  decode.d1.loss_mask: 0.1773  decode.d1.loss_dice: 0.1998  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.1744  decode.d2.loss_dice: 0.1653  decode.d3.loss_cls: 0.1461  decode.d3.loss_mask: 0.1748  decode.d3.loss_dice: 0.1807  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.1766  decode.d4.loss_dice: 0.1776  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.1765  decode.d5.loss_dice: 0.1646  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.1758  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.1774  decode.d8.loss_dice: 0.1924
10/01 01:33:18 - mmengine - INFO - Iter(train) [135350/320000]  base_lr: 6.0965e-05 lr: 6.0965e-06  eta: 22:27:42  time: 0.4422  data_time: 0.0098  memory: 5120  grad_norm: 44.0850  loss: 4.4449  decode.loss_cls: 0.0186  decode.loss_mask: 0.1969  decode.loss_dice: 0.1452  decode.d0.loss_cls: 0.7956  decode.d0.loss_mask: 0.1960  decode.d0.loss_dice: 0.1405  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.1976  decode.d1.loss_dice: 0.1476  decode.d2.loss_cls: 0.0134  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.1470  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.1977  decode.d3.loss_dice: 0.1459  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.1971  decode.d4.loss_dice: 0.1445  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.1971  decode.d5.loss_dice: 0.1435  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.1970  decode.d6.loss_dice: 0.1428  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.1471  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.1457
10/01 01:33:40 - mmengine - INFO - Iter(train) [135400/320000]  base_lr: 6.0950e-05 lr: 6.0950e-06  eta: 22:27:20  time: 0.4426  data_time: 0.0096  memory: 5120  grad_norm: 53.5364  loss: 4.3881  decode.loss_cls: 0.0091  decode.loss_mask: 0.1767  decode.loss_dice: 0.1673  decode.d0.loss_cls: 0.7399  decode.d0.loss_mask: 0.1725  decode.d0.loss_dice: 0.1621  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.1774  decode.d1.loss_dice: 0.1657  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.1771  decode.d2.loss_dice: 0.1643  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.1778  decode.d3.loss_dice: 0.1690  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.1776  decode.d4.loss_dice: 0.1663  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.1812  decode.d5.loss_dice: 0.1691  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.1791  decode.d6.loss_dice: 0.1646  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.1763  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.1748  decode.d8.loss_dice: 0.1585
10/01 01:34:02 - mmengine - INFO - Iter(train) [135450/320000]  base_lr: 6.0935e-05 lr: 6.0935e-06  eta: 22:26:58  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 83.8811  loss: 5.7282  decode.loss_cls: 0.0903  decode.loss_mask: 0.2155  decode.loss_dice: 0.1952  decode.d0.loss_cls: 0.8342  decode.d0.loss_mask: 0.2310  decode.d0.loss_dice: 0.2099  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 0.2106  decode.d1.loss_dice: 0.1934  decode.d2.loss_cls: 0.0551  decode.d2.loss_mask: 0.2177  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.2162  decode.d3.loss_dice: 0.1825  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.2129  decode.d5.loss_cls: 0.0245  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.2185  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2110  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.2078  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.2126  decode.d8.loss_dice: 0.1969
10/01 01:34:24 - mmengine - INFO - Iter(train) [135500/320000]  base_lr: 6.0920e-05 lr: 6.0920e-06  eta: 22:26:37  time: 0.4400  data_time: 0.0097  memory: 5129  grad_norm: 27.8090  loss: 4.1857  decode.loss_cls: 0.0035  decode.loss_mask: 0.2058  decode.loss_dice: 0.1403  decode.d0.loss_cls: 0.7044  decode.d0.loss_mask: 0.2063  decode.d0.loss_dice: 0.1353  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2036  decode.d1.loss_dice: 0.1368  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.1377  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1406  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.1361  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.2095  decode.d5.loss_dice: 0.1402  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.2067  decode.d6.loss_dice: 0.1376  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1379  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.1375
10/01 01:34:47 - mmengine - INFO - Iter(train) [135550/320000]  base_lr: 6.0906e-05 lr: 6.0906e-06  eta: 22:26:15  time: 0.4406  data_time: 0.0096  memory: 5145  grad_norm: 76.2897  loss: 7.2719  decode.loss_cls: 0.2347  decode.loss_mask: 0.2198  decode.loss_dice: 0.2558  decode.d0.loss_cls: 0.9153  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.2305  decode.d1.loss_cls: 0.1380  decode.d1.loss_mask: 0.2402  decode.d1.loss_dice: 0.2469  decode.d2.loss_cls: 0.2371  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.2451  decode.d3.loss_cls: 0.2224  decode.d3.loss_mask: 0.2218  decode.d3.loss_dice: 0.2579  decode.d4.loss_cls: 0.1517  decode.d4.loss_mask: 0.2419  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.2374  decode.d6.loss_cls: 0.1683  decode.d6.loss_mask: 0.2053  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.1761  decode.d7.loss_mask: 0.2273  decode.d7.loss_dice: 0.2310  decode.d8.loss_cls: 0.2008  decode.d8.loss_mask: 0.2304  decode.d8.loss_dice: 0.2355
10/01 01:35:09 - mmengine - INFO - Iter(train) [135600/320000]  base_lr: 6.0891e-05 lr: 6.0891e-06  eta: 22:25:53  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 98.0696  loss: 6.3215  decode.loss_cls: 0.0661  decode.loss_mask: 0.2541  decode.loss_dice: 0.2201  decode.d0.loss_cls: 0.8931  decode.d0.loss_mask: 0.2709  decode.d0.loss_dice: 0.2361  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2200  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.2555  decode.d2.loss_dice: 0.2214  decode.d3.loss_cls: 0.0786  decode.d3.loss_mask: 0.2651  decode.d3.loss_dice: 0.2213  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.2194  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.2119  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2216  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.2606  decode.d7.loss_dice: 0.2298  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.2667  decode.d8.loss_dice: 0.2113
10/01 01:35:31 - mmengine - INFO - Iter(train) [135650/320000]  base_lr: 6.0876e-05 lr: 6.0876e-06  eta: 22:25:32  time: 0.4402  data_time: 0.0098  memory: 5129  grad_norm: 91.7399  loss: 5.1695  decode.loss_cls: 0.0779  decode.loss_mask: 0.1934  decode.loss_dice: 0.1816  decode.d0.loss_cls: 0.8037  decode.d0.loss_mask: 0.1964  decode.d0.loss_dice: 0.1631  decode.d1.loss_cls: 0.0495  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.1917  decode.d2.loss_dice: 0.1673  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.1938  decode.d3.loss_dice: 0.1814  decode.d4.loss_cls: 0.0974  decode.d4.loss_mask: 0.1935  decode.d4.loss_dice: 0.1641  decode.d5.loss_cls: 0.0748  decode.d5.loss_mask: 0.1913  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.1941  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.1938  decode.d7.loss_dice: 0.1717  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.1606
10/01 01:35:53 - mmengine - INFO - Iter(train) [135700/320000]  base_lr: 6.0861e-05 lr: 6.0861e-06  eta: 22:25:10  time: 0.4411  data_time: 0.0099  memory: 5145  grad_norm: 87.0784  loss: 5.6457  decode.loss_cls: 0.0951  decode.loss_mask: 0.2232  decode.loss_dice: 0.1836  decode.d0.loss_cls: 0.8269  decode.d0.loss_mask: 0.2237  decode.d0.loss_dice: 0.1962  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.2276  decode.d2.loss_dice: 0.1946  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.1915  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.1955  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.2222  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.0686  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.1951  decode.d8.loss_cls: 0.0906  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.1969
10/01 01:36:15 - mmengine - INFO - Iter(train) [135750/320000]  base_lr: 6.0846e-05 lr: 6.0846e-06  eta: 22:24:48  time: 0.4447  data_time: 0.0095  memory: 5145  grad_norm: 55.6186  loss: 5.6654  decode.loss_cls: 0.0778  decode.loss_mask: 0.2133  decode.loss_dice: 0.2172  decode.d0.loss_cls: 0.7191  decode.d0.loss_mask: 0.2181  decode.d0.loss_dice: 0.2261  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.2166  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.0518  decode.d2.loss_mask: 0.2190  decode.d2.loss_dice: 0.2209  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.2163  decode.d5.loss_cls: 0.0729  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.2175  decode.d6.loss_dice: 0.2079  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.2099  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.2186  decode.d8.loss_dice: 0.2084
10/01 01:36:37 - mmengine - INFO - Iter(train) [135800/320000]  base_lr: 6.0831e-05 lr: 6.0831e-06  eta: 22:24:27  time: 0.4427  data_time: 0.0097  memory: 5159  grad_norm: 42.8730  loss: 6.7773  decode.loss_cls: 0.1533  decode.loss_mask: 0.2172  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.9479  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.2175  decode.d1.loss_cls: 0.1741  decode.d1.loss_mask: 0.2193  decode.d1.loss_dice: 0.2142  decode.d2.loss_cls: 0.1534  decode.d2.loss_mask: 0.2243  decode.d2.loss_dice: 0.2019  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 0.2163  decode.d3.loss_dice: 0.2149  decode.d4.loss_cls: 0.1654  decode.d4.loss_mask: 0.2196  decode.d4.loss_dice: 0.2129  decode.d5.loss_cls: 0.1538  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.2121  decode.d6.loss_cls: 0.1617  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.2087  decode.d7.loss_cls: 0.1609  decode.d7.loss_mask: 0.2188  decode.d7.loss_dice: 0.2260  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.2486
10/01 01:36:59 - mmengine - INFO - Iter(train) [135850/320000]  base_lr: 6.0816e-05 lr: 6.0816e-06  eta: 22:24:05  time: 0.4420  data_time: 0.0095  memory: 5145  grad_norm: 41.5562  loss: 4.2736  decode.loss_cls: 0.0020  decode.loss_mask: 0.1605  decode.loss_dice: 0.1809  decode.d0.loss_cls: 0.8091  decode.d0.loss_mask: 0.1586  decode.d0.loss_dice: 0.1917  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.1592  decode.d1.loss_dice: 0.1905  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.1613  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.1607  decode.d3.loss_dice: 0.1810  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.1587  decode.d4.loss_dice: 0.1793  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.1609  decode.d5.loss_dice: 0.1821  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.1606  decode.d6.loss_dice: 0.1831  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.1629  decode.d7.loss_dice: 0.1856  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.1620  decode.d8.loss_dice: 0.1835
10/01 01:37:21 - mmengine - INFO - Iter(train) [135900/320000]  base_lr: 6.0802e-05 lr: 6.0802e-06  eta: 22:23:44  time: 0.4420  data_time: 0.0096  memory: 5129  grad_norm: 41.1074  loss: 4.7541  decode.loss_cls: 0.0352  decode.loss_mask: 0.1956  decode.loss_dice: 0.1481  decode.d0.loss_cls: 0.8026  decode.d0.loss_mask: 0.1959  decode.d0.loss_dice: 0.1858  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.1947  decode.d1.loss_dice: 0.1836  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.1953  decode.d2.loss_dice: 0.1458  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.1627  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.1955  decode.d4.loss_dice: 0.1721  decode.d5.loss_cls: 0.0240  decode.d5.loss_mask: 0.1950  decode.d5.loss_dice: 0.1472  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.1965  decode.d6.loss_dice: 0.1701  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.1960  decode.d7.loss_dice: 0.1525  decode.d8.loss_cls: 0.0316  decode.d8.loss_mask: 0.1956  decode.d8.loss_dice: 0.1824
10/01 01:37:43 - mmengine - INFO - Iter(train) [135950/320000]  base_lr: 6.0787e-05 lr: 6.0787e-06  eta: 22:23:22  time: 0.4408  data_time: 0.0098  memory: 5145  grad_norm: 109.8153  loss: 5.6952  decode.loss_cls: 0.1319  decode.loss_mask: 0.1856  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.8343  decode.d0.loss_mask: 0.1883  decode.d0.loss_dice: 0.2037  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.1846  decode.d1.loss_dice: 0.2019  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 0.1848  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.1883  decode.d3.loss_dice: 0.2077  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.1868  decode.d4.loss_dice: 0.1937  decode.d5.loss_cls: 0.1107  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 0.1843  decode.d6.loss_dice: 0.2042  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.1880  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.1447  decode.d8.loss_mask: 0.1879  decode.d8.loss_dice: 0.2162
10/01 01:38:05 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:38:05 - mmengine - INFO - Iter(train) [136000/320000]  base_lr: 6.0772e-05 lr: 6.0772e-06  eta: 22:23:00  time: 0.4414  data_time: 0.0095  memory: 5129  grad_norm: 33.4553  loss: 4.1057  decode.loss_cls: 0.0037  decode.loss_mask: 0.1852  decode.loss_dice: 0.1391  decode.d0.loss_cls: 0.8027  decode.d0.loss_mask: 0.1880  decode.d0.loss_dice: 0.1339  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.1864  decode.d1.loss_dice: 0.1404  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.1845  decode.d2.loss_dice: 0.1442  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.1851  decode.d3.loss_dice: 0.1368  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.1870  decode.d4.loss_dice: 0.1379  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.1418  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.1851  decode.d6.loss_dice: 0.1440  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.1863  decode.d7.loss_dice: 0.1379  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.1819  decode.d8.loss_dice: 0.1413
10/01 01:38:27 - mmengine - INFO - Iter(train) [136050/320000]  base_lr: 6.0757e-05 lr: 6.0757e-06  eta: 22:22:38  time: 0.4408  data_time: 0.0098  memory: 5145  grad_norm: 29.5444  loss: 5.3404  decode.loss_cls: 0.0706  decode.loss_mask: 0.2029  decode.loss_dice: 0.1864  decode.d0.loss_cls: 0.8813  decode.d0.loss_mask: 0.2053  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.2043  decode.d1.loss_dice: 0.1949  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.2217  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.2049  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.2037  decode.d6.loss_dice: 0.2013  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.1813  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.2076
10/01 01:38:49 - mmengine - INFO - Iter(train) [136100/320000]  base_lr: 6.0742e-05 lr: 6.0742e-06  eta: 22:22:17  time: 0.4407  data_time: 0.0093  memory: 5145  grad_norm: 32.8654  loss: 4.4484  decode.loss_cls: 0.0006  decode.loss_mask: 0.1826  decode.loss_dice: 0.1803  decode.d0.loss_cls: 0.8569  decode.d0.loss_mask: 0.1845  decode.d0.loss_dice: 0.1697  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.1821  decode.d1.loss_dice: 0.1784  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.1831  decode.d2.loss_dice: 0.1767  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.1822  decode.d3.loss_dice: 0.1785  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.1797  decode.d4.loss_dice: 0.1758  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.1798  decode.d5.loss_dice: 0.1725  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.1806  decode.d6.loss_dice: 0.1757  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.1813  decode.d7.loss_dice: 0.1756  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.1837  decode.d8.loss_dice: 0.1741
10/01 01:39:12 - mmengine - INFO - Iter(train) [136150/320000]  base_lr: 6.0727e-05 lr: 6.0727e-06  eta: 22:21:55  time: 0.4417  data_time: 0.0094  memory: 5145  grad_norm: 41.1082  loss: 4.4619  decode.loss_cls: 0.0034  decode.loss_mask: 0.1826  decode.loss_dice: 0.1759  decode.d0.loss_cls: 0.7998  decode.d0.loss_mask: 0.1861  decode.d0.loss_dice: 0.1763  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.1870  decode.d1.loss_dice: 0.1741  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.1734  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.1838  decode.d3.loss_dice: 0.1803  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.1797  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.1818  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1850  decode.d6.loss_dice: 0.1801  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1852  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.1836  decode.d8.loss_dice: 0.1751
10/01 01:39:34 - mmengine - INFO - Iter(train) [136200/320000]  base_lr: 6.0712e-05 lr: 6.0712e-06  eta: 22:21:33  time: 0.4388  data_time: 0.0094  memory: 5120  grad_norm: 82.2792  loss: 5.0058  decode.loss_cls: 0.0539  decode.loss_mask: 0.2129  decode.loss_dice: 0.1560  decode.d0.loss_cls: 0.7288  decode.d0.loss_mask: 0.2170  decode.d0.loss_dice: 0.1561  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.1574  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.2123  decode.d2.loss_dice: 0.1604  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2136  decode.d3.loss_dice: 0.1589  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.1558  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1587  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.1571  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.2140  decode.d7.loss_dice: 0.1578  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.2108  decode.d8.loss_dice: 0.1565
10/01 01:39:56 - mmengine - INFO - Iter(train) [136250/320000]  base_lr: 6.0698e-05 lr: 6.0698e-06  eta: 22:21:12  time: 0.4385  data_time: 0.0092  memory: 5120  grad_norm: 54.3755  loss: 5.7451  decode.loss_cls: 0.0426  decode.loss_mask: 0.2395  decode.loss_dice: 0.1781  decode.d0.loss_cls: 0.9253  decode.d0.loss_mask: 0.2440  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.2436  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.2394  decode.d3.loss_dice: 0.2029  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.2391  decode.d4.loss_dice: 0.2107  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.2386  decode.d5.loss_dice: 0.1952  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.2373  decode.d6.loss_dice: 0.1736  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.1873  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.2372  decode.d8.loss_dice: 0.2053
10/01 01:40:17 - mmengine - INFO - Iter(train) [136300/320000]  base_lr: 6.0683e-05 lr: 6.0683e-06  eta: 22:20:50  time: 0.4387  data_time: 0.0095  memory: 5145  grad_norm: 36.2896  loss: 5.7641  decode.loss_cls: 0.0420  decode.loss_mask: 0.2165  decode.loss_dice: 0.2154  decode.d0.loss_cls: 0.8904  decode.d0.loss_mask: 0.2132  decode.d0.loss_dice: 0.2137  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.2170  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.2090  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.0875  decode.d4.loss_mask: 0.2153  decode.d4.loss_dice: 0.2222  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 0.2178  decode.d5.loss_dice: 0.2339  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.2149  decode.d7.loss_dice: 0.2075  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.2075
10/01 01:40:40 - mmengine - INFO - Iter(train) [136350/320000]  base_lr: 6.0668e-05 lr: 6.0668e-06  eta: 22:20:28  time: 0.4401  data_time: 0.0094  memory: 5129  grad_norm: 46.7953  loss: 5.3549  decode.loss_cls: 0.0076  decode.loss_mask: 0.2422  decode.loss_dice: 0.1830  decode.d0.loss_cls: 0.8808  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.1901  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.1817  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.2401  decode.d3.loss_dice: 0.2025  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2106  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.1909  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.2404  decode.d6.loss_dice: 0.1877  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.2034  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.1902
10/01 01:41:02 - mmengine - INFO - Iter(train) [136400/320000]  base_lr: 6.0653e-05 lr: 6.0653e-06  eta: 22:20:06  time: 0.4404  data_time: 0.0097  memory: 5129  grad_norm: 76.9374  loss: 5.9586  decode.loss_cls: 0.0874  decode.loss_mask: 0.2832  decode.loss_dice: 0.2206  decode.d0.loss_cls: 0.8719  decode.d0.loss_mask: 0.2207  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.2177  decode.d1.loss_dice: 0.1931  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.2184  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.0988  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.1840  decode.d4.loss_cls: 0.0956  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.1859  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.1859  decode.d6.loss_cls: 0.1001  decode.d6.loss_mask: 0.2189  decode.d6.loss_dice: 0.1869  decode.d7.loss_cls: 0.0962  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.2545  decode.d8.loss_dice: 0.2181
10/01 01:41:24 - mmengine - INFO - Iter(train) [136450/320000]  base_lr: 6.0638e-05 lr: 6.0638e-06  eta: 22:19:44  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 50.8562  loss: 5.1546  decode.loss_cls: 0.1001  decode.loss_mask: 0.2050  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.8738  decode.d0.loss_mask: 0.1986  decode.d0.loss_dice: 0.1712  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.1998  decode.d1.loss_dice: 0.1499  decode.d2.loss_cls: 0.0371  decode.d2.loss_mask: 0.1980  decode.d2.loss_dice: 0.1823  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.1981  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.1996  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.1787  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.2012  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0544  decode.d7.loss_mask: 0.1981  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.2003  decode.d8.loss_dice: 0.1958
10/01 01:41:45 - mmengine - INFO - Iter(train) [136500/320000]  base_lr: 6.0623e-05 lr: 6.0623e-06  eta: 22:19:23  time: 0.4379  data_time: 0.0094  memory: 5129  grad_norm: 51.7245  loss: 4.6172  decode.loss_cls: 0.0252  decode.loss_mask: 0.1914  decode.loss_dice: 0.1657  decode.d0.loss_cls: 0.8219  decode.d0.loss_mask: 0.1953  decode.d0.loss_dice: 0.1563  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.1642  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.1646  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.1801  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.1937  decode.d4.loss_dice: 0.1877  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.1928  decode.d5.loss_dice: 0.1576  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.1920  decode.d6.loss_dice: 0.1657  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.1950  decode.d7.loss_dice: 0.1583  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.1921  decode.d8.loss_dice: 0.1591
10/01 01:42:08 - mmengine - INFO - Iter(train) [136550/320000]  base_lr: 6.0608e-05 lr: 6.0608e-06  eta: 22:19:01  time: 0.4401  data_time: 0.0096  memory: 5129  grad_norm: 85.0834  loss: 4.9931  decode.loss_cls: 0.0865  decode.loss_mask: 0.1677  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.8861  decode.d0.loss_mask: 0.1684  decode.d0.loss_dice: 0.1767  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.1671  decode.d1.loss_dice: 0.1967  decode.d2.loss_cls: 0.0419  decode.d2.loss_mask: 0.1671  decode.d2.loss_dice: 0.1911  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.1660  decode.d3.loss_dice: 0.1804  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.1697  decode.d4.loss_dice: 0.1787  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.1686  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.0580  decode.d6.loss_mask: 0.1665  decode.d6.loss_dice: 0.1871  decode.d7.loss_cls: 0.0887  decode.d7.loss_mask: 0.1666  decode.d7.loss_dice: 0.1715  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.1695  decode.d8.loss_dice: 0.1721
10/01 01:42:30 - mmengine - INFO - Iter(train) [136600/320000]  base_lr: 6.0593e-05 lr: 6.0593e-06  eta: 22:18:39  time: 0.4403  data_time: 0.0097  memory: 5129  grad_norm: 31.7054  loss: 4.7717  decode.loss_cls: 0.0040  decode.loss_mask: 0.2220  decode.loss_dice: 0.1635  decode.d0.loss_cls: 0.8465  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.1669  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.1721  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.2245  decode.d2.loss_dice: 0.1677  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.2223  decode.d3.loss_dice: 0.1563  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.1686  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.1701  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.1668  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2227  decode.d7.loss_dice: 0.1637  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2194  decode.d8.loss_dice: 0.1708
10/01 01:42:52 - mmengine - INFO - Iter(train) [136650/320000]  base_lr: 6.0579e-05 lr: 6.0579e-06  eta: 22:18:17  time: 0.4413  data_time: 0.0095  memory: 5129  grad_norm: 106.0923  loss: 5.7303  decode.loss_cls: 0.0780  decode.loss_mask: 0.2065  decode.loss_dice: 0.2056  decode.d0.loss_cls: 0.8892  decode.d0.loss_mask: 0.2096  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.0953  decode.d1.loss_mask: 0.2135  decode.d1.loss_dice: 0.2469  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.2105  decode.d2.loss_dice: 0.2183  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.2198  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.2094  decode.d4.loss_dice: 0.2191  decode.d5.loss_cls: 0.0387  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.2111  decode.d6.loss_dice: 0.2445  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.2072  decode.d7.loss_dice: 0.2397  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.2227
10/01 01:43:14 - mmengine - INFO - Iter(train) [136700/320000]  base_lr: 6.0564e-05 lr: 6.0564e-06  eta: 22:17:56  time: 0.4395  data_time: 0.0095  memory: 5146  grad_norm: 37.0838  loss: 4.5541  decode.loss_cls: 0.0149  decode.loss_mask: 0.1974  decode.loss_dice: 0.1703  decode.d0.loss_cls: 0.7431  decode.d0.loss_mask: 0.1980  decode.d0.loss_dice: 0.1715  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.1706  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.1960  decode.d2.loss_dice: 0.1681  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.1739  decode.d4.loss_cls: 0.0280  decode.d4.loss_mask: 0.1962  decode.d4.loss_dice: 0.1695  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.1928  decode.d5.loss_dice: 0.1677  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.1678  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.1933  decode.d7.loss_dice: 0.1657  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.1967  decode.d8.loss_dice: 0.1698
10/01 01:43:36 - mmengine - INFO - Iter(train) [136750/320000]  base_lr: 6.0549e-05 lr: 6.0549e-06  eta: 22:17:34  time: 0.4400  data_time: 0.0095  memory: 5145  grad_norm: 17.3166  loss: 3.6408  decode.loss_cls: 0.0052  decode.loss_mask: 0.1455  decode.loss_dice: 0.1335  decode.d0.loss_cls: 0.8461  decode.d0.loss_mask: 0.1478  decode.d0.loss_dice: 0.1236  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.1452  decode.d1.loss_dice: 0.1293  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.1459  decode.d2.loss_dice: 0.1323  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.1448  decode.d3.loss_dice: 0.1319  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.1461  decode.d4.loss_dice: 0.1301  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.1467  decode.d5.loss_dice: 0.1299  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.1457  decode.d6.loss_dice: 0.1318  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.1467  decode.d7.loss_dice: 0.1288  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.1457  decode.d8.loss_dice: 0.1276
10/01 01:43:58 - mmengine - INFO - Iter(train) [136800/320000]  base_lr: 6.0534e-05 lr: 6.0534e-06  eta: 22:17:12  time: 0.4399  data_time: 0.0095  memory: 5129  grad_norm: 77.4817  loss: 5.6535  decode.loss_cls: 0.0135  decode.loss_mask: 0.2422  decode.loss_dice: 0.2030  decode.d0.loss_cls: 0.9125  decode.d0.loss_mask: 0.2380  decode.d0.loss_dice: 0.2149  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.2423  decode.d1.loss_dice: 0.2023  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.2404  decode.d2.loss_dice: 0.2123  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.2404  decode.d3.loss_dice: 0.2134  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.2189  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2367  decode.d5.loss_dice: 0.2319  decode.d6.loss_cls: 0.0125  decode.d6.loss_mask: 0.2436  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.2110  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.2463  decode.d8.loss_dice: 0.2305
10/01 01:44:20 - mmengine - INFO - Iter(train) [136850/320000]  base_lr: 6.0519e-05 lr: 6.0519e-06  eta: 22:16:50  time: 0.4402  data_time: 0.0095  memory: 5129  grad_norm: 53.9152  loss: 4.5725  decode.loss_cls: 0.0032  decode.loss_mask: 0.1946  decode.loss_dice: 0.1680  decode.d0.loss_cls: 0.8888  decode.d0.loss_mask: 0.2005  decode.d0.loss_dice: 0.1485  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.1944  decode.d1.loss_dice: 0.1600  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.1969  decode.d2.loss_dice: 0.1653  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.1950  decode.d3.loss_dice: 0.1627  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.1611  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.1964  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1995  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1977  decode.d7.loss_dice: 0.1695  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.1963  decode.d8.loss_dice: 0.1625
10/01 01:44:42 - mmengine - INFO - Iter(train) [136900/320000]  base_lr: 6.0504e-05 lr: 6.0504e-06  eta: 22:16:29  time: 0.4402  data_time: 0.0099  memory: 5129  grad_norm: 36.8609  loss: 5.1052  decode.loss_cls: 0.0389  decode.loss_mask: 0.1930  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.9668  decode.d0.loss_mask: 0.1926  decode.d0.loss_dice: 0.1832  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.1948  decode.d1.loss_dice: 0.1611  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.1949  decode.d2.loss_dice: 0.1423  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.1952  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.1716  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.1938  decode.d5.loss_dice: 0.1493  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.1965  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.1910  decode.d7.loss_dice: 0.1582  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.1947  decode.d8.loss_dice: 0.1662
10/01 01:45:04 - mmengine - INFO - Iter(train) [136950/320000]  base_lr: 6.0489e-05 lr: 6.0489e-06  eta: 22:16:07  time: 0.4403  data_time: 0.0098  memory: 5129  grad_norm: 82.6645  loss: 7.8042  decode.loss_cls: 0.2155  decode.loss_mask: 0.2566  decode.loss_dice: 0.2399  decode.d0.loss_cls: 0.9027  decode.d0.loss_mask: 0.2656  decode.d0.loss_dice: 0.2324  decode.d1.loss_cls: 0.2050  decode.d1.loss_mask: 0.2508  decode.d1.loss_dice: 0.2156  decode.d2.loss_cls: 0.2252  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.2237  decode.d3.loss_cls: 0.2176  decode.d3.loss_mask: 0.2586  decode.d3.loss_dice: 0.2302  decode.d4.loss_cls: 0.2099  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.2155  decode.d5.loss_cls: 0.2437  decode.d5.loss_mask: 0.2582  decode.d5.loss_dice: 0.2324  decode.d6.loss_cls: 0.1616  decode.d6.loss_mask: 0.3403  decode.d6.loss_dice: 0.2476  decode.d7.loss_cls: 0.1785  decode.d7.loss_mask: 0.2654  decode.d7.loss_dice: 0.2495  decode.d8.loss_cls: 0.2336  decode.d8.loss_mask: 0.2847  decode.d8.loss_dice: 0.2283
10/01 01:45:26 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:45:26 - mmengine - INFO - Iter(train) [137000/320000]  base_lr: 6.0474e-05 lr: 6.0474e-06  eta: 22:15:45  time: 0.4408  data_time: 0.0099  memory: 5129  grad_norm: 47.6227  loss: 4.8750  decode.loss_cls: 0.0412  decode.loss_mask: 0.1968  decode.loss_dice: 0.1735  decode.d0.loss_cls: 0.8114  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.1749  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.1940  decode.d1.loss_dice: 0.1563  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.1608  decode.d3.loss_cls: 0.0376  decode.d3.loss_mask: 0.1947  decode.d3.loss_dice: 0.1696  decode.d4.loss_cls: 0.0386  decode.d4.loss_mask: 0.1930  decode.d4.loss_dice: 0.1686  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.1951  decode.d5.loss_dice: 0.1721  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.1964  decode.d6.loss_dice: 0.1868  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.1927  decode.d7.loss_dice: 0.1655  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.1941  decode.d8.loss_dice: 0.1855
10/01 01:45:48 - mmengine - INFO - Iter(train) [137050/320000]  base_lr: 6.0460e-05 lr: 6.0460e-06  eta: 22:15:23  time: 0.4419  data_time: 0.0098  memory: 5145  grad_norm: 20.9559  loss: 4.0140  decode.loss_cls: 0.0021  decode.loss_mask: 0.1760  decode.loss_dice: 0.1386  decode.d0.loss_cls: 0.8282  decode.d0.loss_mask: 0.1737  decode.d0.loss_dice: 0.1373  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.1792  decode.d1.loss_dice: 0.1411  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.1763  decode.d2.loss_dice: 0.1377  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1748  decode.d3.loss_dice: 0.1363  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.1755  decode.d4.loss_dice: 0.1370  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.1755  decode.d5.loss_dice: 0.1390  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.1771  decode.d6.loss_dice: 0.1398  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.1757  decode.d7.loss_dice: 0.1394  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1752  decode.d8.loss_dice: 0.1354
10/01 01:46:10 - mmengine - INFO - Iter(train) [137100/320000]  base_lr: 6.0445e-05 lr: 6.0445e-06  eta: 22:15:02  time: 0.4415  data_time: 0.0099  memory: 5120  grad_norm: 145.9525  loss: 7.4330  decode.loss_cls: 0.0597  decode.loss_mask: 0.3724  decode.loss_dice: 0.2350  decode.d0.loss_cls: 0.9971  decode.d0.loss_mask: 0.3531  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.3627  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.3732  decode.d2.loss_dice: 0.2299  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.3649  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.3522  decode.d4.loss_dice: 0.2386  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.3504  decode.d5.loss_dice: 0.2313  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.3596  decode.d6.loss_dice: 0.2277  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.3576  decode.d7.loss_dice: 0.2259  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.3613  decode.d8.loss_dice: 0.2256
10/01 01:46:32 - mmengine - INFO - Iter(train) [137150/320000]  base_lr: 6.0430e-05 lr: 6.0430e-06  eta: 22:14:40  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 35.1215  loss: 4.1344  decode.loss_cls: 0.0079  decode.loss_mask: 0.1782  decode.loss_dice: 0.1394  decode.d0.loss_cls: 0.8305  decode.d0.loss_mask: 0.1782  decode.d0.loss_dice: 0.1469  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.1753  decode.d1.loss_dice: 0.1402  decode.d2.loss_cls: 0.0142  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.1420  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.1770  decode.d3.loss_dice: 0.1442  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.1439  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.1767  decode.d5.loss_dice: 0.1420  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.1773  decode.d6.loss_dice: 0.1423  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1759  decode.d7.loss_dice: 0.1414  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.1779  decode.d8.loss_dice: 0.1432
10/01 01:46:54 - mmengine - INFO - Iter(train) [137200/320000]  base_lr: 6.0415e-05 lr: 6.0415e-06  eta: 22:14:18  time: 0.4405  data_time: 0.0097  memory: 5145  grad_norm: 42.7277  loss: 4.8646  decode.loss_cls: 0.0601  decode.loss_mask: 0.1969  decode.loss_dice: 0.1450  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 0.2005  decode.d0.loss_dice: 0.1414  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.1975  decode.d1.loss_dice: 0.1384  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.1959  decode.d2.loss_dice: 0.1678  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.1948  decode.d3.loss_dice: 0.1446  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.1962  decode.d4.loss_dice: 0.1437  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.1401  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.1965  decode.d6.loss_dice: 0.1444  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.1455  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.1964  decode.d8.loss_dice: 0.1456
10/01 01:47:16 - mmengine - INFO - Iter(train) [137250/320000]  base_lr: 6.0400e-05 lr: 6.0400e-06  eta: 22:13:57  time: 0.4407  data_time: 0.0097  memory: 5145  grad_norm: 42.6699  loss: 4.7610  decode.loss_cls: 0.1072  decode.loss_mask: 0.1728  decode.loss_dice: 0.1303  decode.d0.loss_cls: 0.8212  decode.d0.loss_mask: 0.1692  decode.d0.loss_dice: 0.1332  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.1701  decode.d1.loss_dice: 0.1315  decode.d2.loss_cls: 0.1068  decode.d2.loss_mask: 0.1701  decode.d2.loss_dice: 0.1368  decode.d3.loss_cls: 0.0981  decode.d3.loss_mask: 0.1718  decode.d3.loss_dice: 0.1334  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.1716  decode.d4.loss_dice: 0.1305  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.1715  decode.d5.loss_dice: 0.1368  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.1710  decode.d6.loss_dice: 0.1320  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.1727  decode.d7.loss_dice: 0.1291  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.1724  decode.d8.loss_dice: 0.1308
10/01 01:47:38 - mmengine - INFO - Iter(train) [137300/320000]  base_lr: 6.0385e-05 lr: 6.0385e-06  eta: 22:13:35  time: 0.4406  data_time: 0.0097  memory: 5129  grad_norm: 79.3241  loss: 4.3229  decode.loss_cls: 0.0249  decode.loss_mask: 0.1898  decode.loss_dice: 0.1364  decode.d0.loss_cls: 0.7924  decode.d0.loss_mask: 0.1909  decode.d0.loss_dice: 0.1368  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.1909  decode.d1.loss_dice: 0.1429  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.1913  decode.d2.loss_dice: 0.1351  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.1916  decode.d3.loss_dice: 0.1364  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.1887  decode.d4.loss_dice: 0.1341  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.1351  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.1904  decode.d6.loss_dice: 0.1338  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.1907  decode.d7.loss_dice: 0.1391  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.1912  decode.d8.loss_dice: 0.1379
10/01 01:48:00 - mmengine - INFO - Iter(train) [137350/320000]  base_lr: 6.0370e-05 lr: 6.0370e-06  eta: 22:13:13  time: 0.4402  data_time: 0.0095  memory: 5145  grad_norm: 43.0150  loss: 4.2708  decode.loss_cls: 0.0208  decode.loss_mask: 0.1773  decode.loss_dice: 0.1407  decode.d0.loss_cls: 0.8824  decode.d0.loss_mask: 0.1778  decode.d0.loss_dice: 0.1485  decode.d1.loss_cls: 0.0230  decode.d1.loss_mask: 0.1773  decode.d1.loss_dice: 0.1366  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.1750  decode.d2.loss_dice: 0.1370  decode.d3.loss_cls: 0.0191  decode.d3.loss_mask: 0.1777  decode.d3.loss_dice: 0.1382  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.1388  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.1789  decode.d5.loss_dice: 0.1596  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.1768  decode.d6.loss_dice: 0.1349  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.1782  decode.d7.loss_dice: 0.1424  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.1786  decode.d8.loss_dice: 0.1380
10/01 01:48:22 - mmengine - INFO - Iter(train) [137400/320000]  base_lr: 6.0356e-05 lr: 6.0356e-06  eta: 22:12:52  time: 0.4437  data_time: 0.0100  memory: 5120  grad_norm: 62.4862  loss: 5.7163  decode.loss_cls: 0.0612  decode.loss_mask: 0.2357  decode.loss_dice: 0.1770  decode.d0.loss_cls: 0.7916  decode.d0.loss_mask: 0.2404  decode.d0.loss_dice: 0.1959  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.2015  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.2357  decode.d2.loss_dice: 0.1846  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.2381  decode.d4.loss_dice: 0.2006  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.2372  decode.d5.loss_dice: 0.1992  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2340  decode.d6.loss_dice: 0.1753  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.2379  decode.d8.loss_dice: 0.2092
10/01 01:48:44 - mmengine - INFO - Iter(train) [137450/320000]  base_lr: 6.0341e-05 lr: 6.0341e-06  eta: 22:12:30  time: 0.4409  data_time: 0.0096  memory: 5129  grad_norm: 39.6050  loss: 4.9237  decode.loss_cls: 0.0751  decode.loss_mask: 0.1612  decode.loss_dice: 0.1718  decode.d0.loss_cls: 0.9079  decode.d0.loss_mask: 0.1601  decode.d0.loss_dice: 0.1488  decode.d1.loss_cls: 0.1565  decode.d1.loss_mask: 0.1627  decode.d1.loss_dice: 0.1517  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 0.1652  decode.d2.loss_dice: 0.1489  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.1623  decode.d3.loss_dice: 0.1577  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 0.1642  decode.d4.loss_dice: 0.1454  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.1648  decode.d5.loss_dice: 0.1625  decode.d6.loss_cls: 0.0991  decode.d6.loss_mask: 0.1616  decode.d6.loss_dice: 0.1551  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.1626  decode.d7.loss_dice: 0.1542  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.1639  decode.d8.loss_dice: 0.1545
10/01 01:49:06 - mmengine - INFO - Iter(train) [137500/320000]  base_lr: 6.0326e-05 lr: 6.0326e-06  eta: 22:12:08  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 88.9143  loss: 5.6314  decode.loss_cls: 0.1073  decode.loss_mask: 0.1910  decode.loss_dice: 0.1631  decode.d0.loss_cls: 1.0507  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.1550  decode.d1.loss_cls: 0.1347  decode.d1.loss_mask: 0.1947  decode.d1.loss_dice: 0.1590  decode.d2.loss_cls: 0.1284  decode.d2.loss_mask: 0.1861  decode.d2.loss_dice: 0.1583  decode.d3.loss_cls: 0.1149  decode.d3.loss_mask: 0.1884  decode.d3.loss_dice: 0.1533  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.1592  decode.d5.loss_cls: 0.1213  decode.d5.loss_mask: 0.1894  decode.d5.loss_dice: 0.1598  decode.d6.loss_cls: 0.1202  decode.d6.loss_mask: 0.1872  decode.d6.loss_dice: 0.1614  decode.d7.loss_cls: 0.1123  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.1632  decode.d8.loss_cls: 0.1042  decode.d8.loss_mask: 0.1999  decode.d8.loss_dice: 0.1628
10/01 01:49:28 - mmengine - INFO - Iter(train) [137550/320000]  base_lr: 6.0311e-05 lr: 6.0311e-06  eta: 22:11:46  time: 0.4407  data_time: 0.0097  memory: 5129  grad_norm: 34.9048  loss: 4.4850  decode.loss_cls: 0.0014  decode.loss_mask: 0.1973  decode.loss_dice: 0.1651  decode.d0.loss_cls: 0.7762  decode.d0.loss_mask: 0.2028  decode.d0.loss_dice: 0.1617  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.1989  decode.d1.loss_dice: 0.1698  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.2006  decode.d2.loss_dice: 0.1716  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1977  decode.d3.loss_dice: 0.1726  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.1966  decode.d4.loss_dice: 0.1693  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.1961  decode.d5.loss_dice: 0.1713  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.1990  decode.d6.loss_dice: 0.1723  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1997  decode.d7.loss_dice: 0.1730  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.1958  decode.d8.loss_dice: 0.1738
10/01 01:49:51 - mmengine - INFO - Iter(train) [137600/320000]  base_lr: 6.0296e-05 lr: 6.0296e-06  eta: 22:11:25  time: 0.4405  data_time: 0.0097  memory: 5129  grad_norm: 87.9780  loss: 4.7656  decode.loss_cls: 0.0128  decode.loss_mask: 0.2003  decode.loss_dice: 0.1487  decode.d0.loss_cls: 0.7901  decode.d0.loss_mask: 0.1935  decode.d0.loss_dice: 0.1515  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.1973  decode.d1.loss_dice: 0.1521  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.2237  decode.d2.loss_dice: 0.1606  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.1862  decode.d3.loss_dice: 0.1482  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.1906  decode.d4.loss_dice: 0.1449  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.2483  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.2086  decode.d6.loss_dice: 0.1517  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.1508  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.1546
10/01 01:50:13 - mmengine - INFO - Iter(train) [137650/320000]  base_lr: 6.0281e-05 lr: 6.0281e-06  eta: 22:11:03  time: 0.4410  data_time: 0.0098  memory: 5129  grad_norm: 39.9306  loss: 5.2026  decode.loss_cls: 0.0985  decode.loss_mask: 0.2166  decode.loss_dice: 0.1614  decode.d0.loss_cls: 0.7849  decode.d0.loss_mask: 0.2186  decode.d0.loss_dice: 0.1607  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.2160  decode.d1.loss_dice: 0.1589  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.2145  decode.d2.loss_dice: 0.1647  decode.d3.loss_cls: 0.0291  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.2170  decode.d4.loss_dice: 0.1645  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.2172  decode.d5.loss_dice: 0.1707  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.1656  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.2149  decode.d8.loss_dice: 0.1675
10/01 01:50:35 - mmengine - INFO - Iter(train) [137700/320000]  base_lr: 6.0266e-05 lr: 6.0266e-06  eta: 22:10:41  time: 0.4404  data_time: 0.0098  memory: 5129  grad_norm: 19.1876  loss: 4.0285  decode.loss_cls: 0.0021  decode.loss_mask: 0.1899  decode.loss_dice: 0.1393  decode.d0.loss_cls: 0.7446  decode.d0.loss_mask: 0.1909  decode.d0.loss_dice: 0.1269  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.1411  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.1380  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1885  decode.d3.loss_dice: 0.1342  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.1374  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.1412  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1897  decode.d6.loss_dice: 0.1380  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.1868  decode.d7.loss_dice: 0.1402  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.1873  decode.d8.loss_dice: 0.1367
10/01 01:50:57 - mmengine - INFO - Iter(train) [137750/320000]  base_lr: 6.0251e-05 lr: 6.0251e-06  eta: 22:10:20  time: 0.4399  data_time: 0.0097  memory: 5129  grad_norm: 44.1294  loss: 5.6424  decode.loss_cls: 0.0368  decode.loss_mask: 0.2330  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.7796  decode.d0.loss_mask: 0.2281  decode.d0.loss_dice: 0.2084  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.2212  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.2114  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.2315  decode.d4.loss_dice: 0.2053  decode.d5.loss_cls: 0.0453  decode.d5.loss_mask: 0.2350  decode.d5.loss_dice: 0.2157  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.2340  decode.d6.loss_dice: 0.2189  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2171  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2082
10/01 01:51:19 - mmengine - INFO - Iter(train) [137800/320000]  base_lr: 6.0237e-05 lr: 6.0237e-06  eta: 22:09:58  time: 0.4403  data_time: 0.0098  memory: 5129  grad_norm: 83.9035  loss: 4.9042  decode.loss_cls: 0.0534  decode.loss_mask: 0.2089  decode.loss_dice: 0.1699  decode.d0.loss_cls: 0.8058  decode.d0.loss_mask: 0.2078  decode.d0.loss_dice: 0.1671  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.2081  decode.d1.loss_dice: 0.1644  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.1680  decode.d3.loss_cls: 0.0211  decode.d3.loss_mask: 0.2094  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.1740  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.2098  decode.d5.loss_dice: 0.1667  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.2093  decode.d6.loss_dice: 0.1684  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.0211  decode.d8.loss_mask: 0.2085  decode.d8.loss_dice: 0.1643
10/01 01:51:41 - mmengine - INFO - Iter(train) [137850/320000]  base_lr: 6.0222e-05 lr: 6.0222e-06  eta: 22:09:36  time: 0.4409  data_time: 0.0098  memory: 5145  grad_norm: 49.1594  loss: 5.2751  decode.loss_cls: 0.0760  decode.loss_mask: 0.1738  decode.loss_dice: 0.1869  decode.d0.loss_cls: 0.9020  decode.d0.loss_mask: 0.1757  decode.d0.loss_dice: 0.1859  decode.d1.loss_cls: 0.1146  decode.d1.loss_mask: 0.1751  decode.d1.loss_dice: 0.1586  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.1754  decode.d2.loss_dice: 0.1822  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.1741  decode.d3.loss_dice: 0.1863  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.1746  decode.d4.loss_dice: 0.1826  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.1741  decode.d5.loss_dice: 0.1823  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.1745  decode.d6.loss_dice: 0.1738  decode.d7.loss_cls: 0.0975  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.1635  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.1795  decode.d8.loss_dice: 0.1924
10/01 01:52:03 - mmengine - INFO - Iter(train) [137900/320000]  base_lr: 6.0207e-05 lr: 6.0207e-06  eta: 22:09:14  time: 0.4399  data_time: 0.0098  memory: 5120  grad_norm: 45.2557  loss: 5.5768  decode.loss_cls: 0.0050  decode.loss_mask: 0.2660  decode.loss_dice: 0.2037  decode.d0.loss_cls: 0.8574  decode.d0.loss_mask: 0.2725  decode.d0.loss_dice: 0.1883  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 0.2669  decode.d1.loss_dice: 0.2000  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2643  decode.d2.loss_dice: 0.2028  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.2648  decode.d3.loss_dice: 0.2074  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.1953  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2663  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.2627  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.2054  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2653  decode.d8.loss_dice: 0.2009
10/01 01:52:25 - mmengine - INFO - Iter(train) [137950/320000]  base_lr: 6.0192e-05 lr: 6.0192e-06  eta: 22:08:53  time: 0.4402  data_time: 0.0097  memory: 5120  grad_norm: 24.0253  loss: 4.5861  decode.loss_cls: 0.0299  decode.loss_mask: 0.1695  decode.loss_dice: 0.1643  decode.d0.loss_cls: 0.8860  decode.d0.loss_mask: 0.1663  decode.d0.loss_dice: 0.1680  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.1694  decode.d1.loss_dice: 0.1726  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.1709  decode.d2.loss_dice: 0.1753  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 0.1705  decode.d3.loss_dice: 0.1663  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.1721  decode.d4.loss_dice: 0.1707  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.1701  decode.d5.loss_dice: 0.1672  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.1682  decode.d6.loss_dice: 0.1637  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.1698  decode.d7.loss_dice: 0.1644  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.1719  decode.d8.loss_dice: 0.1654
10/01 01:52:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 01:52:47 - mmengine - INFO - Iter(train) [138000/320000]  base_lr: 6.0177e-05 lr: 6.0177e-06  eta: 22:08:31  time: 0.4430  data_time: 0.0098  memory: 5145  grad_norm: 44.8521  loss: 5.5370  decode.loss_cls: 0.0580  decode.loss_mask: 0.1887  decode.loss_dice: 0.2043  decode.d0.loss_cls: 0.8226  decode.d0.loss_mask: 0.1922  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.1876  decode.d1.loss_dice: 0.1891  decode.d2.loss_cls: 0.0943  decode.d2.loss_mask: 0.1890  decode.d2.loss_dice: 0.2080  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.1889  decode.d3.loss_dice: 0.2041  decode.d4.loss_cls: 0.0875  decode.d4.loss_mask: 0.1866  decode.d4.loss_dice: 0.1938  decode.d5.loss_cls: 0.0883  decode.d5.loss_mask: 0.1891  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.1910  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.1885  decode.d7.loss_dice: 0.2056  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.1884  decode.d8.loss_dice: 0.1963
10/01 01:53:09 - mmengine - INFO - Iter(train) [138050/320000]  base_lr: 6.0162e-05 lr: 6.0162e-06  eta: 22:08:09  time: 0.4402  data_time: 0.0098  memory: 5119  grad_norm: 32.4772  loss: 4.3296  decode.loss_cls: 0.0093  decode.loss_mask: 0.1934  decode.loss_dice: 0.1653  decode.d0.loss_cls: 0.7476  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.1933  decode.d1.loss_dice: 0.1636  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.1745  decode.d2.loss_dice: 0.1594  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.1731  decode.d3.loss_dice: 0.1567  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.1913  decode.d4.loss_dice: 0.1621  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.1951  decode.d5.loss_dice: 0.1659  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.1927  decode.d6.loss_dice: 0.1569  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.1903  decode.d7.loss_dice: 0.1619  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.1610
10/01 01:53:31 - mmengine - INFO - Iter(train) [138100/320000]  base_lr: 6.0147e-05 lr: 6.0147e-06  eta: 22:07:48  time: 0.4419  data_time: 0.0094  memory: 5129  grad_norm: 110.1938  loss: 5.5747  decode.loss_cls: 0.1329  decode.loss_mask: 0.1986  decode.loss_dice: 0.1396  decode.d0.loss_cls: 0.8427  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.1441  decode.d1.loss_cls: 0.1478  decode.d1.loss_mask: 0.2125  decode.d1.loss_dice: 0.1543  decode.d2.loss_cls: 0.1691  decode.d2.loss_mask: 0.2060  decode.d2.loss_dice: 0.1586  decode.d3.loss_cls: 0.1636  decode.d3.loss_mask: 0.2032  decode.d3.loss_dice: 0.1410  decode.d4.loss_cls: 0.1406  decode.d4.loss_mask: 0.2041  decode.d4.loss_dice: 0.1422  decode.d5.loss_cls: 0.1254  decode.d5.loss_mask: 0.2030  decode.d5.loss_dice: 0.1471  decode.d6.loss_cls: 0.1316  decode.d6.loss_mask: 0.2074  decode.d6.loss_dice: 0.1436  decode.d7.loss_cls: 0.1171  decode.d7.loss_mask: 0.1962  decode.d7.loss_dice: 0.1399  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 0.2025  decode.d8.loss_dice: 0.1399
10/01 01:53:53 - mmengine - INFO - Iter(train) [138150/320000]  base_lr: 6.0132e-05 lr: 6.0132e-06  eta: 22:07:26  time: 0.4408  data_time: 0.0095  memory: 5120  grad_norm: 128.5916  loss: 5.3123  decode.loss_cls: 0.0508  decode.loss_mask: 0.1901  decode.loss_dice: 0.2119  decode.d0.loss_cls: 0.8540  decode.d0.loss_mask: 0.1914  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.1673  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.1675  decode.d3.loss_cls: 0.0505  decode.d3.loss_mask: 0.1900  decode.d3.loss_dice: 0.2035  decode.d4.loss_cls: 0.0573  decode.d4.loss_mask: 0.1892  decode.d4.loss_dice: 0.1897  decode.d5.loss_cls: 0.1035  decode.d5.loss_mask: 0.1908  decode.d5.loss_dice: 0.2071  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.1914  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.2141  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.1894  decode.d8.loss_dice: 0.2054
10/01 01:54:15 - mmengine - INFO - Iter(train) [138200/320000]  base_lr: 6.0117e-05 lr: 6.0117e-06  eta: 22:07:04  time: 0.4419  data_time: 0.0095  memory: 5145  grad_norm: 42.1443  loss: 4.9359  decode.loss_cls: 0.0323  decode.loss_mask: 0.1853  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.8688  decode.d0.loss_mask: 0.1863  decode.d0.loss_dice: 0.1788  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.1860  decode.d1.loss_dice: 0.1787  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.1854  decode.d2.loss_dice: 0.1800  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.1880  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.1862  decode.d4.loss_dice: 0.1846  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.1857  decode.d5.loss_dice: 0.1763  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.1853  decode.d6.loss_dice: 0.1639  decode.d7.loss_cls: 0.0343  decode.d7.loss_mask: 0.1847  decode.d7.loss_dice: 0.1802  decode.d8.loss_cls: 0.0314  decode.d8.loss_mask: 0.1877  decode.d8.loss_dice: 0.1833
10/01 01:54:37 - mmengine - INFO - Iter(train) [138250/320000]  base_lr: 6.0103e-05 lr: 6.0103e-06  eta: 22:06:43  time: 0.4395  data_time: 0.0094  memory: 5129  grad_norm: 60.3975  loss: 4.2681  decode.loss_cls: 0.0827  decode.loss_mask: 0.1541  decode.loss_dice: 0.1422  decode.d0.loss_cls: 0.7287  decode.d0.loss_mask: 0.1579  decode.d0.loss_dice: 0.1435  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.1533  decode.d1.loss_dice: 0.1463  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.1524  decode.d2.loss_dice: 0.1437  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.1516  decode.d3.loss_dice: 0.1421  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.1522  decode.d4.loss_dice: 0.1419  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.1546  decode.d5.loss_dice: 0.1443  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.1526  decode.d6.loss_dice: 0.1427  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.1527  decode.d7.loss_dice: 0.1431  decode.d8.loss_cls: 0.0451  decode.d8.loss_mask: 0.1527  decode.d8.loss_dice: 0.1410
10/01 01:54:59 - mmengine - INFO - Iter(train) [138300/320000]  base_lr: 6.0088e-05 lr: 6.0088e-06  eta: 22:06:21  time: 0.4394  data_time: 0.0093  memory: 5120  grad_norm: 31.0198  loss: 4.4513  decode.loss_cls: 0.0263  decode.loss_mask: 0.1665  decode.loss_dice: 0.1493  decode.d0.loss_cls: 0.8528  decode.d0.loss_mask: 0.1708  decode.d0.loss_dice: 0.1547  decode.d1.loss_cls: 0.0392  decode.d1.loss_mask: 0.1686  decode.d1.loss_dice: 0.1547  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.1667  decode.d2.loss_dice: 0.1623  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.1693  decode.d3.loss_dice: 0.1634  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.1693  decode.d4.loss_dice: 0.1617  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.1698  decode.d5.loss_dice: 0.1570  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.1692  decode.d6.loss_dice: 0.1703  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.1682  decode.d7.loss_dice: 0.1477  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.1719  decode.d8.loss_dice: 0.1625
10/01 01:55:21 - mmengine - INFO - Iter(train) [138350/320000]  base_lr: 6.0073e-05 lr: 6.0073e-06  eta: 22:05:59  time: 0.4401  data_time: 0.0095  memory: 5120  grad_norm: 25.4366  loss: 4.3519  decode.loss_cls: 0.0020  decode.loss_mask: 0.2012  decode.loss_dice: 0.1584  decode.d0.loss_cls: 0.7390  decode.d0.loss_mask: 0.2026  decode.d0.loss_dice: 0.1549  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.2043  decode.d1.loss_dice: 0.1616  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2045  decode.d2.loss_dice: 0.1610  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2024  decode.d3.loss_dice: 0.1591  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.1558  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2005  decode.d5.loss_dice: 0.1570  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.2015  decode.d6.loss_dice: 0.1525  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.1547  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.2030  decode.d8.loss_dice: 0.1538
10/01 01:55:43 - mmengine - INFO - Iter(train) [138400/320000]  base_lr: 6.0058e-05 lr: 6.0058e-06  eta: 22:05:37  time: 0.4392  data_time: 0.0094  memory: 5129  grad_norm: 16.1723  loss: 3.8179  decode.loss_cls: 0.0020  decode.loss_mask: 0.1575  decode.loss_dice: 0.1348  decode.d0.loss_cls: 0.8529  decode.d0.loss_mask: 0.1550  decode.d0.loss_dice: 0.1338  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.1570  decode.d1.loss_dice: 0.1361  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.1603  decode.d2.loss_dice: 0.1368  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.1562  decode.d3.loss_dice: 0.1324  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1602  decode.d4.loss_dice: 0.1363  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.1605  decode.d5.loss_dice: 0.1389  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.1587  decode.d6.loss_dice: 0.1340  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.1614  decode.d7.loss_dice: 0.1383  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.1605  decode.d8.loss_dice: 0.1349
10/01 01:56:05 - mmengine - INFO - Iter(train) [138450/320000]  base_lr: 6.0043e-05 lr: 6.0043e-06  eta: 22:05:15  time: 0.4393  data_time: 0.0095  memory: 5129  grad_norm: 29.7271  loss: 5.2288  decode.loss_cls: 0.0739  decode.loss_mask: 0.2078  decode.loss_dice: 0.1617  decode.d0.loss_cls: 0.8660  decode.d0.loss_mask: 0.2126  decode.d0.loss_dice: 0.1643  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.2111  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.1606  decode.d3.loss_cls: 0.0667  decode.d3.loss_mask: 0.2070  decode.d3.loss_dice: 0.1587  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.2089  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.1628  decode.d6.loss_cls: 0.0684  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.1668  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.1716  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.2103  decode.d8.loss_dice: 0.1669
10/01 01:56:27 - mmengine - INFO - Iter(train) [138500/320000]  base_lr: 6.0028e-05 lr: 6.0028e-06  eta: 22:04:54  time: 0.4397  data_time: 0.0095  memory: 5145  grad_norm: 34.5555  loss: 5.1694  decode.loss_cls: 0.0256  decode.loss_mask: 0.2050  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.8782  decode.d0.loss_mask: 0.2059  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.2039  decode.d1.loss_dice: 0.1857  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.2042  decode.d2.loss_dice: 0.1689  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.2046  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.2033  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2048  decode.d5.loss_dice: 0.2015  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.1764  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.2028  decode.d7.loss_dice: 0.1786  decode.d8.loss_cls: 0.0582  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.1701
10/01 01:56:49 - mmengine - INFO - Iter(train) [138550/320000]  base_lr: 6.0013e-05 lr: 6.0013e-06  eta: 22:04:32  time: 0.4410  data_time: 0.0095  memory: 5129  grad_norm: 39.2478  loss: 4.7963  decode.loss_cls: 0.0298  decode.loss_mask: 0.1932  decode.loss_dice: 0.1663  decode.d0.loss_cls: 0.7435  decode.d0.loss_mask: 0.1918  decode.d0.loss_dice: 0.1665  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.1900  decode.d1.loss_dice: 0.1626  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.1896  decode.d2.loss_dice: 0.1592  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.1909  decode.d3.loss_dice: 0.1659  decode.d4.loss_cls: 0.0970  decode.d4.loss_mask: 0.1895  decode.d4.loss_dice: 0.1610  decode.d5.loss_cls: 0.0894  decode.d5.loss_mask: 0.1904  decode.d5.loss_dice: 0.1644  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.1873  decode.d6.loss_dice: 0.1611  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.1905  decode.d7.loss_dice: 0.1653  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.1917  decode.d8.loss_dice: 0.1654
10/01 01:57:11 - mmengine - INFO - Iter(train) [138600/320000]  base_lr: 5.9998e-05 lr: 5.9998e-06  eta: 22:04:10  time: 0.4406  data_time: 0.0095  memory: 5129  grad_norm: 130.6387  loss: 5.2460  decode.loss_cls: 0.0443  decode.loss_mask: 0.2289  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.8158  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.2321  decode.d1.loss_dice: 0.2031  decode.d2.loss_cls: 0.0142  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.1876  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.1913  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.1888  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.2315  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.2268  decode.d6.loss_dice: 0.1883  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.2326  decode.d7.loss_dice: 0.1939  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.1931
10/01 01:57:33 - mmengine - INFO - Iter(train) [138650/320000]  base_lr: 5.9984e-05 lr: 5.9984e-06  eta: 22:03:49  time: 0.4397  data_time: 0.0093  memory: 5129  grad_norm: 36.0057  loss: 5.0332  decode.loss_cls: 0.0683  decode.loss_mask: 0.1843  decode.loss_dice: 0.1755  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 0.1882  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.1867  decode.d1.loss_dice: 0.1851  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.1863  decode.d2.loss_dice: 0.1848  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.1852  decode.d3.loss_dice: 0.1853  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.1853  decode.d4.loss_dice: 0.1840  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 0.1859  decode.d5.loss_dice: 0.1850  decode.d6.loss_cls: 0.0773  decode.d6.loss_mask: 0.1839  decode.d6.loss_dice: 0.1811  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.1853  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.1872  decode.d8.loss_dice: 0.1821
10/01 01:57:55 - mmengine - INFO - Iter(train) [138700/320000]  base_lr: 5.9969e-05 lr: 5.9969e-06  eta: 22:03:27  time: 0.4408  data_time: 0.0093  memory: 5129  grad_norm: 19.9426  loss: 4.0590  decode.loss_cls: 0.0030  decode.loss_mask: 0.1571  decode.loss_dice: 0.1518  decode.d0.loss_cls: 0.8647  decode.d0.loss_mask: 0.1570  decode.d0.loss_dice: 0.1495  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 0.1572  decode.d1.loss_dice: 0.1572  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.1568  decode.d2.loss_dice: 0.1647  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.1579  decode.d3.loss_dice: 0.1519  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.1565  decode.d4.loss_dice: 0.1605  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.1565  decode.d5.loss_dice: 0.1634  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.1577  decode.d6.loss_dice: 0.1348  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1564  decode.d7.loss_dice: 0.1609  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.1558  decode.d8.loss_dice: 0.1626
10/01 01:58:18 - mmengine - INFO - Iter(train) [138750/320000]  base_lr: 5.9954e-05 lr: 5.9954e-06  eta: 22:03:05  time: 0.4411  data_time: 0.0097  memory: 5145  grad_norm: 54.9601  loss: 5.2356  decode.loss_cls: 0.0515  decode.loss_mask: 0.1833  decode.loss_dice: 0.1975  decode.d0.loss_cls: 0.8937  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1791  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.1816  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.1814  decode.d2.loss_dice: 0.2028  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.1809  decode.d3.loss_dice: 0.1996  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.1814  decode.d4.loss_dice: 0.2165  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.1814  decode.d5.loss_dice: 0.2226  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.1814  decode.d6.loss_dice: 0.1742  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.1840  decode.d7.loss_dice: 0.1828  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.1819  decode.d8.loss_dice: 0.1804
10/01 01:58:40 - mmengine - INFO - Iter(train) [138800/320000]  base_lr: 5.9939e-05 lr: 5.9939e-06  eta: 22:02:43  time: 0.4401  data_time: 0.0094  memory: 5129  grad_norm: 28.7310  loss: 5.2377  decode.loss_cls: 0.0379  decode.loss_mask: 0.1878  decode.loss_dice: 0.1974  decode.d0.loss_cls: 0.9036  decode.d0.loss_mask: 0.1898  decode.d0.loss_dice: 0.2006  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.2129  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.2082  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.1901  decode.d3.loss_dice: 0.1472  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.1889  decode.d4.loss_dice: 0.1914  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.1907  decode.d5.loss_dice: 0.1935  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.1883  decode.d6.loss_dice: 0.1999  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.1895  decode.d7.loss_dice: 0.2023  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.1874
10/01 01:59:02 - mmengine - INFO - Iter(train) [138850/320000]  base_lr: 5.9924e-05 lr: 5.9924e-06  eta: 22:02:22  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 83.2317  loss: 6.0992  decode.loss_cls: 0.0686  decode.loss_mask: 0.1981  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.7557  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.2364  decode.d1.loss_cls: 0.2403  decode.d1.loss_mask: 0.1985  decode.d1.loss_dice: 0.2158  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.2521  decode.d3.loss_cls: 0.1010  decode.d3.loss_mask: 0.1984  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.1016  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.2518  decode.d5.loss_cls: 0.1215  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.1976  decode.d6.loss_dice: 0.2521  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.1976  decode.d7.loss_dice: 0.2448  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.1979  decode.d8.loss_dice: 0.2370
10/01 01:59:24 - mmengine - INFO - Iter(train) [138900/320000]  base_lr: 5.9909e-05 lr: 5.9909e-06  eta: 22:02:00  time: 0.4403  data_time: 0.0094  memory: 5129  grad_norm: 28.6513  loss: 4.6847  decode.loss_cls: 0.0059  decode.loss_mask: 0.1837  decode.loss_dice: 0.1806  decode.d0.loss_cls: 0.9053  decode.d0.loss_mask: 0.1862  decode.d0.loss_dice: 0.2012  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.1846  decode.d1.loss_dice: 0.1950  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.1879  decode.d2.loss_dice: 0.1816  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.1881  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.1890  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.1862  decode.d5.loss_dice: 0.1794  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1835  decode.d6.loss_dice: 0.1929  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.1832  decode.d7.loss_dice: 0.1830  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.1857  decode.d8.loss_dice: 0.1830
10/01 01:59:46 - mmengine - INFO - Iter(train) [138950/320000]  base_lr: 5.9894e-05 lr: 5.9894e-06  eta: 22:01:38  time: 0.4394  data_time: 0.0092  memory: 5145  grad_norm: 89.8649  loss: 4.5922  decode.loss_cls: 0.0083  decode.loss_mask: 0.1838  decode.loss_dice: 0.1959  decode.d0.loss_cls: 0.7727  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.1744  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.1782  decode.d1.loss_dice: 0.1861  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.1827  decode.d2.loss_dice: 0.1869  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.1860  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.1842  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.1820  decode.d5.loss_dice: 0.1868  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.1826  decode.d6.loss_dice: 0.1773  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1842  decode.d7.loss_dice: 0.1954  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.1807  decode.d8.loss_dice: 0.1890
10/01 02:00:08 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:00:08 - mmengine - INFO - Iter(train) [139000/320000]  base_lr: 5.9879e-05 lr: 5.9879e-06  eta: 22:01:16  time: 0.4412  data_time: 0.0095  memory: 5129  grad_norm: 65.4844  loss: 6.4046  decode.loss_cls: 0.1164  decode.loss_mask: 0.2483  decode.loss_dice: 0.1801  decode.d0.loss_cls: 0.7909  decode.d0.loss_mask: 0.2450  decode.d0.loss_dice: 0.2164  decode.d1.loss_cls: 0.1402  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.2457  decode.d2.loss_dice: 0.2303  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.2483  decode.d3.loss_dice: 0.2308  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.2481  decode.d4.loss_dice: 0.2253  decode.d5.loss_cls: 0.1168  decode.d5.loss_mask: 0.2497  decode.d5.loss_dice: 0.2256  decode.d6.loss_cls: 0.1091  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.2468  decode.d7.loss_dice: 0.2292  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 0.2518  decode.d8.loss_dice: 0.2324
10/01 02:00:30 - mmengine - INFO - Iter(train) [139050/320000]  base_lr: 5.9864e-05 lr: 5.9864e-06  eta: 22:00:55  time: 0.4433  data_time: 0.0094  memory: 5145  grad_norm: 30.0928  loss: 3.9419  decode.loss_cls: 0.0047  decode.loss_mask: 0.1597  decode.loss_dice: 0.1560  decode.d0.loss_cls: 0.7846  decode.d0.loss_mask: 0.1567  decode.d0.loss_dice: 0.1539  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.1571  decode.d1.loss_dice: 0.1551  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.1576  decode.d2.loss_dice: 0.1467  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.1578  decode.d3.loss_dice: 0.1558  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.1596  decode.d4.loss_dice: 0.1557  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.1561  decode.d5.loss_dice: 0.1494  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.1586  decode.d6.loss_dice: 0.1455  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.1578  decode.d7.loss_dice: 0.1466  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.1579  decode.d8.loss_dice: 0.1501
10/01 02:00:52 - mmengine - INFO - Iter(train) [139100/320000]  base_lr: 5.9850e-05 lr: 5.9850e-06  eta: 22:00:33  time: 0.4408  data_time: 0.0095  memory: 5145  grad_norm: 49.4010  loss: 4.1012  decode.loss_cls: 0.0053  decode.loss_mask: 0.1912  decode.loss_dice: 0.1252  decode.d0.loss_cls: 0.8135  decode.d0.loss_mask: 0.1880  decode.d0.loss_dice: 0.1233  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.1292  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.1308  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.1896  decode.d3.loss_dice: 0.1326  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.1299  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.1909  decode.d5.loss_dice: 0.1315  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.1893  decode.d6.loss_dice: 0.1302  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1918  decode.d7.loss_dice: 0.1298  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1913  decode.d8.loss_dice: 0.1282
10/01 02:01:14 - mmengine - INFO - Iter(train) [139150/320000]  base_lr: 5.9835e-05 lr: 5.9835e-06  eta: 22:00:11  time: 0.4406  data_time: 0.0095  memory: 5145  grad_norm: 93.6874  loss: 5.1650  decode.loss_cls: 0.0718  decode.loss_mask: 0.1840  decode.loss_dice: 0.1586  decode.d0.loss_cls: 0.8836  decode.d0.loss_mask: 0.1855  decode.d0.loss_dice: 0.1562  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.1601  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.1823  decode.d2.loss_dice: 0.1508  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.1051  decode.d4.loss_mask: 0.1866  decode.d4.loss_dice: 0.1612  decode.d5.loss_cls: 0.1127  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1636  decode.d6.loss_cls: 0.1001  decode.d6.loss_mask: 0.1851  decode.d6.loss_dice: 0.1608  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.1873  decode.d7.loss_dice: 0.1585  decode.d8.loss_cls: 0.1120  decode.d8.loss_mask: 0.1859  decode.d8.loss_dice: 0.1581
10/01 02:01:36 - mmengine - INFO - Iter(train) [139200/320000]  base_lr: 5.9820e-05 lr: 5.9820e-06  eta: 21:59:50  time: 0.4402  data_time: 0.0094  memory: 5145  grad_norm: 63.9478  loss: 4.6179  decode.loss_cls: 0.0033  decode.loss_mask: 0.2222  decode.loss_dice: 0.1638  decode.d0.loss_cls: 0.7781  decode.d0.loss_mask: 0.2212  decode.d0.loss_dice: 0.1639  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.2248  decode.d1.loss_dice: 0.1534  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.1534  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.1604  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.1589  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.2211  decode.d5.loss_dice: 0.1621  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.2197  decode.d6.loss_dice: 0.1631  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.2208  decode.d7.loss_dice: 0.1582  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.2194  decode.d8.loss_dice: 0.1561
10/01 02:01:58 - mmengine - INFO - Iter(train) [139250/320000]  base_lr: 5.9805e-05 lr: 5.9805e-06  eta: 21:59:28  time: 0.4402  data_time: 0.0096  memory: 5145  grad_norm: 21.2713  loss: 4.1516  decode.loss_cls: 0.0017  decode.loss_mask: 0.1915  decode.loss_dice: 0.1421  decode.d0.loss_cls: 0.8265  decode.d0.loss_mask: 0.1925  decode.d0.loss_dice: 0.1413  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.1921  decode.d1.loss_dice: 0.1376  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.1922  decode.d2.loss_dice: 0.1382  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.1905  decode.d3.loss_dice: 0.1402  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.1893  decode.d4.loss_dice: 0.1376  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1923  decode.d5.loss_dice: 0.1377  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.1914  decode.d6.loss_dice: 0.1410  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.1392  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.1366
10/01 02:02:20 - mmengine - INFO - Iter(train) [139300/320000]  base_lr: 5.9790e-05 lr: 5.9790e-06  eta: 21:59:06  time: 0.4401  data_time: 0.0093  memory: 5119  grad_norm: 26.8831  loss: 4.3267  decode.loss_cls: 0.0543  decode.loss_mask: 0.1523  decode.loss_dice: 0.1676  decode.d0.loss_cls: 0.7567  decode.d0.loss_mask: 0.1545  decode.d0.loss_dice: 0.1754  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.1565  decode.d1.loss_dice: 0.1878  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.1534  decode.d2.loss_dice: 0.1605  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.1542  decode.d3.loss_dice: 0.1588  decode.d4.loss_cls: 0.0248  decode.d4.loss_mask: 0.1562  decode.d4.loss_dice: 0.1652  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.1537  decode.d5.loss_dice: 0.1604  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.1550  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.1564  decode.d7.loss_dice: 0.1734  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.1559  decode.d8.loss_dice: 0.1816
10/01 02:02:42 - mmengine - INFO - Iter(train) [139350/320000]  base_lr: 5.9775e-05 lr: 5.9775e-06  eta: 21:58:44  time: 0.4412  data_time: 0.0096  memory: 5145  grad_norm: 70.5705  loss: 6.2383  decode.loss_cls: 0.1646  decode.loss_mask: 0.1959  decode.loss_dice: 0.1991  decode.d0.loss_cls: 0.9773  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 0.1952  decode.d1.loss_dice: 0.1860  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.1899  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.1410  decode.d3.loss_mask: 0.1903  decode.d3.loss_dice: 0.1891  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.1903  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.1687  decode.d5.loss_mask: 0.1894  decode.d5.loss_dice: 0.1909  decode.d6.loss_cls: 0.1726  decode.d6.loss_mask: 0.1910  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.1544  decode.d7.loss_mask: 0.1923  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.1804  decode.d8.loss_mask: 0.1925  decode.d8.loss_dice: 0.1992
10/01 02:03:04 - mmengine - INFO - Iter(train) [139400/320000]  base_lr: 5.9760e-05 lr: 5.9760e-06  eta: 21:58:23  time: 0.4410  data_time: 0.0096  memory: 5145  grad_norm: 33.1776  loss: 4.4750  decode.loss_cls: 0.0038  decode.loss_mask: 0.1998  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.7436  decode.d0.loss_mask: 0.2019  decode.d0.loss_dice: 0.1691  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.2010  decode.d1.loss_dice: 0.1721  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.1994  decode.d2.loss_dice: 0.1671  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.1689  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.1973  decode.d4.loss_dice: 0.1750  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.2002  decode.d5.loss_dice: 0.1674  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.2005  decode.d6.loss_dice: 0.1726  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.1681  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.1669
10/01 02:03:26 - mmengine - INFO - Iter(train) [139450/320000]  base_lr: 5.9745e-05 lr: 5.9745e-06  eta: 21:58:01  time: 0.4407  data_time: 0.0098  memory: 5145  grad_norm: 43.8246  loss: 5.4887  decode.loss_cls: 0.0077  decode.loss_mask: 0.2556  decode.loss_dice: 0.2037  decode.d0.loss_cls: 0.8126  decode.d0.loss_mask: 0.2531  decode.d0.loss_dice: 0.1992  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2527  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.2005  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.2560  decode.d3.loss_dice: 0.1939  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.2511  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2526  decode.d5.loss_dice: 0.2009  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.2523  decode.d6.loss_dice: 0.1976  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.2034  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2533  decode.d8.loss_dice: 0.2036
10/01 02:03:48 - mmengine - INFO - Iter(train) [139500/320000]  base_lr: 5.9730e-05 lr: 5.9730e-06  eta: 21:57:39  time: 0.4423  data_time: 0.0095  memory: 5120  grad_norm: 27.1680  loss: 4.0144  decode.loss_cls: 0.0028  decode.loss_mask: 0.1778  decode.loss_dice: 0.1418  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 0.1811  decode.d0.loss_dice: 0.1421  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.1802  decode.d1.loss_dice: 0.1415  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.1776  decode.d2.loss_dice: 0.1393  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.1790  decode.d3.loss_dice: 0.1448  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.1771  decode.d4.loss_dice: 0.1375  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.1739  decode.d5.loss_dice: 0.1362  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1742  decode.d6.loss_dice: 0.1401  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.1764  decode.d7.loss_dice: 0.1401  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.1785  decode.d8.loss_dice: 0.1431
10/01 02:04:11 - mmengine - INFO - Iter(train) [139550/320000]  base_lr: 5.9716e-05 lr: 5.9716e-06  eta: 21:57:18  time: 0.4442  data_time: 0.0094  memory: 5145  grad_norm: 66.8265  loss: 5.6836  decode.loss_cls: 0.0412  decode.loss_mask: 0.2006  decode.loss_dice: 0.2032  decode.d0.loss_cls: 0.9052  decode.d0.loss_mask: 0.2035  decode.d0.loss_dice: 0.2036  decode.d1.loss_cls: 0.1504  decode.d1.loss_mask: 0.2019  decode.d1.loss_dice: 0.1970  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.2019  decode.d2.loss_dice: 0.2106  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.2097  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.2129  decode.d4.loss_dice: 0.2349  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.2092  decode.d5.loss_dice: 0.2171  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.2076  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.2039  decode.d8.loss_dice: 0.2133
10/01 02:04:33 - mmengine - INFO - Iter(train) [139600/320000]  base_lr: 5.9701e-05 lr: 5.9701e-06  eta: 21:56:56  time: 0.4429  data_time: 0.0096  memory: 5129  grad_norm: 48.5710  loss: 4.6508  decode.loss_cls: 0.0038  decode.loss_mask: 0.2218  decode.loss_dice: 0.1516  decode.d0.loss_cls: 0.8021  decode.d0.loss_mask: 0.2227  decode.d0.loss_dice: 0.1603  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.1818  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.2227  decode.d2.loss_dice: 0.1639  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.2227  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.2217  decode.d4.loss_dice: 0.1521  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.2216  decode.d5.loss_dice: 0.1527  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.2236  decode.d6.loss_dice: 0.1550  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.1483  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.1555
10/01 02:04:55 - mmengine - INFO - Iter(train) [139650/320000]  base_lr: 5.9686e-05 lr: 5.9686e-06  eta: 21:56:34  time: 0.4428  data_time: 0.0096  memory: 5145  grad_norm: 240.9237  loss: 7.6919  decode.loss_cls: 0.1236  decode.loss_mask: 0.3316  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.9163  decode.d0.loss_mask: 0.3384  decode.d0.loss_dice: 0.2155  decode.d1.loss_cls: 0.1265  decode.d1.loss_mask: 0.3390  decode.d1.loss_dice: 0.2152  decode.d2.loss_cls: 0.1446  decode.d2.loss_mask: 0.3314  decode.d2.loss_dice: 0.2223  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 0.3330  decode.d3.loss_dice: 0.2115  decode.d4.loss_cls: 0.1306  decode.d4.loss_mask: 0.3387  decode.d4.loss_dice: 0.2182  decode.d5.loss_cls: 0.1295  decode.d5.loss_mask: 0.3324  decode.d5.loss_dice: 0.2210  decode.d6.loss_cls: 0.1499  decode.d6.loss_mask: 0.3309  decode.d6.loss_dice: 0.2183  decode.d7.loss_cls: 0.1602  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.2185  decode.d8.loss_cls: 0.1463  decode.d8.loss_mask: 0.3396  decode.d8.loss_dice: 0.2165
10/01 02:05:17 - mmengine - INFO - Iter(train) [139700/320000]  base_lr: 5.9671e-05 lr: 5.9671e-06  eta: 21:56:13  time: 0.4435  data_time: 0.0098  memory: 5129  grad_norm: 43.7221  loss: 4.7384  decode.loss_cls: 0.0665  decode.loss_mask: 0.1664  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.9400  decode.d0.loss_mask: 0.1657  decode.d0.loss_dice: 0.1541  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.1628  decode.d1.loss_dice: 0.1571  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.1646  decode.d2.loss_dice: 0.1575  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.1630  decode.d3.loss_dice: 0.1504  decode.d4.loss_cls: 0.0521  decode.d4.loss_mask: 0.1649  decode.d4.loss_dice: 0.1586  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.1652  decode.d5.loss_dice: 0.1553  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.1660  decode.d6.loss_dice: 0.1516  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.1652  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0673  decode.d8.loss_mask: 0.1659  decode.d8.loss_dice: 0.1644
10/01 02:05:39 - mmengine - INFO - Iter(train) [139750/320000]  base_lr: 5.9656e-05 lr: 5.9656e-06  eta: 21:55:51  time: 0.4434  data_time: 0.0099  memory: 5145  grad_norm: 53.7989  loss: 6.8907  decode.loss_cls: 0.1063  decode.loss_mask: 0.2249  decode.loss_dice: 0.2755  decode.d0.loss_cls: 0.8234  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2482  decode.d1.loss_cls: 0.2002  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.2588  decode.d2.loss_cls: 0.1403  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.2809  decode.d3.loss_cls: 0.1282  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.2739  decode.d4.loss_cls: 0.1112  decode.d4.loss_mask: 0.2283  decode.d4.loss_dice: 0.2599  decode.d5.loss_cls: 0.1098  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.2279  decode.d6.loss_cls: 0.1285  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2807  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.2615  decode.d8.loss_cls: 0.1291  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.2237
10/01 02:06:01 - mmengine - INFO - Iter(train) [139800/320000]  base_lr: 5.9641e-05 lr: 5.9641e-06  eta: 21:55:30  time: 0.4425  data_time: 0.0095  memory: 5129  grad_norm: 97.9276  loss: 4.9189  decode.loss_cls: 0.0147  decode.loss_mask: 0.2192  decode.loss_dice: 0.1740  decode.d0.loss_cls: 0.8023  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.1802  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.2196  decode.d1.loss_dice: 0.1692  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.1707  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.2163  decode.d3.loss_dice: 0.1702  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.2170  decode.d4.loss_dice: 0.1678  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.1726  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.2193  decode.d6.loss_dice: 0.1729  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.2164  decode.d7.loss_dice: 0.1740  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.1736
10/01 02:06:24 - mmengine - INFO - Iter(train) [139850/320000]  base_lr: 5.9626e-05 lr: 5.9626e-06  eta: 21:55:08  time: 0.4427  data_time: 0.0094  memory: 5119  grad_norm: 69.2059  loss: 4.5890  decode.loss_cls: 0.0586  decode.loss_mask: 0.1717  decode.loss_dice: 0.1515  decode.d0.loss_cls: 0.7695  decode.d0.loss_mask: 0.1702  decode.d0.loss_dice: 0.1456  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.1724  decode.d1.loss_dice: 0.1513  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.1724  decode.d2.loss_dice: 0.1572  decode.d3.loss_cls: 0.0679  decode.d3.loss_mask: 0.1716  decode.d3.loss_dice: 0.1546  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.1722  decode.d4.loss_dice: 0.1576  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.1714  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.1732  decode.d6.loss_dice: 0.1540  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.1719  decode.d7.loss_dice: 0.1535  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.1720  decode.d8.loss_dice: 0.1532
10/01 02:06:46 - mmengine - INFO - Iter(train) [139900/320000]  base_lr: 5.9611e-05 lr: 5.9611e-06  eta: 21:54:47  time: 0.4431  data_time: 0.0097  memory: 5129  grad_norm: 59.7840  loss: 5.4232  decode.loss_cls: 0.1067  decode.loss_mask: 0.1848  decode.loss_dice: 0.1539  decode.d0.loss_cls: 0.8823  decode.d0.loss_mask: 0.1892  decode.d0.loss_dice: 0.1595  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 0.1862  decode.d1.loss_dice: 0.1672  decode.d2.loss_cls: 0.1156  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.1641  decode.d3.loss_cls: 0.1197  decode.d3.loss_mask: 0.1883  decode.d3.loss_dice: 0.1627  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 0.1890  decode.d4.loss_dice: 0.1636  decode.d5.loss_cls: 0.1199  decode.d5.loss_mask: 0.1871  decode.d5.loss_dice: 0.1576  decode.d6.loss_cls: 0.1194  decode.d6.loss_mask: 0.1874  decode.d6.loss_dice: 0.1583  decode.d7.loss_cls: 0.1170  decode.d7.loss_mask: 0.1885  decode.d7.loss_dice: 0.1582  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.1881  decode.d8.loss_dice: 0.1601
10/01 02:07:08 - mmengine - INFO - Iter(train) [139950/320000]  base_lr: 5.9596e-05 lr: 5.9596e-06  eta: 21:54:25  time: 0.4420  data_time: 0.0096  memory: 5129  grad_norm: 68.4926  loss: 5.4891  decode.loss_cls: 0.0512  decode.loss_mask: 0.2136  decode.loss_dice: 0.2014  decode.d0.loss_cls: 0.8551  decode.d0.loss_mask: 0.2145  decode.d0.loss_dice: 0.2101  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.2079  decode.d2.loss_cls: 0.0527  decode.d2.loss_mask: 0.2106  decode.d2.loss_dice: 0.2025  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.2094  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.1884  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.1986  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.2118  decode.d7.loss_dice: 0.1989  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.2121  decode.d8.loss_dice: 0.2074
10/01 02:07:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:07:30 - mmengine - INFO - Iter(train) [140000/320000]  base_lr: 5.9582e-05 lr: 5.9582e-06  eta: 21:54:04  time: 0.4420  data_time: 0.0093  memory: 5129  grad_norm: 27.5262  loss: 4.4153  decode.loss_cls: 0.0043  decode.loss_mask: 0.1985  decode.loss_dice: 0.1662  decode.d0.loss_cls: 0.7348  decode.d0.loss_mask: 0.1955  decode.d0.loss_dice: 0.1679  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.1961  decode.d1.loss_dice: 0.1649  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.1642  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.1970  decode.d3.loss_dice: 0.1770  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.1951  decode.d4.loss_dice: 0.1644  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.1695  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.1938  decode.d6.loss_dice: 0.1670  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.1967  decode.d7.loss_dice: 0.1661  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.1962  decode.d8.loss_dice: 0.1635
10/01 02:07:52 - mmengine - INFO - Iter(train) [140050/320000]  base_lr: 5.9567e-05 lr: 5.9567e-06  eta: 21:53:42  time: 0.4417  data_time: 0.0094  memory: 5145  grad_norm: 69.1044  loss: 5.5692  decode.loss_cls: 0.0948  decode.loss_mask: 0.2007  decode.loss_dice: 0.1885  decode.d0.loss_cls: 0.9392  decode.d0.loss_mask: 0.2021  decode.d0.loss_dice: 0.1814  decode.d1.loss_cls: 0.1472  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.1130  decode.d2.loss_mask: 0.1984  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.2013  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.2079  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.1993  decode.d5.loss_dice: 0.1916  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.2036  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.1989  decode.d7.loss_dice: 0.2056  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.1835
10/01 02:08:14 - mmengine - INFO - Iter(train) [140100/320000]  base_lr: 5.9552e-05 lr: 5.9552e-06  eta: 21:53:20  time: 0.4409  data_time: 0.0096  memory: 5120  grad_norm: 69.6729  loss: 5.4081  decode.loss_cls: 0.0777  decode.loss_mask: 0.2047  decode.loss_dice: 0.2159  decode.d0.loss_cls: 0.9805  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.2032  decode.d2.loss_dice: 0.2096  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.2002  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.1986  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.2012  decode.d5.loss_dice: 0.2044  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.2100  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.2151  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.1982  decode.d8.loss_dice: 0.2130
10/01 02:08:36 - mmengine - INFO - Iter(train) [140150/320000]  base_lr: 5.9537e-05 lr: 5.9537e-06  eta: 21:52:59  time: 0.4419  data_time: 0.0095  memory: 5129  grad_norm: 109.0378  loss: 5.2471  decode.loss_cls: 0.0587  decode.loss_mask: 0.2234  decode.loss_dice: 0.1562  decode.d0.loss_cls: 0.8600  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.1612  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.1588  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.1579  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.1537  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.2260  decode.d4.loss_dice: 0.1564  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.1569  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.1563  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.2242  decode.d7.loss_dice: 0.1569  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.1557
10/01 02:08:59 - mmengine - INFO - Iter(train) [140200/320000]  base_lr: 5.9522e-05 lr: 5.9522e-06  eta: 21:52:37  time: 0.4396  data_time: 0.0095  memory: 5129  grad_norm: 48.6218  loss: 4.7858  decode.loss_cls: 0.0021  decode.loss_mask: 0.1972  decode.loss_dice: 0.1899  decode.d0.loss_cls: 0.7136  decode.d0.loss_mask: 0.2031  decode.d0.loss_dice: 0.2052  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.1990  decode.d1.loss_dice: 0.1840  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.1984  decode.d2.loss_dice: 0.2017  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.1988  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.1953  decode.d4.loss_dice: 0.1897  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.2016  decode.d5.loss_dice: 0.2107  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1964  decode.d6.loss_dice: 0.2041  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1978  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.1965
10/01 02:09:20 - mmengine - INFO - Iter(train) [140250/320000]  base_lr: 5.9507e-05 lr: 5.9507e-06  eta: 21:52:15  time: 0.4390  data_time: 0.0095  memory: 5129  grad_norm: 28.9201  loss: 4.3850  decode.loss_cls: 0.0012  decode.loss_mask: 0.2152  decode.loss_dice: 0.1500  decode.d0.loss_cls: 0.7130  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.1480  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.1507  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2142  decode.d2.loss_dice: 0.1495  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2150  decode.d3.loss_dice: 0.1497  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2155  decode.d4.loss_dice: 0.1502  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2150  decode.d5.loss_dice: 0.1513  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.2179  decode.d6.loss_dice: 0.1524  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.1538  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2143  decode.d8.loss_dice: 0.1510
10/01 02:09:43 - mmengine - INFO - Iter(train) [140300/320000]  base_lr: 5.9492e-05 lr: 5.9492e-06  eta: 21:51:53  time: 0.4395  data_time: 0.0094  memory: 5129  grad_norm: 34.6961  loss: 5.0271  decode.loss_cls: 0.0064  decode.loss_mask: 0.2013  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.8828  decode.d0.loss_mask: 0.2005  decode.d0.loss_dice: 0.1845  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.1990  decode.d1.loss_dice: 0.2086  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.2084  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.1992  decode.d3.loss_dice: 0.2055  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.2002  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.2073  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.2081  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2033  decode.d7.loss_dice: 0.2106  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.2112
10/01 02:10:05 - mmengine - INFO - Iter(train) [140350/320000]  base_lr: 5.9477e-05 lr: 5.9477e-06  eta: 21:51:32  time: 0.4400  data_time: 0.0095  memory: 5129  grad_norm: 133.6469  loss: 5.0388  decode.loss_cls: 0.0160  decode.loss_mask: 0.2029  decode.loss_dice: 0.2156  decode.d0.loss_cls: 0.7954  decode.d0.loss_mask: 0.2037  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.1993  decode.d1.loss_dice: 0.2006  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.2039  decode.d2.loss_dice: 0.1817  decode.d3.loss_cls: 0.0100  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.2019  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.2021  decode.d4.loss_dice: 0.2147  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.2035  decode.d5.loss_dice: 0.2144  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.2043  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.0503  decode.d7.loss_mask: 0.2072  decode.d7.loss_dice: 0.2132  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.2048
10/01 02:10:27 - mmengine - INFO - Iter(train) [140400/320000]  base_lr: 5.9462e-05 lr: 5.9462e-06  eta: 21:51:10  time: 0.4388  data_time: 0.0095  memory: 5129  grad_norm: 163.1100  loss: 6.0769  decode.loss_cls: 0.0522  decode.loss_mask: 0.2768  decode.loss_dice: 0.2084  decode.d0.loss_cls: 0.8575  decode.d0.loss_mask: 0.2813  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.2821  decode.d1.loss_dice: 0.2130  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.2143  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.2138  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.2782  decode.d4.loss_dice: 0.2139  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0333  decode.d6.loss_mask: 0.2779  decode.d6.loss_dice: 0.2128  decode.d7.loss_cls: 0.0339  decode.d7.loss_mask: 0.2823  decode.d7.loss_dice: 0.2105  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.2787  decode.d8.loss_dice: 0.2097
10/01 02:10:49 - mmengine - INFO - Iter(train) [140450/320000]  base_lr: 5.9447e-05 lr: 5.9447e-06  eta: 21:50:48  time: 0.4429  data_time: 0.0095  memory: 5145  grad_norm: 31.3405  loss: 5.0960  decode.loss_cls: 0.0428  decode.loss_mask: 0.2094  decode.loss_dice: 0.1676  decode.d0.loss_cls: 0.8865  decode.d0.loss_mask: 0.2102  decode.d0.loss_dice: 0.1662  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1721  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.2068  decode.d2.loss_dice: 0.1761  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.1735  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.2091  decode.d4.loss_dice: 0.1757  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.2051  decode.d5.loss_dice: 0.1748  decode.d6.loss_cls: 0.0408  decode.d6.loss_mask: 0.2104  decode.d6.loss_dice: 0.1759  decode.d7.loss_cls: 0.0415  decode.d7.loss_mask: 0.2093  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0413  decode.d8.loss_mask: 0.2100  decode.d8.loss_dice: 0.1730
10/01 02:11:11 - mmengine - INFO - Iter(train) [140500/320000]  base_lr: 5.9433e-05 lr: 5.9433e-06  eta: 21:50:27  time: 0.4436  data_time: 0.0093  memory: 5129  grad_norm: 79.4357  loss: 5.4831  decode.loss_cls: 0.0767  decode.loss_mask: 0.2001  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.9067  decode.d0.loss_mask: 0.2093  decode.d0.loss_dice: 0.1808  decode.d1.loss_cls: 0.0907  decode.d1.loss_mask: 0.2057  decode.d1.loss_dice: 0.1757  decode.d2.loss_cls: 0.1368  decode.d2.loss_mask: 0.1993  decode.d2.loss_dice: 0.1702  decode.d3.loss_cls: 0.1374  decode.d3.loss_mask: 0.2005  decode.d3.loss_dice: 0.1698  decode.d4.loss_cls: 0.0560  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 0.1962  decode.d5.loss_dice: 0.1664  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.1835  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.1696
10/01 02:11:33 - mmengine - INFO - Iter(train) [140550/320000]  base_lr: 5.9418e-05 lr: 5.9418e-06  eta: 21:50:05  time: 0.4421  data_time: 0.0094  memory: 5129  grad_norm: 78.6974  loss: 6.8396  decode.loss_cls: 0.1003  decode.loss_mask: 0.2069  decode.loss_dice: 0.2765  decode.d0.loss_cls: 0.9638  decode.d0.loss_mask: 0.2255  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.1700  decode.d1.loss_mask: 0.1994  decode.d1.loss_dice: 0.2601  decode.d2.loss_cls: 0.0908  decode.d2.loss_mask: 0.1956  decode.d2.loss_dice: 0.2779  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.2005  decode.d3.loss_dice: 0.2661  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.1986  decode.d4.loss_dice: 0.2762  decode.d5.loss_cls: 0.0948  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.1316  decode.d6.loss_mask: 0.2200  decode.d6.loss_dice: 0.2712  decode.d7.loss_cls: 0.1398  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2897  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.2722
10/01 02:11:55 - mmengine - INFO - Iter(train) [140600/320000]  base_lr: 5.9403e-05 lr: 5.9403e-06  eta: 21:49:43  time: 0.4442  data_time: 0.0094  memory: 5129  grad_norm: 23.7199  loss: 4.0620  decode.loss_cls: 0.0060  decode.loss_mask: 0.1807  decode.loss_dice: 0.1364  decode.d0.loss_cls: 0.7979  decode.d0.loss_mask: 0.2203  decode.d0.loss_dice: 0.1433  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.1368  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.1794  decode.d2.loss_dice: 0.1356  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.1805  decode.d3.loss_dice: 0.1325  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.1766  decode.d4.loss_dice: 0.1336  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.1792  decode.d5.loss_dice: 0.1355  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.1776  decode.d6.loss_dice: 0.1324  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.1818  decode.d7.loss_dice: 0.1345  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.1808  decode.d8.loss_dice: 0.1355
10/01 02:12:17 - mmengine - INFO - Iter(train) [140650/320000]  base_lr: 5.9388e-05 lr: 5.9388e-06  eta: 21:49:22  time: 0.4418  data_time: 0.0094  memory: 5129  grad_norm: 74.7425  loss: 4.4978  decode.loss_cls: 0.0316  decode.loss_mask: 0.1833  decode.loss_dice: 0.1604  decode.d0.loss_cls: 0.8671  decode.d0.loss_mask: 0.1893  decode.d0.loss_dice: 0.1495  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.1882  decode.d1.loss_dice: 0.1577  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.1871  decode.d2.loss_dice: 0.1597  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.1865  decode.d3.loss_dice: 0.1578  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.1877  decode.d4.loss_dice: 0.1610  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.1864  decode.d5.loss_dice: 0.1580  decode.d6.loss_cls: 0.0278  decode.d6.loss_mask: 0.1849  decode.d6.loss_dice: 0.1601  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.1838  decode.d7.loss_dice: 0.1598  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.1859  decode.d8.loss_dice: 0.1550
10/01 02:12:39 - mmengine - INFO - Iter(train) [140700/320000]  base_lr: 5.9373e-05 lr: 5.9373e-06  eta: 21:49:00  time: 0.4444  data_time: 0.0094  memory: 5129  grad_norm: 86.9832  loss: 4.0568  decode.loss_cls: 0.0056  decode.loss_mask: 0.1717  decode.loss_dice: 0.1426  decode.d0.loss_cls: 0.7179  decode.d0.loss_mask: 0.1838  decode.d0.loss_dice: 0.1489  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 0.1753  decode.d1.loss_dice: 0.1380  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.1735  decode.d2.loss_dice: 0.1403  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.1750  decode.d3.loss_dice: 0.1361  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.1710  decode.d4.loss_dice: 0.1376  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.1730  decode.d5.loss_dice: 0.1361  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.1717  decode.d6.loss_dice: 0.1365  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.1749  decode.d7.loss_dice: 0.1427  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.1713  decode.d8.loss_dice: 0.1368
10/01 02:13:01 - mmengine - INFO - Iter(train) [140750/320000]  base_lr: 5.9358e-05 lr: 5.9358e-06  eta: 21:48:39  time: 0.4423  data_time: 0.0095  memory: 5129  grad_norm: 24.9320  loss: 4.2588  decode.loss_cls: 0.0049  decode.loss_mask: 0.1782  decode.loss_dice: 0.1678  decode.d0.loss_cls: 0.7660  decode.d0.loss_mask: 0.1791  decode.d0.loss_dice: 0.1694  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.1784  decode.d1.loss_dice: 0.1664  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.1797  decode.d2.loss_dice: 0.1681  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.1788  decode.d3.loss_dice: 0.1688  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1787  decode.d4.loss_dice: 0.1671  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.1795  decode.d5.loss_dice: 0.1699  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.1778  decode.d6.loss_dice: 0.1690  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.1795  decode.d7.loss_dice: 0.1663  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.1783  decode.d8.loss_dice: 0.1640
10/01 02:13:24 - mmengine - INFO - Iter(train) [140800/320000]  base_lr: 5.9343e-05 lr: 5.9343e-06  eta: 21:48:17  time: 0.4423  data_time: 0.0096  memory: 5129  grad_norm: 102.8994  loss: 6.3289  decode.loss_cls: 0.0918  decode.loss_mask: 0.2397  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.8050  decode.d0.loss_mask: 0.2413  decode.d0.loss_dice: 0.2277  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.2393  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.2237  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.2441  decode.d3.loss_dice: 0.2240  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.2437  decode.d4.loss_dice: 0.2552  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.2375  decode.d5.loss_dice: 0.2358  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.2171  decode.d7.loss_cls: 0.1072  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.2313  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.2401  decode.d8.loss_dice: 0.2332
10/01 02:13:46 - mmengine - INFO - Iter(train) [140850/320000]  base_lr: 5.9328e-05 lr: 5.9328e-06  eta: 21:47:55  time: 0.4417  data_time: 0.0095  memory: 5129  grad_norm: 33.1580  loss: 4.5602  decode.loss_cls: 0.0096  decode.loss_mask: 0.1875  decode.loss_dice: 0.1758  decode.d0.loss_cls: 0.8841  decode.d0.loss_mask: 0.1860  decode.d0.loss_dice: 0.1640  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.1883  decode.d1.loss_dice: 0.1773  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.1865  decode.d2.loss_dice: 0.1774  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.1842  decode.d3.loss_dice: 0.1747  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.1853  decode.d4.loss_dice: 0.1791  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.1887  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.1860  decode.d6.loss_dice: 0.1733  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.1864  decode.d7.loss_dice: 0.1681  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.1864  decode.d8.loss_dice: 0.1688
10/01 02:14:08 - mmengine - INFO - Iter(train) [140900/320000]  base_lr: 5.9313e-05 lr: 5.9313e-06  eta: 21:47:34  time: 0.4423  data_time: 0.0095  memory: 5120  grad_norm: 55.1753  loss: 6.7159  decode.loss_cls: 0.1664  decode.loss_mask: 0.2180  decode.loss_dice: 0.1859  decode.d0.loss_cls: 0.9987  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.1797  decode.d1.loss_cls: 0.1635  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.1914  decode.d2.loss_cls: 0.1621  decode.d2.loss_mask: 0.2143  decode.d2.loss_dice: 0.1820  decode.d3.loss_cls: 0.1694  decode.d3.loss_mask: 0.2133  decode.d3.loss_dice: 0.1834  decode.d4.loss_cls: 0.1639  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.1832  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.3768  decode.d5.loss_dice: 0.2148  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 0.2554  decode.d6.loss_dice: 0.1952  decode.d7.loss_cls: 0.1781  decode.d7.loss_mask: 0.2242  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.1787  decode.d8.loss_mask: 0.2180  decode.d8.loss_dice: 0.1849
10/01 02:14:30 - mmengine - INFO - Iter(train) [140950/320000]  base_lr: 5.9298e-05 lr: 5.9298e-06  eta: 21:47:12  time: 0.4416  data_time: 0.0093  memory: 5129  grad_norm: 112.4329  loss: 5.3793  decode.loss_cls: 0.0617  decode.loss_mask: 0.2016  decode.loss_dice: 0.1796  decode.d0.loss_cls: 0.7689  decode.d0.loss_mask: 0.2039  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.2039  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.2020  decode.d3.loss_dice: 0.1953  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.2001  decode.d4.loss_dice: 0.1828  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.2020  decode.d5.loss_dice: 0.1942  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.2023  decode.d6.loss_dice: 0.1877  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.1756  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.2033  decode.d8.loss_dice: 0.1848
10/01 02:14:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:14:52 - mmengine - INFO - Iter(train) [141000/320000]  base_lr: 5.9284e-05 lr: 5.9284e-06  eta: 21:46:50  time: 0.4410  data_time: 0.0093  memory: 5129  grad_norm: 24.5554  loss: 4.0555  decode.loss_cls: 0.0038  decode.loss_mask: 0.1560  decode.loss_dice: 0.1656  decode.d0.loss_cls: 0.7916  decode.d0.loss_mask: 0.1574  decode.d0.loss_dice: 0.1663  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.1591  decode.d1.loss_dice: 0.1619  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.1576  decode.d2.loss_dice: 0.1648  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1583  decode.d3.loss_dice: 0.1651  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.1595  decode.d4.loss_dice: 0.1580  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.1578  decode.d5.loss_dice: 0.1642  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.1593  decode.d6.loss_dice: 0.1659  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.1572  decode.d7.loss_dice: 0.1555  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.1561  decode.d8.loss_dice: 0.1657
10/01 02:15:14 - mmengine - INFO - Iter(train) [141050/320000]  base_lr: 5.9269e-05 lr: 5.9269e-06  eta: 21:46:29  time: 0.4395  data_time: 0.0097  memory: 5120  grad_norm: 42.7962  loss: 5.7189  decode.loss_cls: 0.0626  decode.loss_mask: 0.2218  decode.loss_dice: 0.2141  decode.d0.loss_cls: 0.7591  decode.d0.loss_mask: 0.2239  decode.d0.loss_dice: 0.2317  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.1948  decode.d2.loss_cls: 0.1028  decode.d2.loss_mask: 0.2189  decode.d2.loss_dice: 0.2326  decode.d3.loss_cls: 0.0946  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1977  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.2351  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2187  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.2238  decode.d7.loss_dice: 0.2031  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.2214  decode.d8.loss_dice: 0.2154
10/01 02:15:36 - mmengine - INFO - Iter(train) [141100/320000]  base_lr: 5.9254e-05 lr: 5.9254e-06  eta: 21:46:07  time: 0.4399  data_time: 0.0094  memory: 5129  grad_norm: 24.2388  loss: 4.0849  decode.loss_cls: 0.0037  decode.loss_mask: 0.1635  decode.loss_dice: 0.1491  decode.d0.loss_cls: 0.8389  decode.d0.loss_mask: 0.1678  decode.d0.loss_dice: 0.1623  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.1649  decode.d1.loss_dice: 0.1572  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1661  decode.d2.loss_dice: 0.1556  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.1638  decode.d3.loss_dice: 0.1629  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.1660  decode.d4.loss_dice: 0.1568  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.1647  decode.d5.loss_dice: 0.1591  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.1634  decode.d6.loss_dice: 0.1517  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.1655  decode.d7.loss_dice: 0.1506  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.1660  decode.d8.loss_dice: 0.1571
10/01 02:15:58 - mmengine - INFO - Iter(train) [141150/320000]  base_lr: 5.9239e-05 lr: 5.9239e-06  eta: 21:45:45  time: 0.4439  data_time: 0.0097  memory: 5129  grad_norm: 46.2057  loss: 6.1033  decode.loss_cls: 0.0835  decode.loss_mask: 0.2332  decode.loss_dice: 0.2111  decode.d0.loss_cls: 0.9106  decode.d0.loss_mask: 0.2383  decode.d0.loss_dice: 0.2104  decode.d1.loss_cls: 0.1094  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.2056  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2102  decode.d3.loss_cls: 0.0988  decode.d3.loss_mask: 0.2363  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.2315  decode.d4.loss_dice: 0.1999  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.2347  decode.d5.loss_dice: 0.2137  decode.d6.loss_cls: 0.0934  decode.d6.loss_mask: 0.2349  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.2336  decode.d7.loss_dice: 0.2075  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2003
10/01 02:16:20 - mmengine - INFO - Iter(train) [141200/320000]  base_lr: 5.9224e-05 lr: 5.9224e-06  eta: 21:45:24  time: 0.4428  data_time: 0.0095  memory: 5129  grad_norm: 75.3133  loss: 4.6145  decode.loss_cls: 0.0082  decode.loss_mask: 0.2034  decode.loss_dice: 0.1729  decode.d0.loss_cls: 0.7474  decode.d0.loss_mask: 0.2043  decode.d0.loss_dice: 0.1668  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.2047  decode.d1.loss_dice: 0.1779  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.2044  decode.d2.loss_dice: 0.1754  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.2040  decode.d3.loss_dice: 0.1740  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.1750  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.2007  decode.d5.loss_dice: 0.1697  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2007  decode.d6.loss_dice: 0.1750  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2034  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.2027  decode.d8.loss_dice: 0.1724
10/01 02:16:43 - mmengine - INFO - Iter(train) [141250/320000]  base_lr: 5.9209e-05 lr: 5.9209e-06  eta: 21:45:02  time: 0.4425  data_time: 0.0095  memory: 5145  grad_norm: 28.9187  loss: 4.5491  decode.loss_cls: 0.0044  decode.loss_mask: 0.2127  decode.loss_dice: 0.1483  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 0.2152  decode.d0.loss_dice: 0.1487  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2149  decode.d1.loss_dice: 0.1526  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.2120  decode.d2.loss_dice: 0.1498  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.1483  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.1494  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2152  decode.d5.loss_dice: 0.1491  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.2133  decode.d6.loss_dice: 0.1510  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.2143  decode.d7.loss_dice: 0.1470  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2132  decode.d8.loss_dice: 0.1483
10/01 02:17:05 - mmengine - INFO - Iter(train) [141300/320000]  base_lr: 5.9194e-05 lr: 5.9194e-06  eta: 21:44:40  time: 0.4429  data_time: 0.0095  memory: 5129  grad_norm: 61.0022  loss: 5.4406  decode.loss_cls: 0.0297  decode.loss_mask: 0.2195  decode.loss_dice: 0.2052  decode.d0.loss_cls: 0.7610  decode.d0.loss_mask: 0.2254  decode.d0.loss_dice: 0.2182  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.2273  decode.d1.loss_dice: 0.2380  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.2224  decode.d3.loss_dice: 0.2217  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.2235  decode.d4.loss_dice: 0.2187  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.2220  decode.d5.loss_dice: 0.2207  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.2230  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 0.2216  decode.d7.loss_dice: 0.2281  decode.d8.loss_cls: 0.0280  decode.d8.loss_mask: 0.2200  decode.d8.loss_dice: 0.2170
10/01 02:17:27 - mmengine - INFO - Iter(train) [141350/320000]  base_lr: 5.9179e-05 lr: 5.9179e-06  eta: 21:44:19  time: 0.4418  data_time: 0.0093  memory: 5129  grad_norm: 71.0136  loss: 5.6594  decode.loss_cls: 0.0985  decode.loss_mask: 0.2115  decode.loss_dice: 0.1854  decode.d0.loss_cls: 0.9953  decode.d0.loss_mask: 0.2185  decode.d0.loss_dice: 0.1738  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 0.2083  decode.d1.loss_dice: 0.1814  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.2103  decode.d2.loss_dice: 0.1818  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.1905  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.1871  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.2102  decode.d5.loss_dice: 0.1847  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.2110  decode.d6.loss_dice: 0.1928  decode.d7.loss_cls: 0.1120  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1998
10/01 02:17:49 - mmengine - INFO - Iter(train) [141400/320000]  base_lr: 5.9164e-05 lr: 5.9164e-06  eta: 21:43:57  time: 0.4429  data_time: 0.0094  memory: 5129  grad_norm: 44.5865  loss: 5.1186  decode.loss_cls: 0.0077  decode.loss_mask: 0.2201  decode.loss_dice: 0.1886  decode.d0.loss_cls: 0.8537  decode.d0.loss_mask: 0.2208  decode.d0.loss_dice: 0.1919  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.2183  decode.d1.loss_dice: 0.2017  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.2201  decode.d2.loss_dice: 0.2059  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.2199  decode.d3.loss_dice: 0.2139  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.1994  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.1944  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.2158  decode.d6.loss_dice: 0.2050  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.2112  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.1935
10/01 02:18:11 - mmengine - INFO - Iter(train) [141450/320000]  base_lr: 5.9149e-05 lr: 5.9149e-06  eta: 21:43:36  time: 0.4452  data_time: 0.0096  memory: 5130  grad_norm: 75.2308  loss: 5.2069  decode.loss_cls: 0.0193  decode.loss_mask: 0.2282  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.7665  decode.d0.loss_mask: 0.2294  decode.d0.loss_dice: 0.2250  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.2269  decode.d1.loss_dice: 0.1923  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.2278  decode.d2.loss_dice: 0.2097  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.2272  decode.d3.loss_dice: 0.1912  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.2026  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.2273  decode.d5.loss_dice: 0.1958  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2237  decode.d6.loss_dice: 0.1937  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.2113  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.1988
10/01 02:18:34 - mmengine - INFO - Iter(train) [141500/320000]  base_lr: 5.9134e-05 lr: 5.9134e-06  eta: 21:43:14  time: 0.4429  data_time: 0.0095  memory: 5145  grad_norm: 104.3125  loss: 5.4988  decode.loss_cls: 0.0648  decode.loss_mask: 0.2245  decode.loss_dice: 0.1705  decode.d0.loss_cls: 0.9365  decode.d0.loss_mask: 0.2266  decode.d0.loss_dice: 0.1738  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.1830  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.1770  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.2224  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.2232  decode.d5.loss_dice: 0.1845  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.2233  decode.d6.loss_dice: 0.1814  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.2272  decode.d7.loss_dice: 0.1783  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.1782
10/01 02:18:56 - mmengine - INFO - Iter(train) [141550/320000]  base_lr: 5.9120e-05 lr: 5.9120e-06  eta: 21:42:53  time: 0.4445  data_time: 0.0095  memory: 5129  grad_norm: 74.6745  loss: 5.1722  decode.loss_cls: 0.0075  decode.loss_mask: 0.2467  decode.loss_dice: 0.1834  decode.d0.loss_cls: 0.8046  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.1851  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.2509  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.1813  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.2519  decode.d3.loss_dice: 0.1851  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.1872  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.2413  decode.d5.loss_dice: 0.1759  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.1838  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.2478  decode.d7.loss_dice: 0.1821  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.2457  decode.d8.loss_dice: 0.1829
10/01 02:19:18 - mmengine - INFO - Iter(train) [141600/320000]  base_lr: 5.9105e-05 lr: 5.9105e-06  eta: 21:42:31  time: 0.4416  data_time: 0.0094  memory: 5120  grad_norm: 45.1899  loss: 4.9338  decode.loss_cls: 0.0573  decode.loss_mask: 0.1805  decode.loss_dice: 0.1953  decode.d0.loss_cls: 0.8508  decode.d0.loss_mask: 0.1801  decode.d0.loss_dice: 0.1699  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 0.1807  decode.d1.loss_dice: 0.1674  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.1807  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.1782  decode.d3.loss_dice: 0.1773  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.1812  decode.d4.loss_dice: 0.1682  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.1801  decode.d5.loss_dice: 0.1720  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.1816  decode.d6.loss_dice: 0.1772  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.1811  decode.d7.loss_dice: 0.1720  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.1806  decode.d8.loss_dice: 0.1821
10/01 02:19:40 - mmengine - INFO - Iter(train) [141650/320000]  base_lr: 5.9090e-05 lr: 5.9090e-06  eta: 21:42:09  time: 0.4416  data_time: 0.0094  memory: 5145  grad_norm: 48.6174  loss: 4.5644  decode.loss_cls: 0.0045  decode.loss_mask: 0.1777  decode.loss_dice: 0.1883  decode.d0.loss_cls: 0.7675  decode.d0.loss_mask: 0.1772  decode.d0.loss_dice: 0.1934  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.1754  decode.d1.loss_dice: 0.1797  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.1766  decode.d2.loss_dice: 0.1943  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.1788  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.1773  decode.d4.loss_dice: 0.1884  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.1774  decode.d5.loss_dice: 0.1849  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.1773  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.1783  decode.d7.loss_dice: 0.1948  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.1776  decode.d8.loss_dice: 0.1934
10/01 02:20:02 - mmengine - INFO - Iter(train) [141700/320000]  base_lr: 5.9075e-05 lr: 5.9075e-06  eta: 21:41:48  time: 0.4423  data_time: 0.0094  memory: 5129  grad_norm: 56.5047  loss: 5.5226  decode.loss_cls: 0.0419  decode.loss_mask: 0.2186  decode.loss_dice: 0.1932  decode.d0.loss_cls: 0.8098  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.2022  decode.d1.loss_cls: 0.0973  decode.d1.loss_mask: 0.2178  decode.d1.loss_dice: 0.1954  decode.d2.loss_cls: 0.0831  decode.d2.loss_mask: 0.2163  decode.d2.loss_dice: 0.1938  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.1963  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 0.2207  decode.d4.loss_dice: 0.2005  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.2144  decode.d5.loss_dice: 0.1918  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.1888  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.2052  decode.d8.loss_cls: 0.0494  decode.d8.loss_mask: 0.2174  decode.d8.loss_dice: 0.2024
10/01 02:20:24 - mmengine - INFO - Iter(train) [141750/320000]  base_lr: 5.9060e-05 lr: 5.9060e-06  eta: 21:41:26  time: 0.4426  data_time: 0.0093  memory: 5145  grad_norm: 91.3168  loss: 5.6388  decode.loss_cls: 0.0835  decode.loss_mask: 0.2118  decode.loss_dice: 0.2053  decode.d0.loss_cls: 0.7606  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.2106  decode.d1.loss_dice: 0.2215  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.2167  decode.d2.loss_dice: 0.2247  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.2064  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.2158  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2065  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.2074  decode.d6.loss_dice: 0.2075  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.2034  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.2115  decode.d8.loss_dice: 0.2118
10/01 02:20:46 - mmengine - INFO - Iter(train) [141800/320000]  base_lr: 5.9045e-05 lr: 5.9045e-06  eta: 21:41:04  time: 0.4428  data_time: 0.0096  memory: 5129  grad_norm: 42.8424  loss: 4.4030  decode.loss_cls: 0.0055  decode.loss_mask: 0.2014  decode.loss_dice: 0.1510  decode.d0.loss_cls: 0.7892  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.1535  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.2071  decode.d1.loss_dice: 0.1575  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.2016  decode.d2.loss_dice: 0.1555  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.1977  decode.d3.loss_dice: 0.1578  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.2003  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.1519  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.1544  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2011  decode.d7.loss_dice: 0.1542  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.2027  decode.d8.loss_dice: 0.1545
10/01 02:21:08 - mmengine - INFO - Iter(train) [141850/320000]  base_lr: 5.9030e-05 lr: 5.9030e-06  eta: 21:40:43  time: 0.4395  data_time: 0.0093  memory: 5129  grad_norm: 74.6991  loss: 4.5640  decode.loss_cls: 0.0459  decode.loss_mask: 0.1922  decode.loss_dice: 0.1595  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 0.1883  decode.d0.loss_dice: 0.1545  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 0.1874  decode.d1.loss_dice: 0.1494  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.1878  decode.d2.loss_dice: 0.1507  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.1889  decode.d3.loss_dice: 0.1545  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.1873  decode.d4.loss_dice: 0.1524  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.1861  decode.d5.loss_dice: 0.1558  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.1896  decode.d6.loss_dice: 0.1516  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.1547  decode.d8.loss_cls: 0.0417  decode.d8.loss_mask: 0.1891  decode.d8.loss_dice: 0.1525
10/01 02:21:31 - mmengine - INFO - Iter(train) [141900/320000]  base_lr: 5.9015e-05 lr: 5.9015e-06  eta: 21:40:21  time: 0.4421  data_time: 0.0095  memory: 5120  grad_norm: 63.6954  loss: 6.8274  decode.loss_cls: 0.1200  decode.loss_mask: 0.2394  decode.loss_dice: 0.2506  decode.d0.loss_cls: 0.7863  decode.d0.loss_mask: 0.2516  decode.d0.loss_dice: 0.2529  decode.d1.loss_cls: 0.1104  decode.d1.loss_mask: 0.2456  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.1310  decode.d2.loss_mask: 0.2386  decode.d2.loss_dice: 0.2637  decode.d3.loss_cls: 0.1161  decode.d3.loss_mask: 0.2435  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.1497  decode.d4.loss_mask: 0.2438  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.1559  decode.d5.loss_mask: 0.2417  decode.d5.loss_dice: 0.2400  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.2444  decode.d6.loss_dice: 0.2513  decode.d7.loss_cls: 0.1245  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 0.2403  decode.d8.loss_dice: 0.2422
10/01 02:21:53 - mmengine - INFO - Iter(train) [141950/320000]  base_lr: 5.9000e-05 lr: 5.9000e-06  eta: 21:39:59  time: 0.4425  data_time: 0.0097  memory: 5145  grad_norm: 53.2712  loss: 5.3208  decode.loss_cls: 0.0584  decode.loss_mask: 0.2212  decode.loss_dice: 0.1498  decode.d0.loss_cls: 0.8557  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.1559  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.2272  decode.d1.loss_dice: 0.1595  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.2260  decode.d2.loss_dice: 0.1534  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.1571  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.1541  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.1548  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.2328  decode.d6.loss_dice: 0.1538  decode.d7.loss_cls: 0.0702  decode.d7.loss_mask: 0.2246  decode.d7.loss_dice: 0.1508  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.2252  decode.d8.loss_dice: 0.1520
10/01 02:22:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:22:15 - mmengine - INFO - Iter(train) [142000/320000]  base_lr: 5.8985e-05 lr: 5.8985e-06  eta: 21:39:38  time: 0.4424  data_time: 0.0096  memory: 5145  grad_norm: 28.5350  loss: 4.2994  decode.loss_cls: 0.0029  decode.loss_mask: 0.1856  decode.loss_dice: 0.1795  decode.d0.loss_cls: 0.6519  decode.d0.loss_mask: 0.1855  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.1879  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1880  decode.d2.loss_dice: 0.1699  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.1834  decode.d3.loss_dice: 0.1752  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1869  decode.d4.loss_dice: 0.1751  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.1854  decode.d5.loss_dice: 0.1774  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.1858  decode.d6.loss_dice: 0.1685  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1866  decode.d7.loss_dice: 0.1809  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.1873  decode.d8.loss_dice: 0.1772
10/01 02:22:37 - mmengine - INFO - Iter(train) [142050/320000]  base_lr: 5.8970e-05 lr: 5.8970e-06  eta: 21:39:16  time: 0.4429  data_time: 0.0094  memory: 5129  grad_norm: 90.6920  loss: 6.6065  decode.loss_cls: 0.1312  decode.loss_mask: 0.2165  decode.loss_dice: 0.2327  decode.d0.loss_cls: 0.9521  decode.d0.loss_mask: 0.2180  decode.d0.loss_dice: 0.2441  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.2159  decode.d1.loss_dice: 0.2280  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.2144  decode.d2.loss_dice: 0.2293  decode.d3.loss_cls: 0.1531  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.2196  decode.d4.loss_cls: 0.1050  decode.d4.loss_mask: 0.2108  decode.d4.loss_dice: 0.2269  decode.d5.loss_cls: 0.1396  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.2275  decode.d6.loss_cls: 0.1719  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.2333  decode.d7.loss_cls: 0.1281  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.2336  decode.d8.loss_cls: 0.1274  decode.d8.loss_mask: 0.2147  decode.d8.loss_dice: 0.2286
10/01 02:22:59 - mmengine - INFO - Iter(train) [142100/320000]  base_lr: 5.8956e-05 lr: 5.8956e-06  eta: 21:38:54  time: 0.4421  data_time: 0.0096  memory: 5129  grad_norm: 66.4587  loss: 5.4140  decode.loss_cls: 0.0178  decode.loss_mask: 0.2580  decode.loss_dice: 0.1797  decode.d0.loss_cls: 0.6666  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.2158  decode.d1.loss_cls: 0.0366  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.2038  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.1972  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.1759  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.1831  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.2557  decode.d5.loss_dice: 0.1872  decode.d6.loss_cls: 0.0195  decode.d6.loss_mask: 0.2571  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.2564  decode.d7.loss_dice: 0.1908  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.2573  decode.d8.loss_dice: 0.1998
10/01 02:23:21 - mmengine - INFO - Iter(train) [142150/320000]  base_lr: 5.8941e-05 lr: 5.8941e-06  eta: 21:38:33  time: 0.4421  data_time: 0.0095  memory: 5145  grad_norm: 62.2545  loss: 5.2213  decode.loss_cls: 0.0252  decode.loss_mask: 0.2016  decode.loss_dice: 0.1530  decode.d0.loss_cls: 0.8443  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1526  decode.d1.loss_cls: 0.0423  decode.d1.loss_mask: 0.2020  decode.d1.loss_dice: 0.1554  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.2169  decode.d2.loss_dice: 0.1701  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.1797  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3594  decode.d5.loss_dice: 0.1635  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.2541  decode.d6.loss_dice: 0.1943  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.2061  decode.d7.loss_dice: 0.1519  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.2041  decode.d8.loss_dice: 0.1514
10/01 02:23:43 - mmengine - INFO - Iter(train) [142200/320000]  base_lr: 5.8926e-05 lr: 5.8926e-06  eta: 21:38:11  time: 0.4426  data_time: 0.0096  memory: 5129  grad_norm: 88.0761  loss: 6.1500  decode.loss_cls: 0.0245  decode.loss_mask: 0.2401  decode.loss_dice: 0.2679  decode.d0.loss_cls: 0.7834  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.2313  decode.d1.loss_cls: 0.1480  decode.d1.loss_mask: 0.2393  decode.d1.loss_dice: 0.2451  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.2443  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.2363  decode.d3.loss_dice: 0.2490  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.2381  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.2387  decode.d5.loss_dice: 0.2498  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2253  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2592  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.2373  decode.d8.loss_dice: 0.2589
10/01 02:24:05 - mmengine - INFO - Iter(train) [142250/320000]  base_lr: 5.8911e-05 lr: 5.8911e-06  eta: 21:37:50  time: 0.4399  data_time: 0.0093  memory: 5145  grad_norm: 80.7586  loss: 5.1003  decode.loss_cls: 0.0271  decode.loss_mask: 0.1901  decode.loss_dice: 0.2038  decode.d0.loss_cls: 0.8605  decode.d0.loss_mask: 0.1925  decode.d0.loss_dice: 0.2024  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.1883  decode.d1.loss_dice: 0.1970  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.1937  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.1991  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.1936  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.1886  decode.d5.loss_dice: 0.1913  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.1878  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.1870  decode.d7.loss_dice: 0.1814  decode.d8.loss_cls: 0.0806  decode.d8.loss_mask: 0.1883  decode.d8.loss_dice: 0.1902
10/01 02:24:28 - mmengine - INFO - Iter(train) [142300/320000]  base_lr: 5.8896e-05 lr: 5.8896e-06  eta: 21:37:28  time: 0.4406  data_time: 0.0097  memory: 5145  grad_norm: 35.2521  loss: 4.6672  decode.loss_cls: 0.0226  decode.loss_mask: 0.2013  decode.loss_dice: 0.1545  decode.d0.loss_cls: 0.8437  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.1472  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.2010  decode.d1.loss_dice: 0.1512  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.2042  decode.d2.loss_dice: 0.1519  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.2031  decode.d3.loss_dice: 0.1529  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.1508  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.2004  decode.d5.loss_dice: 0.1506  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.2018  decode.d6.loss_dice: 0.1490  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.2023  decode.d7.loss_dice: 0.1529  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.2022  decode.d8.loss_dice: 0.1529
10/01 02:24:50 - mmengine - INFO - Iter(train) [142350/320000]  base_lr: 5.8881e-05 lr: 5.8881e-06  eta: 21:37:06  time: 0.4412  data_time: 0.0094  memory: 5145  grad_norm: 61.1584  loss: 5.0004  decode.loss_cls: 0.0218  decode.loss_mask: 0.1922  decode.loss_dice: 0.1999  decode.d0.loss_cls: 0.6843  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.2175  decode.d1.loss_cls: 0.0947  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.2024  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.1946  decode.d2.loss_dice: 0.1828  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.1884  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.1914  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0276  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.1993  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.1920  decode.d6.loss_dice: 0.2022  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.1909  decode.d7.loss_dice: 0.2050  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.2152
10/01 02:25:12 - mmengine - INFO - Iter(train) [142400/320000]  base_lr: 5.8866e-05 lr: 5.8866e-06  eta: 21:36:44  time: 0.4418  data_time: 0.0095  memory: 5145  grad_norm: 107.6225  loss: 6.3000  decode.loss_cls: 0.1106  decode.loss_mask: 0.2231  decode.loss_dice: 0.1912  decode.d0.loss_cls: 0.9535  decode.d0.loss_mask: 0.2242  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.2272  decode.d2.loss_cls: 0.0931  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.2179  decode.d3.loss_dice: 0.2067  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.2191  decode.d4.loss_dice: 0.2054  decode.d5.loss_cls: 0.1484  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.2152  decode.d6.loss_cls: 0.1321  decode.d6.loss_mask: 0.2192  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.1253  decode.d7.loss_mask: 0.2168  decode.d7.loss_dice: 0.1968  decode.d8.loss_cls: 0.1055  decode.d8.loss_mask: 0.2212  decode.d8.loss_dice: 0.2076
10/01 02:25:34 - mmengine - INFO - Iter(train) [142450/320000]  base_lr: 5.8851e-05 lr: 5.8851e-06  eta: 21:36:22  time: 0.4400  data_time: 0.0095  memory: 5145  grad_norm: 28.4391  loss: 4.3626  decode.loss_cls: 0.0012  decode.loss_mask: 0.2034  decode.loss_dice: 0.1592  decode.d0.loss_cls: 0.7117  decode.d0.loss_mask: 0.2026  decode.d0.loss_dice: 0.1524  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2043  decode.d1.loss_dice: 0.1628  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2045  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2035  decode.d3.loss_dice: 0.1593  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.1628  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2022  decode.d5.loss_dice: 0.1614  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2022  decode.d6.loss_dice: 0.1610  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2061  decode.d7.loss_dice: 0.1620  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2036  decode.d8.loss_dice: 0.1586
10/01 02:25:56 - mmengine - INFO - Iter(train) [142500/320000]  base_lr: 5.8836e-05 lr: 5.8836e-06  eta: 21:36:01  time: 0.4417  data_time: 0.0095  memory: 5129  grad_norm: 35.4084  loss: 5.1096  decode.loss_cls: 0.0631  decode.loss_mask: 0.2041  decode.loss_dice: 0.1602  decode.d0.loss_cls: 0.7340  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.1602  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.2074  decode.d1.loss_dice: 0.1957  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.2075  decode.d2.loss_dice: 0.1629  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.2078  decode.d3.loss_dice: 0.1611  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1591  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.1940  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.1584  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.2052  decode.d7.loss_dice: 0.1597  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.2054  decode.d8.loss_dice: 0.1610
10/01 02:26:18 - mmengine - INFO - Iter(train) [142550/320000]  base_lr: 5.8821e-05 lr: 5.8821e-06  eta: 21:35:39  time: 0.4403  data_time: 0.0094  memory: 5145  grad_norm: 25.3032  loss: 4.2330  decode.loss_cls: 0.0333  decode.loss_mask: 0.1661  decode.loss_dice: 0.1414  decode.d0.loss_cls: 0.8581  decode.d0.loss_mask: 0.1666  decode.d0.loss_dice: 0.1393  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.1676  decode.d1.loss_dice: 0.1428  decode.d2.loss_cls: 0.0298  decode.d2.loss_mask: 0.1668  decode.d2.loss_dice: 0.1413  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.1670  decode.d3.loss_dice: 0.1422  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.1659  decode.d4.loss_dice: 0.1406  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.1672  decode.d5.loss_dice: 0.1422  decode.d6.loss_cls: 0.0313  decode.d6.loss_mask: 0.1679  decode.d6.loss_dice: 0.1407  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 0.1682  decode.d7.loss_dice: 0.1416  decode.d8.loss_cls: 0.0330  decode.d8.loss_mask: 0.1665  decode.d8.loss_dice: 0.1406
10/01 02:26:40 - mmengine - INFO - Iter(train) [142600/320000]  base_lr: 5.8806e-05 lr: 5.8806e-06  eta: 21:35:17  time: 0.4421  data_time: 0.0094  memory: 5145  grad_norm: 29.9150  loss: 5.0059  decode.loss_cls: 0.1044  decode.loss_mask: 0.1618  decode.loss_dice: 0.1625  decode.d0.loss_cls: 0.9094  decode.d0.loss_mask: 0.1625  decode.d0.loss_dice: 0.1643  decode.d1.loss_cls: 0.1128  decode.d1.loss_mask: 0.1614  decode.d1.loss_dice: 0.1619  decode.d2.loss_cls: 0.1016  decode.d2.loss_mask: 0.1631  decode.d2.loss_dice: 0.1760  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 0.1619  decode.d3.loss_dice: 0.1602  decode.d4.loss_cls: 0.0959  decode.d4.loss_mask: 0.1629  decode.d4.loss_dice: 0.1674  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.1614  decode.d5.loss_dice: 0.1580  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.1624  decode.d6.loss_dice: 0.1457  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.1613  decode.d7.loss_dice: 0.1543  decode.d8.loss_cls: 0.1022  decode.d8.loss_mask: 0.1613  decode.d8.loss_dice: 0.1577
10/01 02:27:02 - mmengine - INFO - Iter(train) [142650/320000]  base_lr: 5.8791e-05 lr: 5.8791e-06  eta: 21:34:55  time: 0.4398  data_time: 0.0095  memory: 5145  grad_norm: 53.0224  loss: 5.3272  decode.loss_cls: 0.0550  decode.loss_mask: 0.2138  decode.loss_dice: 0.1800  decode.d0.loss_cls: 0.7377  decode.d0.loss_mask: 0.2156  decode.d0.loss_dice: 0.1841  decode.d1.loss_cls: 0.1358  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.1838  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.2162  decode.d2.loss_dice: 0.1793  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.1771  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.2162  decode.d4.loss_dice: 0.1899  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.1840  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.1841  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.2125  decode.d7.loss_dice: 0.1837  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.1842
10/01 02:27:24 - mmengine - INFO - Iter(train) [142700/320000]  base_lr: 5.8777e-05 lr: 5.8777e-06  eta: 21:34:34  time: 0.4400  data_time: 0.0090  memory: 5120  grad_norm: 82.1032  loss: 5.2789  decode.loss_cls: 0.1110  decode.loss_mask: 0.1831  decode.loss_dice: 0.1893  decode.d0.loss_cls: 0.8580  decode.d0.loss_mask: 0.1791  decode.d0.loss_dice: 0.1791  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.2052  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.1950  decode.d2.loss_dice: 0.1817  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.1743  decode.d3.loss_dice: 0.1704  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.1829  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.1956  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.1817  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.1813  decode.d7.loss_dice: 0.1881  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.1982
10/01 02:27:46 - mmengine - INFO - Iter(train) [142750/320000]  base_lr: 5.8762e-05 lr: 5.8762e-06  eta: 21:34:12  time: 0.4400  data_time: 0.0094  memory: 5120  grad_norm: 33.3322  loss: 5.7475  decode.loss_cls: 0.0464  decode.loss_mask: 0.2174  decode.loss_dice: 0.2379  decode.d0.loss_cls: 0.8339  decode.d0.loss_mask: 0.2152  decode.d0.loss_dice: 0.2351  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.2149  decode.d1.loss_dice: 0.2372  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.2178  decode.d2.loss_dice: 0.2366  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.2382  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.2149  decode.d4.loss_dice: 0.2373  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2313  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.2157  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.2165  decode.d7.loss_dice: 0.2391  decode.d8.loss_cls: 0.0354  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.2393
10/01 02:28:08 - mmengine - INFO - Iter(train) [142800/320000]  base_lr: 5.8747e-05 lr: 5.8747e-06  eta: 21:33:50  time: 0.4404  data_time: 0.0096  memory: 5120  grad_norm: 93.9760  loss: 6.2861  decode.loss_cls: 0.1152  decode.loss_mask: 0.2087  decode.loss_dice: 0.2468  decode.d0.loss_cls: 0.7326  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.2667  decode.d1.loss_cls: 0.1469  decode.d1.loss_mask: 0.2069  decode.d1.loss_dice: 0.2371  decode.d2.loss_cls: 0.1110  decode.d2.loss_mask: 0.2096  decode.d2.loss_dice: 0.2375  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2096  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.0912  decode.d4.loss_mask: 0.2092  decode.d4.loss_dice: 0.2531  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.2094  decode.d5.loss_dice: 0.2355  decode.d6.loss_cls: 0.1257  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.2152  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.2126  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.2199
10/01 02:28:30 - mmengine - INFO - Iter(train) [142850/320000]  base_lr: 5.8732e-05 lr: 5.8732e-06  eta: 21:33:28  time: 0.4412  data_time: 0.0097  memory: 5129  grad_norm: 120.3704  loss: 5.8765  decode.loss_cls: 0.0874  decode.loss_mask: 0.2165  decode.loss_dice: 0.1980  decode.d0.loss_cls: 0.8505  decode.d0.loss_mask: 0.2184  decode.d0.loss_dice: 0.1994  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.2139  decode.d1.loss_dice: 0.1993  decode.d2.loss_cls: 0.0902  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.2026  decode.d3.loss_cls: 0.1155  decode.d3.loss_mask: 0.2104  decode.d3.loss_dice: 0.1946  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1981  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.2141  decode.d5.loss_dice: 0.1988  decode.d6.loss_cls: 0.1017  decode.d6.loss_mask: 0.2153  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 0.2155  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.0961  decode.d8.loss_mask: 0.2123  decode.d8.loss_dice: 0.2011
10/01 02:28:52 - mmengine - INFO - Iter(train) [142900/320000]  base_lr: 5.8717e-05 lr: 5.8717e-06  eta: 21:33:07  time: 0.4409  data_time: 0.0094  memory: 5120  grad_norm: 26.2270  loss: 4.1915  decode.loss_cls: 0.0029  decode.loss_mask: 0.1617  decode.loss_dice: 0.1585  decode.d0.loss_cls: 0.9213  decode.d0.loss_mask: 0.1618  decode.d0.loss_dice: 0.1507  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.1647  decode.d1.loss_dice: 0.1559  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.1621  decode.d2.loss_dice: 0.1507  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.1645  decode.d3.loss_dice: 0.1642  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.1641  decode.d4.loss_dice: 0.1542  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.1626  decode.d5.loss_dice: 0.1573  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.1640  decode.d6.loss_dice: 0.1718  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.1649  decode.d7.loss_dice: 0.1576  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.1638  decode.d8.loss_dice: 0.1770
10/01 02:29:14 - mmengine - INFO - Iter(train) [142950/320000]  base_lr: 5.8702e-05 lr: 5.8702e-06  eta: 21:32:45  time: 0.4404  data_time: 0.0094  memory: 5159  grad_norm: 109.5222  loss: 6.1724  decode.loss_cls: 0.0850  decode.loss_mask: 0.2019  decode.loss_dice: 0.2519  decode.d0.loss_cls: 0.7617  decode.d0.loss_mask: 0.2066  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.1649  decode.d1.loss_mask: 0.2019  decode.d1.loss_dice: 0.2643  decode.d2.loss_cls: 0.0896  decode.d2.loss_mask: 0.2009  decode.d2.loss_dice: 0.2650  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.1999  decode.d3.loss_dice: 0.2544  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 0.2002  decode.d4.loss_dice: 0.2439  decode.d5.loss_cls: 0.0827  decode.d5.loss_mask: 0.2003  decode.d5.loss_dice: 0.2617  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.1988  decode.d6.loss_dice: 0.2600  decode.d7.loss_cls: 0.1242  decode.d7.loss_mask: 0.1990  decode.d7.loss_dice: 0.2362  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.1999  decode.d8.loss_dice: 0.2255
10/01 02:29:36 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:29:36 - mmengine - INFO - Iter(train) [143000/320000]  base_lr: 5.8687e-05 lr: 5.8687e-06  eta: 21:32:23  time: 0.4415  data_time: 0.0096  memory: 5119  grad_norm: 63.2291  loss: 5.9430  decode.loss_cls: 0.0651  decode.loss_mask: 0.3010  decode.loss_dice: 0.1903  decode.d0.loss_cls: 0.6534  decode.d0.loss_mask: 0.3002  decode.d0.loss_dice: 0.2064  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.3011  decode.d2.loss_dice: 0.1976  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.2024  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.3011  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.0304  decode.d5.loss_mask: 0.2995  decode.d5.loss_dice: 0.1905  decode.d6.loss_cls: 0.0449  decode.d6.loss_mask: 0.2988  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.0358  decode.d7.loss_mask: 0.3002  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.0293  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.2001
10/01 02:29:58 - mmengine - INFO - Iter(train) [143050/320000]  base_lr: 5.8672e-05 lr: 5.8672e-06  eta: 21:32:02  time: 0.4404  data_time: 0.0094  memory: 5129  grad_norm: 54.4089  loss: 4.9742  decode.loss_cls: 0.0066  decode.loss_mask: 0.2334  decode.loss_dice: 0.1754  decode.d0.loss_cls: 0.7933  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.1803  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.2326  decode.d1.loss_dice: 0.1713  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.1795  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.2333  decode.d3.loss_dice: 0.1742  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.1828  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.2323  decode.d5.loss_dice: 0.1756  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.2352  decode.d6.loss_dice: 0.1741  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.2330  decode.d8.loss_dice: 0.1815
10/01 02:30:20 - mmengine - INFO - Iter(train) [143100/320000]  base_lr: 5.8657e-05 lr: 5.8657e-06  eta: 21:31:40  time: 0.4418  data_time: 0.0096  memory: 5129  grad_norm: 137.0084  loss: 4.7283  decode.loss_cls: 0.0464  decode.loss_mask: 0.2048  decode.loss_dice: 0.1594  decode.d0.loss_cls: 0.7445  decode.d0.loss_mask: 0.2045  decode.d0.loss_dice: 0.1658  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.2021  decode.d1.loss_dice: 0.1586  decode.d2.loss_cls: 0.0487  decode.d2.loss_mask: 0.2052  decode.d2.loss_dice: 0.1601  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.2059  decode.d3.loss_dice: 0.1590  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.2081  decode.d4.loss_dice: 0.1588  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.2038  decode.d5.loss_dice: 0.1559  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.2073  decode.d6.loss_dice: 0.1557  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.2035  decode.d7.loss_dice: 0.1576  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.2038  decode.d8.loss_dice: 0.1578
10/01 02:30:42 - mmengine - INFO - Iter(train) [143150/320000]  base_lr: 5.8642e-05 lr: 5.8642e-06  eta: 21:31:18  time: 0.4408  data_time: 0.0096  memory: 5129  grad_norm: 57.9730  loss: 6.6981  decode.loss_cls: 0.1734  decode.loss_mask: 0.1873  decode.loss_dice: 0.2300  decode.d0.loss_cls: 0.8794  decode.d0.loss_mask: 0.1906  decode.d0.loss_dice: 0.2273  decode.d1.loss_cls: 0.2304  decode.d1.loss_mask: 0.1875  decode.d1.loss_dice: 0.2180  decode.d2.loss_cls: 0.2079  decode.d2.loss_mask: 0.1901  decode.d2.loss_dice: 0.2239  decode.d3.loss_cls: 0.1740  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.2172  decode.d4.loss_cls: 0.1624  decode.d4.loss_mask: 0.1874  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.1737  decode.d5.loss_mask: 0.1886  decode.d5.loss_dice: 0.2221  decode.d6.loss_cls: 0.2000  decode.d6.loss_mask: 0.1876  decode.d6.loss_dice: 0.2195  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.2217  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 0.1899  decode.d8.loss_dice: 0.2299
10/01 02:31:04 - mmengine - INFO - Iter(train) [143200/320000]  base_lr: 5.8627e-05 lr: 5.8627e-06  eta: 21:30:57  time: 0.4407  data_time: 0.0094  memory: 5120  grad_norm: 57.2400  loss: 7.1985  decode.loss_cls: 0.1697  decode.loss_mask: 0.3021  decode.loss_dice: 0.2239  decode.d0.loss_cls: 0.9224  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.2104  decode.d1.loss_cls: 0.1575  decode.d1.loss_mask: 0.2610  decode.d1.loss_dice: 0.2139  decode.d2.loss_cls: 0.1352  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.2138  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2584  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.1410  decode.d4.loss_mask: 0.2851  decode.d4.loss_dice: 0.2190  decode.d5.loss_cls: 0.1474  decode.d5.loss_mask: 0.2654  decode.d5.loss_dice: 0.2104  decode.d6.loss_cls: 0.1609  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.2201  decode.d7.loss_cls: 0.1546  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.1979  decode.d8.loss_cls: 0.1612  decode.d8.loss_mask: 0.3029  decode.d8.loss_dice: 0.2241
10/01 02:31:27 - mmengine - INFO - Iter(train) [143250/320000]  base_lr: 5.8612e-05 lr: 5.8612e-06  eta: 21:30:35  time: 0.4404  data_time: 0.0093  memory: 5145  grad_norm: 21.8614  loss: 3.6040  decode.loss_cls: 0.0051  decode.loss_mask: 0.1575  decode.loss_dice: 0.1238  decode.d0.loss_cls: 0.7597  decode.d0.loss_mask: 0.1569  decode.d0.loss_dice: 0.1234  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.1550  decode.d1.loss_dice: 0.1218  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.1540  decode.d2.loss_dice: 0.1195  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.1540  decode.d3.loss_dice: 0.1179  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.1550  decode.d4.loss_dice: 0.1244  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.1543  decode.d5.loss_dice: 0.1234  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.1527  decode.d6.loss_dice: 0.1195  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.1580  decode.d7.loss_dice: 0.1238  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.1563  decode.d8.loss_dice: 0.1214
10/01 02:31:49 - mmengine - INFO - Iter(train) [143300/320000]  base_lr: 5.8598e-05 lr: 5.8598e-06  eta: 21:30:13  time: 0.4405  data_time: 0.0095  memory: 5129  grad_norm: 58.6676  loss: 6.6304  decode.loss_cls: 0.0560  decode.loss_mask: 0.2221  decode.loss_dice: 0.2818  decode.d0.loss_cls: 0.9328  decode.d0.loss_mask: 0.2741  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.1114  decode.d1.loss_mask: 0.2231  decode.d1.loss_dice: 0.2600  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.2218  decode.d2.loss_dice: 0.2408  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.2222  decode.d3.loss_dice: 0.2800  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.2828  decode.d5.loss_cls: 0.1113  decode.d5.loss_mask: 0.2211  decode.d5.loss_dice: 0.2659  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.2241  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.2250  decode.d7.loss_dice: 0.2765  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.2225  decode.d8.loss_dice: 0.3103
10/01 02:32:11 - mmengine - INFO - Iter(train) [143350/320000]  base_lr: 5.8583e-05 lr: 5.8583e-06  eta: 21:29:51  time: 0.4406  data_time: 0.0095  memory: 5120  grad_norm: 166.8333  loss: 6.6682  decode.loss_cls: 0.2196  decode.loss_mask: 0.2234  decode.loss_dice: 0.1885  decode.d0.loss_cls: 0.9306  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.1555  decode.d1.loss_cls: 0.1496  decode.d1.loss_mask: 0.2251  decode.d1.loss_dice: 0.1761  decode.d2.loss_cls: 0.1561  decode.d2.loss_mask: 0.2190  decode.d2.loss_dice: 0.1849  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.2056  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.2181  decode.d5.loss_cls: 0.1831  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.2249  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.2247  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.1849  decode.d7.loss_mask: 0.2253  decode.d7.loss_dice: 0.2021  decode.d8.loss_cls: 0.1724  decode.d8.loss_mask: 0.2218  decode.d8.loss_dice: 0.1867
10/01 02:32:33 - mmengine - INFO - Iter(train) [143400/320000]  base_lr: 5.8568e-05 lr: 5.8568e-06  eta: 21:29:30  time: 0.4404  data_time: 0.0094  memory: 5120  grad_norm: 27.8191  loss: 4.8125  decode.loss_cls: 0.0028  decode.loss_mask: 0.1918  decode.loss_dice: 0.1858  decode.d0.loss_cls: 0.7624  decode.d0.loss_mask: 0.1901  decode.d0.loss_dice: 0.1771  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.1815  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.1906  decode.d2.loss_dice: 0.1666  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.1932  decode.d3.loss_dice: 0.1668  decode.d4.loss_cls: 0.0866  decode.d4.loss_mask: 0.1901  decode.d4.loss_dice: 0.1712  decode.d5.loss_cls: 0.0687  decode.d5.loss_mask: 0.1882  decode.d5.loss_dice: 0.1566  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.1767  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.1865  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.1911  decode.d8.loss_dice: 0.1855
10/01 02:32:55 - mmengine - INFO - Iter(train) [143450/320000]  base_lr: 5.8553e-05 lr: 5.8553e-06  eta: 21:29:08  time: 0.4409  data_time: 0.0094  memory: 5129  grad_norm: 45.7563  loss: 4.6590  decode.loss_cls: 0.0018  decode.loss_mask: 0.2171  decode.loss_dice: 0.1616  decode.d0.loss_cls: 0.7726  decode.d0.loss_mask: 0.2264  decode.d0.loss_dice: 0.1730  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.1618  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.2203  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2226  decode.d3.loss_dice: 0.1715  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.2205  decode.d4.loss_dice: 0.1630  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.2227  decode.d5.loss_dice: 0.1675  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.1645  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.2200  decode.d7.loss_dice: 0.1607  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2167  decode.d8.loss_dice: 0.1606
10/01 02:33:17 - mmengine - INFO - Iter(train) [143500/320000]  base_lr: 5.8538e-05 lr: 5.8538e-06  eta: 21:28:46  time: 0.4402  data_time: 0.0095  memory: 5129  grad_norm: 71.2941  loss: 5.3158  decode.loss_cls: 0.0071  decode.loss_mask: 0.2097  decode.loss_dice: 0.2119  decode.d0.loss_cls: 0.8464  decode.d0.loss_mask: 0.2127  decode.d0.loss_dice: 0.2196  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.2150  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2126  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.2112  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.2122  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.2084  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.2131  decode.d6.loss_dice: 0.2139  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.2105  decode.d7.loss_dice: 0.2205  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.2099  decode.d8.loss_dice: 0.2172
10/01 02:33:39 - mmengine - INFO - Iter(train) [143550/320000]  base_lr: 5.8523e-05 lr: 5.8523e-06  eta: 21:28:24  time: 0.4407  data_time: 0.0094  memory: 5145  grad_norm: 101.0480  loss: 7.4236  decode.loss_cls: 0.1704  decode.loss_mask: 0.1996  decode.loss_dice: 0.2449  decode.d0.loss_cls: 0.9784  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.2858  decode.d1.loss_cls: 0.3131  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.2344  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 0.1969  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 0.1984  decode.d3.loss_dice: 0.2516  decode.d4.loss_cls: 0.2391  decode.d4.loss_mask: 0.2001  decode.d4.loss_dice: 0.2639  decode.d5.loss_cls: 0.1941  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2733  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 0.1998  decode.d6.loss_dice: 0.2571  decode.d7.loss_cls: 0.2217  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 0.1986  decode.d8.loss_dice: 0.2624
10/01 02:34:01 - mmengine - INFO - Iter(train) [143600/320000]  base_lr: 5.8508e-05 lr: 5.8508e-06  eta: 21:28:03  time: 0.4407  data_time: 0.0094  memory: 5129  grad_norm: 41.3881  loss: 5.1295  decode.loss_cls: 0.0558  decode.loss_mask: 0.2233  decode.loss_dice: 0.1573  decode.d0.loss_cls: 0.8612  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.1458  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.1596  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.1537  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.2266  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.1548  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.2245  decode.d5.loss_dice: 0.1593  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.1556  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.1539  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.2217  decode.d8.loss_dice: 0.1541
10/01 02:34:23 - mmengine - INFO - Iter(train) [143650/320000]  base_lr: 5.8493e-05 lr: 5.8493e-06  eta: 21:27:41  time: 0.4423  data_time: 0.0094  memory: 5129  grad_norm: 31.6353  loss: 5.3290  decode.loss_cls: 0.0206  decode.loss_mask: 0.1761  decode.loss_dice: 0.2326  decode.d0.loss_cls: 0.8725  decode.d0.loss_mask: 0.1762  decode.d0.loss_dice: 0.2116  decode.d1.loss_cls: 0.1384  decode.d1.loss_mask: 0.1750  decode.d1.loss_dice: 0.2364  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.1771  decode.d2.loss_dice: 0.2486  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.1766  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.1746  decode.d4.loss_dice: 0.2404  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.1728  decode.d5.loss_dice: 0.2363  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.1752  decode.d6.loss_dice: 0.2430  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.1762  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.1768  decode.d8.loss_dice: 0.2453
10/01 02:34:45 - mmengine - INFO - Iter(train) [143700/320000]  base_lr: 5.8478e-05 lr: 5.8478e-06  eta: 21:27:19  time: 0.4414  data_time: 0.0095  memory: 5129  grad_norm: 38.1412  loss: 4.6919  decode.loss_cls: 0.0254  decode.loss_mask: 0.1952  decode.loss_dice: 0.1445  decode.d0.loss_cls: 0.8349  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1960  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.1945  decode.d1.loss_dice: 0.1483  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.1927  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.1938  decode.d3.loss_dice: 0.1452  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.1511  decode.d5.loss_cls: 0.0219  decode.d5.loss_mask: 0.1925  decode.d5.loss_dice: 0.2091  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.1930  decode.d6.loss_dice: 0.1428  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 0.1914  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.1922  decode.d8.loss_dice: 0.1977
10/01 02:35:07 - mmengine - INFO - Iter(train) [143750/320000]  base_lr: 5.8463e-05 lr: 5.8463e-06  eta: 21:26:58  time: 0.4411  data_time: 0.0095  memory: 5129  grad_norm: 164.9118  loss: 4.5426  decode.loss_cls: 0.0275  decode.loss_mask: 0.2104  decode.loss_dice: 0.1481  decode.d0.loss_cls: 0.7819  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.1446  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.2160  decode.d1.loss_dice: 0.1522  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.2127  decode.d2.loss_dice: 0.1470  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.1483  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.2131  decode.d4.loss_dice: 0.1491  decode.d5.loss_cls: 0.0229  decode.d5.loss_mask: 0.2101  decode.d5.loss_dice: 0.1487  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.1473  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.2081  decode.d7.loss_dice: 0.1478  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.2105  decode.d8.loss_dice: 0.1481
10/01 02:35:29 - mmengine - INFO - Iter(train) [143800/320000]  base_lr: 5.8448e-05 lr: 5.8448e-06  eta: 21:26:36  time: 0.4402  data_time: 0.0095  memory: 5129  grad_norm: 97.0385  loss: 6.3741  decode.loss_cls: 0.1895  decode.loss_mask: 0.2360  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.8623  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.1613  decode.d1.loss_cls: 0.1533  decode.d1.loss_mask: 0.2344  decode.d1.loss_dice: 0.1673  decode.d2.loss_cls: 0.1525  decode.d2.loss_mask: 0.2338  decode.d2.loss_dice: 0.1595  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.1613  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.1547  decode.d5.loss_cls: 0.1498  decode.d5.loss_mask: 0.2802  decode.d5.loss_dice: 0.1742  decode.d6.loss_cls: 0.1654  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.1673  decode.d7.loss_cls: 0.1633  decode.d7.loss_mask: 0.2405  decode.d7.loss_dice: 0.1634  decode.d8.loss_cls: 0.1825  decode.d8.loss_mask: 0.2425  decode.d8.loss_dice: 0.1722
10/01 02:35:51 - mmengine - INFO - Iter(train) [143850/320000]  base_lr: 5.8433e-05 lr: 5.8433e-06  eta: 21:26:14  time: 0.4408  data_time: 0.0094  memory: 5129  grad_norm: 52.1814  loss: 3.6932  decode.loss_cls: 0.0184  decode.loss_mask: 0.1464  decode.loss_dice: 0.1291  decode.d0.loss_cls: 0.8307  decode.d0.loss_mask: 0.1466  decode.d0.loss_dice: 0.1297  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.1471  decode.d1.loss_dice: 0.1297  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.1466  decode.d2.loss_dice: 0.1259  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.1454  decode.d3.loss_dice: 0.1252  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.1471  decode.d4.loss_dice: 0.1246  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.1441  decode.d5.loss_dice: 0.1298  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.1458  decode.d6.loss_dice: 0.1247  decode.d7.loss_cls: 0.0199  decode.d7.loss_mask: 0.1452  decode.d7.loss_dice: 0.1260  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.1464  decode.d8.loss_dice: 0.1263
10/01 02:36:13 - mmengine - INFO - Iter(train) [143900/320000]  base_lr: 5.8418e-05 lr: 5.8418e-06  eta: 21:25:52  time: 0.4408  data_time: 0.0099  memory: 5130  grad_norm: 25.5737  loss: 4.2743  decode.loss_cls: 0.0162  decode.loss_mask: 0.1803  decode.loss_dice: 0.1503  decode.d0.loss_cls: 0.8232  decode.d0.loss_mask: 0.1800  decode.d0.loss_dice: 0.1512  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.1836  decode.d1.loss_dice: 0.1498  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.1454  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.1800  decode.d3.loss_dice: 0.1467  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.1816  decode.d4.loss_dice: 0.1490  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.1822  decode.d5.loss_dice: 0.1553  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.1798  decode.d6.loss_dice: 0.1454  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.1799  decode.d7.loss_dice: 0.1495  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.1804  decode.d8.loss_dice: 0.1478
10/01 02:36:35 - mmengine - INFO - Iter(train) [143950/320000]  base_lr: 5.8403e-05 lr: 5.8403e-06  eta: 21:25:31  time: 0.4427  data_time: 0.0100  memory: 5146  grad_norm: 110.7569  loss: 6.5196  decode.loss_cls: 0.0382  decode.loss_mask: 0.2646  decode.loss_dice: 0.2721  decode.d0.loss_cls: 0.7497  decode.d0.loss_mask: 0.2623  decode.d0.loss_dice: 0.2735  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.2649  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.2620  decode.d3.loss_dice: 0.2761  decode.d4.loss_cls: 0.0277  decode.d4.loss_mask: 0.2598  decode.d4.loss_dice: 0.2818  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.2631  decode.d5.loss_dice: 0.2894  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.2767  decode.d7.loss_cls: 0.0318  decode.d7.loss_mask: 0.2594  decode.d7.loss_dice: 0.2785  decode.d8.loss_cls: 0.0351  decode.d8.loss_mask: 0.2656  decode.d8.loss_dice: 0.2726
10/01 02:36:58 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:36:58 - mmengine - INFO - Iter(train) [144000/320000]  base_lr: 5.8389e-05 lr: 5.8389e-06  eta: 21:25:09  time: 0.4453  data_time: 0.0098  memory: 5129  grad_norm: 35.0714  loss: 5.6156  decode.loss_cls: 0.0558  decode.loss_mask: 0.2281  decode.loss_dice: 0.1911  decode.d0.loss_cls: 0.7748  decode.d0.loss_mask: 0.2314  decode.d0.loss_dice: 0.1989  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.1693  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 0.2324  decode.d2.loss_dice: 0.1900  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.2293  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.2294  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.2132  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.2304  decode.d6.loss_dice: 0.1862  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.1991  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.2291  decode.d8.loss_dice: 0.2000
10/01 02:37:20 - mmengine - INFO - Iter(train) [144050/320000]  base_lr: 5.8374e-05 lr: 5.8374e-06  eta: 21:24:47  time: 0.4432  data_time: 0.0097  memory: 5129  grad_norm: 36.7519  loss: 5.0425  decode.loss_cls: 0.1010  decode.loss_mask: 0.1710  decode.loss_dice: 0.1988  decode.d0.loss_cls: 0.8073  decode.d0.loss_mask: 0.1680  decode.d0.loss_dice: 0.2159  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.1694  decode.d1.loss_dice: 0.2136  decode.d2.loss_cls: 0.0664  decode.d2.loss_mask: 0.1688  decode.d2.loss_dice: 0.2029  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.1677  decode.d3.loss_dice: 0.1739  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.1685  decode.d4.loss_dice: 0.2254  decode.d5.loss_cls: 0.0266  decode.d5.loss_mask: 0.1713  decode.d5.loss_dice: 0.2186  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.1699  decode.d6.loss_dice: 0.1891  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.1691  decode.d7.loss_dice: 0.1886  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.1689  decode.d8.loss_dice: 0.1882
10/01 02:37:42 - mmengine - INFO - Iter(train) [144100/320000]  base_lr: 5.8359e-05 lr: 5.8359e-06  eta: 21:24:25  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 34.8896  loss: 5.1157  decode.loss_cls: 0.0707  decode.loss_mask: 0.1992  decode.loss_dice: 0.1573  decode.d0.loss_cls: 0.8179  decode.d0.loss_mask: 0.2019  decode.d0.loss_dice: 0.1695  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.2029  decode.d1.loss_dice: 0.1618  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.1980  decode.d2.loss_dice: 0.1576  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.2010  decode.d3.loss_dice: 0.1574  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 0.2007  decode.d4.loss_dice: 0.1585  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.1578  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.1667  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.2016  decode.d7.loss_dice: 0.1704  decode.d8.loss_cls: 0.0784  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.1558
10/01 02:38:04 - mmengine - INFO - Iter(train) [144150/320000]  base_lr: 5.8344e-05 lr: 5.8344e-06  eta: 21:24:04  time: 0.4429  data_time: 0.0097  memory: 5129  grad_norm: 28.9268  loss: 4.6193  decode.loss_cls: 0.0054  decode.loss_mask: 0.2046  decode.loss_dice: 0.1727  decode.d0.loss_cls: 0.8427  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.1631  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.2042  decode.d1.loss_dice: 0.1676  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.2034  decode.d2.loss_dice: 0.1739  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.1685  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.1647  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.1639  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2043  decode.d7.loss_dice: 0.1729  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.2026  decode.d8.loss_dice: 0.1696
10/01 02:38:26 - mmengine - INFO - Iter(train) [144200/320000]  base_lr: 5.8329e-05 lr: 5.8329e-06  eta: 21:23:42  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 68.0621  loss: 5.7664  decode.loss_cls: 0.0830  decode.loss_mask: 0.1825  decode.loss_dice: 0.1823  decode.d0.loss_cls: 0.9567  decode.d0.loss_mask: 0.1800  decode.d0.loss_dice: 0.1884  decode.d1.loss_cls: 0.1489  decode.d1.loss_mask: 0.1799  decode.d1.loss_dice: 0.1922  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.1828  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.1320  decode.d3.loss_mask: 0.1806  decode.d3.loss_dice: 0.1761  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.1810  decode.d4.loss_dice: 0.1840  decode.d5.loss_cls: 0.1892  decode.d5.loss_mask: 0.1809  decode.d5.loss_dice: 0.1995  decode.d6.loss_cls: 0.1226  decode.d6.loss_mask: 0.1829  decode.d6.loss_dice: 0.1820  decode.d7.loss_cls: 0.1340  decode.d7.loss_mask: 0.1807  decode.d7.loss_dice: 0.2010  decode.d8.loss_cls: 0.1158  decode.d8.loss_mask: 0.1822  decode.d8.loss_dice: 0.1789
10/01 02:38:48 - mmengine - INFO - Iter(train) [144250/320000]  base_lr: 5.8314e-05 lr: 5.8314e-06  eta: 21:23:20  time: 0.4402  data_time: 0.0097  memory: 5129  grad_norm: 67.3255  loss: 5.3832  decode.loss_cls: 0.0653  decode.loss_mask: 0.2281  decode.loss_dice: 0.1742  decode.d0.loss_cls: 0.8667  decode.d0.loss_mask: 0.2284  decode.d0.loss_dice: 0.1724  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.2296  decode.d1.loss_dice: 0.1720  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.2319  decode.d2.loss_dice: 0.1725  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.2254  decode.d3.loss_dice: 0.1750  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.2310  decode.d4.loss_dice: 0.1761  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.2267  decode.d5.loss_dice: 0.1762  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.2272  decode.d6.loss_dice: 0.1771  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.1818  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.2288  decode.d8.loss_dice: 0.1773
10/01 02:39:10 - mmengine - INFO - Iter(train) [144300/320000]  base_lr: 5.8299e-05 lr: 5.8299e-06  eta: 21:22:58  time: 0.4408  data_time: 0.0098  memory: 5120  grad_norm: 99.7825  loss: 7.0114  decode.loss_cls: 0.0686  decode.loss_mask: 0.3047  decode.loss_dice: 0.2149  decode.d0.loss_cls: 0.8842  decode.d0.loss_mask: 0.2914  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.3169  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.1589  decode.d2.loss_mask: 0.2965  decode.d2.loss_dice: 0.2111  decode.d3.loss_cls: 0.1366  decode.d3.loss_mask: 0.2966  decode.d3.loss_dice: 0.2112  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.2141  decode.d5.loss_cls: 0.1208  decode.d5.loss_mask: 0.2990  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.1256  decode.d6.loss_mask: 0.3027  decode.d6.loss_dice: 0.2123  decode.d7.loss_cls: 0.1296  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.3010  decode.d8.loss_dice: 0.2150
10/01 02:39:32 - mmengine - INFO - Iter(train) [144350/320000]  base_lr: 5.8284e-05 lr: 5.8284e-06  eta: 21:22:37  time: 0.4409  data_time: 0.0098  memory: 5129  grad_norm: 53.4130  loss: 5.9965  decode.loss_cls: 0.0731  decode.loss_mask: 0.1839  decode.loss_dice: 0.2539  decode.d0.loss_cls: 0.8621  decode.d0.loss_mask: 0.1848  decode.d0.loss_dice: 0.2375  decode.d1.loss_cls: 0.1368  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.1128  decode.d2.loss_mask: 0.1870  decode.d2.loss_dice: 0.2447  decode.d3.loss_cls: 0.1126  decode.d3.loss_mask: 0.1842  decode.d3.loss_dice: 0.2288  decode.d4.loss_cls: 0.0814  decode.d4.loss_mask: 0.1841  decode.d4.loss_dice: 0.2392  decode.d5.loss_cls: 0.0937  decode.d5.loss_mask: 0.1838  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 0.1869  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.1876  decode.d7.loss_dice: 0.2321  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.1862  decode.d8.loss_dice: 0.2435
10/01 02:39:54 - mmengine - INFO - Iter(train) [144400/320000]  base_lr: 5.8269e-05 lr: 5.8269e-06  eta: 21:22:15  time: 0.4411  data_time: 0.0098  memory: 5145  grad_norm: 46.9710  loss: 4.0708  decode.loss_cls: 0.0011  decode.loss_mask: 0.1845  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.7325  decode.d0.loss_mask: 0.1855  decode.d0.loss_dice: 0.1448  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.1843  decode.d1.loss_dice: 0.1491  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.1835  decode.d2.loss_dice: 0.1517  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.1841  decode.d3.loss_dice: 0.1499  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1851  decode.d4.loss_dice: 0.1491  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.1826  decode.d5.loss_dice: 0.1471  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.1834  decode.d6.loss_dice: 0.1481  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1828  decode.d7.loss_dice: 0.1477  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.1833  decode.d8.loss_dice: 0.1482
10/01 02:40:16 - mmengine - INFO - Iter(train) [144450/320000]  base_lr: 5.8254e-05 lr: 5.8254e-06  eta: 21:21:53  time: 0.4410  data_time: 0.0098  memory: 5129  grad_norm: 97.6103  loss: 6.6733  decode.loss_cls: 0.1148  decode.loss_mask: 0.2286  decode.loss_dice: 0.2228  decode.d0.loss_cls: 0.9578  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2146  decode.d1.loss_cls: 0.1362  decode.d1.loss_mask: 0.2596  decode.d1.loss_dice: 0.2332  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 0.2325  decode.d2.loss_dice: 0.2420  decode.d3.loss_cls: 0.1138  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.2334  decode.d4.loss_cls: 0.1009  decode.d4.loss_mask: 0.2318  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.1102  decode.d5.loss_mask: 0.2376  decode.d5.loss_dice: 0.2155  decode.d6.loss_cls: 0.1256  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.1337  decode.d7.loss_mask: 0.2352  decode.d7.loss_dice: 0.2143  decode.d8.loss_cls: 0.1142  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2392
10/01 02:40:38 - mmengine - INFO - Iter(train) [144500/320000]  base_lr: 5.8239e-05 lr: 5.8239e-06  eta: 21:21:32  time: 0.4422  data_time: 0.0098  memory: 5145  grad_norm: 41.0575  loss: 4.8313  decode.loss_cls: 0.0179  decode.loss_mask: 0.2298  decode.loss_dice: 0.1513  decode.d0.loss_cls: 0.8416  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.1456  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 0.2305  decode.d1.loss_dice: 0.1540  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.2313  decode.d2.loss_dice: 0.1508  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.1537  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.1444  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.2311  decode.d5.loss_dice: 0.1518  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.1454  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.1514  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.1521
10/01 02:41:00 - mmengine - INFO - Iter(train) [144550/320000]  base_lr: 5.8224e-05 lr: 5.8224e-06  eta: 21:21:10  time: 0.4411  data_time: 0.0097  memory: 5129  grad_norm: 41.9114  loss: 5.6515  decode.loss_cls: 0.0270  decode.loss_mask: 0.2121  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.9275  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.2508  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.2150  decode.d1.loss_dice: 0.2191  decode.d2.loss_cls: 0.0312  decode.d2.loss_mask: 0.2136  decode.d2.loss_dice: 0.2235  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.0295  decode.d4.loss_mask: 0.2139  decode.d4.loss_dice: 0.2289  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.2153  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.2190  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.2097  decode.d7.loss_dice: 0.2357  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2330
10/01 02:41:22 - mmengine - INFO - Iter(train) [144600/320000]  base_lr: 5.8209e-05 lr: 5.8209e-06  eta: 21:20:48  time: 0.4408  data_time: 0.0096  memory: 5129  grad_norm: 47.8667  loss: 4.4836  decode.loss_cls: 0.0092  decode.loss_mask: 0.2143  decode.loss_dice: 0.1527  decode.d0.loss_cls: 0.7675  decode.d0.loss_mask: 0.2097  decode.d0.loss_dice: 0.1446  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.2125  decode.d1.loss_dice: 0.1577  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.2149  decode.d2.loss_dice: 0.1527  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.2145  decode.d3.loss_dice: 0.1517  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.2123  decode.d4.loss_dice: 0.1533  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.1512  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2167  decode.d6.loss_dice: 0.1548  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.2111  decode.d7.loss_dice: 0.1528  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2093  decode.d8.loss_dice: 0.1520
10/01 02:41:45 - mmengine - INFO - Iter(train) [144650/320000]  base_lr: 5.8194e-05 lr: 5.8194e-06  eta: 21:20:27  time: 0.4408  data_time: 0.0098  memory: 5145  grad_norm: 24.5332  loss: 4.3640  decode.loss_cls: 0.0025  decode.loss_mask: 0.2022  decode.loss_dice: 0.1509  decode.d0.loss_cls: 0.7552  decode.d0.loss_mask: 0.2026  decode.d0.loss_dice: 0.1534  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.2022  decode.d1.loss_dice: 0.1532  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.2034  decode.d2.loss_dice: 0.1569  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2032  decode.d3.loss_dice: 0.1538  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.2035  decode.d4.loss_dice: 0.1549  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2051  decode.d5.loss_dice: 0.1533  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.2033  decode.d6.loss_dice: 0.1502  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2033  decode.d7.loss_dice: 0.1485  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.2043  decode.d8.loss_dice: 0.1539
10/01 02:42:07 - mmengine - INFO - Iter(train) [144700/320000]  base_lr: 5.8179e-05 lr: 5.8179e-06  eta: 21:20:05  time: 0.4408  data_time: 0.0097  memory: 5129  grad_norm: 97.8208  loss: 4.9079  decode.loss_cls: 0.0013  decode.loss_mask: 0.2163  decode.loss_dice: 0.1790  decode.d0.loss_cls: 0.7870  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.1710  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.1860  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.2171  decode.d2.loss_dice: 0.1776  decode.d3.loss_cls: 0.0211  decode.d3.loss_mask: 0.2171  decode.d3.loss_dice: 0.1830  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.2170  decode.d4.loss_dice: 0.1804  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.1792  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2199  decode.d6.loss_dice: 0.1854  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.2194  decode.d7.loss_dice: 0.1755  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2154  decode.d8.loss_dice: 0.1827
10/01 02:42:29 - mmengine - INFO - Iter(train) [144750/320000]  base_lr: 5.8165e-05 lr: 5.8165e-06  eta: 21:19:43  time: 0.4401  data_time: 0.0094  memory: 5129  grad_norm: 43.9783  loss: 4.3275  decode.loss_cls: 0.0072  decode.loss_mask: 0.1885  decode.loss_dice: 0.1560  decode.d0.loss_cls: 0.8041  decode.d0.loss_mask: 0.1916  decode.d0.loss_dice: 0.1520  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.1893  decode.d1.loss_dice: 0.1517  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.1573  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.1867  decode.d3.loss_dice: 0.1536  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.1551  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1495  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.1523  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.1875  decode.d7.loss_dice: 0.1587  decode.d8.loss_cls: 0.0479  decode.d8.loss_mask: 0.1908  decode.d8.loss_dice: 0.1481
10/01 02:42:51 - mmengine - INFO - Iter(train) [144800/320000]  base_lr: 5.8150e-05 lr: 5.8150e-06  eta: 21:19:22  time: 0.4402  data_time: 0.0096  memory: 5129  grad_norm: 120.7454  loss: 5.8087  decode.loss_cls: 0.0033  decode.loss_mask: 0.3134  decode.loss_dice: 0.1725  decode.d0.loss_cls: 0.8512  decode.d0.loss_mask: 0.3205  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.3133  decode.d1.loss_dice: 0.1752  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.3132  decode.d2.loss_dice: 0.1711  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.3126  decode.d3.loss_dice: 0.1748  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.3074  decode.d4.loss_dice: 0.1744  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.3085  decode.d5.loss_dice: 0.1726  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3099  decode.d6.loss_dice: 0.1713  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3157  decode.d7.loss_dice: 0.1721  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.3126  decode.d8.loss_dice: 0.1731
10/01 02:43:13 - mmengine - INFO - Iter(train) [144850/320000]  base_lr: 5.8135e-05 lr: 5.8135e-06  eta: 21:19:00  time: 0.4401  data_time: 0.0096  memory: 5129  grad_norm: 87.4323  loss: 9.4202  decode.loss_cls: 0.3021  decode.loss_mask: 0.2823  decode.loss_dice: 0.3259  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 0.2743  decode.d0.loss_dice: 0.2645  decode.d1.loss_cls: 0.2140  decode.d1.loss_mask: 0.3742  decode.d1.loss_dice: 0.3403  decode.d2.loss_cls: 0.2248  decode.d2.loss_mask: 0.3377  decode.d2.loss_dice: 0.3235  decode.d3.loss_cls: 0.2124  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3188  decode.d4.loss_cls: 0.2036  decode.d4.loss_mask: 0.3659  decode.d4.loss_dice: 0.3600  decode.d5.loss_cls: 0.2180  decode.d5.loss_mask: 0.3058  decode.d5.loss_dice: 0.2876  decode.d6.loss_cls: 0.3018  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.3906  decode.d7.loss_mask: 0.2779  decode.d7.loss_dice: 0.2563  decode.d8.loss_cls: 0.3123  decode.d8.loss_mask: 0.2800  decode.d8.loss_dice: 0.2768
10/01 02:43:35 - mmengine - INFO - Iter(train) [144900/320000]  base_lr: 5.8120e-05 lr: 5.8120e-06  eta: 21:18:38  time: 0.4402  data_time: 0.0095  memory: 5129  grad_norm: 82.2762  loss: 5.5223  decode.loss_cls: 0.1173  decode.loss_mask: 0.2019  decode.loss_dice: 0.1834  decode.d0.loss_cls: 0.7899  decode.d0.loss_mask: 0.2026  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.1248  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1876  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1804  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.1765  decode.d4.loss_cls: 0.1087  decode.d4.loss_mask: 0.2025  decode.d4.loss_dice: 0.1839  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.2046  decode.d5.loss_dice: 0.1826  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.2024  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.2024  decode.d7.loss_dice: 0.1906  decode.d8.loss_cls: 0.0692  decode.d8.loss_mask: 0.2029  decode.d8.loss_dice: 0.2090
10/01 02:43:57 - mmengine - INFO - Iter(train) [144950/320000]  base_lr: 5.8105e-05 lr: 5.8105e-06  eta: 21:18:16  time: 0.4408  data_time: 0.0097  memory: 5129  grad_norm: 103.1425  loss: 7.6270  decode.loss_cls: 0.2628  decode.loss_mask: 0.2237  decode.loss_dice: 0.2241  decode.d0.loss_cls: 0.8456  decode.d0.loss_mask: 0.2252  decode.d0.loss_dice: 0.2356  decode.d1.loss_cls: 0.2594  decode.d1.loss_mask: 0.2236  decode.d1.loss_dice: 0.2253  decode.d2.loss_cls: 0.2518  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.2342  decode.d3.loss_cls: 0.2618  decode.d3.loss_mask: 0.2253  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.2536  decode.d4.loss_mask: 0.2265  decode.d4.loss_dice: 0.2388  decode.d5.loss_cls: 0.2438  decode.d5.loss_mask: 0.2251  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.2398  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.2246  decode.d7.loss_cls: 0.2300  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2244  decode.d8.loss_cls: 0.2463  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.2243
10/01 02:44:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:44:19 - mmengine - INFO - Iter(train) [145000/320000]  base_lr: 5.8090e-05 lr: 5.8090e-06  eta: 21:17:55  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 106.3382  loss: 6.3336  decode.loss_cls: 0.0939  decode.loss_mask: 0.2557  decode.loss_dice: 0.2104  decode.d0.loss_cls: 0.8162  decode.d0.loss_mask: 0.2511  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.2578  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.2111  decode.d4.loss_cls: 0.1049  decode.d4.loss_mask: 0.2526  decode.d4.loss_dice: 0.1971  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.2569  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2538  decode.d6.loss_dice: 0.2073  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.2051  decode.d8.loss_cls: 0.0981  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.2110
10/01 02:44:41 - mmengine - INFO - Iter(train) [145050/320000]  base_lr: 5.8075e-05 lr: 5.8075e-06  eta: 21:17:33  time: 0.4411  data_time: 0.0097  memory: 5145  grad_norm: 53.6294  loss: 5.9615  decode.loss_cls: 0.0331  decode.loss_mask: 0.2398  decode.loss_dice: 0.2343  decode.d0.loss_cls: 0.9376  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2263  decode.d1.loss_cls: 0.0957  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.1845  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.2398  decode.d2.loss_dice: 0.2324  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.2345  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.1819  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.2310  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.2430  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.2041
10/01 02:45:03 - mmengine - INFO - Iter(train) [145100/320000]  base_lr: 5.8060e-05 lr: 5.8060e-06  eta: 21:17:11  time: 0.4409  data_time: 0.0095  memory: 5120  grad_norm: 32.3207  loss: 4.6735  decode.loss_cls: 0.0729  decode.loss_mask: 0.1802  decode.loss_dice: 0.1641  decode.d0.loss_cls: 0.7433  decode.d0.loss_mask: 0.1864  decode.d0.loss_dice: 0.1728  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.1833  decode.d1.loss_dice: 0.1707  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.1825  decode.d2.loss_dice: 0.1570  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.1818  decode.d3.loss_dice: 0.1553  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.1830  decode.d4.loss_dice: 0.1741  decode.d5.loss_cls: 0.0564  decode.d5.loss_mask: 0.1814  decode.d5.loss_dice: 0.1718  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.1826  decode.d6.loss_dice: 0.1752  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.1831  decode.d7.loss_dice: 0.1740  decode.d8.loss_cls: 0.0205  decode.d8.loss_mask: 0.1806  decode.d8.loss_dice: 0.1680
10/01 02:45:25 - mmengine - INFO - Iter(train) [145150/320000]  base_lr: 5.8045e-05 lr: 5.8045e-06  eta: 21:16:49  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 28.5366  loss: 4.0117  decode.loss_cls: 0.0115  decode.loss_mask: 0.1791  decode.loss_dice: 0.1351  decode.d0.loss_cls: 0.8162  decode.d0.loss_mask: 0.1838  decode.d0.loss_dice: 0.1305  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.1782  decode.d1.loss_dice: 0.1309  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.1810  decode.d2.loss_dice: 0.1348  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.1763  decode.d3.loss_dice: 0.1310  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.1777  decode.d4.loss_dice: 0.1277  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.1765  decode.d5.loss_dice: 0.1284  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.1776  decode.d6.loss_dice: 0.1332  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.1357  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.1769  decode.d8.loss_dice: 0.1314
10/01 02:45:47 - mmengine - INFO - Iter(train) [145200/320000]  base_lr: 5.8030e-05 lr: 5.8030e-06  eta: 21:16:28  time: 0.4404  data_time: 0.0098  memory: 5120  grad_norm: 19.8582  loss: 4.4344  decode.loss_cls: 0.0266  decode.loss_mask: 0.1547  decode.loss_dice: 0.1888  decode.d0.loss_cls: 0.9258  decode.d0.loss_mask: 0.1557  decode.d0.loss_dice: 0.1778  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.1543  decode.d1.loss_dice: 0.1874  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.1538  decode.d2.loss_dice: 0.1822  decode.d3.loss_cls: 0.0262  decode.d3.loss_mask: 0.1539  decode.d3.loss_dice: 0.1684  decode.d4.loss_cls: 0.0239  decode.d4.loss_mask: 0.1516  decode.d4.loss_dice: 0.1715  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.1524  decode.d5.loss_dice: 0.1558  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.1543  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.1535  decode.d7.loss_dice: 0.1611  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.1548  decode.d8.loss_dice: 0.1577
10/01 02:46:09 - mmengine - INFO - Iter(train) [145250/320000]  base_lr: 5.8015e-05 lr: 5.8015e-06  eta: 21:16:06  time: 0.4411  data_time: 0.0098  memory: 5120  grad_norm: 28.4770  loss: 4.7333  decode.loss_cls: 0.0018  decode.loss_mask: 0.2270  decode.loss_dice: 0.1615  decode.d0.loss_cls: 0.7874  decode.d0.loss_mask: 0.2256  decode.d0.loss_dice: 0.1642  decode.d1.loss_cls: 0.0191  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.1662  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.1611  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.1620  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2331  decode.d4.loss_dice: 0.1618  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.1623  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.1627  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.1592  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.2271  decode.d8.loss_dice: 0.1621
10/01 02:46:31 - mmengine - INFO - Iter(train) [145300/320000]  base_lr: 5.8000e-05 lr: 5.8000e-06  eta: 21:15:44  time: 0.4407  data_time: 0.0099  memory: 5129  grad_norm: 40.4743  loss: 5.9966  decode.loss_cls: 0.1704  decode.loss_mask: 0.1910  decode.loss_dice: 0.1845  decode.d0.loss_cls: 0.9184  decode.d0.loss_mask: 0.1870  decode.d0.loss_dice: 0.1818  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 0.2087  decode.d1.loss_dice: 0.1844  decode.d2.loss_cls: 0.1338  decode.d2.loss_mask: 0.2349  decode.d2.loss_dice: 0.1911  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 0.1885  decode.d3.loss_dice: 0.1845  decode.d4.loss_cls: 0.1407  decode.d4.loss_mask: 0.1916  decode.d4.loss_dice: 0.1830  decode.d5.loss_cls: 0.1421  decode.d5.loss_mask: 0.1928  decode.d5.loss_dice: 0.1837  decode.d6.loss_cls: 0.1336  decode.d6.loss_mask: 0.1892  decode.d6.loss_dice: 0.1825  decode.d7.loss_cls: 0.1373  decode.d7.loss_mask: 0.1866  decode.d7.loss_dice: 0.1790  decode.d8.loss_cls: 0.1532  decode.d8.loss_mask: 0.1860  decode.d8.loss_dice: 0.1793
10/01 02:46:53 - mmengine - INFO - Iter(train) [145350/320000]  base_lr: 5.7985e-05 lr: 5.7985e-06  eta: 21:15:22  time: 0.4399  data_time: 0.0097  memory: 5120  grad_norm: 42.9830  loss: 4.6593  decode.loss_cls: 0.0129  decode.loss_mask: 0.1805  decode.loss_dice: 0.1636  decode.d0.loss_cls: 0.7990  decode.d0.loss_mask: 0.1799  decode.d0.loss_dice: 0.1726  decode.d1.loss_cls: 0.0585  decode.d1.loss_mask: 0.1799  decode.d1.loss_dice: 0.1660  decode.d2.loss_cls: 0.0406  decode.d2.loss_mask: 0.1798  decode.d2.loss_dice: 0.1787  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 0.1802  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0448  decode.d4.loss_mask: 0.1814  decode.d4.loss_dice: 0.1591  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.1820  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.1818  decode.d6.loss_dice: 0.1760  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.1792  decode.d7.loss_dice: 0.1641  decode.d8.loss_cls: 0.0426  decode.d8.loss_mask: 0.1802  decode.d8.loss_dice: 0.1573
10/01 02:47:16 - mmengine - INFO - Iter(train) [145400/320000]  base_lr: 5.7970e-05 lr: 5.7970e-06  eta: 21:15:01  time: 0.4401  data_time: 0.0097  memory: 5129  grad_norm: 62.5695  loss: 5.0060  decode.loss_cls: 0.0543  decode.loss_mask: 0.1945  decode.loss_dice: 0.1592  decode.d0.loss_cls: 0.9021  decode.d0.loss_mask: 0.1944  decode.d0.loss_dice: 0.1623  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 0.1954  decode.d1.loss_dice: 0.1612  decode.d2.loss_cls: 0.0521  decode.d2.loss_mask: 0.1921  decode.d2.loss_dice: 0.1605  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.1925  decode.d3.loss_dice: 0.1609  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.1950  decode.d4.loss_dice: 0.1668  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.1601  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.1942  decode.d6.loss_dice: 0.1621  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.1927  decode.d7.loss_dice: 0.1586  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.1935  decode.d8.loss_dice: 0.1600
10/01 02:47:38 - mmengine - INFO - Iter(train) [145450/320000]  base_lr: 5.7955e-05 lr: 5.7955e-06  eta: 21:14:39  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 50.6039  loss: 5.3681  decode.loss_cls: 0.0282  decode.loss_mask: 0.2111  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.9955  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.1988  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.2104  decode.d1.loss_dice: 0.1866  decode.d2.loss_cls: 0.0205  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.1800  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.2200  decode.d3.loss_dice: 0.1883  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.1852  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.1962  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.2157  decode.d6.loss_dice: 0.1997  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.2123  decode.d7.loss_dice: 0.1957  decode.d8.loss_cls: 0.0275  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.1918
10/01 02:48:00 - mmengine - INFO - Iter(train) [145500/320000]  base_lr: 5.7940e-05 lr: 5.7940e-06  eta: 21:14:17  time: 0.4406  data_time: 0.0100  memory: 5145  grad_norm: 53.0740  loss: 5.5655  decode.loss_cls: 0.0346  decode.loss_mask: 0.2708  decode.loss_dice: 0.1827  decode.d0.loss_cls: 0.7324  decode.d0.loss_mask: 0.2672  decode.d0.loss_dice: 0.1790  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 0.2694  decode.d1.loss_dice: 0.1827  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.2650  decode.d2.loss_dice: 0.1839  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.2712  decode.d3.loss_dice: 0.1818  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.2679  decode.d4.loss_dice: 0.1806  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.2660  decode.d5.loss_dice: 0.1821  decode.d6.loss_cls: 0.0357  decode.d6.loss_mask: 0.2646  decode.d6.loss_dice: 0.1827  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.1855  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.2653  decode.d8.loss_dice: 0.1800
10/01 02:48:22 - mmengine - INFO - Iter(train) [145550/320000]  base_lr: 5.7926e-05 lr: 5.7926e-06  eta: 21:13:55  time: 0.4409  data_time: 0.0100  memory: 5129  grad_norm: 79.2243  loss: 6.1022  decode.loss_cls: 0.1168  decode.loss_mask: 0.2209  decode.loss_dice: 0.2298  decode.d0.loss_cls: 0.7614  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2429  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2392  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2373  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.2349  decode.d4.loss_cls: 0.1000  decode.d4.loss_mask: 0.2206  decode.d4.loss_dice: 0.2388  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.2216  decode.d5.loss_dice: 0.2450  decode.d6.loss_cls: 0.0899  decode.d6.loss_mask: 0.2202  decode.d6.loss_dice: 0.2382  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.2188  decode.d7.loss_dice: 0.2268  decode.d8.loss_cls: 0.1045  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2381
10/01 02:48:44 - mmengine - INFO - Iter(train) [145600/320000]  base_lr: 5.7911e-05 lr: 5.7911e-06  eta: 21:13:34  time: 0.4428  data_time: 0.0099  memory: 5129  grad_norm: 76.4801  loss: 6.0611  decode.loss_cls: 0.0599  decode.loss_mask: 0.2580  decode.loss_dice: 0.2523  decode.d0.loss_cls: 0.7229  decode.d0.loss_mask: 0.2599  decode.d0.loss_dice: 0.2104  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.2571  decode.d1.loss_dice: 0.2162  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2176  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.2311  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.2314  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.2507  decode.d5.loss_dice: 0.2341  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.0520  decode.d7.loss_mask: 0.2537  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.2590  decode.d8.loss_dice: 0.2438
10/01 02:49:06 - mmengine - INFO - Iter(train) [145650/320000]  base_lr: 5.7896e-05 lr: 5.7896e-06  eta: 21:13:12  time: 0.4444  data_time: 0.0097  memory: 5145  grad_norm: 55.9259  loss: 4.5181  decode.loss_cls: 0.0052  decode.loss_mask: 0.1981  decode.loss_dice: 0.1592  decode.d0.loss_cls: 0.8503  decode.d0.loss_mask: 0.1980  decode.d0.loss_dice: 0.1572  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.2083  decode.d1.loss_dice: 0.1645  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.1999  decode.d2.loss_dice: 0.1598  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.1979  decode.d3.loss_dice: 0.1634  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.1616  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.1987  decode.d5.loss_dice: 0.1600  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.1994  decode.d6.loss_dice: 0.1599  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.1628  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.2006  decode.d8.loss_dice: 0.1596
10/01 02:49:28 - mmengine - INFO - Iter(train) [145700/320000]  base_lr: 5.7881e-05 lr: 5.7881e-06  eta: 21:12:50  time: 0.4435  data_time: 0.0097  memory: 5129  grad_norm: 16.6607  loss: 4.0068  decode.loss_cls: 0.0730  decode.loss_mask: 0.1283  decode.loss_dice: 0.1438  decode.d0.loss_cls: 0.8496  decode.d0.loss_mask: 0.1298  decode.d0.loss_dice: 0.1456  decode.d1.loss_cls: 0.0573  decode.d1.loss_mask: 0.1280  decode.d1.loss_dice: 0.1355  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.1309  decode.d2.loss_dice: 0.1442  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.1294  decode.d3.loss_dice: 0.1399  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.1294  decode.d4.loss_dice: 0.1452  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.1313  decode.d5.loss_dice: 0.1418  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.1300  decode.d6.loss_dice: 0.1395  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.1299  decode.d7.loss_dice: 0.1383  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.1301  decode.d8.loss_dice: 0.1394
10/01 02:49:50 - mmengine - INFO - Iter(train) [145750/320000]  base_lr: 5.7866e-05 lr: 5.7866e-06  eta: 21:12:29  time: 0.4415  data_time: 0.0097  memory: 5129  grad_norm: 54.1855  loss: 4.1242  decode.loss_cls: 0.0212  decode.loss_mask: 0.1607  decode.loss_dice: 0.1678  decode.d0.loss_cls: 0.7704  decode.d0.loss_mask: 0.1629  decode.d0.loss_dice: 0.1651  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.1603  decode.d1.loss_dice: 0.1648  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.1607  decode.d2.loss_dice: 0.1635  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.1590  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.1588  decode.d4.loss_dice: 0.1623  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.1583  decode.d5.loss_dice: 0.1572  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.1594  decode.d6.loss_dice: 0.1625  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.1604  decode.d7.loss_dice: 0.1656  decode.d8.loss_cls: 0.0177  decode.d8.loss_mask: 0.1592  decode.d8.loss_dice: 0.1651
10/01 02:50:12 - mmengine - INFO - Iter(train) [145800/320000]  base_lr: 5.7851e-05 lr: 5.7851e-06  eta: 21:12:07  time: 0.4433  data_time: 0.0096  memory: 5120  grad_norm: 36.9229  loss: 5.0646  decode.loss_cls: 0.0610  decode.loss_mask: 0.1963  decode.loss_dice: 0.1770  decode.d0.loss_cls: 0.8087  decode.d0.loss_mask: 0.1953  decode.d0.loss_dice: 0.1923  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.1841  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.1778  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.1957  decode.d3.loss_dice: 0.1765  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.1992  decode.d4.loss_dice: 0.1759  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.1979  decode.d5.loss_dice: 0.1743  decode.d6.loss_cls: 0.0480  decode.d6.loss_mask: 0.1998  decode.d6.loss_dice: 0.1774  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.1961  decode.d7.loss_dice: 0.1729  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.1990  decode.d8.loss_dice: 0.1766
10/01 02:50:34 - mmengine - INFO - Iter(train) [145850/320000]  base_lr: 5.7836e-05 lr: 5.7836e-06  eta: 21:11:45  time: 0.4413  data_time: 0.0097  memory: 5145  grad_norm: 49.4439  loss: 4.4691  decode.loss_cls: 0.0219  decode.loss_mask: 0.2064  decode.loss_dice: 0.1536  decode.d0.loss_cls: 0.7075  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.1495  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.2061  decode.d1.loss_dice: 0.1535  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.1494  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.2053  decode.d3.loss_dice: 0.1517  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.2048  decode.d4.loss_dice: 0.1517  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2055  decode.d5.loss_dice: 0.1542  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.2058  decode.d6.loss_dice: 0.1502  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2046  decode.d7.loss_dice: 0.1500  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.1512
10/01 02:50:56 - mmengine - INFO - Iter(train) [145900/320000]  base_lr: 5.7821e-05 lr: 5.7821e-06  eta: 21:11:23  time: 0.4410  data_time: 0.0097  memory: 5145  grad_norm: 54.5313  loss: 6.9662  decode.loss_cls: 0.1571  decode.loss_mask: 0.2572  decode.loss_dice: 0.2269  decode.d0.loss_cls: 0.9248  decode.d0.loss_mask: 0.2605  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.2575  decode.d1.loss_dice: 0.2247  decode.d2.loss_cls: 0.1194  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.2555  decode.d3.loss_cls: 0.1674  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.1661  decode.d4.loss_mask: 0.2587  decode.d4.loss_dice: 0.2168  decode.d5.loss_cls: 0.1264  decode.d5.loss_mask: 0.2573  decode.d5.loss_dice: 0.2563  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.2546  decode.d6.loss_dice: 0.2259  decode.d7.loss_cls: 0.1375  decode.d7.loss_mask: 0.2560  decode.d7.loss_dice: 0.2213  decode.d8.loss_cls: 0.1376  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2309
10/01 02:51:18 - mmengine - INFO - Iter(train) [145950/320000]  base_lr: 5.7806e-05 lr: 5.7806e-06  eta: 21:11:02  time: 0.4404  data_time: 0.0097  memory: 5129  grad_norm: 43.7335  loss: 4.1127  decode.loss_cls: 0.0009  decode.loss_mask: 0.1881  decode.loss_dice: 0.1526  decode.d0.loss_cls: 0.7043  decode.d0.loss_mask: 0.1922  decode.d0.loss_dice: 0.1564  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.1864  decode.d1.loss_dice: 0.1512  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.1872  decode.d2.loss_dice: 0.1514  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.1860  decode.d3.loss_dice: 0.1529  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.1881  decode.d4.loss_dice: 0.1516  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.1884  decode.d5.loss_dice: 0.1492  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.1854  decode.d6.loss_dice: 0.1501  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.1878  decode.d7.loss_dice: 0.1527  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.1884  decode.d8.loss_dice: 0.1530
10/01 02:51:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:51:40 - mmengine - INFO - Iter(train) [146000/320000]  base_lr: 5.7791e-05 lr: 5.7791e-06  eta: 21:10:40  time: 0.4409  data_time: 0.0097  memory: 5119  grad_norm: 60.7434  loss: 4.8423  decode.loss_cls: 0.0035  decode.loss_mask: 0.2407  decode.loss_dice: 0.1670  decode.d0.loss_cls: 0.7863  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.1659  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.1624  decode.d2.loss_cls: 0.0037  decode.d2.loss_mask: 0.2463  decode.d2.loss_dice: 0.1650  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.2333  decode.d3.loss_dice: 0.1635  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.1581  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.2357  decode.d5.loss_dice: 0.1636  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.2388  decode.d6.loss_dice: 0.1653  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2395  decode.d7.loss_dice: 0.1675  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2399  decode.d8.loss_dice: 0.1611
10/01 02:52:03 - mmengine - INFO - Iter(train) [146050/320000]  base_lr: 5.7776e-05 lr: 5.7776e-06  eta: 21:10:18  time: 0.4411  data_time: 0.0099  memory: 5145  grad_norm: 80.2108  loss: 4.8404  decode.loss_cls: 0.0118  decode.loss_mask: 0.2397  decode.loss_dice: 0.1491  decode.d0.loss_cls: 0.7708  decode.d0.loss_mask: 0.2503  decode.d0.loss_dice: 0.1520  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2419  decode.d1.loss_dice: 0.1487  decode.d2.loss_cls: 0.0259  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.1467  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.2569  decode.d3.loss_dice: 0.1530  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.1564  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.2480  decode.d5.loss_dice: 0.1494  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.1479  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.1469  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.1449
10/01 02:52:25 - mmengine - INFO - Iter(train) [146100/320000]  base_lr: 5.7761e-05 lr: 5.7761e-06  eta: 21:09:56  time: 0.4407  data_time: 0.0094  memory: 5129  grad_norm: 51.6963  loss: 4.7493  decode.loss_cls: 0.0357  decode.loss_mask: 0.1793  decode.loss_dice: 0.1407  decode.d0.loss_cls: 0.8611  decode.d0.loss_mask: 0.1806  decode.d0.loss_dice: 0.1545  decode.d1.loss_cls: 0.0827  decode.d1.loss_mask: 0.1771  decode.d1.loss_dice: 0.1548  decode.d2.loss_cls: 0.0859  decode.d2.loss_mask: 0.1774  decode.d2.loss_dice: 0.1446  decode.d3.loss_cls: 0.0902  decode.d3.loss_mask: 0.1765  decode.d3.loss_dice: 0.1488  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.1771  decode.d4.loss_dice: 0.1406  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.1762  decode.d5.loss_dice: 0.1685  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.1774  decode.d6.loss_dice: 0.1488  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.1769  decode.d7.loss_dice: 0.1511  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.1787  decode.d8.loss_dice: 0.1460
10/01 02:52:47 - mmengine - INFO - Iter(train) [146150/320000]  base_lr: 5.7746e-05 lr: 5.7746e-06  eta: 21:09:35  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 68.4548  loss: 5.6260  decode.loss_cls: 0.0069  decode.loss_mask: 0.2847  decode.loss_dice: 0.2100  decode.d0.loss_cls: 0.6391  decode.d0.loss_mask: 0.2955  decode.d0.loss_dice: 0.2006  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.2909  decode.d1.loss_dice: 0.2034  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.2935  decode.d2.loss_dice: 0.2008  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.2920  decode.d3.loss_dice: 0.2054  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.2917  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.2891  decode.d5.loss_dice: 0.1970  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.1990  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2859  decode.d7.loss_dice: 0.1945  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2866  decode.d8.loss_dice: 0.1975
10/01 02:53:09 - mmengine - INFO - Iter(train) [146200/320000]  base_lr: 5.7731e-05 lr: 5.7731e-06  eta: 21:09:13  time: 0.4408  data_time: 0.0095  memory: 5129  grad_norm: 42.6858  loss: 5.8140  decode.loss_cls: 0.0914  decode.loss_mask: 0.2072  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.7236  decode.d0.loss_mask: 0.2079  decode.d0.loss_dice: 0.2179  decode.d1.loss_cls: 0.1016  decode.d1.loss_mask: 0.2085  decode.d1.loss_dice: 0.2370  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 0.2073  decode.d2.loss_dice: 0.2181  decode.d3.loss_cls: 0.0931  decode.d3.loss_mask: 0.2035  decode.d3.loss_dice: 0.2202  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.2074  decode.d4.loss_dice: 0.2226  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.2045  decode.d5.loss_dice: 0.2214  decode.d6.loss_cls: 0.0899  decode.d6.loss_mask: 0.2057  decode.d6.loss_dice: 0.2191  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.2069  decode.d7.loss_dice: 0.2293  decode.d8.loss_cls: 0.0903  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.2102
10/01 02:53:31 - mmengine - INFO - Iter(train) [146250/320000]  base_lr: 5.7716e-05 lr: 5.7716e-06  eta: 21:08:51  time: 0.4410  data_time: 0.0096  memory: 5129  grad_norm: 92.9872  loss: 5.8720  decode.loss_cls: 0.1325  decode.loss_mask: 0.2155  decode.loss_dice: 0.1740  decode.d0.loss_cls: 0.8652  decode.d0.loss_mask: 0.2172  decode.d0.loss_dice: 0.1827  decode.d1.loss_cls: 0.1039  decode.d1.loss_mask: 0.2123  decode.d1.loss_dice: 0.1646  decode.d2.loss_cls: 0.1682  decode.d2.loss_mask: 0.2136  decode.d2.loss_dice: 0.1573  decode.d3.loss_cls: 0.1300  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.1639  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.1695  decode.d5.loss_cls: 0.1572  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.1613  decode.d6.loss_cls: 0.1241  decode.d6.loss_mask: 0.2147  decode.d6.loss_dice: 0.1607  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 0.2150  decode.d7.loss_dice: 0.1616  decode.d8.loss_cls: 0.1269  decode.d8.loss_mask: 0.2150  decode.d8.loss_dice: 0.1676
10/01 02:53:53 - mmengine - INFO - Iter(train) [146300/320000]  base_lr: 5.7701e-05 lr: 5.7701e-06  eta: 21:08:29  time: 0.4418  data_time: 0.0097  memory: 5129  grad_norm: 54.6705  loss: 5.8402  decode.loss_cls: 0.0526  decode.loss_mask: 0.2364  decode.loss_dice: 0.1882  decode.d0.loss_cls: 0.8572  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.1887  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.1993  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.0975  decode.d3.loss_mask: 0.2351  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.1759  decode.d5.loss_cls: 0.1102  decode.d5.loss_mask: 0.2300  decode.d5.loss_dice: 0.1914  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.2611  decode.d6.loss_dice: 0.2044  decode.d7.loss_cls: 0.0356  decode.d7.loss_mask: 0.2527  decode.d7.loss_dice: 0.1941  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.2359  decode.d8.loss_dice: 0.1803
10/01 02:54:15 - mmengine - INFO - Iter(train) [146350/320000]  base_lr: 5.7686e-05 lr: 5.7686e-06  eta: 21:08:08  time: 0.4416  data_time: 0.0097  memory: 5120  grad_norm: 113.1426  loss: 5.4683  decode.loss_cls: 0.0144  decode.loss_mask: 0.2286  decode.loss_dice: 0.2221  decode.d0.loss_cls: 0.8058  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.2081  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.2254  decode.d1.loss_dice: 0.2045  decode.d2.loss_cls: 0.0340  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.2131  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.2042  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.0326  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2163  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.2258  decode.d6.loss_dice: 0.2204  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.2330  decode.d7.loss_dice: 0.2034  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.2280  decode.d8.loss_dice: 0.2215
10/01 02:54:37 - mmengine - INFO - Iter(train) [146400/320000]  base_lr: 5.7671e-05 lr: 5.7671e-06  eta: 21:07:46  time: 0.4407  data_time: 0.0095  memory: 5129  grad_norm: 83.4963  loss: 4.9660  decode.loss_cls: 0.0099  decode.loss_mask: 0.2421  decode.loss_dice: 0.1654  decode.d0.loss_cls: 0.7707  decode.d0.loss_mask: 0.2468  decode.d0.loss_dice: 0.1704  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.2434  decode.d1.loss_dice: 0.1666  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.2435  decode.d2.loss_dice: 0.1646  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.2454  decode.d3.loss_dice: 0.1655  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.1645  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.2401  decode.d5.loss_dice: 0.1633  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.1672  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.2414  decode.d7.loss_dice: 0.1684  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.1686
10/01 02:54:59 - mmengine - INFO - Iter(train) [146450/320000]  base_lr: 5.7657e-05 lr: 5.7657e-06  eta: 21:07:25  time: 0.4402  data_time: 0.0094  memory: 5129  grad_norm: 39.6992  loss: 4.7861  decode.loss_cls: 0.0033  decode.loss_mask: 0.1983  decode.loss_dice: 0.1839  decode.d0.loss_cls: 0.8902  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1742  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.2020  decode.d1.loss_dice: 0.1935  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.1984  decode.d2.loss_dice: 0.1763  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.1990  decode.d3.loss_dice: 0.1741  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.1972  decode.d4.loss_dice: 0.1866  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.1991  decode.d5.loss_dice: 0.1904  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.1993  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.1974  decode.d7.loss_dice: 0.1657  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.1920
10/01 02:55:21 - mmengine - INFO - Iter(train) [146500/320000]  base_lr: 5.7642e-05 lr: 5.7642e-06  eta: 21:07:03  time: 0.4402  data_time: 0.0095  memory: 5120  grad_norm: 23.4364  loss: 4.0879  decode.loss_cls: 0.0058  decode.loss_mask: 0.1783  decode.loss_dice: 0.1416  decode.d0.loss_cls: 0.7717  decode.d0.loss_mask: 0.1842  decode.d0.loss_dice: 0.1383  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.1859  decode.d1.loss_dice: 0.1437  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.1793  decode.d2.loss_dice: 0.1377  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.1807  decode.d3.loss_dice: 0.1402  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.1820  decode.d4.loss_dice: 0.1445  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.1799  decode.d5.loss_dice: 0.1419  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.1805  decode.d6.loss_dice: 0.1426  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.1799  decode.d7.loss_dice: 0.1470  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.1820  decode.d8.loss_dice: 0.1427
10/01 02:55:43 - mmengine - INFO - Iter(train) [146550/320000]  base_lr: 5.7627e-05 lr: 5.7627e-06  eta: 21:06:41  time: 0.4405  data_time: 0.0094  memory: 5145  grad_norm: 61.0025  loss: 5.1053  decode.loss_cls: 0.0597  decode.loss_mask: 0.1832  decode.loss_dice: 0.1855  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 0.1859  decode.d0.loss_dice: 0.1852  decode.d1.loss_cls: 0.0797  decode.d1.loss_mask: 0.1835  decode.d1.loss_dice: 0.1980  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.1844  decode.d2.loss_dice: 0.2104  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.1825  decode.d3.loss_dice: 0.1896  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.1823  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.1832  decode.d5.loss_dice: 0.1941  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.1831  decode.d6.loss_dice: 0.1814  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.1807  decode.d8.loss_dice: 0.1808
10/01 02:56:05 - mmengine - INFO - Iter(train) [146600/320000]  base_lr: 5.7612e-05 lr: 5.7612e-06  eta: 21:06:19  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 30.3027  loss: 4.6518  decode.loss_cls: 0.0241  decode.loss_mask: 0.1847  decode.loss_dice: 0.1622  decode.d0.loss_cls: 0.9104  decode.d0.loss_mask: 0.1843  decode.d0.loss_dice: 0.1604  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.1840  decode.d1.loss_dice: 0.1622  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.1832  decode.d2.loss_dice: 0.1732  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.1833  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0294  decode.d4.loss_mask: 0.1828  decode.d4.loss_dice: 0.1631  decode.d5.loss_cls: 0.0315  decode.d5.loss_mask: 0.1833  decode.d5.loss_dice: 0.1585  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 0.1834  decode.d6.loss_dice: 0.1632  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.1849  decode.d7.loss_dice: 0.1539  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.1812  decode.d8.loss_dice: 0.1594
10/01 02:56:28 - mmengine - INFO - Iter(train) [146650/320000]  base_lr: 5.7597e-05 lr: 5.7597e-06  eta: 21:05:58  time: 0.4412  data_time: 0.0097  memory: 5129  grad_norm: 30.5427  loss: 4.2216  decode.loss_cls: 0.0026  decode.loss_mask: 0.1977  decode.loss_dice: 0.1524  decode.d0.loss_cls: 0.7118  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.1531  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.1986  decode.d1.loss_dice: 0.1487  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.1963  decode.d2.loss_dice: 0.1515  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.1967  decode.d3.loss_dice: 0.1490  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.1983  decode.d4.loss_dice: 0.1526  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.1969  decode.d5.loss_dice: 0.1447  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.1936  decode.d6.loss_dice: 0.1472  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.1986  decode.d7.loss_dice: 0.1478  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.1973  decode.d8.loss_dice: 0.1500
10/01 02:56:50 - mmengine - INFO - Iter(train) [146700/320000]  base_lr: 5.7582e-05 lr: 5.7582e-06  eta: 21:05:36  time: 0.4412  data_time: 0.0095  memory: 5145  grad_norm: 45.1865  loss: 4.7301  decode.loss_cls: 0.0261  decode.loss_mask: 0.1819  decode.loss_dice: 0.1639  decode.d0.loss_cls: 0.8999  decode.d0.loss_mask: 0.1833  decode.d0.loss_dice: 0.1771  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.1842  decode.d1.loss_dice: 0.1619  decode.d2.loss_cls: 0.0353  decode.d2.loss_mask: 0.1829  decode.d2.loss_dice: 0.1520  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.1586  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.1819  decode.d4.loss_dice: 0.1678  decode.d5.loss_cls: 0.1097  decode.d5.loss_mask: 0.1793  decode.d5.loss_dice: 0.1601  decode.d6.loss_cls: 0.0346  decode.d6.loss_mask: 0.1822  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.1840  decode.d7.loss_dice: 0.1671  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.1813  decode.d8.loss_dice: 0.1542
10/01 02:57:12 - mmengine - INFO - Iter(train) [146750/320000]  base_lr: 5.7567e-05 lr: 5.7567e-06  eta: 21:05:14  time: 0.4421  data_time: 0.0099  memory: 5129  grad_norm: 47.0004  loss: 4.9636  decode.loss_cls: 0.0180  decode.loss_mask: 0.2227  decode.loss_dice: 0.1858  decode.d0.loss_cls: 0.7552  decode.d0.loss_mask: 0.2207  decode.d0.loss_dice: 0.1801  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.2225  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.1858  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.1927  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.1782  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.2232  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.2216  decode.d8.loss_dice: 0.1842
10/01 02:57:34 - mmengine - INFO - Iter(train) [146800/320000]  base_lr: 5.7552e-05 lr: 5.7552e-06  eta: 21:04:52  time: 0.4408  data_time: 0.0094  memory: 5129  grad_norm: 95.7227  loss: 4.8695  decode.loss_cls: 0.0284  decode.loss_mask: 0.2030  decode.loss_dice: 0.1804  decode.d0.loss_cls: 0.7281  decode.d0.loss_mask: 0.2030  decode.d0.loss_dice: 0.1794  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.2028  decode.d1.loss_dice: 0.1760  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.2031  decode.d2.loss_dice: 0.1796  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.2044  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.1744  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.2025  decode.d5.loss_dice: 0.1716  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.2006  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.2015  decode.d8.loss_dice: 0.1756
10/01 02:57:56 - mmengine - INFO - Iter(train) [146850/320000]  base_lr: 5.7537e-05 lr: 5.7537e-06  eta: 21:04:31  time: 0.4408  data_time: 0.0096  memory: 5120  grad_norm: 40.0845  loss: 4.2279  decode.loss_cls: 0.0067  decode.loss_mask: 0.1868  decode.loss_dice: 0.1504  decode.d0.loss_cls: 0.7323  decode.d0.loss_mask: 0.1925  decode.d0.loss_dice: 0.1595  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1566  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.1561  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.1900  decode.d3.loss_dice: 0.1592  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.1877  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.1879  decode.d5.loss_dice: 0.1560  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.1872  decode.d6.loss_dice: 0.1553  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.1868  decode.d7.loss_dice: 0.1529  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.1876  decode.d8.loss_dice: 0.1589
10/01 02:58:18 - mmengine - INFO - Iter(train) [146900/320000]  base_lr: 5.7522e-05 lr: 5.7522e-06  eta: 21:04:09  time: 0.4414  data_time: 0.0096  memory: 5129  grad_norm: 90.8063  loss: 6.1804  decode.loss_cls: 0.1373  decode.loss_mask: 0.1890  decode.loss_dice: 0.2434  decode.d0.loss_cls: 0.8887  decode.d0.loss_mask: 0.1891  decode.d0.loss_dice: 0.2291  decode.d1.loss_cls: 0.1047  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.2387  decode.d2.loss_cls: 0.1001  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.2220  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 0.1883  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.1887  decode.d4.loss_dice: 0.2390  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.1945  decode.d5.loss_dice: 0.2624  decode.d6.loss_cls: 0.1259  decode.d6.loss_mask: 0.1925  decode.d6.loss_dice: 0.2365  decode.d7.loss_cls: 0.1351  decode.d7.loss_mask: 0.1916  decode.d7.loss_dice: 0.2311  decode.d8.loss_cls: 0.1257  decode.d8.loss_mask: 0.1899  decode.d8.loss_dice: 0.2375
10/01 02:58:40 - mmengine - INFO - Iter(train) [146950/320000]  base_lr: 5.7507e-05 lr: 5.7507e-06  eta: 21:03:47  time: 0.4408  data_time: 0.0096  memory: 5120  grad_norm: 30.3543  loss: 4.9837  decode.loss_cls: 0.0422  decode.loss_mask: 0.1988  decode.loss_dice: 0.1872  decode.d0.loss_cls: 0.7749  decode.d0.loss_mask: 0.2004  decode.d0.loss_dice: 0.1594  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.1528  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.2014  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.1991  decode.d3.loss_dice: 0.1944  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.1586  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.1972  decode.d5.loss_dice: 0.1634  decode.d6.loss_cls: 0.0435  decode.d6.loss_mask: 0.1996  decode.d6.loss_dice: 0.1520  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.2015  decode.d7.loss_dice: 0.1798  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.1971  decode.d8.loss_dice: 0.1850
10/01 02:59:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 02:59:02 - mmengine - INFO - Iter(train) [147000/320000]  base_lr: 5.7492e-05 lr: 5.7492e-06  eta: 21:03:25  time: 0.4403  data_time: 0.0093  memory: 5129  grad_norm: 35.5641  loss: 4.3191  decode.loss_cls: 0.0641  decode.loss_mask: 0.1596  decode.loss_dice: 0.1463  decode.d0.loss_cls: 0.7597  decode.d0.loss_mask: 0.1618  decode.d0.loss_dice: 0.1463  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.1596  decode.d1.loss_dice: 0.1458  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.1596  decode.d2.loss_dice: 0.1419  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.1590  decode.d3.loss_dice: 0.1456  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.1581  decode.d4.loss_dice: 0.1441  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.1592  decode.d5.loss_dice: 0.1460  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.1587  decode.d6.loss_dice: 0.1458  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.1593  decode.d7.loss_dice: 0.1428  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.1583  decode.d8.loss_dice: 0.1415
10/01 02:59:24 - mmengine - INFO - Iter(train) [147050/320000]  base_lr: 5.7477e-05 lr: 5.7477e-06  eta: 21:03:04  time: 0.4401  data_time: 0.0094  memory: 5145  grad_norm: 25.6853  loss: 3.4904  decode.loss_cls: 0.0041  decode.loss_mask: 0.1375  decode.loss_dice: 0.1293  decode.d0.loss_cls: 0.8272  decode.d0.loss_mask: 0.1380  decode.d0.loss_dice: 0.1210  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.1387  decode.d1.loss_dice: 0.1146  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1379  decode.d2.loss_dice: 0.1140  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.1397  decode.d3.loss_dice: 0.1274  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1381  decode.d4.loss_dice: 0.1260  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.1393  decode.d5.loss_dice: 0.1326  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.1387  decode.d6.loss_dice: 0.1231  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.1395  decode.d7.loss_dice: 0.1221  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1387  decode.d8.loss_dice: 0.1243
10/01 02:59:46 - mmengine - INFO - Iter(train) [147100/320000]  base_lr: 5.7462e-05 lr: 5.7462e-06  eta: 21:02:42  time: 0.4409  data_time: 0.0095  memory: 5129  grad_norm: 45.9531  loss: 4.5263  decode.loss_cls: 0.0105  decode.loss_mask: 0.1989  decode.loss_dice: 0.1537  decode.d0.loss_cls: 0.8599  decode.d0.loss_mask: 0.1963  decode.d0.loss_dice: 0.1480  decode.d1.loss_cls: 0.0419  decode.d1.loss_mask: 0.1987  decode.d1.loss_dice: 0.1514  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.1994  decode.d2.loss_dice: 0.1612  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.1992  decode.d3.loss_dice: 0.1561  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.1987  decode.d4.loss_dice: 0.1540  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.1975  decode.d5.loss_dice: 0.1561  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1543  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.1959  decode.d7.loss_dice: 0.1488  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.1978  decode.d8.loss_dice: 0.1514
10/01 03:00:08 - mmengine - INFO - Iter(train) [147150/320000]  base_lr: 5.7447e-05 lr: 5.7447e-06  eta: 21:02:20  time: 0.4423  data_time: 0.0095  memory: 5120  grad_norm: 32.8028  loss: 5.5563  decode.loss_cls: 0.0037  decode.loss_mask: 0.2717  decode.loss_dice: 0.2094  decode.d0.loss_cls: 0.6768  decode.d0.loss_mask: 0.2799  decode.d0.loss_dice: 0.2038  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.2740  decode.d1.loss_dice: 0.2092  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2746  decode.d2.loss_dice: 0.2115  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2078  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.2710  decode.d4.loss_dice: 0.2119  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2737  decode.d5.loss_dice: 0.2098  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.2744  decode.d6.loss_dice: 0.2137  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2718  decode.d7.loss_dice: 0.2099  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2723  decode.d8.loss_dice: 0.2108
10/01 03:00:30 - mmengine - INFO - Iter(train) [147200/320000]  base_lr: 5.7432e-05 lr: 5.7432e-06  eta: 21:01:58  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 65.7162  loss: 4.7217  decode.loss_cls: 0.0063  decode.loss_mask: 0.2280  decode.loss_dice: 0.1559  decode.d0.loss_cls: 0.7296  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.1518  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.2283  decode.d1.loss_dice: 0.1488  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.1526  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.1515  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1538  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.1513  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.1545  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.2279  decode.d7.loss_dice: 0.1506  decode.d8.loss_cls: 0.0177  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.1519
10/01 03:00:52 - mmengine - INFO - Iter(train) [147250/320000]  base_lr: 5.7417e-05 lr: 5.7417e-06  eta: 21:01:37  time: 0.4428  data_time: 0.0096  memory: 5129  grad_norm: 27.9371  loss: 4.5830  decode.loss_cls: 0.0574  decode.loss_mask: 0.1799  decode.loss_dice: 0.1417  decode.d0.loss_cls: 0.8550  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1365  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.1837  decode.d1.loss_dice: 0.1388  decode.d2.loss_cls: 0.0803  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.1420  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.1806  decode.d3.loss_dice: 0.1410  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.1821  decode.d4.loss_dice: 0.1632  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.1801  decode.d5.loss_dice: 0.1501  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.1799  decode.d6.loss_dice: 0.1445  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.1804  decode.d7.loss_dice: 0.1409  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.1783  decode.d8.loss_dice: 0.1403
10/01 03:01:14 - mmengine - INFO - Iter(train) [147300/320000]  base_lr: 5.7402e-05 lr: 5.7402e-06  eta: 21:01:15  time: 0.4405  data_time: 0.0095  memory: 5129  grad_norm: 67.4734  loss: 6.2548  decode.loss_cls: 0.0787  decode.loss_mask: 0.2532  decode.loss_dice: 0.2250  decode.d0.loss_cls: 0.7397  decode.d0.loss_mask: 0.2427  decode.d0.loss_dice: 0.2359  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.2522  decode.d1.loss_dice: 0.2216  decode.d2.loss_cls: 0.0768  decode.d2.loss_mask: 0.2486  decode.d2.loss_dice: 0.2218  decode.d3.loss_cls: 0.0950  decode.d3.loss_mask: 0.2519  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.0988  decode.d4.loss_mask: 0.2542  decode.d4.loss_dice: 0.2220  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.2508  decode.d5.loss_dice: 0.2218  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.2504  decode.d6.loss_dice: 0.2319  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.2532  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.2313
10/01 03:01:36 - mmengine - INFO - Iter(train) [147350/320000]  base_lr: 5.7387e-05 lr: 5.7387e-06  eta: 21:00:53  time: 0.4426  data_time: 0.0094  memory: 5120  grad_norm: 67.8907  loss: 4.6060  decode.loss_cls: 0.0236  decode.loss_mask: 0.1723  decode.loss_dice: 0.1936  decode.d0.loss_cls: 0.8541  decode.d0.loss_mask: 0.1753  decode.d0.loss_dice: 0.1877  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.1742  decode.d1.loss_dice: 0.1848  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.1735  decode.d2.loss_dice: 0.1951  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.1735  decode.d3.loss_dice: 0.1888  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.1734  decode.d4.loss_dice: 0.1815  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.1726  decode.d5.loss_dice: 0.1883  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.1726  decode.d6.loss_dice: 0.1875  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.1739  decode.d7.loss_dice: 0.1875  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.1726  decode.d8.loss_dice: 0.1944
10/01 03:01:59 - mmengine - INFO - Iter(train) [147400/320000]  base_lr: 5.7372e-05 lr: 5.7372e-06  eta: 21:00:31  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 62.0645  loss: 6.6903  decode.loss_cls: 0.0896  decode.loss_mask: 0.2898  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.9358  decode.d0.loss_mask: 0.2254  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.2321  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.1103  decode.d2.loss_mask: 0.2265  decode.d2.loss_dice: 0.2122  decode.d3.loss_cls: 0.1228  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.1958  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.2260  decode.d4.loss_dice: 0.1956  decode.d5.loss_cls: 0.1243  decode.d5.loss_mask: 0.2352  decode.d5.loss_dice: 0.2012  decode.d6.loss_cls: 0.1432  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.1952  decode.d7.loss_cls: 0.1289  decode.d7.loss_mask: 0.3233  decode.d7.loss_dice: 0.2269  decode.d8.loss_cls: 0.1214  decode.d8.loss_mask: 0.4051  decode.d8.loss_dice: 0.2352
10/01 03:02:21 - mmengine - INFO - Iter(train) [147450/320000]  base_lr: 5.7357e-05 lr: 5.7357e-06  eta: 21:00:10  time: 0.4426  data_time: 0.0094  memory: 5145  grad_norm: 44.9850  loss: 4.5532  decode.loss_cls: 0.0255  decode.loss_mask: 0.1778  decode.loss_dice: 0.1660  decode.d0.loss_cls: 0.8024  decode.d0.loss_mask: 0.1788  decode.d0.loss_dice: 0.1588  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.1789  decode.d1.loss_dice: 0.1651  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.1798  decode.d2.loss_dice: 0.1671  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.1792  decode.d3.loss_dice: 0.1649  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.1771  decode.d4.loss_dice: 0.1686  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.1807  decode.d5.loss_dice: 0.1705  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.1805  decode.d6.loss_dice: 0.1694  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.1796  decode.d7.loss_dice: 0.1653  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.1778  decode.d8.loss_dice: 0.1709
10/01 03:02:43 - mmengine - INFO - Iter(train) [147500/320000]  base_lr: 5.7342e-05 lr: 5.7342e-06  eta: 20:59:48  time: 0.4414  data_time: 0.0096  memory: 5145  grad_norm: 15.2259  loss: 3.3866  decode.loss_cls: 0.0033  decode.loss_mask: 0.1262  decode.loss_dice: 0.1311  decode.d0.loss_cls: 0.7414  decode.d0.loss_mask: 0.1269  decode.d0.loss_dice: 0.1316  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.1250  decode.d1.loss_dice: 0.1281  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.1265  decode.d2.loss_dice: 0.1294  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.1251  decode.d3.loss_dice: 0.1293  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1255  decode.d4.loss_dice: 0.1333  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.1272  decode.d5.loss_dice: 0.1282  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.1256  decode.d6.loss_dice: 0.1295  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1259  decode.d7.loss_dice: 0.1307  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.1264  decode.d8.loss_dice: 0.1298
10/01 03:03:05 - mmengine - INFO - Iter(train) [147550/320000]  base_lr: 5.7328e-05 lr: 5.7328e-06  eta: 20:59:26  time: 0.4412  data_time: 0.0097  memory: 5129  grad_norm: 88.0799  loss: 5.4719  decode.loss_cls: 0.0453  decode.loss_mask: 0.2105  decode.loss_dice: 0.2352  decode.d0.loss_cls: 0.7737  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.2073  decode.d1.loss_dice: 0.2321  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.2310  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.2080  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.2111  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.2086  decode.d6.loss_dice: 0.2322  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.2370  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.2077  decode.d8.loss_dice: 0.2211
10/01 03:03:27 - mmengine - INFO - Iter(train) [147600/320000]  base_lr: 5.7313e-05 lr: 5.7313e-06  eta: 20:59:04  time: 0.4407  data_time: 0.0095  memory: 5145  grad_norm: 52.9451  loss: 5.4052  decode.loss_cls: 0.0034  decode.loss_mask: 0.2333  decode.loss_dice: 0.2121  decode.d0.loss_cls: 0.8715  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.2080  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2325  decode.d1.loss_dice: 0.2227  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2189  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2341  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2179  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2334  decode.d5.loss_dice: 0.2098  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.2120  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2376  decode.d8.loss_dice: 0.2176
10/01 03:03:49 - mmengine - INFO - Iter(train) [147650/320000]  base_lr: 5.7298e-05 lr: 5.7298e-06  eta: 20:58:43  time: 0.4408  data_time: 0.0095  memory: 5129  grad_norm: 107.4629  loss: 6.1833  decode.loss_cls: 0.0153  decode.loss_mask: 0.2211  decode.loss_dice: 0.3111  decode.d0.loss_cls: 0.8624  decode.d0.loss_mask: 0.2189  decode.d0.loss_dice: 0.2622  decode.d1.loss_cls: 0.0179  decode.d1.loss_mask: 0.2178  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.2258  decode.d2.loss_dice: 0.3079  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2775  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.2256  decode.d4.loss_dice: 0.3132  decode.d5.loss_cls: 0.0342  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.2963  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.2906  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.2190  decode.d8.loss_dice: 0.2932
10/01 03:04:11 - mmengine - INFO - Iter(train) [147700/320000]  base_lr: 5.7283e-05 lr: 5.7283e-06  eta: 20:58:21  time: 0.4415  data_time: 0.0096  memory: 5129  grad_norm: 37.8829  loss: 4.7507  decode.loss_cls: 0.0623  decode.loss_mask: 0.1822  decode.loss_dice: 0.1499  decode.d0.loss_cls: 0.9101  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.1762  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.1914  decode.d1.loss_dice: 0.1622  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.1966  decode.d2.loss_dice: 0.1604  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.1929  decode.d3.loss_dice: 0.1518  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.1832  decode.d4.loss_dice: 0.1506  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.1511  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.1832  decode.d6.loss_dice: 0.1599  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.1824  decode.d7.loss_dice: 0.1520  decode.d8.loss_cls: 0.0582  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1578
10/01 03:04:33 - mmengine - INFO - Iter(train) [147750/320000]  base_lr: 5.7268e-05 lr: 5.7268e-06  eta: 20:57:59  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 37.3981  loss: 4.2465  decode.loss_cls: 0.0096  decode.loss_mask: 0.2028  decode.loss_dice: 0.1538  decode.d0.loss_cls: 0.6626  decode.d0.loss_mask: 0.1976  decode.d0.loss_dice: 0.1466  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.1979  decode.d1.loss_dice: 0.1544  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.1951  decode.d2.loss_dice: 0.1511  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.1961  decode.d3.loss_dice: 0.1521  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.1978  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.1514  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.1981  decode.d6.loss_dice: 0.1525  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.1533  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.1552
10/01 03:04:55 - mmengine - INFO - Iter(train) [147800/320000]  base_lr: 5.7253e-05 lr: 5.7253e-06  eta: 20:57:38  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 65.4857  loss: 5.1222  decode.loss_cls: 0.0721  decode.loss_mask: 0.2013  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.8296  decode.d0.loss_mask: 0.2016  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.2011  decode.d1.loss_dice: 0.1808  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.1994  decode.d2.loss_dice: 0.1753  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.1789  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.1988  decode.d4.loss_dice: 0.1792  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.1975  decode.d5.loss_dice: 0.1823  decode.d6.loss_cls: 0.0416  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.1837  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.2010  decode.d7.loss_dice: 0.1914  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.2012  decode.d8.loss_dice: 0.1831
10/01 03:05:17 - mmengine - INFO - Iter(train) [147850/320000]  base_lr: 5.7238e-05 lr: 5.7238e-06  eta: 20:57:16  time: 0.4407  data_time: 0.0094  memory: 5129  grad_norm: 55.0548  loss: 5.2437  decode.loss_cls: 0.0761  decode.loss_mask: 0.1907  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.7267  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.1895  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.1910  decode.d1.loss_dice: 0.2035  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.1923  decode.d2.loss_dice: 0.2096  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.1929  decode.d3.loss_dice: 0.2075  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.1961  decode.d4.loss_dice: 0.2058  decode.d5.loss_cls: 0.0746  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.1910  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.1907  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.1923  decode.d7.loss_dice: 0.1909  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.1902  decode.d8.loss_dice: 0.1928
10/01 03:05:39 - mmengine - INFO - Iter(train) [147900/320000]  base_lr: 5.7223e-05 lr: 5.7223e-06  eta: 20:56:54  time: 0.4406  data_time: 0.0094  memory: 5145  grad_norm: 23.5653  loss: 4.1343  decode.loss_cls: 0.0020  decode.loss_mask: 0.1915  decode.loss_dice: 0.1439  decode.d0.loss_cls: 0.7301  decode.d0.loss_mask: 0.1957  decode.d0.loss_dice: 0.1454  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.1910  decode.d1.loss_dice: 0.1453  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.1925  decode.d2.loss_dice: 0.1445  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.1930  decode.d3.loss_dice: 0.1452  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.1926  decode.d4.loss_dice: 0.1463  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.1452  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.1405  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.1937  decode.d7.loss_dice: 0.1454  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1925  decode.d8.loss_dice: 0.1440
10/01 03:06:01 - mmengine - INFO - Iter(train) [147950/320000]  base_lr: 5.7208e-05 lr: 5.7208e-06  eta: 20:56:32  time: 0.4403  data_time: 0.0094  memory: 5120  grad_norm: 33.1362  loss: 4.3413  decode.loss_cls: 0.0017  decode.loss_mask: 0.1839  decode.loss_dice: 0.1655  decode.d0.loss_cls: 0.7748  decode.d0.loss_mask: 0.1875  decode.d0.loss_dice: 0.1754  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.1856  decode.d1.loss_dice: 0.1652  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1853  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.1854  decode.d3.loss_dice: 0.1610  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1863  decode.d4.loss_dice: 0.1670  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.1869  decode.d5.loss_dice: 0.1630  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.1851  decode.d6.loss_dice: 0.1509  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1848  decode.d7.loss_dice: 0.1652  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.1868  decode.d8.loss_dice: 0.1525
10/01 03:06:23 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:06:23 - mmengine - INFO - Iter(train) [148000/320000]  base_lr: 5.7193e-05 lr: 5.7193e-06  eta: 20:56:11  time: 0.4402  data_time: 0.0095  memory: 5145  grad_norm: 49.8046  loss: 4.2990  decode.loss_cls: 0.0136  decode.loss_mask: 0.1918  decode.loss_dice: 0.1446  decode.d0.loss_cls: 0.7769  decode.d0.loss_mask: 0.1910  decode.d0.loss_dice: 0.1399  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.1927  decode.d1.loss_dice: 0.1452  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.1910  decode.d2.loss_dice: 0.1392  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.1911  decode.d3.loss_dice: 0.1451  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.1905  decode.d4.loss_dice: 0.1457  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.1935  decode.d5.loss_dice: 0.1495  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.1892  decode.d6.loss_dice: 0.1440  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.1923  decode.d7.loss_dice: 0.1446  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.1951  decode.d8.loss_dice: 0.1462
10/01 03:06:45 - mmengine - INFO - Iter(train) [148050/320000]  base_lr: 5.7178e-05 lr: 5.7178e-06  eta: 20:55:49  time: 0.4403  data_time: 0.0095  memory: 5129  grad_norm: 50.1301  loss: 4.2836  decode.loss_cls: 0.0055  decode.loss_mask: 0.1833  decode.loss_dice: 0.1575  decode.d0.loss_cls: 0.7972  decode.d0.loss_mask: 0.1910  decode.d0.loss_dice: 0.1573  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.1874  decode.d2.loss_dice: 0.1559  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1846  decode.d3.loss_dice: 0.1578  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.1631  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.1851  decode.d5.loss_dice: 0.1574  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1842  decode.d6.loss_dice: 0.1589  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1833  decode.d7.loss_dice: 0.1556  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.1838  decode.d8.loss_dice: 0.1595
10/01 03:07:08 - mmengine - INFO - Iter(train) [148100/320000]  base_lr: 5.7163e-05 lr: 5.7163e-06  eta: 20:55:27  time: 0.4411  data_time: 0.0097  memory: 5119  grad_norm: 65.6959  loss: 6.9742  decode.loss_cls: 0.1490  decode.loss_mask: 0.2798  decode.loss_dice: 0.2210  decode.d0.loss_cls: 0.7584  decode.d0.loss_mask: 0.2476  decode.d0.loss_dice: 0.2629  decode.d1.loss_cls: 0.2415  decode.d1.loss_mask: 0.2477  decode.d1.loss_dice: 0.2146  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.2482  decode.d2.loss_dice: 0.2410  decode.d3.loss_cls: 0.1471  decode.d3.loss_mask: 0.2446  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.1750  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.2147  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.2182  decode.d6.loss_cls: 0.1524  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2382  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2513  decode.d8.loss_cls: 0.1524  decode.d8.loss_mask: 0.2626  decode.d8.loss_dice: 0.2282
10/01 03:07:30 - mmengine - INFO - Iter(train) [148150/320000]  base_lr: 5.7148e-05 lr: 5.7148e-06  eta: 20:55:05  time: 0.4395  data_time: 0.0095  memory: 5120  grad_norm: 31.9417  loss: 5.2801  decode.loss_cls: 0.1029  decode.loss_mask: 0.1774  decode.loss_dice: 0.1950  decode.d0.loss_cls: 0.8423  decode.d0.loss_mask: 0.1799  decode.d0.loss_dice: 0.1879  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.1788  decode.d1.loss_dice: 0.1886  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.1793  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.1777  decode.d3.loss_dice: 0.1926  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.1782  decode.d4.loss_dice: 0.1786  decode.d5.loss_cls: 0.0768  decode.d5.loss_mask: 0.1764  decode.d5.loss_dice: 0.1737  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.1787  decode.d6.loss_dice: 0.1859  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.1790  decode.d7.loss_dice: 0.1934  decode.d8.loss_cls: 0.0955  decode.d8.loss_mask: 0.1779  decode.d8.loss_dice: 0.1860
10/01 03:07:52 - mmengine - INFO - Iter(train) [148200/320000]  base_lr: 5.7133e-05 lr: 5.7133e-06  eta: 20:54:44  time: 0.4407  data_time: 0.0095  memory: 5120  grad_norm: 101.0555  loss: 5.6976  decode.loss_cls: 0.0824  decode.loss_mask: 0.2291  decode.loss_dice: 0.1805  decode.d0.loss_cls: 0.8083  decode.d0.loss_mask: 0.2323  decode.d0.loss_dice: 0.1823  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.1803  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.1754  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.1793  decode.d4.loss_cls: 0.1135  decode.d4.loss_mask: 0.2291  decode.d4.loss_dice: 0.1761  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.2283  decode.d5.loss_dice: 0.1771  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.0775  decode.d7.loss_mask: 0.2291  decode.d7.loss_dice: 0.1763  decode.d8.loss_cls: 0.1093  decode.d8.loss_mask: 0.2289  decode.d8.loss_dice: 0.1760
10/01 03:08:14 - mmengine - INFO - Iter(train) [148250/320000]  base_lr: 5.7118e-05 lr: 5.7118e-06  eta: 20:54:22  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 40.3119  loss: 5.0605  decode.loss_cls: 0.0053  decode.loss_mask: 0.2522  decode.loss_dice: 0.1781  decode.d0.loss_cls: 0.7262  decode.d0.loss_mask: 0.2541  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.2489  decode.d1.loss_dice: 0.1757  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.2475  decode.d2.loss_dice: 0.1803  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.1795  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2491  decode.d4.loss_dice: 0.1766  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2506  decode.d5.loss_dice: 0.1798  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2521  decode.d6.loss_dice: 0.1770  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.2523  decode.d7.loss_dice: 0.1762  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.1776
10/01 03:08:36 - mmengine - INFO - Iter(train) [148300/320000]  base_lr: 5.7103e-05 lr: 5.7103e-06  eta: 20:54:00  time: 0.4410  data_time: 0.0094  memory: 5120  grad_norm: 100.6747  loss: 5.9594  decode.loss_cls: 0.0529  decode.loss_mask: 0.2021  decode.loss_dice: 0.1912  decode.d0.loss_cls: 0.9918  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2337  decode.d1.loss_cls: 0.1537  decode.d1.loss_mask: 0.2021  decode.d1.loss_dice: 0.1989  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.2027  decode.d2.loss_dice: 0.2057  decode.d3.loss_cls: 0.1207  decode.d3.loss_mask: 0.2004  decode.d3.loss_dice: 0.2135  decode.d4.loss_cls: 0.0779  decode.d4.loss_mask: 0.2045  decode.d4.loss_dice: 0.1963  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.2035  decode.d5.loss_dice: 0.2046  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.2027  decode.d6.loss_dice: 0.2032  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.2056  decode.d7.loss_dice: 0.2028  decode.d8.loss_cls: 0.1144  decode.d8.loss_mask: 0.2058  decode.d8.loss_dice: 0.2048
10/01 03:08:58 - mmengine - INFO - Iter(train) [148350/320000]  base_lr: 5.7088e-05 lr: 5.7088e-06  eta: 20:53:38  time: 0.4403  data_time: 0.0096  memory: 5145  grad_norm: 22.4665  loss: 4.0359  decode.loss_cls: 0.0063  decode.loss_mask: 0.1928  decode.loss_dice: 0.1246  decode.d0.loss_cls: 0.7832  decode.d0.loss_mask: 0.1961  decode.d0.loss_dice: 0.1252  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.1956  decode.d1.loss_dice: 0.1289  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.1943  decode.d2.loss_dice: 0.1264  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.1963  decode.d3.loss_dice: 0.1259  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.1944  decode.d4.loss_dice: 0.1267  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.1929  decode.d5.loss_dice: 0.1265  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.1968  decode.d6.loss_dice: 0.1275  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.1933  decode.d7.loss_dice: 0.1253  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.1923  decode.d8.loss_dice: 0.1257
10/01 03:09:20 - mmengine - INFO - Iter(train) [148400/320000]  base_lr: 5.7073e-05 lr: 5.7073e-06  eta: 20:53:17  time: 0.4414  data_time: 0.0097  memory: 5145  grad_norm: 94.3876  loss: 5.4634  decode.loss_cls: 0.0363  decode.loss_mask: 0.2022  decode.loss_dice: 0.2091  decode.d0.loss_cls: 0.8667  decode.d0.loss_mask: 0.2073  decode.d0.loss_dice: 0.2078  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.2023  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.2057  decode.d2.loss_dice: 0.2171  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.2037  decode.d3.loss_dice: 0.2190  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.2032  decode.d4.loss_dice: 0.2118  decode.d5.loss_cls: 0.0349  decode.d5.loss_mask: 0.2025  decode.d5.loss_dice: 0.2163  decode.d6.loss_cls: 0.0366  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0410  decode.d7.loss_mask: 0.2006  decode.d7.loss_dice: 0.1944  decode.d8.loss_cls: 0.0403  decode.d8.loss_mask: 0.2008  decode.d8.loss_dice: 0.2073
10/01 03:09:42 - mmengine - INFO - Iter(train) [148450/320000]  base_lr: 5.7058e-05 lr: 5.7058e-06  eta: 20:52:55  time: 0.4403  data_time: 0.0095  memory: 5145  grad_norm: 42.1619  loss: 4.5489  decode.loss_cls: 0.0183  decode.loss_mask: 0.2015  decode.loss_dice: 0.1546  decode.d0.loss_cls: 0.9168  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.1469  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.1496  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.1948  decode.d2.loss_dice: 0.1481  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.1971  decode.d3.loss_dice: 0.1491  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.1975  decode.d4.loss_dice: 0.1492  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.2053  decode.d5.loss_dice: 0.1502  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.2061  decode.d6.loss_dice: 0.1537  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.1969  decode.d7.loss_dice: 0.1511  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.1963  decode.d8.loss_dice: 0.1507
10/01 03:10:04 - mmengine - INFO - Iter(train) [148500/320000]  base_lr: 5.7043e-05 lr: 5.7043e-06  eta: 20:52:33  time: 0.4410  data_time: 0.0099  memory: 5145  grad_norm: 32.4293  loss: 4.3677  decode.loss_cls: 0.0202  decode.loss_mask: 0.1599  decode.loss_dice: 0.1624  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 0.1598  decode.d0.loss_dice: 0.1615  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.1611  decode.d1.loss_dice: 0.1646  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.1596  decode.d2.loss_dice: 0.1566  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.1585  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.1615  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.1598  decode.d5.loss_dice: 0.1713  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.1610  decode.d6.loss_dice: 0.1578  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.1577  decode.d7.loss_dice: 0.1582  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.1605  decode.d8.loss_dice: 0.1685
10/01 03:10:26 - mmengine - INFO - Iter(train) [148550/320000]  base_lr: 5.7028e-05 lr: 5.7028e-06  eta: 20:52:11  time: 0.4399  data_time: 0.0097  memory: 5130  grad_norm: 33.6612  loss: 4.8496  decode.loss_cls: 0.0111  decode.loss_mask: 0.2117  decode.loss_dice: 0.1810  decode.d0.loss_cls: 0.7838  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.1798  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.2116  decode.d1.loss_dice: 0.1858  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.1724  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.2127  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.1869  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.2115  decode.d5.loss_dice: 0.1840  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.1866  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.2129  decode.d8.loss_dice: 0.1851
10/01 03:10:48 - mmengine - INFO - Iter(train) [148600/320000]  base_lr: 5.7013e-05 lr: 5.7013e-06  eta: 20:51:50  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 78.9967  loss: 5.3625  decode.loss_cls: 0.0293  decode.loss_mask: 0.2276  decode.loss_dice: 0.2094  decode.d0.loss_cls: 0.8326  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.1949  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2316  decode.d1.loss_dice: 0.2156  decode.d2.loss_cls: 0.0232  decode.d2.loss_mask: 0.2263  decode.d2.loss_dice: 0.2152  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.2283  decode.d3.loss_dice: 0.2084  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.2270  decode.d4.loss_dice: 0.1975  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.2260  decode.d5.loss_dice: 0.2009  decode.d6.loss_cls: 0.0209  decode.d6.loss_mask: 0.2267  decode.d6.loss_dice: 0.2131  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.1973
10/01 03:11:10 - mmengine - INFO - Iter(train) [148650/320000]  base_lr: 5.6998e-05 lr: 5.6998e-06  eta: 20:51:28  time: 0.4408  data_time: 0.0095  memory: 5145  grad_norm: 107.3147  loss: 4.6194  decode.loss_cls: 0.0040  decode.loss_mask: 0.2073  decode.loss_dice: 0.1572  decode.d0.loss_cls: 0.7065  decode.d0.loss_mask: 0.2114  decode.d0.loss_dice: 0.1745  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.2093  decode.d1.loss_dice: 0.1709  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.1698  decode.d3.loss_cls: 0.0707  decode.d3.loss_mask: 0.2081  decode.d3.loss_dice: 0.1791  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.1895  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.2080  decode.d5.loss_dice: 0.1709  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.2078  decode.d6.loss_dice: 0.1514  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.2075  decode.d7.loss_dice: 0.1706  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2094  decode.d8.loss_dice: 0.1732
10/01 03:11:32 - mmengine - INFO - Iter(train) [148700/320000]  base_lr: 5.6983e-05 lr: 5.6983e-06  eta: 20:51:06  time: 0.4412  data_time: 0.0098  memory: 5130  grad_norm: 21.6859  loss: 4.0962  decode.loss_cls: 0.0015  decode.loss_mask: 0.1835  decode.loss_dice: 0.1513  decode.d0.loss_cls: 0.7347  decode.d0.loss_mask: 0.1841  decode.d0.loss_dice: 0.1501  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.1876  decode.d1.loss_dice: 0.1506  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.1826  decode.d2.loss_dice: 0.1463  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.1820  decode.d3.loss_dice: 0.1495  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1814  decode.d4.loss_dice: 0.1518  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1850  decode.d6.loss_dice: 0.1493  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.1848  decode.d7.loss_dice: 0.1524  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.1820  decode.d8.loss_dice: 0.1519
10/01 03:11:54 - mmengine - INFO - Iter(train) [148750/320000]  base_lr: 5.6968e-05 lr: 5.6968e-06  eta: 20:50:44  time: 0.4406  data_time: 0.0098  memory: 5129  grad_norm: 45.9840  loss: 5.0959  decode.loss_cls: 0.0057  decode.loss_mask: 0.2258  decode.loss_dice: 0.1844  decode.d0.loss_cls: 0.7895  decode.d0.loss_mask: 0.2236  decode.d0.loss_dice: 0.1921  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.2258  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.1886  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.2236  decode.d3.loss_dice: 0.1924  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.1853  decode.d5.loss_cls: 0.0398  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.1872  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.2216  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1998
10/01 03:12:16 - mmengine - INFO - Iter(train) [148800/320000]  base_lr: 5.6953e-05 lr: 5.6953e-06  eta: 20:50:23  time: 0.4425  data_time: 0.0096  memory: 5145  grad_norm: 72.2010  loss: 4.7783  decode.loss_cls: 0.0180  decode.loss_mask: 0.2394  decode.loss_dice: 0.1520  decode.d0.loss_cls: 0.7110  decode.d0.loss_mask: 0.2412  decode.d0.loss_dice: 0.1545  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.1555  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.1604  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.1547  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.2437  decode.d4.loss_dice: 0.1537  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.2403  decode.d5.loss_dice: 0.1555  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.1557  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.2379  decode.d7.loss_dice: 0.1522  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.1532
10/01 03:12:38 - mmengine - INFO - Iter(train) [148850/320000]  base_lr: 5.6938e-05 lr: 5.6938e-06  eta: 20:50:01  time: 0.4409  data_time: 0.0094  memory: 5129  grad_norm: 47.5987  loss: 4.9390  decode.loss_cls: 0.0383  decode.loss_mask: 0.1709  decode.loss_dice: 0.2041  decode.d0.loss_cls: 0.9005  decode.d0.loss_mask: 0.1713  decode.d0.loss_dice: 0.2079  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.1699  decode.d1.loss_dice: 0.2029  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.1699  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.1692  decode.d3.loss_dice: 0.1992  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.1713  decode.d4.loss_dice: 0.1977  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.1724  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0475  decode.d6.loss_mask: 0.1720  decode.d6.loss_dice: 0.2093  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.1693  decode.d7.loss_dice: 0.1986  decode.d8.loss_cls: 0.0359  decode.d8.loss_mask: 0.1694  decode.d8.loss_dice: 0.1850
10/01 03:13:01 - mmengine - INFO - Iter(train) [148900/320000]  base_lr: 5.6923e-05 lr: 5.6923e-06  eta: 20:49:39  time: 0.4434  data_time: 0.0097  memory: 5129  grad_norm: 130.9199  loss: 7.9987  decode.loss_cls: 0.2370  decode.loss_mask: 0.2180  decode.loss_dice: 0.2847  decode.d0.loss_cls: 0.9164  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2639  decode.d1.loss_cls: 0.2225  decode.d1.loss_mask: 0.2194  decode.d1.loss_dice: 0.2438  decode.d2.loss_cls: 0.2211  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.2956  decode.d3.loss_cls: 0.2382  decode.d3.loss_mask: 0.2184  decode.d3.loss_dice: 0.3027  decode.d4.loss_cls: 0.2960  decode.d4.loss_mask: 0.2192  decode.d4.loss_dice: 0.2877  decode.d5.loss_cls: 0.2106  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.2921  decode.d6.loss_cls: 0.1975  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.2766  decode.d7.loss_cls: 0.2656  decode.d7.loss_mask: 0.2206  decode.d7.loss_dice: 0.2516  decode.d8.loss_cls: 0.2468  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.2639
10/01 03:13:23 - mmengine - INFO - Iter(train) [148950/320000]  base_lr: 5.6908e-05 lr: 5.6908e-06  eta: 20:49:17  time: 0.4408  data_time: 0.0095  memory: 5129  grad_norm: 77.6106  loss: 7.7784  decode.loss_cls: 0.0887  decode.loss_mask: 0.3136  decode.loss_dice: 0.3200  decode.d0.loss_cls: 0.6705  decode.d0.loss_mask: 0.3208  decode.d0.loss_dice: 0.3131  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.3115  decode.d1.loss_dice: 0.3167  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.3136  decode.d2.loss_dice: 0.3277  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.3068  decode.d3.loss_dice: 0.3246  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.3139  decode.d4.loss_dice: 0.3398  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.3243  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.3081  decode.d6.loss_dice: 0.3214  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.3173  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.3125  decode.d8.loss_dice: 0.3342
10/01 03:13:45 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:13:45 - mmengine - INFO - Iter(train) [149000/320000]  base_lr: 5.6894e-05 lr: 5.6894e-06  eta: 20:48:56  time: 0.4433  data_time: 0.0096  memory: 5120  grad_norm: 40.0055  loss: 4.6117  decode.loss_cls: 0.0039  decode.loss_mask: 0.2271  decode.loss_dice: 0.1457  decode.d0.loss_cls: 0.8092  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.1459  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.1472  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.2243  decode.d2.loss_dice: 0.1471  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.2275  decode.d3.loss_dice: 0.1453  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.1480  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1501  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.2289  decode.d6.loss_dice: 0.1490  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.1468  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.2255  decode.d8.loss_dice: 0.1452
10/01 03:14:07 - mmengine - INFO - Iter(train) [149050/320000]  base_lr: 5.6879e-05 lr: 5.6879e-06  eta: 20:48:34  time: 0.4405  data_time: 0.0095  memory: 5129  grad_norm: 85.4447  loss: 6.2245  decode.loss_cls: 0.1209  decode.loss_mask: 0.2217  decode.loss_dice: 0.2431  decode.d0.loss_cls: 0.7188  decode.d0.loss_mask: 0.2278  decode.d0.loss_dice: 0.2488  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.2260  decode.d1.loss_dice: 0.2735  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.2258  decode.d2.loss_dice: 0.2537  decode.d3.loss_cls: 0.0825  decode.d3.loss_mask: 0.2257  decode.d3.loss_dice: 0.2434  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.2577  decode.d6.loss_cls: 0.0978  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.2614  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2564  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.2259  decode.d8.loss_dice: 0.2573
10/01 03:14:29 - mmengine - INFO - Iter(train) [149100/320000]  base_lr: 5.6864e-05 lr: 5.6864e-06  eta: 20:48:12  time: 0.4409  data_time: 0.0094  memory: 5129  grad_norm: 23.7151  loss: 4.4613  decode.loss_cls: 0.0012  decode.loss_mask: 0.2171  decode.loss_dice: 0.1544  decode.d0.loss_cls: 0.7145  decode.d0.loss_mask: 0.2186  decode.d0.loss_dice: 0.1568  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.2155  decode.d1.loss_dice: 0.1577  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.2166  decode.d2.loss_dice: 0.1559  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2168  decode.d3.loss_dice: 0.1557  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2152  decode.d4.loss_dice: 0.1561  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.1569  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.2184  decode.d6.loss_dice: 0.1553  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2172  decode.d7.loss_dice: 0.1546  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2175  decode.d8.loss_dice: 0.1549
10/01 03:14:51 - mmengine - INFO - Iter(train) [149150/320000]  base_lr: 5.6849e-05 lr: 5.6849e-06  eta: 20:47:50  time: 0.4411  data_time: 0.0095  memory: 5145  grad_norm: 435.5770  loss: 7.8726  decode.loss_cls: 0.1718  decode.loss_mask: 0.2665  decode.loss_dice: 0.2793  decode.d0.loss_cls: 0.9152  decode.d0.loss_mask: 0.2485  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.1863  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.2687  decode.d2.loss_cls: 0.2060  decode.d2.loss_mask: 0.2577  decode.d2.loss_dice: 0.2749  decode.d3.loss_cls: 0.1866  decode.d3.loss_mask: 0.2666  decode.d3.loss_dice: 0.2798  decode.d4.loss_cls: 0.1820  decode.d4.loss_mask: 0.2540  decode.d4.loss_dice: 0.2728  decode.d5.loss_cls: 0.1751  decode.d5.loss_mask: 0.2539  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.1850  decode.d6.loss_mask: 0.2531  decode.d6.loss_dice: 0.2692  decode.d7.loss_cls: 0.1915  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.2776  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.2594  decode.d8.loss_dice: 0.2719
10/01 03:15:13 - mmengine - INFO - Iter(train) [149200/320000]  base_lr: 5.6834e-05 lr: 5.6834e-06  eta: 20:47:29  time: 0.4412  data_time: 0.0095  memory: 5145  grad_norm: 434.6176  loss: 7.8547  decode.loss_cls: 0.2010  decode.loss_mask: 0.2260  decode.loss_dice: 0.2805  decode.d0.loss_cls: 0.9455  decode.d0.loss_mask: 0.2304  decode.d0.loss_dice: 0.2681  decode.d1.loss_cls: 0.2149  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.2591  decode.d2.loss_cls: 0.2287  decode.d2.loss_mask: 0.2209  decode.d2.loss_dice: 0.2465  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.2601  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.2782  decode.d5.loss_cls: 0.2344  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.2466  decode.d6.loss_cls: 0.2304  decode.d6.loss_mask: 0.2322  decode.d6.loss_dice: 0.2652  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 0.2205  decode.d7.loss_dice: 0.2621  decode.d8.loss_cls: 0.2255  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2894
10/01 03:15:35 - mmengine - INFO - Iter(train) [149250/320000]  base_lr: 5.6819e-05 lr: 5.6819e-06  eta: 20:47:07  time: 0.4417  data_time: 0.0097  memory: 5129  grad_norm: 42.4054  loss: 4.9809  decode.loss_cls: 0.0219  decode.loss_mask: 0.2018  decode.loss_dice: 0.2043  decode.d0.loss_cls: 0.7383  decode.d0.loss_mask: 0.2023  decode.d0.loss_dice: 0.2014  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.2001  decode.d1.loss_dice: 0.2003  decode.d2.loss_cls: 0.0275  decode.d2.loss_mask: 0.1982  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.1992  decode.d3.loss_dice: 0.1917  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.1992  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.2053  decode.d5.loss_dice: 0.2091  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.1966  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.1991  decode.d8.loss_dice: 0.1909
10/01 03:15:57 - mmengine - INFO - Iter(train) [149300/320000]  base_lr: 5.6804e-05 lr: 5.6804e-06  eta: 20:46:45  time: 0.4409  data_time: 0.0095  memory: 5129  grad_norm: 24.2299  loss: 4.1711  decode.loss_cls: 0.0010  decode.loss_mask: 0.1898  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.8007  decode.d0.loss_mask: 0.1884  decode.d0.loss_dice: 0.1376  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.1902  decode.d1.loss_dice: 0.1479  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.1892  decode.d2.loss_dice: 0.1475  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1886  decode.d3.loss_dice: 0.1485  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.1461  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.1902  decode.d5.loss_dice: 0.1484  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.1895  decode.d6.loss_dice: 0.1463  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.1911  decode.d7.loss_dice: 0.1480  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.1878  decode.d8.loss_dice: 0.1453
10/01 03:16:19 - mmengine - INFO - Iter(train) [149350/320000]  base_lr: 5.6789e-05 lr: 5.6789e-06  eta: 20:46:23  time: 0.4405  data_time: 0.0097  memory: 5145  grad_norm: 28.2689  loss: 4.3051  decode.loss_cls: 0.0099  decode.loss_mask: 0.1767  decode.loss_dice: 0.1533  decode.d0.loss_cls: 0.7660  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.1612  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.1759  decode.d1.loss_dice: 0.1738  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.1767  decode.d2.loss_dice: 0.1615  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.1759  decode.d3.loss_dice: 0.1756  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.1743  decode.d4.loss_dice: 0.1560  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.1797  decode.d5.loss_dice: 0.1573  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.1775  decode.d6.loss_dice: 0.1674  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.1777  decode.d7.loss_dice: 0.1625  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.1768  decode.d8.loss_dice: 0.1534
10/01 03:16:41 - mmengine - INFO - Iter(train) [149400/320000]  base_lr: 5.6774e-05 lr: 5.6774e-06  eta: 20:46:02  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 50.6533  loss: 5.6366  decode.loss_cls: 0.0231  decode.loss_mask: 0.2188  decode.loss_dice: 0.2361  decode.d0.loss_cls: 0.9393  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.2157  decode.d1.loss_cls: 0.0294  decode.d1.loss_mask: 0.2198  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.2177  decode.d2.loss_dice: 0.2253  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.2168  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.2190  decode.d4.loss_dice: 0.2331  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.2180  decode.d5.loss_dice: 0.2202  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.2181  decode.d6.loss_dice: 0.2398  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.2188  decode.d7.loss_dice: 0.2286  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.2276
10/01 03:17:03 - mmengine - INFO - Iter(train) [149450/320000]  base_lr: 5.6759e-05 lr: 5.6759e-06  eta: 20:45:40  time: 0.4412  data_time: 0.0099  memory: 5120  grad_norm: 22.9986  loss: 4.1119  decode.loss_cls: 0.0039  decode.loss_mask: 0.1893  decode.loss_dice: 0.1335  decode.d0.loss_cls: 0.8295  decode.d0.loss_mask: 0.1919  decode.d0.loss_dice: 0.1301  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.1941  decode.d1.loss_dice: 0.1355  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.1911  decode.d2.loss_dice: 0.1352  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.1928  decode.d3.loss_dice: 0.1361  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.1886  decode.d4.loss_dice: 0.1337  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.1907  decode.d5.loss_dice: 0.1352  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.1876  decode.d6.loss_dice: 0.1333  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.1928  decode.d7.loss_dice: 0.1351  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.1918  decode.d8.loss_dice: 0.1342
10/01 03:17:25 - mmengine - INFO - Iter(train) [149500/320000]  base_lr: 5.6744e-05 lr: 5.6744e-06  eta: 20:45:18  time: 0.4410  data_time: 0.0096  memory: 5120  grad_norm: 44.0516  loss: 4.7937  decode.loss_cls: 0.0031  decode.loss_mask: 0.2228  decode.loss_dice: 0.1717  decode.d0.loss_cls: 0.7584  decode.d0.loss_mask: 0.2271  decode.d0.loss_dice: 0.1705  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.2230  decode.d1.loss_dice: 0.1728  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.1785  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.1798  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.2233  decode.d4.loss_dice: 0.1748  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2237  decode.d5.loss_dice: 0.1841  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.2242  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2251  decode.d7.loss_dice: 0.1736  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.1781
10/01 03:17:48 - mmengine - INFO - Iter(train) [149550/320000]  base_lr: 5.6729e-05 lr: 5.6729e-06  eta: 20:44:56  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 49.3787  loss: 5.1725  decode.loss_cls: 0.0326  decode.loss_mask: 0.2024  decode.loss_dice: 0.1897  decode.d0.loss_cls: 0.9179  decode.d0.loss_mask: 0.2023  decode.d0.loss_dice: 0.1884  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.1995  decode.d1.loss_dice: 0.1902  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.1994  decode.d2.loss_dice: 0.1959  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.1992  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.1869  decode.d5.loss_cls: 0.0402  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.1851  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.1988  decode.d7.loss_dice: 0.1832  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.1992  decode.d8.loss_dice: 0.1854
10/01 03:18:10 - mmengine - INFO - Iter(train) [149600/320000]  base_lr: 5.6714e-05 lr: 5.6714e-06  eta: 20:44:35  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 47.3792  loss: 4.9747  decode.loss_cls: 0.0178  decode.loss_mask: 0.2267  decode.loss_dice: 0.1839  decode.d0.loss_cls: 0.7372  decode.d0.loss_mask: 0.2313  decode.d0.loss_dice: 0.1829  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2258  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.2260  decode.d2.loss_dice: 0.1865  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.2282  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.2282  decode.d5.loss_dice: 0.1838  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.2263  decode.d6.loss_dice: 0.1899  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.1790  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.1807
10/01 03:18:32 - mmengine - INFO - Iter(train) [149650/320000]  base_lr: 5.6699e-05 lr: 5.6699e-06  eta: 20:44:13  time: 0.4405  data_time: 0.0097  memory: 5145  grad_norm: 28.6740  loss: 5.2646  decode.loss_cls: 0.0714  decode.loss_mask: 0.1862  decode.loss_dice: 0.1748  decode.d0.loss_cls: 0.8839  decode.d0.loss_mask: 0.1823  decode.d0.loss_dice: 0.1846  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.1841  decode.d1.loss_dice: 0.1740  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.1827  decode.d2.loss_dice: 0.1693  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.1836  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.1815  decode.d4.loss_dice: 0.1871  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.1828  decode.d5.loss_dice: 0.2008  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.1843  decode.d6.loss_dice: 0.1814  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.1831  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0773  decode.d8.loss_mask: 0.1867  decode.d8.loss_dice: 0.1769
10/01 03:18:54 - mmengine - INFO - Iter(train) [149700/320000]  base_lr: 5.6684e-05 lr: 5.6684e-06  eta: 20:43:51  time: 0.4407  data_time: 0.0096  memory: 5145  grad_norm: 24.5799  loss: 4.0271  decode.loss_cls: 0.0022  decode.loss_mask: 0.1736  decode.loss_dice: 0.1425  decode.d0.loss_cls: 0.8709  decode.d0.loss_mask: 0.1752  decode.d0.loss_dice: 0.1410  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.1702  decode.d1.loss_dice: 0.1471  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.1708  decode.d2.loss_dice: 0.1426  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.1708  decode.d3.loss_dice: 0.1426  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.1702  decode.d4.loss_dice: 0.1425  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1690  decode.d5.loss_dice: 0.1410  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.1698  decode.d6.loss_dice: 0.1409  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.1696  decode.d7.loss_dice: 0.1410  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.1712  decode.d8.loss_dice: 0.1394
10/01 03:19:16 - mmengine - INFO - Iter(train) [149750/320000]  base_lr: 5.6669e-05 lr: 5.6669e-06  eta: 20:43:30  time: 0.4415  data_time: 0.0096  memory: 5145  grad_norm: 187.5537  loss: 9.0669  decode.loss_cls: 0.2440  decode.loss_mask: 0.5971  decode.loss_dice: 0.2570  decode.d0.loss_cls: 1.1025  decode.d0.loss_mask: 0.2661  decode.d0.loss_dice: 0.2770  decode.d1.loss_cls: 0.2266  decode.d1.loss_mask: 0.2716  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.2502  decode.d2.loss_mask: 0.2794  decode.d2.loss_dice: 0.2144  decode.d3.loss_cls: 0.2888  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.2234  decode.d4.loss_cls: 0.2867  decode.d4.loss_mask: 0.2933  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.2581  decode.d5.loss_mask: 0.2719  decode.d5.loss_dice: 0.2072  decode.d6.loss_cls: 0.2525  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.2608  decode.d7.loss_cls: 0.2809  decode.d7.loss_mask: 0.3034  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.2840  decode.d8.loss_mask: 0.3911  decode.d8.loss_dice: 0.2141
10/01 03:19:38 - mmengine - INFO - Iter(train) [149800/320000]  base_lr: 5.6654e-05 lr: 5.6654e-06  eta: 20:43:08  time: 0.4408  data_time: 0.0097  memory: 5145  grad_norm: 68.0834  loss: 5.6225  decode.loss_cls: 0.0653  decode.loss_mask: 0.2183  decode.loss_dice: 0.1760  decode.d0.loss_cls: 0.9224  decode.d0.loss_mask: 0.2243  decode.d0.loss_dice: 0.1758  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.2179  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.1832  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.2210  decode.d3.loss_dice: 0.1809  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.1754  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.2146  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.2171  decode.d6.loss_dice: 0.1822  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.2156  decode.d7.loss_dice: 0.1759  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.2161  decode.d8.loss_dice: 0.1748
10/01 03:20:00 - mmengine - INFO - Iter(train) [149850/320000]  base_lr: 5.6639e-05 lr: 5.6639e-06  eta: 20:42:46  time: 0.4429  data_time: 0.0098  memory: 5129  grad_norm: 48.1942  loss: 6.1247  decode.loss_cls: 0.0659  decode.loss_mask: 0.2422  decode.loss_dice: 0.2195  decode.d0.loss_cls: 0.8466  decode.d0.loss_mask: 0.2452  decode.d0.loss_dice: 0.2272  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.2448  decode.d1.loss_dice: 0.2225  decode.d2.loss_cls: 0.0690  decode.d2.loss_mask: 0.2436  decode.d2.loss_dice: 0.2230  decode.d3.loss_cls: 0.0721  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.2169  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.2468  decode.d4.loss_dice: 0.2222  decode.d5.loss_cls: 0.0663  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.2448  decode.d6.loss_dice: 0.2288  decode.d7.loss_cls: 0.0712  decode.d7.loss_mask: 0.2420  decode.d7.loss_dice: 0.2216  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2235
10/01 03:20:22 - mmengine - INFO - Iter(train) [149900/320000]  base_lr: 5.6624e-05 lr: 5.6624e-06  eta: 20:42:25  time: 0.4408  data_time: 0.0097  memory: 5145  grad_norm: 137.4827  loss: 6.0905  decode.loss_cls: 0.0897  decode.loss_mask: 0.2385  decode.loss_dice: 0.1864  decode.d0.loss_cls: 0.8593  decode.d0.loss_mask: 0.2442  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.1645  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.2002  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.2474  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0937  decode.d4.loss_mask: 0.2497  decode.d4.loss_dice: 0.2151  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2164  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2272  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.2117  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.2370  decode.d8.loss_dice: 0.1961
10/01 03:20:45 - mmengine - INFO - Iter(train) [149950/320000]  base_lr: 5.6609e-05 lr: 5.6609e-06  eta: 20:42:03  time: 0.4406  data_time: 0.0098  memory: 5145  grad_norm: 26.1121  loss: 4.2587  decode.loss_cls: 0.0036  decode.loss_mask: 0.1843  decode.loss_dice: 0.1520  decode.d0.loss_cls: 0.8367  decode.d0.loss_mask: 0.1865  decode.d0.loss_dice: 0.1479  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.1870  decode.d1.loss_dice: 0.1511  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.1880  decode.d2.loss_dice: 0.1455  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.1843  decode.d3.loss_dice: 0.1535  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.1866  decode.d4.loss_dice: 0.1598  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.1836  decode.d5.loss_dice: 0.1503  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.1851  decode.d6.loss_dice: 0.1516  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.1864  decode.d7.loss_dice: 0.1587  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.1524
10/01 03:21:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:21:07 - mmengine - INFO - Iter(train) [150000/320000]  base_lr: 5.6594e-05 lr: 5.6594e-06  eta: 20:41:41  time: 0.4408  data_time: 0.0096  memory: 5104  grad_norm: 127.6579  loss: 6.9976  decode.loss_cls: 0.1295  decode.loss_mask: 0.2505  decode.loss_dice: 0.2045  decode.d0.loss_cls: 0.9469  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.2249  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.1554  decode.d2.loss_mask: 0.2514  decode.d2.loss_dice: 0.1920  decode.d3.loss_cls: 0.1405  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.1642  decode.d4.loss_mask: 0.2531  decode.d4.loss_dice: 0.2103  decode.d5.loss_cls: 0.1488  decode.d5.loss_mask: 0.2482  decode.d5.loss_dice: 0.2043  decode.d6.loss_cls: 0.1505  decode.d6.loss_mask: 0.2482  decode.d6.loss_dice: 0.2154  decode.d7.loss_cls: 0.1697  decode.d7.loss_mask: 0.2503  decode.d7.loss_dice: 0.2310  decode.d8.loss_cls: 0.1624  decode.d8.loss_mask: 0.2472  decode.d8.loss_dice: 0.2208
10/01 03:21:29 - mmengine - INFO - Iter(train) [150050/320000]  base_lr: 5.6579e-05 lr: 5.6579e-06  eta: 20:41:20  time: 0.4411  data_time: 0.0098  memory: 5120  grad_norm: 65.4160  loss: 6.3446  decode.loss_cls: 0.0481  decode.loss_mask: 0.2709  decode.loss_dice: 0.2266  decode.d0.loss_cls: 0.8624  decode.d0.loss_mask: 0.2694  decode.d0.loss_dice: 0.2232  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.2699  decode.d1.loss_dice: 0.2277  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.2661  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.2731  decode.d3.loss_dice: 0.2216  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.2797  decode.d4.loss_dice: 0.2204  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.2711  decode.d5.loss_dice: 0.2276  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.2749  decode.d6.loss_dice: 0.2269  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.2675  decode.d7.loss_dice: 0.2249  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.2788  decode.d8.loss_dice: 0.2295
10/01 03:21:51 - mmengine - INFO - Iter(train) [150100/320000]  base_lr: 5.6564e-05 lr: 5.6564e-06  eta: 20:40:58  time: 0.4405  data_time: 0.0096  memory: 5129  grad_norm: 105.1982  loss: 5.7645  decode.loss_cls: 0.1137  decode.loss_mask: 0.2002  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.9005  decode.d0.loss_mask: 0.2055  decode.d0.loss_dice: 0.1784  decode.d1.loss_cls: 0.1527  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.1877  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.2013  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.2033  decode.d3.loss_dice: 0.1856  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.1856  decode.d5.loss_cls: 0.1204  decode.d5.loss_mask: 0.1996  decode.d5.loss_dice: 0.1874  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.2038  decode.d6.loss_dice: 0.1843  decode.d7.loss_cls: 0.1067  decode.d7.loss_mask: 0.2040  decode.d7.loss_dice: 0.1827  decode.d8.loss_cls: 0.1478  decode.d8.loss_mask: 0.2051  decode.d8.loss_dice: 0.1909
10/01 03:22:13 - mmengine - INFO - Iter(train) [150150/320000]  base_lr: 5.6549e-05 lr: 5.6549e-06  eta: 20:40:36  time: 0.4416  data_time: 0.0096  memory: 5129  grad_norm: 31.4206  loss: 5.4345  decode.loss_cls: 0.0938  decode.loss_mask: 0.1882  decode.loss_dice: 0.1733  decode.d0.loss_cls: 0.8076  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1749  decode.d1.loss_cls: 0.1056  decode.d1.loss_mask: 0.1877  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.1092  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1694  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.1906  decode.d3.loss_dice: 0.1943  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.1684  decode.d5.loss_cls: 0.1094  decode.d5.loss_mask: 0.1865  decode.d5.loss_dice: 0.1915  decode.d6.loss_cls: 0.1155  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.1669  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.1863  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 0.1872  decode.d8.loss_dice: 0.1928
10/01 03:22:35 - mmengine - INFO - Iter(train) [150200/320000]  base_lr: 5.6534e-05 lr: 5.6534e-06  eta: 20:40:14  time: 0.4406  data_time: 0.0098  memory: 5145  grad_norm: 27.1860  loss: 4.3867  decode.loss_cls: 0.0069  decode.loss_mask: 0.1768  decode.loss_dice: 0.1832  decode.d0.loss_cls: 0.7553  decode.d0.loss_mask: 0.1801  decode.d0.loss_dice: 0.1737  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.1772  decode.d1.loss_dice: 0.1895  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.1781  decode.d2.loss_dice: 0.1817  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.1767  decode.d3.loss_dice: 0.1788  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.1766  decode.d4.loss_dice: 0.1677  decode.d5.loss_cls: 0.0128  decode.d5.loss_mask: 0.1774  decode.d5.loss_dice: 0.1827  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.1751  decode.d6.loss_dice: 0.1758  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.1754  decode.d7.loss_dice: 0.1762  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.1762  decode.d8.loss_dice: 0.1832
10/01 03:22:57 - mmengine - INFO - Iter(train) [150250/320000]  base_lr: 5.6519e-05 lr: 5.6519e-06  eta: 20:39:53  time: 0.4411  data_time: 0.0096  memory: 5129  grad_norm: 62.2157  loss: 5.4289  decode.loss_cls: 0.0656  decode.loss_mask: 0.1872  decode.loss_dice: 0.2033  decode.d0.loss_cls: 0.9069  decode.d0.loss_mask: 0.1862  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.1860  decode.d1.loss_dice: 0.1959  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.1857  decode.d2.loss_dice: 0.2019  decode.d3.loss_cls: 0.0798  decode.d3.loss_mask: 0.1875  decode.d3.loss_dice: 0.1996  decode.d4.loss_cls: 0.1097  decode.d4.loss_mask: 0.1871  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.0989  decode.d5.loss_mask: 0.1881  decode.d5.loss_dice: 0.1863  decode.d6.loss_cls: 0.0819  decode.d6.loss_mask: 0.1856  decode.d6.loss_dice: 0.1910  decode.d7.loss_cls: 0.0802  decode.d7.loss_mask: 0.1869  decode.d7.loss_dice: 0.1888  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.1868  decode.d8.loss_dice: 0.1855
10/01 03:23:19 - mmengine - INFO - Iter(train) [150300/320000]  base_lr: 5.6504e-05 lr: 5.6504e-06  eta: 20:39:31  time: 0.4407  data_time: 0.0096  memory: 5146  grad_norm: 38.5581  loss: 3.7184  decode.loss_cls: 0.0037  decode.loss_mask: 0.1590  decode.loss_dice: 0.1380  decode.d0.loss_cls: 0.7456  decode.d0.loss_mask: 0.1587  decode.d0.loss_dice: 0.1345  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.1601  decode.d1.loss_dice: 0.1357  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.1598  decode.d2.loss_dice: 0.1368  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.1585  decode.d3.loss_dice: 0.1348  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.1596  decode.d4.loss_dice: 0.1326  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.1572  decode.d5.loss_dice: 0.1334  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.1570  decode.d6.loss_dice: 0.1326  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.1580  decode.d7.loss_dice: 0.1343  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.1569  decode.d8.loss_dice: 0.1326
10/01 03:23:41 - mmengine - INFO - Iter(train) [150350/320000]  base_lr: 5.6489e-05 lr: 5.6489e-06  eta: 20:39:09  time: 0.4417  data_time: 0.0100  memory: 5129  grad_norm: 41.8819  loss: 5.3347  decode.loss_cls: 0.0674  decode.loss_mask: 0.1853  decode.loss_dice: 0.2008  decode.d0.loss_cls: 0.8227  decode.d0.loss_mask: 0.1865  decode.d0.loss_dice: 0.1963  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.1878  decode.d1.loss_dice: 0.1942  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.1840  decode.d2.loss_dice: 0.1909  decode.d3.loss_cls: 0.0934  decode.d3.loss_mask: 0.1863  decode.d3.loss_dice: 0.1964  decode.d4.loss_cls: 0.1161  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.1867  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.1843  decode.d5.loss_dice: 0.1852  decode.d6.loss_cls: 0.0741  decode.d6.loss_mask: 0.1857  decode.d6.loss_dice: 0.1992  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.1850  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.1857  decode.d8.loss_dice: 0.1722
10/01 03:24:03 - mmengine - INFO - Iter(train) [150400/320000]  base_lr: 5.6474e-05 lr: 5.6474e-06  eta: 20:38:47  time: 0.4434  data_time: 0.0098  memory: 5129  grad_norm: 88.1119  loss: 5.7976  decode.loss_cls: 0.0450  decode.loss_mask: 0.2621  decode.loss_dice: 0.2109  decode.d0.loss_cls: 0.7480  decode.d0.loss_mask: 0.2764  decode.d0.loss_dice: 0.2154  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.2073  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.2614  decode.d2.loss_dice: 0.2121  decode.d3.loss_cls: 0.0388  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.2082  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.2560  decode.d4.loss_dice: 0.2078  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2099  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.2113  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.2067  decode.d8.loss_cls: 0.0384  decode.d8.loss_mask: 0.2668  decode.d8.loss_dice: 0.2107
10/01 03:24:26 - mmengine - INFO - Iter(train) [150450/320000]  base_lr: 5.6459e-05 lr: 5.6459e-06  eta: 20:38:26  time: 0.4455  data_time: 0.0100  memory: 5145  grad_norm: 35.6245  loss: 4.2035  decode.loss_cls: 0.0023  decode.loss_mask: 0.1987  decode.loss_dice: 0.1404  decode.d0.loss_cls: 0.7323  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.1433  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.1997  decode.d1.loss_dice: 0.1446  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.1978  decode.d2.loss_dice: 0.1423  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2019  decode.d3.loss_dice: 0.1452  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.2021  decode.d4.loss_dice: 0.1445  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.2009  decode.d5.loss_dice: 0.1457  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2017  decode.d6.loss_dice: 0.1434  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2001  decode.d7.loss_dice: 0.1450  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.1990  decode.d8.loss_dice: 0.1416
10/01 03:24:48 - mmengine - INFO - Iter(train) [150500/320000]  base_lr: 5.6444e-05 lr: 5.6444e-06  eta: 20:38:04  time: 0.4419  data_time: 0.0096  memory: 5129  grad_norm: 115.3483  loss: 5.3817  decode.loss_cls: 0.0874  decode.loss_mask: 0.1797  decode.loss_dice: 0.1695  decode.d0.loss_cls: 1.0133  decode.d0.loss_mask: 0.1651  decode.d0.loss_dice: 0.1560  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.1770  decode.d1.loss_dice: 0.1669  decode.d2.loss_cls: 0.1120  decode.d2.loss_mask: 0.1848  decode.d2.loss_dice: 0.1745  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.1915  decode.d3.loss_dice: 0.1730  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.1923  decode.d4.loss_dice: 0.1773  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.2029  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.1851  decode.d6.loss_dice: 0.1618  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.1837  decode.d7.loss_dice: 0.1695  decode.d8.loss_cls: 0.0957  decode.d8.loss_mask: 0.1841  decode.d8.loss_dice: 0.1710
10/01 03:25:10 - mmengine - INFO - Iter(train) [150550/320000]  base_lr: 5.6429e-05 lr: 5.6429e-06  eta: 20:37:42  time: 0.4431  data_time: 0.0096  memory: 5145  grad_norm: 55.1145  loss: 4.2905  decode.loss_cls: 0.0065  decode.loss_mask: 0.1840  decode.loss_dice: 0.1517  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 0.1850  decode.d0.loss_dice: 0.1496  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.1851  decode.d1.loss_dice: 0.1499  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.1846  decode.d2.loss_dice: 0.1477  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.1833  decode.d3.loss_dice: 0.1472  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.1859  decode.d4.loss_dice: 0.1423  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.1474  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.1855  decode.d6.loss_dice: 0.1458  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.1856  decode.d7.loss_dice: 0.1491  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.1847  decode.d8.loss_dice: 0.1595
10/01 03:25:32 - mmengine - INFO - Iter(train) [150600/320000]  base_lr: 5.6414e-05 lr: 5.6414e-06  eta: 20:37:21  time: 0.4408  data_time: 0.0096  memory: 5159  grad_norm: 83.5332  loss: 5.8749  decode.loss_cls: 0.0414  decode.loss_mask: 0.2153  decode.loss_dice: 0.2170  decode.d0.loss_cls: 0.9703  decode.d0.loss_mask: 0.2203  decode.d0.loss_dice: 0.2039  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.2283  decode.d1.loss_dice: 0.2382  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.2225  decode.d2.loss_dice: 0.2322  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.2170  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.2264  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.2186  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2198  decode.d6.loss_dice: 0.2161  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.2096  decode.d8.loss_cls: 0.0692  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.2235
10/01 03:25:54 - mmengine - INFO - Iter(train) [150650/320000]  base_lr: 5.6399e-05 lr: 5.6399e-06  eta: 20:36:59  time: 0.4406  data_time: 0.0096  memory: 5129  grad_norm: 36.0163  loss: 4.6006  decode.loss_cls: 0.0008  decode.loss_mask: 0.2198  decode.loss_dice: 0.1540  decode.d0.loss_cls: 0.8518  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.1541  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.1557  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.1526  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2182  decode.d3.loss_dice: 0.1535  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2173  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2178  decode.d5.loss_dice: 0.1547  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2201  decode.d6.loss_dice: 0.1556  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2190  decode.d7.loss_dice: 0.1563  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2163  decode.d8.loss_dice: 0.1539
10/01 03:26:16 - mmengine - INFO - Iter(train) [150700/320000]  base_lr: 5.6384e-05 lr: 5.6384e-06  eta: 20:36:37  time: 0.4401  data_time: 0.0094  memory: 5129  grad_norm: 24.4703  loss: 3.8062  decode.loss_cls: 0.0103  decode.loss_mask: 0.1599  decode.loss_dice: 0.1450  decode.d0.loss_cls: 0.7144  decode.d0.loss_mask: 0.1609  decode.d0.loss_dice: 0.1432  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.1579  decode.d1.loss_dice: 0.1418  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.1609  decode.d2.loss_dice: 0.1471  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.1609  decode.d3.loss_dice: 0.1447  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.1601  decode.d4.loss_dice: 0.1442  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.1602  decode.d5.loss_dice: 0.1461  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.1593  decode.d6.loss_dice: 0.1427  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.1573  decode.d7.loss_dice: 0.1380  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.1606  decode.d8.loss_dice: 0.1427
10/01 03:26:38 - mmengine - INFO - Iter(train) [150750/320000]  base_lr: 5.6369e-05 lr: 5.6369e-06  eta: 20:36:15  time: 0.4401  data_time: 0.0095  memory: 5120  grad_norm: 45.2212  loss: 5.3595  decode.loss_cls: 0.1093  decode.loss_mask: 0.2033  decode.loss_dice: 0.1832  decode.d0.loss_cls: 0.8272  decode.d0.loss_mask: 0.2015  decode.d0.loss_dice: 0.1821  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.2061  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.2035  decode.d2.loss_dice: 0.1878  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.2030  decode.d3.loss_dice: 0.1951  decode.d4.loss_cls: 0.1263  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.1853  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.2054  decode.d5.loss_dice: 0.1965  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.2011  decode.d6.loss_dice: 0.1753  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.2039  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1949
10/01 03:27:00 - mmengine - INFO - Iter(train) [150800/320000]  base_lr: 5.6354e-05 lr: 5.6354e-06  eta: 20:35:54  time: 0.4414  data_time: 0.0096  memory: 5145  grad_norm: 39.2499  loss: 5.1553  decode.loss_cls: 0.0734  decode.loss_mask: 0.1550  decode.loss_dice: 0.2072  decode.d0.loss_cls: 0.9729  decode.d0.loss_mask: 0.1583  decode.d0.loss_dice: 0.2073  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.1551  decode.d1.loss_dice: 0.2323  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.1572  decode.d2.loss_dice: 0.2153  decode.d3.loss_cls: 0.0327  decode.d3.loss_mask: 0.1559  decode.d3.loss_dice: 0.2273  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.1563  decode.d4.loss_dice: 0.2245  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.1552  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 0.1539  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.1540  decode.d7.loss_dice: 0.2153  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.1561  decode.d8.loss_dice: 0.2047
10/01 03:27:22 - mmengine - INFO - Iter(train) [150850/320000]  base_lr: 5.6339e-05 lr: 5.6339e-06  eta: 20:35:32  time: 0.4421  data_time: 0.0095  memory: 5129  grad_norm: 83.7996  loss: 5.6801  decode.loss_cls: 0.1289  decode.loss_mask: 0.1673  decode.loss_dice: 0.1780  decode.d0.loss_cls: 0.9183  decode.d0.loss_mask: 0.1667  decode.d0.loss_dice: 0.1671  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.1675  decode.d1.loss_dice: 0.1676  decode.d2.loss_cls: 0.1657  decode.d2.loss_mask: 0.1677  decode.d2.loss_dice: 0.1750  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 0.1677  decode.d3.loss_dice: 0.1821  decode.d4.loss_cls: 0.1468  decode.d4.loss_mask: 0.1645  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.1714  decode.d5.loss_mask: 0.1655  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.1431  decode.d6.loss_mask: 0.1646  decode.d6.loss_dice: 0.1647  decode.d7.loss_cls: 0.1763  decode.d7.loss_mask: 0.1663  decode.d7.loss_dice: 0.1620  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 0.1680  decode.d8.loss_dice: 0.1714
10/01 03:27:44 - mmengine - INFO - Iter(train) [150900/320000]  base_lr: 5.6324e-05 lr: 5.6324e-06  eta: 20:35:10  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 55.6757  loss: 5.7933  decode.loss_cls: 0.0565  decode.loss_mask: 0.2658  decode.loss_dice: 0.1851  decode.d0.loss_cls: 0.7673  decode.d0.loss_mask: 0.2681  decode.d0.loss_dice: 0.1768  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 0.2597  decode.d1.loss_dice: 0.1843  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.1853  decode.d3.loss_cls: 0.0807  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.1994  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.2628  decode.d4.loss_dice: 0.1797  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.2633  decode.d5.loss_dice: 0.1795  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.2658  decode.d6.loss_dice: 0.1803  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.1917  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.2599  decode.d8.loss_dice: 0.1744
10/01 03:28:06 - mmengine - INFO - Iter(train) [150950/320000]  base_lr: 5.6309e-05 lr: 5.6309e-06  eta: 20:34:48  time: 0.4412  data_time: 0.0094  memory: 5129  grad_norm: 26.9183  loss: 3.9225  decode.loss_cls: 0.0050  decode.loss_mask: 0.1515  decode.loss_dice: 0.1370  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.1495  decode.d0.loss_dice: 0.1533  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.1499  decode.d1.loss_dice: 0.1448  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.1494  decode.d2.loss_dice: 0.1507  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.1499  decode.d3.loss_dice: 0.1513  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.1501  decode.d4.loss_dice: 0.1417  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.1494  decode.d5.loss_dice: 0.1543  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.1502  decode.d6.loss_dice: 0.1486  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1504  decode.d7.loss_dice: 0.1500  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.1517  decode.d8.loss_dice: 0.1452
10/01 03:28:28 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:28:28 - mmengine - INFO - Iter(train) [151000/320000]  base_lr: 5.6294e-05 lr: 5.6294e-06  eta: 20:34:27  time: 0.4411  data_time: 0.0096  memory: 5145  grad_norm: 249.1602  loss: 7.8467  decode.loss_cls: 0.1558  decode.loss_mask: 0.2771  decode.loss_dice: 0.2380  decode.d0.loss_cls: 0.8808  decode.d0.loss_mask: 0.3512  decode.d0.loss_dice: 0.2915  decode.d1.loss_cls: 0.2224  decode.d1.loss_mask: 0.2913  decode.d1.loss_dice: 0.2318  decode.d2.loss_cls: 0.2115  decode.d2.loss_mask: 0.2998  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.1563  decode.d3.loss_mask: 0.3017  decode.d3.loss_dice: 0.2213  decode.d4.loss_cls: 0.1484  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.2136  decode.d5.loss_mask: 0.2955  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.2852  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.1494  decode.d7.loss_mask: 0.3143  decode.d7.loss_dice: 0.2561  decode.d8.loss_cls: 0.1292  decode.d8.loss_mask: 0.3199  decode.d8.loss_dice: 0.2406
10/01 03:28:50 - mmengine - INFO - Iter(train) [151050/320000]  base_lr: 5.6279e-05 lr: 5.6279e-06  eta: 20:34:05  time: 0.4409  data_time: 0.0095  memory: 5145  grad_norm: 63.2769  loss: 4.4041  decode.loss_cls: 0.0135  decode.loss_mask: 0.1885  decode.loss_dice: 0.1594  decode.d0.loss_cls: 0.8137  decode.d0.loss_mask: 0.1891  decode.d0.loss_dice: 0.1461  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.1877  decode.d1.loss_dice: 0.1674  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1611  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.1886  decode.d3.loss_dice: 0.1606  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.1869  decode.d4.loss_dice: 0.1602  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1577  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.1891  decode.d6.loss_dice: 0.1625  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.1573  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.1880  decode.d8.loss_dice: 0.1581
10/01 03:29:12 - mmengine - INFO - Iter(train) [151100/320000]  base_lr: 5.6264e-05 lr: 5.6264e-06  eta: 20:33:43  time: 0.4414  data_time: 0.0096  memory: 5145  grad_norm: 188.9689  loss: 5.0310  decode.loss_cls: 0.0878  decode.loss_mask: 0.1845  decode.loss_dice: 0.1616  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.1835  decode.d0.loss_dice: 0.1924  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 0.1844  decode.d1.loss_dice: 0.1724  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.1834  decode.d2.loss_dice: 0.1857  decode.d3.loss_cls: 0.0819  decode.d3.loss_mask: 0.1840  decode.d3.loss_dice: 0.1754  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.1836  decode.d4.loss_dice: 0.1724  decode.d5.loss_cls: 0.0835  decode.d5.loss_mask: 0.1820  decode.d5.loss_dice: 0.1629  decode.d6.loss_cls: 0.0819  decode.d6.loss_mask: 0.1830  decode.d6.loss_dice: 0.1607  decode.d7.loss_cls: 0.0817  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.1602  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1637
10/01 03:29:35 - mmengine - INFO - Iter(train) [151150/320000]  base_lr: 5.6249e-05 lr: 5.6249e-06  eta: 20:33:21  time: 0.4411  data_time: 0.0096  memory: 5145  grad_norm: 65.9099  loss: 4.3175  decode.loss_cls: 0.0332  decode.loss_mask: 0.1790  decode.loss_dice: 0.1284  decode.d0.loss_cls: 0.8428  decode.d0.loss_mask: 0.1785  decode.d0.loss_dice: 0.1316  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.1799  decode.d1.loss_dice: 0.1308  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.1767  decode.d2.loss_dice: 0.1289  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.1830  decode.d3.loss_dice: 0.1318  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.1869  decode.d4.loss_dice: 0.1344  decode.d5.loss_cls: 0.0316  decode.d5.loss_mask: 0.1827  decode.d5.loss_dice: 0.1311  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.1799  decode.d6.loss_dice: 0.1306  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.1301  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.1783  decode.d8.loss_dice: 0.1282
10/01 03:29:57 - mmengine - INFO - Iter(train) [151200/320000]  base_lr: 5.6234e-05 lr: 5.6234e-06  eta: 20:32:59  time: 0.4395  data_time: 0.0094  memory: 5120  grad_norm: 31.5351  loss: 4.1043  decode.loss_cls: 0.0020  decode.loss_mask: 0.1762  decode.loss_dice: 0.1556  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 0.1774  decode.d0.loss_dice: 0.1435  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.1733  decode.d1.loss_dice: 0.1605  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.1746  decode.d2.loss_dice: 0.1501  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.1754  decode.d3.loss_dice: 0.1552  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.1770  decode.d4.loss_dice: 0.1716  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1751  decode.d5.loss_dice: 0.1472  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1767  decode.d6.loss_dice: 0.1628  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.1745  decode.d7.loss_dice: 0.1714  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.1759  decode.d8.loss_dice: 0.1785
10/01 03:30:19 - mmengine - INFO - Iter(train) [151250/320000]  base_lr: 5.6219e-05 lr: 5.6219e-06  eta: 20:32:38  time: 0.4421  data_time: 0.0097  memory: 5120  grad_norm: 50.7120  loss: 6.6795  decode.loss_cls: 0.1871  decode.loss_mask: 0.2109  decode.loss_dice: 0.2498  decode.d0.loss_cls: 0.9942  decode.d0.loss_mask: 0.2137  decode.d0.loss_dice: 0.2362  decode.d1.loss_cls: 0.2524  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.1369  decode.d2.loss_mask: 0.2140  decode.d2.loss_dice: 0.2579  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2136  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 0.2120  decode.d4.loss_dice: 0.2240  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0982  decode.d6.loss_mask: 0.2111  decode.d6.loss_dice: 0.2274  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.2099  decode.d7.loss_dice: 0.2380  decode.d8.loss_cls: 0.1134  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.2418
10/01 03:30:41 - mmengine - INFO - Iter(train) [151300/320000]  base_lr: 5.6204e-05 lr: 5.6204e-06  eta: 20:32:16  time: 0.4407  data_time: 0.0096  memory: 5145  grad_norm: 49.4880  loss: 4.9956  decode.loss_cls: 0.0216  decode.loss_mask: 0.2317  decode.loss_dice: 0.1658  decode.d0.loss_cls: 0.7739  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.1675  decode.d1.loss_cls: 0.0928  decode.d1.loss_mask: 0.2282  decode.d1.loss_dice: 0.1607  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 0.2336  decode.d2.loss_dice: 0.1696  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.1656  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.1473  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.1527  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.1665  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.1657  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.1591
10/01 03:31:03 - mmengine - INFO - Iter(train) [151350/320000]  base_lr: 5.6189e-05 lr: 5.6189e-06  eta: 20:31:54  time: 0.4407  data_time: 0.0096  memory: 5146  grad_norm: 43.3252  loss: 5.3121  decode.loss_cls: 0.0349  decode.loss_mask: 0.2354  decode.loss_dice: 0.1788  decode.d0.loss_cls: 0.7668  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.1721  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.1872  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.2340  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.2351  decode.d3.loss_dice: 0.1667  decode.d4.loss_cls: 0.0344  decode.d4.loss_mask: 0.2340  decode.d4.loss_dice: 0.1743  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.2363  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.1860  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.2333  decode.d7.loss_dice: 0.2057  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.2350  decode.d8.loss_dice: 0.2013
10/01 03:31:25 - mmengine - INFO - Iter(train) [151400/320000]  base_lr: 5.6174e-05 lr: 5.6174e-06  eta: 20:31:33  time: 0.4408  data_time: 0.0095  memory: 5129  grad_norm: 46.9550  loss: 5.1685  decode.loss_cls: 0.0577  decode.loss_mask: 0.1781  decode.loss_dice: 0.1887  decode.d0.loss_cls: 0.9254  decode.d0.loss_mask: 0.1816  decode.d0.loss_dice: 0.1968  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.1771  decode.d1.loss_dice: 0.2005  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.1802  decode.d2.loss_dice: 0.1850  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.1792  decode.d3.loss_dice: 0.1600  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.1799  decode.d4.loss_dice: 0.1852  decode.d5.loss_cls: 0.0585  decode.d5.loss_mask: 0.1804  decode.d5.loss_dice: 0.1852  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.1784  decode.d6.loss_dice: 0.1919  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.1798  decode.d7.loss_dice: 0.1588  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.1805  decode.d8.loss_dice: 0.1858
10/01 03:31:47 - mmengine - INFO - Iter(train) [151450/320000]  base_lr: 5.6159e-05 lr: 5.6159e-06  eta: 20:31:11  time: 0.4408  data_time: 0.0095  memory: 5145  grad_norm: 127.5754  loss: 5.1422  decode.loss_cls: 0.0374  decode.loss_mask: 0.2231  decode.loss_dice: 0.1902  decode.d0.loss_cls: 0.8106  decode.d0.loss_mask: 0.2203  decode.d0.loss_dice: 0.1795  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.1916  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.2238  decode.d2.loss_dice: 0.1965  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.1683  decode.d4.loss_cls: 0.0267  decode.d4.loss_mask: 0.2225  decode.d4.loss_dice: 0.1808  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.2207  decode.d5.loss_dice: 0.1833  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.2189  decode.d6.loss_dice: 0.1768  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2188  decode.d7.loss_dice: 0.1821  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.1917
10/01 03:32:09 - mmengine - INFO - Iter(train) [151500/320000]  base_lr: 5.6144e-05 lr: 5.6144e-06  eta: 20:30:49  time: 0.4412  data_time: 0.0096  memory: 5129  grad_norm: 26.7649  loss: 4.5808  decode.loss_cls: 0.0009  decode.loss_mask: 0.2128  decode.loss_dice: 0.1665  decode.d0.loss_cls: 0.7534  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.1621  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.2131  decode.d1.loss_dice: 0.1677  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.1731  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.1692  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2125  decode.d4.loss_dice: 0.1741  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2102  decode.d5.loss_dice: 0.1705  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.2119  decode.d6.loss_dice: 0.1670  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2129  decode.d7.loss_dice: 0.1641  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2119  decode.d8.loss_dice: 0.1715
10/01 03:32:31 - mmengine - INFO - Iter(train) [151550/320000]  base_lr: 5.6129e-05 lr: 5.6129e-06  eta: 20:30:27  time: 0.4409  data_time: 0.0096  memory: 5129  grad_norm: 38.4694  loss: 4.8584  decode.loss_cls: 0.0496  decode.loss_mask: 0.1980  decode.loss_dice: 0.1835  decode.d0.loss_cls: 0.7826  decode.d0.loss_mask: 0.1956  decode.d0.loss_dice: 0.1625  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.1964  decode.d1.loss_dice: 0.1852  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.1977  decode.d2.loss_dice: 0.1606  decode.d3.loss_cls: 0.0503  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.1590  decode.d4.loss_cls: 0.0623  decode.d4.loss_mask: 0.1979  decode.d4.loss_dice: 0.1580  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.1588  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.1965  decode.d6.loss_dice: 0.1595  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.1592  decode.d8.loss_cls: 0.0465  decode.d8.loss_mask: 0.1980  decode.d8.loss_dice: 0.1589
10/01 03:32:53 - mmengine - INFO - Iter(train) [151600/320000]  base_lr: 5.6114e-05 lr: 5.6114e-06  eta: 20:30:06  time: 0.4416  data_time: 0.0096  memory: 5145  grad_norm: 238.0790  loss: 5.5239  decode.loss_cls: 0.0467  decode.loss_mask: 0.2873  decode.loss_dice: 0.2135  decode.d0.loss_cls: 0.8514  decode.d0.loss_mask: 0.2293  decode.d0.loss_dice: 0.1858  decode.d1.loss_cls: 0.0308  decode.d1.loss_mask: 0.2221  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.0288  decode.d2.loss_mask: 0.2102  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.2054  decode.d3.loss_dice: 0.1769  decode.d4.loss_cls: 0.0857  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.1859  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.2184  decode.d5.loss_dice: 0.1821  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.2407  decode.d7.loss_dice: 0.1938  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.2615  decode.d8.loss_dice: 0.2051
10/01 03:33:15 - mmengine - INFO - Iter(train) [151650/320000]  base_lr: 5.6099e-05 lr: 5.6099e-06  eta: 20:29:44  time: 0.4416  data_time: 0.0096  memory: 5145  grad_norm: 208.9967  loss: 8.7534  decode.loss_cls: 0.1006  decode.loss_mask: 0.2973  decode.loss_dice: 0.3161  decode.d0.loss_cls: 1.0726  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.3054  decode.d1.loss_cls: 0.2245  decode.d1.loss_mask: 0.2967  decode.d1.loss_dice: 0.3031  decode.d2.loss_cls: 0.2017  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.3134  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 0.3273  decode.d3.loss_dice: 0.3501  decode.d4.loss_cls: 0.1518  decode.d4.loss_mask: 0.3639  decode.d4.loss_dice: 0.3351  decode.d5.loss_cls: 0.1368  decode.d5.loss_mask: 0.3842  decode.d5.loss_dice: 0.3425  decode.d6.loss_cls: 0.1070  decode.d6.loss_mask: 0.2900  decode.d6.loss_dice: 0.3169  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.3075  decode.d7.loss_dice: 0.3340  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.3119  decode.d8.loss_dice: 0.3412
10/01 03:33:38 - mmengine - INFO - Iter(train) [151700/320000]  base_lr: 5.6084e-05 lr: 5.6084e-06  eta: 20:29:22  time: 0.4418  data_time: 0.0094  memory: 5129  grad_norm: 38.0731  loss: 5.5669  decode.loss_cls: 0.0897  decode.loss_mask: 0.1894  decode.loss_dice: 0.1938  decode.d0.loss_cls: 0.7904  decode.d0.loss_mask: 0.2019  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.1915  decode.d1.loss_dice: 0.1937  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 0.1853  decode.d2.loss_dice: 0.1995  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.1989  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.2160  decode.d4.loss_dice: 0.1991  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.2142  decode.d5.loss_dice: 0.2051  decode.d6.loss_cls: 0.0888  decode.d6.loss_mask: 0.2087  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.0888  decode.d7.loss_mask: 0.1840  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0884  decode.d8.loss_mask: 0.1902  decode.d8.loss_dice: 0.2029
10/01 03:34:00 - mmengine - INFO - Iter(train) [151750/320000]  base_lr: 5.6069e-05 lr: 5.6069e-06  eta: 20:29:00  time: 0.4404  data_time: 0.0094  memory: 5129  grad_norm: 50.3012  loss: 5.1842  decode.loss_cls: 0.0312  decode.loss_mask: 0.2342  decode.loss_dice: 0.1810  decode.d0.loss_cls: 0.8168  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.1776  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.1818  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.2236  decode.d2.loss_dice: 0.1802  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.1789  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 0.2309  decode.d5.loss_dice: 0.1805  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.2326  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.2283  decode.d7.loss_dice: 0.1744  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.2267  decode.d8.loss_dice: 0.1730
10/01 03:34:22 - mmengine - INFO - Iter(train) [151800/320000]  base_lr: 5.6054e-05 lr: 5.6054e-06  eta: 20:28:39  time: 0.4400  data_time: 0.0094  memory: 5129  grad_norm: 52.2802  loss: 5.9534  decode.loss_cls: 0.0746  decode.loss_mask: 0.2412  decode.loss_dice: 0.2101  decode.d0.loss_cls: 0.7664  decode.d0.loss_mask: 0.2465  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.0848  decode.d1.loss_mask: 0.2411  decode.d1.loss_dice: 0.1986  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.2421  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.0817  decode.d3.loss_mask: 0.2392  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 0.2431  decode.d4.loss_dice: 0.2139  decode.d5.loss_cls: 0.0900  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.1935  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.2013  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.2438  decode.d7.loss_dice: 0.2083  decode.d8.loss_cls: 0.0739  decode.d8.loss_mask: 0.2415  decode.d8.loss_dice: 0.2104
10/01 03:34:44 - mmengine - INFO - Iter(train) [151850/320000]  base_lr: 5.6039e-05 lr: 5.6039e-06  eta: 20:28:17  time: 0.4421  data_time: 0.0097  memory: 5129  grad_norm: 97.8121  loss: 7.5908  decode.loss_cls: 0.1757  decode.loss_mask: 0.2710  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.9733  decode.d0.loss_mask: 0.2782  decode.d0.loss_dice: 0.2047  decode.d1.loss_cls: 0.1719  decode.d1.loss_mask: 0.2747  decode.d1.loss_dice: 0.2226  decode.d2.loss_cls: 0.1643  decode.d2.loss_mask: 0.2638  decode.d2.loss_dice: 0.1983  decode.d3.loss_cls: 0.1824  decode.d3.loss_mask: 0.2704  decode.d3.loss_dice: 0.2080  decode.d4.loss_cls: 0.1983  decode.d4.loss_mask: 0.2979  decode.d4.loss_dice: 0.2254  decode.d5.loss_cls: 0.2237  decode.d5.loss_mask: 0.2744  decode.d5.loss_dice: 0.2088  decode.d6.loss_cls: 0.2054  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.2161  decode.d7.loss_cls: 0.1835  decode.d7.loss_mask: 0.2732  decode.d7.loss_dice: 0.2156  decode.d8.loss_cls: 0.2127  decode.d8.loss_mask: 0.2799  decode.d8.loss_dice: 0.2278
10/01 03:35:06 - mmengine - INFO - Iter(train) [151900/320000]  base_lr: 5.6024e-05 lr: 5.6024e-06  eta: 20:27:55  time: 0.4409  data_time: 0.0094  memory: 5145  grad_norm: 63.6685  loss: 5.2228  decode.loss_cls: 0.0964  decode.loss_mask: 0.1862  decode.loss_dice: 0.1816  decode.d0.loss_cls: 0.8018  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.1059  decode.d1.loss_mask: 0.1875  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.1858  decode.d2.loss_dice: 0.1902  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.1937  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.1866  decode.d5.loss_dice: 0.1879  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.1855  decode.d6.loss_dice: 0.1708  decode.d7.loss_cls: 0.0754  decode.d7.loss_mask: 0.1834  decode.d7.loss_dice: 0.1702  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.1852  decode.d8.loss_dice: 0.1930
10/01 03:35:28 - mmengine - INFO - Iter(train) [151950/320000]  base_lr: 5.6009e-05 lr: 5.6009e-06  eta: 20:27:33  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 134.7129  loss: 5.1528  decode.loss_cls: 0.0648  decode.loss_mask: 0.1860  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.7818  decode.d0.loss_mask: 0.1713  decode.d0.loss_dice: 0.1857  decode.d1.loss_cls: 0.0861  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.1941  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.1887  decode.d2.loss_dice: 0.1987  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.2007  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.1805  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.1823  decode.d5.loss_dice: 0.1836  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 0.1796  decode.d6.loss_dice: 0.1732  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.1856  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.1831  decode.d8.loss_dice: 0.1712
10/01 03:35:50 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:35:50 - mmengine - INFO - Iter(train) [152000/320000]  base_lr: 5.5994e-05 lr: 5.5994e-06  eta: 20:27:12  time: 0.4430  data_time: 0.0095  memory: 5129  grad_norm: 46.4944  loss: 5.7484  decode.loss_cls: 0.0610  decode.loss_mask: 0.2191  decode.loss_dice: 0.2148  decode.d0.loss_cls: 0.7611  decode.d0.loss_mask: 0.2208  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.0549  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.2326  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.2196  decode.d2.loss_dice: 0.2169  decode.d3.loss_cls: 0.1393  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.2181  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.2186  decode.d4.loss_dice: 0.2294  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 0.2224  decode.d5.loss_dice: 0.2254  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.2199  decode.d6.loss_dice: 0.2140  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.2202  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 0.2221  decode.d8.loss_dice: 0.2274
10/01 03:36:12 - mmengine - INFO - Iter(train) [152050/320000]  base_lr: 5.5979e-05 lr: 5.5979e-06  eta: 20:26:50  time: 0.4402  data_time: 0.0094  memory: 5129  grad_norm: 43.2541  loss: 4.6401  decode.loss_cls: 0.0362  decode.loss_mask: 0.1654  decode.loss_dice: 0.1750  decode.d0.loss_cls: 0.7519  decode.d0.loss_mask: 0.1672  decode.d0.loss_dice: 0.1817  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.1668  decode.d1.loss_dice: 0.1827  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.1641  decode.d2.loss_dice: 0.1495  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.1657  decode.d3.loss_dice: 0.1924  decode.d4.loss_cls: 0.0516  decode.d4.loss_mask: 0.1664  decode.d4.loss_dice: 0.1666  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.1696  decode.d5.loss_dice: 0.1807  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.1675  decode.d6.loss_dice: 0.1840  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.1677  decode.d7.loss_dice: 0.1781  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.1684  decode.d8.loss_dice: 0.1838
10/01 03:36:34 - mmengine - INFO - Iter(train) [152100/320000]  base_lr: 5.5964e-05 lr: 5.5964e-06  eta: 20:26:28  time: 0.4437  data_time: 0.0097  memory: 5129  grad_norm: 41.6850  loss: 4.9881  decode.loss_cls: 0.0088  decode.loss_mask: 0.2386  decode.loss_dice: 0.1746  decode.d0.loss_cls: 0.7553  decode.d0.loss_mask: 0.2339  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.1745  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.1723  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.2382  decode.d3.loss_dice: 0.1780  decode.d4.loss_cls: 0.0123  decode.d4.loss_mask: 0.2398  decode.d4.loss_dice: 0.1743  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.1714  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.1822  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.2370  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.2405  decode.d8.loss_dice: 0.1770
10/01 03:36:56 - mmengine - INFO - Iter(train) [152150/320000]  base_lr: 5.5949e-05 lr: 5.5949e-06  eta: 20:26:06  time: 0.4415  data_time: 0.0094  memory: 5145  grad_norm: 21.6041  loss: 4.2362  decode.loss_cls: 0.0011  decode.loss_mask: 0.1893  decode.loss_dice: 0.1726  decode.d0.loss_cls: 0.6903  decode.d0.loss_mask: 0.1871  decode.d0.loss_dice: 0.1613  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.1607  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.1909  decode.d2.loss_dice: 0.1564  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.1915  decode.d3.loss_dice: 0.1665  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.1893  decode.d4.loss_dice: 0.1609  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.1902  decode.d5.loss_dice: 0.1592  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.1893  decode.d6.loss_dice: 0.1670  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.1894  decode.d7.loss_dice: 0.1607  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.1891  decode.d8.loss_dice: 0.1716
10/01 03:37:18 - mmengine - INFO - Iter(train) [152200/320000]  base_lr: 5.5934e-05 lr: 5.5934e-06  eta: 20:25:45  time: 0.4433  data_time: 0.0095  memory: 5145  grad_norm: 63.2901  loss: 6.3021  decode.loss_cls: 0.0832  decode.loss_mask: 0.2621  decode.loss_dice: 0.2272  decode.d0.loss_cls: 0.6898  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.2096  decode.d1.loss_cls: 0.0957  decode.d1.loss_mask: 0.2653  decode.d1.loss_dice: 0.2120  decode.d2.loss_cls: 0.0852  decode.d2.loss_mask: 0.2670  decode.d2.loss_dice: 0.2160  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.2708  decode.d3.loss_dice: 0.2280  decode.d4.loss_cls: 0.0851  decode.d4.loss_mask: 0.2681  decode.d4.loss_dice: 0.2268  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.2642  decode.d5.loss_dice: 0.2235  decode.d6.loss_cls: 0.0810  decode.d6.loss_mask: 0.2607  decode.d6.loss_dice: 0.2190  decode.d7.loss_cls: 0.0912  decode.d7.loss_mask: 0.2667  decode.d7.loss_dice: 0.2182  decode.d8.loss_cls: 0.0739  decode.d8.loss_mask: 0.2678  decode.d8.loss_dice: 0.2111
10/01 03:37:40 - mmengine - INFO - Iter(train) [152250/320000]  base_lr: 5.5919e-05 lr: 5.5919e-06  eta: 20:25:23  time: 0.4410  data_time: 0.0094  memory: 5145  grad_norm: 38.0153  loss: 4.8955  decode.loss_cls: 0.0544  decode.loss_mask: 0.1772  decode.loss_dice: 0.1657  decode.d0.loss_cls: 0.8847  decode.d0.loss_mask: 0.1790  decode.d0.loss_dice: 0.1556  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.1810  decode.d1.loss_dice: 0.1623  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.1789  decode.d2.loss_dice: 0.1614  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.1775  decode.d3.loss_dice: 0.1664  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.1810  decode.d4.loss_dice: 0.1630  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.1796  decode.d5.loss_dice: 0.1559  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.1768  decode.d6.loss_dice: 0.1608  decode.d7.loss_cls: 0.1057  decode.d7.loss_mask: 0.1777  decode.d7.loss_dice: 0.1642  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.1780  decode.d8.loss_dice: 0.1608
10/01 03:38:02 - mmengine - INFO - Iter(train) [152300/320000]  base_lr: 5.5904e-05 lr: 5.5904e-06  eta: 20:25:01  time: 0.4436  data_time: 0.0098  memory: 5129  grad_norm: 109.4447  loss: 7.9775  decode.loss_cls: 0.2630  decode.loss_mask: 0.2227  decode.loss_dice: 0.2258  decode.d0.loss_cls: 1.2053  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.2324  decode.d1.loss_cls: 0.3305  decode.d1.loss_mask: 0.2551  decode.d1.loss_dice: 0.2407  decode.d2.loss_cls: 0.3055  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.2082  decode.d3.loss_cls: 0.2329  decode.d3.loss_mask: 0.2412  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.2468  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2332  decode.d5.loss_cls: 0.2463  decode.d5.loss_mask: 0.2034  decode.d5.loss_dice: 0.2092  decode.d6.loss_cls: 0.2576  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.2141  decode.d7.loss_cls: 0.2235  decode.d7.loss_mask: 0.2066  decode.d7.loss_dice: 0.2072  decode.d8.loss_cls: 0.2326  decode.d8.loss_mask: 0.2157  decode.d8.loss_dice: 0.2109
10/01 03:38:25 - mmengine - INFO - Iter(train) [152350/320000]  base_lr: 5.5889e-05 lr: 5.5889e-06  eta: 20:24:39  time: 0.4404  data_time: 0.0093  memory: 5120  grad_norm: 83.0876  loss: 4.8353  decode.loss_cls: 0.0120  decode.loss_mask: 0.1910  decode.loss_dice: 0.1868  decode.d0.loss_cls: 0.8731  decode.d0.loss_mask: 0.1851  decode.d0.loss_dice: 0.1782  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.1990  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.1934  decode.d2.loss_dice: 0.2003  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1925  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.1931  decode.d4.loss_dice: 0.1914  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.1923  decode.d5.loss_dice: 0.2079  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.1938  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.1963  decode.d7.loss_dice: 0.1986  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.1984  decode.d8.loss_dice: 0.1980
10/01 03:38:47 - mmengine - INFO - Iter(train) [152400/320000]  base_lr: 5.5874e-05 lr: 5.5874e-06  eta: 20:24:18  time: 0.4399  data_time: 0.0096  memory: 5130  grad_norm: 55.4018  loss: 5.8452  decode.loss_cls: 0.0869  decode.loss_mask: 0.1912  decode.loss_dice: 0.2408  decode.d0.loss_cls: 0.7585  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.2341  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.1927  decode.d1.loss_dice: 0.2159  decode.d2.loss_cls: 0.0831  decode.d2.loss_mask: 0.1937  decode.d2.loss_dice: 0.1766  decode.d3.loss_cls: 0.1562  decode.d3.loss_mask: 0.1936  decode.d3.loss_dice: 0.2135  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.1926  decode.d4.loss_dice: 0.1827  decode.d5.loss_cls: 0.1210  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.2501  decode.d6.loss_cls: 0.1367  decode.d6.loss_mask: 0.1947  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.2199  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.1941  decode.d8.loss_dice: 0.1953
10/01 03:39:09 - mmengine - INFO - Iter(train) [152450/320000]  base_lr: 5.5859e-05 lr: 5.5859e-06  eta: 20:23:56  time: 0.4404  data_time: 0.0095  memory: 5129  grad_norm: 46.5265  loss: 6.1662  decode.loss_cls: 0.0624  decode.loss_mask: 0.2067  decode.loss_dice: 0.2329  decode.d0.loss_cls: 0.8051  decode.d0.loss_mask: 0.2090  decode.d0.loss_dice: 0.2403  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.2522  decode.d2.loss_cls: 0.1277  decode.d2.loss_mask: 0.2078  decode.d2.loss_dice: 0.2390  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.2069  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.2041  decode.d4.loss_dice: 0.2387  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.2069  decode.d5.loss_dice: 0.2301  decode.d6.loss_cls: 0.0913  decode.d6.loss_mask: 0.2067  decode.d6.loss_dice: 0.2408  decode.d7.loss_cls: 0.1206  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.2424  decode.d8.loss_cls: 0.1351  decode.d8.loss_mask: 0.2064  decode.d8.loss_dice: 0.2503
10/01 03:39:31 - mmengine - INFO - Iter(train) [152500/320000]  base_lr: 5.5844e-05 lr: 5.5844e-06  eta: 20:23:34  time: 0.4406  data_time: 0.0098  memory: 5145  grad_norm: 63.5125  loss: 5.7636  decode.loss_cls: 0.0823  decode.loss_mask: 0.1920  decode.loss_dice: 0.2263  decode.d0.loss_cls: 0.9084  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.1934  decode.d1.loss_cls: 0.1608  decode.d1.loss_mask: 0.1963  decode.d1.loss_dice: 0.2196  decode.d2.loss_cls: 0.0982  decode.d2.loss_mask: 0.1923  decode.d2.loss_dice: 0.2136  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.1985  decode.d3.loss_dice: 0.2139  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.1926  decode.d4.loss_dice: 0.2223  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.1950  decode.d5.loss_dice: 0.2202  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.1903  decode.d6.loss_dice: 0.2068  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.2006  decode.d7.loss_dice: 0.2394  decode.d8.loss_cls: 0.0426  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.2405
10/01 03:39:53 - mmengine - INFO - Iter(train) [152550/320000]  base_lr: 5.5829e-05 lr: 5.5829e-06  eta: 20:23:12  time: 0.4399  data_time: 0.0093  memory: 5129  grad_norm: 16.3300  loss: 3.7077  decode.loss_cls: 0.0054  decode.loss_mask: 0.1544  decode.loss_dice: 0.1307  decode.d0.loss_cls: 0.8044  decode.d0.loss_mask: 0.1577  decode.d0.loss_dice: 0.1295  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.1558  decode.d1.loss_dice: 0.1293  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.1540  decode.d2.loss_dice: 0.1288  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.1572  decode.d3.loss_dice: 0.1299  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.1553  decode.d4.loss_dice: 0.1298  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.1558  decode.d5.loss_dice: 0.1298  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.1546  decode.d6.loss_dice: 0.1309  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1558  decode.d7.loss_dice: 0.1302  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.1569  decode.d8.loss_dice: 0.1311
10/01 03:40:15 - mmengine - INFO - Iter(train) [152600/320000]  base_lr: 5.5814e-05 lr: 5.5814e-06  eta: 20:22:50  time: 0.4409  data_time: 0.0095  memory: 5145  grad_norm: 25.6496  loss: 3.8833  decode.loss_cls: 0.0073  decode.loss_mask: 0.1697  decode.loss_dice: 0.1447  decode.d0.loss_cls: 0.6889  decode.d0.loss_mask: 0.1704  decode.d0.loss_dice: 0.1414  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.1703  decode.d1.loss_dice: 0.1472  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.1674  decode.d2.loss_dice: 0.1477  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.1711  decode.d3.loss_dice: 0.1475  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.1689  decode.d4.loss_dice: 0.1463  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.1693  decode.d5.loss_dice: 0.1452  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.1693  decode.d6.loss_dice: 0.1426  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.1714  decode.d7.loss_dice: 0.1423  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.1692  decode.d8.loss_dice: 0.1429
10/01 03:40:37 - mmengine - INFO - Iter(train) [152650/320000]  base_lr: 5.5799e-05 lr: 5.5799e-06  eta: 20:22:29  time: 0.4403  data_time: 0.0097  memory: 5145  grad_norm: 43.6264  loss: 5.7550  decode.loss_cls: 0.0685  decode.loss_mask: 0.2346  decode.loss_dice: 0.1968  decode.d0.loss_cls: 0.8507  decode.d0.loss_mask: 0.2384  decode.d0.loss_dice: 0.1928  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.2330  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.2137  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.1925  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.2344  decode.d4.loss_dice: 0.1921  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.2331  decode.d5.loss_dice: 0.1939  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.2331  decode.d6.loss_dice: 0.1968  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.2332  decode.d7.loss_dice: 0.1907  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.2346  decode.d8.loss_dice: 0.1972
10/01 03:40:59 - mmengine - INFO - Iter(train) [152700/320000]  base_lr: 5.5784e-05 lr: 5.5784e-06  eta: 20:22:07  time: 0.4408  data_time: 0.0095  memory: 5129  grad_norm: 30.9670  loss: 5.0952  decode.loss_cls: 0.1581  decode.loss_mask: 0.1601  decode.loss_dice: 0.1216  decode.d0.loss_cls: 0.9426  decode.d0.loss_mask: 0.1746  decode.d0.loss_dice: 0.1239  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 0.1657  decode.d1.loss_dice: 0.1182  decode.d2.loss_cls: 0.1388  decode.d2.loss_mask: 0.1577  decode.d2.loss_dice: 0.1213  decode.d3.loss_cls: 0.1539  decode.d3.loss_mask: 0.1708  decode.d3.loss_dice: 0.1311  decode.d4.loss_cls: 0.1304  decode.d4.loss_mask: 0.1713  decode.d4.loss_dice: 0.1161  decode.d5.loss_cls: 0.1378  decode.d5.loss_mask: 0.1689  decode.d5.loss_dice: 0.1262  decode.d6.loss_cls: 0.1365  decode.d6.loss_mask: 0.1627  decode.d6.loss_dice: 0.1183  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 0.1626  decode.d7.loss_dice: 0.1154  decode.d8.loss_cls: 0.1368  decode.d8.loss_mask: 0.1765  decode.d8.loss_dice: 0.1344
10/01 03:41:21 - mmengine - INFO - Iter(train) [152750/320000]  base_lr: 5.5769e-05 lr: 5.5769e-06  eta: 20:21:45  time: 0.4408  data_time: 0.0096  memory: 5129  grad_norm: 50.1874  loss: 5.3837  decode.loss_cls: 0.0067  decode.loss_mask: 0.2767  decode.loss_dice: 0.1695  decode.d0.loss_cls: 0.8500  decode.d0.loss_mask: 0.2830  decode.d0.loss_dice: 0.1660  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.2799  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.2778  decode.d2.loss_dice: 0.1664  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.1677  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2797  decode.d4.loss_dice: 0.1708  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.2787  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.2799  decode.d6.loss_dice: 0.1696  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.2764  decode.d7.loss_dice: 0.1684  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2747  decode.d8.loss_dice: 0.1688
10/01 03:41:43 - mmengine - INFO - Iter(train) [152800/320000]  base_lr: 5.5754e-05 lr: 5.5754e-06  eta: 20:21:23  time: 0.4405  data_time: 0.0095  memory: 5120  grad_norm: 81.5063  loss: 5.1715  decode.loss_cls: 0.1092  decode.loss_mask: 0.1814  decode.loss_dice: 0.1617  decode.d0.loss_cls: 0.8070  decode.d0.loss_mask: 0.1878  decode.d0.loss_dice: 0.1593  decode.d1.loss_cls: 0.1008  decode.d1.loss_mask: 0.1860  decode.d1.loss_dice: 0.1707  decode.d2.loss_cls: 0.0880  decode.d2.loss_mask: 0.1817  decode.d2.loss_dice: 0.1595  decode.d3.loss_cls: 0.0956  decode.d3.loss_mask: 0.1821  decode.d3.loss_dice: 0.1689  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 0.1804  decode.d4.loss_dice: 0.1717  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.1807  decode.d5.loss_dice: 0.1509  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 0.1808  decode.d6.loss_dice: 0.1548  decode.d7.loss_cls: 0.1148  decode.d7.loss_mask: 0.1796  decode.d7.loss_dice: 0.1535  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.1821  decode.d8.loss_dice: 0.1636
10/01 03:42:05 - mmengine - INFO - Iter(train) [152850/320000]  base_lr: 5.5739e-05 lr: 5.5739e-06  eta: 20:21:02  time: 0.4404  data_time: 0.0094  memory: 5129  grad_norm: 82.9693  loss: 6.0125  decode.loss_cls: 0.0762  decode.loss_mask: 0.2252  decode.loss_dice: 0.2120  decode.d0.loss_cls: 0.8617  decode.d0.loss_mask: 0.2348  decode.d0.loss_dice: 0.1965  decode.d1.loss_cls: 0.1021  decode.d1.loss_mask: 0.2300  decode.d1.loss_dice: 0.2171  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.2305  decode.d2.loss_dice: 0.2206  decode.d3.loss_cls: 0.1180  decode.d3.loss_mask: 0.2279  decode.d3.loss_dice: 0.2173  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.2201  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.2264  decode.d5.loss_dice: 0.2141  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2067  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.2205  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.2281  decode.d8.loss_dice: 0.2139
10/01 03:42:27 - mmengine - INFO - Iter(train) [152900/320000]  base_lr: 5.5724e-05 lr: 5.5724e-06  eta: 20:20:40  time: 0.4402  data_time: 0.0096  memory: 5145  grad_norm: 85.8879  loss: 5.0331  decode.loss_cls: 0.0496  decode.loss_mask: 0.1765  decode.loss_dice: 0.1474  decode.d0.loss_cls: 0.8459  decode.d0.loss_mask: 0.1768  decode.d0.loss_dice: 0.1730  decode.d1.loss_cls: 0.0985  decode.d1.loss_mask: 0.1795  decode.d1.loss_dice: 0.1886  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.1786  decode.d2.loss_dice: 0.1947  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.1775  decode.d3.loss_dice: 0.1974  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.1757  decode.d4.loss_dice: 0.1986  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.1773  decode.d5.loss_dice: 0.1840  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.1789  decode.d6.loss_dice: 0.1740  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.1700  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.1783  decode.d8.loss_dice: 0.1799
10/01 03:42:49 - mmengine - INFO - Iter(train) [152950/320000]  base_lr: 5.5709e-05 lr: 5.5709e-06  eta: 20:20:18  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 36.1783  loss: 5.0660  decode.loss_cls: 0.0624  decode.loss_mask: 0.1773  decode.loss_dice: 0.1755  decode.d0.loss_cls: 0.9172  decode.d0.loss_mask: 0.2336  decode.d0.loss_dice: 0.1924  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.1730  decode.d1.loss_dice: 0.1813  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.1748  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.0539  decode.d3.loss_mask: 0.1766  decode.d3.loss_dice: 0.1813  decode.d4.loss_cls: 0.0405  decode.d4.loss_mask: 0.1751  decode.d4.loss_dice: 0.1881  decode.d5.loss_cls: 0.0931  decode.d5.loss_mask: 0.1758  decode.d5.loss_dice: 0.1705  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.1760  decode.d6.loss_dice: 0.1724  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.1775  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.1774  decode.d8.loss_dice: 0.1787
10/01 03:43:11 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:43:11 - mmengine - INFO - Iter(train) [153000/320000]  base_lr: 5.5694e-05 lr: 5.5694e-06  eta: 20:19:56  time: 0.4422  data_time: 0.0098  memory: 5129  grad_norm: 64.7596  loss: 6.5263  decode.loss_cls: 0.0648  decode.loss_mask: 0.2408  decode.loss_dice: 0.2012  decode.d0.loss_cls: 0.9977  decode.d0.loss_mask: 0.2459  decode.d0.loss_dice: 0.1850  decode.d1.loss_cls: 0.1658  decode.d1.loss_mask: 0.2366  decode.d1.loss_dice: 0.2396  decode.d2.loss_cls: 0.1232  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0967  decode.d3.loss_mask: 0.2403  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.1199  decode.d4.loss_mask: 0.2328  decode.d4.loss_dice: 0.2282  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.1081  decode.d6.loss_mask: 0.2373  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 0.2381  decode.d7.loss_dice: 0.2074  decode.d8.loss_cls: 0.1105  decode.d8.loss_mask: 0.2394  decode.d8.loss_dice: 0.1725
10/01 03:43:34 - mmengine - INFO - Iter(train) [153050/320000]  base_lr: 5.5679e-05 lr: 5.5679e-06  eta: 20:19:35  time: 0.4402  data_time: 0.0096  memory: 5130  grad_norm: 83.3653  loss: 7.8734  decode.loss_cls: 0.1796  decode.loss_mask: 0.3809  decode.loss_dice: 0.2525  decode.d0.loss_cls: 1.0136  decode.d0.loss_mask: 0.2529  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.2601  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.2260  decode.d2.loss_cls: 0.2233  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.2503  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2304  decode.d4.loss_cls: 0.2125  decode.d4.loss_mask: 0.2475  decode.d4.loss_dice: 0.2342  decode.d5.loss_cls: 0.1983  decode.d5.loss_mask: 0.2465  decode.d5.loss_dice: 0.2448  decode.d6.loss_cls: 0.2081  decode.d6.loss_mask: 0.2469  decode.d6.loss_dice: 0.2107  decode.d7.loss_cls: 0.2013  decode.d7.loss_mask: 0.2460  decode.d7.loss_dice: 0.2321  decode.d8.loss_cls: 0.1958  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.2493
10/01 03:43:56 - mmengine - INFO - Iter(train) [153100/320000]  base_lr: 5.5664e-05 lr: 5.5664e-06  eta: 20:19:13  time: 0.4402  data_time: 0.0095  memory: 5145  grad_norm: 34.7587  loss: 5.2000  decode.loss_cls: 0.0481  decode.loss_mask: 0.2021  decode.loss_dice: 0.1861  decode.d0.loss_cls: 0.9205  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.1786  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.1993  decode.d1.loss_dice: 0.2009  decode.d2.loss_cls: 0.0551  decode.d2.loss_mask: 0.2002  decode.d2.loss_dice: 0.1849  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.2010  decode.d3.loss_dice: 0.1861  decode.d4.loss_cls: 0.0275  decode.d4.loss_mask: 0.1992  decode.d4.loss_dice: 0.1928  decode.d5.loss_cls: 0.0902  decode.d5.loss_mask: 0.2008  decode.d5.loss_dice: 0.1768  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.1847  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.1991  decode.d7.loss_dice: 0.1812  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.1994  decode.d8.loss_dice: 0.1800
10/01 03:44:18 - mmengine - INFO - Iter(train) [153150/320000]  base_lr: 5.5649e-05 lr: 5.5649e-06  eta: 20:18:51  time: 0.4405  data_time: 0.0095  memory: 5129  grad_norm: 24.7561  loss: 3.9858  decode.loss_cls: 0.0014  decode.loss_mask: 0.1929  decode.loss_dice: 0.1313  decode.d0.loss_cls: 0.6944  decode.d0.loss_mask: 0.1946  decode.d0.loss_dice: 0.1293  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.1938  decode.d1.loss_dice: 0.1320  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.1956  decode.d2.loss_dice: 0.1327  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.1964  decode.d3.loss_dice: 0.1359  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1938  decode.d4.loss_dice: 0.1312  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.1953  decode.d5.loss_dice: 0.1341  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1947  decode.d6.loss_dice: 0.1332  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1939  decode.d7.loss_dice: 0.1344  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.1918  decode.d8.loss_dice: 0.1397
10/01 03:44:40 - mmengine - INFO - Iter(train) [153200/320000]  base_lr: 5.5634e-05 lr: 5.5634e-06  eta: 20:18:29  time: 0.4409  data_time: 0.0097  memory: 5129  grad_norm: 84.9204  loss: 5.6624  decode.loss_cls: 0.0563  decode.loss_mask: 0.2048  decode.loss_dice: 0.2042  decode.d0.loss_cls: 0.9221  decode.d0.loss_mask: 0.2067  decode.d0.loss_dice: 0.2009  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.2041  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 0.2011  decode.d2.loss_dice: 0.1997  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.2020  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.2042  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.2015  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.2056  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.1136  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.2071  decode.d8.loss_cls: 0.1085  decode.d8.loss_mask: 0.2041  decode.d8.loss_dice: 0.2096
10/01 03:45:02 - mmengine - INFO - Iter(train) [153250/320000]  base_lr: 5.5619e-05 lr: 5.5619e-06  eta: 20:18:08  time: 0.4413  data_time: 0.0094  memory: 5119  grad_norm: 51.7658  loss: 3.9257  decode.loss_cls: 0.0041  decode.loss_mask: 0.1453  decode.loss_dice: 0.1527  decode.d0.loss_cls: 0.9012  decode.d0.loss_mask: 0.1444  decode.d0.loss_dice: 0.1371  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.1461  decode.d1.loss_dice: 0.1616  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.1461  decode.d2.loss_dice: 0.1604  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.1444  decode.d3.loss_dice: 0.1492  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.1450  decode.d4.loss_dice: 0.1553  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.1451  decode.d5.loss_dice: 0.1526  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.1454  decode.d6.loss_dice: 0.1504  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1461  decode.d7.loss_dice: 0.1570  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.1462  decode.d8.loss_dice: 0.1552
10/01 03:45:24 - mmengine - INFO - Iter(train) [153300/320000]  base_lr: 5.5604e-05 lr: 5.5604e-06  eta: 20:17:46  time: 0.4420  data_time: 0.0095  memory: 5129  grad_norm: 44.9482  loss: 5.3812  decode.loss_cls: 0.0713  decode.loss_mask: 0.1960  decode.loss_dice: 0.2217  decode.d0.loss_cls: 0.8686  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.1977  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.1939  decode.d2.loss_dice: 0.1980  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.2296  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.1944  decode.d4.loss_dice: 0.2196  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.1974  decode.d5.loss_dice: 0.2024  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.2298  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.1940  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.1948  decode.d8.loss_dice: 0.2061
10/01 03:45:46 - mmengine - INFO - Iter(train) [153350/320000]  base_lr: 5.5589e-05 lr: 5.5589e-06  eta: 20:17:24  time: 0.4410  data_time: 0.0095  memory: 5120  grad_norm: 344.0244  loss: 6.0776  decode.loss_cls: 0.1091  decode.loss_mask: 0.2434  decode.loss_dice: 0.2043  decode.d0.loss_cls: 0.6763  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.2028  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 0.2425  decode.d1.loss_dice: 0.2024  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.2476  decode.d2.loss_dice: 0.2084  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.2430  decode.d3.loss_dice: 0.2031  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.2439  decode.d4.loss_dice: 0.2014  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.2020  decode.d6.loss_cls: 0.0997  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2031  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 0.2416  decode.d7.loss_dice: 0.2070  decode.d8.loss_cls: 0.1104  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2039
10/01 03:46:08 - mmengine - INFO - Iter(train) [153400/320000]  base_lr: 5.5574e-05 lr: 5.5574e-06  eta: 20:17:02  time: 0.4409  data_time: 0.0095  memory: 5145  grad_norm: 26.6627  loss: 4.2191  decode.loss_cls: 0.0068  decode.loss_mask: 0.1867  decode.loss_dice: 0.1360  decode.d0.loss_cls: 0.9258  decode.d0.loss_mask: 0.1852  decode.d0.loss_dice: 0.1374  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.1856  decode.d1.loss_dice: 0.1390  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.1842  decode.d2.loss_dice: 0.1367  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.1851  decode.d3.loss_dice: 0.1352  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.1350  decode.d5.loss_cls: 0.0099  decode.d5.loss_mask: 0.1858  decode.d5.loss_dice: 0.1381  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.1839  decode.d6.loss_dice: 0.1365  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.1853  decode.d7.loss_dice: 0.1361  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.1846  decode.d8.loss_dice: 0.1381
10/01 03:46:30 - mmengine - INFO - Iter(train) [153450/320000]  base_lr: 5.5559e-05 lr: 5.5559e-06  eta: 20:16:41  time: 0.4413  data_time: 0.0096  memory: 5129  grad_norm: 72.9330  loss: 6.8669  decode.loss_cls: 0.1660  decode.loss_mask: 0.2393  decode.loss_dice: 0.1861  decode.d0.loss_cls: 0.9781  decode.d0.loss_mask: 0.2634  decode.d0.loss_dice: 0.2050  decode.d1.loss_cls: 0.1632  decode.d1.loss_mask: 0.2347  decode.d1.loss_dice: 0.1774  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 0.2589  decode.d2.loss_dice: 0.1829  decode.d3.loss_cls: 0.1698  decode.d3.loss_mask: 0.2710  decode.d3.loss_dice: 0.1950  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.2637  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.1512  decode.d5.loss_mask: 0.2556  decode.d5.loss_dice: 0.1907  decode.d6.loss_cls: 0.1785  decode.d6.loss_mask: 0.2446  decode.d6.loss_dice: 0.1905  decode.d7.loss_cls: 0.1545  decode.d7.loss_mask: 0.2328  decode.d7.loss_dice: 0.2148  decode.d8.loss_cls: 0.1600  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.1716
10/01 03:46:52 - mmengine - INFO - Iter(train) [153500/320000]  base_lr: 5.5544e-05 lr: 5.5544e-06  eta: 20:16:19  time: 0.4401  data_time: 0.0093  memory: 5145  grad_norm: 34.8991  loss: 4.2897  decode.loss_cls: 0.0033  decode.loss_mask: 0.2022  decode.loss_dice: 0.1548  decode.d0.loss_cls: 0.6716  decode.d0.loss_mask: 0.2047  decode.d0.loss_dice: 0.1512  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.2053  decode.d1.loss_dice: 0.1561  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2049  decode.d2.loss_dice: 0.1557  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2060  decode.d3.loss_dice: 0.1540  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.2064  decode.d4.loss_dice: 0.1536  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.2040  decode.d5.loss_dice: 0.1545  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2024  decode.d6.loss_dice: 0.1540  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.1527  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.2059  decode.d8.loss_dice: 0.1604
10/01 03:47:14 - mmengine - INFO - Iter(train) [153550/320000]  base_lr: 5.5529e-05 lr: 5.5529e-06  eta: 20:15:57  time: 0.4412  data_time: 0.0097  memory: 5129  grad_norm: 45.3098  loss: 5.4304  decode.loss_cls: 0.0767  decode.loss_mask: 0.2036  decode.loss_dice: 0.1960  decode.d0.loss_cls: 0.7580  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.2015  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.2057  decode.d1.loss_dice: 0.1886  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.2056  decode.d2.loss_dice: 0.1950  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.2044  decode.d3.loss_dice: 0.1957  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.2020  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.2050  decode.d5.loss_dice: 0.1960  decode.d6.loss_cls: 0.0726  decode.d6.loss_mask: 0.2060  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.1964  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.2043  decode.d8.loss_dice: 0.1944
10/01 03:47:36 - mmengine - INFO - Iter(train) [153600/320000]  base_lr: 5.5514e-05 lr: 5.5514e-06  eta: 20:15:35  time: 0.4419  data_time: 0.0099  memory: 5129  grad_norm: 57.6914  loss: 4.7057  decode.loss_cls: 0.0530  decode.loss_mask: 0.1865  decode.loss_dice: 0.1636  decode.d0.loss_cls: 0.8749  decode.d0.loss_mask: 0.1942  decode.d0.loss_dice: 0.1512  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.1867  decode.d1.loss_dice: 0.1590  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.1869  decode.d2.loss_dice: 0.1587  decode.d3.loss_cls: 0.0328  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.1547  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.1869  decode.d4.loss_dice: 0.1567  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.1854  decode.d5.loss_dice: 0.1537  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.1908  decode.d6.loss_dice: 0.1593  decode.d7.loss_cls: 0.0367  decode.d7.loss_mask: 0.1857  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.1889  decode.d8.loss_dice: 0.1625
10/01 03:47:58 - mmengine - INFO - Iter(train) [153650/320000]  base_lr: 5.5499e-05 lr: 5.5499e-06  eta: 20:15:14  time: 0.4427  data_time: 0.0096  memory: 5129  grad_norm: 98.6602  loss: 5.8283  decode.loss_cls: 0.0952  decode.loss_mask: 0.2179  decode.loss_dice: 0.1682  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.2194  decode.d0.loss_dice: 0.1618  decode.d1.loss_cls: 0.1193  decode.d1.loss_mask: 0.2158  decode.d1.loss_dice: 0.1676  decode.d2.loss_cls: 0.1104  decode.d2.loss_mask: 0.2177  decode.d2.loss_dice: 0.1706  decode.d3.loss_cls: 0.1277  decode.d3.loss_mask: 0.2162  decode.d3.loss_dice: 0.1708  decode.d4.loss_cls: 0.1194  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.1695  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.1674  decode.d6.loss_cls: 0.1302  decode.d6.loss_mask: 0.2181  decode.d6.loss_dice: 0.1728  decode.d7.loss_cls: 0.1367  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.1728  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.1765
10/01 03:48:21 - mmengine - INFO - Iter(train) [153700/320000]  base_lr: 5.5484e-05 lr: 5.5484e-06  eta: 20:14:52  time: 0.4417  data_time: 0.0097  memory: 5129  grad_norm: 41.1279  loss: 4.4539  decode.loss_cls: 0.0259  decode.loss_mask: 0.1571  decode.loss_dice: 0.1860  decode.d0.loss_cls: 0.9018  decode.d0.loss_mask: 0.1590  decode.d0.loss_dice: 0.1506  decode.d1.loss_cls: 0.0233  decode.d1.loss_mask: 0.1577  decode.d1.loss_dice: 0.1826  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.1569  decode.d2.loss_dice: 0.1556  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.1585  decode.d3.loss_dice: 0.1788  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.1572  decode.d4.loss_dice: 0.1811  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.1561  decode.d5.loss_dice: 0.1799  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.1567  decode.d6.loss_dice: 0.1585  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.1570  decode.d7.loss_dice: 0.1896  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.1566  decode.d8.loss_dice: 0.1583
10/01 03:48:43 - mmengine - INFO - Iter(train) [153750/320000]  base_lr: 5.5469e-05 lr: 5.5469e-06  eta: 20:14:30  time: 0.4432  data_time: 0.0096  memory: 5129  grad_norm: 43.9813  loss: 4.7094  decode.loss_cls: 0.0585  decode.loss_mask: 0.1651  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.1684  decode.d0.loss_dice: 0.1560  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.1682  decode.d1.loss_dice: 0.1657  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.1668  decode.d2.loss_dice: 0.1597  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.1661  decode.d3.loss_dice: 0.1673  decode.d4.loss_cls: 0.0627  decode.d4.loss_mask: 0.1644  decode.d4.loss_dice: 0.1660  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.1637  decode.d5.loss_dice: 0.1613  decode.d6.loss_cls: 0.0757  decode.d6.loss_mask: 0.1643  decode.d6.loss_dice: 0.1628  decode.d7.loss_cls: 0.0253  decode.d7.loss_mask: 0.1648  decode.d7.loss_dice: 0.1777  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.1649  decode.d8.loss_dice: 0.1578
10/01 03:49:05 - mmengine - INFO - Iter(train) [153800/320000]  base_lr: 5.5454e-05 lr: 5.5454e-06  eta: 20:14:08  time: 0.4412  data_time: 0.0096  memory: 5129  grad_norm: 31.0112  loss: 4.2954  decode.loss_cls: 0.0061  decode.loss_mask: 0.1898  decode.loss_dice: 0.1486  decode.d0.loss_cls: 0.8154  decode.d0.loss_mask: 0.1954  decode.d0.loss_dice: 0.1443  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.1920  decode.d1.loss_dice: 0.1505  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.1894  decode.d2.loss_dice: 0.1454  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.1905  decode.d3.loss_dice: 0.1519  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.1932  decode.d4.loss_dice: 0.1506  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.1888  decode.d5.loss_dice: 0.1504  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.1869  decode.d6.loss_dice: 0.1502  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.1463  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.1886  decode.d8.loss_dice: 0.1475
10/01 03:49:27 - mmengine - INFO - Iter(train) [153850/320000]  base_lr: 5.5439e-05 lr: 5.5439e-06  eta: 20:13:47  time: 0.4441  data_time: 0.0098  memory: 5145  grad_norm: 38.3571  loss: 5.8458  decode.loss_cls: 0.0289  decode.loss_mask: 0.2625  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.7760  decode.d0.loss_mask: 0.2705  decode.d0.loss_dice: 0.2064  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.2622  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.2616  decode.d2.loss_dice: 0.2069  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.2616  decode.d3.loss_dice: 0.2163  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.2664  decode.d4.loss_dice: 0.2215  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.2019  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.2623  decode.d6.loss_dice: 0.2073  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.2116
10/01 03:49:49 - mmengine - INFO - Iter(train) [153900/320000]  base_lr: 5.5424e-05 lr: 5.5424e-06  eta: 20:13:25  time: 0.4407  data_time: 0.0093  memory: 5129  grad_norm: 89.8861  loss: 5.8702  decode.loss_cls: 0.0993  decode.loss_mask: 0.1917  decode.loss_dice: 0.1538  decode.d0.loss_cls: 0.9517  decode.d0.loss_mask: 0.2340  decode.d0.loss_dice: 0.1715  decode.d1.loss_cls: 0.1301  decode.d1.loss_mask: 0.2241  decode.d1.loss_dice: 0.1767  decode.d2.loss_cls: 0.1228  decode.d2.loss_mask: 0.2308  decode.d2.loss_dice: 0.1677  decode.d3.loss_cls: 0.1231  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.1692  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.2223  decode.d4.loss_dice: 0.1657  decode.d5.loss_cls: 0.1082  decode.d5.loss_mask: 0.2275  decode.d5.loss_dice: 0.1686  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.2295  decode.d6.loss_dice: 0.1741  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.2261  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0935  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.1661
10/01 03:50:11 - mmengine - INFO - Iter(train) [153950/320000]  base_lr: 5.5409e-05 lr: 5.5409e-06  eta: 20:13:03  time: 0.4400  data_time: 0.0093  memory: 5129  grad_norm: 42.2122  loss: 5.4897  decode.loss_cls: 0.0479  decode.loss_mask: 0.2033  decode.loss_dice: 0.1627  decode.d0.loss_cls: 0.8821  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.1579  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.3167  decode.d1.loss_dice: 0.1707  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.1690  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.2013  decode.d3.loss_dice: 0.1586  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.2011  decode.d4.loss_dice: 0.1571  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.3090  decode.d5.loss_dice: 0.1669  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.3110  decode.d6.loss_dice: 0.1735  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.3103  decode.d7.loss_dice: 0.1684  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.3135  decode.d8.loss_dice: 0.1698
10/01 03:50:33 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:50:33 - mmengine - INFO - Iter(train) [154000/320000]  base_lr: 5.5394e-05 lr: 5.5394e-06  eta: 20:12:41  time: 0.4403  data_time: 0.0094  memory: 5129  grad_norm: 81.1972  loss: 6.4915  decode.loss_cls: 0.1804  decode.loss_mask: 0.2196  decode.loss_dice: 0.2065  decode.d0.loss_cls: 0.9638  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.1967  decode.d1.loss_cls: 0.2045  decode.d1.loss_mask: 0.2130  decode.d1.loss_dice: 0.2012  decode.d2.loss_cls: 0.1889  decode.d2.loss_mask: 0.2080  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.1545  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.2096  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.1190  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2082  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 0.2083  decode.d6.loss_dice: 0.2063  decode.d7.loss_cls: 0.1402  decode.d7.loss_mask: 0.2122  decode.d7.loss_dice: 0.2043  decode.d8.loss_cls: 0.1271  decode.d8.loss_mask: 0.2071  decode.d8.loss_dice: 0.1992
10/01 03:50:55 - mmengine - INFO - Iter(train) [154050/320000]  base_lr: 5.5379e-05 lr: 5.5379e-06  eta: 20:12:20  time: 0.4395  data_time: 0.0095  memory: 5145  grad_norm: 35.7784  loss: 4.0236  decode.loss_cls: 0.0100  decode.loss_mask: 0.1606  decode.loss_dice: 0.1635  decode.d0.loss_cls: 0.7806  decode.d0.loss_mask: 0.1632  decode.d0.loss_dice: 0.1637  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.1603  decode.d1.loss_dice: 0.1544  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.1605  decode.d2.loss_dice: 0.1569  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.1602  decode.d3.loss_dice: 0.1500  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.1597  decode.d4.loss_dice: 0.1544  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.1600  decode.d5.loss_dice: 0.1531  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.1606  decode.d6.loss_dice: 0.1515  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.1617  decode.d7.loss_dice: 0.1504  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.1613  decode.d8.loss_dice: 0.1638
10/01 03:51:17 - mmengine - INFO - Iter(train) [154100/320000]  base_lr: 5.5364e-05 lr: 5.5364e-06  eta: 20:11:58  time: 0.4408  data_time: 0.0096  memory: 5145  grad_norm: 38.3813  loss: 5.8460  decode.loss_cls: 0.0773  decode.loss_mask: 0.2464  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.6646  decode.d0.loss_mask: 0.2503  decode.d0.loss_dice: 0.2243  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2226  decode.d2.loss_cls: 0.0607  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.1856  decode.d3.loss_cls: 0.1067  decode.d3.loss_mask: 0.2501  decode.d3.loss_dice: 0.1858  decode.d4.loss_cls: 0.0933  decode.d4.loss_mask: 0.2500  decode.d4.loss_dice: 0.1903  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.2464  decode.d5.loss_dice: 0.1837  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.2494  decode.d6.loss_dice: 0.1893  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.2489  decode.d8.loss_dice: 0.2156
10/01 03:51:39 - mmengine - INFO - Iter(train) [154150/320000]  base_lr: 5.5349e-05 lr: 5.5349e-06  eta: 20:11:36  time: 0.4409  data_time: 0.0097  memory: 5104  grad_norm: 113.8591  loss: 6.2198  decode.loss_cls: 0.1401  decode.loss_mask: 0.1996  decode.loss_dice: 0.1900  decode.d0.loss_cls: 0.9829  decode.d0.loss_mask: 0.1997  decode.d0.loss_dice: 0.1836  decode.d1.loss_cls: 0.1560  decode.d1.loss_mask: 0.2054  decode.d1.loss_dice: 0.1971  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 0.2007  decode.d2.loss_dice: 0.1777  decode.d3.loss_cls: 0.1653  decode.d3.loss_mask: 0.1991  decode.d3.loss_dice: 0.1786  decode.d4.loss_cls: 0.1699  decode.d4.loss_mask: 0.1994  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.1679  decode.d5.loss_mask: 0.2014  decode.d5.loss_dice: 0.1956  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.1976  decode.d6.loss_dice: 0.1781  decode.d7.loss_cls: 0.1589  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 0.1985  decode.d8.loss_dice: 0.1890
10/01 03:52:01 - mmengine - INFO - Iter(train) [154200/320000]  base_lr: 5.5334e-05 lr: 5.5334e-06  eta: 20:11:14  time: 0.4412  data_time: 0.0096  memory: 5145  grad_norm: 30.8696  loss: 4.0980  decode.loss_cls: 0.0100  decode.loss_mask: 0.1749  decode.loss_dice: 0.1371  decode.d0.loss_cls: 0.7983  decode.d0.loss_mask: 0.1776  decode.d0.loss_dice: 0.1461  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.1759  decode.d1.loss_dice: 0.1369  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.1734  decode.d2.loss_dice: 0.1374  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.1732  decode.d3.loss_dice: 0.1360  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.1732  decode.d4.loss_dice: 0.1372  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.1750  decode.d5.loss_dice: 0.1398  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.1756  decode.d6.loss_dice: 0.1407  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.1749  decode.d7.loss_dice: 0.1390  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.1745  decode.d8.loss_dice: 0.1393
10/01 03:52:23 - mmengine - INFO - Iter(train) [154250/320000]  base_lr: 5.5319e-05 lr: 5.5319e-06  eta: 20:10:52  time: 0.4425  data_time: 0.0098  memory: 5145  grad_norm: 41.7057  loss: 5.7759  decode.loss_cls: 0.0293  decode.loss_mask: 0.1740  decode.loss_dice: 0.2974  decode.d0.loss_cls: 0.7496  decode.d0.loss_mask: 0.1720  decode.d0.loss_dice: 0.2891  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.1728  decode.d1.loss_dice: 0.3084  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.1702  decode.d2.loss_dice: 0.2947  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.1716  decode.d3.loss_dice: 0.2792  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.1715  decode.d4.loss_dice: 0.2833  decode.d5.loss_cls: 0.0334  decode.d5.loss_mask: 0.1721  decode.d5.loss_dice: 0.3222  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 0.1731  decode.d6.loss_dice: 0.3000  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.1709  decode.d7.loss_dice: 0.2941  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.1720  decode.d8.loss_dice: 0.3002
10/01 03:52:45 - mmengine - INFO - Iter(train) [154300/320000]  base_lr: 5.5304e-05 lr: 5.5304e-06  eta: 20:10:31  time: 0.4419  data_time: 0.0098  memory: 5120  grad_norm: 75.9926  loss: 5.2245  decode.loss_cls: 0.0451  decode.loss_mask: 0.2319  decode.loss_dice: 0.1685  decode.d0.loss_cls: 0.7865  decode.d0.loss_mask: 0.2271  decode.d0.loss_dice: 0.1719  decode.d1.loss_cls: 0.1004  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.1770  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.2314  decode.d2.loss_dice: 0.1679  decode.d3.loss_cls: 0.0373  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.1660  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.2318  decode.d4.loss_dice: 0.1727  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 0.2311  decode.d5.loss_dice: 0.1645  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.1644  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.2270  decode.d7.loss_dice: 0.1611  decode.d8.loss_cls: 0.0482  decode.d8.loss_mask: 0.2283  decode.d8.loss_dice: 0.1629
10/01 03:53:08 - mmengine - INFO - Iter(train) [154350/320000]  base_lr: 5.5289e-05 lr: 5.5289e-06  eta: 20:10:09  time: 0.4411  data_time: 0.0094  memory: 5159  grad_norm: 46.8672  loss: 4.6097  decode.loss_cls: 0.0442  decode.loss_mask: 0.1805  decode.loss_dice: 0.1426  decode.d0.loss_cls: 0.8147  decode.d0.loss_mask: 0.1816  decode.d0.loss_dice: 0.1466  decode.d1.loss_cls: 0.0938  decode.d1.loss_mask: 0.1796  decode.d1.loss_dice: 0.1439  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.1778  decode.d2.loss_dice: 0.1386  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.1783  decode.d3.loss_dice: 0.1419  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.1473  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.1769  decode.d5.loss_dice: 0.1466  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.1797  decode.d6.loss_dice: 0.1412  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.1773  decode.d7.loss_dice: 0.1361  decode.d8.loss_cls: 0.0578  decode.d8.loss_mask: 0.1791  decode.d8.loss_dice: 0.1413
10/01 03:53:30 - mmengine - INFO - Iter(train) [154400/320000]  base_lr: 5.5274e-05 lr: 5.5274e-06  eta: 20:09:47  time: 0.4410  data_time: 0.0096  memory: 5145  grad_norm: 191.3582  loss: 5.6404  decode.loss_cls: 0.1007  decode.loss_mask: 0.2431  decode.loss_dice: 0.1809  decode.d0.loss_cls: 0.9008  decode.d0.loss_mask: 0.2587  decode.d0.loss_dice: 0.1924  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.1860  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.1793  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.1885  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.2471  decode.d4.loss_dice: 0.1821  decode.d5.loss_cls: 0.0319  decode.d5.loss_mask: 0.2406  decode.d5.loss_dice: 0.1803  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.2452  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0341  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.1777  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.2517  decode.d8.loss_dice: 0.1849
10/01 03:53:52 - mmengine - INFO - Iter(train) [154450/320000]  base_lr: 5.5259e-05 lr: 5.5259e-06  eta: 20:09:26  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 46.2375  loss: 5.7367  decode.loss_cls: 0.1086  decode.loss_mask: 0.1790  decode.loss_dice: 0.2025  decode.d0.loss_cls: 1.0306  decode.d0.loss_mask: 0.1779  decode.d0.loss_dice: 0.2113  decode.d1.loss_cls: 0.1231  decode.d1.loss_mask: 0.1797  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.1830  decode.d2.loss_dice: 0.1972  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.1803  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.1805  decode.d4.loss_dice: 0.1885  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.1776  decode.d5.loss_dice: 0.2025  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.1799  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.1817  decode.d7.loss_dice: 0.1917  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 0.1806  decode.d8.loss_dice: 0.2025
10/01 03:54:14 - mmengine - INFO - Iter(train) [154500/320000]  base_lr: 5.5244e-05 lr: 5.5244e-06  eta: 20:09:04  time: 0.4409  data_time: 0.0095  memory: 5129  grad_norm: 65.1267  loss: 4.8440  decode.loss_cls: 0.0231  decode.loss_mask: 0.2160  decode.loss_dice: 0.1732  decode.d0.loss_cls: 0.7177  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.1821  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.2157  decode.d1.loss_dice: 0.1760  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.2160  decode.d2.loss_dice: 0.1809  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.1848  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2130  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.2190  decode.d6.loss_dice: 0.1761  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.2163  decode.d7.loss_dice: 0.1736  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.2150  decode.d8.loss_dice: 0.1738
10/01 03:54:36 - mmengine - INFO - Iter(train) [154550/320000]  base_lr: 5.5229e-05 lr: 5.5229e-06  eta: 20:08:42  time: 0.4408  data_time: 0.0096  memory: 5129  grad_norm: 98.5668  loss: 6.4325  decode.loss_cls: 0.1392  decode.loss_mask: 0.2323  decode.loss_dice: 0.2032  decode.d0.loss_cls: 0.8190  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.1302  decode.d1.loss_mask: 0.2306  decode.d1.loss_dice: 0.1956  decode.d2.loss_cls: 0.1112  decode.d2.loss_mask: 0.2343  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 0.2300  decode.d3.loss_dice: 0.2152  decode.d4.loss_cls: 0.1531  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.2106  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.2293  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 0.2322  decode.d6.loss_dice: 0.2126  decode.d7.loss_cls: 0.1321  decode.d7.loss_mask: 0.2288  decode.d7.loss_dice: 0.2121  decode.d8.loss_cls: 0.1226  decode.d8.loss_mask: 0.2312  decode.d8.loss_dice: 0.2093
10/01 03:54:58 - mmengine - INFO - Iter(train) [154600/320000]  base_lr: 5.5214e-05 lr: 5.5214e-06  eta: 20:08:20  time: 0.4402  data_time: 0.0097  memory: 5145  grad_norm: 463.0333  loss: 11.7289  decode.loss_cls: 0.2926  decode.loss_mask: 0.7537  decode.loss_dice: 0.2748  decode.d0.loss_cls: 1.0727  decode.d0.loss_mask: 0.2120  decode.d0.loss_dice: 0.2262  decode.d1.loss_cls: 0.3259  decode.d1.loss_mask: 0.3497  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.2470  decode.d2.loss_mask: 0.4889  decode.d2.loss_dice: 0.2867  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 0.8665  decode.d3.loss_dice: 0.2592  decode.d4.loss_cls: 0.2474  decode.d4.loss_mask: 1.2030  decode.d4.loss_dice: 0.2979  decode.d5.loss_cls: 0.3529  decode.d5.loss_mask: 0.4166  decode.d5.loss_dice: 0.2572  decode.d6.loss_cls: 0.2706  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.2630  decode.d7.loss_cls: 0.2777  decode.d7.loss_mask: 0.4150  decode.d7.loss_dice: 0.2251  decode.d8.loss_cls: 0.2597  decode.d8.loss_mask: 0.6088  decode.d8.loss_dice: 0.2586
10/01 03:55:20 - mmengine - INFO - Iter(train) [154650/320000]  base_lr: 5.5199e-05 lr: 5.5199e-06  eta: 20:07:59  time: 0.4410  data_time: 0.0096  memory: 5129  grad_norm: 41.1258  loss: 4.4649  decode.loss_cls: 0.0027  decode.loss_mask: 0.1820  decode.loss_dice: 0.1628  decode.d0.loss_cls: 0.8981  decode.d0.loss_mask: 0.1915  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.1881  decode.d1.loss_dice: 0.1743  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.1846  decode.d2.loss_dice: 0.1686  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.1828  decode.d3.loss_dice: 0.1676  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.1844  decode.d4.loss_dice: 0.1658  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.1843  decode.d5.loss_dice: 0.1679  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.1842  decode.d6.loss_dice: 0.1639  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1849  decode.d7.loss_dice: 0.1719  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.1840  decode.d8.loss_dice: 0.1668
10/01 03:55:42 - mmengine - INFO - Iter(train) [154700/320000]  base_lr: 5.5184e-05 lr: 5.5184e-06  eta: 20:07:37  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 135.9412  loss: 7.6556  decode.loss_cls: 0.1216  decode.loss_mask: 0.3093  decode.loss_dice: 0.2775  decode.d0.loss_cls: 0.7153  decode.d0.loss_mask: 0.3121  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.3103  decode.d1.loss_dice: 0.2453  decode.d2.loss_cls: 0.0981  decode.d2.loss_mask: 0.3078  decode.d2.loss_dice: 0.2869  decode.d3.loss_cls: 0.1353  decode.d3.loss_mask: 0.3106  decode.d3.loss_dice: 0.2967  decode.d4.loss_cls: 0.0989  decode.d4.loss_mask: 0.3117  decode.d4.loss_dice: 0.2831  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.3096  decode.d5.loss_dice: 0.2998  decode.d6.loss_cls: 0.1175  decode.d6.loss_mask: 0.3067  decode.d6.loss_dice: 0.2826  decode.d7.loss_cls: 0.1251  decode.d7.loss_mask: 0.3075  decode.d7.loss_dice: 0.2859  decode.d8.loss_cls: 0.1456  decode.d8.loss_mask: 0.3085  decode.d8.loss_dice: 0.2566
10/01 03:56:05 - mmengine - INFO - Iter(train) [154750/320000]  base_lr: 5.5169e-05 lr: 5.5169e-06  eta: 20:07:15  time: 0.4409  data_time: 0.0094  memory: 5145  grad_norm: 21.6746  loss: 4.2558  decode.loss_cls: 0.0085  decode.loss_mask: 0.1738  decode.loss_dice: 0.1569  decode.d0.loss_cls: 0.8291  decode.d0.loss_mask: 0.1741  decode.d0.loss_dice: 0.1529  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.1707  decode.d1.loss_dice: 0.1614  decode.d2.loss_cls: 0.0134  decode.d2.loss_mask: 0.1746  decode.d2.loss_dice: 0.1629  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.1755  decode.d3.loss_dice: 0.1609  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.1765  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.1749  decode.d5.loss_dice: 0.1604  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.1744  decode.d6.loss_dice: 0.1586  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.1747  decode.d7.loss_dice: 0.1636  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.1726  decode.d8.loss_dice: 0.1555
10/01 03:56:27 - mmengine - INFO - Iter(train) [154800/320000]  base_lr: 5.5154e-05 lr: 5.5154e-06  eta: 20:06:54  time: 0.4411  data_time: 0.0094  memory: 5129  grad_norm: 53.2976  loss: 6.8936  decode.loss_cls: 0.1174  decode.loss_mask: 0.1921  decode.loss_dice: 0.2884  decode.d0.loss_cls: 0.8656  decode.d0.loss_mask: 0.1950  decode.d0.loss_dice: 0.3039  decode.d1.loss_cls: 0.1597  decode.d1.loss_mask: 0.1896  decode.d1.loss_dice: 0.2530  decode.d2.loss_cls: 0.1472  decode.d2.loss_mask: 0.1911  decode.d2.loss_dice: 0.2862  decode.d3.loss_cls: 0.1438  decode.d3.loss_mask: 0.1934  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.1200  decode.d4.loss_mask: 0.1952  decode.d4.loss_dice: 0.3069  decode.d5.loss_cls: 0.1811  decode.d5.loss_mask: 0.1945  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.1294  decode.d6.loss_mask: 0.1944  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.1387  decode.d7.loss_mask: 0.1917  decode.d7.loss_dice: 0.2862  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.1908  decode.d8.loss_dice: 0.2747
10/01 03:56:49 - mmengine - INFO - Iter(train) [154850/320000]  base_lr: 5.5139e-05 lr: 5.5139e-06  eta: 20:06:32  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 24.2392  loss: 4.2689  decode.loss_cls: 0.0088  decode.loss_mask: 0.1694  decode.loss_dice: 0.1567  decode.d0.loss_cls: 0.8256  decode.d0.loss_mask: 0.1705  decode.d0.loss_dice: 0.1489  decode.d1.loss_cls: 0.0502  decode.d1.loss_mask: 0.1703  decode.d1.loss_dice: 0.1577  decode.d2.loss_cls: 0.0388  decode.d2.loss_mask: 0.1732  decode.d2.loss_dice: 0.1544  decode.d3.loss_cls: 0.0245  decode.d3.loss_mask: 0.1719  decode.d3.loss_dice: 0.1588  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.1720  decode.d4.loss_dice: 0.1536  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.1716  decode.d5.loss_dice: 0.1513  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.1729  decode.d6.loss_dice: 0.1583  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.1717  decode.d7.loss_dice: 0.1593  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.1712  decode.d8.loss_dice: 0.1576
10/01 03:57:11 - mmengine - INFO - Iter(train) [154900/320000]  base_lr: 5.5124e-05 lr: 5.5124e-06  eta: 20:06:10  time: 0.4428  data_time: 0.0098  memory: 5129  grad_norm: 58.7884  loss: 5.6102  decode.loss_cls: 0.0939  decode.loss_mask: 0.1998  decode.loss_dice: 0.1918  decode.d0.loss_cls: 0.8906  decode.d0.loss_mask: 0.1989  decode.d0.loss_dice: 0.1917  decode.d1.loss_cls: 0.0913  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.1878  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.1992  decode.d3.loss_dice: 0.1843  decode.d4.loss_cls: 0.0779  decode.d4.loss_mask: 0.1976  decode.d4.loss_dice: 0.1886  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.1979  decode.d5.loss_dice: 0.1916  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 0.1988  decode.d6.loss_dice: 0.1854  decode.d7.loss_cls: 0.0941  decode.d7.loss_mask: 0.1982  decode.d7.loss_dice: 0.1888  decode.d8.loss_cls: 0.1608  decode.d8.loss_mask: 0.2011  decode.d8.loss_dice: 0.1818
10/01 03:57:33 - mmengine - INFO - Iter(train) [154950/320000]  base_lr: 5.5109e-05 lr: 5.5109e-06  eta: 20:05:48  time: 0.4420  data_time: 0.0095  memory: 5129  grad_norm: 29.6655  loss: 4.0836  decode.loss_cls: 0.0438  decode.loss_mask: 0.1565  decode.loss_dice: 0.1359  decode.d0.loss_cls: 0.8007  decode.d0.loss_mask: 0.1587  decode.d0.loss_dice: 0.1382  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 0.1564  decode.d1.loss_dice: 0.1375  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.1567  decode.d2.loss_dice: 0.1396  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.1548  decode.d3.loss_dice: 0.1360  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.1554  decode.d4.loss_dice: 0.1403  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.1563  decode.d5.loss_dice: 0.1371  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.1565  decode.d6.loss_dice: 0.1402  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.1558  decode.d7.loss_dice: 0.1370  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.1552  decode.d8.loss_dice: 0.1404
10/01 03:57:55 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 03:57:55 - mmengine - INFO - Iter(train) [155000/320000]  base_lr: 5.5094e-05 lr: 5.5094e-06  eta: 20:05:27  time: 0.4407  data_time: 0.0097  memory: 5119  grad_norm: 75.6396  loss: 6.5770  decode.loss_cls: 0.1275  decode.loss_mask: 0.2299  decode.loss_dice: 0.1974  decode.d0.loss_cls: 0.8484  decode.d0.loss_mask: 0.2364  decode.d0.loss_dice: 0.2027  decode.d1.loss_cls: 0.2201  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.1884  decode.d2.loss_cls: 0.1409  decode.d2.loss_mask: 0.2330  decode.d2.loss_dice: 0.2061  decode.d3.loss_cls: 0.1285  decode.d3.loss_mask: 0.2336  decode.d3.loss_dice: 0.1972  decode.d4.loss_cls: 0.1390  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.1922  decode.d5.loss_cls: 0.1663  decode.d5.loss_mask: 0.2295  decode.d5.loss_dice: 0.1945  decode.d6.loss_cls: 0.1899  decode.d6.loss_mask: 0.2327  decode.d6.loss_dice: 0.1966  decode.d7.loss_cls: 0.1713  decode.d7.loss_mask: 0.2305  decode.d7.loss_dice: 0.1914  decode.d8.loss_cls: 0.1689  decode.d8.loss_mask: 0.2294  decode.d8.loss_dice: 0.1909
10/01 03:58:17 - mmengine - INFO - Iter(train) [155050/320000]  base_lr: 5.5079e-05 lr: 5.5079e-06  eta: 20:05:05  time: 0.4425  data_time: 0.0096  memory: 5145  grad_norm: 48.5621  loss: 5.2277  decode.loss_cls: 0.0167  decode.loss_mask: 0.1918  decode.loss_dice: 0.2212  decode.d0.loss_cls: 0.8652  decode.d0.loss_mask: 0.1898  decode.d0.loss_dice: 0.1748  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.1883  decode.d1.loss_dice: 0.2139  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.1878  decode.d2.loss_dice: 0.2033  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.1888  decode.d3.loss_dice: 0.1958  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.1885  decode.d4.loss_dice: 0.2137  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.1901  decode.d5.loss_dice: 0.1990  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.1879  decode.d6.loss_dice: 0.1933  decode.d7.loss_cls: 0.0725  decode.d7.loss_mask: 0.1907  decode.d7.loss_dice: 0.1912  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.1903  decode.d8.loss_dice: 0.1926
10/01 03:58:40 - mmengine - INFO - Iter(train) [155100/320000]  base_lr: 5.5064e-05 lr: 5.5064e-06  eta: 20:04:43  time: 0.4429  data_time: 0.0098  memory: 5129  grad_norm: 32.4096  loss: 4.4147  decode.loss_cls: 0.0025  decode.loss_mask: 0.1966  decode.loss_dice: 0.1581  decode.d0.loss_cls: 0.7746  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.1621  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.1960  decode.d1.loss_dice: 0.1627  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.1968  decode.d2.loss_dice: 0.1615  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.1955  decode.d3.loss_dice: 0.1674  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.1939  decode.d4.loss_dice: 0.1729  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.1964  decode.d5.loss_dice: 0.1621  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.1928  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1953  decode.d7.loss_dice: 0.1796  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.1597
10/01 03:59:02 - mmengine - INFO - Iter(train) [155150/320000]  base_lr: 5.5049e-05 lr: 5.5049e-06  eta: 20:04:22  time: 0.4432  data_time: 0.0099  memory: 5129  grad_norm: 56.9977  loss: 6.0626  decode.loss_cls: 0.1138  decode.loss_mask: 0.1674  decode.loss_dice: 0.2701  decode.d0.loss_cls: 0.8715  decode.d0.loss_mask: 0.1645  decode.d0.loss_dice: 0.2307  decode.d1.loss_cls: 0.1245  decode.d1.loss_mask: 0.1649  decode.d1.loss_dice: 0.2523  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.1652  decode.d2.loss_dice: 0.2379  decode.d3.loss_cls: 0.1200  decode.d3.loss_mask: 0.1639  decode.d3.loss_dice: 0.2534  decode.d4.loss_cls: 0.1154  decode.d4.loss_mask: 0.1653  decode.d4.loss_dice: 0.2675  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.1671  decode.d5.loss_dice: 0.2328  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 0.1642  decode.d6.loss_dice: 0.2418  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 0.1670  decode.d7.loss_dice: 0.2285  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.1649  decode.d8.loss_dice: 0.2093
10/01 03:59:24 - mmengine - INFO - Iter(train) [155200/320000]  base_lr: 5.5034e-05 lr: 5.5034e-06  eta: 20:04:00  time: 0.4436  data_time: 0.0097  memory: 5129  grad_norm: 57.9615  loss: 4.8288  decode.loss_cls: 0.0494  decode.loss_mask: 0.1876  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.8388  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1599  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.1881  decode.d1.loss_dice: 0.1580  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.1895  decode.d2.loss_dice: 0.1549  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.1527  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.1565  decode.d5.loss_cls: 0.0560  decode.d5.loss_mask: 0.1880  decode.d5.loss_dice: 0.1696  decode.d6.loss_cls: 0.0464  decode.d6.loss_mask: 0.1848  decode.d6.loss_dice: 0.1635  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.1858  decode.d7.loss_dice: 0.1698  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 0.1855  decode.d8.loss_dice: 0.1668
10/01 03:59:46 - mmengine - INFO - Iter(train) [155250/320000]  base_lr: 5.5019e-05 lr: 5.5019e-06  eta: 20:03:38  time: 0.4427  data_time: 0.0095  memory: 5129  grad_norm: 51.1942  loss: 4.8978  decode.loss_cls: 0.0579  decode.loss_mask: 0.1773  decode.loss_dice: 0.1721  decode.d0.loss_cls: 0.9158  decode.d0.loss_mask: 0.1763  decode.d0.loss_dice: 0.1640  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.1838  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.1786  decode.d2.loss_dice: 0.1701  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.1788  decode.d3.loss_dice: 0.1695  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.1778  decode.d4.loss_dice: 0.1656  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.1793  decode.d5.loss_dice: 0.1707  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.1776  decode.d6.loss_dice: 0.1726  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.1780  decode.d7.loss_dice: 0.1731  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.1789  decode.d8.loss_dice: 0.1714
10/01 04:00:08 - mmengine - INFO - Iter(train) [155300/320000]  base_lr: 5.5004e-05 lr: 5.5004e-06  eta: 20:03:17  time: 0.4419  data_time: 0.0096  memory: 5129  grad_norm: 38.6403  loss: 5.6272  decode.loss_cls: 0.0542  decode.loss_mask: 0.2162  decode.loss_dice: 0.1970  decode.d0.loss_cls: 1.0254  decode.d0.loss_mask: 0.2155  decode.d0.loss_dice: 0.1709  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1729  decode.d2.loss_cls: 0.1070  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.2124  decode.d3.loss_dice: 0.1735  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.1958  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.2124  decode.d5.loss_dice: 0.1826  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.1757  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.1670  decode.d8.loss_cls: 0.0759  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.1630
10/01 04:00:30 - mmengine - INFO - Iter(train) [155350/320000]  base_lr: 5.4988e-05 lr: 5.4988e-06  eta: 20:02:55  time: 0.4409  data_time: 0.0097  memory: 5120  grad_norm: 64.7069  loss: 5.9414  decode.loss_cls: 0.0533  decode.loss_mask: 0.2366  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.9095  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.2076  decode.d1.loss_cls: 0.0823  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2273  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.2363  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.2352  decode.d3.loss_dice: 0.2121  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.2365  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.2349  decode.d5.loss_dice: 0.2180  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.2025  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.2119  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.2116
10/01 04:00:52 - mmengine - INFO - Iter(train) [155400/320000]  base_lr: 5.4973e-05 lr: 5.4973e-06  eta: 20:02:33  time: 0.4414  data_time: 0.0099  memory: 5120  grad_norm: 96.7136  loss: 8.0032  decode.loss_cls: 0.2871  decode.loss_mask: 0.1945  decode.loss_dice: 0.2019  decode.d0.loss_cls: 0.8988  decode.d0.loss_mask: 0.2002  decode.d0.loss_dice: 0.1929  decode.d1.loss_cls: 0.3324  decode.d1.loss_mask: 0.4167  decode.d1.loss_dice: 0.2101  decode.d2.loss_cls: 0.2780  decode.d2.loss_mask: 0.1974  decode.d2.loss_dice: 0.2080  decode.d3.loss_cls: 0.2701  decode.d3.loss_mask: 0.1969  decode.d3.loss_dice: 0.2119  decode.d4.loss_cls: 0.3053  decode.d4.loss_mask: 0.1944  decode.d4.loss_dice: 0.2160  decode.d5.loss_cls: 0.3238  decode.d5.loss_mask: 0.3107  decode.d5.loss_dice: 0.2518  decode.d6.loss_cls: 0.3033  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.3018  decode.d7.loss_mask: 0.1978  decode.d7.loss_dice: 0.1761  decode.d8.loss_cls: 0.3238  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.1945
10/01 04:01:14 - mmengine - INFO - Iter(train) [155450/320000]  base_lr: 5.4958e-05 lr: 5.4958e-06  eta: 20:02:12  time: 0.4404  data_time: 0.0096  memory: 5145  grad_norm: 28.1966  loss: 4.0648  decode.loss_cls: 0.0013  decode.loss_mask: 0.2004  decode.loss_dice: 0.1331  decode.d0.loss_cls: 0.7100  decode.d0.loss_mask: 0.1983  decode.d0.loss_dice: 0.1295  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.1319  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1342  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2006  decode.d3.loss_dice: 0.1323  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2023  decode.d4.loss_dice: 0.1387  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1990  decode.d5.loss_dice: 0.1330  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2013  decode.d6.loss_dice: 0.1327  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2009  decode.d7.loss_dice: 0.1337  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2016  decode.d8.loss_dice: 0.1329
10/01 04:01:37 - mmengine - INFO - Iter(train) [155500/320000]  base_lr: 5.4943e-05 lr: 5.4943e-06  eta: 20:01:50  time: 0.4412  data_time: 0.0098  memory: 5145  grad_norm: 151.2885  loss: 7.4344  decode.loss_cls: 0.2097  decode.loss_mask: 0.2855  decode.loss_dice: 0.2522  decode.d0.loss_cls: 0.9451  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.2023  decode.d1.loss_cls: 0.1289  decode.d1.loss_mask: 0.2439  decode.d1.loss_dice: 0.1995  decode.d2.loss_cls: 0.0991  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.2147  decode.d3.loss_cls: 0.1401  decode.d3.loss_mask: 0.2450  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.1390  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.2565  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 0.2689  decode.d5.loss_dice: 0.2472  decode.d6.loss_cls: 0.1900  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.2770  decode.d7.loss_cls: 0.2161  decode.d7.loss_mask: 0.2834  decode.d7.loss_dice: 0.2847  decode.d8.loss_cls: 0.1720  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.2618
10/01 04:01:59 - mmengine - INFO - Iter(train) [155550/320000]  base_lr: 5.4928e-05 lr: 5.4928e-06  eta: 20:01:28  time: 0.4417  data_time: 0.0100  memory: 5129  grad_norm: 125.6125  loss: 6.0084  decode.loss_cls: 0.1195  decode.loss_mask: 0.2233  decode.loss_dice: 0.1750  decode.d0.loss_cls: 0.8965  decode.d0.loss_mask: 0.2207  decode.d0.loss_dice: 0.1741  decode.d1.loss_cls: 0.1326  decode.d1.loss_mask: 0.2228  decode.d1.loss_dice: 0.1675  decode.d2.loss_cls: 0.1241  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.1818  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.1730  decode.d4.loss_cls: 0.1573  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.1720  decode.d5.loss_cls: 0.1329  decode.d5.loss_mask: 0.2205  decode.d5.loss_dice: 0.1683  decode.d6.loss_cls: 0.1207  decode.d6.loss_mask: 0.2283  decode.d6.loss_dice: 0.1662  decode.d7.loss_cls: 0.1256  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.1784  decode.d8.loss_cls: 0.1226  decode.d8.loss_mask: 0.2259  decode.d8.loss_dice: 0.1771
10/01 04:02:21 - mmengine - INFO - Iter(train) [155600/320000]  base_lr: 5.4913e-05 lr: 5.4913e-06  eta: 20:01:06  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 39.5112  loss: 4.2448  decode.loss_cls: 0.0125  decode.loss_mask: 0.1708  decode.loss_dice: 0.1581  decode.d0.loss_cls: 0.8208  decode.d0.loss_mask: 0.1688  decode.d0.loss_dice: 0.1544  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.1729  decode.d1.loss_dice: 0.1600  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.1717  decode.d2.loss_dice: 0.1598  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.1696  decode.d3.loss_dice: 0.1574  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.1698  decode.d4.loss_dice: 0.1601  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.1708  decode.d5.loss_dice: 0.1628  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.1709  decode.d6.loss_dice: 0.1602  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.1725  decode.d7.loss_dice: 0.1660  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.1720  decode.d8.loss_dice: 0.1613
10/01 04:02:43 - mmengine - INFO - Iter(train) [155650/320000]  base_lr: 5.4898e-05 lr: 5.4898e-06  eta: 20:00:45  time: 0.4407  data_time: 0.0096  memory: 5120  grad_norm: 155.2946  loss: 7.0322  decode.loss_cls: 0.1618  decode.loss_mask: 0.2349  decode.loss_dice: 0.2482  decode.d0.loss_cls: 0.8024  decode.d0.loss_mask: 0.2409  decode.d0.loss_dice: 0.2705  decode.d1.loss_cls: 0.1799  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.2805  decode.d2.loss_cls: 0.1632  decode.d2.loss_mask: 0.2354  decode.d2.loss_dice: 0.2698  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 0.2332  decode.d3.loss_dice: 0.2253  decode.d4.loss_cls: 0.1319  decode.d4.loss_mask: 0.2365  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.2512  decode.d6.loss_cls: 0.1401  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.1691  decode.d7.loss_mask: 0.2355  decode.d7.loss_dice: 0.2272  decode.d8.loss_cls: 0.1649  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2388
10/01 04:03:05 - mmengine - INFO - Iter(train) [155700/320000]  base_lr: 5.4883e-05 lr: 5.4883e-06  eta: 20:00:23  time: 0.4413  data_time: 0.0099  memory: 5129  grad_norm: 56.5673  loss: 6.1469  decode.loss_cls: 0.1297  decode.loss_mask: 0.1987  decode.loss_dice: 0.1820  decode.d0.loss_cls: 0.8435  decode.d0.loss_mask: 0.2004  decode.d0.loss_dice: 0.2185  decode.d1.loss_cls: 0.1279  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.2135  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.2041  decode.d2.loss_dice: 0.2128  decode.d3.loss_cls: 0.1328  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.2136  decode.d4.loss_cls: 0.1492  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.2115  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.1871  decode.d6.loss_cls: 0.1806  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.1837  decode.d7.loss_cls: 0.1568  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.1318  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.1825
10/01 04:03:27 - mmengine - INFO - Iter(train) [155750/320000]  base_lr: 5.4868e-05 lr: 5.4868e-06  eta: 20:00:01  time: 0.4408  data_time: 0.0098  memory: 5129  grad_norm: 62.2672  loss: 6.0491  decode.loss_cls: 0.0825  decode.loss_mask: 0.2302  decode.loss_dice: 0.1918  decode.d0.loss_cls: 0.9710  decode.d0.loss_mask: 0.2295  decode.d0.loss_dice: 0.1946  decode.d1.loss_cls: 0.1299  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.1888  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.1886  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.1867  decode.d4.loss_cls: 0.1166  decode.d4.loss_mask: 0.2279  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.1104  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.1003  decode.d6.loss_mask: 0.2267  decode.d6.loss_dice: 0.1846  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.2278  decode.d7.loss_dice: 0.1858  decode.d8.loss_cls: 0.1066  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.1829
10/01 04:03:49 - mmengine - INFO - Iter(train) [155800/320000]  base_lr: 5.4853e-05 lr: 5.4853e-06  eta: 19:59:39  time: 0.4407  data_time: 0.0098  memory: 5129  grad_norm: 72.9824  loss: 4.3347  decode.loss_cls: 0.0666  decode.loss_mask: 0.1764  decode.loss_dice: 0.1294  decode.d0.loss_cls: 0.7428  decode.d0.loss_mask: 0.1783  decode.d0.loss_dice: 0.1285  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.1795  decode.d1.loss_dice: 0.1288  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.1790  decode.d2.loss_dice: 0.1314  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.1776  decode.d3.loss_dice: 0.1314  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.1777  decode.d4.loss_dice: 0.1340  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.1755  decode.d5.loss_dice: 0.1313  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.1761  decode.d6.loss_dice: 0.1291  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.1770  decode.d7.loss_dice: 0.1292  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.1781  decode.d8.loss_dice: 0.1328
10/01 04:04:11 - mmengine - INFO - Iter(train) [155850/320000]  base_lr: 5.4838e-05 lr: 5.4838e-06  eta: 19:59:18  time: 0.4411  data_time: 0.0096  memory: 5129  grad_norm: 29.0478  loss: 3.9844  decode.loss_cls: 0.0056  decode.loss_mask: 0.1652  decode.loss_dice: 0.1383  decode.d0.loss_cls: 0.9076  decode.d0.loss_mask: 0.1641  decode.d0.loss_dice: 0.1382  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.1643  decode.d1.loss_dice: 0.1358  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.1674  decode.d2.loss_dice: 0.1391  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.1685  decode.d3.loss_dice: 0.1371  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.1662  decode.d4.loss_dice: 0.1382  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.1673  decode.d5.loss_dice: 0.1379  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.1623  decode.d6.loss_dice: 0.1341  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.1635  decode.d7.loss_dice: 0.1367  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.1661  decode.d8.loss_dice: 0.1369
10/01 04:04:33 - mmengine - INFO - Iter(train) [155900/320000]  base_lr: 5.4823e-05 lr: 5.4823e-06  eta: 19:58:56  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 37.7755  loss: 4.8605  decode.loss_cls: 0.0471  decode.loss_mask: 0.1988  decode.loss_dice: 0.1593  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.1991  decode.d0.loss_dice: 0.1701  decode.d1.loss_cls: 0.0788  decode.d1.loss_mask: 0.1991  decode.d1.loss_dice: 0.1571  decode.d2.loss_cls: 0.0450  decode.d2.loss_mask: 0.1979  decode.d2.loss_dice: 0.1560  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.1548  decode.d4.loss_cls: 0.0344  decode.d4.loss_mask: 0.1986  decode.d4.loss_dice: 0.1627  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.1569  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.2006  decode.d6.loss_dice: 0.1569  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.2021  decode.d7.loss_dice: 0.1575  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.1990  decode.d8.loss_dice: 0.1554
10/01 04:04:55 - mmengine - INFO - Iter(train) [155950/320000]  base_lr: 5.4808e-05 lr: 5.4808e-06  eta: 19:58:34  time: 0.4412  data_time: 0.0096  memory: 5145  grad_norm: 19.0009  loss: 3.7199  decode.loss_cls: 0.0014  decode.loss_mask: 0.1581  decode.loss_dice: 0.1318  decode.d0.loss_cls: 0.8206  decode.d0.loss_mask: 0.1578  decode.d0.loss_dice: 0.1323  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.1559  decode.d1.loss_dice: 0.1316  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.1578  decode.d2.loss_dice: 0.1310  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.1581  decode.d3.loss_dice: 0.1298  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1591  decode.d4.loss_dice: 0.1353  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.1559  decode.d5.loss_dice: 0.1284  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.1567  decode.d6.loss_dice: 0.1320  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.1561  decode.d7.loss_dice: 0.1309  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.1565  decode.d8.loss_dice: 0.1293
10/01 04:05:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:05:18 - mmengine - INFO - Iter(train) [156000/320000]  base_lr: 5.4793e-05 lr: 5.4793e-06  eta: 19:58:12  time: 0.4415  data_time: 0.0098  memory: 5130  grad_norm: 45.6662  loss: 5.7473  decode.loss_cls: 0.0848  decode.loss_mask: 0.1931  decode.loss_dice: 0.1986  decode.d0.loss_cls: 0.8746  decode.d0.loss_mask: 0.1958  decode.d0.loss_dice: 0.2060  decode.d1.loss_cls: 0.1196  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.1967  decode.d2.loss_cls: 0.1294  decode.d2.loss_mask: 0.1909  decode.d2.loss_dice: 0.2029  decode.d3.loss_cls: 0.0992  decode.d3.loss_mask: 0.1878  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.0868  decode.d4.loss_mask: 0.1924  decode.d4.loss_dice: 0.1932  decode.d5.loss_cls: 0.0878  decode.d5.loss_mask: 0.1938  decode.d5.loss_dice: 0.2008  decode.d6.loss_cls: 0.1340  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.1927  decode.d7.loss_cls: 0.1203  decode.d7.loss_mask: 0.1924  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.1029  decode.d8.loss_mask: 0.2055  decode.d8.loss_dice: 0.2088
10/01 04:05:40 - mmengine - INFO - Iter(train) [156050/320000]  base_lr: 5.4778e-05 lr: 5.4778e-06  eta: 19:57:51  time: 0.4414  data_time: 0.0099  memory: 5129  grad_norm: 59.3018  loss: 8.6293  decode.loss_cls: 0.2039  decode.loss_mask: 0.2452  decode.loss_dice: 0.3184  decode.d0.loss_cls: 1.0740  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.3162  decode.d1.loss_cls: 0.1678  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.3242  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.3596  decode.d3.loss_cls: 0.1760  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.3268  decode.d4.loss_cls: 0.1952  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.3240  decode.d5.loss_cls: 0.1326  decode.d5.loss_mask: 0.2889  decode.d5.loss_dice: 0.3372  decode.d6.loss_cls: 0.1539  decode.d6.loss_mask: 0.2890  decode.d6.loss_dice: 0.3331  decode.d7.loss_cls: 0.2196  decode.d7.loss_mask: 0.2842  decode.d7.loss_dice: 0.3327  decode.d8.loss_cls: 0.1583  decode.d8.loss_mask: 0.2933  decode.d8.loss_dice: 0.3311
10/01 04:06:02 - mmengine - INFO - Iter(train) [156100/320000]  base_lr: 5.4763e-05 lr: 5.4763e-06  eta: 19:57:29  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 86.2615  loss: 6.4591  decode.loss_cls: 0.1658  decode.loss_mask: 0.2009  decode.loss_dice: 0.1979  decode.d0.loss_cls: 0.7837  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.2156  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 0.2008  decode.d1.loss_dice: 0.2046  decode.d2.loss_cls: 0.1882  decode.d2.loss_mask: 0.1998  decode.d2.loss_dice: 0.2081  decode.d3.loss_cls: 0.1834  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.2048  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.2015  decode.d4.loss_dice: 0.2125  decode.d5.loss_cls: 0.1462  decode.d5.loss_mask: 0.2051  decode.d5.loss_dice: 0.2218  decode.d6.loss_cls: 0.1706  decode.d6.loss_mask: 0.2014  decode.d6.loss_dice: 0.2151  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.2041  decode.d8.loss_cls: 0.1762  decode.d8.loss_mask: 0.2019  decode.d8.loss_dice: 0.2044
10/01 04:06:24 - mmengine - INFO - Iter(train) [156150/320000]  base_lr: 5.4748e-05 lr: 5.4748e-06  eta: 19:57:07  time: 0.4418  data_time: 0.0098  memory: 5129  grad_norm: 21.6214  loss: 3.9252  decode.loss_cls: 0.0022  decode.loss_mask: 0.1734  decode.loss_dice: 0.1335  decode.d0.loss_cls: 0.7813  decode.d0.loss_mask: 0.1732  decode.d0.loss_dice: 0.1341  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.1760  decode.d1.loss_dice: 0.1415  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.1733  decode.d2.loss_dice: 0.1391  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.1735  decode.d3.loss_dice: 0.1399  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.1739  decode.d4.loss_dice: 0.1403  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.1757  decode.d5.loss_dice: 0.1399  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.1723  decode.d6.loss_dice: 0.1341  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.1744  decode.d7.loss_dice: 0.1387  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.1728  decode.d8.loss_dice: 0.1355
10/01 04:06:46 - mmengine - INFO - Iter(train) [156200/320000]  base_lr: 5.4733e-05 lr: 5.4733e-06  eta: 19:56:45  time: 0.4413  data_time: 0.0097  memory: 5145  grad_norm: 21.7677  loss: 3.9289  decode.loss_cls: 0.0023  decode.loss_mask: 0.1662  decode.loss_dice: 0.1481  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 0.1657  decode.d0.loss_dice: 0.1440  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.1644  decode.d1.loss_dice: 0.1476  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.1621  decode.d2.loss_dice: 0.1424  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.1646  decode.d3.loss_dice: 0.1478  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1653  decode.d4.loss_dice: 0.1470  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.1635  decode.d5.loss_dice: 0.1450  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.1639  decode.d6.loss_dice: 0.1414  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1642  decode.d7.loss_dice: 0.1435  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1664  decode.d8.loss_dice: 0.1437
10/01 04:07:08 - mmengine - INFO - Iter(train) [156250/320000]  base_lr: 5.4718e-05 lr: 5.4718e-06  eta: 19:56:24  time: 0.4417  data_time: 0.0098  memory: 5120  grad_norm: 61.8633  loss: 4.9661  decode.loss_cls: 0.0783  decode.loss_mask: 0.1980  decode.loss_dice: 0.1616  decode.d0.loss_cls: 0.8792  decode.d0.loss_mask: 0.1989  decode.d0.loss_dice: 0.1590  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.1529  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.1509  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.1986  decode.d3.loss_dice: 0.1744  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.1981  decode.d4.loss_dice: 0.1616  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.1971  decode.d5.loss_dice: 0.1740  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.2129  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.2020  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.1860
10/01 04:07:30 - mmengine - INFO - Iter(train) [156300/320000]  base_lr: 5.4703e-05 lr: 5.4703e-06  eta: 19:56:02  time: 0.4419  data_time: 0.0096  memory: 5145  grad_norm: 26.0879  loss: 3.9853  decode.loss_cls: 0.0133  decode.loss_mask: 0.1582  decode.loss_dice: 0.1510  decode.d0.loss_cls: 0.8189  decode.d0.loss_mask: 0.1599  decode.d0.loss_dice: 0.1446  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.1574  decode.d1.loss_dice: 0.1549  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.1586  decode.d2.loss_dice: 0.1547  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.1554  decode.d3.loss_dice: 0.1531  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.1562  decode.d4.loss_dice: 0.1529  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.1567  decode.d5.loss_dice: 0.1476  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.1592  decode.d6.loss_dice: 0.1539  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.1561  decode.d7.loss_dice: 0.1516  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.1566  decode.d8.loss_dice: 0.1512
10/01 04:07:52 - mmengine - INFO - Iter(train) [156350/320000]  base_lr: 5.4688e-05 lr: 5.4688e-06  eta: 19:55:40  time: 0.4408  data_time: 0.0097  memory: 5120  grad_norm: 134.5943  loss: 5.4426  decode.loss_cls: 0.0722  decode.loss_mask: 0.1911  decode.loss_dice: 0.2212  decode.d0.loss_cls: 0.7131  decode.d0.loss_mask: 0.1943  decode.d0.loss_dice: 0.2046  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.1928  decode.d1.loss_dice: 0.2063  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.1920  decode.d2.loss_dice: 0.2050  decode.d3.loss_cls: 0.1006  decode.d3.loss_mask: 0.1900  decode.d3.loss_dice: 0.1734  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.1941  decode.d4.loss_dice: 0.2071  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.1925  decode.d5.loss_dice: 0.2183  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.1906  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.1904  decode.d7.loss_dice: 0.1916  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.1928  decode.d8.loss_dice: 0.2224
10/01 04:08:15 - mmengine - INFO - Iter(train) [156400/320000]  base_lr: 5.4673e-05 lr: 5.4673e-06  eta: 19:55:19  time: 0.4407  data_time: 0.0096  memory: 5129  grad_norm: 91.5332  loss: 6.3634  decode.loss_cls: 0.0906  decode.loss_mask: 0.2369  decode.loss_dice: 0.2031  decode.d0.loss_cls: 0.7555  decode.d0.loss_mask: 0.2463  decode.d0.loss_dice: 0.2082  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 0.2372  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.1680  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.2012  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.2054  decode.d5.loss_cls: 0.1378  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.2147  decode.d6.loss_cls: 0.1203  decode.d6.loss_mask: 0.2432  decode.d6.loss_dice: 0.2104  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.2382  decode.d7.loss_dice: 0.2012  decode.d8.loss_cls: 0.1134  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.2105
10/01 04:08:37 - mmengine - INFO - Iter(train) [156450/320000]  base_lr: 5.4658e-05 lr: 5.4658e-06  eta: 19:54:57  time: 0.4404  data_time: 0.0096  memory: 5129  grad_norm: 46.1465  loss: 5.5093  decode.loss_cls: 0.0554  decode.loss_mask: 0.2270  decode.loss_dice: 0.1769  decode.d0.loss_cls: 0.9308  decode.d0.loss_mask: 0.2303  decode.d0.loss_dice: 0.1882  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.2291  decode.d1.loss_dice: 0.1776  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.2245  decode.d2.loss_dice: 0.1797  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.2262  decode.d3.loss_dice: 0.1789  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.2275  decode.d4.loss_dice: 0.1813  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.2248  decode.d5.loss_dice: 0.1800  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.2259  decode.d6.loss_dice: 0.1870  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.2255  decode.d7.loss_dice: 0.1892  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.2241  decode.d8.loss_dice: 0.1792
10/01 04:08:59 - mmengine - INFO - Iter(train) [156500/320000]  base_lr: 5.4643e-05 lr: 5.4643e-06  eta: 19:54:35  time: 0.4419  data_time: 0.0096  memory: 5146  grad_norm: 39.3747  loss: 4.8409  decode.loss_cls: 0.0091  decode.loss_mask: 0.2065  decode.loss_dice: 0.1815  decode.d0.loss_cls: 0.8264  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.1878  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.2080  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.1893  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.2070  decode.d3.loss_dice: 0.1930  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.2069  decode.d4.loss_dice: 0.1869  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.2080  decode.d5.loss_dice: 0.1866  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.1848  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.1845  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2100  decode.d8.loss_dice: 0.1894
10/01 04:09:21 - mmengine - INFO - Iter(train) [156550/320000]  base_lr: 5.4628e-05 lr: 5.4628e-06  eta: 19:54:13  time: 0.4409  data_time: 0.0097  memory: 5129  grad_norm: 51.8818  loss: 6.1145  decode.loss_cls: 0.0871  decode.loss_mask: 0.1918  decode.loss_dice: 0.2642  decode.d0.loss_cls: 0.8121  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.1905  decode.d1.loss_dice: 0.2717  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.1891  decode.d2.loss_dice: 0.2592  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.1896  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.1873  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.2665  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.1884  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.1885  decode.d7.loss_dice: 0.2768  decode.d8.loss_cls: 0.0950  decode.d8.loss_mask: 0.1859  decode.d8.loss_dice: 0.2706
10/01 04:09:43 - mmengine - INFO - Iter(train) [156600/320000]  base_lr: 5.4613e-05 lr: 5.4613e-06  eta: 19:53:51  time: 0.4405  data_time: 0.0096  memory: 5129  grad_norm: 82.4327  loss: 6.6590  decode.loss_cls: 0.1096  decode.loss_mask: 0.2581  decode.loss_dice: 0.2175  decode.d0.loss_cls: 0.8375  decode.d0.loss_mask: 0.2600  decode.d0.loss_dice: 0.2194  decode.d1.loss_cls: 0.1596  decode.d1.loss_mask: 0.2608  decode.d1.loss_dice: 0.2125  decode.d2.loss_cls: 0.0978  decode.d2.loss_mask: 0.2620  decode.d2.loss_dice: 0.2172  decode.d3.loss_cls: 0.1349  decode.d3.loss_mask: 0.2585  decode.d3.loss_dice: 0.2077  decode.d4.loss_cls: 0.1224  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.2110  decode.d5.loss_cls: 0.1346  decode.d5.loss_mask: 0.2601  decode.d5.loss_dice: 0.2113  decode.d6.loss_cls: 0.0899  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.2131  decode.d7.loss_cls: 0.1125  decode.d7.loss_mask: 0.2574  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.1197  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.2202
10/01 04:10:05 - mmengine - INFO - Iter(train) [156650/320000]  base_lr: 5.4598e-05 lr: 5.4598e-06  eta: 19:53:30  time: 0.4438  data_time: 0.0097  memory: 5145  grad_norm: 50.5353  loss: 5.4618  decode.loss_cls: 0.1039  decode.loss_mask: 0.1879  decode.loss_dice: 0.1807  decode.d0.loss_cls: 0.9174  decode.d0.loss_mask: 0.1919  decode.d0.loss_dice: 0.1838  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.1904  decode.d1.loss_dice: 0.1986  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.1919  decode.d2.loss_dice: 0.2086  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 0.1919  decode.d3.loss_dice: 0.1776  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.1921  decode.d4.loss_dice: 0.2165  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.1919  decode.d5.loss_dice: 0.2054  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.1895  decode.d6.loss_dice: 0.1739  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.1966  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.1894  decode.d8.loss_dice: 0.1826
10/01 04:10:27 - mmengine - INFO - Iter(train) [156700/320000]  base_lr: 5.4583e-05 lr: 5.4583e-06  eta: 19:53:08  time: 0.4439  data_time: 0.0098  memory: 5145  grad_norm: 34.7194  loss: 4.2785  decode.loss_cls: 0.0050  decode.loss_mask: 0.1829  decode.loss_dice: 0.1449  decode.d0.loss_cls: 0.8926  decode.d0.loss_mask: 0.1845  decode.d0.loss_dice: 0.1489  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.1834  decode.d1.loss_dice: 0.1499  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.1840  decode.d2.loss_dice: 0.1461  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.1861  decode.d3.loss_dice: 0.1456  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.1861  decode.d4.loss_dice: 0.1466  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.1853  decode.d5.loss_dice: 0.1486  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.1866  decode.d6.loss_dice: 0.1472  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.1836  decode.d7.loss_dice: 0.1477  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.1495
10/01 04:10:49 - mmengine - INFO - Iter(train) [156750/320000]  base_lr: 5.4568e-05 lr: 5.4568e-06  eta: 19:52:46  time: 0.4450  data_time: 0.0098  memory: 5145  grad_norm: 23.0957  loss: 4.2184  decode.loss_cls: 0.0092  decode.loss_mask: 0.1582  decode.loss_dice: 0.1563  decode.d0.loss_cls: 0.9847  decode.d0.loss_mask: 0.1561  decode.d0.loss_dice: 0.1485  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.1588  decode.d1.loss_dice: 0.1585  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.1580  decode.d2.loss_dice: 0.1539  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.1572  decode.d3.loss_dice: 0.1547  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.1580  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.1603  decode.d5.loss_dice: 0.1560  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.1576  decode.d6.loss_dice: 0.1583  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.1583  decode.d7.loss_dice: 0.1538  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.1606  decode.d8.loss_dice: 0.1595
10/01 04:11:11 - mmengine - INFO - Iter(train) [156800/320000]  base_lr: 5.4552e-05 lr: 5.4552e-06  eta: 19:52:25  time: 0.4411  data_time: 0.0098  memory: 5129  grad_norm: 23.7721  loss: 4.3543  decode.loss_cls: 0.0035  decode.loss_mask: 0.1916  decode.loss_dice: 0.1461  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.1461  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.1913  decode.d1.loss_dice: 0.1533  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.1944  decode.d2.loss_dice: 0.1527  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1916  decode.d3.loss_dice: 0.1501  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1920  decode.d4.loss_dice: 0.1466  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.1931  decode.d5.loss_dice: 0.1549  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.1504  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.1927  decode.d7.loss_dice: 0.1513  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1894  decode.d8.loss_dice: 0.1468
10/01 04:11:33 - mmengine - INFO - Iter(train) [156850/320000]  base_lr: 5.4537e-05 lr: 5.4537e-06  eta: 19:52:03  time: 0.4441  data_time: 0.0097  memory: 5145  grad_norm: 29.4118  loss: 4.1883  decode.loss_cls: 0.0391  decode.loss_mask: 0.1438  decode.loss_dice: 0.1604  decode.d0.loss_cls: 0.7404  decode.d0.loss_mask: 0.1456  decode.d0.loss_dice: 0.1820  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.1415  decode.d1.loss_dice: 0.1543  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.1430  decode.d2.loss_dice: 0.1629  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.1416  decode.d3.loss_dice: 0.1612  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.1431  decode.d4.loss_dice: 0.1610  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.1413  decode.d5.loss_dice: 0.1589  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.1443  decode.d6.loss_dice: 0.1731  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.1427  decode.d7.loss_dice: 0.1578  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.1427  decode.d8.loss_dice: 0.1643
10/01 04:11:56 - mmengine - INFO - Iter(train) [156900/320000]  base_lr: 5.4522e-05 lr: 5.4522e-06  eta: 19:51:41  time: 0.4418  data_time: 0.0097  memory: 5146  grad_norm: 78.5705  loss: 5.1326  decode.loss_cls: 0.0822  decode.loss_mask: 0.1839  decode.loss_dice: 0.1537  decode.d0.loss_cls: 0.8984  decode.d0.loss_mask: 0.1854  decode.d0.loss_dice: 0.1593  decode.d1.loss_cls: 0.1679  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.1688  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.1854  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.1829  decode.d3.loss_dice: 0.1546  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.1862  decode.d4.loss_dice: 0.1614  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.1842  decode.d5.loss_dice: 0.1477  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.1871  decode.d6.loss_dice: 0.1690  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 0.1850  decode.d7.loss_dice: 0.1584  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 0.1861  decode.d8.loss_dice: 0.1751
10/01 04:12:18 - mmengine - INFO - Iter(train) [156950/320000]  base_lr: 5.4507e-05 lr: 5.4507e-06  eta: 19:51:19  time: 0.4438  data_time: 0.0097  memory: 5120  grad_norm: 23.7749  loss: 3.7790  decode.loss_cls: 0.0011  decode.loss_mask: 0.1627  decode.loss_dice: 0.1356  decode.d0.loss_cls: 0.7766  decode.d0.loss_mask: 0.1649  decode.d0.loss_dice: 0.1355  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.1622  decode.d1.loss_dice: 0.1355  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.1624  decode.d2.loss_dice: 0.1355  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.1632  decode.d3.loss_dice: 0.1352  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.1627  decode.d4.loss_dice: 0.1353  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1628  decode.d5.loss_dice: 0.1369  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.1657  decode.d6.loss_dice: 0.1368  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.1636  decode.d7.loss_dice: 0.1362  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1627  decode.d8.loss_dice: 0.1358
10/01 04:12:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:12:40 - mmengine - INFO - Iter(train) [157000/320000]  base_lr: 5.4492e-05 lr: 5.4492e-06  eta: 19:50:58  time: 0.4417  data_time: 0.0098  memory: 5145  grad_norm: 240.3073  loss: 4.4484  decode.loss_cls: 0.0096  decode.loss_mask: 0.1952  decode.loss_dice: 0.1566  decode.d0.loss_cls: 0.8932  decode.d0.loss_mask: 0.1990  decode.d0.loss_dice: 0.1541  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.1921  decode.d1.loss_dice: 0.1561  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.1926  decode.d2.loss_dice: 0.1546  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.1910  decode.d3.loss_dice: 0.1566  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.1870  decode.d4.loss_dice: 0.1484  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.1935  decode.d5.loss_dice: 0.1538  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.1894  decode.d6.loss_dice: 0.1493  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.1895  decode.d7.loss_dice: 0.1504  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.1924  decode.d8.loss_dice: 0.1522
10/01 04:13:02 - mmengine - INFO - Iter(train) [157050/320000]  base_lr: 5.4477e-05 lr: 5.4477e-06  eta: 19:50:36  time: 0.4421  data_time: 0.0098  memory: 5129  grad_norm: 38.6799  loss: 4.7582  decode.loss_cls: 0.0028  decode.loss_mask: 0.1845  decode.loss_dice: 0.1800  decode.d0.loss_cls: 0.9932  decode.d0.loss_mask: 0.1849  decode.d0.loss_dice: 0.1594  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.1848  decode.d1.loss_dice: 0.1901  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1864  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.1858  decode.d3.loss_dice: 0.1917  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.1859  decode.d4.loss_dice: 0.1797  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.1851  decode.d5.loss_dice: 0.1684  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1839  decode.d6.loss_dice: 0.1767  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.1853  decode.d7.loss_dice: 0.1870  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.1836  decode.d8.loss_dice: 0.1661
10/01 04:13:24 - mmengine - INFO - Iter(train) [157100/320000]  base_lr: 5.4462e-05 lr: 5.4462e-06  eta: 19:50:14  time: 0.4419  data_time: 0.0097  memory: 5120  grad_norm: 47.2836  loss: 5.0448  decode.loss_cls: 0.0820  decode.loss_mask: 0.1731  decode.loss_dice: 0.1438  decode.d0.loss_cls: 0.9915  decode.d0.loss_mask: 0.1754  decode.d0.loss_dice: 0.1482  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.1781  decode.d1.loss_dice: 0.1404  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.1711  decode.d2.loss_dice: 0.1382  decode.d3.loss_cls: 0.1009  decode.d3.loss_mask: 0.1739  decode.d3.loss_dice: 0.1471  decode.d4.loss_cls: 0.0973  decode.d4.loss_mask: 0.1728  decode.d4.loss_dice: 0.1432  decode.d5.loss_cls: 0.1046  decode.d5.loss_mask: 0.1756  decode.d5.loss_dice: 0.1438  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.1740  decode.d6.loss_dice: 0.1440  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 0.1721  decode.d7.loss_dice: 0.1430  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.1740  decode.d8.loss_dice: 0.1452
10/01 04:13:46 - mmengine - INFO - Iter(train) [157150/320000]  base_lr: 5.4447e-05 lr: 5.4447e-06  eta: 19:49:52  time: 0.4426  data_time: 0.0098  memory: 5145  grad_norm: 80.8862  loss: 7.3735  decode.loss_cls: 0.1566  decode.loss_mask: 0.2301  decode.loss_dice: 0.2498  decode.d0.loss_cls: 0.8403  decode.d0.loss_mask: 0.2332  decode.d0.loss_dice: 0.2590  decode.d1.loss_cls: 0.2250  decode.d1.loss_mask: 0.2270  decode.d1.loss_dice: 0.2397  decode.d2.loss_cls: 0.1411  decode.d2.loss_mask: 0.2258  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.2201  decode.d3.loss_mask: 0.2308  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.2190  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2267  decode.d5.loss_cls: 0.2271  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2294  decode.d6.loss_cls: 0.2552  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2257  decode.d7.loss_cls: 0.2300  decode.d7.loss_mask: 0.2261  decode.d7.loss_dice: 0.2254  decode.d8.loss_cls: 0.1807  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2385
10/01 04:14:08 - mmengine - INFO - Iter(train) [157200/320000]  base_lr: 5.4432e-05 lr: 5.4432e-06  eta: 19:49:31  time: 0.4421  data_time: 0.0099  memory: 5145  grad_norm: 57.3621  loss: 5.1531  decode.loss_cls: 0.0149  decode.loss_mask: 0.1774  decode.loss_dice: 0.2021  decode.d0.loss_cls: 0.9464  decode.d0.loss_mask: 0.1769  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.1768  decode.d1.loss_dice: 0.2021  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.1777  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.1751  decode.d3.loss_dice: 0.1878  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.1786  decode.d4.loss_dice: 0.1838  decode.d5.loss_cls: 0.1726  decode.d5.loss_mask: 0.1784  decode.d5.loss_dice: 0.2220  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.1743  decode.d6.loss_dice: 0.1805  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.1756  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.1758  decode.d8.loss_dice: 0.1834
10/01 04:14:30 - mmengine - INFO - Iter(train) [157250/320000]  base_lr: 5.4417e-05 lr: 5.4417e-06  eta: 19:49:09  time: 0.4417  data_time: 0.0097  memory: 5129  grad_norm: 38.4292  loss: 6.1213  decode.loss_cls: 0.1598  decode.loss_mask: 0.1783  decode.loss_dice: 0.1953  decode.d0.loss_cls: 0.9345  decode.d0.loss_mask: 0.1790  decode.d0.loss_dice: 0.2077  decode.d1.loss_cls: 0.1245  decode.d1.loss_mask: 0.1806  decode.d1.loss_dice: 0.1999  decode.d2.loss_cls: 0.1519  decode.d2.loss_mask: 0.1816  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.2023  decode.d3.loss_mask: 0.1778  decode.d3.loss_dice: 0.2109  decode.d4.loss_cls: 0.1660  decode.d4.loss_mask: 0.1775  decode.d4.loss_dice: 0.1993  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 0.1809  decode.d5.loss_dice: 0.1974  decode.d6.loss_cls: 0.1170  decode.d6.loss_mask: 0.1790  decode.d6.loss_dice: 0.2068  decode.d7.loss_cls: 0.1233  decode.d7.loss_mask: 0.1787  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.1345  decode.d8.loss_mask: 0.1815  decode.d8.loss_dice: 0.2072
10/01 04:14:53 - mmengine - INFO - Iter(train) [157300/320000]  base_lr: 5.4402e-05 lr: 5.4402e-06  eta: 19:48:47  time: 0.4421  data_time: 0.0099  memory: 5145  grad_norm: 75.8098  loss: 4.7553  decode.loss_cls: 0.0097  decode.loss_mask: 0.2209  decode.loss_dice: 0.1690  decode.d0.loss_cls: 0.7402  decode.d0.loss_mask: 0.2263  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.1805  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2231  decode.d2.loss_dice: 0.1753  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.2228  decode.d4.loss_dice: 0.1648  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.2236  decode.d5.loss_dice: 0.1758  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.2239  decode.d6.loss_dice: 0.1634  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.2220  decode.d7.loss_dice: 0.1658  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.2229  decode.d8.loss_dice: 0.1689
10/01 04:15:15 - mmengine - INFO - Iter(train) [157350/320000]  base_lr: 5.4387e-05 lr: 5.4387e-06  eta: 19:48:26  time: 0.4421  data_time: 0.0099  memory: 5120  grad_norm: 55.8499  loss: 4.2300  decode.loss_cls: 0.0017  decode.loss_mask: 0.2006  decode.loss_dice: 0.1522  decode.d0.loss_cls: 0.6703  decode.d0.loss_mask: 0.2056  decode.d0.loss_dice: 0.1563  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.2009  decode.d1.loss_dice: 0.1537  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.1970  decode.d2.loss_dice: 0.1504  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.1996  decode.d3.loss_dice: 0.1463  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1976  decode.d4.loss_dice: 0.1532  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.1994  decode.d5.loss_dice: 0.1535  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.2011  decode.d6.loss_dice: 0.1539  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.2007  decode.d7.loss_dice: 0.1562  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.2012  decode.d8.loss_dice: 0.1542
10/01 04:15:37 - mmengine - INFO - Iter(train) [157400/320000]  base_lr: 5.4372e-05 lr: 5.4372e-06  eta: 19:48:04  time: 0.4414  data_time: 0.0095  memory: 5129  grad_norm: 115.3312  loss: 5.8609  decode.loss_cls: 0.0836  decode.loss_mask: 0.2196  decode.loss_dice: 0.2258  decode.d0.loss_cls: 0.8090  decode.d0.loss_mask: 0.2180  decode.d0.loss_dice: 0.2193  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2068  decode.d2.loss_cls: 0.1446  decode.d2.loss_mask: 0.2233  decode.d2.loss_dice: 0.2010  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.0959  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2132  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.2246  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.2210  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.2204  decode.d8.loss_dice: 0.2301
10/01 04:15:59 - mmengine - INFO - Iter(train) [157450/320000]  base_lr: 5.4357e-05 lr: 5.4357e-06  eta: 19:47:42  time: 0.4420  data_time: 0.0096  memory: 5145  grad_norm: 58.5415  loss: 5.2143  decode.loss_cls: 0.0185  decode.loss_mask: 0.2281  decode.loss_dice: 0.1620  decode.d0.loss_cls: 1.0282  decode.d0.loss_mask: 0.2326  decode.d0.loss_dice: 0.1634  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.1603  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.1633  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.2322  decode.d3.loss_dice: 0.1654  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.2289  decode.d4.loss_dice: 0.1590  decode.d5.loss_cls: 0.0197  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.1623  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.1596  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.2319  decode.d8.loss_dice: 0.1623
10/01 04:16:21 - mmengine - INFO - Iter(train) [157500/320000]  base_lr: 5.4342e-05 lr: 5.4342e-06  eta: 19:47:20  time: 0.4410  data_time: 0.0094  memory: 5129  grad_norm: 91.9632  loss: 6.6881  decode.loss_cls: 0.0871  decode.loss_mask: 0.2192  decode.loss_dice: 0.2527  decode.d0.loss_cls: 0.9175  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.2553  decode.d1.loss_cls: 0.1635  decode.d1.loss_mask: 0.2199  decode.d1.loss_dice: 0.2313  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.2219  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.1424  decode.d3.loss_mask: 0.2215  decode.d3.loss_dice: 0.2297  decode.d4.loss_cls: 0.1221  decode.d4.loss_mask: 0.2184  decode.d4.loss_dice: 0.2446  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 0.2208  decode.d5.loss_dice: 0.2542  decode.d6.loss_cls: 0.1002  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.2520  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.2300  decode.d8.loss_cls: 0.0961  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.2618
10/01 04:16:43 - mmengine - INFO - Iter(train) [157550/320000]  base_lr: 5.4327e-05 lr: 5.4327e-06  eta: 19:46:59  time: 0.4421  data_time: 0.0099  memory: 5129  grad_norm: 51.7203  loss: 4.4320  decode.loss_cls: 0.0744  decode.loss_mask: 0.1773  decode.loss_dice: 0.1518  decode.d0.loss_cls: 0.7919  decode.d0.loss_mask: 0.1773  decode.d0.loss_dice: 0.1452  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.1784  decode.d1.loss_dice: 0.1370  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.1784  decode.d2.loss_dice: 0.1571  decode.d3.loss_cls: 0.0383  decode.d3.loss_mask: 0.1799  decode.d3.loss_dice: 0.1470  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.1784  decode.d4.loss_dice: 0.1302  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.1801  decode.d5.loss_dice: 0.1520  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.1790  decode.d6.loss_dice: 0.1303  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.1788  decode.d7.loss_dice: 0.1353  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.1799  decode.d8.loss_dice: 0.1365
10/01 04:17:05 - mmengine - INFO - Iter(train) [157600/320000]  base_lr: 5.4312e-05 lr: 5.4312e-06  eta: 19:46:37  time: 0.4420  data_time: 0.0096  memory: 5120  grad_norm: 96.7351  loss: 4.9083  decode.loss_cls: 0.0084  decode.loss_mask: 0.2098  decode.loss_dice: 0.1864  decode.d0.loss_cls: 0.8193  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.1825  decode.d1.loss_cls: 0.0180  decode.d1.loss_mask: 0.2133  decode.d1.loss_dice: 0.1980  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.1884  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.2100  decode.d3.loss_dice: 0.1978  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.2139  decode.d4.loss_dice: 0.1926  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.2061  decode.d5.loss_dice: 0.1839  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.2038  decode.d6.loss_dice: 0.1893  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.2053  decode.d7.loss_dice: 0.1813  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2067  decode.d8.loss_dice: 0.1874
10/01 04:17:27 - mmengine - INFO - Iter(train) [157650/320000]  base_lr: 5.4297e-05 lr: 5.4297e-06  eta: 19:46:15  time: 0.4402  data_time: 0.0095  memory: 5145  grad_norm: 80.1035  loss: 4.5680  decode.loss_cls: 0.0516  decode.loss_mask: 0.1683  decode.loss_dice: 0.1409  decode.d0.loss_cls: 0.9172  decode.d0.loss_mask: 0.1752  decode.d0.loss_dice: 0.1544  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.1706  decode.d1.loss_dice: 0.1507  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.1688  decode.d2.loss_dice: 0.1394  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.1676  decode.d3.loss_dice: 0.1538  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.1708  decode.d4.loss_dice: 0.1442  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.1698  decode.d5.loss_dice: 0.1459  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.1684  decode.d6.loss_dice: 0.1421  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.1690  decode.d7.loss_dice: 0.1478  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.1690  decode.d8.loss_dice: 0.1397
10/01 04:17:49 - mmengine - INFO - Iter(train) [157700/320000]  base_lr: 5.4282e-05 lr: 5.4282e-06  eta: 19:45:53  time: 0.4408  data_time: 0.0094  memory: 5120  grad_norm: 101.5983  loss: 6.2887  decode.loss_cls: 0.1184  decode.loss_mask: 0.1774  decode.loss_dice: 0.2343  decode.d0.loss_cls: 1.0356  decode.d0.loss_mask: 0.1795  decode.d0.loss_dice: 0.2450  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.1825  decode.d1.loss_dice: 0.2474  decode.d2.loss_cls: 0.1260  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.2264  decode.d3.loss_cls: 0.0992  decode.d3.loss_mask: 0.1804  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.1422  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.2358  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 0.1808  decode.d5.loss_dice: 0.2363  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 0.1828  decode.d6.loss_dice: 0.2568  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.1776  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 0.1784  decode.d8.loss_dice: 0.2403
10/01 04:18:11 - mmengine - INFO - Iter(train) [157750/320000]  base_lr: 5.4267e-05 lr: 5.4267e-06  eta: 19:45:32  time: 0.4405  data_time: 0.0095  memory: 5145  grad_norm: 52.9269  loss: 5.0191  decode.loss_cls: 0.0235  decode.loss_mask: 0.2040  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.8338  decode.d0.loss_mask: 0.2089  decode.d0.loss_dice: 0.1860  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1927  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.2031  decode.d2.loss_dice: 0.1858  decode.d3.loss_cls: 0.0309  decode.d3.loss_mask: 0.2049  decode.d3.loss_dice: 0.1837  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.2056  decode.d4.loss_dice: 0.1876  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.2049  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 0.2043  decode.d7.loss_dice: 0.1853  decode.d8.loss_cls: 0.0328  decode.d8.loss_mask: 0.2091  decode.d8.loss_dice: 0.1885
10/01 04:18:34 - mmengine - INFO - Iter(train) [157800/320000]  base_lr: 5.4252e-05 lr: 5.4252e-06  eta: 19:45:10  time: 0.4413  data_time: 0.0096  memory: 5129  grad_norm: 50.3048  loss: 5.7444  decode.loss_cls: 0.0198  decode.loss_mask: 0.2647  decode.loss_dice: 0.2088  decode.d0.loss_cls: 0.7979  decode.d0.loss_mask: 0.2653  decode.d0.loss_dice: 0.2068  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.2655  decode.d1.loss_dice: 0.1975  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.1886  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.2638  decode.d3.loss_dice: 0.1952  decode.d4.loss_cls: 0.1046  decode.d4.loss_mask: 0.2613  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.1964  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.2588  decode.d7.loss_dice: 0.1986  decode.d8.loss_cls: 0.0211  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.1965
10/01 04:18:56 - mmengine - INFO - Iter(train) [157850/320000]  base_lr: 5.4236e-05 lr: 5.4236e-06  eta: 19:44:48  time: 0.4411  data_time: 0.0097  memory: 5129  grad_norm: 60.0169  loss: 6.5901  decode.loss_cls: 0.1155  decode.loss_mask: 0.1946  decode.loss_dice: 0.2459  decode.d0.loss_cls: 0.8081  decode.d0.loss_mask: 0.1888  decode.d0.loss_dice: 0.2831  decode.d1.loss_cls: 0.1726  decode.d1.loss_mask: 0.1913  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 0.1943  decode.d2.loss_dice: 0.2556  decode.d3.loss_cls: 0.1621  decode.d3.loss_mask: 0.1901  decode.d3.loss_dice: 0.2509  decode.d4.loss_cls: 0.1427  decode.d4.loss_mask: 0.1961  decode.d4.loss_dice: 0.2500  decode.d5.loss_cls: 0.1560  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.1322  decode.d6.loss_mask: 0.1898  decode.d6.loss_dice: 0.2424  decode.d7.loss_cls: 0.1769  decode.d7.loss_mask: 0.1931  decode.d7.loss_dice: 0.2628  decode.d8.loss_cls: 0.1081  decode.d8.loss_mask: 0.1902  decode.d8.loss_dice: 0.2547
10/01 04:19:18 - mmengine - INFO - Iter(train) [157900/320000]  base_lr: 5.4221e-05 lr: 5.4221e-06  eta: 19:44:26  time: 0.4410  data_time: 0.0096  memory: 5129  grad_norm: 27.4755  loss: 4.3025  decode.loss_cls: 0.0009  decode.loss_mask: 0.1925  decode.loss_dice: 0.1459  decode.d0.loss_cls: 0.8376  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.1498  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.2002  decode.d1.loss_dice: 0.1490  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.1480  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1950  decode.d3.loss_dice: 0.1486  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.1955  decode.d4.loss_dice: 0.1496  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1965  decode.d5.loss_dice: 0.1504  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.1940  decode.d6.loss_dice: 0.1485  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.1950  decode.d7.loss_dice: 0.1479  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.1994  decode.d8.loss_dice: 0.1515
10/01 04:19:40 - mmengine - INFO - Iter(train) [157950/320000]  base_lr: 5.4206e-05 lr: 5.4206e-06  eta: 19:44:04  time: 0.4409  data_time: 0.0095  memory: 5129  grad_norm: 119.8575  loss: 4.8326  decode.loss_cls: 0.0027  decode.loss_mask: 0.2031  decode.loss_dice: 0.1810  decode.d0.loss_cls: 0.7835  decode.d0.loss_mask: 0.2042  decode.d0.loss_dice: 0.1761  decode.d1.loss_cls: 0.0909  decode.d1.loss_mask: 0.2072  decode.d1.loss_dice: 0.1852  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.2058  decode.d2.loss_dice: 0.1830  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.2060  decode.d3.loss_dice: 0.1819  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1891  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.2098  decode.d5.loss_dice: 0.1820  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.1752  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.1633  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2012  decode.d8.loss_dice: 0.1697
10/01 04:20:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:20:02 - mmengine - INFO - Iter(train) [158000/320000]  base_lr: 5.4191e-05 lr: 5.4191e-06  eta: 19:43:43  time: 0.4405  data_time: 0.0096  memory: 5120  grad_norm: 41.4458  loss: 6.0207  decode.loss_cls: 0.1012  decode.loss_mask: 0.2685  decode.loss_dice: 0.1807  decode.d0.loss_cls: 0.7806  decode.d0.loss_mask: 0.2716  decode.d0.loss_dice: 0.1680  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.2716  decode.d1.loss_dice: 0.1794  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.1832  decode.d3.loss_cls: 0.0982  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.1800  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.2693  decode.d4.loss_dice: 0.1782  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.2700  decode.d5.loss_dice: 0.1846  decode.d6.loss_cls: 0.1033  decode.d6.loss_mask: 0.2717  decode.d6.loss_dice: 0.1873  decode.d7.loss_cls: 0.1066  decode.d7.loss_mask: 0.2627  decode.d7.loss_dice: 0.1849  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.1749
10/01 04:20:24 - mmengine - INFO - Iter(train) [158050/320000]  base_lr: 5.4176e-05 lr: 5.4176e-06  eta: 19:43:21  time: 0.4419  data_time: 0.0096  memory: 5119  grad_norm: 32.3124  loss: 5.2237  decode.loss_cls: 0.0973  decode.loss_mask: 0.1561  decode.loss_dice: 0.2042  decode.d0.loss_cls: 0.8073  decode.d0.loss_mask: 0.1546  decode.d0.loss_dice: 0.2043  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.1567  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.1557  decode.d2.loss_dice: 0.2108  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.1558  decode.d3.loss_dice: 0.2020  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.1553  decode.d4.loss_dice: 0.1986  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.1577  decode.d5.loss_dice: 0.1908  decode.d6.loss_cls: 0.0831  decode.d6.loss_mask: 0.1559  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 0.1570  decode.d7.loss_dice: 0.2138  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.1592  decode.d8.loss_dice: 0.2169
10/01 04:20:46 - mmengine - INFO - Iter(train) [158100/320000]  base_lr: 5.4161e-05 lr: 5.4161e-06  eta: 19:42:59  time: 0.4419  data_time: 0.0097  memory: 5129  grad_norm: 44.4729  loss: 5.5540  decode.loss_cls: 0.0535  decode.loss_mask: 0.2280  decode.loss_dice: 0.1920  decode.d0.loss_cls: 0.8790  decode.d0.loss_mask: 0.2358  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.2298  decode.d1.loss_dice: 0.2129  decode.d2.loss_cls: 0.0490  decode.d2.loss_mask: 0.2308  decode.d2.loss_dice: 0.2005  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.2290  decode.d3.loss_dice: 0.1987  decode.d4.loss_cls: 0.0401  decode.d4.loss_mask: 0.2314  decode.d4.loss_dice: 0.1764  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.2332  decode.d5.loss_dice: 0.2025  decode.d6.loss_cls: 0.0408  decode.d6.loss_mask: 0.2286  decode.d6.loss_dice: 0.1727  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.1757  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.2300  decode.d8.loss_dice: 0.2023
10/01 04:21:08 - mmengine - INFO - Iter(train) [158150/320000]  base_lr: 5.4146e-05 lr: 5.4146e-06  eta: 19:42:38  time: 0.4412  data_time: 0.0094  memory: 5145  grad_norm: 55.5647  loss: 4.0566  decode.loss_cls: 0.0390  decode.loss_mask: 0.1576  decode.loss_dice: 0.1296  decode.d0.loss_cls: 0.7982  decode.d0.loss_mask: 0.1800  decode.d0.loss_dice: 0.1293  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.1689  decode.d1.loss_dice: 0.1344  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.1667  decode.d2.loss_dice: 0.1308  decode.d3.loss_cls: 0.0296  decode.d3.loss_mask: 0.1645  decode.d3.loss_dice: 0.1308  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.1635  decode.d4.loss_dice: 0.1302  decode.d5.loss_cls: 0.0376  decode.d5.loss_mask: 0.1637  decode.d5.loss_dice: 0.1318  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.1581  decode.d6.loss_dice: 0.1302  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 0.1589  decode.d7.loss_dice: 0.1285  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.1601  decode.d8.loss_dice: 0.1318
10/01 04:21:30 - mmengine - INFO - Iter(train) [158200/320000]  base_lr: 5.4131e-05 lr: 5.4131e-06  eta: 19:42:16  time: 0.4405  data_time: 0.0094  memory: 5129  grad_norm: 37.7133  loss: 4.3340  decode.loss_cls: 0.0030  decode.loss_mask: 0.1790  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.8124  decode.d0.loss_mask: 0.1793  decode.d0.loss_dice: 0.1607  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.1779  decode.d1.loss_dice: 0.1671  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.1811  decode.d2.loss_dice: 0.1769  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.1797  decode.d3.loss_dice: 0.1698  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.1797  decode.d4.loss_dice: 0.1767  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.1795  decode.d5.loss_dice: 0.1737  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.1785  decode.d6.loss_dice: 0.1701  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.1790  decode.d7.loss_dice: 0.1736  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.1772  decode.d8.loss_dice: 0.1667
10/01 04:21:53 - mmengine - INFO - Iter(train) [158250/320000]  base_lr: 5.4116e-05 lr: 5.4116e-06  eta: 19:41:54  time: 0.4410  data_time: 0.0094  memory: 5129  grad_norm: 105.3020  loss: 6.4021  decode.loss_cls: 0.2270  decode.loss_mask: 0.1825  decode.loss_dice: 0.2445  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 0.1790  decode.d0.loss_dice: 0.2285  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 0.1786  decode.d1.loss_dice: 0.2409  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.1813  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.1662  decode.d3.loss_mask: 0.1780  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.2198  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.1821  decode.d5.loss_dice: 0.2317  decode.d6.loss_cls: 0.1662  decode.d6.loss_mask: 0.1771  decode.d6.loss_dice: 0.2126  decode.d7.loss_cls: 0.1630  decode.d7.loss_mask: 0.1790  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 0.1793  decode.d8.loss_dice: 0.2465
10/01 04:22:15 - mmengine - INFO - Iter(train) [158300/320000]  base_lr: 5.4101e-05 lr: 5.4101e-06  eta: 19:41:32  time: 0.4418  data_time: 0.0094  memory: 5145  grad_norm: 156.8352  loss: 5.8138  decode.loss_cls: 0.0925  decode.loss_mask: 0.2393  decode.loss_dice: 0.2261  decode.d0.loss_cls: 0.7898  decode.d0.loss_mask: 0.2302  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.1889  decode.d2.loss_cls: 0.0806  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.1985  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.2198  decode.d3.loss_dice: 0.2197  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.2252  decode.d4.loss_dice: 0.1987  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.2234  decode.d5.loss_dice: 0.2000  decode.d6.loss_cls: 0.0819  decode.d6.loss_mask: 0.2265  decode.d6.loss_dice: 0.2094  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.2306  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.2259  decode.d8.loss_dice: 0.2185
10/01 04:22:37 - mmengine - INFO - Iter(train) [158350/320000]  base_lr: 5.4086e-05 lr: 5.4086e-06  eta: 19:41:11  time: 0.4425  data_time: 0.0097  memory: 5129  grad_norm: 40.5824  loss: 4.0456  decode.loss_cls: 0.0040  decode.loss_mask: 0.1845  decode.loss_dice: 0.1384  decode.d0.loss_cls: 0.7843  decode.d0.loss_mask: 0.1842  decode.d0.loss_dice: 0.1388  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.1839  decode.d1.loss_dice: 0.1393  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.1839  decode.d2.loss_dice: 0.1387  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.1871  decode.d3.loss_dice: 0.1414  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.1825  decode.d4.loss_dice: 0.1350  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.1837  decode.d5.loss_dice: 0.1372  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.1847  decode.d6.loss_dice: 0.1373  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.1839  decode.d7.loss_dice: 0.1357  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.1856  decode.d8.loss_dice: 0.1393
10/01 04:22:59 - mmengine - INFO - Iter(train) [158400/320000]  base_lr: 5.4071e-05 lr: 5.4071e-06  eta: 19:40:49  time: 0.4439  data_time: 0.0096  memory: 5129  grad_norm: 62.7014  loss: 4.9866  decode.loss_cls: 0.0858  decode.loss_mask: 0.1721  decode.loss_dice: 0.1798  decode.d0.loss_cls: 0.9118  decode.d0.loss_mask: 0.1732  decode.d0.loss_dice: 0.1634  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.1732  decode.d1.loss_dice: 0.1604  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.1716  decode.d2.loss_dice: 0.1461  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.1726  decode.d3.loss_dice: 0.1743  decode.d4.loss_cls: 0.0611  decode.d4.loss_mask: 0.1719  decode.d4.loss_dice: 0.1733  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.1709  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.1729  decode.d6.loss_dice: 0.1794  decode.d7.loss_cls: 0.0901  decode.d7.loss_mask: 0.1720  decode.d7.loss_dice: 0.1679  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.1701  decode.d8.loss_dice: 0.1707
10/01 04:23:21 - mmengine - INFO - Iter(train) [158450/320000]  base_lr: 5.4056e-05 lr: 5.4056e-06  eta: 19:40:27  time: 0.4417  data_time: 0.0097  memory: 5129  grad_norm: 27.8869  loss: 4.3407  decode.loss_cls: 0.0010  decode.loss_mask: 0.2020  decode.loss_dice: 0.1618  decode.d0.loss_cls: 0.6764  decode.d0.loss_mask: 0.2041  decode.d0.loss_dice: 0.1573  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.1631  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.2024  decode.d2.loss_dice: 0.1638  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2020  decode.d3.loss_dice: 0.1589  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.1651  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2059  decode.d5.loss_dice: 0.1640  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2009  decode.d6.loss_dice: 0.1611  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.1652  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2038  decode.d8.loss_dice: 0.1632
10/01 04:23:43 - mmengine - INFO - Iter(train) [158500/320000]  base_lr: 5.4041e-05 lr: 5.4041e-06  eta: 19:40:05  time: 0.4452  data_time: 0.0101  memory: 5129  grad_norm: 63.0268  loss: 4.2182  decode.loss_cls: 0.0105  decode.loss_mask: 0.1982  decode.loss_dice: 0.1306  decode.d0.loss_cls: 0.7767  decode.d0.loss_mask: 0.2002  decode.d0.loss_dice: 0.1287  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.1983  decode.d1.loss_dice: 0.1307  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.1956  decode.d2.loss_dice: 0.1315  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.1324  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.1942  decode.d4.loss_dice: 0.1300  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.1977  decode.d5.loss_dice: 0.1304  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.2005  decode.d6.loss_dice: 0.1320  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2002  decode.d7.loss_dice: 0.1326  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.1988  decode.d8.loss_dice: 0.1313
10/01 04:24:05 - mmengine - INFO - Iter(train) [158550/320000]  base_lr: 5.4026e-05 lr: 5.4026e-06  eta: 19:39:44  time: 0.4423  data_time: 0.0097  memory: 5145  grad_norm: 27.6065  loss: 4.3667  decode.loss_cls: 0.0016  decode.loss_mask: 0.1921  decode.loss_dice: 0.1672  decode.d0.loss_cls: 0.7222  decode.d0.loss_mask: 0.1911  decode.d0.loss_dice: 0.1655  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.1947  decode.d1.loss_dice: 0.1761  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.1935  decode.d2.loss_dice: 0.1714  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.1913  decode.d3.loss_dice: 0.1695  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.1919  decode.d4.loss_dice: 0.1909  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.1752  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.1919  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.1896  decode.d7.loss_dice: 0.1595  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1928  decode.d8.loss_dice: 0.1705
10/01 04:24:27 - mmengine - INFO - Iter(train) [158600/320000]  base_lr: 5.4011e-05 lr: 5.4011e-06  eta: 19:39:22  time: 0.4439  data_time: 0.0096  memory: 5129  grad_norm: 26.4087  loss: 4.4252  decode.loss_cls: 0.0074  decode.loss_mask: 0.2052  decode.loss_dice: 0.1475  decode.d0.loss_cls: 0.8389  decode.d0.loss_mask: 0.2106  decode.d0.loss_dice: 0.1557  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.2020  decode.d1.loss_dice: 0.1443  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.2025  decode.d2.loss_dice: 0.1465  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.1461  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.2036  decode.d4.loss_dice: 0.1460  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.2021  decode.d5.loss_dice: 0.1472  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.2030  decode.d6.loss_dice: 0.1457  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.1455  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.2047  decode.d8.loss_dice: 0.1450
10/01 04:24:49 - mmengine - INFO - Iter(train) [158650/320000]  base_lr: 5.3996e-05 lr: 5.3996e-06  eta: 19:39:00  time: 0.4415  data_time: 0.0095  memory: 5129  grad_norm: 53.3891  loss: 4.3838  decode.loss_cls: 0.0177  decode.loss_mask: 0.1903  decode.loss_dice: 0.1553  decode.d0.loss_cls: 0.7606  decode.d0.loss_mask: 0.1899  decode.d0.loss_dice: 0.1554  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.1935  decode.d1.loss_dice: 0.1546  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.1535  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.1883  decode.d3.loss_dice: 0.1559  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.1897  decode.d4.loss_dice: 0.1557  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.1545  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.1906  decode.d6.loss_dice: 0.1548  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.1886  decode.d7.loss_dice: 0.1534  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.1892  decode.d8.loss_dice: 0.1529
10/01 04:25:11 - mmengine - INFO - Iter(train) [158700/320000]  base_lr: 5.3981e-05 lr: 5.3981e-06  eta: 19:38:38  time: 0.4421  data_time: 0.0095  memory: 5129  grad_norm: 88.8441  loss: 6.3826  decode.loss_cls: 0.0223  decode.loss_mask: 0.3118  decode.loss_dice: 0.2144  decode.d0.loss_cls: 0.7395  decode.d0.loss_mask: 0.3284  decode.d0.loss_dice: 0.2164  decode.d1.loss_cls: 0.0606  decode.d1.loss_mask: 0.3160  decode.d1.loss_dice: 0.2140  decode.d2.loss_cls: 0.0410  decode.d2.loss_mask: 0.3150  decode.d2.loss_dice: 0.2134  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.3189  decode.d3.loss_dice: 0.2186  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.3127  decode.d4.loss_dice: 0.2192  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.2178  decode.d6.loss_cls: 0.0294  decode.d6.loss_mask: 0.3141  decode.d6.loss_dice: 0.2230  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.3113  decode.d7.loss_dice: 0.2125  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.3074  decode.d8.loss_dice: 0.2152
10/01 04:25:34 - mmengine - INFO - Iter(train) [158750/320000]  base_lr: 5.3965e-05 lr: 5.3965e-06  eta: 19:38:17  time: 0.4409  data_time: 0.0096  memory: 5129  grad_norm: 89.7422  loss: 4.7324  decode.loss_cls: 0.0245  decode.loss_mask: 0.2247  decode.loss_dice: 0.1609  decode.d0.loss_cls: 0.7186  decode.d0.loss_mask: 0.2221  decode.d0.loss_dice: 0.1590  decode.d1.loss_cls: 0.0261  decode.d1.loss_mask: 0.2251  decode.d1.loss_dice: 0.1623  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2215  decode.d2.loss_dice: 0.1671  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.1655  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.2192  decode.d4.loss_dice: 0.1617  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.1595  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.2215  decode.d6.loss_dice: 0.1616  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.2185  decode.d7.loss_dice: 0.1613  decode.d8.loss_cls: 0.0267  decode.d8.loss_mask: 0.2189  decode.d8.loss_dice: 0.1620
10/01 04:25:56 - mmengine - INFO - Iter(train) [158800/320000]  base_lr: 5.3950e-05 lr: 5.3950e-06  eta: 19:37:55  time: 0.4409  data_time: 0.0096  memory: 5120  grad_norm: 42.0928  loss: 4.7891  decode.loss_cls: 0.0764  decode.loss_mask: 0.1941  decode.loss_dice: 0.1540  decode.d0.loss_cls: 0.6924  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.1472  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.1560  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.1931  decode.d2.loss_dice: 0.1568  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.1581  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.1562  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.1550  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.1572  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.1890  decode.d7.loss_dice: 0.1526  decode.d8.loss_cls: 0.0816  decode.d8.loss_mask: 0.1935  decode.d8.loss_dice: 0.1555
10/01 04:26:18 - mmengine - INFO - Iter(train) [158850/320000]  base_lr: 5.3935e-05 lr: 5.3935e-06  eta: 19:37:33  time: 0.4410  data_time: 0.0097  memory: 5145  grad_norm: 49.6493  loss: 5.0423  decode.loss_cls: 0.0924  decode.loss_mask: 0.1701  decode.loss_dice: 0.1623  decode.d0.loss_cls: 0.8528  decode.d0.loss_mask: 0.1686  decode.d0.loss_dice: 0.1592  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.1695  decode.d1.loss_dice: 0.1489  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.1701  decode.d2.loss_dice: 0.1609  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.1706  decode.d3.loss_dice: 0.1574  decode.d4.loss_cls: 0.1378  decode.d4.loss_mask: 0.1683  decode.d4.loss_dice: 0.1527  decode.d5.loss_cls: 0.1367  decode.d5.loss_mask: 0.1696  decode.d5.loss_dice: 0.1663  decode.d6.loss_cls: 0.1444  decode.d6.loss_mask: 0.1691  decode.d6.loss_dice: 0.1523  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.1668  decode.d7.loss_dice: 0.1551  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.1694  decode.d8.loss_dice: 0.1463
10/01 04:26:40 - mmengine - INFO - Iter(train) [158900/320000]  base_lr: 5.3920e-05 lr: 5.3920e-06  eta: 19:37:11  time: 0.4405  data_time: 0.0095  memory: 5145  grad_norm: 88.5829  loss: 5.4199  decode.loss_cls: 0.0590  decode.loss_mask: 0.2207  decode.loss_dice: 0.2228  decode.d0.loss_cls: 0.6878  decode.d0.loss_mask: 0.2202  decode.d0.loss_dice: 0.2269  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.2190  decode.d1.loss_dice: 0.2293  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.2210  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.2166  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.2215  decode.d4.loss_dice: 0.2215  decode.d5.loss_cls: 0.0553  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2113  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.2169  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.2186  decode.d8.loss_dice: 0.2163
10/01 04:27:02 - mmengine - INFO - Iter(train) [158950/320000]  base_lr: 5.3905e-05 lr: 5.3905e-06  eta: 19:36:49  time: 0.4410  data_time: 0.0095  memory: 5129  grad_norm: 20.2132  loss: 4.6087  decode.loss_cls: 0.0166  decode.loss_mask: 0.1423  decode.loss_dice: 0.2277  decode.d0.loss_cls: 1.0345  decode.d0.loss_mask: 0.1445  decode.d0.loss_dice: 0.1980  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.1435  decode.d1.loss_dice: 0.2218  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.1436  decode.d2.loss_dice: 0.1746  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.1439  decode.d3.loss_dice: 0.2016  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.1428  decode.d4.loss_dice: 0.1923  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.1435  decode.d5.loss_dice: 0.1848  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.1426  decode.d6.loss_dice: 0.2344  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.1423  decode.d7.loss_dice: 0.1898  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.1457  decode.d8.loss_dice: 0.2070
10/01 04:27:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:27:24 - mmengine - INFO - Iter(train) [159000/320000]  base_lr: 5.3890e-05 lr: 5.3890e-06  eta: 19:36:28  time: 0.4415  data_time: 0.0095  memory: 5129  grad_norm: 89.2956  loss: 5.9089  decode.loss_cls: 0.1859  decode.loss_mask: 0.1730  decode.loss_dice: 0.1669  decode.d0.loss_cls: 0.8612  decode.d0.loss_mask: 0.1730  decode.d0.loss_dice: 0.1918  decode.d1.loss_cls: 0.1713  decode.d1.loss_mask: 0.1709  decode.d1.loss_dice: 0.1857  decode.d2.loss_cls: 0.1726  decode.d2.loss_mask: 0.1682  decode.d2.loss_dice: 0.1900  decode.d3.loss_cls: 0.1615  decode.d3.loss_mask: 0.1713  decode.d3.loss_dice: 0.1701  decode.d4.loss_cls: 0.1659  decode.d4.loss_mask: 0.1704  decode.d4.loss_dice: 0.1957  decode.d5.loss_cls: 0.1765  decode.d5.loss_mask: 0.1694  decode.d5.loss_dice: 0.1661  decode.d6.loss_cls: 0.1669  decode.d6.loss_mask: 0.1695  decode.d6.loss_dice: 0.1864  decode.d7.loss_cls: 0.1648  decode.d7.loss_mask: 0.1720  decode.d7.loss_dice: 0.1807  decode.d8.loss_cls: 0.1703  decode.d8.loss_mask: 0.1701  decode.d8.loss_dice: 0.1708
10/01 04:27:46 - mmengine - INFO - Iter(train) [159050/320000]  base_lr: 5.3875e-05 lr: 5.3875e-06  eta: 19:36:06  time: 0.4406  data_time: 0.0095  memory: 5129  grad_norm: 26.3873  loss: 3.8426  decode.loss_cls: 0.0057  decode.loss_mask: 0.1658  decode.loss_dice: 0.1290  decode.d0.loss_cls: 0.8255  decode.d0.loss_mask: 0.1698  decode.d0.loss_dice: 0.1289  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.1650  decode.d1.loss_dice: 0.1290  decode.d2.loss_cls: 0.0100  decode.d2.loss_mask: 0.1629  decode.d2.loss_dice: 0.1280  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.1667  decode.d3.loss_dice: 0.1306  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.1648  decode.d4.loss_dice: 0.1309  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.1656  decode.d5.loss_dice: 0.1291  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.1644  decode.d6.loss_dice: 0.1291  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1663  decode.d7.loss_dice: 0.1295  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.1652  decode.d8.loss_dice: 0.1268
10/01 04:28:08 - mmengine - INFO - Iter(train) [159100/320000]  base_lr: 5.3860e-05 lr: 5.3860e-06  eta: 19:35:44  time: 0.4419  data_time: 0.0096  memory: 5145  grad_norm: 21.8804  loss: 4.1869  decode.loss_cls: 0.0031  decode.loss_mask: 0.1797  decode.loss_dice: 0.1501  decode.d0.loss_cls: 0.8022  decode.d0.loss_mask: 0.1832  decode.d0.loss_dice: 0.1501  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.1792  decode.d1.loss_dice: 0.1542  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1840  decode.d2.loss_dice: 0.1569  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.1818  decode.d3.loss_dice: 0.1575  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.1824  decode.d4.loss_dice: 0.1615  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.1804  decode.d5.loss_dice: 0.1473  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.1824  decode.d6.loss_dice: 0.1586  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.1808  decode.d7.loss_dice: 0.1541  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.1826  decode.d8.loss_dice: 0.1522
10/01 04:28:30 - mmengine - INFO - Iter(train) [159150/320000]  base_lr: 5.3845e-05 lr: 5.3845e-06  eta: 19:35:22  time: 0.4425  data_time: 0.0100  memory: 5145  grad_norm: 34.2769  loss: 4.9210  decode.loss_cls: 0.0083  decode.loss_mask: 0.2300  decode.loss_dice: 0.1712  decode.d0.loss_cls: 0.7704  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.1755  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.1752  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.2326  decode.d2.loss_dice: 0.1702  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.2300  decode.d3.loss_dice: 0.1717  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.2292  decode.d4.loss_dice: 0.1718  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.2308  decode.d5.loss_dice: 0.1708  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2287  decode.d6.loss_dice: 0.1717  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.2298  decode.d7.loss_dice: 0.1735  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.1729
10/01 04:28:52 - mmengine - INFO - Iter(train) [159200/320000]  base_lr: 5.3830e-05 lr: 5.3830e-06  eta: 19:35:01  time: 0.4414  data_time: 0.0096  memory: 5129  grad_norm: 47.8145  loss: 4.0871  decode.loss_cls: 0.0023  decode.loss_mask: 0.1744  decode.loss_dice: 0.1552  decode.d0.loss_cls: 0.7544  decode.d0.loss_mask: 0.1736  decode.d0.loss_dice: 0.1639  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.1768  decode.d1.loss_dice: 0.1647  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.1756  decode.d2.loss_dice: 0.1577  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.1714  decode.d3.loss_dice: 0.1500  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1724  decode.d4.loss_dice: 0.1564  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.1729  decode.d5.loss_dice: 0.1564  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.1574  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.1741  decode.d7.loss_dice: 0.1605  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.1717  decode.d8.loss_dice: 0.1499
10/01 04:29:14 - mmengine - INFO - Iter(train) [159250/320000]  base_lr: 5.3815e-05 lr: 5.3815e-06  eta: 19:34:39  time: 0.4417  data_time: 0.0096  memory: 5129  grad_norm: 59.4356  loss: 6.1261  decode.loss_cls: 0.1459  decode.loss_mask: 0.1829  decode.loss_dice: 0.2319  decode.d0.loss_cls: 0.9013  decode.d0.loss_mask: 0.1825  decode.d0.loss_dice: 0.1990  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.1801  decode.d1.loss_dice: 0.2212  decode.d2.loss_cls: 0.1388  decode.d2.loss_mask: 0.1821  decode.d2.loss_dice: 0.2284  decode.d3.loss_cls: 0.1434  decode.d3.loss_mask: 0.1792  decode.d3.loss_dice: 0.2182  decode.d4.loss_cls: 0.1147  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.1794  decode.d5.loss_dice: 0.2304  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.1819  decode.d6.loss_dice: 0.2512  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.1797  decode.d7.loss_dice: 0.2450  decode.d8.loss_cls: 0.2070  decode.d8.loss_mask: 0.1798  decode.d8.loss_dice: 0.2095
10/01 04:29:37 - mmengine - INFO - Iter(train) [159300/320000]  base_lr: 5.3800e-05 lr: 5.3800e-06  eta: 19:34:17  time: 0.4411  data_time: 0.0095  memory: 5120  grad_norm: 48.4329  loss: 4.0764  decode.loss_cls: 0.0156  decode.loss_mask: 0.1625  decode.loss_dice: 0.1270  decode.d0.loss_cls: 0.8619  decode.d0.loss_mask: 0.2368  decode.d0.loss_dice: 0.1478  decode.d1.loss_cls: 0.0270  decode.d1.loss_mask: 0.1678  decode.d1.loss_dice: 0.1308  decode.d2.loss_cls: 0.0227  decode.d2.loss_mask: 0.1656  decode.d2.loss_dice: 0.1335  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.1669  decode.d3.loss_dice: 0.1300  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.1666  decode.d4.loss_dice: 0.1333  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.1648  decode.d5.loss_dice: 0.1331  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.1667  decode.d6.loss_dice: 0.1327  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.1658  decode.d7.loss_dice: 0.1334  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.1643  decode.d8.loss_dice: 0.1295
10/01 04:29:59 - mmengine - INFO - Iter(train) [159350/320000]  base_lr: 5.3785e-05 lr: 5.3785e-06  eta: 19:33:55  time: 0.4423  data_time: 0.0099  memory: 5120  grad_norm: 21.1072  loss: 3.8217  decode.loss_cls: 0.0010  decode.loss_mask: 0.1680  decode.loss_dice: 0.1356  decode.d0.loss_cls: 0.7718  decode.d0.loss_mask: 0.1687  decode.d0.loss_dice: 0.1339  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.1664  decode.d1.loss_dice: 0.1347  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1654  decode.d2.loss_dice: 0.1381  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.1679  decode.d3.loss_dice: 0.1348  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.1673  decode.d4.loss_dice: 0.1368  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.1684  decode.d5.loss_dice: 0.1377  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1695  decode.d6.loss_dice: 0.1408  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.1663  decode.d7.loss_dice: 0.1346  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.1687  decode.d8.loss_dice: 0.1358
10/01 04:30:21 - mmengine - INFO - Iter(train) [159400/320000]  base_lr: 5.3770e-05 lr: 5.3770e-06  eta: 19:33:34  time: 0.4424  data_time: 0.0096  memory: 5120  grad_norm: 22.6959  loss: 3.5692  decode.loss_cls: 0.0007  decode.loss_mask: 0.1371  decode.loss_dice: 0.1352  decode.d0.loss_cls: 0.8719  decode.d0.loss_mask: 0.1347  decode.d0.loss_dice: 0.1314  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.1371  decode.d1.loss_dice: 0.1319  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.1368  decode.d2.loss_dice: 0.1310  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.1373  decode.d3.loss_dice: 0.1307  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.1370  decode.d4.loss_dice: 0.1321  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1375  decode.d5.loss_dice: 0.1312  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.1349  decode.d6.loss_dice: 0.1314  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1382  decode.d7.loss_dice: 0.1328  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.1377  decode.d8.loss_dice: 0.1323
10/01 04:30:43 - mmengine - INFO - Iter(train) [159450/320000]  base_lr: 5.3755e-05 lr: 5.3755e-06  eta: 19:33:12  time: 0.4425  data_time: 0.0096  memory: 5129  grad_norm: 49.1819  loss: 4.8005  decode.loss_cls: 0.0223  decode.loss_mask: 0.1878  decode.loss_dice: 0.1807  decode.d0.loss_cls: 0.8827  decode.d0.loss_mask: 0.1855  decode.d0.loss_dice: 0.1614  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.1897  decode.d1.loss_dice: 0.1740  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.1854  decode.d2.loss_dice: 0.1618  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.1871  decode.d3.loss_dice: 0.1664  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.1862  decode.d4.loss_dice: 0.1635  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.1878  decode.d5.loss_dice: 0.1666  decode.d6.loss_cls: 0.0273  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.1678  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.1858  decode.d7.loss_dice: 0.1674  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.1874  decode.d8.loss_dice: 0.1649
10/01 04:31:05 - mmengine - INFO - Iter(train) [159500/320000]  base_lr: 5.3740e-05 lr: 5.3740e-06  eta: 19:32:50  time: 0.4430  data_time: 0.0095  memory: 5129  grad_norm: 57.5660  loss: 5.9706  decode.loss_cls: 0.1127  decode.loss_mask: 0.1821  decode.loss_dice: 0.2180  decode.d0.loss_cls: 0.8639  decode.d0.loss_mask: 0.1837  decode.d0.loss_dice: 0.2270  decode.d1.loss_cls: 0.1183  decode.d1.loss_mask: 0.1813  decode.d1.loss_dice: 0.2160  decode.d2.loss_cls: 0.1223  decode.d2.loss_mask: 0.1824  decode.d2.loss_dice: 0.2117  decode.d3.loss_cls: 0.1029  decode.d3.loss_mask: 0.1815  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.1214  decode.d4.loss_mask: 0.1791  decode.d4.loss_dice: 0.2181  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.1838  decode.d5.loss_dice: 0.2176  decode.d6.loss_cls: 0.0870  decode.d6.loss_mask: 0.1824  decode.d6.loss_dice: 0.2040  decode.d7.loss_cls: 0.1410  decode.d7.loss_mask: 0.1819  decode.d7.loss_dice: 0.2267  decode.d8.loss_cls: 0.1348  decode.d8.loss_mask: 0.1805  decode.d8.loss_dice: 0.2328
10/01 04:31:27 - mmengine - INFO - Iter(train) [159550/320000]  base_lr: 5.3724e-05 lr: 5.3724e-06  eta: 19:32:29  time: 0.4430  data_time: 0.0096  memory: 5120  grad_norm: 47.9164  loss: 4.5597  decode.loss_cls: 0.0467  decode.loss_mask: 0.1450  decode.loss_dice: 0.1836  decode.d0.loss_cls: 0.8328  decode.d0.loss_mask: 0.1464  decode.d0.loss_dice: 0.2068  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.1448  decode.d1.loss_dice: 0.1794  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.1460  decode.d2.loss_dice: 0.1819  decode.d3.loss_cls: 0.0384  decode.d3.loss_mask: 0.1450  decode.d3.loss_dice: 0.1818  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.1461  decode.d4.loss_dice: 0.1840  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.1443  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.1483  decode.d6.loss_dice: 0.1912  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.1471  decode.d7.loss_dice: 0.1829  decode.d8.loss_cls: 0.0452  decode.d8.loss_mask: 0.1465  decode.d8.loss_dice: 0.1818
10/01 04:31:50 - mmengine - INFO - Iter(train) [159600/320000]  base_lr: 5.3709e-05 lr: 5.3709e-06  eta: 19:32:07  time: 0.4431  data_time: 0.0096  memory: 5129  grad_norm: 31.2568  loss: 4.1652  decode.loss_cls: 0.0060  decode.loss_mask: 0.1766  decode.loss_dice: 0.1486  decode.d0.loss_cls: 0.7908  decode.d0.loss_mask: 0.1783  decode.d0.loss_dice: 0.1498  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.1783  decode.d1.loss_dice: 0.1592  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.1785  decode.d2.loss_dice: 0.1529  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.1791  decode.d3.loss_dice: 0.1560  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.1791  decode.d4.loss_dice: 0.1578  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.1768  decode.d5.loss_dice: 0.1494  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.1782  decode.d6.loss_dice: 0.1543  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1762  decode.d7.loss_dice: 0.1534  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.1770  decode.d8.loss_dice: 0.1540
10/01 04:32:12 - mmengine - INFO - Iter(train) [159650/320000]  base_lr: 5.3694e-05 lr: 5.3694e-06  eta: 19:31:45  time: 0.4442  data_time: 0.0097  memory: 5129  grad_norm: 98.0766  loss: 5.1163  decode.loss_cls: 0.0063  decode.loss_mask: 0.2171  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.9057  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.1657  decode.d1.loss_cls: 0.1056  decode.d1.loss_mask: 0.2180  decode.d1.loss_dice: 0.1699  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2160  decode.d2.loss_dice: 0.1705  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.2171  decode.d3.loss_dice: 0.1739  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2220  decode.d4.loss_dice: 0.1897  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.2198  decode.d5.loss_dice: 0.1866  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.2209  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.1856  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.1773
10/01 04:32:34 - mmengine - INFO - Iter(train) [159700/320000]  base_lr: 5.3679e-05 lr: 5.3679e-06  eta: 19:31:24  time: 0.4422  data_time: 0.0097  memory: 5129  grad_norm: 94.4662  loss: 6.7951  decode.loss_cls: 0.1819  decode.loss_mask: 0.1973  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.8622  decode.d0.loss_mask: 0.1994  decode.d0.loss_dice: 0.2253  decode.d1.loss_cls: 0.1862  decode.d1.loss_mask: 0.1977  decode.d1.loss_dice: 0.2408  decode.d2.loss_cls: 0.1593  decode.d2.loss_mask: 0.1961  decode.d2.loss_dice: 0.2297  decode.d3.loss_cls: 0.1786  decode.d3.loss_mask: 0.1961  decode.d3.loss_dice: 0.2343  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.1976  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.1692  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.2451  decode.d6.loss_cls: 0.2335  decode.d6.loss_mask: 0.1962  decode.d6.loss_dice: 0.2441  decode.d7.loss_cls: 0.1861  decode.d7.loss_mask: 0.1951  decode.d7.loss_dice: 0.2240  decode.d8.loss_cls: 0.1597  decode.d8.loss_mask: 0.1968  decode.d8.loss_dice: 0.2229
10/01 04:32:56 - mmengine - INFO - Iter(train) [159750/320000]  base_lr: 5.3664e-05 lr: 5.3664e-06  eta: 19:31:02  time: 0.4419  data_time: 0.0095  memory: 5145  grad_norm: 67.1015  loss: 4.8073  decode.loss_cls: 0.0485  decode.loss_mask: 0.2063  decode.loss_dice: 0.1621  decode.d0.loss_cls: 0.7752  decode.d0.loss_mask: 0.2094  decode.d0.loss_dice: 0.1662  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.2072  decode.d1.loss_dice: 0.1607  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.2057  decode.d2.loss_dice: 0.1607  decode.d3.loss_cls: 0.0404  decode.d3.loss_mask: 0.2058  decode.d3.loss_dice: 0.1570  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.2034  decode.d4.loss_dice: 0.1574  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.2040  decode.d5.loss_dice: 0.1569  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.2056  decode.d6.loss_dice: 0.1583  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.2030  decode.d7.loss_dice: 0.1582  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.2060  decode.d8.loss_dice: 0.1594
10/01 04:33:18 - mmengine - INFO - Iter(train) [159800/320000]  base_lr: 5.3649e-05 lr: 5.3649e-06  eta: 19:30:40  time: 0.4405  data_time: 0.0095  memory: 5120  grad_norm: 110.0124  loss: 5.1055  decode.loss_cls: 0.0184  decode.loss_mask: 0.2385  decode.loss_dice: 0.1782  decode.d0.loss_cls: 0.6932  decode.d0.loss_mask: 0.2464  decode.d0.loss_dice: 0.1802  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.2391  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.1797  decode.d3.loss_cls: 0.0185  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.1864  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.2389  decode.d4.loss_dice: 0.1777  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.1879  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.1916
10/01 04:33:40 - mmengine - INFO - Iter(train) [159850/320000]  base_lr: 5.3634e-05 lr: 5.3634e-06  eta: 19:30:18  time: 0.4419  data_time: 0.0096  memory: 5129  grad_norm: 71.4701  loss: 5.0932  decode.loss_cls: 0.0432  decode.loss_mask: 0.2191  decode.loss_dice: 0.1588  decode.d0.loss_cls: 0.7932  decode.d0.loss_mask: 0.2245  decode.d0.loss_dice: 0.1574  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.2182  decode.d1.loss_dice: 0.1591  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.1569  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2205  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.1579  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.1611  decode.d6.loss_cls: 0.0543  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1541  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.2214  decode.d7.loss_dice: 0.1507  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.1560
10/01 04:34:02 - mmengine - INFO - Iter(train) [159900/320000]  base_lr: 5.3619e-05 lr: 5.3619e-06  eta: 19:29:57  time: 0.4411  data_time: 0.0095  memory: 5129  grad_norm: 26.3586  loss: 4.1825  decode.loss_cls: 0.0017  decode.loss_mask: 0.1894  decode.loss_dice: 0.1486  decode.d0.loss_cls: 0.8273  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.1429  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.1875  decode.d1.loss_dice: 0.1420  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.1882  decode.d2.loss_dice: 0.1482  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1862  decode.d3.loss_dice: 0.1435  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.1889  decode.d4.loss_dice: 0.1463  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.1879  decode.d5.loss_dice: 0.1482  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1885  decode.d6.loss_dice: 0.1476  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1854  decode.d7.loss_dice: 0.1447  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.1881  decode.d8.loss_dice: 0.1502
10/01 04:34:25 - mmengine - INFO - Iter(train) [159950/320000]  base_lr: 5.3604e-05 lr: 5.3604e-06  eta: 19:29:35  time: 0.4414  data_time: 0.0095  memory: 5145  grad_norm: 117.3030  loss: 5.5048  decode.loss_cls: 0.1016  decode.loss_mask: 0.1865  decode.loss_dice: 0.1597  decode.d0.loss_cls: 0.8362  decode.d0.loss_mask: 0.1861  decode.d0.loss_dice: 0.1697  decode.d1.loss_cls: 0.2198  decode.d1.loss_mask: 0.1799  decode.d1.loss_dice: 0.1646  decode.d2.loss_cls: 0.1616  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.1651  decode.d3.loss_cls: 0.1218  decode.d3.loss_mask: 0.1864  decode.d3.loss_dice: 0.1596  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 0.1880  decode.d4.loss_dice: 0.1596  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.1481  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.1887  decode.d6.loss_dice: 0.1521  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.1744  decode.d8.loss_cls: 0.0997  decode.d8.loss_mask: 0.1890  decode.d8.loss_dice: 0.1678
10/01 04:34:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:34:47 - mmengine - INFO - Iter(train) [160000/320000]  base_lr: 5.3589e-05 lr: 5.3589e-06  eta: 19:29:13  time: 0.4410  data_time: 0.0094  memory: 5120  grad_norm: 70.4407  loss: 5.8374  decode.loss_cls: 0.0595  decode.loss_mask: 0.2480  decode.loss_dice: 0.2157  decode.d0.loss_cls: 0.9332  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.2156  decode.d1.loss_cls: 0.0890  decode.d1.loss_mask: 0.2084  decode.d1.loss_dice: 0.2165  decode.d2.loss_cls: 0.0315  decode.d2.loss_mask: 0.2064  decode.d2.loss_dice: 0.2093  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.2110  decode.d3.loss_dice: 0.2148  decode.d4.loss_cls: 0.0393  decode.d4.loss_mask: 0.2114  decode.d4.loss_dice: 0.2201  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.2227  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2246  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2354  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.2344  decode.d8.loss_dice: 0.2211
10/01 04:34:47 - mmengine - INFO - Saving checkpoint at 160000 iterations
10/01 04:34:57 - mmengine - INFO - Iter(val) [ 50/206]    eta: 0:00:25  time: 0.1766  data_time: 0.0045  memory: 2997  
10/01 04:35:06 - mmengine - INFO - Iter(val) [100/206]    eta: 0:00:17  time: 0.1768  data_time: 0.0044  memory: 2997  
10/01 04:35:15 - mmengine - INFO - Iter(val) [150/206]    eta: 0:00:09  time: 0.1769  data_time: 0.0044  memory: 2997  
10/01 04:35:24 - mmengine - INFO - Iter(val) [200/206]    eta: 0:00:01  time: 0.1756  data_time: 0.0040  memory: 2997  
10/01 04:35:25 - mmengine - INFO - per class results:
10/01 04:35:25 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|      background     | 98.77 | 99.38 |
|   beetroot-poriyal  | 98.04 |  98.9 |
|        bhindi       | 94.58 | 98.27 |
| capsicum-green-peas | 95.92 | 98.72 |
|     dosakay-dal     | 82.35 |  92.5 |
|    dosakaya-curry   | 64.04 | 98.06 |
|    jaipuri-sabji    | 97.57 | 98.35 |
|  ladiesfinger-curry | 97.71 | 98.82 |
|    lobiya-masala    | 95.78 | 99.15 |
|        pongal       | 95.31 | 97.36 |
|    pumpkin-gravy    | 98.36 | 99.09 |
|     pumpkin-dry     | 95.12 | 96.45 |
|     rajma-masala    | 97.94 | 98.68 |
|      tomato-dal     | 89.84 | 90.76 |
|     turai-moong     | 91.67 |  99.2 |
|     turai-tomato    | 96.45 | 98.25 |
|    beerakay-curry   | 97.46 | 98.46 |
|   cabbage-poriyal   | 97.46 | 98.55 |
|    capsicum-gravy   | 97.79 | 98.77 |
|     chana-masala    | 96.69 | 98.39 |
|      chow-chow      | 97.11 | 98.47 |
|       chutney       | 88.67 | 89.65 |
|      curd-rice      | 95.21 | 98.28 |
|         dal         | 92.72 | 93.67 |
|      dal-tadka      | 97.27 | 98.57 |
|        daliya       | 97.87 | 99.12 |
|     daliya-upma     | 97.01 | 98.24 |
|     donda-curry     | 97.47 | 98.22 |
|    dosakaya-gravy   | 95.86 | 97.62 |
|      egg-white      | 90.17 | 94.61 |
|         idly        | 95.97 | 97.68 |
|       khichdi       | 94.91 |  98.1 |
| ladies-finger-gravy | 97.62 | 98.46 |
|      methi-dal      | 97.53 | 98.52 |
|  mixed-veg-poriyal  | 95.21 | 97.09 |
|   palak-soya-curry  | 96.69 | 97.69 |
|     paneer-gravy    | 97.32 | 98.19 |
|         poha        | 95.33 |  96.1 |
|    pumpkin-masala   | 92.82 | 98.13 |
|    raw-banana-dry   | 96.65 | 97.71 |
|         rice        | 96.23 | 98.22 |
|         roti        | 95.68 | 98.93 |
|        sambar       | 89.76 | 90.79 |
|    snakegourd-dry   |  0.0  |  0.0  |
|   snakeguard-curry  | 97.71 | 98.61 |
|      soya-gravy     | 97.62 | 98.68 |
|   thotakura-pappu   | 96.85 | 98.47 |
|         upma        | 95.65 | 97.98 |
|       uttapam       |  0.0  |  0.0  |
+---------------------+-------+-------+
10/01 04:35:25 - mmengine - INFO - Iter(val) [206/206]    aAcc: 98.8800  mIoU: 90.9800  mAcc: 93.5100  data_time: 0.0046  time: 0.1731
10/01 04:35:47 - mmengine - INFO - Iter(train) [160050/320000]  base_lr: 5.3574e-05 lr: 5.3574e-06  eta: 19:28:52  time: 0.4628  data_time: 0.0096  memory: 5129  grad_norm: 33.7008  loss: 4.2939  decode.loss_cls: 0.0135  decode.loss_mask: 0.1670  decode.loss_dice: 0.1610  decode.d0.loss_cls: 0.8221  decode.d0.loss_mask: 0.1703  decode.d0.loss_dice: 0.1683  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.1714  decode.d1.loss_dice: 0.1602  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.1679  decode.d2.loss_dice: 0.1686  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.1704  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.1681  decode.d4.loss_dice: 0.1643  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.1710  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.1704  decode.d6.loss_dice: 0.1682  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.1694  decode.d7.loss_dice: 0.1631  decode.d8.loss_cls: 0.0149  decode.d8.loss_mask: 0.1712  decode.d8.loss_dice: 0.1623
10/01 04:36:09 - mmengine - INFO - Iter(train) [160100/320000]  base_lr: 5.3559e-05 lr: 5.3559e-06  eta: 19:28:30  time: 0.4404  data_time: 0.0097  memory: 5145  grad_norm: 36.2993  loss: 4.4830  decode.loss_cls: 0.0071  decode.loss_mask: 0.2137  decode.loss_dice: 0.1484  decode.d0.loss_cls: 0.8116  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.1462  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.2112  decode.d1.loss_dice: 0.1492  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1459  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.2109  decode.d3.loss_dice: 0.1473  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.2145  decode.d4.loss_dice: 0.1498  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1499  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2127  decode.d6.loss_dice: 0.1472  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2159  decode.d7.loss_dice: 0.1499  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.2148  decode.d8.loss_dice: 0.1501
10/01 04:36:31 - mmengine - INFO - Iter(train) [160150/320000]  base_lr: 5.3544e-05 lr: 5.3544e-06  eta: 19:28:08  time: 0.4415  data_time: 0.0096  memory: 5145  grad_norm: 45.4093  loss: 4.6871  decode.loss_cls: 0.0583  decode.loss_mask: 0.1871  decode.loss_dice: 0.1761  decode.d0.loss_cls: 0.7735  decode.d0.loss_mask: 0.1890  decode.d0.loss_dice: 0.1787  decode.d1.loss_cls: 0.0190  decode.d1.loss_mask: 0.1873  decode.d1.loss_dice: 0.1701  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.1884  decode.d2.loss_dice: 0.1708  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.1884  decode.d3.loss_dice: 0.1702  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.1879  decode.d4.loss_dice: 0.1731  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.1867  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.1851  decode.d6.loss_dice: 0.1823  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.1874  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.1864  decode.d8.loss_dice: 0.1742
10/01 04:36:53 - mmengine - INFO - Iter(train) [160200/320000]  base_lr: 5.3529e-05 lr: 5.3529e-06  eta: 19:27:46  time: 0.4409  data_time: 0.0099  memory: 5129  grad_norm: 48.2530  loss: 4.7426  decode.loss_cls: 0.0354  decode.loss_mask: 0.1982  decode.loss_dice: 0.1613  decode.d0.loss_cls: 0.7432  decode.d0.loss_mask: 0.1942  decode.d0.loss_dice: 0.1645  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.1555  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.1976  decode.d2.loss_dice: 0.1636  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.1973  decode.d3.loss_dice: 0.1650  decode.d4.loss_cls: 0.0377  decode.d4.loss_mask: 0.2016  decode.d4.loss_dice: 0.1560  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.2015  decode.d5.loss_dice: 0.1623  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1546  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.2001  decode.d7.loss_dice: 0.1612  decode.d8.loss_cls: 0.0474  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.1661
10/01 04:37:15 - mmengine - INFO - Iter(train) [160250/320000]  base_lr: 5.3513e-05 lr: 5.3513e-06  eta: 19:27:25  time: 0.4411  data_time: 0.0098  memory: 5145  grad_norm: 98.0410  loss: 4.8305  decode.loss_cls: 0.0482  decode.loss_mask: 0.2143  decode.loss_dice: 0.1586  decode.d0.loss_cls: 0.6360  decode.d0.loss_mask: 0.2179  decode.d0.loss_dice: 0.1615  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.2154  decode.d1.loss_dice: 0.1654  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.2124  decode.d2.loss_dice: 0.1619  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.1626  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.1588  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.2132  decode.d5.loss_dice: 0.1588  decode.d6.loss_cls: 0.0313  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.1581  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.2136  decode.d7.loss_dice: 0.1643  decode.d8.loss_cls: 0.0970  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.1618
10/01 04:37:37 - mmengine - INFO - Iter(train) [160300/320000]  base_lr: 5.3498e-05 lr: 5.3498e-06  eta: 19:27:03  time: 0.4410  data_time: 0.0096  memory: 5120  grad_norm: 50.7113  loss: 5.9435  decode.loss_cls: 0.0884  decode.loss_mask: 0.1913  decode.loss_dice: 0.2441  decode.d0.loss_cls: 0.9672  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.2275  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.1916  decode.d1.loss_dice: 0.2406  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 0.1897  decode.d2.loss_dice: 0.2379  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.1904  decode.d3.loss_dice: 0.2486  decode.d4.loss_cls: 0.0799  decode.d4.loss_mask: 0.1902  decode.d4.loss_dice: 0.2303  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.1909  decode.d5.loss_dice: 0.2338  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.1900  decode.d6.loss_dice: 0.2343  decode.d7.loss_cls: 0.0952  decode.d7.loss_mask: 0.1902  decode.d7.loss_dice: 0.2329  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.1920  decode.d8.loss_dice: 0.2367
10/01 04:37:59 - mmengine - INFO - Iter(train) [160350/320000]  base_lr: 5.3483e-05 lr: 5.3483e-06  eta: 19:26:41  time: 0.4408  data_time: 0.0097  memory: 5120  grad_norm: 33.5643  loss: 5.3785  decode.loss_cls: 0.0116  decode.loss_mask: 0.2263  decode.loss_dice: 0.2123  decode.d0.loss_cls: 0.8963  decode.d0.loss_mask: 0.2232  decode.d0.loss_dice: 0.1977  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.2249  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2213  decode.d2.loss_dice: 0.2137  decode.d3.loss_cls: 0.0265  decode.d3.loss_mask: 0.2262  decode.d3.loss_dice: 0.2153  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2150  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2088  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.2267  decode.d7.loss_dice: 0.2194  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.2263  decode.d8.loss_dice: 0.2158
10/01 04:38:22 - mmengine - INFO - Iter(train) [160400/320000]  base_lr: 5.3468e-05 lr: 5.3468e-06  eta: 19:26:19  time: 0.4418  data_time: 0.0097  memory: 5129  grad_norm: 61.0469  loss: 5.3128  decode.loss_cls: 0.0091  decode.loss_mask: 0.2456  decode.loss_dice: 0.2098  decode.d0.loss_cls: 0.7011  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2147  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.2440  decode.d1.loss_dice: 0.2082  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.2454  decode.d2.loss_dice: 0.2015  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.2469  decode.d3.loss_dice: 0.2079  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2421  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2442  decode.d5.loss_dice: 0.2073  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2074  decode.d7.loss_cls: 0.0125  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2107  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2045
10/01 04:38:44 - mmengine - INFO - Iter(train) [160450/320000]  base_lr: 5.3453e-05 lr: 5.3453e-06  eta: 19:25:57  time: 0.4415  data_time: 0.0097  memory: 5129  grad_norm: 83.0388  loss: 7.3403  decode.loss_cls: 0.1463  decode.loss_mask: 0.1958  decode.loss_dice: 0.2982  decode.d0.loss_cls: 0.9462  decode.d0.loss_mask: 0.1918  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.1953  decode.d1.loss_dice: 0.2753  decode.d2.loss_cls: 0.2712  decode.d2.loss_mask: 0.1938  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.2105  decode.d3.loss_mask: 0.1927  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.2484  decode.d4.loss_mask: 0.1936  decode.d4.loss_dice: 0.2514  decode.d5.loss_cls: 0.1861  decode.d5.loss_mask: 0.1948  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.1929  decode.d6.loss_dice: 0.2550  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.1973  decode.d7.loss_dice: 0.2860  decode.d8.loss_cls: 0.1617  decode.d8.loss_mask: 0.1921  decode.d8.loss_dice: 0.2631
10/01 04:39:06 - mmengine - INFO - Iter(train) [160500/320000]  base_lr: 5.3438e-05 lr: 5.3438e-06  eta: 19:25:36  time: 0.4440  data_time: 0.0096  memory: 5129  grad_norm: 51.5177  loss: 5.0974  decode.loss_cls: 0.0551  decode.loss_mask: 0.2167  decode.loss_dice: 0.1433  decode.d0.loss_cls: 0.9118  decode.d0.loss_mask: 0.2318  decode.d0.loss_dice: 0.1556  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.1447  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.2211  decode.d2.loss_dice: 0.1434  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.2196  decode.d3.loss_dice: 0.1418  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.1442  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.1415  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.2228  decode.d6.loss_dice: 0.1455  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.1461  decode.d8.loss_cls: 0.0533  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.1418
10/01 04:39:28 - mmengine - INFO - Iter(train) [160550/320000]  base_lr: 5.3423e-05 lr: 5.3423e-06  eta: 19:25:14  time: 0.4408  data_time: 0.0098  memory: 5145  grad_norm: 27.4325  loss: 4.4534  decode.loss_cls: 0.0522  decode.loss_mask: 0.1477  decode.loss_dice: 0.1345  decode.d0.loss_cls: 1.0036  decode.d0.loss_mask: 0.1498  decode.d0.loss_dice: 0.1298  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.1529  decode.d1.loss_dice: 0.1339  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.1511  decode.d2.loss_dice: 0.1320  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.1538  decode.d3.loss_dice: 0.1343  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.1514  decode.d4.loss_dice: 0.1330  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.1522  decode.d5.loss_dice: 0.1284  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.1512  decode.d6.loss_dice: 0.1307  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.1520  decode.d7.loss_dice: 0.1318  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.1513  decode.d8.loss_dice: 0.1309
10/01 04:39:50 - mmengine - INFO - Iter(train) [160600/320000]  base_lr: 5.3408e-05 lr: 5.3408e-06  eta: 19:24:52  time: 0.4433  data_time: 0.0098  memory: 5129  grad_norm: 31.1299  loss: 4.8379  decode.loss_cls: 0.0446  decode.loss_mask: 0.1904  decode.loss_dice: 0.1696  decode.d0.loss_cls: 0.8148  decode.d0.loss_mask: 0.1942  decode.d0.loss_dice: 0.1750  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.1911  decode.d1.loss_dice: 0.1708  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.1712  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.1919  decode.d3.loss_dice: 0.1693  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.1888  decode.d4.loss_dice: 0.1751  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.1799  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.1894  decode.d6.loss_dice: 0.1704  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.1888  decode.d7.loss_dice: 0.1687  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.1904  decode.d8.loss_dice: 0.1729
10/01 04:40:12 - mmengine - INFO - Iter(train) [160650/320000]  base_lr: 5.3393e-05 lr: 5.3393e-06  eta: 19:24:30  time: 0.4407  data_time: 0.0095  memory: 5129  grad_norm: 156.0848  loss: 5.9208  decode.loss_cls: 0.2080  decode.loss_mask: 0.1680  decode.loss_dice: 0.1918  decode.d0.loss_cls: 0.8071  decode.d0.loss_mask: 0.1703  decode.d0.loss_dice: 0.1736  decode.d1.loss_cls: 0.1627  decode.d1.loss_mask: 0.1692  decode.d1.loss_dice: 0.2058  decode.d2.loss_cls: 0.1346  decode.d2.loss_mask: 0.1680  decode.d2.loss_dice: 0.2143  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 0.1708  decode.d3.loss_dice: 0.1872  decode.d4.loss_cls: 0.1065  decode.d4.loss_mask: 0.1707  decode.d4.loss_dice: 0.2118  decode.d5.loss_cls: 0.1381  decode.d5.loss_mask: 0.1709  decode.d5.loss_dice: 0.2210  decode.d6.loss_cls: 0.2060  decode.d6.loss_mask: 0.1670  decode.d6.loss_dice: 0.1850  decode.d7.loss_cls: 0.2216  decode.d7.loss_mask: 0.1665  decode.d7.loss_dice: 0.1592  decode.d8.loss_cls: 0.1701  decode.d8.loss_mask: 0.1674  decode.d8.loss_dice: 0.1837
10/01 04:40:34 - mmengine - INFO - Iter(train) [160700/320000]  base_lr: 5.3378e-05 lr: 5.3378e-06  eta: 19:24:09  time: 0.4439  data_time: 0.0097  memory: 5129  grad_norm: 45.1676  loss: 4.8940  decode.loss_cls: 0.0488  decode.loss_mask: 0.1959  decode.loss_dice: 0.1592  decode.d0.loss_cls: 0.8695  decode.d0.loss_mask: 0.1998  decode.d0.loss_dice: 0.1597  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.1674  decode.d2.loss_cls: 0.0435  decode.d2.loss_mask: 0.1895  decode.d2.loss_dice: 0.1671  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.1946  decode.d3.loss_dice: 0.1609  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.1947  decode.d4.loss_dice: 0.1703  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.1910  decode.d5.loss_dice: 0.1667  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.1989  decode.d6.loss_dice: 0.1689  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.1870  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.1964  decode.d8.loss_dice: 0.1698
10/01 04:40:56 - mmengine - INFO - Iter(train) [160750/320000]  base_lr: 5.3363e-05 lr: 5.3363e-06  eta: 19:23:47  time: 0.4413  data_time: 0.0097  memory: 5129  grad_norm: 26.1403  loss: 3.9769  decode.loss_cls: 0.0027  decode.loss_mask: 0.1712  decode.loss_dice: 0.1429  decode.d0.loss_cls: 0.7872  decode.d0.loss_mask: 0.1704  decode.d0.loss_dice: 0.1410  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.1710  decode.d1.loss_dice: 0.1478  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.1705  decode.d2.loss_dice: 0.1477  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1725  decode.d3.loss_dice: 0.1478  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.1715  decode.d4.loss_dice: 0.1446  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.1709  decode.d5.loss_dice: 0.1415  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1694  decode.d6.loss_dice: 0.1418  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1704  decode.d7.loss_dice: 0.1509  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1728  decode.d8.loss_dice: 0.1502
10/01 04:41:18 - mmengine - INFO - Iter(train) [160800/320000]  base_lr: 5.3348e-05 lr: 5.3348e-06  eta: 19:23:25  time: 0.4404  data_time: 0.0094  memory: 5145  grad_norm: 30.2305  loss: 4.3658  decode.loss_cls: 0.0014  decode.loss_mask: 0.1935  decode.loss_dice: 0.1595  decode.d0.loss_cls: 0.7902  decode.d0.loss_mask: 0.1975  decode.d0.loss_dice: 0.1618  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.1931  decode.d1.loss_dice: 0.1606  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.1952  decode.d2.loss_dice: 0.1660  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.1926  decode.d3.loss_dice: 0.1617  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.1913  decode.d4.loss_dice: 0.1604  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.1620  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.1938  decode.d6.loss_dice: 0.1637  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.1927  decode.d7.loss_dice: 0.1626  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1940  decode.d8.loss_dice: 0.1609
10/01 04:41:40 - mmengine - INFO - Iter(train) [160850/320000]  base_lr: 5.3333e-05 lr: 5.3333e-06  eta: 19:23:03  time: 0.4405  data_time: 0.0097  memory: 5146  grad_norm: 46.5874  loss: 5.3385  decode.loss_cls: 0.0565  decode.loss_mask: 0.2203  decode.loss_dice: 0.1597  decode.d0.loss_cls: 0.9052  decode.d0.loss_mask: 0.2200  decode.d0.loss_dice: 0.1639  decode.d1.loss_cls: 0.1106  decode.d1.loss_mask: 0.2202  decode.d1.loss_dice: 0.1616  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.1608  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.2187  decode.d3.loss_dice: 0.1611  decode.d4.loss_cls: 0.0793  decode.d4.loss_mask: 0.2157  decode.d4.loss_dice: 0.1666  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.1642  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.2190  decode.d6.loss_dice: 0.1660  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.1615  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.2188  decode.d8.loss_dice: 0.1692
10/01 04:42:02 - mmengine - INFO - Iter(train) [160900/320000]  base_lr: 5.3317e-05 lr: 5.3317e-06  eta: 19:22:41  time: 0.4429  data_time: 0.0095  memory: 5129  grad_norm: 33.2387  loss: 5.0226  decode.loss_cls: 0.0011  decode.loss_mask: 0.2556  decode.loss_dice: 0.1718  decode.d0.loss_cls: 0.7090  decode.d0.loss_mask: 0.2632  decode.d0.loss_dice: 0.1717  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.1714  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2571  decode.d2.loss_dice: 0.1704  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2608  decode.d3.loss_dice: 0.1713  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.1699  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.1742  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.1709  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.1733  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2563  decode.d8.loss_dice: 0.1741
10/01 04:42:24 - mmengine - INFO - Iter(train) [160950/320000]  base_lr: 5.3302e-05 lr: 5.3302e-06  eta: 19:22:20  time: 0.4417  data_time: 0.0095  memory: 5145  grad_norm: 68.3682  loss: 4.6560  decode.loss_cls: 0.0179  decode.loss_mask: 0.1985  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.7695  decode.d0.loss_mask: 0.2011  decode.d0.loss_dice: 0.1667  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.2003  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.2000  decode.d2.loss_dice: 0.1655  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2012  decode.d3.loss_dice: 0.1697  decode.d4.loss_cls: 0.0279  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.1663  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.1981  decode.d5.loss_dice: 0.1621  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.1986  decode.d6.loss_dice: 0.1611  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.2025  decode.d7.loss_dice: 0.1614  decode.d8.loss_cls: 0.0230  decode.d8.loss_mask: 0.2009  decode.d8.loss_dice: 0.1653
10/01 04:42:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:42:47 - mmengine - INFO - Iter(train) [161000/320000]  base_lr: 5.3287e-05 lr: 5.3287e-06  eta: 19:21:58  time: 0.4430  data_time: 0.0096  memory: 5145  grad_norm: 21.3155  loss: 4.0517  decode.loss_cls: 0.0032  decode.loss_mask: 0.1635  decode.loss_dice: 0.1756  decode.d0.loss_cls: 0.8166  decode.d0.loss_mask: 0.1644  decode.d0.loss_dice: 0.1644  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.1624  decode.d1.loss_dice: 0.1544  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.1631  decode.d2.loss_dice: 0.1490  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.1621  decode.d3.loss_dice: 0.1529  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.1636  decode.d4.loss_dice: 0.1530  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.1631  decode.d5.loss_dice: 0.1586  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.1620  decode.d6.loss_dice: 0.1391  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.1650  decode.d7.loss_dice: 0.1695  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1626  decode.d8.loss_dice: 0.1546
10/01 04:43:09 - mmengine - INFO - Iter(train) [161050/320000]  base_lr: 5.3272e-05 lr: 5.3272e-06  eta: 19:21:36  time: 0.4432  data_time: 0.0097  memory: 5129  grad_norm: 94.9659  loss: 4.6172  decode.loss_cls: 0.0436  decode.loss_mask: 0.1671  decode.loss_dice: 0.1665  decode.d0.loss_cls: 0.9979  decode.d0.loss_mask: 0.1654  decode.d0.loss_dice: 0.1470  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.1687  decode.d1.loss_dice: 0.1652  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.1641  decode.d2.loss_dice: 0.1597  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.1687  decode.d3.loss_dice: 0.1651  decode.d4.loss_cls: 0.0393  decode.d4.loss_mask: 0.1682  decode.d4.loss_dice: 0.1675  decode.d5.loss_cls: 0.0360  decode.d5.loss_mask: 0.1653  decode.d5.loss_dice: 0.1597  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.1694  decode.d6.loss_dice: 0.1650  decode.d7.loss_cls: 0.0339  decode.d7.loss_mask: 0.1687  decode.d7.loss_dice: 0.1673  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.1675  decode.d8.loss_dice: 0.1674
10/01 04:43:31 - mmengine - INFO - Iter(train) [161100/320000]  base_lr: 5.3257e-05 lr: 5.3257e-06  eta: 19:21:14  time: 0.4434  data_time: 0.0097  memory: 5145  grad_norm: 46.5170  loss: 5.1906  decode.loss_cls: 0.0379  decode.loss_mask: 0.1966  decode.loss_dice: 0.1913  decode.d0.loss_cls: 0.7330  decode.d0.loss_mask: 0.1984  decode.d0.loss_dice: 0.2153  decode.d1.loss_cls: 0.1055  decode.d1.loss_mask: 0.1959  decode.d1.loss_dice: 0.2105  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.1973  decode.d2.loss_dice: 0.2132  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.1951  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.0417  decode.d4.loss_mask: 0.1954  decode.d4.loss_dice: 0.1997  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.1962  decode.d5.loss_dice: 0.1989  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.1946  decode.d6.loss_dice: 0.2113  decode.d7.loss_cls: 0.0589  decode.d7.loss_mask: 0.1960  decode.d7.loss_dice: 0.1926  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.1945  decode.d8.loss_dice: 0.1830
10/01 04:43:53 - mmengine - INFO - Iter(train) [161150/320000]  base_lr: 5.3242e-05 lr: 5.3242e-06  eta: 19:20:53  time: 0.4414  data_time: 0.0098  memory: 5145  grad_norm: 33.5060  loss: 4.2605  decode.loss_cls: 0.0231  decode.loss_mask: 0.1658  decode.loss_dice: 0.1584  decode.d0.loss_cls: 0.9007  decode.d0.loss_mask: 0.1652  decode.d0.loss_dice: 0.1835  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.1662  decode.d1.loss_dice: 0.1561  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.1645  decode.d2.loss_dice: 0.1429  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.1657  decode.d3.loss_dice: 0.1658  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.1629  decode.d4.loss_dice: 0.1515  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.1652  decode.d5.loss_dice: 0.1556  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.1656  decode.d6.loss_dice: 0.1484  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.1655  decode.d7.loss_dice: 0.1564  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.1645  decode.d8.loss_dice: 0.1463
10/01 04:44:15 - mmengine - INFO - Iter(train) [161200/320000]  base_lr: 5.3227e-05 lr: 5.3227e-06  eta: 19:20:31  time: 0.4418  data_time: 0.0100  memory: 5145  grad_norm: 61.2184  loss: 4.1701  decode.loss_cls: 0.0250  decode.loss_mask: 0.1724  decode.loss_dice: 0.1488  decode.d0.loss_cls: 0.7759  decode.d0.loss_mask: 0.1755  decode.d0.loss_dice: 0.1472  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.1745  decode.d1.loss_dice: 0.1503  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.1747  decode.d2.loss_dice: 0.1526  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.1750  decode.d3.loss_dice: 0.1505  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.1732  decode.d4.loss_dice: 0.1474  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.1752  decode.d5.loss_dice: 0.1500  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.1467  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.1748  decode.d7.loss_dice: 0.1491  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.1728  decode.d8.loss_dice: 0.1505
10/01 04:44:37 - mmengine - INFO - Iter(train) [161250/320000]  base_lr: 5.3212e-05 lr: 5.3212e-06  eta: 19:20:09  time: 0.4405  data_time: 0.0098  memory: 5129  grad_norm: 76.1437  loss: 6.2979  decode.loss_cls: 0.1048  decode.loss_mask: 0.2313  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.8085  decode.d0.loss_mask: 0.2258  decode.d0.loss_dice: 0.2100  decode.d1.loss_cls: 0.1070  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.2329  decode.d2.loss_dice: 0.2321  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.2238  decode.d4.loss_cls: 0.1437  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.2313  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2298  decode.d5.loss_dice: 0.2126  decode.d6.loss_cls: 0.1047  decode.d6.loss_mask: 0.2299  decode.d6.loss_dice: 0.2087  decode.d7.loss_cls: 0.1430  decode.d7.loss_mask: 0.2305  decode.d7.loss_dice: 0.2228  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.2320  decode.d8.loss_dice: 0.2221
10/01 04:44:59 - mmengine - INFO - Iter(train) [161300/320000]  base_lr: 5.3197e-05 lr: 5.3197e-06  eta: 19:19:47  time: 0.4426  data_time: 0.0099  memory: 5145  grad_norm: 116.7616  loss: 8.2033  decode.loss_cls: 0.0562  decode.loss_mask: 0.3162  decode.loss_dice: 0.3220  decode.d0.loss_cls: 1.0664  decode.d0.loss_mask: 0.3000  decode.d0.loss_dice: 0.3290  decode.d1.loss_cls: 0.2629  decode.d1.loss_mask: 0.3004  decode.d1.loss_dice: 0.3200  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.3209  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3279  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.3178  decode.d4.loss_dice: 0.3262  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.3133  decode.d5.loss_dice: 0.3191  decode.d6.loss_cls: 0.0997  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.3036  decode.d7.loss_cls: 0.0935  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.3104  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.3194  decode.d8.loss_dice: 0.3343
10/01 04:45:21 - mmengine - INFO - Iter(train) [161350/320000]  base_lr: 5.3182e-05 lr: 5.3182e-06  eta: 19:19:26  time: 0.4413  data_time: 0.0095  memory: 5129  grad_norm: 18.1172  loss: 3.6717  decode.loss_cls: 0.0035  decode.loss_mask: 0.1502  decode.loss_dice: 0.1381  decode.d0.loss_cls: 0.7964  decode.d0.loss_mask: 0.1518  decode.d0.loss_dice: 0.1328  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.1494  decode.d1.loss_dice: 0.1360  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1507  decode.d2.loss_dice: 0.1393  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.1497  decode.d3.loss_dice: 0.1356  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.1487  decode.d4.loss_dice: 0.1259  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.1494  decode.d5.loss_dice: 0.1355  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.1486  decode.d6.loss_dice: 0.1354  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.1488  decode.d7.loss_dice: 0.1347  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1485  decode.d8.loss_dice: 0.1421
10/01 04:45:44 - mmengine - INFO - Iter(train) [161400/320000]  base_lr: 5.3167e-05 lr: 5.3167e-06  eta: 19:19:04  time: 0.4434  data_time: 0.0097  memory: 5129  grad_norm: 77.0075  loss: 5.0329  decode.loss_cls: 0.0385  decode.loss_mask: 0.1998  decode.loss_dice: 0.2217  decode.d0.loss_cls: 0.8842  decode.d0.loss_mask: 0.2008  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.2015  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.2011  decode.d2.loss_dice: 0.1862  decode.d3.loss_cls: 0.0211  decode.d3.loss_mask: 0.2026  decode.d3.loss_dice: 0.1954  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.1582  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.1986  decode.d5.loss_dice: 0.1898  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.1999  decode.d6.loss_dice: 0.1899  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 0.2014  decode.d7.loss_dice: 0.1676  decode.d8.loss_cls: 0.0312  decode.d8.loss_mask: 0.2004  decode.d8.loss_dice: 0.1575
10/01 04:46:06 - mmengine - INFO - Iter(train) [161450/320000]  base_lr: 5.3152e-05 lr: 5.3152e-06  eta: 19:18:42  time: 0.4415  data_time: 0.0099  memory: 5129  grad_norm: 35.8560  loss: 4.4561  decode.loss_cls: 0.0233  decode.loss_mask: 0.1753  decode.loss_dice: 0.1731  decode.d0.loss_cls: 0.7372  decode.d0.loss_mask: 0.1756  decode.d0.loss_dice: 0.1676  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.1725  decode.d1.loss_dice: 0.1646  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.1706  decode.d2.loss_dice: 0.1755  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.1718  decode.d3.loss_dice: 0.1693  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.1717  decode.d4.loss_dice: 0.1663  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.1732  decode.d5.loss_dice: 0.1748  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.1706  decode.d6.loss_dice: 0.1735  decode.d7.loss_cls: 0.0308  decode.d7.loss_mask: 0.1727  decode.d7.loss_dice: 0.1676  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.1742  decode.d8.loss_dice: 0.1726
10/01 04:46:28 - mmengine - INFO - Iter(train) [161500/320000]  base_lr: 5.3136e-05 lr: 5.3136e-06  eta: 19:18:20  time: 0.4418  data_time: 0.0098  memory: 5129  grad_norm: 83.6779  loss: 4.9395  decode.loss_cls: 0.0377  decode.loss_mask: 0.1941  decode.loss_dice: 0.1755  decode.d0.loss_cls: 0.8250  decode.d0.loss_mask: 0.1996  decode.d0.loss_dice: 0.1689  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.1951  decode.d1.loss_dice: 0.1717  decode.d2.loss_cls: 0.0864  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.1679  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.1905  decode.d3.loss_dice: 0.1653  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.1944  decode.d4.loss_dice: 0.1709  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.1692  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.1920  decode.d6.loss_dice: 0.1740  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.1737  decode.d8.loss_cls: 0.0281  decode.d8.loss_mask: 0.1950  decode.d8.loss_dice: 0.1781
10/01 04:46:50 - mmengine - INFO - Iter(train) [161550/320000]  base_lr: 5.3121e-05 lr: 5.3121e-06  eta: 19:17:59  time: 0.4421  data_time: 0.0099  memory: 5129  grad_norm: 71.9899  loss: 5.6990  decode.loss_cls: 0.0340  decode.loss_mask: 0.2092  decode.loss_dice: 0.2551  decode.d0.loss_cls: 0.8306  decode.d0.loss_mask: 0.2095  decode.d0.loss_dice: 0.2054  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.0448  decode.d2.loss_mask: 0.2083  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.0455  decode.d3.loss_mask: 0.2090  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.2519  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.2125  decode.d5.loss_dice: 0.2327  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.2070  decode.d6.loss_dice: 0.2427  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.2519  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.2084  decode.d8.loss_dice: 0.2407
10/01 04:47:12 - mmengine - INFO - Iter(train) [161600/320000]  base_lr: 5.3106e-05 lr: 5.3106e-06  eta: 19:17:37  time: 0.4412  data_time: 0.0097  memory: 5145  grad_norm: 44.0581  loss: 4.4409  decode.loss_cls: 0.0118  decode.loss_mask: 0.1958  decode.loss_dice: 0.1491  decode.d0.loss_cls: 0.8371  decode.d0.loss_mask: 0.2087  decode.d0.loss_dice: 0.1527  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.2142  decode.d1.loss_dice: 0.1555  decode.d2.loss_cls: 0.0094  decode.d2.loss_mask: 0.2179  decode.d2.loss_dice: 0.1484  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.1948  decode.d3.loss_dice: 0.1474  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.1951  decode.d4.loss_dice: 0.1442  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.2136  decode.d5.loss_dice: 0.1405  decode.d6.loss_cls: 0.0163  decode.d6.loss_mask: 0.1969  decode.d6.loss_dice: 0.1453  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.1947  decode.d7.loss_dice: 0.1446  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.1376
10/01 04:47:34 - mmengine - INFO - Iter(train) [161650/320000]  base_lr: 5.3091e-05 lr: 5.3091e-06  eta: 19:17:15  time: 0.4419  data_time: 0.0099  memory: 5119  grad_norm: 36.8926  loss: 4.9151  decode.loss_cls: 0.0022  decode.loss_mask: 0.2419  decode.loss_dice: 0.1639  decode.d0.loss_cls: 0.8089  decode.d0.loss_mask: 0.2475  decode.d0.loss_dice: 0.1618  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.2431  decode.d1.loss_dice: 0.1638  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.2418  decode.d2.loss_dice: 0.1654  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2451  decode.d3.loss_dice: 0.1671  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.1637  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2431  decode.d5.loss_dice: 0.1648  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.1634  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.1663  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.2436  decode.d8.loss_dice: 0.1649
10/01 04:47:56 - mmengine - INFO - Iter(train) [161700/320000]  base_lr: 5.3076e-05 lr: 5.3076e-06  eta: 19:16:54  time: 0.4578  data_time: 0.0098  memory: 5145  grad_norm: 92.8098  loss: 4.4615  decode.loss_cls: 0.0190  decode.loss_mask: 0.1823  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.7952  decode.d0.loss_mask: 0.1891  decode.d0.loss_dice: 0.1742  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.1874  decode.d1.loss_dice: 0.1675  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.1837  decode.d2.loss_dice: 0.1631  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.1841  decode.d3.loss_dice: 0.1682  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.1837  decode.d4.loss_dice: 0.1635  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.1818  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.1830  decode.d6.loss_dice: 0.1767  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.1836  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0323  decode.d8.loss_mask: 0.1846  decode.d8.loss_dice: 0.1661
10/01 04:48:19 - mmengine - INFO - Iter(train) [161750/320000]  base_lr: 5.3061e-05 lr: 5.3061e-06  eta: 19:16:32  time: 0.4419  data_time: 0.0100  memory: 5120  grad_norm: 123.5683  loss: 7.2161  decode.loss_cls: 0.1648  decode.loss_mask: 0.2106  decode.loss_dice: 0.3463  decode.d0.loss_cls: 0.8282  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.3144  decode.d1.loss_cls: 0.2346  decode.d1.loss_mask: 0.2106  decode.d1.loss_dice: 0.3174  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 0.2089  decode.d2.loss_dice: 0.2677  decode.d3.loss_cls: 0.1144  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.2764  decode.d4.loss_cls: 0.0966  decode.d4.loss_mask: 0.2166  decode.d4.loss_dice: 0.2868  decode.d5.loss_cls: 0.1049  decode.d5.loss_mask: 0.2233  decode.d5.loss_dice: 0.3190  decode.d6.loss_cls: 0.1472  decode.d6.loss_mask: 0.2201  decode.d6.loss_dice: 0.3392  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.2227  decode.d8.loss_dice: 0.2965
10/01 04:48:41 - mmengine - INFO - Iter(train) [161800/320000]  base_lr: 5.3046e-05 lr: 5.3046e-06  eta: 19:16:10  time: 0.4417  data_time: 0.0098  memory: 5129  grad_norm: 39.5849  loss: 4.5256  decode.loss_cls: 0.0127  decode.loss_mask: 0.1718  decode.loss_dice: 0.1753  decode.d0.loss_cls: 0.8846  decode.d0.loss_mask: 0.1761  decode.d0.loss_dice: 0.1649  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.1717  decode.d1.loss_dice: 0.1779  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.1703  decode.d2.loss_dice: 0.1771  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.1707  decode.d3.loss_dice: 0.1564  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.1729  decode.d4.loss_dice: 0.1759  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.1727  decode.d5.loss_dice: 0.1788  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.1708  decode.d6.loss_dice: 0.1700  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.1717  decode.d7.loss_dice: 0.1725  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.1722  decode.d8.loss_dice: 0.1729
10/01 04:49:03 - mmengine - INFO - Iter(train) [161850/320000]  base_lr: 5.3031e-05 lr: 5.3031e-06  eta: 19:15:48  time: 0.4421  data_time: 0.0098  memory: 5129  grad_norm: 66.7880  loss: 4.8038  decode.loss_cls: 0.0492  decode.loss_mask: 0.1873  decode.loss_dice: 0.1684  decode.d0.loss_cls: 0.7950  decode.d0.loss_mask: 0.2033  decode.d0.loss_dice: 0.1796  decode.d1.loss_cls: 0.0567  decode.d1.loss_mask: 0.1909  decode.d1.loss_dice: 0.1870  decode.d2.loss_cls: 0.0446  decode.d2.loss_mask: 0.1866  decode.d2.loss_dice: 0.1810  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.1870  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.1877  decode.d4.loss_dice: 0.1804  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.1868  decode.d5.loss_dice: 0.1749  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.1892  decode.d6.loss_dice: 0.1651  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.1870  decode.d7.loss_dice: 0.1791  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.1857  decode.d8.loss_dice: 0.1816
10/01 04:49:25 - mmengine - INFO - Iter(train) [161900/320000]  base_lr: 5.3016e-05 lr: 5.3016e-06  eta: 19:15:27  time: 0.4422  data_time: 0.0099  memory: 5120  grad_norm: 78.2483  loss: 5.6389  decode.loss_cls: 0.0956  decode.loss_mask: 0.2315  decode.loss_dice: 0.1512  decode.d0.loss_cls: 0.8051  decode.d0.loss_mask: 0.2234  decode.d0.loss_dice: 0.1503  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.1560  decode.d2.loss_cls: 0.1501  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.1527  decode.d3.loss_cls: 0.1276  decode.d3.loss_mask: 0.2297  decode.d3.loss_dice: 0.1526  decode.d4.loss_cls: 0.1144  decode.d4.loss_mask: 0.2315  decode.d4.loss_dice: 0.1549  decode.d5.loss_cls: 0.1042  decode.d5.loss_mask: 0.2315  decode.d5.loss_dice: 0.1550  decode.d6.loss_cls: 0.1078  decode.d6.loss_mask: 0.2306  decode.d6.loss_dice: 0.1566  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.1558  decode.d8.loss_cls: 0.1067  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.1544
10/01 04:49:47 - mmengine - INFO - Iter(train) [161950/320000]  base_lr: 5.3001e-05 lr: 5.3001e-06  eta: 19:15:05  time: 0.4416  data_time: 0.0098  memory: 5129  grad_norm: 63.1976  loss: 4.0671  decode.loss_cls: 0.0107  decode.loss_mask: 0.1695  decode.loss_dice: 0.1330  decode.d0.loss_cls: 0.7798  decode.d0.loss_mask: 0.2135  decode.d0.loss_dice: 0.1457  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.1853  decode.d1.loss_dice: 0.1412  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.1943  decode.d2.loss_dice: 0.1419  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.1851  decode.d3.loss_dice: 0.1434  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.1812  decode.d4.loss_dice: 0.1391  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.1431  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.1771  decode.d6.loss_dice: 0.1345  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.1713  decode.d7.loss_dice: 0.1335  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.1680  decode.d8.loss_dice: 0.1300
10/01 04:50:09 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:50:09 - mmengine - INFO - Iter(train) [162000/320000]  base_lr: 5.2986e-05 lr: 5.2986e-06  eta: 19:14:43  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 57.6539  loss: 5.4082  decode.loss_cls: 0.0463  decode.loss_mask: 0.1910  decode.loss_dice: 0.2410  decode.d0.loss_cls: 0.7399  decode.d0.loss_mask: 0.1918  decode.d0.loss_dice: 0.2206  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.1910  decode.d1.loss_dice: 0.2251  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.1925  decode.d2.loss_dice: 0.2070  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.1942  decode.d3.loss_dice: 0.2361  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.1925  decode.d4.loss_dice: 0.2054  decode.d5.loss_cls: 0.0975  decode.d5.loss_mask: 0.1930  decode.d5.loss_dice: 0.2026  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.1943  decode.d6.loss_dice: 0.2033  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.1930  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.1956  decode.d8.loss_dice: 0.2143
10/01 04:50:31 - mmengine - INFO - Iter(train) [162050/320000]  base_lr: 5.2970e-05 lr: 5.2970e-06  eta: 19:14:21  time: 0.4419  data_time: 0.0098  memory: 5145  grad_norm: 69.1925  loss: 4.7389  decode.loss_cls: 0.0210  decode.loss_mask: 0.1506  decode.loss_dice: 0.1837  decode.d0.loss_cls: 0.8847  decode.d0.loss_mask: 0.1495  decode.d0.loss_dice: 0.1564  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.1516  decode.d1.loss_dice: 0.1783  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.1499  decode.d2.loss_dice: 0.1717  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 0.1495  decode.d3.loss_dice: 0.1542  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.1499  decode.d4.loss_dice: 0.1676  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.1503  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.1498  decode.d6.loss_dice: 0.1728  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.1514  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.1508  decode.d8.loss_dice: 0.1775
10/01 04:50:53 - mmengine - INFO - Iter(train) [162100/320000]  base_lr: 5.2955e-05 lr: 5.2955e-06  eta: 19:14:00  time: 0.4421  data_time: 0.0098  memory: 5129  grad_norm: 61.9707  loss: 4.7392  decode.loss_cls: 0.0062  decode.loss_mask: 0.2216  decode.loss_dice: 0.1707  decode.d0.loss_cls: 0.7663  decode.d0.loss_mask: 0.2250  decode.d0.loss_dice: 0.1686  decode.d1.loss_cls: 0.0181  decode.d1.loss_mask: 0.2259  decode.d1.loss_dice: 0.1679  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.2220  decode.d2.loss_dice: 0.1670  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.2242  decode.d3.loss_dice: 0.1692  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.2193  decode.d4.loss_dice: 0.1688  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.1650  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.2204  decode.d6.loss_dice: 0.1618  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.2212  decode.d7.loss_dice: 0.1620  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.2198  decode.d8.loss_dice: 0.1658
10/01 04:51:16 - mmengine - INFO - Iter(train) [162150/320000]  base_lr: 5.2940e-05 lr: 5.2940e-06  eta: 19:13:38  time: 0.4414  data_time: 0.0100  memory: 5145  grad_norm: 36.0306  loss: 4.5156  decode.loss_cls: 0.0022  decode.loss_mask: 0.2129  decode.loss_dice: 0.1563  decode.d0.loss_cls: 0.7658  decode.d0.loss_mask: 0.2143  decode.d0.loss_dice: 0.1563  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.1563  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.2168  decode.d2.loss_dice: 0.1629  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.2143  decode.d3.loss_dice: 0.1610  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.2105  decode.d4.loss_dice: 0.1559  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.2132  decode.d5.loss_dice: 0.1580  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2142  decode.d6.loss_dice: 0.1625  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.2128  decode.d7.loss_dice: 0.1598  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.1596
10/01 04:51:38 - mmengine - INFO - Iter(train) [162200/320000]  base_lr: 5.2925e-05 lr: 5.2925e-06  eta: 19:13:16  time: 0.4425  data_time: 0.0105  memory: 5129  grad_norm: 55.9181  loss: 4.9642  decode.loss_cls: 0.0659  decode.loss_mask: 0.1991  decode.loss_dice: 0.1545  decode.d0.loss_cls: 0.7472  decode.d0.loss_mask: 0.2029  decode.d0.loss_dice: 0.1749  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.2001  decode.d1.loss_dice: 0.1579  decode.d2.loss_cls: 0.0699  decode.d2.loss_mask: 0.2021  decode.d2.loss_dice: 0.1525  decode.d3.loss_cls: 0.0600  decode.d3.loss_mask: 0.1988  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.1984  decode.d4.loss_dice: 0.1752  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.2009  decode.d5.loss_dice: 0.1527  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.2005  decode.d6.loss_dice: 0.1630  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.2027  decode.d7.loss_dice: 0.1508  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.1974  decode.d8.loss_dice: 0.1736
10/01 04:52:00 - mmengine - INFO - Iter(train) [162250/320000]  base_lr: 5.2910e-05 lr: 5.2910e-06  eta: 19:12:54  time: 0.4446  data_time: 0.0100  memory: 5145  grad_norm: 20.9002  loss: 4.2866  decode.loss_cls: 0.0566  decode.loss_mask: 0.1621  decode.loss_dice: 0.1303  decode.d0.loss_cls: 0.8046  decode.d0.loss_mask: 0.1666  decode.d0.loss_dice: 0.1303  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.1665  decode.d1.loss_dice: 0.1313  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.1663  decode.d2.loss_dice: 0.1320  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.1630  decode.d3.loss_dice: 0.1324  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.1643  decode.d4.loss_dice: 0.1303  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.1642  decode.d5.loss_dice: 0.1304  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.1658  decode.d6.loss_dice: 0.1300  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.1675  decode.d7.loss_dice: 0.1320  decode.d8.loss_cls: 0.0639  decode.d8.loss_mask: 0.1671  decode.d8.loss_dice: 0.1298
10/01 04:52:22 - mmengine - INFO - Iter(train) [162300/320000]  base_lr: 5.2895e-05 lr: 5.2895e-06  eta: 19:12:33  time: 0.4419  data_time: 0.0099  memory: 5129  grad_norm: 47.9551  loss: 4.3645  decode.loss_cls: 0.0481  decode.loss_mask: 0.1608  decode.loss_dice: 0.1515  decode.d0.loss_cls: 0.8254  decode.d0.loss_mask: 0.1610  decode.d0.loss_dice: 0.1452  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.1594  decode.d1.loss_dice: 0.1546  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.1611  decode.d2.loss_dice: 0.1502  decode.d3.loss_cls: 0.0578  decode.d3.loss_mask: 0.1606  decode.d3.loss_dice: 0.1550  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.1643  decode.d4.loss_dice: 0.1677  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.1609  decode.d5.loss_dice: 0.1607  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.1604  decode.d6.loss_dice: 0.1514  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.1600  decode.d7.loss_dice: 0.1505  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.1600  decode.d8.loss_dice: 0.1446
10/01 04:52:44 - mmengine - INFO - Iter(train) [162350/320000]  base_lr: 5.2880e-05 lr: 5.2880e-06  eta: 19:12:11  time: 0.4439  data_time: 0.0098  memory: 5129  grad_norm: 66.7437  loss: 4.9229  decode.loss_cls: 0.0086  decode.loss_mask: 0.1893  decode.loss_dice: 0.2124  decode.d0.loss_cls: 0.7748  decode.d0.loss_mask: 0.1887  decode.d0.loss_dice: 0.2149  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.1884  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.2093  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.1901  decode.d3.loss_dice: 0.2149  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.1891  decode.d4.loss_dice: 0.2160  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.1914  decode.d5.loss_dice: 0.2210  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.1902  decode.d6.loss_dice: 0.2204  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.1864  decode.d7.loss_dice: 0.2170  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.1919  decode.d8.loss_dice: 0.2254
10/01 04:53:06 - mmengine - INFO - Iter(train) [162400/320000]  base_lr: 5.2865e-05 lr: 5.2865e-06  eta: 19:11:49  time: 0.4424  data_time: 0.0097  memory: 5129  grad_norm: 51.8761  loss: 4.2232  decode.loss_cls: 0.0273  decode.loss_mask: 0.1640  decode.loss_dice: 0.1485  decode.d0.loss_cls: 0.7859  decode.d0.loss_mask: 0.1606  decode.d0.loss_dice: 0.1572  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.1620  decode.d1.loss_dice: 0.1531  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.1628  decode.d2.loss_dice: 0.1440  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.1613  decode.d3.loss_dice: 0.1544  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.1628  decode.d4.loss_dice: 0.1548  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.1635  decode.d5.loss_dice: 0.1559  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.1629  decode.d6.loss_dice: 0.1417  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.1640  decode.d7.loss_dice: 0.1563  decode.d8.loss_cls: 0.0272  decode.d8.loss_mask: 0.1612  decode.d8.loss_dice: 0.1505
10/01 04:53:28 - mmengine - INFO - Iter(train) [162450/320000]  base_lr: 5.2850e-05 lr: 5.2850e-06  eta: 19:11:27  time: 0.4445  data_time: 0.0098  memory: 5145  grad_norm: 25.5814  loss: 3.7927  decode.loss_cls: 0.0050  decode.loss_mask: 0.1523  decode.loss_dice: 0.1399  decode.d0.loss_cls: 0.8229  decode.d0.loss_mask: 0.1539  decode.d0.loss_dice: 0.1407  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.1540  decode.d1.loss_dice: 0.1516  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.1532  decode.d2.loss_dice: 0.1374  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.1531  decode.d3.loss_dice: 0.1379  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.1529  decode.d4.loss_dice: 0.1368  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.1521  decode.d5.loss_dice: 0.1351  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.1518  decode.d6.loss_dice: 0.1369  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.1522  decode.d7.loss_dice: 0.1379  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.1507  decode.d8.loss_dice: 0.1355
10/01 04:53:50 - mmengine - INFO - Iter(train) [162500/320000]  base_lr: 5.2835e-05 lr: 5.2835e-06  eta: 19:11:06  time: 0.4416  data_time: 0.0099  memory: 5145  grad_norm: 42.8072  loss: 4.6488  decode.loss_cls: 0.0037  decode.loss_mask: 0.2082  decode.loss_dice: 0.1658  decode.d0.loss_cls: 0.8405  decode.d0.loss_mask: 0.2106  decode.d0.loss_dice: 0.1685  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.2077  decode.d1.loss_dice: 0.1665  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.2107  decode.d2.loss_dice: 0.1693  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.2068  decode.d4.loss_dice: 0.1696  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.1666  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.1655  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.2078  decode.d7.loss_dice: 0.1676  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.2079  decode.d8.loss_dice: 0.1693
10/01 04:54:12 - mmengine - INFO - Iter(train) [162550/320000]  base_lr: 5.2820e-05 lr: 5.2820e-06  eta: 19:10:44  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 51.6690  loss: 5.4855  decode.loss_cls: 0.0908  decode.loss_mask: 0.1876  decode.loss_dice: 0.1618  decode.d0.loss_cls: 1.0145  decode.d0.loss_mask: 0.1905  decode.d0.loss_dice: 0.1650  decode.d1.loss_cls: 0.1188  decode.d1.loss_mask: 0.2201  decode.d1.loss_dice: 0.2015  decode.d2.loss_cls: 0.1163  decode.d2.loss_mask: 0.1921  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.1034  decode.d3.loss_mask: 0.1885  decode.d3.loss_dice: 0.1574  decode.d4.loss_cls: 0.0937  decode.d4.loss_mask: 0.1859  decode.d4.loss_dice: 0.1531  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.1892  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.1856  decode.d6.loss_dice: 0.1592  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 0.1866  decode.d7.loss_dice: 0.1580  decode.d8.loss_cls: 0.1086  decode.d8.loss_mask: 0.1845  decode.d8.loss_dice: 0.1523
10/01 04:54:35 - mmengine - INFO - Iter(train) [162600/320000]  base_lr: 5.2804e-05 lr: 5.2804e-06  eta: 19:10:22  time: 0.4409  data_time: 0.0097  memory: 5129  grad_norm: 103.4643  loss: 6.1674  decode.loss_cls: 0.1659  decode.loss_mask: 0.2051  decode.loss_dice: 0.1796  decode.d0.loss_cls: 0.9756  decode.d0.loss_mask: 0.2038  decode.d0.loss_dice: 0.1407  decode.d1.loss_cls: 0.1910  decode.d1.loss_mask: 0.2106  decode.d1.loss_dice: 0.1729  decode.d2.loss_cls: 0.1490  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.1692  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.2094  decode.d3.loss_dice: 0.1874  decode.d4.loss_cls: 0.1472  decode.d4.loss_mask: 0.2054  decode.d4.loss_dice: 0.1770  decode.d5.loss_cls: 0.1179  decode.d5.loss_mask: 0.2051  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.1797  decode.d6.loss_mask: 0.2024  decode.d6.loss_dice: 0.1696  decode.d7.loss_cls: 0.1599  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.1707  decode.d8.loss_cls: 0.1607  decode.d8.loss_mask: 0.2024  decode.d8.loss_dice: 0.1726
10/01 04:54:57 - mmengine - INFO - Iter(train) [162650/320000]  base_lr: 5.2789e-05 lr: 5.2789e-06  eta: 19:10:00  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 24.0558  loss: 4.0185  decode.loss_cls: 0.0031  decode.loss_mask: 0.1774  decode.loss_dice: 0.1307  decode.d0.loss_cls: 0.8641  decode.d0.loss_mask: 0.1806  decode.d0.loss_dice: 0.1315  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.1805  decode.d1.loss_dice: 0.1347  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.1775  decode.d2.loss_dice: 0.1324  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.1767  decode.d3.loss_dice: 0.1323  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.1786  decode.d4.loss_dice: 0.1341  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.1784  decode.d5.loss_dice: 0.1311  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.1787  decode.d6.loss_dice: 0.1322  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1787  decode.d7.loss_dice: 0.1321  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.1780  decode.d8.loss_dice: 0.1319
10/01 04:55:19 - mmengine - INFO - Iter(train) [162700/320000]  base_lr: 5.2774e-05 lr: 5.2774e-06  eta: 19:09:39  time: 0.4418  data_time: 0.0099  memory: 5129  grad_norm: 34.6668  loss: 5.4448  decode.loss_cls: 0.0086  decode.loss_mask: 0.2156  decode.loss_dice: 0.2357  decode.d0.loss_cls: 0.8660  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.2230  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.2155  decode.d1.loss_dice: 0.2333  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.2141  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.2138  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.2352  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2188  decode.d6.loss_dice: 0.2374  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.2371  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.2165  decode.d8.loss_dice: 0.2380
10/01 04:55:41 - mmengine - INFO - Iter(train) [162750/320000]  base_lr: 5.2759e-05 lr: 5.2759e-06  eta: 19:09:17  time: 0.4418  data_time: 0.0099  memory: 5129  grad_norm: 34.5519  loss: 4.4983  decode.loss_cls: 0.0088  decode.loss_mask: 0.1817  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.7955  decode.d0.loss_mask: 0.1814  decode.d0.loss_dice: 0.1681  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.1813  decode.d1.loss_dice: 0.1660  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.1816  decode.d2.loss_dice: 0.1796  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.1813  decode.d3.loss_dice: 0.1773  decode.d4.loss_cls: 0.0193  decode.d4.loss_mask: 0.1809  decode.d4.loss_dice: 0.1604  decode.d5.loss_cls: 0.0220  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.1670  decode.d6.loss_cls: 0.0203  decode.d6.loss_mask: 0.1803  decode.d6.loss_dice: 0.1698  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.1652  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.1834  decode.d8.loss_dice: 0.1738
10/01 04:56:03 - mmengine - INFO - Iter(train) [162800/320000]  base_lr: 5.2744e-05 lr: 5.2744e-06  eta: 19:08:55  time: 0.4416  data_time: 0.0099  memory: 5119  grad_norm: 32.5789  loss: 4.6622  decode.loss_cls: 0.0489  decode.loss_mask: 0.1654  decode.loss_dice: 0.1814  decode.d0.loss_cls: 0.8251  decode.d0.loss_mask: 0.1693  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.0512  decode.d1.loss_mask: 0.1655  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0340  decode.d2.loss_mask: 0.1671  decode.d2.loss_dice: 0.1778  decode.d3.loss_cls: 0.0287  decode.d3.loss_mask: 0.1665  decode.d3.loss_dice: 0.1864  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.1654  decode.d4.loss_dice: 0.1952  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.1662  decode.d5.loss_dice: 0.1989  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.1684  decode.d6.loss_dice: 0.1907  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.1667  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.1653  decode.d8.loss_dice: 0.1847
10/01 04:56:25 - mmengine - INFO - Iter(train) [162850/320000]  base_lr: 5.2729e-05 lr: 5.2729e-06  eta: 19:08:33  time: 0.4420  data_time: 0.0098  memory: 5129  grad_norm: 261.0049  loss: 7.2889  decode.loss_cls: 0.2605  decode.loss_mask: 0.2326  decode.loss_dice: 0.2133  decode.d0.loss_cls: 0.9877  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.1847  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.1705  decode.d2.loss_mask: 0.2349  decode.d2.loss_dice: 0.2161  decode.d3.loss_cls: 0.1936  decode.d3.loss_mask: 0.2342  decode.d3.loss_dice: 0.2479  decode.d4.loss_cls: 0.1922  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.2064  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 0.2331  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.1950  decode.d6.loss_mask: 0.2366  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.2193  decode.d8.loss_cls: 0.1454  decode.d8.loss_mask: 0.2335  decode.d8.loss_dice: 0.2239
10/01 04:56:47 - mmengine - INFO - Iter(train) [162900/320000]  base_lr: 5.2714e-05 lr: 5.2714e-06  eta: 19:08:12  time: 0.4416  data_time: 0.0100  memory: 5145  grad_norm: 70.9432  loss: 5.8807  decode.loss_cls: 0.1520  decode.loss_mask: 0.1864  decode.loss_dice: 0.1903  decode.d0.loss_cls: 0.7989  decode.d0.loss_mask: 0.1848  decode.d0.loss_dice: 0.1745  decode.d1.loss_cls: 0.1080  decode.d1.loss_mask: 0.1870  decode.d1.loss_dice: 0.2098  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.1845  decode.d2.loss_dice: 0.1748  decode.d3.loss_cls: 0.1465  decode.d3.loss_mask: 0.1872  decode.d3.loss_dice: 0.1930  decode.d4.loss_cls: 0.1517  decode.d4.loss_mask: 0.1863  decode.d4.loss_dice: 0.1817  decode.d5.loss_cls: 0.2104  decode.d5.loss_mask: 0.1859  decode.d5.loss_dice: 0.1827  decode.d6.loss_cls: 0.1747  decode.d6.loss_mask: 0.1828  decode.d6.loss_dice: 0.1772  decode.d7.loss_cls: 0.1824  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.1785  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1691
10/01 04:57:09 - mmengine - INFO - Iter(train) [162950/320000]  base_lr: 5.2699e-05 lr: 5.2699e-06  eta: 19:07:50  time: 0.4423  data_time: 0.0100  memory: 5129  grad_norm: 50.2401  loss: 5.2465  decode.loss_cls: 0.0060  decode.loss_mask: 0.2404  decode.loss_dice: 0.1750  decode.d0.loss_cls: 0.9278  decode.d0.loss_mask: 0.2449  decode.d0.loss_dice: 0.1827  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.2705  decode.d1.loss_dice: 0.1867  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.1829  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.1757  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.2392  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.1789  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.2420  decode.d6.loss_dice: 0.1802  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.1797  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.1784
10/01 04:57:32 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 04:57:32 - mmengine - INFO - Iter(train) [163000/320000]  base_lr: 5.2684e-05 lr: 5.2684e-06  eta: 19:07:28  time: 0.4417  data_time: 0.0097  memory: 5129  grad_norm: 34.5296  loss: 4.7832  decode.loss_cls: 0.0038  decode.loss_mask: 0.2084  decode.loss_dice: 0.1847  decode.d0.loss_cls: 0.7634  decode.d0.loss_mask: 0.2102  decode.d0.loss_dice: 0.1989  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.2094  decode.d1.loss_dice: 0.1894  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.2098  decode.d2.loss_dice: 0.1894  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.2095  decode.d3.loss_dice: 0.1853  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2107  decode.d4.loss_dice: 0.1838  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.2094  decode.d5.loss_dice: 0.1823  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.2097  decode.d6.loss_dice: 0.1935  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.1862  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2106  decode.d8.loss_dice: 0.1906
10/01 04:57:54 - mmengine - INFO - Iter(train) [163050/320000]  base_lr: 5.2669e-05 lr: 5.2669e-06  eta: 19:07:06  time: 0.4411  data_time: 0.0100  memory: 5129  grad_norm: 84.2161  loss: 5.6721  decode.loss_cls: 0.0683  decode.loss_mask: 0.2557  decode.loss_dice: 0.1745  decode.d0.loss_cls: 0.8424  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.1682  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.1703  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.2537  decode.d2.loss_dice: 0.1712  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.1714  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.2539  decode.d4.loss_dice: 0.1674  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.2572  decode.d5.loss_dice: 0.1682  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.2557  decode.d6.loss_dice: 0.1665  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.2579  decode.d7.loss_dice: 0.1700  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.1687
10/01 04:58:16 - mmengine - INFO - Iter(train) [163100/320000]  base_lr: 5.2653e-05 lr: 5.2653e-06  eta: 19:06:45  time: 0.4417  data_time: 0.0099  memory: 5129  grad_norm: 29.4733  loss: 4.6568  decode.loss_cls: 0.0026  decode.loss_mask: 0.2197  decode.loss_dice: 0.1722  decode.d0.loss_cls: 0.7115  decode.d0.loss_mask: 0.2174  decode.d0.loss_dice: 0.1632  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.2187  decode.d1.loss_dice: 0.1746  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.1751  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.2200  decode.d3.loss_dice: 0.1707  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.1763  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2202  decode.d5.loss_dice: 0.1720  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2194  decode.d6.loss_dice: 0.1705  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.2189  decode.d7.loss_dice: 0.1680  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2215  decode.d8.loss_dice: 0.1697
10/01 04:58:38 - mmengine - INFO - Iter(train) [163150/320000]  base_lr: 5.2638e-05 lr: 5.2638e-06  eta: 19:06:23  time: 0.4420  data_time: 0.0098  memory: 5129  grad_norm: 36.6355  loss: 4.0847  decode.loss_cls: 0.0061  decode.loss_mask: 0.1901  decode.loss_dice: 0.1385  decode.d0.loss_cls: 0.6904  decode.d0.loss_mask: 0.1918  decode.d0.loss_dice: 0.1452  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1399  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.1923  decode.d2.loss_dice: 0.1379  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.1918  decode.d3.loss_dice: 0.1379  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.1895  decode.d4.loss_dice: 0.1375  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.1382  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.1910  decode.d6.loss_dice: 0.1430  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.1899  decode.d7.loss_dice: 0.1419  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.1913  decode.d8.loss_dice: 0.1421
10/01 04:59:00 - mmengine - INFO - Iter(train) [163200/320000]  base_lr: 5.2623e-05 lr: 5.2623e-06  eta: 19:06:01  time: 0.4414  data_time: 0.0098  memory: 5129  grad_norm: 101.0965  loss: 4.8859  decode.loss_cls: 0.0039  decode.loss_mask: 0.2231  decode.loss_dice: 0.1825  decode.d0.loss_cls: 0.7248  decode.d0.loss_mask: 0.2211  decode.d0.loss_dice: 0.1871  decode.d1.loss_cls: 0.0355  decode.d1.loss_mask: 0.2203  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.2236  decode.d2.loss_dice: 0.1778  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.2216  decode.d3.loss_dice: 0.1763  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.2211  decode.d4.loss_dice: 0.1774  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.2216  decode.d5.loss_dice: 0.1784  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.1867  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.1835  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.2231  decode.d8.loss_dice: 0.1823
10/01 04:59:22 - mmengine - INFO - Iter(train) [163250/320000]  base_lr: 5.2608e-05 lr: 5.2608e-06  eta: 19:05:39  time: 0.4417  data_time: 0.0099  memory: 5145  grad_norm: 47.5630  loss: 5.1224  decode.loss_cls: 0.0323  decode.loss_mask: 0.1842  decode.loss_dice: 0.1774  decode.d0.loss_cls: 0.9402  decode.d0.loss_mask: 0.1819  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.1798  decode.d1.loss_dice: 0.1689  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.1839  decode.d2.loss_dice: 0.1656  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.1816  decode.d3.loss_dice: 0.1647  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.1762  decode.d5.loss_cls: 0.0793  decode.d5.loss_mask: 0.1805  decode.d5.loss_dice: 0.1756  decode.d6.loss_cls: 0.0866  decode.d6.loss_mask: 0.1806  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.1799  decode.d7.loss_dice: 0.1616  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.1832  decode.d8.loss_dice: 0.1782
10/01 04:59:44 - mmengine - INFO - Iter(train) [163300/320000]  base_lr: 5.2593e-05 lr: 5.2593e-06  eta: 19:05:17  time: 0.4412  data_time: 0.0099  memory: 5129  grad_norm: 84.3485  loss: 5.5896  decode.loss_cls: 0.0594  decode.loss_mask: 0.2158  decode.loss_dice: 0.2413  decode.d0.loss_cls: 0.8573  decode.d0.loss_mask: 0.2217  decode.d0.loss_dice: 0.2068  decode.d1.loss_cls: 0.1263  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.1759  decode.d2.loss_cls: 0.0172  decode.d2.loss_mask: 0.2160  decode.d2.loss_dice: 0.2374  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.2157  decode.d3.loss_dice: 0.2225  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.2174  decode.d4.loss_dice: 0.2387  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.2164  decode.d5.loss_dice: 0.2164  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.2130  decode.d6.loss_dice: 0.2306  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.2135  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.2146  decode.d8.loss_dice: 0.2239
10/01 05:00:07 - mmengine - INFO - Iter(train) [163350/320000]  base_lr: 5.2578e-05 lr: 5.2578e-06  eta: 19:04:56  time: 0.4603  data_time: 0.0099  memory: 5129  grad_norm: 42.8743  loss: 5.0562  decode.loss_cls: 0.0035  decode.loss_mask: 0.2157  decode.loss_dice: 0.1826  decode.d0.loss_cls: 0.8681  decode.d0.loss_mask: 0.2164  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.0820  decode.d1.loss_mask: 0.2159  decode.d1.loss_dice: 0.1638  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.1763  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.2139  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.1851  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.2135  decode.d5.loss_dice: 0.1686  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2139  decode.d6.loss_dice: 0.1891  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.2170  decode.d7.loss_dice: 0.1872  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.1825
10/01 05:00:29 - mmengine - INFO - Iter(train) [163400/320000]  base_lr: 5.2563e-05 lr: 5.2563e-06  eta: 19:04:34  time: 0.4418  data_time: 0.0100  memory: 5129  grad_norm: 61.0305  loss: 4.5060  decode.loss_cls: 0.0359  decode.loss_mask: 0.2048  decode.loss_dice: 0.1449  decode.d0.loss_cls: 0.7734  decode.d0.loss_mask: 0.2017  decode.d0.loss_dice: 0.1433  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.2038  decode.d1.loss_dice: 0.1454  decode.d2.loss_cls: 0.0327  decode.d2.loss_mask: 0.2029  decode.d2.loss_dice: 0.1453  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.2012  decode.d3.loss_dice: 0.1443  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.1416  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 0.2040  decode.d5.loss_dice: 0.1477  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.2003  decode.d6.loss_dice: 0.1436  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.2012  decode.d7.loss_dice: 0.1429  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1440
10/01 05:00:51 - mmengine - INFO - Iter(train) [163450/320000]  base_lr: 5.2548e-05 lr: 5.2548e-06  eta: 19:04:12  time: 0.4414  data_time: 0.0099  memory: 5119  grad_norm: 114.1316  loss: 6.4294  decode.loss_cls: 0.0662  decode.loss_mask: 0.2677  decode.loss_dice: 0.2320  decode.d0.loss_cls: 0.8329  decode.d0.loss_mask: 0.2755  decode.d0.loss_dice: 0.2101  decode.d1.loss_cls: 0.0726  decode.d1.loss_mask: 0.2721  decode.d1.loss_dice: 0.2304  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.2276  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.2661  decode.d3.loss_dice: 0.2263  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.2750  decode.d4.loss_dice: 0.2339  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.2143  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.2632  decode.d6.loss_dice: 0.2118  decode.d7.loss_cls: 0.0933  decode.d7.loss_mask: 0.2681  decode.d7.loss_dice: 0.2337  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.2725  decode.d8.loss_dice: 0.2317
10/01 05:01:13 - mmengine - INFO - Iter(train) [163500/320000]  base_lr: 5.2533e-05 lr: 5.2533e-06  eta: 19:03:51  time: 0.4421  data_time: 0.0098  memory: 5145  grad_norm: 27.2318  loss: 5.2945  decode.loss_cls: 0.0557  decode.loss_mask: 0.1768  decode.loss_dice: 0.2182  decode.d0.loss_cls: 0.9425  decode.d0.loss_mask: 0.1747  decode.d0.loss_dice: 0.2170  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.1752  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.1748  decode.d2.loss_dice: 0.2121  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.1740  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.1700  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.1737  decode.d5.loss_dice: 0.2134  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.1752  decode.d6.loss_dice: 0.2138  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.1754  decode.d7.loss_dice: 0.2178  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.1753  decode.d8.loss_dice: 0.2135
10/01 05:01:35 - mmengine - INFO - Iter(train) [163550/320000]  base_lr: 5.2518e-05 lr: 5.2518e-06  eta: 19:03:29  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 89.5083  loss: 6.3939  decode.loss_cls: 0.0926  decode.loss_mask: 0.2113  decode.loss_dice: 0.2336  decode.d0.loss_cls: 0.9380  decode.d0.loss_mask: 0.2160  decode.d0.loss_dice: 0.2412  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.2454  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.2126  decode.d2.loss_dice: 0.2331  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.2104  decode.d3.loss_dice: 0.2574  decode.d4.loss_cls: 0.1100  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.2469  decode.d5.loss_cls: 0.0937  decode.d5.loss_mask: 0.2146  decode.d5.loss_dice: 0.2467  decode.d6.loss_cls: 0.0952  decode.d6.loss_mask: 0.2126  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.2332  decode.d8.loss_cls: 0.1091  decode.d8.loss_mask: 0.2091  decode.d8.loss_dice: 0.2356
10/01 05:01:57 - mmengine - INFO - Iter(train) [163600/320000]  base_lr: 5.2502e-05 lr: 5.2502e-06  eta: 19:03:07  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 88.5913  loss: 4.7856  decode.loss_cls: 0.0125  decode.loss_mask: 0.2186  decode.loss_dice: 0.1578  decode.d0.loss_cls: 0.8761  decode.d0.loss_mask: 0.2170  decode.d0.loss_dice: 0.1575  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.2179  decode.d1.loss_dice: 0.1649  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.1593  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.2175  decode.d3.loss_dice: 0.1629  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.2187  decode.d4.loss_dice: 0.1603  decode.d5.loss_cls: 0.0133  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.1641  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.2184  decode.d6.loss_dice: 0.1633  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.1604
10/01 05:02:19 - mmengine - INFO - Iter(train) [163650/320000]  base_lr: 5.2487e-05 lr: 5.2487e-06  eta: 19:02:45  time: 0.4416  data_time: 0.0099  memory: 5119  grad_norm: 55.3118  loss: 5.4151  decode.loss_cls: 0.0999  decode.loss_mask: 0.1592  decode.loss_dice: 0.1990  decode.d0.loss_cls: 0.9465  decode.d0.loss_mask: 0.1586  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 0.1603  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.1013  decode.d2.loss_mask: 0.1605  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.1588  decode.d3.loss_dice: 0.1967  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.1578  decode.d4.loss_dice: 0.1953  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 0.1606  decode.d5.loss_dice: 0.2204  decode.d6.loss_cls: 0.1234  decode.d6.loss_mask: 0.1603  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.0998  decode.d7.loss_mask: 0.1577  decode.d7.loss_dice: 0.1923  decode.d8.loss_cls: 0.1378  decode.d8.loss_mask: 0.1588  decode.d8.loss_dice: 0.1921
10/01 05:02:41 - mmengine - INFO - Iter(train) [163700/320000]  base_lr: 5.2472e-05 lr: 5.2472e-06  eta: 19:02:24  time: 0.4418  data_time: 0.0099  memory: 5129  grad_norm: 72.5681  loss: 4.7549  decode.loss_cls: 0.0124  decode.loss_mask: 0.2143  decode.loss_dice: 0.1605  decode.d0.loss_cls: 0.8173  decode.d0.loss_mask: 0.2231  decode.d0.loss_dice: 0.1686  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.2179  decode.d1.loss_dice: 0.1605  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.2179  decode.d2.loss_dice: 0.1588  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.2187  decode.d3.loss_dice: 0.1588  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.2153  decode.d4.loss_dice: 0.1599  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2168  decode.d5.loss_dice: 0.1578  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.2149  decode.d6.loss_dice: 0.1557  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.2182  decode.d7.loss_dice: 0.1671  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.2175  decode.d8.loss_dice: 0.1600
10/01 05:03:03 - mmengine - INFO - Iter(train) [163750/320000]  base_lr: 5.2457e-05 lr: 5.2457e-06  eta: 19:02:02  time: 0.4418  data_time: 0.0099  memory: 5120  grad_norm: 57.4362  loss: 5.4640  decode.loss_cls: 0.0038  decode.loss_mask: 0.2569  decode.loss_dice: 0.1879  decode.d0.loss_cls: 0.9321  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.1861  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.2634  decode.d1.loss_dice: 0.1899  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.1846  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.1847  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.2626  decode.d4.loss_dice: 0.1880  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.2655  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.1871  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2578  decode.d7.loss_dice: 0.1861  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.2555  decode.d8.loss_dice: 0.1819
10/01 05:03:26 - mmengine - INFO - Iter(train) [163800/320000]  base_lr: 5.2442e-05 lr: 5.2442e-06  eta: 19:01:40  time: 0.4416  data_time: 0.0099  memory: 5120  grad_norm: 53.2537  loss: 6.7046  decode.loss_cls: 0.0770  decode.loss_mask: 0.2350  decode.loss_dice: 0.2400  decode.d0.loss_cls: 0.9194  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2636  decode.d1.loss_cls: 0.1168  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2603  decode.d2.loss_cls: 0.1444  decode.d2.loss_mask: 0.2371  decode.d2.loss_dice: 0.2764  decode.d3.loss_cls: 0.0891  decode.d3.loss_mask: 0.2358  decode.d3.loss_dice: 0.2176  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2284  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.2727  decode.d6.loss_cls: 0.0797  decode.d6.loss_mask: 0.2369  decode.d6.loss_dice: 0.2239  decode.d7.loss_cls: 0.1367  decode.d7.loss_mask: 0.2364  decode.d7.loss_dice: 0.2467  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 0.2377  decode.d8.loss_dice: 0.2471
10/01 05:03:48 - mmengine - INFO - Iter(train) [163850/320000]  base_lr: 5.2427e-05 lr: 5.2427e-06  eta: 19:01:18  time: 0.4424  data_time: 0.0099  memory: 5129  grad_norm: 102.9111  loss: 5.5042  decode.loss_cls: 0.0452  decode.loss_mask: 0.2040  decode.loss_dice: 0.2069  decode.d0.loss_cls: 0.7828  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.2209  decode.d1.loss_cls: 0.1163  decode.d1.loss_mask: 0.2027  decode.d1.loss_dice: 0.2120  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.2029  decode.d2.loss_dice: 0.2017  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.2026  decode.d3.loss_dice: 0.2057  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.2045  decode.d4.loss_dice: 0.2138  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.2110  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.2020  decode.d6.loss_dice: 0.2148  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.2038  decode.d7.loss_dice: 0.2179  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.2025  decode.d8.loss_dice: 0.2155
10/01 05:04:10 - mmengine - INFO - Iter(train) [163900/320000]  base_lr: 5.2412e-05 lr: 5.2412e-06  eta: 19:00:57  time: 0.4418  data_time: 0.0100  memory: 5129  grad_norm: 55.2060  loss: 5.3776  decode.loss_cls: 0.0550  decode.loss_mask: 0.2114  decode.loss_dice: 0.1706  decode.d0.loss_cls: 0.8930  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1778  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.1735  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.2124  decode.d2.loss_dice: 0.1909  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.2115  decode.d3.loss_dice: 0.1706  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.2109  decode.d4.loss_dice: 0.1713  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.1681  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.1694  decode.d7.loss_cls: 0.1096  decode.d7.loss_mask: 0.2103  decode.d7.loss_dice: 0.1681  decode.d8.loss_cls: 0.0806  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.1700
10/01 05:04:32 - mmengine - INFO - Iter(train) [163950/320000]  base_lr: 5.2397e-05 lr: 5.2397e-06  eta: 19:00:35  time: 0.4412  data_time: 0.0098  memory: 5129  grad_norm: 33.3735  loss: 4.5113  decode.loss_cls: 0.0906  decode.loss_mask: 0.1536  decode.loss_dice: 0.1210  decode.d0.loss_cls: 0.8800  decode.d0.loss_mask: 0.1570  decode.d0.loss_dice: 0.1218  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.1567  decode.d1.loss_dice: 0.1228  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 0.1534  decode.d2.loss_dice: 0.1207  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.1532  decode.d3.loss_dice: 0.1214  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.1560  decode.d4.loss_dice: 0.1234  decode.d5.loss_cls: 0.0976  decode.d5.loss_mask: 0.1557  decode.d5.loss_dice: 0.1211  decode.d6.loss_cls: 0.0938  decode.d6.loss_mask: 0.1542  decode.d6.loss_dice: 0.1212  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.1535  decode.d7.loss_dice: 0.1219  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.1539  decode.d8.loss_dice: 0.1213
10/01 05:04:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:04:54 - mmengine - INFO - Iter(train) [164000/320000]  base_lr: 5.2382e-05 lr: 5.2382e-06  eta: 19:00:13  time: 0.4444  data_time: 0.0099  memory: 5120  grad_norm: 125.0467  loss: 5.3226  decode.loss_cls: 0.0232  decode.loss_mask: 0.2173  decode.loss_dice: 0.1924  decode.d0.loss_cls: 0.8577  decode.d0.loss_mask: 0.2214  decode.d0.loss_dice: 0.2062  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.2164  decode.d1.loss_dice: 0.2159  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.1929  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.2154  decode.d3.loss_dice: 0.1959  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.2152  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.2160  decode.d5.loss_dice: 0.1980  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.0259  decode.d7.loss_mask: 0.2206  decode.d7.loss_dice: 0.2044  decode.d8.loss_cls: 0.0255  decode.d8.loss_mask: 0.2195  decode.d8.loss_dice: 0.2023
10/01 05:05:16 - mmengine - INFO - Iter(train) [164050/320000]  base_lr: 5.2366e-05 lr: 5.2366e-06  eta: 18:59:51  time: 0.4420  data_time: 0.0098  memory: 5129  grad_norm: 39.3023  loss: 4.1550  decode.loss_cls: 0.0025  decode.loss_mask: 0.1791  decode.loss_dice: 0.1565  decode.d0.loss_cls: 0.7312  decode.d0.loss_mask: 0.1793  decode.d0.loss_dice: 0.1578  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.1789  decode.d1.loss_dice: 0.1627  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1827  decode.d2.loss_dice: 0.1598  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.1767  decode.d3.loss_dice: 0.1607  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.1823  decode.d4.loss_dice: 0.1623  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.1784  decode.d5.loss_dice: 0.1609  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1796  decode.d6.loss_dice: 0.1617  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1775  decode.d7.loss_dice: 0.1622  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.1808  decode.d8.loss_dice: 0.1608
10/01 05:05:38 - mmengine - INFO - Iter(train) [164100/320000]  base_lr: 5.2351e-05 lr: 5.2351e-06  eta: 18:59:29  time: 0.4446  data_time: 0.0102  memory: 5145  grad_norm: 63.4697  loss: 5.3957  decode.loss_cls: 0.0610  decode.loss_mask: 0.2231  decode.loss_dice: 0.1878  decode.d0.loss_cls: 0.8516  decode.d0.loss_mask: 0.2233  decode.d0.loss_dice: 0.1752  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 0.2190  decode.d1.loss_dice: 0.1824  decode.d2.loss_cls: 0.0634  decode.d2.loss_mask: 0.2214  decode.d2.loss_dice: 0.1791  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.1790  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.2212  decode.d4.loss_dice: 0.1824  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.2208  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.1812  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.1762
10/01 05:06:00 - mmengine - INFO - Iter(train) [164150/320000]  base_lr: 5.2336e-05 lr: 5.2336e-06  eta: 18:59:08  time: 0.4415  data_time: 0.0100  memory: 5129  grad_norm: 38.0173  loss: 6.3044  decode.loss_cls: 0.1533  decode.loss_mask: 0.1724  decode.loss_dice: 0.2423  decode.d0.loss_cls: 0.9952  decode.d0.loss_mask: 0.1695  decode.d0.loss_dice: 0.2001  decode.d1.loss_cls: 0.1701  decode.d1.loss_mask: 0.1670  decode.d1.loss_dice: 0.2115  decode.d2.loss_cls: 0.1818  decode.d2.loss_mask: 0.1667  decode.d2.loss_dice: 0.2292  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.1672  decode.d3.loss_dice: 0.2147  decode.d4.loss_cls: 0.1247  decode.d4.loss_mask: 0.1745  decode.d4.loss_dice: 0.2551  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.1715  decode.d5.loss_dice: 0.2530  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.1760  decode.d6.loss_dice: 0.2374  decode.d7.loss_cls: 0.1153  decode.d7.loss_mask: 0.1739  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.1755  decode.d8.loss_dice: 0.2475
10/01 05:06:23 - mmengine - INFO - Iter(train) [164200/320000]  base_lr: 5.2321e-05 lr: 5.2321e-06  eta: 18:58:46  time: 0.4436  data_time: 0.0101  memory: 5120  grad_norm: 106.6739  loss: 4.7680  decode.loss_cls: 0.0726  decode.loss_mask: 0.2094  decode.loss_dice: 0.1346  decode.d0.loss_cls: 0.8054  decode.d0.loss_mask: 0.2102  decode.d0.loss_dice: 0.1387  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.2061  decode.d1.loss_dice: 0.1338  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.2080  decode.d2.loss_dice: 0.1401  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.2030  decode.d3.loss_dice: 0.1404  decode.d4.loss_cls: 0.0705  decode.d4.loss_mask: 0.2026  decode.d4.loss_dice: 0.1323  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.2067  decode.d5.loss_dice: 0.1355  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.2044  decode.d6.loss_dice: 0.1398  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.2063  decode.d7.loss_dice: 0.1338  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.2109  decode.d8.loss_dice: 0.1388
10/01 05:06:45 - mmengine - INFO - Iter(train) [164250/320000]  base_lr: 5.2306e-05 lr: 5.2306e-06  eta: 18:58:24  time: 0.4423  data_time: 0.0101  memory: 5129  grad_norm: 48.9918  loss: 5.6581  decode.loss_cls: 0.0918  decode.loss_mask: 0.1815  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.7345  decode.d0.loss_mask: 0.1811  decode.d0.loss_dice: 0.2228  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.0924  decode.d2.loss_mask: 0.1802  decode.d2.loss_dice: 0.2373  decode.d3.loss_cls: 0.1050  decode.d3.loss_mask: 0.1846  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.1046  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.2121  decode.d5.loss_cls: 0.1173  decode.d5.loss_mask: 0.1856  decode.d5.loss_dice: 0.2165  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.2215  decode.d7.loss_cls: 0.1193  decode.d7.loss_mask: 0.1849  decode.d7.loss_dice: 0.2157  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.1790  decode.d8.loss_dice: 0.2206
10/01 05:07:07 - mmengine - INFO - Iter(train) [164300/320000]  base_lr: 5.2291e-05 lr: 5.2291e-06  eta: 18:58:02  time: 0.4421  data_time: 0.0099  memory: 5129  grad_norm: 62.7958  loss: 5.9495  decode.loss_cls: 0.0514  decode.loss_mask: 0.2177  decode.loss_dice: 0.2524  decode.d0.loss_cls: 0.8015  decode.d0.loss_mask: 0.2232  decode.d0.loss_dice: 0.2599  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.2191  decode.d1.loss_dice: 0.2535  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.2155  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.2190  decode.d3.loss_dice: 0.2158  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.2171  decode.d4.loss_dice: 0.2023  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2380  decode.d6.loss_cls: 0.0826  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.2434  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.2193  decode.d7.loss_dice: 0.2279  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.2191  decode.d8.loss_dice: 0.2280
10/01 05:07:29 - mmengine - INFO - Iter(train) [164350/320000]  base_lr: 5.2276e-05 lr: 5.2276e-06  eta: 18:57:41  time: 0.4409  data_time: 0.0098  memory: 5120  grad_norm: 80.5430  loss: 4.6630  decode.loss_cls: 0.0120  decode.loss_mask: 0.2144  decode.loss_dice: 0.1743  decode.d0.loss_cls: 0.6297  decode.d0.loss_mask: 0.2178  decode.d0.loss_dice: 0.1769  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.2181  decode.d1.loss_dice: 0.1777  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.2178  decode.d2.loss_dice: 0.1758  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.1776  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.2146  decode.d4.loss_dice: 0.1729  decode.d5.loss_cls: 0.0121  decode.d5.loss_mask: 0.2178  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2174  decode.d6.loss_dice: 0.1725  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.1760  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.2153  decode.d8.loss_dice: 0.1739
10/01 05:07:51 - mmengine - INFO - Iter(train) [164400/320000]  base_lr: 5.2261e-05 lr: 5.2261e-06  eta: 18:57:19  time: 0.4416  data_time: 0.0098  memory: 5129  grad_norm: 67.4645  loss: 4.4433  decode.loss_cls: 0.0377  decode.loss_mask: 0.1903  decode.loss_dice: 0.1491  decode.d0.loss_cls: 0.7099  decode.d0.loss_mask: 0.1878  decode.d0.loss_dice: 0.1433  decode.d1.loss_cls: 0.0465  decode.d1.loss_mask: 0.1886  decode.d1.loss_dice: 0.1499  decode.d2.loss_cls: 0.0241  decode.d2.loss_mask: 0.1867  decode.d2.loss_dice: 0.1476  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.1874  decode.d3.loss_dice: 0.1499  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.1896  decode.d4.loss_dice: 0.1481  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.1500  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.1902  decode.d6.loss_dice: 0.1477  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.1895  decode.d7.loss_dice: 0.1473  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.1898  decode.d8.loss_dice: 0.1488
10/01 05:08:13 - mmengine - INFO - Iter(train) [164450/320000]  base_lr: 5.2246e-05 lr: 5.2246e-06  eta: 18:56:57  time: 0.4437  data_time: 0.0096  memory: 5145  grad_norm: 40.0027  loss: 4.3965  decode.loss_cls: 0.0332  decode.loss_mask: 0.1747  decode.loss_dice: 0.1398  decode.d0.loss_cls: 0.7936  decode.d0.loss_mask: 0.1773  decode.d0.loss_dice: 0.1396  decode.d1.loss_cls: 0.0836  decode.d1.loss_mask: 0.1764  decode.d1.loss_dice: 0.1472  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.1741  decode.d2.loss_dice: 0.1417  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.1744  decode.d3.loss_dice: 0.1429  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.1741  decode.d4.loss_dice: 0.1393  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.1759  decode.d5.loss_dice: 0.1435  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.1739  decode.d6.loss_dice: 0.1434  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.1748  decode.d7.loss_dice: 0.1412  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.1777  decode.d8.loss_dice: 0.1418
10/01 05:08:35 - mmengine - INFO - Iter(train) [164500/320000]  base_lr: 5.2230e-05 lr: 5.2230e-06  eta: 18:56:35  time: 0.4421  data_time: 0.0100  memory: 5129  grad_norm: 45.5908  loss: 4.0296  decode.loss_cls: 0.0065  decode.loss_mask: 0.1671  decode.loss_dice: 0.1557  decode.d0.loss_cls: 0.7917  decode.d0.loss_mask: 0.1657  decode.d0.loss_dice: 0.1478  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.1652  decode.d1.loss_dice: 0.1547  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.1647  decode.d2.loss_dice: 0.1544  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.1647  decode.d3.loss_dice: 0.1551  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.1652  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.1645  decode.d5.loss_dice: 0.1564  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.1652  decode.d6.loss_dice: 0.1563  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.1638  decode.d7.loss_dice: 0.1554  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.1653  decode.d8.loss_dice: 0.1523
10/01 05:08:58 - mmengine - INFO - Iter(train) [164550/320000]  base_lr: 5.2215e-05 lr: 5.2215e-06  eta: 18:56:14  time: 0.4427  data_time: 0.0098  memory: 5120  grad_norm: 26.9659  loss: 3.8506  decode.loss_cls: 0.0010  decode.loss_mask: 0.1665  decode.loss_dice: 0.1379  decode.d0.loss_cls: 0.7855  decode.d0.loss_mask: 0.1658  decode.d0.loss_dice: 0.1299  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.1687  decode.d1.loss_dice: 0.1409  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.1680  decode.d2.loss_dice: 0.1395  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1674  decode.d3.loss_dice: 0.1368  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.1678  decode.d4.loss_dice: 0.1404  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.1688  decode.d5.loss_dice: 0.1428  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.1653  decode.d6.loss_dice: 0.1376  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.1662  decode.d7.loss_dice: 0.1366  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.1660  decode.d8.loss_dice: 0.1370
10/01 05:09:20 - mmengine - INFO - Iter(train) [164600/320000]  base_lr: 5.2200e-05 lr: 5.2200e-06  eta: 18:55:52  time: 0.4421  data_time: 0.0101  memory: 5120  grad_norm: 30.1811  loss: 4.5388  decode.loss_cls: 0.0009  decode.loss_mask: 0.2125  decode.loss_dice: 0.1664  decode.d0.loss_cls: 0.7515  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.1595  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.2133  decode.d1.loss_dice: 0.1685  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2156  decode.d2.loss_dice: 0.1675  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.1666  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.1640  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2117  decode.d5.loss_dice: 0.1653  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2104  decode.d6.loss_dice: 0.1644  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2112  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2143  decode.d8.loss_dice: 0.1644
10/01 05:09:42 - mmengine - INFO - Iter(train) [164650/320000]  base_lr: 5.2185e-05 lr: 5.2185e-06  eta: 18:55:30  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 77.6524  loss: 5.5596  decode.loss_cls: 0.1142  decode.loss_mask: 0.1925  decode.loss_dice: 0.1872  decode.d0.loss_cls: 0.8382  decode.d0.loss_mask: 0.1942  decode.d0.loss_dice: 0.1959  decode.d1.loss_cls: 0.1447  decode.d1.loss_mask: 0.1918  decode.d1.loss_dice: 0.1922  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.1903  decode.d2.loss_dice: 0.1846  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 0.1949  decode.d3.loss_dice: 0.1781  decode.d4.loss_cls: 0.1109  decode.d4.loss_mask: 0.1918  decode.d4.loss_dice: 0.1913  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.1914  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 0.1903  decode.d6.loss_dice: 0.1810  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.1938  decode.d7.loss_dice: 0.1851  decode.d8.loss_cls: 0.1062  decode.d8.loss_mask: 0.1920  decode.d8.loss_dice: 0.1918
10/01 05:10:04 - mmengine - INFO - Iter(train) [164700/320000]  base_lr: 5.2170e-05 lr: 5.2170e-06  eta: 18:55:08  time: 0.4413  data_time: 0.0097  memory: 5129  grad_norm: 29.8659  loss: 4.5041  decode.loss_cls: 0.0012  decode.loss_mask: 0.2161  decode.loss_dice: 0.1624  decode.d0.loss_cls: 0.6952  decode.d0.loss_mask: 0.2206  decode.d0.loss_dice: 0.1593  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.2198  decode.d1.loss_dice: 0.1606  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2198  decode.d2.loss_dice: 0.1640  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.2165  decode.d3.loss_dice: 0.1622  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.2149  decode.d4.loss_dice: 0.1627  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2157  decode.d5.loss_dice: 0.1639  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.2156  decode.d6.loss_dice: 0.1639  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2167  decode.d7.loss_dice: 0.1639  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.2153  decode.d8.loss_dice: 0.1606
10/01 05:10:26 - mmengine - INFO - Iter(train) [164750/320000]  base_lr: 5.2155e-05 lr: 5.2155e-06  eta: 18:54:47  time: 0.4414  data_time: 0.0099  memory: 5129  grad_norm: 25.8410  loss: 4.5462  decode.loss_cls: 0.0037  decode.loss_mask: 0.1967  decode.loss_dice: 0.1674  decode.d0.loss_cls: 0.8840  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.1688  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.1976  decode.d1.loss_dice: 0.1636  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.1970  decode.d2.loss_dice: 0.1641  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.1982  decode.d3.loss_dice: 0.1629  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.1992  decode.d4.loss_dice: 0.1753  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.1962  decode.d5.loss_dice: 0.1603  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.1624  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.1961  decode.d7.loss_dice: 0.1615  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.1570
10/01 05:10:48 - mmengine - INFO - Iter(train) [164800/320000]  base_lr: 5.2140e-05 lr: 5.2140e-06  eta: 18:54:25  time: 0.4419  data_time: 0.0098  memory: 5145  grad_norm: 82.0333  loss: 4.8215  decode.loss_cls: 0.0129  decode.loss_mask: 0.2168  decode.loss_dice: 0.1766  decode.d0.loss_cls: 0.7454  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.1642  decode.d1.loss_cls: 0.0197  decode.d1.loss_mask: 0.2175  decode.d1.loss_dice: 0.1753  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.1730  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.1751  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.1732  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.2178  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.2162  decode.d6.loss_dice: 0.1712  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.2226  decode.d7.loss_dice: 0.1739  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.2205  decode.d8.loss_dice: 0.1742
10/01 05:11:10 - mmengine - INFO - Iter(train) [164850/320000]  base_lr: 5.2125e-05 lr: 5.2125e-06  eta: 18:54:03  time: 0.4425  data_time: 0.0100  memory: 5119  grad_norm: 134.4553  loss: 6.4695  decode.loss_cls: 0.0844  decode.loss_mask: 0.2479  decode.loss_dice: 0.2406  decode.d0.loss_cls: 0.8732  decode.d0.loss_mask: 0.2575  decode.d0.loss_dice: 0.2239  decode.d1.loss_cls: 0.1953  decode.d1.loss_mask: 0.2425  decode.d1.loss_dice: 0.2142  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 0.2449  decode.d2.loss_dice: 0.2252  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2096  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.2402  decode.d4.loss_dice: 0.2164  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.2383  decode.d5.loss_dice: 0.2149  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.2399  decode.d6.loss_dice: 0.2282  decode.d7.loss_cls: 0.0620  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.2373  decode.d8.loss_cls: 0.0769  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.2404
10/01 05:11:32 - mmengine - INFO - Iter(train) [164900/320000]  base_lr: 5.2109e-05 lr: 5.2109e-06  eta: 18:53:41  time: 0.4419  data_time: 0.0097  memory: 5119  grad_norm: 102.0045  loss: 5.8742  decode.loss_cls: 0.0276  decode.loss_mask: 0.2255  decode.loss_dice: 0.2224  decode.d0.loss_cls: 0.8319  decode.d0.loss_mask: 0.2286  decode.d0.loss_dice: 0.1976  decode.d1.loss_cls: 0.1001  decode.d1.loss_mask: 0.2250  decode.d1.loss_dice: 0.1972  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.2295  decode.d2.loss_dice: 0.2415  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.2271  decode.d3.loss_dice: 0.2424  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.2301  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.2441  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.2478  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.2543  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.2253  decode.d8.loss_dice: 0.2321
10/01 05:11:54 - mmengine - INFO - Iter(train) [164950/320000]  base_lr: 5.2094e-05 lr: 5.2094e-06  eta: 18:53:20  time: 0.4415  data_time: 0.0098  memory: 5129  grad_norm: 50.4630  loss: 6.1854  decode.loss_cls: 0.0273  decode.loss_mask: 0.2565  decode.loss_dice: 0.2350  decode.d0.loss_cls: 0.8876  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.2053  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 0.2559  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.2089  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2292  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.2548  decode.d4.loss_dice: 0.2067  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.2584  decode.d5.loss_dice: 0.2382  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.2557  decode.d6.loss_dice: 0.2185  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.2562  decode.d7.loss_dice: 0.2344  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.2567  decode.d8.loss_dice: 0.2286
10/01 05:12:17 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:12:17 - mmengine - INFO - Iter(train) [165000/320000]  base_lr: 5.2079e-05 lr: 5.2079e-06  eta: 18:52:58  time: 0.4579  data_time: 0.0096  memory: 5129  grad_norm: 28.3007  loss: 4.1952  decode.loss_cls: 0.0061  decode.loss_mask: 0.1844  decode.loss_dice: 0.1585  decode.d0.loss_cls: 0.7566  decode.d0.loss_mask: 0.1847  decode.d0.loss_dice: 0.1553  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.1834  decode.d1.loss_dice: 0.1544  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.1817  decode.d2.loss_dice: 0.1592  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.1819  decode.d3.loss_dice: 0.1595  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1819  decode.d4.loss_dice: 0.1589  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.1804  decode.d5.loss_dice: 0.1529  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.1817  decode.d6.loss_dice: 0.1589  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1819  decode.d7.loss_dice: 0.1567  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.1810  decode.d8.loss_dice: 0.1581
10/01 05:12:39 - mmengine - INFO - Iter(train) [165050/320000]  base_lr: 5.2064e-05 lr: 5.2064e-06  eta: 18:52:36  time: 0.4420  data_time: 0.0095  memory: 5129  grad_norm: 44.5905  loss: 5.4089  decode.loss_cls: 0.0716  decode.loss_mask: 0.1773  decode.loss_dice: 0.2087  decode.d0.loss_cls: 0.9399  decode.d0.loss_mask: 0.1765  decode.d0.loss_dice: 0.1872  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.1753  decode.d1.loss_dice: 0.1835  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 0.1762  decode.d2.loss_dice: 0.2238  decode.d3.loss_cls: 0.1044  decode.d3.loss_mask: 0.1750  decode.d3.loss_dice: 0.1823  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 0.1777  decode.d4.loss_dice: 0.1989  decode.d5.loss_cls: 0.0744  decode.d5.loss_mask: 0.1753  decode.d5.loss_dice: 0.2070  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.1750  decode.d6.loss_dice: 0.1862  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.1747  decode.d7.loss_dice: 0.2049  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.1745  decode.d8.loss_dice: 0.1904
10/01 05:13:01 - mmengine - INFO - Iter(train) [165100/320000]  base_lr: 5.2049e-05 lr: 5.2049e-06  eta: 18:52:15  time: 0.4430  data_time: 0.0100  memory: 5130  grad_norm: 38.5213  loss: 5.5485  decode.loss_cls: 0.0970  decode.loss_mask: 0.1619  decode.loss_dice: 0.1946  decode.d0.loss_cls: 0.8184  decode.d0.loss_mask: 0.1633  decode.d0.loss_dice: 0.2150  decode.d1.loss_cls: 0.2031  decode.d1.loss_mask: 0.1613  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 0.1637  decode.d2.loss_dice: 0.1998  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.1627  decode.d3.loss_dice: 0.2144  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.1619  decode.d4.loss_dice: 0.2214  decode.d5.loss_cls: 0.1049  decode.d5.loss_mask: 0.1633  decode.d5.loss_dice: 0.2246  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.1602  decode.d6.loss_dice: 0.2113  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.1601  decode.d7.loss_dice: 0.2272  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.1622  decode.d8.loss_dice: 0.2395
10/01 05:13:23 - mmengine - INFO - Iter(train) [165150/320000]  base_lr: 5.2034e-05 lr: 5.2034e-06  eta: 18:51:53  time: 0.4428  data_time: 0.0098  memory: 5129  grad_norm: 25.6349  loss: 3.9034  decode.loss_cls: 0.0026  decode.loss_mask: 0.1783  decode.loss_dice: 0.1396  decode.d0.loss_cls: 0.6873  decode.d0.loss_mask: 0.1774  decode.d0.loss_dice: 0.1346  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.1767  decode.d1.loss_dice: 0.1436  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1777  decode.d2.loss_dice: 0.1411  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.1774  decode.d3.loss_dice: 0.1421  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.1782  decode.d4.loss_dice: 0.1417  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.1763  decode.d5.loss_dice: 0.1431  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.1781  decode.d6.loss_dice: 0.1414  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.1767  decode.d7.loss_dice: 0.1440  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.1768  decode.d8.loss_dice: 0.1406
10/01 05:13:45 - mmengine - INFO - Iter(train) [165200/320000]  base_lr: 5.2019e-05 lr: 5.2019e-06  eta: 18:51:31  time: 0.4423  data_time: 0.0100  memory: 5129  grad_norm: 276.4669  loss: 5.7663  decode.loss_cls: 0.0274  decode.loss_mask: 0.2498  decode.loss_dice: 0.1773  decode.d0.loss_cls: 0.6178  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.2485  decode.d1.loss_dice: 0.1811  decode.d2.loss_cls: 0.0828  decode.d2.loss_mask: 0.2494  decode.d2.loss_dice: 0.1873  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.3335  decode.d3.loss_dice: 0.2163  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.2288  decode.d4.loss_dice: 0.1961  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.3333  decode.d5.loss_dice: 0.1881  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.3508  decode.d6.loss_dice: 0.1887  decode.d7.loss_cls: 0.0211  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.2269  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.2681  decode.d8.loss_dice: 0.1854
10/01 05:14:08 - mmengine - INFO - Iter(train) [165250/320000]  base_lr: 5.2004e-05 lr: 5.2004e-06  eta: 18:51:09  time: 0.4438  data_time: 0.0100  memory: 5145  grad_norm: 29.2900  loss: 4.4530  decode.loss_cls: 0.0030  decode.loss_mask: 0.2034  decode.loss_dice: 0.1606  decode.d0.loss_cls: 0.7865  decode.d0.loss_mask: 0.2057  decode.d0.loss_dice: 0.1582  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.2027  decode.d1.loss_dice: 0.1592  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.1603  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.2017  decode.d3.loss_dice: 0.1619  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.2046  decode.d4.loss_dice: 0.1611  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2011  decode.d5.loss_dice: 0.1625  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.2041  decode.d6.loss_dice: 0.1623  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.2035  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2030  decode.d8.loss_dice: 0.1590
10/01 05:14:30 - mmengine - INFO - Iter(train) [165300/320000]  base_lr: 5.1989e-05 lr: 5.1989e-06  eta: 18:50:48  time: 0.4429  data_time: 0.0100  memory: 5145  grad_norm: 32.7863  loss: 5.4155  decode.loss_cls: 0.0787  decode.loss_mask: 0.1806  decode.loss_dice: 0.2318  decode.d0.loss_cls: 0.9638  decode.d0.loss_mask: 0.1812  decode.d0.loss_dice: 0.2192  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.1828  decode.d1.loss_dice: 0.2383  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.1821  decode.d2.loss_dice: 0.2304  decode.d3.loss_cls: 0.0295  decode.d3.loss_mask: 0.1824  decode.d3.loss_dice: 0.2047  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.2396  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.1806  decode.d5.loss_dice: 0.2306  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.1804  decode.d6.loss_dice: 0.2122  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.1797  decode.d7.loss_dice: 0.1977  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.1804  decode.d8.loss_dice: 0.2035
10/01 05:14:52 - mmengine - INFO - Iter(train) [165350/320000]  base_lr: 5.1973e-05 lr: 5.1973e-06  eta: 18:50:26  time: 0.4430  data_time: 0.0098  memory: 5145  grad_norm: 32.4309  loss: 4.7920  decode.loss_cls: 0.0826  decode.loss_mask: 0.1503  decode.loss_dice: 0.1691  decode.d0.loss_cls: 0.8295  decode.d0.loss_mask: 0.1530  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.1498  decode.d1.loss_dice: 0.1730  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.1495  decode.d2.loss_dice: 0.1697  decode.d3.loss_cls: 0.0832  decode.d3.loss_mask: 0.1506  decode.d3.loss_dice: 0.1679  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.1518  decode.d4.loss_dice: 0.1764  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 0.1488  decode.d5.loss_dice: 0.1698  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.1511  decode.d6.loss_dice: 0.1687  decode.d7.loss_cls: 0.0901  decode.d7.loss_mask: 0.1500  decode.d7.loss_dice: 0.1715  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 0.1490  decode.d8.loss_dice: 0.1697
10/01 05:15:14 - mmengine - INFO - Iter(train) [165400/320000]  base_lr: 5.1958e-05 lr: 5.1958e-06  eta: 18:50:04  time: 0.4422  data_time: 0.0100  memory: 5120  grad_norm: 150.3471  loss: 5.4836  decode.loss_cls: 0.0879  decode.loss_mask: 0.2234  decode.loss_dice: 0.1783  decode.d0.loss_cls: 0.8412  decode.d0.loss_mask: 0.2273  decode.d0.loss_dice: 0.1806  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.2243  decode.d1.loss_dice: 0.1936  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.1696  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.1892  decode.d4.loss_cls: 0.0226  decode.d4.loss_mask: 0.2199  decode.d4.loss_dice: 0.2018  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.2210  decode.d6.loss_dice: 0.1825  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.1568  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.2235  decode.d8.loss_dice: 0.1893
10/01 05:15:36 - mmengine - INFO - Iter(train) [165450/320000]  base_lr: 5.1943e-05 lr: 5.1943e-06  eta: 18:49:42  time: 0.4427  data_time: 0.0100  memory: 5129  grad_norm: 53.9588  loss: 5.2255  decode.loss_cls: 0.0059  decode.loss_mask: 0.2443  decode.loss_dice: 0.2028  decode.d0.loss_cls: 0.6816  decode.d0.loss_mask: 0.2505  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.1994  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.2454  decode.d2.loss_dice: 0.1960  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2437  decode.d3.loss_dice: 0.2093  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.2468  decode.d4.loss_dice: 0.2015  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2480  decode.d5.loss_dice: 0.1965  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.2446  decode.d6.loss_dice: 0.1956  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.2423  decode.d7.loss_dice: 0.2039  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2008
10/01 05:15:58 - mmengine - INFO - Iter(train) [165500/320000]  base_lr: 5.1928e-05 lr: 5.1928e-06  eta: 18:49:21  time: 0.4422  data_time: 0.0099  memory: 5129  grad_norm: 47.4711  loss: 5.8861  decode.loss_cls: 0.1050  decode.loss_mask: 0.2007  decode.loss_dice: 0.1914  decode.d0.loss_cls: 0.8428  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.1664  decode.d1.loss_cls: 0.1093  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.2047  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 0.1872  decode.d2.loss_dice: 0.1993  decode.d3.loss_cls: 0.1267  decode.d3.loss_mask: 0.1904  decode.d3.loss_dice: 0.1831  decode.d4.loss_cls: 0.1328  decode.d4.loss_mask: 0.1939  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 0.1770  decode.d5.loss_dice: 0.1937  decode.d6.loss_cls: 0.1338  decode.d6.loss_mask: 0.1736  decode.d6.loss_dice: 0.2051  decode.d7.loss_cls: 0.1290  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.2087  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.2305
10/01 05:16:20 - mmengine - INFO - Iter(train) [165550/320000]  base_lr: 5.1913e-05 lr: 5.1913e-06  eta: 18:48:59  time: 0.4416  data_time: 0.0098  memory: 5129  grad_norm: 25.3589  loss: 3.9405  decode.loss_cls: 0.0012  decode.loss_mask: 0.1611  decode.loss_dice: 0.1463  decode.d0.loss_cls: 0.8267  decode.d0.loss_mask: 0.1614  decode.d0.loss_dice: 0.1399  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.1618  decode.d1.loss_dice: 0.1482  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.1637  decode.d2.loss_dice: 0.1505  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.1623  decode.d3.loss_dice: 0.1477  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.1620  decode.d4.loss_dice: 0.1571  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1623  decode.d5.loss_dice: 0.1502  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1597  decode.d6.loss_dice: 0.1464  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1617  decode.d7.loss_dice: 0.1506  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.1629  decode.d8.loss_dice: 0.1455
10/01 05:16:43 - mmengine - INFO - Iter(train) [165600/320000]  base_lr: 5.1898e-05 lr: 5.1898e-06  eta: 18:48:37  time: 0.4420  data_time: 0.0098  memory: 5120  grad_norm: 57.7118  loss: 5.4144  decode.loss_cls: 0.1139  decode.loss_mask: 0.1725  decode.loss_dice: 0.2352  decode.d0.loss_cls: 0.8686  decode.d0.loss_mask: 0.1730  decode.d0.loss_dice: 0.1962  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.1724  decode.d1.loss_dice: 0.2149  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.1715  decode.d2.loss_dice: 0.2288  decode.d3.loss_cls: 0.1387  decode.d3.loss_mask: 0.1730  decode.d3.loss_dice: 0.2193  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.1722  decode.d4.loss_dice: 0.1760  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.1727  decode.d5.loss_dice: 0.2096  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 0.1716  decode.d6.loss_dice: 0.2140  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.1699  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.1704  decode.d8.loss_dice: 0.2205
10/01 05:17:05 - mmengine - INFO - Iter(train) [165650/320000]  base_lr: 5.1883e-05 lr: 5.1883e-06  eta: 18:48:15  time: 0.4405  data_time: 0.0096  memory: 5120  grad_norm: 223.9222  loss: 5.8047  decode.loss_cls: 0.0254  decode.loss_mask: 0.2385  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.2117  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.2466  decode.d1.loss_dice: 0.2017  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.2058  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.2397  decode.d3.loss_dice: 0.2075  decode.d4.loss_cls: 0.0536  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.2420  decode.d6.loss_dice: 0.2294  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.2399  decode.d7.loss_dice: 0.2086  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.2187
10/01 05:17:27 - mmengine - INFO - Iter(train) [165700/320000]  base_lr: 5.1868e-05 lr: 5.1868e-06  eta: 18:47:54  time: 0.4405  data_time: 0.0097  memory: 5120  grad_norm: 124.6122  loss: 5.1043  decode.loss_cls: 0.0358  decode.loss_mask: 0.2271  decode.loss_dice: 0.1763  decode.d0.loss_cls: 0.7680  decode.d0.loss_mask: 0.2300  decode.d0.loss_dice: 0.1677  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.1767  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.2283  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.2255  decode.d3.loss_dice: 0.1815  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.1751  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.1750  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.1856  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.2224  decode.d7.loss_dice: 0.1765  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.1760
10/01 05:17:49 - mmengine - INFO - Iter(train) [165750/320000]  base_lr: 5.1852e-05 lr: 5.1852e-06  eta: 18:47:32  time: 0.4439  data_time: 0.0097  memory: 5129  grad_norm: 80.4562  loss: 5.6306  decode.loss_cls: 0.0606  decode.loss_mask: 0.2242  decode.loss_dice: 0.1772  decode.d0.loss_cls: 0.8268  decode.d0.loss_mask: 0.2260  decode.d0.loss_dice: 0.1977  decode.d1.loss_cls: 0.1309  decode.d1.loss_mask: 0.2259  decode.d1.loss_dice: 0.1765  decode.d2.loss_cls: 0.0926  decode.d2.loss_mask: 0.2248  decode.d2.loss_dice: 0.1933  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.2282  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.1744  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.2252  decode.d5.loss_dice: 0.1912  decode.d6.loss_cls: 0.0847  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.1769  decode.d8.loss_cls: 0.0969  decode.d8.loss_mask: 0.2279  decode.d8.loss_dice: 0.1779
10/01 05:18:11 - mmengine - INFO - Iter(train) [165800/320000]  base_lr: 5.1837e-05 lr: 5.1837e-06  eta: 18:47:10  time: 0.4424  data_time: 0.0098  memory: 5129  grad_norm: 33.3877  loss: 4.1994  decode.loss_cls: 0.0144  decode.loss_mask: 0.1594  decode.loss_dice: 0.1610  decode.d0.loss_cls: 0.9051  decode.d0.loss_mask: 0.1602  decode.d0.loss_dice: 0.1537  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.1579  decode.d1.loss_dice: 0.1656  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.1589  decode.d2.loss_dice: 0.1593  decode.d3.loss_cls: 0.0103  decode.d3.loss_mask: 0.1592  decode.d3.loss_dice: 0.1671  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.1579  decode.d4.loss_dice: 0.1542  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.1596  decode.d5.loss_dice: 0.1616  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.1606  decode.d6.loss_dice: 0.1647  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.1587  decode.d7.loss_dice: 0.1658  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.1593  decode.d8.loss_dice: 0.1647
10/01 05:18:33 - mmengine - INFO - Iter(train) [165850/320000]  base_lr: 5.1822e-05 lr: 5.1822e-06  eta: 18:46:48  time: 0.4453  data_time: 0.0100  memory: 5129  grad_norm: 83.3704  loss: 5.2718  decode.loss_cls: 0.0173  decode.loss_mask: 0.2018  decode.loss_dice: 0.2091  decode.d0.loss_cls: 0.9408  decode.d0.loss_mask: 0.1906  decode.d0.loss_dice: 0.1781  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.1811  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.1943  decode.d2.loss_dice: 0.1964  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.1921  decode.d3.loss_dice: 0.1863  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.1886  decode.d4.loss_dice: 0.1836  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.1938  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.1894  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.1905  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.2032  decode.d8.loss_dice: 0.2074
10/01 05:18:55 - mmengine - INFO - Iter(train) [165900/320000]  base_lr: 5.1807e-05 lr: 5.1807e-06  eta: 18:46:27  time: 0.4424  data_time: 0.0100  memory: 5145  grad_norm: 25.7904  loss: 3.9427  decode.loss_cls: 0.0013  decode.loss_mask: 0.1615  decode.loss_dice: 0.1426  decode.d0.loss_cls: 0.8921  decode.d0.loss_mask: 0.1619  decode.d0.loss_dice: 0.1342  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.1587  decode.d1.loss_dice: 0.1475  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.1614  decode.d2.loss_dice: 0.1485  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1595  decode.d3.loss_dice: 0.1389  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.1620  decode.d4.loss_dice: 0.1443  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1613  decode.d5.loss_dice: 0.1441  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.1602  decode.d6.loss_dice: 0.1425  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1600  decode.d7.loss_dice: 0.1454  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1591  decode.d8.loss_dice: 0.1441
10/01 05:19:17 - mmengine - INFO - Iter(train) [165950/320000]  base_lr: 5.1792e-05 lr: 5.1792e-06  eta: 18:46:05  time: 0.4445  data_time: 0.0101  memory: 5129  grad_norm: 132.1723  loss: 9.1281  decode.loss_cls: 0.2546  decode.loss_mask: 0.3014  decode.loss_dice: 0.2214  decode.d0.loss_cls: 0.8647  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.2181  decode.d1.loss_cls: 0.2269  decode.d1.loss_mask: 0.3002  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.2745  decode.d2.loss_mask: 0.3064  decode.d2.loss_dice: 0.2172  decode.d3.loss_cls: 0.2382  decode.d3.loss_mask: 0.3325  decode.d3.loss_dice: 0.2263  decode.d4.loss_cls: 0.1978  decode.d4.loss_mask: 0.4653  decode.d4.loss_dice: 0.2714  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.3437  decode.d5.loss_dice: 0.2695  decode.d6.loss_cls: 0.3327  decode.d6.loss_mask: 0.3660  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.3169  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.2965  decode.d8.loss_mask: 0.4491  decode.d8.loss_dice: 0.2767
10/01 05:19:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:19:40 - mmengine - INFO - Iter(train) [166000/320000]  base_lr: 5.1777e-05 lr: 5.1777e-06  eta: 18:45:43  time: 0.4429  data_time: 0.0101  memory: 5129  grad_norm: 72.3805  loss: 5.9590  decode.loss_cls: 0.0584  decode.loss_mask: 0.2074  decode.loss_dice: 0.2069  decode.d0.loss_cls: 1.0406  decode.d0.loss_mask: 0.2133  decode.d0.loss_dice: 0.2023  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.2101  decode.d1.loss_dice: 0.2111  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.2093  decode.d2.loss_dice: 0.2077  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.2094  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.2070  decode.d5.loss_cls: 0.0835  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1973  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 0.2061  decode.d6.loss_dice: 0.2052  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.2342  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.2063
10/01 05:20:02 - mmengine - INFO - Iter(train) [166050/320000]  base_lr: 5.1762e-05 lr: 5.1762e-06  eta: 18:45:21  time: 0.4450  data_time: 0.0099  memory: 5129  grad_norm: 56.6661  loss: 4.0135  decode.loss_cls: 0.0089  decode.loss_mask: 0.1775  decode.loss_dice: 0.1405  decode.d0.loss_cls: 0.7838  decode.d0.loss_mask: 0.1787  decode.d0.loss_dice: 0.1367  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.1785  decode.d1.loss_dice: 0.1379  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.1801  decode.d2.loss_dice: 0.1433  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.1775  decode.d3.loss_dice: 0.1366  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.1772  decode.d4.loss_dice: 0.1396  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.1749  decode.d5.loss_dice: 0.1349  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.1765  decode.d6.loss_dice: 0.1369  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.1782  decode.d7.loss_dice: 0.1364  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.1795  decode.d8.loss_dice: 0.1402
10/01 05:20:24 - mmengine - INFO - Iter(train) [166100/320000]  base_lr: 5.1747e-05 lr: 5.1747e-06  eta: 18:45:00  time: 0.4423  data_time: 0.0098  memory: 5145  grad_norm: 65.1803  loss: 6.5474  decode.loss_cls: 0.1188  decode.loss_mask: 0.1842  decode.loss_dice: 0.2273  decode.d0.loss_cls: 1.1484  decode.d0.loss_mask: 0.1902  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.2639  decode.d1.loss_mask: 0.1883  decode.d1.loss_dice: 0.2097  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.1873  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.1208  decode.d3.loss_mask: 0.1876  decode.d3.loss_dice: 0.2279  decode.d4.loss_cls: 0.1148  decode.d4.loss_mask: 0.1863  decode.d4.loss_dice: 0.2082  decode.d5.loss_cls: 0.1354  decode.d5.loss_mask: 0.1885  decode.d5.loss_dice: 0.2087  decode.d6.loss_cls: 0.1190  decode.d6.loss_mask: 0.1882  decode.d6.loss_dice: 0.2334  decode.d7.loss_cls: 0.1318  decode.d7.loss_mask: 0.1900  decode.d7.loss_dice: 0.2180  decode.d8.loss_cls: 0.1450  decode.d8.loss_mask: 0.1880  decode.d8.loss_dice: 0.2084
10/01 05:20:46 - mmengine - INFO - Iter(train) [166150/320000]  base_lr: 5.1731e-05 lr: 5.1731e-06  eta: 18:44:38  time: 0.4417  data_time: 0.0097  memory: 5120  grad_norm: 58.2632  loss: 5.2880  decode.loss_cls: 0.0324  decode.loss_mask: 0.2089  decode.loss_dice: 0.1852  decode.d0.loss_cls: 0.8063  decode.d0.loss_mask: 0.2104  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.2100  decode.d1.loss_dice: 0.2255  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.2091  decode.d2.loss_dice: 0.2070  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.1851  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.2087  decode.d4.loss_dice: 0.2103  decode.d5.loss_cls: 0.0584  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.1956  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.2078  decode.d6.loss_dice: 0.1796  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.2087  decode.d8.loss_dice: 0.1839
10/01 05:21:08 - mmengine - INFO - Iter(train) [166200/320000]  base_lr: 5.1716e-05 lr: 5.1716e-06  eta: 18:44:16  time: 0.4420  data_time: 0.0100  memory: 5120  grad_norm: 26.8320  loss: 4.0931  decode.loss_cls: 0.0008  decode.loss_mask: 0.1883  decode.loss_dice: 0.1549  decode.d0.loss_cls: 0.6789  decode.d0.loss_mask: 0.1875  decode.d0.loss_dice: 0.1498  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.1868  decode.d1.loss_dice: 0.1487  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1540  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.1866  decode.d3.loss_dice: 0.1509  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.1848  decode.d4.loss_dice: 0.1534  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.1872  decode.d5.loss_dice: 0.1508  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1913  decode.d6.loss_dice: 0.1551  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.1874  decode.d7.loss_dice: 0.1564  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.1871  decode.d8.loss_dice: 0.1569
10/01 05:21:30 - mmengine - INFO - Iter(train) [166250/320000]  base_lr: 5.1701e-05 lr: 5.1701e-06  eta: 18:43:54  time: 0.4418  data_time: 0.0100  memory: 5129  grad_norm: 81.0104  loss: 5.2382  decode.loss_cls: 0.0720  decode.loss_mask: 0.1829  decode.loss_dice: 0.2078  decode.d0.loss_cls: 0.7400  decode.d0.loss_mask: 0.1869  decode.d0.loss_dice: 0.2110  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.1874  decode.d1.loss_dice: 0.1990  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.1838  decode.d2.loss_dice: 0.2052  decode.d3.loss_cls: 0.1024  decode.d3.loss_mask: 0.1865  decode.d3.loss_dice: 0.2076  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.1841  decode.d4.loss_dice: 0.2012  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.1839  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.1835  decode.d6.loss_dice: 0.2033  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.1826  decode.d7.loss_dice: 0.2049  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.1847  decode.d8.loss_dice: 0.2103
10/01 05:21:52 - mmengine - INFO - Iter(train) [166300/320000]  base_lr: 5.1686e-05 lr: 5.1686e-06  eta: 18:43:33  time: 0.4419  data_time: 0.0099  memory: 5120  grad_norm: 37.3213  loss: 5.4298  decode.loss_cls: 0.0648  decode.loss_mask: 0.1726  decode.loss_dice: 0.2054  decode.d0.loss_cls: 0.9361  decode.d0.loss_mask: 0.1748  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.1307  decode.d1.loss_mask: 0.1711  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.0869  decode.d2.loss_mask: 0.1729  decode.d2.loss_dice: 0.2136  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.1718  decode.d3.loss_dice: 0.2035  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 0.1718  decode.d4.loss_dice: 0.2014  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.1732  decode.d5.loss_dice: 0.2100  decode.d6.loss_cls: 0.0860  decode.d6.loss_mask: 0.1721  decode.d6.loss_dice: 0.2029  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.1725  decode.d7.loss_dice: 0.2119  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.1724  decode.d8.loss_dice: 0.2153
10/01 05:22:15 - mmengine - INFO - Iter(train) [166350/320000]  base_lr: 5.1671e-05 lr: 5.1671e-06  eta: 18:43:11  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 44.4343  loss: 4.4948  decode.loss_cls: 0.0329  decode.loss_mask: 0.1810  decode.loss_dice: 0.1441  decode.d0.loss_cls: 0.8647  decode.d0.loss_mask: 0.1812  decode.d0.loss_dice: 0.1424  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.1813  decode.d1.loss_dice: 0.1384  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.1819  decode.d2.loss_dice: 0.1398  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.1812  decode.d3.loss_dice: 0.1487  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.1831  decode.d4.loss_dice: 0.1493  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.1813  decode.d5.loss_dice: 0.1417  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.1810  decode.d6.loss_dice: 0.1393  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.1824  decode.d7.loss_dice: 0.1445  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.1806  decode.d8.loss_dice: 0.1417
10/01 05:22:37 - mmengine - INFO - Iter(train) [166400/320000]  base_lr: 5.1656e-05 lr: 5.1656e-06  eta: 18:42:49  time: 0.4423  data_time: 0.0101  memory: 5129  grad_norm: 63.9129  loss: 4.9596  decode.loss_cls: 0.0071  decode.loss_mask: 0.2107  decode.loss_dice: 0.1836  decode.d0.loss_cls: 0.9390  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1801  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.2111  decode.d1.loss_dice: 0.1844  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.2117  decode.d2.loss_dice: 0.1905  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.1832  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1942  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1858  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.2104  decode.d6.loss_dice: 0.1809  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.1829  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.1815
10/01 05:22:59 - mmengine - INFO - Iter(train) [166450/320000]  base_lr: 5.1641e-05 lr: 5.1641e-06  eta: 18:42:27  time: 0.4420  data_time: 0.0100  memory: 5129  grad_norm: 73.5546  loss: 4.5713  decode.loss_cls: 0.0083  decode.loss_mask: 0.2106  decode.loss_dice: 0.1571  decode.d0.loss_cls: 0.7218  decode.d0.loss_mask: 0.2116  decode.d0.loss_dice: 0.1614  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2136  decode.d1.loss_dice: 0.1636  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.2139  decode.d2.loss_dice: 0.1624  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.1592  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2147  decode.d4.loss_dice: 0.1633  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.2127  decode.d5.loss_dice: 0.1596  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.2128  decode.d6.loss_dice: 0.1628  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2121  decode.d7.loss_dice: 0.1651  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.2152  decode.d8.loss_dice: 0.1659
10/01 05:23:21 - mmengine - INFO - Iter(train) [166500/320000]  base_lr: 5.1625e-05 lr: 5.1625e-06  eta: 18:42:06  time: 0.4422  data_time: 0.0100  memory: 5146  grad_norm: 102.6222  loss: 6.2010  decode.loss_cls: 0.1342  decode.loss_mask: 0.2091  decode.loss_dice: 0.2257  decode.d0.loss_cls: 0.8936  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.2181  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.2258  decode.d1.loss_dice: 0.2268  decode.d2.loss_cls: 0.1346  decode.d2.loss_mask: 0.2136  decode.d2.loss_dice: 0.2233  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 0.2075  decode.d3.loss_dice: 0.2030  decode.d4.loss_cls: 0.1334  decode.d4.loss_mask: 0.2075  decode.d4.loss_dice: 0.2071  decode.d5.loss_cls: 0.1374  decode.d5.loss_mask: 0.2100  decode.d5.loss_dice: 0.1981  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.0826  decode.d7.loss_mask: 0.2125  decode.d7.loss_dice: 0.2249  decode.d8.loss_cls: 0.1363  decode.d8.loss_mask: 0.2076  decode.d8.loss_dice: 0.2097
10/01 05:23:43 - mmengine - INFO - Iter(train) [166550/320000]  base_lr: 5.1610e-05 lr: 5.1610e-06  eta: 18:41:44  time: 0.4424  data_time: 0.0098  memory: 5145  grad_norm: 33.3094  loss: 4.8070  decode.loss_cls: 0.0906  decode.loss_mask: 0.1297  decode.loss_dice: 0.1466  decode.d0.loss_cls: 0.8671  decode.d0.loss_mask: 0.1291  decode.d0.loss_dice: 0.1702  decode.d1.loss_cls: 0.0955  decode.d1.loss_mask: 0.1286  decode.d1.loss_dice: 0.1510  decode.d2.loss_cls: 0.1341  decode.d2.loss_mask: 0.1278  decode.d2.loss_dice: 0.1431  decode.d3.loss_cls: 0.1290  decode.d3.loss_mask: 0.1289  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 0.1298  decode.d4.loss_dice: 0.1391  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.1285  decode.d5.loss_dice: 0.1278  decode.d6.loss_cls: 0.1519  decode.d6.loss_mask: 0.1292  decode.d6.loss_dice: 0.1428  decode.d7.loss_cls: 0.1397  decode.d7.loss_mask: 0.1280  decode.d7.loss_dice: 0.1490  decode.d8.loss_cls: 0.1424  decode.d8.loss_mask: 0.1298  decode.d8.loss_dice: 0.1639
10/01 05:24:05 - mmengine - INFO - Iter(train) [166600/320000]  base_lr: 5.1595e-05 lr: 5.1595e-06  eta: 18:41:22  time: 0.4414  data_time: 0.0098  memory: 5129  grad_norm: 187.2116  loss: 5.5136  decode.loss_cls: 0.0442  decode.loss_mask: 0.2435  decode.loss_dice: 0.1908  decode.d0.loss_cls: 0.6766  decode.d0.loss_mask: 0.2598  decode.d0.loss_dice: 0.1971  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.2535  decode.d1.loss_dice: 0.1912  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.1916  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.2511  decode.d3.loss_dice: 0.1920  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.1872  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.2480  decode.d5.loss_dice: 0.1906  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.2452  decode.d6.loss_dice: 0.1883  decode.d7.loss_cls: 0.0629  decode.d7.loss_mask: 0.2412  decode.d7.loss_dice: 0.1851  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.1886
10/01 05:24:27 - mmengine - INFO - Iter(train) [166650/320000]  base_lr: 5.1580e-05 lr: 5.1580e-06  eta: 18:41:00  time: 0.4595  data_time: 0.0098  memory: 5119  grad_norm: 59.1959  loss: 5.4828  decode.loss_cls: 0.0841  decode.loss_mask: 0.1724  decode.loss_dice: 0.1702  decode.d0.loss_cls: 0.9131  decode.d0.loss_mask: 0.1718  decode.d0.loss_dice: 0.1725  decode.d1.loss_cls: 0.1573  decode.d1.loss_mask: 0.1752  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.1094  decode.d2.loss_mask: 0.1689  decode.d2.loss_dice: 0.1719  decode.d3.loss_cls: 0.1210  decode.d3.loss_mask: 0.1685  decode.d3.loss_dice: 0.1689  decode.d4.loss_cls: 0.1247  decode.d4.loss_mask: 0.1688  decode.d4.loss_dice: 0.1769  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.1720  decode.d5.loss_dice: 0.1812  decode.d6.loss_cls: 0.1378  decode.d6.loss_mask: 0.1701  decode.d6.loss_dice: 0.1722  decode.d7.loss_cls: 0.1235  decode.d7.loss_mask: 0.1706  decode.d7.loss_dice: 0.1683  decode.d8.loss_cls: 0.1147  decode.d8.loss_mask: 0.1695  decode.d8.loss_dice: 0.1760
10/01 05:24:50 - mmengine - INFO - Iter(train) [166700/320000]  base_lr: 5.1565e-05 lr: 5.1565e-06  eta: 18:40:39  time: 0.4420  data_time: 0.0099  memory: 5129  grad_norm: 49.6943  loss: 5.3040  decode.loss_cls: 0.0819  decode.loss_mask: 0.1733  decode.loss_dice: 0.1862  decode.d0.loss_cls: 0.9423  decode.d0.loss_mask: 0.1966  decode.d0.loss_dice: 0.1802  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.1746  decode.d1.loss_dice: 0.2007  decode.d2.loss_cls: 0.0741  decode.d2.loss_mask: 0.1765  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.1808  decode.d3.loss_dice: 0.1953  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.1832  decode.d4.loss_dice: 0.1736  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.1807  decode.d5.loss_dice: 0.1988  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 0.1756  decode.d6.loss_dice: 0.1962  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.1768  decode.d7.loss_dice: 0.1936  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.1770  decode.d8.loss_dice: 0.1944
10/01 05:25:12 - mmengine - INFO - Iter(train) [166750/320000]  base_lr: 5.1550e-05 lr: 5.1550e-06  eta: 18:40:17  time: 0.4420  data_time: 0.0097  memory: 5129  grad_norm: 160.2580  loss: 5.0726  decode.loss_cls: 0.0618  decode.loss_mask: 0.2223  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.7623  decode.d0.loss_mask: 0.2327  decode.d0.loss_dice: 0.1809  decode.d1.loss_cls: 0.0851  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.1670  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.2208  decode.d2.loss_dice: 0.1662  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.1600  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.2217  decode.d4.loss_dice: 0.1679  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.2221  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1710  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.2237  decode.d7.loss_dice: 0.1706  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1718
10/01 05:25:34 - mmengine - INFO - Iter(train) [166800/320000]  base_lr: 5.1535e-05 lr: 5.1535e-06  eta: 18:39:55  time: 0.4426  data_time: 0.0099  memory: 5129  grad_norm: 34.3422  loss: 4.2153  decode.loss_cls: 0.0094  decode.loss_mask: 0.1853  decode.loss_dice: 0.1404  decode.d0.loss_cls: 0.7707  decode.d0.loss_mask: 0.1860  decode.d0.loss_dice: 0.1415  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.1869  decode.d1.loss_dice: 0.1410  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.1827  decode.d2.loss_dice: 0.1400  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.1848  decode.d3.loss_dice: 0.1379  decode.d4.loss_cls: 0.0260  decode.d4.loss_mask: 0.1860  decode.d4.loss_dice: 0.1388  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.1373  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.1857  decode.d6.loss_dice: 0.1385  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.1843  decode.d7.loss_dice: 0.1409  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.1842  decode.d8.loss_dice: 0.1416
10/01 05:25:56 - mmengine - INFO - Iter(train) [166850/320000]  base_lr: 5.1519e-05 lr: 5.1519e-06  eta: 18:39:33  time: 0.4424  data_time: 0.0101  memory: 5129  grad_norm: 47.4412  loss: 6.7146  decode.loss_cls: 0.2194  decode.loss_mask: 0.2350  decode.loss_dice: 0.1626  decode.d0.loss_cls: 0.9342  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.1620  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.1703  decode.d2.loss_cls: 0.2041  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.1674  decode.d3.loss_cls: 0.1854  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.1684  decode.d4.loss_cls: 0.1851  decode.d4.loss_mask: 0.2365  decode.d4.loss_dice: 0.1715  decode.d5.loss_cls: 0.2005  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.1720  decode.d6.loss_cls: 0.1987  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.1642  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.1705  decode.d8.loss_mask: 0.2540  decode.d8.loss_dice: 0.1722
10/01 05:26:18 - mmengine - INFO - Iter(train) [166900/320000]  base_lr: 5.1504e-05 lr: 5.1504e-06  eta: 18:39:12  time: 0.4414  data_time: 0.0100  memory: 5120  grad_norm: 111.8778  loss: 5.7149  decode.loss_cls: 0.0195  decode.loss_mask: 0.2689  decode.loss_dice: 0.1983  decode.d0.loss_cls: 0.8294  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.2032  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.2020  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.2723  decode.d3.loss_dice: 0.1977  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.2704  decode.d4.loss_dice: 0.1962  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.2711  decode.d5.loss_dice: 0.2011  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.2682  decode.d6.loss_dice: 0.2007  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.2663  decode.d7.loss_dice: 0.2014  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.2002
10/01 05:26:40 - mmengine - INFO - Iter(train) [166950/320000]  base_lr: 5.1489e-05 lr: 5.1489e-06  eta: 18:38:50  time: 0.4428  data_time: 0.0101  memory: 5129  grad_norm: 356.4783  loss: 6.5836  decode.loss_cls: 0.0942  decode.loss_mask: 0.2323  decode.loss_dice: 0.2160  decode.d0.loss_cls: 0.8787  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.2342  decode.d1.loss_cls: 0.1640  decode.d1.loss_mask: 0.2285  decode.d1.loss_dice: 0.2406  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.2259  decode.d3.loss_cls: 0.1308  decode.d3.loss_mask: 0.2357  decode.d3.loss_dice: 0.2436  decode.d4.loss_cls: 0.1393  decode.d4.loss_mask: 0.2328  decode.d4.loss_dice: 0.2104  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 0.2293  decode.d5.loss_dice: 0.2136  decode.d6.loss_cls: 0.1305  decode.d6.loss_mask: 0.2357  decode.d6.loss_dice: 0.2182  decode.d7.loss_cls: 0.1188  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.2322  decode.d8.loss_dice: 0.2057
10/01 05:27:03 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:27:03 - mmengine - INFO - Iter(train) [167000/320000]  base_lr: 5.1474e-05 lr: 5.1474e-06  eta: 18:38:28  time: 0.4425  data_time: 0.0098  memory: 5145  grad_norm: 38.2038  loss: 4.9470  decode.loss_cls: 0.0991  decode.loss_mask: 0.1513  decode.loss_dice: 0.1305  decode.d0.loss_cls: 0.8937  decode.d0.loss_mask: 0.1533  decode.d0.loss_dice: 0.1321  decode.d1.loss_cls: 0.1620  decode.d1.loss_mask: 0.1517  decode.d1.loss_dice: 0.1475  decode.d2.loss_cls: 0.1356  decode.d2.loss_mask: 0.1521  decode.d2.loss_dice: 0.1272  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 0.1516  decode.d3.loss_dice: 0.1433  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 0.1516  decode.d4.loss_dice: 0.1484  decode.d5.loss_cls: 0.1279  decode.d5.loss_mask: 0.1531  decode.d5.loss_dice: 0.1339  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.1524  decode.d6.loss_dice: 0.1541  decode.d7.loss_cls: 0.1206  decode.d7.loss_mask: 0.1522  decode.d7.loss_dice: 0.1517  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.1511  decode.d8.loss_dice: 0.1331
10/01 05:27:25 - mmengine - INFO - Iter(train) [167050/320000]  base_lr: 5.1459e-05 lr: 5.1459e-06  eta: 18:38:06  time: 0.4427  data_time: 0.0099  memory: 5145  grad_norm: 76.5373  loss: 6.9522  decode.loss_cls: 0.2121  decode.loss_mask: 0.2011  decode.loss_dice: 0.2482  decode.d0.loss_cls: 0.9141  decode.d0.loss_mask: 0.1973  decode.d0.loss_dice: 0.2295  decode.d1.loss_cls: 0.2030  decode.d1.loss_mask: 0.1957  decode.d1.loss_dice: 0.2061  decode.d2.loss_cls: 0.2661  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.2168  decode.d3.loss_cls: 0.2021  decode.d3.loss_mask: 0.1982  decode.d3.loss_dice: 0.2195  decode.d4.loss_cls: 0.2054  decode.d4.loss_mask: 0.1933  decode.d4.loss_dice: 0.2280  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 0.1954  decode.d5.loss_dice: 0.2114  decode.d6.loss_cls: 0.1931  decode.d6.loss_mask: 0.1932  decode.d6.loss_dice: 0.2243  decode.d7.loss_cls: 0.1807  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.2184  decode.d8.loss_cls: 0.1999  decode.d8.loss_mask: 0.1975  decode.d8.loss_dice: 0.2147
10/01 05:27:47 - mmengine - INFO - Iter(train) [167100/320000]  base_lr: 5.1444e-05 lr: 5.1444e-06  eta: 18:37:45  time: 0.4427  data_time: 0.0101  memory: 5120  grad_norm: 30.1556  loss: 4.1967  decode.loss_cls: 0.0023  decode.loss_mask: 0.1928  decode.loss_dice: 0.1534  decode.d0.loss_cls: 0.7198  decode.d0.loss_mask: 0.1928  decode.d0.loss_dice: 0.1525  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.1907  decode.d1.loss_dice: 0.1500  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.1940  decode.d2.loss_dice: 0.1511  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.1919  decode.d3.loss_dice: 0.1525  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.1541  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.1921  decode.d5.loss_dice: 0.1515  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.1935  decode.d6.loss_dice: 0.1526  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.1924  decode.d7.loss_dice: 0.1551  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.1934  decode.d8.loss_dice: 0.1541
10/01 05:28:09 - mmengine - INFO - Iter(train) [167150/320000]  base_lr: 5.1429e-05 lr: 5.1429e-06  eta: 18:37:23  time: 0.4438  data_time: 0.0100  memory: 5129  grad_norm: 72.0804  loss: 5.3959  decode.loss_cls: 0.0359  decode.loss_mask: 0.2256  decode.loss_dice: 0.2026  decode.d0.loss_cls: 0.7483  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.1859  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.2261  decode.d1.loss_dice: 0.2077  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.2224  decode.d2.loss_dice: 0.1863  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.2234  decode.d3.loss_dice: 0.1894  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 0.2233  decode.d5.loss_dice: 0.1974  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 0.2230  decode.d6.loss_dice: 0.1980  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.2236  decode.d7.loss_dice: 0.1998  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.2008
10/01 05:28:31 - mmengine - INFO - Iter(train) [167200/320000]  base_lr: 5.1414e-05 lr: 5.1414e-06  eta: 18:37:01  time: 0.4420  data_time: 0.0099  memory: 5120  grad_norm: 42.9628  loss: 5.1192  decode.loss_cls: 0.0551  decode.loss_mask: 0.1800  decode.loss_dice: 0.2135  decode.d0.loss_cls: 0.7721  decode.d0.loss_mask: 0.1784  decode.d0.loss_dice: 0.2016  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.1774  decode.d1.loss_dice: 0.1864  decode.d2.loss_cls: 0.0691  decode.d2.loss_mask: 0.1762  decode.d2.loss_dice: 0.1922  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.1760  decode.d3.loss_dice: 0.1996  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.1784  decode.d4.loss_dice: 0.1952  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.1771  decode.d5.loss_dice: 0.2101  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 0.1772  decode.d6.loss_dice: 0.1973  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.1735  decode.d7.loss_dice: 0.2116  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.1772  decode.d8.loss_dice: 0.1949
10/01 05:28:53 - mmengine - INFO - Iter(train) [167250/320000]  base_lr: 5.1398e-05 lr: 5.1398e-06  eta: 18:36:39  time: 0.4425  data_time: 0.0100  memory: 5120  grad_norm: 35.7058  loss: 5.0392  decode.loss_cls: 0.0106  decode.loss_mask: 0.2098  decode.loss_dice: 0.2186  decode.d0.loss_cls: 0.8266  decode.d0.loss_mask: 0.2066  decode.d0.loss_dice: 0.1683  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1723  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.1610  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.2085  decode.d3.loss_dice: 0.1760  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.2066  decode.d4.loss_dice: 0.1642  decode.d5.loss_cls: 0.0352  decode.d5.loss_mask: 0.2069  decode.d5.loss_dice: 0.1727  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.2092  decode.d6.loss_dice: 0.1649  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.2090  decode.d7.loss_dice: 0.1701  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.2086
10/01 05:29:15 - mmengine - INFO - Iter(train) [167300/320000]  base_lr: 5.1383e-05 lr: 5.1383e-06  eta: 18:36:18  time: 0.4418  data_time: 0.0099  memory: 5120  grad_norm: 31.6836  loss: 3.5666  decode.loss_cls: 0.0010  decode.loss_mask: 0.1574  decode.loss_dice: 0.1214  decode.d0.loss_cls: 0.7436  decode.d0.loss_mask: 0.1612  decode.d0.loss_dice: 0.1212  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.1598  decode.d1.loss_dice: 0.1216  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.1614  decode.d2.loss_dice: 0.1214  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.1600  decode.d3.loss_dice: 0.1244  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.1610  decode.d4.loss_dice: 0.1227  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.1599  decode.d5.loss_dice: 0.1214  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.1587  decode.d6.loss_dice: 0.1209  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.1594  decode.d7.loss_dice: 0.1219  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1587  decode.d8.loss_dice: 0.1185
10/01 05:29:38 - mmengine - INFO - Iter(train) [167350/320000]  base_lr: 5.1368e-05 lr: 5.1368e-06  eta: 18:35:56  time: 0.4426  data_time: 0.0100  memory: 5145  grad_norm: 44.7760  loss: 4.8705  decode.loss_cls: 0.0112  decode.loss_mask: 0.2162  decode.loss_dice: 0.1878  decode.d0.loss_cls: 0.7473  decode.d0.loss_mask: 0.2158  decode.d0.loss_dice: 0.1883  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.2123  decode.d1.loss_dice: 0.1829  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.2128  decode.d2.loss_dice: 0.1792  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2132  decode.d3.loss_dice: 0.1786  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.2150  decode.d4.loss_dice: 0.1906  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.2155  decode.d5.loss_dice: 0.1832  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.2150  decode.d7.loss_dice: 0.1838  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.1828
10/01 05:30:00 - mmengine - INFO - Iter(train) [167400/320000]  base_lr: 5.1353e-05 lr: 5.1353e-06  eta: 18:35:34  time: 0.4428  data_time: 0.0100  memory: 5145  grad_norm: 53.9026  loss: 4.8525  decode.loss_cls: 0.0527  decode.loss_mask: 0.1884  decode.loss_dice: 0.1623  decode.d0.loss_cls: 0.8163  decode.d0.loss_mask: 0.1906  decode.d0.loss_dice: 0.1657  decode.d1.loss_cls: 0.0585  decode.d1.loss_mask: 0.1882  decode.d1.loss_dice: 0.1714  decode.d2.loss_cls: 0.0536  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.1542  decode.d3.loss_cls: 0.0669  decode.d3.loss_mask: 0.1906  decode.d3.loss_dice: 0.1583  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.1899  decode.d4.loss_dice: 0.1577  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.1548  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.1914  decode.d6.loss_dice: 0.1511  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.1884  decode.d7.loss_dice: 0.1558  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.1892  decode.d8.loss_dice: 0.1609
10/01 05:30:22 - mmengine - INFO - Iter(train) [167450/320000]  base_lr: 5.1338e-05 lr: 5.1338e-06  eta: 18:35:13  time: 0.4427  data_time: 0.0100  memory: 5120  grad_norm: 61.6457  loss: 4.7758  decode.loss_cls: 0.0068  decode.loss_mask: 0.2256  decode.loss_dice: 0.1573  decode.d0.loss_cls: 0.8324  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.1630  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.2279  decode.d1.loss_dice: 0.1627  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.1560  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.2304  decode.d3.loss_dice: 0.1592  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.1567  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2241  decode.d5.loss_dice: 0.1549  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.2272  decode.d6.loss_dice: 0.1584  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.2285  decode.d7.loss_dice: 0.1613  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2257  decode.d8.loss_dice: 0.1555
10/01 05:30:44 - mmengine - INFO - Iter(train) [167500/320000]  base_lr: 5.1323e-05 lr: 5.1323e-06  eta: 18:34:51  time: 0.4423  data_time: 0.0099  memory: 5120  grad_norm: 73.4553  loss: 5.8984  decode.loss_cls: 0.1203  decode.loss_mask: 0.2041  decode.loss_dice: 0.2127  decode.d0.loss_cls: 0.8883  decode.d0.loss_mask: 0.2056  decode.d0.loss_dice: 0.2104  decode.d1.loss_cls: 0.1134  decode.d1.loss_mask: 0.2008  decode.d1.loss_dice: 0.2004  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.2008  decode.d2.loss_dice: 0.2003  decode.d3.loss_cls: 0.1035  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.1133  decode.d4.loss_mask: 0.2012  decode.d4.loss_dice: 0.2029  decode.d5.loss_cls: 0.1246  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.1141  decode.d6.loss_mask: 0.2038  decode.d6.loss_dice: 0.2018  decode.d7.loss_cls: 0.0902  decode.d7.loss_mask: 0.2035  decode.d7.loss_dice: 0.1962  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.2034  decode.d8.loss_dice: 0.2196
10/01 05:31:06 - mmengine - INFO - Iter(train) [167550/320000]  base_lr: 5.1308e-05 lr: 5.1308e-06  eta: 18:34:29  time: 0.4423  data_time: 0.0101  memory: 5120  grad_norm: 58.7597  loss: 5.1257  decode.loss_cls: 0.0075  decode.loss_mask: 0.2538  decode.loss_dice: 0.1769  decode.d0.loss_cls: 0.7583  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.1670  decode.d1.loss_cls: 0.0180  decode.d1.loss_mask: 0.2547  decode.d1.loss_dice: 0.1746  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.1709  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.1741  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.2529  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.1729  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2556  decode.d6.loss_dice: 0.1727  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.2531  decode.d7.loss_dice: 0.1753  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.1722
10/01 05:31:29 - mmengine - INFO - Iter(train) [167600/320000]  base_lr: 5.1292e-05 lr: 5.1292e-06  eta: 18:34:07  time: 0.4455  data_time: 0.0101  memory: 5129  grad_norm: 30.6630  loss: 4.4281  decode.loss_cls: 0.0339  decode.loss_mask: 0.1766  decode.loss_dice: 0.1577  decode.d0.loss_cls: 0.7669  decode.d0.loss_mask: 0.1784  decode.d0.loss_dice: 0.1566  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.1766  decode.d1.loss_dice: 0.1603  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.1767  decode.d2.loss_dice: 0.1535  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.1759  decode.d3.loss_dice: 0.1575  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.1759  decode.d4.loss_dice: 0.1568  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.1759  decode.d5.loss_dice: 0.1544  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.1791  decode.d6.loss_dice: 0.1571  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.1782  decode.d7.loss_dice: 0.1576  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.1763  decode.d8.loss_dice: 0.1553
10/01 05:31:51 - mmengine - INFO - Iter(train) [167650/320000]  base_lr: 5.1277e-05 lr: 5.1277e-06  eta: 18:33:46  time: 0.4426  data_time: 0.0099  memory: 5119  grad_norm: 32.4828  loss: 4.4845  decode.loss_cls: 0.0013  decode.loss_mask: 0.1948  decode.loss_dice: 0.1711  decode.d0.loss_cls: 0.8131  decode.d0.loss_mask: 0.1960  decode.d0.loss_dice: 0.1662  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.1958  decode.d1.loss_dice: 0.1696  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.1958  decode.d2.loss_dice: 0.1703  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.1991  decode.d3.loss_dice: 0.1672  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.1957  decode.d4.loss_dice: 0.1708  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.1960  decode.d5.loss_dice: 0.1684  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.1952  decode.d6.loss_dice: 0.1662  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.1983  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.1973  decode.d8.loss_dice: 0.1671
10/01 05:32:13 - mmengine - INFO - Iter(train) [167700/320000]  base_lr: 5.1262e-05 lr: 5.1262e-06  eta: 18:33:24  time: 0.4451  data_time: 0.0101  memory: 5120  grad_norm: 25.4404  loss: 4.0606  decode.loss_cls: 0.0011  decode.loss_mask: 0.1805  decode.loss_dice: 0.1442  decode.d0.loss_cls: 0.7523  decode.d0.loss_mask: 0.1827  decode.d0.loss_dice: 0.1374  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.1812  decode.d1.loss_dice: 0.1442  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.1820  decode.d2.loss_dice: 0.1447  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.1832  decode.d3.loss_dice: 0.1457  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.1818  decode.d4.loss_dice: 0.1471  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.1837  decode.d5.loss_dice: 0.1490  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.1844  decode.d6.loss_dice: 0.1510  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.1841  decode.d7.loss_dice: 0.1502  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.1842  decode.d8.loss_dice: 0.1462
10/01 05:32:35 - mmengine - INFO - Iter(train) [167750/320000]  base_lr: 5.1247e-05 lr: 5.1247e-06  eta: 18:33:02  time: 0.4424  data_time: 0.0100  memory: 5129  grad_norm: 63.6735  loss: 5.5128  decode.loss_cls: 0.0147  decode.loss_mask: 0.2770  decode.loss_dice: 0.2024  decode.d0.loss_cls: 0.7185  decode.d0.loss_mask: 0.2752  decode.d0.loss_dice: 0.1841  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.1797  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.2816  decode.d2.loss_dice: 0.1837  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.2723  decode.d3.loss_dice: 0.2012  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.1820  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.1838  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.2747  decode.d6.loss_dice: 0.2092  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.2817  decode.d7.loss_dice: 0.1864  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.1835
10/01 05:32:57 - mmengine - INFO - Iter(train) [167800/320000]  base_lr: 5.1232e-05 lr: 5.1232e-06  eta: 18:32:40  time: 0.4455  data_time: 0.0100  memory: 5129  grad_norm: 32.5011  loss: 5.3389  decode.loss_cls: 0.1375  decode.loss_mask: 0.1651  decode.loss_dice: 0.1690  decode.d0.loss_cls: 0.8287  decode.d0.loss_mask: 0.1653  decode.d0.loss_dice: 0.1803  decode.d1.loss_cls: 0.1311  decode.d1.loss_mask: 0.1659  decode.d1.loss_dice: 0.1816  decode.d2.loss_cls: 0.1090  decode.d2.loss_mask: 0.1638  decode.d2.loss_dice: 0.1782  decode.d3.loss_cls: 0.0956  decode.d3.loss_mask: 0.1656  decode.d3.loss_dice: 0.1713  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.1660  decode.d4.loss_dice: 0.1794  decode.d5.loss_cls: 0.1193  decode.d5.loss_mask: 0.1655  decode.d5.loss_dice: 0.1828  decode.d6.loss_cls: 0.1478  decode.d6.loss_mask: 0.1669  decode.d6.loss_dice: 0.1665  decode.d7.loss_cls: 0.1435  decode.d7.loss_mask: 0.1641  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.1222  decode.d8.loss_mask: 0.1648  decode.d8.loss_dice: 0.1813
10/01 05:33:19 - mmengine - INFO - Iter(train) [167850/320000]  base_lr: 5.1217e-05 lr: 5.1217e-06  eta: 18:32:19  time: 0.4428  data_time: 0.0100  memory: 5120  grad_norm: 41.5722  loss: 5.5371  decode.loss_cls: 0.0838  decode.loss_mask: 0.2314  decode.loss_dice: 0.1682  decode.d0.loss_cls: 0.9274  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.1619  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.1622  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.1588  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.2295  decode.d3.loss_dice: 0.1608  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.2298  decode.d4.loss_dice: 0.1592  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.2290  decode.d5.loss_dice: 0.1644  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.2291  decode.d6.loss_dice: 0.1655  decode.d7.loss_cls: 0.0914  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.1682  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.2307  decode.d8.loss_dice: 0.1648
10/01 05:33:41 - mmengine - INFO - Iter(train) [167900/320000]  base_lr: 5.1201e-05 lr: 5.1201e-06  eta: 18:31:57  time: 0.4448  data_time: 0.0099  memory: 5129  grad_norm: 49.7522  loss: 4.8414  decode.loss_cls: 0.0112  decode.loss_mask: 0.2252  decode.loss_dice: 0.1659  decode.d0.loss_cls: 0.7407  decode.d0.loss_mask: 0.2899  decode.d0.loss_dice: 0.1727  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.2269  decode.d1.loss_dice: 0.1641  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.2285  decode.d2.loss_dice: 0.1632  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.1621  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.2243  decode.d4.loss_dice: 0.1600  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.1657  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.1625  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.2252  decode.d7.loss_dice: 0.1621  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.2261  decode.d8.loss_dice: 0.1699
10/01 05:34:04 - mmengine - INFO - Iter(train) [167950/320000]  base_lr: 5.1186e-05 lr: 5.1186e-06  eta: 18:31:35  time: 0.4425  data_time: 0.0101  memory: 5129  grad_norm: 130.8771  loss: 6.3242  decode.loss_cls: 0.1654  decode.loss_mask: 0.1806  decode.loss_dice: 0.2423  decode.d0.loss_cls: 0.9992  decode.d0.loss_mask: 0.1738  decode.d0.loss_dice: 0.2304  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.1765  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.1743  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.1743  decode.d4.loss_dice: 0.2440  decode.d5.loss_cls: 0.1063  decode.d5.loss_mask: 0.1758  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.1500  decode.d6.loss_mask: 0.1975  decode.d6.loss_dice: 0.2556  decode.d7.loss_cls: 0.1450  decode.d7.loss_mask: 0.2084  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.1807  decode.d8.loss_mask: 0.1751  decode.d8.loss_dice: 0.2378
10/01 05:34:26 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:34:26 - mmengine - INFO - Iter(train) [168000/320000]  base_lr: 5.1171e-05 lr: 5.1171e-06  eta: 18:31:13  time: 0.4424  data_time: 0.0098  memory: 5129  grad_norm: 75.8069  loss: 5.8710  decode.loss_cls: 0.1056  decode.loss_mask: 0.2079  decode.loss_dice: 0.1845  decode.d0.loss_cls: 0.8564  decode.d0.loss_mask: 0.2123  decode.d0.loss_dice: 0.1899  decode.d1.loss_cls: 0.0957  decode.d1.loss_mask: 0.2083  decode.d1.loss_dice: 0.1819  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.2103  decode.d2.loss_dice: 0.1858  decode.d3.loss_cls: 0.1047  decode.d3.loss_mask: 0.2091  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.1381  decode.d4.loss_mask: 0.2057  decode.d4.loss_dice: 0.1841  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1905  decode.d6.loss_cls: 0.1256  decode.d6.loss_mask: 0.2068  decode.d6.loss_dice: 0.2010  decode.d7.loss_cls: 0.1187  decode.d7.loss_mask: 0.2102  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.2126
10/01 05:34:48 - mmengine - INFO - Iter(train) [168050/320000]  base_lr: 5.1156e-05 lr: 5.1156e-06  eta: 18:30:52  time: 0.4421  data_time: 0.0099  memory: 5120  grad_norm: 91.5545  loss: 5.5427  decode.loss_cls: 0.0777  decode.loss_mask: 0.2063  decode.loss_dice: 0.1760  decode.d0.loss_cls: 0.8607  decode.d0.loss_mask: 0.2082  decode.d0.loss_dice: 0.2227  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.2044  decode.d1.loss_dice: 0.1668  decode.d2.loss_cls: 0.1145  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.1923  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.1665  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.2029  decode.d4.loss_dice: 0.1672  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.2036  decode.d5.loss_dice: 0.1663  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.1720  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.2038  decode.d7.loss_dice: 0.1520  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 0.2057  decode.d8.loss_dice: 0.1563
10/01 05:35:10 - mmengine - INFO - Iter(train) [168100/320000]  base_lr: 5.1141e-05 lr: 5.1141e-06  eta: 18:30:30  time: 0.4433  data_time: 0.0099  memory: 5120  grad_norm: 30.8721  loss: 4.1626  decode.loss_cls: 0.0141  decode.loss_mask: 0.1828  decode.loss_dice: 0.1434  decode.d0.loss_cls: 0.8447  decode.d0.loss_mask: 0.1797  decode.d0.loss_dice: 0.1352  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.1821  decode.d1.loss_dice: 0.1432  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.1826  decode.d2.loss_dice: 0.1425  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1817  decode.d3.loss_dice: 0.1425  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.1834  decode.d4.loss_dice: 0.1399  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.1412  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.1822  decode.d6.loss_dice: 0.1429  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.1811  decode.d7.loss_dice: 0.1426  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.1844  decode.d8.loss_dice: 0.1457
10/01 05:35:32 - mmengine - INFO - Iter(train) [168150/320000]  base_lr: 5.1126e-05 lr: 5.1126e-06  eta: 18:30:08  time: 0.4425  data_time: 0.0100  memory: 5129  grad_norm: 30.3332  loss: 4.1563  decode.loss_cls: 0.0074  decode.loss_mask: 0.1621  decode.loss_dice: 0.1615  decode.d0.loss_cls: 0.7256  decode.d0.loss_mask: 0.1618  decode.d0.loss_dice: 0.1571  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.1639  decode.d1.loss_dice: 0.1606  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.1633  decode.d2.loss_dice: 0.1622  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.1624  decode.d3.loss_dice: 0.1660  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.1629  decode.d4.loss_dice: 0.1551  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.1632  decode.d5.loss_dice: 0.1595  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.1626  decode.d6.loss_dice: 0.1616  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.1620  decode.d7.loss_dice: 0.1657  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.1637  decode.d8.loss_dice: 0.1675
10/01 05:35:54 - mmengine - INFO - Iter(train) [168200/320000]  base_lr: 5.1111e-05 lr: 5.1111e-06  eta: 18:29:46  time: 0.4426  data_time: 0.0099  memory: 5129  grad_norm: 31.8012  loss: 4.6759  decode.loss_cls: 0.0058  decode.loss_mask: 0.1834  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.9918  decode.d0.loss_mask: 0.1822  decode.d0.loss_dice: 0.1905  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.1838  decode.d1.loss_dice: 0.1683  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.1844  decode.d2.loss_dice: 0.1729  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.1838  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.1835  decode.d4.loss_dice: 0.1626  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.1833  decode.d5.loss_dice: 0.1694  decode.d6.loss_cls: 0.0598  decode.d6.loss_mask: 0.1849  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.1824  decode.d7.loss_dice: 0.1692  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.1831  decode.d8.loss_dice: 0.1922
10/01 05:36:17 - mmengine - INFO - Iter(train) [168250/320000]  base_lr: 5.1095e-05 lr: 5.1095e-06  eta: 18:29:25  time: 0.4424  data_time: 0.0100  memory: 5129  grad_norm: 98.0239  loss: 5.1985  decode.loss_cls: 0.0825  decode.loss_mask: 0.1983  decode.loss_dice: 0.1707  decode.d0.loss_cls: 0.8051  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.1648  decode.d1.loss_cls: 0.0940  decode.d1.loss_mask: 0.1982  decode.d1.loss_dice: 0.1662  decode.d2.loss_cls: 0.0803  decode.d2.loss_mask: 0.1963  decode.d2.loss_dice: 0.1737  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.1966  decode.d3.loss_dice: 0.1823  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.1960  decode.d4.loss_dice: 0.1756  decode.d5.loss_cls: 0.0842  decode.d5.loss_mask: 0.1976  decode.d5.loss_dice: 0.1702  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.1959  decode.d6.loss_dice: 0.1758  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.1979  decode.d7.loss_dice: 0.1799  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.1979  decode.d8.loss_dice: 0.1806
10/01 05:36:39 - mmengine - INFO - Iter(train) [168300/320000]  base_lr: 5.1080e-05 lr: 5.1080e-06  eta: 18:29:03  time: 0.4600  data_time: 0.0099  memory: 5129  grad_norm: 29.4276  loss: 4.4640  decode.loss_cls: 0.0024  decode.loss_mask: 0.2018  decode.loss_dice: 0.1656  decode.d0.loss_cls: 0.7372  decode.d0.loss_mask: 0.2049  decode.d0.loss_dice: 0.1700  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.2045  decode.d1.loss_dice: 0.1705  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.2030  decode.d2.loss_dice: 0.1684  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.2029  decode.d3.loss_dice: 0.1661  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2019  decode.d4.loss_dice: 0.1655  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.1688  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2017  decode.d6.loss_dice: 0.1677  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2022  decode.d7.loss_dice: 0.1646  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.2041  decode.d8.loss_dice: 0.1681
10/01 05:37:01 - mmengine - INFO - Iter(train) [168350/320000]  base_lr: 5.1065e-05 lr: 5.1065e-06  eta: 18:28:41  time: 0.4423  data_time: 0.0100  memory: 5120  grad_norm: 27.5492  loss: 3.9450  decode.loss_cls: 0.0006  decode.loss_mask: 0.1781  decode.loss_dice: 0.1384  decode.d0.loss_cls: 0.7957  decode.d0.loss_mask: 0.1746  decode.d0.loss_dice: 0.1411  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.1749  decode.d1.loss_dice: 0.1403  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.1758  decode.d2.loss_dice: 0.1390  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.1753  decode.d3.loss_dice: 0.1358  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.1751  decode.d4.loss_dice: 0.1378  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.1771  decode.d5.loss_dice: 0.1381  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.1760  decode.d6.loss_dice: 0.1366  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.1783  decode.d7.loss_dice: 0.1384  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.1768  decode.d8.loss_dice: 0.1345
10/01 05:37:23 - mmengine - INFO - Iter(train) [168400/320000]  base_lr: 5.1050e-05 lr: 5.1050e-06  eta: 18:28:20  time: 0.4418  data_time: 0.0099  memory: 5145  grad_norm: 61.8896  loss: 5.0692  decode.loss_cls: 0.0291  decode.loss_mask: 0.1895  decode.loss_dice: 0.2025  decode.d0.loss_cls: 0.8193  decode.d0.loss_mask: 0.1929  decode.d0.loss_dice: 0.1938  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.1903  decode.d1.loss_dice: 0.2069  decode.d2.loss_cls: 0.0508  decode.d2.loss_mask: 0.1911  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.1865  decode.d3.loss_dice: 0.1887  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.2014  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.1890  decode.d5.loss_dice: 0.1971  decode.d6.loss_cls: 0.0278  decode.d6.loss_mask: 0.1894  decode.d6.loss_dice: 0.2090  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.1891  decode.d7.loss_dice: 0.1966  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.1901  decode.d8.loss_dice: 0.2050
10/01 05:37:45 - mmengine - INFO - Iter(train) [168450/320000]  base_lr: 5.1035e-05 lr: 5.1035e-06  eta: 18:27:58  time: 0.4413  data_time: 0.0099  memory: 5129  grad_norm: 30.8677  loss: 4.1371  decode.loss_cls: 0.0016  decode.loss_mask: 0.1802  decode.loss_dice: 0.1492  decode.d0.loss_cls: 0.7588  decode.d0.loss_mask: 0.1834  decode.d0.loss_dice: 0.1554  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.1831  decode.d1.loss_dice: 0.1532  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.1839  decode.d2.loss_dice: 0.1493  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.1839  decode.d3.loss_dice: 0.1558  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.1815  decode.d4.loss_dice: 0.1543  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.1842  decode.d5.loss_dice: 0.1549  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.1845  decode.d6.loss_dice: 0.1545  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1814  decode.d7.loss_dice: 0.1516  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1828  decode.d8.loss_dice: 0.1554
10/01 05:38:07 - mmengine - INFO - Iter(train) [168500/320000]  base_lr: 5.1020e-05 lr: 5.1020e-06  eta: 18:27:36  time: 0.4422  data_time: 0.0099  memory: 5129  grad_norm: 37.4176  loss: 4.9059  decode.loss_cls: 0.0847  decode.loss_mask: 0.1735  decode.loss_dice: 0.1535  decode.d0.loss_cls: 0.7711  decode.d0.loss_mask: 0.1724  decode.d0.loss_dice: 0.1490  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.1723  decode.d1.loss_dice: 0.1494  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.1733  decode.d2.loss_dice: 0.1832  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.1750  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.1641  decode.d4.loss_mask: 0.1718  decode.d4.loss_dice: 0.1521  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.1719  decode.d5.loss_dice: 0.1329  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.1721  decode.d6.loss_dice: 0.1578  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.1713  decode.d7.loss_dice: 0.1315  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.1715  decode.d8.loss_dice: 0.2036
10/01 05:38:29 - mmengine - INFO - Iter(train) [168550/320000]  base_lr: 5.1005e-05 lr: 5.1005e-06  eta: 18:27:14  time: 0.4413  data_time: 0.0098  memory: 5129  grad_norm: 39.9427  loss: 3.8126  decode.loss_cls: 0.0064  decode.loss_mask: 0.1565  decode.loss_dice: 0.1435  decode.d0.loss_cls: 0.7213  decode.d0.loss_mask: 0.1685  decode.d0.loss_dice: 0.1548  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.1582  decode.d1.loss_dice: 0.1476  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.1561  decode.d2.loss_dice: 0.1383  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.1537  decode.d3.loss_dice: 0.1428  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.1531  decode.d4.loss_dice: 0.1418  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.1525  decode.d5.loss_dice: 0.1478  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.1522  decode.d6.loss_dice: 0.1415  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.1544  decode.d7.loss_dice: 0.1527  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.1555  decode.d8.loss_dice: 0.1483
10/01 05:38:52 - mmengine - INFO - Iter(train) [168600/320000]  base_lr: 5.0989e-05 lr: 5.0989e-06  eta: 18:26:52  time: 0.4415  data_time: 0.0099  memory: 5129  grad_norm: 64.2637  loss: 4.8975  decode.loss_cls: 0.0691  decode.loss_mask: 0.1971  decode.loss_dice: 0.1786  decode.d0.loss_cls: 0.7325  decode.d0.loss_mask: 0.1985  decode.d0.loss_dice: 0.1766  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.1989  decode.d1.loss_dice: 0.1849  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.1962  decode.d2.loss_dice: 0.1745  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.1971  decode.d3.loss_dice: 0.1969  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.1989  decode.d4.loss_dice: 0.1739  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.1974  decode.d5.loss_dice: 0.1882  decode.d6.loss_cls: 0.0251  decode.d6.loss_mask: 0.2001  decode.d6.loss_dice: 0.1849  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.1978  decode.d7.loss_dice: 0.1839  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.1829
10/01 05:39:14 - mmengine - INFO - Iter(train) [168650/320000]  base_lr: 5.0974e-05 lr: 5.0974e-06  eta: 18:26:31  time: 0.4416  data_time: 0.0098  memory: 5129  grad_norm: 46.8493  loss: 4.3945  decode.loss_cls: 0.0372  decode.loss_mask: 0.1613  decode.loss_dice: 0.1514  decode.d0.loss_cls: 0.8496  decode.d0.loss_mask: 0.1625  decode.d0.loss_dice: 0.1457  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.1620  decode.d1.loss_dice: 0.1556  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.1580  decode.d2.loss_dice: 0.1471  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.1627  decode.d3.loss_dice: 0.1522  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.1616  decode.d4.loss_dice: 0.1521  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.1616  decode.d5.loss_dice: 0.1567  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.1627  decode.d6.loss_dice: 0.1530  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.1638  decode.d7.loss_dice: 0.1550  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.1637  decode.d8.loss_dice: 0.1549
10/01 05:39:36 - mmengine - INFO - Iter(train) [168700/320000]  base_lr: 5.0959e-05 lr: 5.0959e-06  eta: 18:26:09  time: 0.4416  data_time: 0.0099  memory: 5129  grad_norm: 26.8755  loss: 4.2077  decode.loss_cls: 0.0045  decode.loss_mask: 0.1752  decode.loss_dice: 0.1474  decode.d0.loss_cls: 0.7886  decode.d0.loss_mask: 0.1726  decode.d0.loss_dice: 0.1702  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.1719  decode.d1.loss_dice: 0.1329  decode.d2.loss_cls: 0.0831  decode.d2.loss_mask: 0.1724  decode.d2.loss_dice: 0.1443  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.1714  decode.d3.loss_dice: 0.1408  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.1741  decode.d4.loss_dice: 0.1300  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.1762  decode.d5.loss_dice: 0.1301  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.1751  decode.d6.loss_dice: 0.1492  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.1752  decode.d7.loss_dice: 0.1515  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.1726  decode.d8.loss_dice: 0.1795
10/01 05:39:58 - mmengine - INFO - Iter(train) [168750/320000]  base_lr: 5.0944e-05 lr: 5.0944e-06  eta: 18:25:47  time: 0.4420  data_time: 0.0099  memory: 5129  grad_norm: 44.6804  loss: 4.7752  decode.loss_cls: 0.0437  decode.loss_mask: 0.1961  decode.loss_dice: 0.1534  decode.d0.loss_cls: 0.8190  decode.d0.loss_mask: 0.1984  decode.d0.loss_dice: 0.1504  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.1934  decode.d1.loss_dice: 0.1547  decode.d2.loss_cls: 0.0481  decode.d2.loss_mask: 0.1968  decode.d2.loss_dice: 0.1525  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.1947  decode.d3.loss_dice: 0.1533  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.1959  decode.d4.loss_dice: 0.1513  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.1933  decode.d5.loss_dice: 0.1512  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.1951  decode.d6.loss_dice: 0.1532  decode.d7.loss_cls: 0.0537  decode.d7.loss_mask: 0.1963  decode.d7.loss_dice: 0.1528  decode.d8.loss_cls: 0.0442  decode.d8.loss_mask: 0.1972  decode.d8.loss_dice: 0.1544
10/01 05:40:20 - mmengine - INFO - Iter(train) [168800/320000]  base_lr: 5.0929e-05 lr: 5.0929e-06  eta: 18:25:25  time: 0.4423  data_time: 0.0099  memory: 5145  grad_norm: 112.1979  loss: 7.5852  decode.loss_cls: 0.0957  decode.loss_mask: 0.3133  decode.loss_dice: 0.2365  decode.d0.loss_cls: 0.9956  decode.d0.loss_mask: 0.2235  decode.d0.loss_dice: 0.2268  decode.d1.loss_cls: 0.1625  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.2420  decode.d2.loss_cls: 0.1351  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.2778  decode.d3.loss_cls: 0.1369  decode.d3.loss_mask: 0.3501  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.1575  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.2478  decode.d5.loss_cls: 0.2110  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.1997  decode.d6.loss_mask: 0.2294  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.1861  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.2391  decode.d8.loss_cls: 0.1667  decode.d8.loss_mask: 0.2553  decode.d8.loss_dice: 0.2658
10/01 05:40:42 - mmengine - INFO - Iter(train) [168850/320000]  base_lr: 5.0914e-05 lr: 5.0914e-06  eta: 18:25:04  time: 0.4410  data_time: 0.0100  memory: 5120  grad_norm: 35.9326  loss: 4.6660  decode.loss_cls: 0.0061  decode.loss_mask: 0.2223  decode.loss_dice: 0.1671  decode.d0.loss_cls: 0.7394  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.1554  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.1562  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.2246  decode.d2.loss_dice: 0.1564  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.2231  decode.d3.loss_dice: 0.1587  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.1596  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.2241  decode.d5.loss_dice: 0.1636  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.2235  decode.d6.loss_dice: 0.1605  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.2252  decode.d7.loss_dice: 0.1689  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2246  decode.d8.loss_dice: 0.1707
10/01 05:41:04 - mmengine - INFO - Iter(train) [168900/320000]  base_lr: 5.0898e-05 lr: 5.0898e-06  eta: 18:24:42  time: 0.4418  data_time: 0.0099  memory: 5145  grad_norm: 33.4054  loss: 4.6244  decode.loss_cls: 0.0127  decode.loss_mask: 0.2084  decode.loss_dice: 0.1650  decode.d0.loss_cls: 0.7711  decode.d0.loss_mask: 0.2110  decode.d0.loss_dice: 0.1624  decode.d1.loss_cls: 0.0139  decode.d1.loss_mask: 0.2102  decode.d1.loss_dice: 0.1624  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.2074  decode.d2.loss_dice: 0.1604  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.2066  decode.d3.loss_dice: 0.1622  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.2099  decode.d4.loss_dice: 0.1661  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.2095  decode.d5.loss_dice: 0.1646  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.2075  decode.d6.loss_dice: 0.1642  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.2091  decode.d7.loss_dice: 0.1654  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.2086  decode.d8.loss_dice: 0.1637
10/01 05:41:26 - mmengine - INFO - Iter(train) [168950/320000]  base_lr: 5.0883e-05 lr: 5.0883e-06  eta: 18:24:20  time: 0.4421  data_time: 0.0100  memory: 5129  grad_norm: 53.7735  loss: 6.0006  decode.loss_cls: 0.0664  decode.loss_mask: 0.2185  decode.loss_dice: 0.2085  decode.d0.loss_cls: 0.8818  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2170  decode.d1.loss_cls: 0.1087  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.2145  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.2278  decode.d2.loss_dice: 0.2090  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.2341  decode.d3.loss_dice: 0.2017  decode.d4.loss_cls: 0.1143  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.2202  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.2257  decode.d5.loss_dice: 0.2134  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.2334  decode.d6.loss_dice: 0.2086  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.2254  decode.d7.loss_dice: 0.2107  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.2221  decode.d8.loss_dice: 0.2156
10/01 05:41:49 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:41:49 - mmengine - INFO - Iter(train) [169000/320000]  base_lr: 5.0868e-05 lr: 5.0868e-06  eta: 18:23:58  time: 0.4420  data_time: 0.0099  memory: 5145  grad_norm: 40.0481  loss: 5.3127  decode.loss_cls: 0.0527  decode.loss_mask: 0.1842  decode.loss_dice: 0.2280  decode.d0.loss_cls: 0.9470  decode.d0.loss_mask: 0.1886  decode.d0.loss_dice: 0.2044  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.1861  decode.d1.loss_dice: 0.2136  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.1886  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.1858  decode.d3.loss_dice: 0.2041  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.1857  decode.d4.loss_dice: 0.2132  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.1851  decode.d5.loss_dice: 0.2267  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.1831  decode.d6.loss_dice: 0.2072  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 0.1856  decode.d7.loss_dice: 0.2068  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.2267
10/01 05:42:11 - mmengine - INFO - Iter(train) [169050/320000]  base_lr: 5.0853e-05 lr: 5.0853e-06  eta: 18:23:36  time: 0.4415  data_time: 0.0095  memory: 5130  grad_norm: 108.3687  loss: 6.0867  decode.loss_cls: 0.0569  decode.loss_mask: 0.2471  decode.loss_dice: 0.2247  decode.d0.loss_cls: 0.8764  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.2468  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 0.2471  decode.d1.loss_dice: 0.2391  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.2456  decode.d2.loss_dice: 0.2272  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.2453  decode.d3.loss_dice: 0.2084  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.2423  decode.d4.loss_dice: 0.2233  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.2437  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.2435  decode.d6.loss_dice: 0.2184  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.2426  decode.d7.loss_dice: 0.2113  decode.d8.loss_cls: 0.0656  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2192
10/01 05:42:33 - mmengine - INFO - Iter(train) [169100/320000]  base_lr: 5.0838e-05 lr: 5.0838e-06  eta: 18:23:15  time: 0.4419  data_time: 0.0098  memory: 5129  grad_norm: 30.9300  loss: 4.3808  decode.loss_cls: 0.0239  decode.loss_mask: 0.1481  decode.loss_dice: 0.1652  decode.d0.loss_cls: 0.9278  decode.d0.loss_mask: 0.1479  decode.d0.loss_dice: 0.1608  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.1480  decode.d1.loss_dice: 0.1724  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.1510  decode.d2.loss_dice: 0.1777  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.1504  decode.d3.loss_dice: 0.1707  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.1491  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.1491  decode.d5.loss_dice: 0.1706  decode.d6.loss_cls: 0.0490  decode.d6.loss_mask: 0.1482  decode.d6.loss_dice: 0.1633  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.1497  decode.d7.loss_dice: 0.1673  decode.d8.loss_cls: 0.0239  decode.d8.loss_mask: 0.1500  decode.d8.loss_dice: 0.1679
10/01 05:42:55 - mmengine - INFO - Iter(train) [169150/320000]  base_lr: 5.0823e-05 lr: 5.0823e-06  eta: 18:22:53  time: 0.4418  data_time: 0.0098  memory: 5120  grad_norm: 101.9832  loss: 5.1060  decode.loss_cls: 0.0554  decode.loss_mask: 0.2408  decode.loss_dice: 0.1413  decode.d0.loss_cls: 0.7367  decode.d0.loss_mask: 0.2418  decode.d0.loss_dice: 0.1422  decode.d1.loss_cls: 0.0452  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.1419  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.2455  decode.d2.loss_dice: 0.1407  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.2466  decode.d3.loss_dice: 0.1429  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.1395  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.1409  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.2400  decode.d6.loss_dice: 0.1401  decode.d7.loss_cls: 0.0541  decode.d7.loss_mask: 0.2448  decode.d7.loss_dice: 0.1423  decode.d8.loss_cls: 0.0578  decode.d8.loss_mask: 0.2364  decode.d8.loss_dice: 0.1399
10/01 05:43:17 - mmengine - INFO - Iter(train) [169200/320000]  base_lr: 5.0807e-05 lr: 5.0807e-06  eta: 18:22:31  time: 0.4424  data_time: 0.0099  memory: 5129  grad_norm: 55.0607  loss: 5.3189  decode.loss_cls: 0.0833  decode.loss_mask: 0.2131  decode.loss_dice: 0.1796  decode.d0.loss_cls: 0.8137  decode.d0.loss_mask: 0.2173  decode.d0.loss_dice: 0.1740  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.2169  decode.d1.loss_dice: 0.1872  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.2143  decode.d2.loss_dice: 0.1879  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.1784  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.2140  decode.d4.loss_dice: 0.1509  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 0.2168  decode.d5.loss_dice: 0.1562  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.2166  decode.d6.loss_dice: 0.1616  decode.d7.loss_cls: 0.0904  decode.d7.loss_mask: 0.2171  decode.d7.loss_dice: 0.1947  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.1854
10/01 05:43:39 - mmengine - INFO - Iter(train) [169250/320000]  base_lr: 5.0792e-05 lr: 5.0792e-06  eta: 18:22:09  time: 0.4432  data_time: 0.0100  memory: 5129  grad_norm: 49.4905  loss: 5.1200  decode.loss_cls: 0.0680  decode.loss_mask: 0.1791  decode.loss_dice: 0.2161  decode.d0.loss_cls: 0.7982  decode.d0.loss_mask: 0.1754  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.1770  decode.d1.loss_dice: 0.1829  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.1775  decode.d2.loss_dice: 0.2039  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.1774  decode.d3.loss_dice: 0.1842  decode.d4.loss_cls: 0.0953  decode.d4.loss_mask: 0.1764  decode.d4.loss_dice: 0.2117  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.1771  decode.d5.loss_dice: 0.2063  decode.d6.loss_cls: 0.1193  decode.d6.loss_mask: 0.1761  decode.d6.loss_dice: 0.1950  decode.d7.loss_cls: 0.0720  decode.d7.loss_mask: 0.1765  decode.d7.loss_dice: 0.2052  decode.d8.loss_cls: 0.0384  decode.d8.loss_mask: 0.1752  decode.d8.loss_dice: 0.1646
10/01 05:44:02 - mmengine - INFO - Iter(train) [169300/320000]  base_lr: 5.0777e-05 lr: 5.0777e-06  eta: 18:21:48  time: 0.4424  data_time: 0.0098  memory: 5129  grad_norm: 26.7464  loss: 4.2913  decode.loss_cls: 0.0047  decode.loss_mask: 0.1826  decode.loss_dice: 0.1625  decode.d0.loss_cls: 0.8007  decode.d0.loss_mask: 0.1852  decode.d0.loss_dice: 0.1615  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.1837  decode.d1.loss_dice: 0.1635  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.1846  decode.d2.loss_dice: 0.1597  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.1819  decode.d3.loss_dice: 0.1595  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.1821  decode.d4.loss_dice: 0.1620  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.1819  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.1829  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.1813  decode.d7.loss_dice: 0.1676  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.1826  decode.d8.loss_dice: 0.1640
10/01 05:44:24 - mmengine - INFO - Iter(train) [169350/320000]  base_lr: 5.0762e-05 lr: 5.0762e-06  eta: 18:21:26  time: 0.4440  data_time: 0.0100  memory: 5120  grad_norm: 53.8435  loss: 6.0531  decode.loss_cls: 0.1270  decode.loss_mask: 0.1730  decode.loss_dice: 0.2251  decode.d0.loss_cls: 0.9570  decode.d0.loss_mask: 0.1754  decode.d0.loss_dice: 0.2182  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.1722  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.1721  decode.d2.loss_dice: 0.2258  decode.d3.loss_cls: 0.1428  decode.d3.loss_mask: 0.1737  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.1387  decode.d4.loss_mask: 0.1726  decode.d4.loss_dice: 0.2039  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.1740  decode.d5.loss_dice: 0.2545  decode.d6.loss_cls: 0.1366  decode.d6.loss_mask: 0.1732  decode.d6.loss_dice: 0.2311  decode.d7.loss_cls: 0.0983  decode.d7.loss_mask: 0.1740  decode.d7.loss_dice: 0.2692  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.1758  decode.d8.loss_dice: 0.2354
10/01 05:44:46 - mmengine - INFO - Iter(train) [169400/320000]  base_lr: 5.0747e-05 lr: 5.0747e-06  eta: 18:21:04  time: 0.4423  data_time: 0.0098  memory: 5145  grad_norm: 76.1471  loss: 5.6839  decode.loss_cls: 0.0850  decode.loss_mask: 0.1987  decode.loss_dice: 0.1641  decode.d0.loss_cls: 0.9341  decode.d0.loss_mask: 0.2208  decode.d0.loss_dice: 0.2078  decode.d1.loss_cls: 0.1345  decode.d1.loss_mask: 0.2000  decode.d1.loss_dice: 0.1779  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 0.1990  decode.d2.loss_dice: 0.1981  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.2303  decode.d4.loss_cls: 0.0378  decode.d4.loss_mask: 0.2223  decode.d4.loss_dice: 0.2524  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.2145  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.2156  decode.d6.loss_dice: 0.2079  decode.d7.loss_cls: 0.0335  decode.d7.loss_mask: 0.2145  decode.d7.loss_dice: 0.2036  decode.d8.loss_cls: 0.0924  decode.d8.loss_mask: 0.1962  decode.d8.loss_dice: 0.1732
10/01 05:45:08 - mmengine - INFO - Iter(train) [169450/320000]  base_lr: 5.0732e-05 lr: 5.0732e-06  eta: 18:20:42  time: 0.4459  data_time: 0.0100  memory: 5145  grad_norm: 24.2009  loss: 4.0007  decode.loss_cls: 0.0008  decode.loss_mask: 0.1762  decode.loss_dice: 0.1430  decode.d0.loss_cls: 0.8031  decode.d0.loss_mask: 0.1753  decode.d0.loss_dice: 0.1394  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.1774  decode.d1.loss_dice: 0.1473  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.1768  decode.d2.loss_dice: 0.1429  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.1764  decode.d3.loss_dice: 0.1423  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.1777  decode.d4.loss_dice: 0.1431  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.1760  decode.d5.loss_dice: 0.1409  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.1763  decode.d6.loss_dice: 0.1427  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.1759  decode.d7.loss_dice: 0.1431  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.1761  decode.d8.loss_dice: 0.1405
10/01 05:45:30 - mmengine - INFO - Iter(train) [169500/320000]  base_lr: 5.0716e-05 lr: 5.0716e-06  eta: 18:20:21  time: 0.4420  data_time: 0.0099  memory: 5129  grad_norm: 43.8571  loss: 6.0255  decode.loss_cls: 0.0599  decode.loss_mask: 0.2208  decode.loss_dice: 0.2236  decode.d0.loss_cls: 0.8648  decode.d0.loss_mask: 0.2273  decode.d0.loss_dice: 0.2485  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.2253  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.2253  decode.d2.loss_dice: 0.1686  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.2280  decode.d3.loss_dice: 0.2301  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.2486  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.2357  decode.d6.loss_cls: 0.0922  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.2329  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.2215  decode.d7.loss_dice: 0.2238  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.2214  decode.d8.loss_dice: 0.2245
10/01 05:45:52 - mmengine - INFO - Iter(train) [169550/320000]  base_lr: 5.0701e-05 lr: 5.0701e-06  eta: 18:19:59  time: 0.4449  data_time: 0.0100  memory: 5129  grad_norm: 69.5534  loss: 5.7303  decode.loss_cls: 0.0317  decode.loss_mask: 0.2360  decode.loss_dice: 0.2090  decode.d0.loss_cls: 0.8829  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.1916  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.2401  decode.d1.loss_dice: 0.2137  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.2345  decode.d2.loss_dice: 0.2052  decode.d3.loss_cls: 0.0334  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.2145  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.2113  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.2329  decode.d5.loss_dice: 0.2040  decode.d6.loss_cls: 0.0315  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.2076  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.2085  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.2402  decode.d8.loss_dice: 0.2053
10/01 05:46:15 - mmengine - INFO - Iter(train) [169600/320000]  base_lr: 5.0686e-05 lr: 5.0686e-06  eta: 18:19:37  time: 0.4432  data_time: 0.0100  memory: 5120  grad_norm: 67.2708  loss: 5.6994  decode.loss_cls: 0.0225  decode.loss_mask: 0.2272  decode.loss_dice: 0.1819  decode.d0.loss_cls: 0.8868  decode.d0.loss_mask: 0.2304  decode.d0.loss_dice: 0.1692  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.1937  decode.d3.loss_cls: 0.0828  decode.d3.loss_mask: 0.2549  decode.d3.loss_dice: 0.1898  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.1802  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.2544  decode.d5.loss_dice: 0.1899  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.1902  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.2262  decode.d7.loss_dice: 0.1856  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.1814
10/01 05:46:37 - mmengine - INFO - Iter(train) [169650/320000]  base_lr: 5.0671e-05 lr: 5.0671e-06  eta: 18:19:15  time: 0.4457  data_time: 0.0101  memory: 5129  grad_norm: 37.1803  loss: 4.1832  decode.loss_cls: 0.0024  decode.loss_mask: 0.1746  decode.loss_dice: 0.1559  decode.d0.loss_cls: 0.8185  decode.d0.loss_mask: 0.1811  decode.d0.loss_dice: 0.1528  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.1794  decode.d1.loss_dice: 0.1584  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.1761  decode.d2.loss_dice: 0.1548  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.1777  decode.d3.loss_dice: 0.1584  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.1791  decode.d4.loss_dice: 0.1586  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.1763  decode.d5.loss_dice: 0.1575  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.1777  decode.d6.loss_dice: 0.1549  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.1756  decode.d7.loss_dice: 0.1569  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.1767  decode.d8.loss_dice: 0.1564
10/01 05:46:59 - mmengine - INFO - Iter(train) [169700/320000]  base_lr: 5.0656e-05 lr: 5.0656e-06  eta: 18:18:54  time: 0.4429  data_time: 0.0100  memory: 5120  grad_norm: 20.9452  loss: 3.7424  decode.loss_cls: 0.0016  decode.loss_mask: 0.1555  decode.loss_dice: 0.1296  decode.d0.loss_cls: 0.8312  decode.d0.loss_mask: 0.1590  decode.d0.loss_dice: 0.1346  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.1558  decode.d1.loss_dice: 0.1359  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.1567  decode.d2.loss_dice: 0.1334  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.1556  decode.d3.loss_dice: 0.1354  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.1562  decode.d4.loss_dice: 0.1311  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.1547  decode.d5.loss_dice: 0.1320  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1564  decode.d6.loss_dice: 0.1342  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.1552  decode.d7.loss_dice: 0.1302  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.1561  decode.d8.loss_dice: 0.1324
10/01 05:47:21 - mmengine - INFO - Iter(train) [169750/320000]  base_lr: 5.0641e-05 lr: 5.0641e-06  eta: 18:18:32  time: 0.4416  data_time: 0.0099  memory: 5119  grad_norm: 40.0438  loss: 4.7444  decode.loss_cls: 0.0816  decode.loss_mask: 0.2026  decode.loss_dice: 0.1562  decode.d0.loss_cls: 0.8108  decode.d0.loss_mask: 0.1852  decode.d0.loss_dice: 0.1390  decode.d1.loss_cls: 0.0535  decode.d1.loss_mask: 0.1854  decode.d1.loss_dice: 0.1430  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.1503  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.1869  decode.d3.loss_dice: 0.1539  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.1826  decode.d4.loss_dice: 0.1428  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.1847  decode.d5.loss_dice: 0.1511  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.1847  decode.d6.loss_dice: 0.1404  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.1820  decode.d7.loss_dice: 0.1406  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.1836  decode.d8.loss_dice: 0.1388
10/01 05:47:43 - mmengine - INFO - Iter(train) [169800/320000]  base_lr: 5.0625e-05 lr: 5.0625e-06  eta: 18:18:10  time: 0.4422  data_time: 0.0100  memory: 5145  grad_norm: 57.2183  loss: 6.3461  decode.loss_cls: 0.1291  decode.loss_mask: 0.2260  decode.loss_dice: 0.1940  decode.d0.loss_cls: 0.9474  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.1916  decode.d1.loss_cls: 0.1591  decode.d1.loss_mask: 0.2238  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.1865  decode.d3.loss_cls: 0.1278  decode.d3.loss_mask: 0.2249  decode.d3.loss_dice: 0.1999  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.2242  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.1075  decode.d5.loss_mask: 0.2255  decode.d5.loss_dice: 0.2021  decode.d6.loss_cls: 0.1064  decode.d6.loss_mask: 0.2256  decode.d6.loss_dice: 0.1917  decode.d7.loss_cls: 0.1372  decode.d7.loss_mask: 0.2249  decode.d7.loss_dice: 0.1999  decode.d8.loss_cls: 0.1077  decode.d8.loss_mask: 0.2260  decode.d8.loss_dice: 0.2004
10/01 05:48:05 - mmengine - INFO - Iter(train) [169850/320000]  base_lr: 5.0610e-05 lr: 5.0610e-06  eta: 18:17:48  time: 0.4427  data_time: 0.0099  memory: 5129  grad_norm: 34.9849  loss: 4.4747  decode.loss_cls: 0.0277  decode.loss_mask: 0.1773  decode.loss_dice: 0.1608  decode.d0.loss_cls: 0.8835  decode.d0.loss_mask: 0.1818  decode.d0.loss_dice: 0.1661  decode.d1.loss_cls: 0.0167  decode.d1.loss_mask: 0.1789  decode.d1.loss_dice: 0.1601  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.1782  decode.d2.loss_dice: 0.1599  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.1793  decode.d3.loss_dice: 0.1646  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.1798  decode.d4.loss_dice: 0.1603  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.1784  decode.d5.loss_dice: 0.1594  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.1792  decode.d6.loss_dice: 0.1576  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.1798  decode.d7.loss_dice: 0.1613  decode.d8.loss_cls: 0.0267  decode.d8.loss_mask: 0.1801  decode.d8.loss_dice: 0.1588
10/01 05:48:27 - mmengine - INFO - Iter(train) [169900/320000]  base_lr: 5.0595e-05 lr: 5.0595e-06  eta: 18:17:27  time: 0.4420  data_time: 0.0099  memory: 5129  grad_norm: 24.3104  loss: 3.6941  decode.loss_cls: 0.0016  decode.loss_mask: 0.1603  decode.loss_dice: 0.1302  decode.d0.loss_cls: 0.7597  decode.d0.loss_mask: 0.1619  decode.d0.loss_dice: 0.1353  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.1616  decode.d1.loss_dice: 0.1324  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.1611  decode.d2.loss_dice: 0.1308  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.1598  decode.d3.loss_dice: 0.1272  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1597  decode.d4.loss_dice: 0.1287  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.1616  decode.d5.loss_dice: 0.1309  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.1600  decode.d6.loss_dice: 0.1312  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.1625  decode.d7.loss_dice: 0.1308  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.1623  decode.d8.loss_dice: 0.1304
10/01 05:48:50 - mmengine - INFO - Iter(train) [169950/320000]  base_lr: 5.0580e-05 lr: 5.0580e-06  eta: 18:17:05  time: 0.4608  data_time: 0.0098  memory: 5120  grad_norm: 35.5159  loss: 4.4017  decode.loss_cls: 0.0062  decode.loss_mask: 0.1834  decode.loss_dice: 0.1767  decode.d0.loss_cls: 0.7671  decode.d0.loss_mask: 0.1903  decode.d0.loss_dice: 0.1746  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.1886  decode.d1.loss_dice: 0.1821  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.1865  decode.d2.loss_dice: 0.1663  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.1855  decode.d3.loss_dice: 0.1686  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.1865  decode.d4.loss_dice: 0.1638  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.1876  decode.d5.loss_dice: 0.1738  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.1856  decode.d6.loss_dice: 0.1781  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.1865  decode.d7.loss_dice: 0.1710  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1690
10/01 05:49:12 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:49:12 - mmengine - INFO - Iter(train) [170000/320000]  base_lr: 5.0565e-05 lr: 5.0565e-06  eta: 18:16:43  time: 0.4421  data_time: 0.0099  memory: 5104  grad_norm: 97.5570  loss: 5.6912  decode.loss_cls: 0.0084  decode.loss_mask: 0.2732  decode.loss_dice: 0.1939  decode.d0.loss_cls: 0.8136  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.1925  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.2807  decode.d1.loss_dice: 0.1951  decode.d2.loss_cls: 0.0275  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.1961  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.2810  decode.d3.loss_dice: 0.1961  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.2813  decode.d4.loss_dice: 0.1964  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.2769  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.2778  decode.d6.loss_dice: 0.1947  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.2785  decode.d7.loss_dice: 0.1960  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.1958
10/01 05:49:34 - mmengine - INFO - Iter(train) [170050/320000]  base_lr: 5.0550e-05 lr: 5.0550e-06  eta: 18:16:22  time: 0.4423  data_time: 0.0100  memory: 5145  grad_norm: 71.2559  loss: 4.2461  decode.loss_cls: 0.0153  decode.loss_mask: 0.1882  decode.loss_dice: 0.1460  decode.d0.loss_cls: 0.7856  decode.d0.loss_mask: 0.1916  decode.d0.loss_dice: 0.1412  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.1911  decode.d1.loss_dice: 0.1420  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.1890  decode.d2.loss_dice: 0.1393  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.1911  decode.d3.loss_dice: 0.1517  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.1896  decode.d4.loss_dice: 0.1505  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.1887  decode.d5.loss_dice: 0.1456  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.1886  decode.d6.loss_dice: 0.1464  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.1460  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.1883  decode.d8.loss_dice: 0.1427
10/01 05:49:56 - mmengine - INFO - Iter(train) [170100/320000]  base_lr: 5.0534e-05 lr: 5.0534e-06  eta: 18:16:00  time: 0.4430  data_time: 0.0100  memory: 5129  grad_norm: 41.0427  loss: 6.1031  decode.loss_cls: 0.1325  decode.loss_mask: 0.1904  decode.loss_dice: 0.2052  decode.d0.loss_cls: 0.7707  decode.d0.loss_mask: 0.1877  decode.d0.loss_dice: 0.2203  decode.d1.loss_cls: 0.1403  decode.d1.loss_mask: 0.1887  decode.d1.loss_dice: 0.2147  decode.d2.loss_cls: 0.1683  decode.d2.loss_mask: 0.1908  decode.d2.loss_dice: 0.2140  decode.d3.loss_cls: 0.1346  decode.d3.loss_mask: 0.1901  decode.d3.loss_dice: 0.2132  decode.d4.loss_cls: 0.1200  decode.d4.loss_mask: 0.1923  decode.d4.loss_dice: 0.2199  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.1901  decode.d5.loss_dice: 0.2556  decode.d6.loss_cls: 0.1420  decode.d6.loss_mask: 0.1875  decode.d6.loss_dice: 0.2101  decode.d7.loss_cls: 0.1438  decode.d7.loss_mask: 0.1903  decode.d7.loss_dice: 0.1990  decode.d8.loss_cls: 0.1644  decode.d8.loss_mask: 0.1905  decode.d8.loss_dice: 0.2359
10/01 05:50:18 - mmengine - INFO - Iter(train) [170150/320000]  base_lr: 5.0519e-05 lr: 5.0519e-06  eta: 18:15:38  time: 0.4428  data_time: 0.0100  memory: 5129  grad_norm: 91.2025  loss: 3.8393  decode.loss_cls: 0.0140  decode.loss_mask: 0.1619  decode.loss_dice: 0.1447  decode.d0.loss_cls: 0.7276  decode.d0.loss_mask: 0.1518  decode.d0.loss_dice: 0.1337  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.1544  decode.d1.loss_dice: 0.1388  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.1540  decode.d2.loss_dice: 0.1392  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.1545  decode.d3.loss_dice: 0.1397  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.1546  decode.d4.loss_dice: 0.1413  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.1547  decode.d5.loss_dice: 0.1397  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.1600  decode.d6.loss_dice: 0.1431  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.1560  decode.d7.loss_dice: 0.1399  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.1569  decode.d8.loss_dice: 0.1413
10/01 05:50:41 - mmengine - INFO - Iter(train) [170200/320000]  base_lr: 5.0504e-05 lr: 5.0504e-06  eta: 18:15:16  time: 0.4428  data_time: 0.0101  memory: 5120  grad_norm: 49.1664  loss: 5.6145  decode.loss_cls: 0.0791  decode.loss_mask: 0.1752  decode.loss_dice: 0.2397  decode.d0.loss_cls: 0.7549  decode.d0.loss_mask: 0.1706  decode.d0.loss_dice: 0.2380  decode.d1.loss_cls: 0.1120  decode.d1.loss_mask: 0.1724  decode.d1.loss_dice: 0.2095  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.1720  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.1732  decode.d3.loss_dice: 0.2361  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.1702  decode.d4.loss_dice: 0.2319  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.1745  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.1025  decode.d6.loss_mask: 0.1694  decode.d6.loss_dice: 0.2364  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.1702  decode.d7.loss_dice: 0.2107  decode.d8.loss_cls: 0.1164  decode.d8.loss_mask: 0.1736  decode.d8.loss_dice: 0.2230
10/01 05:51:03 - mmengine - INFO - Iter(train) [170250/320000]  base_lr: 5.0489e-05 lr: 5.0489e-06  eta: 18:14:55  time: 0.4431  data_time: 0.0099  memory: 5129  grad_norm: 132.4743  loss: 5.5481  decode.loss_cls: 0.0829  decode.loss_mask: 0.1632  decode.loss_dice: 0.1979  decode.d0.loss_cls: 1.0365  decode.d0.loss_mask: 0.1631  decode.d0.loss_dice: 0.1938  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 0.1622  decode.d1.loss_dice: 0.2039  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 0.1627  decode.d2.loss_dice: 0.1644  decode.d3.loss_cls: 0.1209  decode.d3.loss_mask: 0.1598  decode.d3.loss_dice: 0.1968  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.1600  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.1267  decode.d5.loss_mask: 0.1610  decode.d5.loss_dice: 0.1948  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.1622  decode.d6.loss_dice: 0.2149  decode.d7.loss_cls: 0.0925  decode.d7.loss_mask: 0.1627  decode.d7.loss_dice: 0.1920  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.1613  decode.d8.loss_dice: 0.2203
10/01 05:51:25 - mmengine - INFO - Iter(train) [170300/320000]  base_lr: 5.0474e-05 lr: 5.0474e-06  eta: 18:14:33  time: 0.4424  data_time: 0.0099  memory: 5129  grad_norm: 205.0682  loss: 5.6730  decode.loss_cls: 0.0545  decode.loss_mask: 0.2270  decode.loss_dice: 0.1924  decode.d0.loss_cls: 0.9195  decode.d0.loss_mask: 0.2259  decode.d0.loss_dice: 0.1671  decode.d1.loss_cls: 0.0876  decode.d1.loss_mask: 0.2226  decode.d1.loss_dice: 0.1906  decode.d2.loss_cls: 0.0205  decode.d2.loss_mask: 0.2262  decode.d2.loss_dice: 0.1955  decode.d3.loss_cls: 0.0304  decode.d3.loss_mask: 0.2220  decode.d3.loss_dice: 0.2150  decode.d4.loss_cls: 0.0482  decode.d4.loss_mask: 0.2240  decode.d4.loss_dice: 0.1961  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.2133  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.2237  decode.d6.loss_dice: 0.1983  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.2220  decode.d8.loss_cls: 0.0779  decode.d8.loss_mask: 0.2248  decode.d8.loss_dice: 0.2377
10/01 05:51:47 - mmengine - INFO - Iter(train) [170350/320000]  base_lr: 5.0459e-05 lr: 5.0459e-06  eta: 18:14:11  time: 0.4429  data_time: 0.0098  memory: 5129  grad_norm: 82.5849  loss: 4.5226  decode.loss_cls: 0.0124  decode.loss_mask: 0.1844  decode.loss_dice: 0.1834  decode.d0.loss_cls: 0.7076  decode.d0.loss_mask: 0.1927  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.1851  decode.d1.loss_dice: 0.1903  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.1842  decode.d2.loss_dice: 0.1875  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.1846  decode.d3.loss_dice: 0.1856  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.1864  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.1852  decode.d5.loss_dice: 0.1864  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.1869  decode.d6.loss_dice: 0.1834  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.1846  decode.d7.loss_dice: 0.1907  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.1857  decode.d8.loss_dice: 0.1844
10/01 05:52:09 - mmengine - INFO - Iter(train) [170400/320000]  base_lr: 5.0443e-05 lr: 5.0443e-06  eta: 18:13:49  time: 0.4427  data_time: 0.0100  memory: 5129  grad_norm: 77.2253  loss: 4.6317  decode.loss_cls: 0.0046  decode.loss_mask: 0.2264  decode.loss_dice: 0.1682  decode.d0.loss_cls: 0.7001  decode.d0.loss_mask: 0.2279  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.1634  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.1616  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2229  decode.d3.loss_dice: 0.1644  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.2188  decode.d4.loss_dice: 0.1665  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.2168  decode.d5.loss_dice: 0.1652  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.1620  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.2243  decode.d7.loss_dice: 0.1651  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.1677
10/01 05:52:31 - mmengine - INFO - Iter(train) [170450/320000]  base_lr: 5.0428e-05 lr: 5.0428e-06  eta: 18:13:28  time: 0.4427  data_time: 0.0099  memory: 5145  grad_norm: 146.7491  loss: 5.0661  decode.loss_cls: 0.0151  decode.loss_mask: 0.2273  decode.loss_dice: 0.1895  decode.d0.loss_cls: 0.7876  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.1766  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.2271  decode.d1.loss_dice: 0.1830  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.2303  decode.d2.loss_dice: 0.1847  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.2276  decode.d3.loss_dice: 0.1945  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.1863  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1810  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.2289  decode.d6.loss_dice: 0.1873  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.2305  decode.d7.loss_dice: 0.1885  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.1924
10/01 05:52:54 - mmengine - INFO - Iter(train) [170500/320000]  base_lr: 5.0413e-05 lr: 5.0413e-06  eta: 18:13:06  time: 0.4429  data_time: 0.0099  memory: 5145  grad_norm: 36.6654  loss: 4.2451  decode.loss_cls: 0.0462  decode.loss_mask: 0.1588  decode.loss_dice: 0.1649  decode.d0.loss_cls: 0.7845  decode.d0.loss_mask: 0.1621  decode.d0.loss_dice: 0.1603  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.1597  decode.d1.loss_dice: 0.1638  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.1627  decode.d2.loss_dice: 0.1766  decode.d3.loss_cls: 0.0359  decode.d3.loss_mask: 0.1605  decode.d3.loss_dice: 0.1721  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.1584  decode.d4.loss_dice: 0.1649  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.1620  decode.d5.loss_dice: 0.1676  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.1608  decode.d6.loss_dice: 0.1639  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.1613  decode.d7.loss_dice: 0.1597  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.1579  decode.d8.loss_dice: 0.1711
10/01 05:53:16 - mmengine - INFO - Iter(train) [170550/320000]  base_lr: 5.0398e-05 lr: 5.0398e-06  eta: 18:12:44  time: 0.4419  data_time: 0.0100  memory: 5120  grad_norm: 22.2562  loss: 3.9054  decode.loss_cls: 0.0035  decode.loss_mask: 0.1775  decode.loss_dice: 0.1385  decode.d0.loss_cls: 0.7368  decode.d0.loss_mask: 0.1812  decode.d0.loss_dice: 0.1332  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.1797  decode.d1.loss_dice: 0.1328  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.1806  decode.d2.loss_dice: 0.1370  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.1777  decode.d3.loss_dice: 0.1346  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.1801  decode.d4.loss_dice: 0.1386  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.1787  decode.d5.loss_dice: 0.1348  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.1788  decode.d6.loss_dice: 0.1346  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.1795  decode.d7.loss_dice: 0.1355  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.1790  decode.d8.loss_dice: 0.1379
10/01 05:53:38 - mmengine - INFO - Iter(train) [170600/320000]  base_lr: 5.0383e-05 lr: 5.0383e-06  eta: 18:12:22  time: 0.4424  data_time: 0.0101  memory: 5120  grad_norm: 55.5854  loss: 4.0356  decode.loss_cls: 0.0142  decode.loss_mask: 0.1694  decode.loss_dice: 0.1389  decode.d0.loss_cls: 0.8314  decode.d0.loss_mask: 0.1696  decode.d0.loss_dice: 0.1408  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.1697  decode.d1.loss_dice: 0.1371  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.1701  decode.d2.loss_dice: 0.1398  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.1718  decode.d3.loss_dice: 0.1415  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.1722  decode.d4.loss_dice: 0.1423  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.1679  decode.d5.loss_dice: 0.1402  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.1702  decode.d6.loss_dice: 0.1397  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.1692  decode.d7.loss_dice: 0.1398  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.1692  decode.d8.loss_dice: 0.1398
10/01 05:54:00 - mmengine - INFO - Iter(train) [170650/320000]  base_lr: 5.0368e-05 lr: 5.0368e-06  eta: 18:12:01  time: 0.4424  data_time: 0.0099  memory: 5129  grad_norm: 36.5919  loss: 4.7125  decode.loss_cls: 0.0479  decode.loss_mask: 0.1937  decode.loss_dice: 0.1600  decode.d0.loss_cls: 0.8173  decode.d0.loss_mask: 0.1937  decode.d0.loss_dice: 0.1615  decode.d1.loss_cls: 0.0389  decode.d1.loss_mask: 0.1941  decode.d1.loss_dice: 0.1653  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 0.1925  decode.d2.loss_dice: 0.1592  decode.d3.loss_cls: 0.0390  decode.d3.loss_mask: 0.1937  decode.d3.loss_dice: 0.1590  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 0.1943  decode.d4.loss_dice: 0.1656  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.1931  decode.d5.loss_dice: 0.1636  decode.d6.loss_cls: 0.0353  decode.d6.loss_mask: 0.1893  decode.d6.loss_dice: 0.1570  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.1952  decode.d7.loss_dice: 0.1623  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.1929  decode.d8.loss_dice: 0.1581
10/01 05:54:22 - mmengine - INFO - Iter(train) [170700/320000]  base_lr: 5.0352e-05 lr: 5.0352e-06  eta: 18:11:39  time: 0.4423  data_time: 0.0098  memory: 5145  grad_norm: 63.3112  loss: 4.9836  decode.loss_cls: 0.0914  decode.loss_mask: 0.1877  decode.loss_dice: 0.1456  decode.d0.loss_cls: 0.7851  decode.d0.loss_mask: 0.1931  decode.d0.loss_dice: 0.1442  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 0.1932  decode.d1.loss_dice: 0.1492  decode.d2.loss_cls: 0.0869  decode.d2.loss_mask: 0.1913  decode.d2.loss_dice: 0.1469  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.1891  decode.d3.loss_dice: 0.1445  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.1860  decode.d4.loss_dice: 0.1455  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 0.1900  decode.d5.loss_dice: 0.1489  decode.d6.loss_cls: 0.1033  decode.d6.loss_mask: 0.1898  decode.d6.loss_dice: 0.1473  decode.d7.loss_cls: 0.0940  decode.d7.loss_mask: 0.1881  decode.d7.loss_dice: 0.1457  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.1891  decode.d8.loss_dice: 0.1442
10/01 05:54:44 - mmengine - INFO - Iter(train) [170750/320000]  base_lr: 5.0337e-05 lr: 5.0337e-06  eta: 18:11:17  time: 0.4418  data_time: 0.0098  memory: 5120  grad_norm: 28.4352  loss: 4.3182  decode.loss_cls: 0.0017  decode.loss_mask: 0.1892  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.7535  decode.d0.loss_mask: 0.1903  decode.d0.loss_dice: 0.1633  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.1908  decode.d1.loss_dice: 0.1666  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.1910  decode.d2.loss_dice: 0.1620  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.1870  decode.d3.loss_dice: 0.1641  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.1909  decode.d4.loss_dice: 0.1718  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.1899  decode.d5.loss_dice: 0.1694  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.1929  decode.d6.loss_dice: 0.1620  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.1892  decode.d7.loss_dice: 0.1609  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.1915  decode.d8.loss_dice: 0.1614
10/01 05:55:06 - mmengine - INFO - Iter(train) [170800/320000]  base_lr: 5.0322e-05 lr: 5.0322e-06  eta: 18:10:55  time: 0.4428  data_time: 0.0099  memory: 5120  grad_norm: 27.5673  loss: 4.4532  decode.loss_cls: 0.0027  decode.loss_mask: 0.1827  decode.loss_dice: 0.1698  decode.d0.loss_cls: 0.8423  decode.d0.loss_mask: 0.1864  decode.d0.loss_dice: 0.1515  decode.d1.loss_cls: 0.0298  decode.d1.loss_mask: 0.1846  decode.d1.loss_dice: 0.1675  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.1821  decode.d2.loss_dice: 0.1613  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.1841  decode.d3.loss_dice: 0.1748  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.1822  decode.d4.loss_dice: 0.1823  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.1848  decode.d5.loss_dice: 0.1771  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.1846  decode.d6.loss_dice: 0.1863  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.1841  decode.d7.loss_dice: 0.1708  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.1827  decode.d8.loss_dice: 0.1764
10/01 05:55:29 - mmengine - INFO - Iter(train) [170850/320000]  base_lr: 5.0307e-05 lr: 5.0307e-06  eta: 18:10:34  time: 0.4422  data_time: 0.0097  memory: 5145  grad_norm: 32.0815  loss: 4.3527  decode.loss_cls: 0.0079  decode.loss_mask: 0.1846  decode.loss_dice: 0.1808  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.1888  decode.d0.loss_dice: 0.1571  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.1834  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.1837  decode.d2.loss_dice: 0.1465  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.1840  decode.d3.loss_dice: 0.1772  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.1843  decode.d4.loss_dice: 0.1488  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.1827  decode.d5.loss_dice: 0.1647  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.1866  decode.d6.loss_dice: 0.1699  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.1823  decode.d7.loss_dice: 0.1412  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.1844  decode.d8.loss_dice: 0.1778
10/01 05:55:51 - mmengine - INFO - Iter(train) [170900/320000]  base_lr: 5.0292e-05 lr: 5.0292e-06  eta: 18:10:12  time: 0.4426  data_time: 0.0098  memory: 5145  grad_norm: 118.5415  loss: 6.5667  decode.loss_cls: 0.1741  decode.loss_mask: 0.2121  decode.loss_dice: 0.1957  decode.d0.loss_cls: 0.8863  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.1982  decode.d1.loss_cls: 0.1755  decode.d1.loss_mask: 0.2170  decode.d1.loss_dice: 0.1759  decode.d2.loss_cls: 0.1665  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.2241  decode.d3.loss_cls: 0.1829  decode.d3.loss_mask: 0.2038  decode.d3.loss_dice: 0.1769  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 0.2009  decode.d4.loss_dice: 0.1841  decode.d5.loss_cls: 0.1693  decode.d5.loss_mask: 0.3167  decode.d5.loss_dice: 0.2137  decode.d6.loss_cls: 0.1564  decode.d6.loss_mask: 0.2263  decode.d6.loss_dice: 0.1857  decode.d7.loss_cls: 0.1719  decode.d7.loss_mask: 0.1982  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.1682  decode.d8.loss_mask: 0.2022  decode.d8.loss_dice: 0.1723
10/01 05:56:13 - mmengine - INFO - Iter(train) [170950/320000]  base_lr: 5.0276e-05 lr: 5.0276e-06  eta: 18:09:50  time: 0.4414  data_time: 0.0099  memory: 5120  grad_norm: 50.5619  loss: 5.3735  decode.loss_cls: 0.0070  decode.loss_mask: 0.2683  decode.loss_dice: 0.1919  decode.d0.loss_cls: 0.6790  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.1932  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.2677  decode.d1.loss_dice: 0.1980  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2688  decode.d2.loss_dice: 0.1964  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.2692  decode.d3.loss_dice: 0.1998  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.2672  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.2654  decode.d5.loss_dice: 0.1940  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2659  decode.d6.loss_dice: 0.1977  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.1954  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.2708  decode.d8.loss_dice: 0.1953
10/01 05:56:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250930_090242
10/01 05:56:35 - mmengine - INFO - Iter(train) [171000/320000]  base_lr: 5.0261e-05 lr: 5.0261e-06  eta: 18:09:28  time: 0.4419  data_time: 0.0098  memory: 5145  grad_norm: 111.5189  loss: 6.0133  decode.loss_cls: 0.0834  decode.loss_mask: 0.2529  decode.loss_dice: 0.1902  decode.d0.loss_cls: 0.8941  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.1790  decode.d1.loss_cls: 0.1040  decode.d1.loss_mask: 0.2345  decode.d1.loss_dice: 0.1914  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.2539  decode.d2.loss_dice: 0.1932  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.1854  decode.d4.loss_cls: 0.0806  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.1877  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.2542  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.2563  decode.d6.loss_dice: 0.1928  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.1886  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.2531  decode.d8.loss_dice: 0.1883
10/01 05:56:57 - mmengine - INFO - Iter(train) [171050/320000]  base_lr: 5.0246e-05 lr: 5.0246e-06  eta: 18:09:06  time: 0.4429  data_time: 0.0098  memory: 5129  grad_norm: 66.9079  loss: 6.5163  decode.loss_cls: 0.1752  decode.loss_mask: 0.1778  decode.loss_dice: 0.2224  decode.d0.loss_cls: 0.8123  decode.d0.loss_mask: 0.1745  decode.d0.loss_dice: 0.2550  decode.d1.loss_cls: 0.1616  decode.d1.loss_mask: 0.1737  decode.d1.loss_dice: 0.2164  decode.d2.loss_cls: 0.1965  decode.d2.loss_mask: 0.1739  decode.d2.loss_dice: 0.2289  decode.d3.loss_cls: 0.1834  decode.d3.loss_mask: 0.1747  decode.d3.loss_dice: 0.2218  decode.d4.loss_cls: 0.1835  decode.d4.loss_mask: 0.1745  decode.d4.loss_dice: 0.2072  decode.d5.loss_cls: 0.1760  decode.d5.loss_mask: 0.1741  decode.d5.loss_dice: 0.2036  decode.d6.loss_cls: 0.1893  decode.d6.loss_mask: 0.1766  decode.d6.loss_dice: 0.2258  decode.d7.loss_cls: 0.2429  decode.d7.loss_mask: 0.1725  decode.d7.loss_dice: 0.2053  decode.d8.loss_cls: 0.2168  decode.d8.loss_mask: 0.1764  decode.d8.loss_dice: 0.2440
10/01 05:57:19 - mmengine - INFO - Iter(train) [171100/320000]  base_lr: 5.0231e-05 lr: 5.0231e-06  eta: 18:08:45  time: 0.4414  data_time: 0.0097  memory: 5145  grad_norm: 53.4183  loss: 5.8543  decode.loss_cls: 0.0720  decode.loss_mask: 0.2318  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.6900  decode.d0.loss_mask: 0.2322  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.2309  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.2306  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.2304  decode.d4.loss_dice: 0.2290  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.2305  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 0.2261  decode.d6.loss_dice: 0.2273  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.2280  decode.d7.loss_dice: 0.2302  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.2295  decode.d8.loss_dice: 0.2314
10/01 05:57:41 - mmengine - INFO - Iter(train) [171150/320000]  base_lr: 5.0216e-05 lr: 5.0216e-06  eta: 18:08:23  time: 0.4414  data_time: 0.0097  memory: 5129  grad_norm: 29.0230  loss: 4.3212  decode.loss_cls: 0.0022  decode.loss_mask: 0.1972  decode.loss_dice: 0.1530  decode.d0.loss_cls: 0.7971  decode.d0.loss_mask: 0.1994  decode.d0.loss_dice: 0.1523  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.1532  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.1976  decode.d2.loss_dice: 0.1549  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.1957  decode.d3.loss_dice: 0.1517  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.1955  decode.d4.loss_dice: 0.1494  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.1966  decode.d5.loss_dice: 0.1523  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.1960  decode.d6.loss_dice: 0.1577  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.1965  decode.d7.loss_dice: 0.1555  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.1966  decode.d8.loss_dice: 0.1548
10/01 05:58:04 - mmengine - INFO - Iter(train) [171200/320000]  base_lr: 5.0201e-05 lr: 5.0201e-06  eta: 18:08:01  time: 0.4411  data_time: 0.0097  memory: 5145  grad_norm: 38.5933  loss: 4.1329  decode.loss_cls: 0.0043  decode.loss_mask: 0.1780  decode.loss_dice: 0.1495  decode.d0.loss_cls: 0.8211  decode.d0.loss_mask: 0.1821  decode.d0.loss_dice: 0.1435  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.1786  decode.d1.loss_dice: 0.1517  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.1805  decode.d2.loss_dice: 0.1527  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.1783  decode.d3.loss_dice: 0.1456  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.1792  decode.d4.loss_dice: 0.1535  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.1787  decode.d5.loss_dice: 0.1500  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.1763  decode.d6.loss_dice: 0.1458  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.1769  decode.d7.loss_dice: 0.1502  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.1774  decode.d8.loss_dice: 0.1489
10/01 05:58:26 - mmengine - INFO - Iter(train) [171250/320000]  base_lr: 5.0185e-05 lr: 5.0185e-06  eta: 18:07:39  time: 0.4422  data_time: 0.0097  memory: 5129  grad_norm: 263.1761  loss: 4.9038  decode.loss_cls: 0.0285  decode.loss_mask: 0.1915  decode.loss_dice: 0.1539  decode.d0.loss_cls: 0.8137  decode.d0.loss_mask: 0.1962  decode.d0.loss_dice: 0.1525  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.1905  decode.d1.loss_dice: 0.1523  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.1909  decode.d2.loss_dice: 0.1499  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.1908  decode.d3.loss_dice: 0.1501  decode.d4.loss_cls: 0.0634  decode.d4.loss_mask: 0.1927  decode.d4.loss_dice: 0.1527  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.1958  decode.d5.loss_dice: 0.1521  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 0.1904  decode.d6.loss_dice: 0.1519  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.1916  decode.d7.loss_dice: 0.1546  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.1918  decode.d8.loss_dice: 0.1528
10/01 05:58:48 - mmengine - INFO - Iter(train) [171300/320000]  base_lr: 5.0170e-05 lr: 5.0170e-06  eta: 18:07:17  time: 0.4440  data_time: 0.0099  memory: 5129  grad_norm: 118.4659  loss: 5.7647  decode.loss_cls: 0.1281  decode.loss_mask: 0.1735  decode.loss_dice: 0.1904  decode.d0.loss_cls: 0.8911  decode.d0.loss_mask: 0.1815  decode.d0.loss_dice: 0.2155  decode.d1.loss_cls: 0.1527  decode.d1.loss_mask: 0.1783  decode.d1.loss_dice: 0.2317  decode.d2.loss_cls: 0.0979  decode.d2.loss_mask: 0.1749  decode.d2.loss_dice: 0.1953  decode.d3.loss_cls: 0.1027  decode.d3.loss_mask: 0.1774  decode.d3.loss_dice: 0.1950  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.1733  decode.d4.loss_dice: 0.2012  decode.d5.loss_cls: 0.1211  decode.d5.loss_mask: 0.1752  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 0.1769  decode.d6.loss_dice: 0.2070  decode.d7.loss_cls: 0.1100  decode.d7.loss_mask: 0.1744  decode.d7.loss_dice: 0.2081  decode.d8.loss_cls: 0.1495  decode.d8.loss_mask: 0.1752  decode.d8.loss_dice: 0.1865
10/01 05:59:10 - mmengine - INFO - Iter(train) [171350/320000]  base_lr: 5.0155e-05 lr: 5.0155e-06  eta: 18:06:56  time: 0.4423  data_time: 0.0100  memory: 5129  grad_norm: 74.9696  loss: 6.1827  decode.loss_cls: 0.1677  decode.loss_mask: 0.1852  decode.loss_dice: 0.2091  decode.d0.loss_cls: 0.9564  decode.d0.loss_mask: 0.1781  decode.d0.loss_dice: 0.1859  decode.d1.loss_cls: 0.1253  decode.d1.loss_mask: 0.1803  decode.d1.loss_dice: 0.1862  decode.d2.loss_cls: 0.2367  decode.d2.loss_mask: 0.1809  decode.d2.loss_dice: 0.1996  decode.d3.loss_cls: 0.2026  decode.d3.loss_mask: 0.1784  decode.d3.loss_dice: 0.1662  decode.d4.loss_cls: 0.1429  decode.d4.loss_mask: 0.1791  decode.d4.loss_dice: 0.2005  decode.d5.loss_cls: 0.1881  decode.d5.loss_mask: 0.1764  decode.d5.loss_dice: 0.1800  decode.d6.loss_cls: 0.1846  decode.d6.loss_mask: 0.1788  decode.d6.loss_dice: 0.1918  decode.d7.loss_cls: 0.1440  decode.d7.loss_mask: 0.1800  decode.d7.loss_dice: 0.1839  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 0.1833  decode.d8.loss_dice: 0.2063
10/01 05:59:32 - mmengine - INFO - Iter(train) [171400/320000]  base_lr: 5.0140e-05 lr: 5.0140e-06  eta: 18:06:34  time: 0.4447  data_time: 0.0098  memory: 5145  grad_norm: 276.0760  loss: 7.0941  decode.loss_cls: 0.1134  decode.loss_mask: 0.2410  decode.loss_dice: 0.2296  decode.d0.loss_cls: 1.0144  decode.d0.loss_mask: 0.2028  decode.d0.loss_dice: 0.1745  decode.d1.loss_cls: 0.2182  decode.d1.loss_mask: 0.2119  decode.d1.loss_dice: 0.2110  decode.d2.loss_cls: 0.1486  decode.d2.loss_mask: 0.2368  decode.d2.loss_dice: 0.2066  decode.d3.loss_cls: 0.1514  decode.d3.loss_mask: 0.3040  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.1396  decode.d4.loss_mask: 0.2438  decode.d4.loss_dice: 0.2238  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.3584  decode.d6.loss_dice: 0.2687  decode.d7.loss_cls: 0.1469  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.2177  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 0.2457  decode.d8.loss_dice: 0.2040
10/01 05:59:54 - mmengine - INFO - Iter(train) [171450/320000]  base_lr: 5.0125e-05 lr: 5.0125e-06  eta: 18:06:12  time: 0.4428  data_time: 0.0098  memory: 5120  grad_norm: 44.6368  loss: 4.7977  decode.loss_cls: 0.0017  decode.loss_mask: 0.2014  decode.loss_dice: 0.1982  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 0.1999  decode.d0.loss_dice: 0.1935  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.1925  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.1992  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.1953  decode.d3.loss_dice: 0.1981  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.1990  decode.d4.loss_dice: 0.1964  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.1968  decode.d5.loss_dice: 0.1953  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1991  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.1951  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.1991  decode.d8.loss_dice: 0.1986
10/01 06:00:16 - mmengine - INFO - Iter(train) [171500/320000]  base_lr: 5.0109e-05 lr: 5.0109e-06  eta: 18:05:50  time: 0.4455  data_time: 0.0100  memory: 5145  grad_norm: 44.2229  loss: 4.6911  decode.loss_cls: 0.0523  decode.loss_mask: 0.1924  decode.loss_dice: 0.1533  decode.d0.loss_cls: 0.8055  decode.d0.loss_mask: 0.1929  decode.d0.loss_dice: 0.1484  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.1901  decode.d1.loss_dice: 0.1549  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.1572  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.1898  decode.d3.loss_dice: 0.1540  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.1917  decode.d4.loss_dice: 0.1483  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.1903  decode.d5.loss_dice: 0.1464  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.1917  decode.d6.loss_dice: 0.1591  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.1932  decode.d7.loss_dice: 0.1514  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.1542
10/01 06:00:38 - mmengine - INFO - Iter(train) [171550/320000]  base_lr: 5.0094e-05 lr: 5.0094e-06  eta: 18:05:29  time: 0.4419  data_time: 0.0099  memory: 5129  grad_norm: 26.5474  loss: 4.1233  decode.loss_cls: 0.0027  decode.loss_mask: 0.1722  decode.loss_dice: 0.1543  decode.d0.loss_cls: 0.7896  decode.d0.loss_mask: 0.1743  decode.d0.loss_dice: 0.1628  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.1706  decode.d1.loss_dice: 0.1642  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1723  decode.d2.loss_dice: 0.1573  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.1700  decode.d3.loss_dice: 0.1556  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.1716  decode.d4.loss_dice: 0.1551  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.1737  decode.d5.loss_dice: 0.1685  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.1720  decode.d6.loss_dice: 0.1612  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.1699  decode.d7.loss_dice: 0.1594  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.1721  decode.d8.loss_dice: 0.1507
10/01 06:01:01 - mmengine - INFO - Iter(train) [171600/320000]  base_lr: 5.0079e-05 lr: 5.0079e-06  eta: 18:05:07  time: 0.4590  data_time: 0.0097  memory: 5145  grad_norm: 42.3214  loss: 4.7136  decode.loss_cls: 0.0173  decode.loss_mask: 0.1938  decode.loss_dice: 0.1625  decode.d0.loss_cls: 0.9392  decode.d0.loss_mask: 0.1932  decode.d0.loss_dice: 0.1581  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.1970  decode.d1.loss_dice: 0.1760  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.1982  decode.d2.loss_dice: 0.1646  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.1938  decode.d3.loss_dice: 0.1803  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.1978  decode.d4.loss_dice: 0.1646  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.1982  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.1938  decode.d6.loss_dice: 0.1760  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.1668  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.1954  decode.d8.loss_dice: 0.1663
10/01 06:01:23 - mmengine - INFO - Iter(train) [171650/320000]  base_lr: 5.0064e-05 lr: 5.0064e-06  eta: 18:04:45  time: 0.4424  data_time: 0.0098  memory: 5129  grad_norm: 33.1035  loss: 4.1337  decode.loss_cls: 0.0034  decode.loss_mask: 0.1939  decode.loss_dice: 0.1369  decode.d0.loss_cls: 0.7839  decode.d0.loss_mask: 0.1961  decode.d0.loss_dice: 0.1316  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.1943  decode.d1.loss_dice: 0.1347  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.1936  decode.d2.loss_dice: 0.1337  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.1957  decode.d3.loss_dice: 0.1368  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.1942  decode.d4.loss_dice: 0.1356  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.1931  decode.d5.loss_dice: 0.1406  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.1942  decode.d6.loss_dice: 0.1362  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.1934  decode.d7.loss_dice: 0.1361  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.1946  decode.d8.loss_dice: 0.1377
10/01 06:01:45 - mmengine - INFO - Iter(train) [171700/320000]  base_lr: 5.0049e-05 lr: 5.0049e-06  eta: 18:04:23  time: 0.4425  data_time: 0.0098  memory: 5145  grad_norm: 25.7947  loss: 3.8875  decode.loss_cls: 0.0026  decode.loss_mask: 0.1632  decode.loss_dice: 0.1472  decode.d0.loss_cls: 0.7754  decode.d0.loss_mask: 0.1629  decode.d0.loss_dice: 0.1482  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.1639  decode.d1.loss_dice: 0.1492  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.1607  decode.d2.loss_dice: 0.1461  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.1633  decode.d3.loss_dice: 0.1489  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.1625  decode.d4.loss_dice: 0.1458  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.1608  decode.d5.loss_dice: 0.1434  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.1601  decode.d6.loss_dice: 0.1440  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.1627  decode.d7.loss_dice: 0.1435  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.1625  decode.d8.loss_dice: 0.1467
