/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
09/29 23:31:51 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: False
    MUSA available: False
    numpy_random_seed: 268722126
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04.2) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

09/29 23:31:51 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=2, enable=False)
crop_size = (
    512,
    1024,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/segmentation_benchmark/food_FINAL_resized/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=40000,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=49,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 49
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=320000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/food_FINAL_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=320000, type='IterBasedTrainLoop', val_interval=40000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/segmentation_benchmark/food_FINAL_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/food_FINAL_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/segmentation_benchmark/mmseg_work_dir/AR_mask2former'

09/29 23:31:55 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
09/29 23:31:55 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
09/29 23:31:56 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
09/29 23:31:56 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
09/29 23:31:56 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
09/29 23:31:57 - mmengine - INFO - load model from: torchvision://resnet50
09/29 23:31:57 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
09/29 23:31:57 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

09/29 23:31:57 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
09/29 23:31:57 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
09/29 23:31:57 - mmengine - INFO - Checkpoints will be saved to /scratch/segmentation_benchmark/mmseg_work_dir/AR_mask2former.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
09/29 23:45:42 - mmengine - INFO - Iter(train) [    50/320000]  base_lr: 9.9986e-05 lr: 9.9986e-06  eta: 61 days, 2:15:02  time: 16.4899  data_time: 0.0456  grad_norm: 235.8513  loss: 92.2301  decode.loss_cls: 3.3121  decode.loss_mask: 2.9160  decode.loss_dice: 3.7869  decode.d0.loss_cls: 8.0094  decode.d0.loss_mask: 2.1575  decode.d0.loss_dice: 2.9171  decode.d1.loss_cls: 3.2208  decode.d1.loss_mask: 2.1411  decode.d1.loss_dice: 2.8836  decode.d2.loss_cls: 3.0580  decode.d2.loss_mask: 2.1472  decode.d2.loss_dice: 2.9361  decode.d3.loss_cls: 3.0141  decode.d3.loss_mask: 2.1630  decode.d3.loss_dice: 2.9917  decode.d4.loss_cls: 3.0911  decode.d4.loss_mask: 2.1769  decode.d4.loss_dice: 3.0923  decode.d5.loss_cls: 3.0268  decode.d5.loss_mask: 2.2827  decode.d5.loss_dice: 3.0236  decode.d6.loss_cls: 3.1328  decode.d6.loss_mask: 2.3225  decode.d6.loss_dice: 3.2006  decode.d7.loss_cls: 3.2215  decode.d7.loss_mask: 2.8129  decode.d7.loss_dice: 3.4363  decode.d8.loss_cls: 3.2895  decode.d8.loss_mask: 2.8939  decode.d8.loss_dice: 3.5721
09/29 23:59:27 - mmengine - INFO - Iter(train) [   100/320000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 61 days, 2:03:49  time: 16.4463  data_time: 0.0454  grad_norm: 348.9354  loss: 72.4144  decode.loss_cls: 2.7509  decode.loss_mask: 2.1531  decode.loss_dice: 2.5765  decode.d0.loss_cls: 7.9596  decode.d0.loss_mask: 1.8089  decode.d0.loss_dice: 2.2416  decode.d1.loss_cls: 2.6939  decode.d1.loss_mask: 1.7989  decode.d1.loss_dice: 2.0645  decode.d2.loss_cls: 2.5855  decode.d2.loss_mask: 1.9590  decode.d2.loss_dice: 2.0759  decode.d3.loss_cls: 2.6412  decode.d3.loss_mask: 1.7626  decode.d3.loss_dice: 2.0912  decode.d4.loss_cls: 2.6747  decode.d4.loss_mask: 1.7566  decode.d4.loss_dice: 2.0530  decode.d5.loss_cls: 2.6395  decode.d5.loss_mask: 1.8573  decode.d5.loss_dice: 2.0420  decode.d6.loss_cls: 2.5723  decode.d6.loss_mask: 1.9045  decode.d6.loss_dice: 2.1403  decode.d7.loss_cls: 2.6622  decode.d7.loss_mask: 1.8585  decode.d7.loss_dice: 2.1030  decode.d8.loss_cls: 2.7022  decode.d8.loss_mask: 2.0047  decode.d8.loss_dice: 2.2801
09/30 00:13:12 - mmengine - INFO - Iter(train) [   150/320000]  base_lr: 9.9958e-05 lr: 9.9958e-06  eta: 61 days, 2:00:14  time: 16.5936  data_time: 0.0470  grad_norm: 335.2164  loss: 59.1011  decode.loss_cls: 2.5311  decode.loss_mask: 1.5247  decode.loss_dice: 1.5980  decode.d0.loss_cls: 7.8320  decode.d0.loss_mask: 1.4257  decode.d0.loss_dice: 1.7976  decode.d1.loss_cls: 2.4177  decode.d1.loss_mask: 1.3728  decode.d1.loss_dice: 1.5744  decode.d2.loss_cls: 2.3418  decode.d2.loss_mask: 1.3477  decode.d2.loss_dice: 1.5076  decode.d3.loss_cls: 2.3649  decode.d3.loss_mask: 1.2484  decode.d3.loss_dice: 1.5053  decode.d4.loss_cls: 2.3929  decode.d4.loss_mask: 1.3842  decode.d4.loss_dice: 1.4926  decode.d5.loss_cls: 2.3616  decode.d5.loss_mask: 1.4928  decode.d5.loss_dice: 1.4995  decode.d6.loss_cls: 2.4318  decode.d6.loss_mask: 1.4421  decode.d6.loss_dice: 1.4970  decode.d7.loss_cls: 2.4036  decode.d7.loss_mask: 1.4914  decode.d7.loss_dice: 1.4533  decode.d8.loss_cls: 2.4569  decode.d8.loss_mask: 1.4083  decode.d8.loss_dice: 1.5031
09/30 00:26:58 - mmengine - INFO - Iter(train) [   200/320000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 61 days, 1:56:32  time: 16.4738  data_time: 0.0466  grad_norm: 275.4408  loss: 49.4623  decode.loss_cls: 2.2490  decode.loss_mask: 1.2725  decode.loss_dice: 1.0711  decode.d0.loss_cls: 7.6393  decode.d0.loss_mask: 1.2117  decode.d0.loss_dice: 1.2566  decode.d1.loss_cls: 2.2492  decode.d1.loss_mask: 1.1150  decode.d1.loss_dice: 1.0927  decode.d2.loss_cls: 2.1108  decode.d2.loss_mask: 1.1224  decode.d2.loss_dice: 0.9423  decode.d3.loss_cls: 2.1192  decode.d3.loss_mask: 1.0321  decode.d3.loss_dice: 0.9321  decode.d4.loss_cls: 2.1240  decode.d4.loss_mask: 1.1607  decode.d4.loss_dice: 0.9906  decode.d5.loss_cls: 2.1692  decode.d5.loss_mask: 1.1173  decode.d5.loss_dice: 1.0319  decode.d6.loss_cls: 2.1929  decode.d6.loss_mask: 1.1956  decode.d6.loss_dice: 1.0671  decode.d7.loss_cls: 2.1767  decode.d7.loss_mask: 1.3012  decode.d7.loss_dice: 1.0261  decode.d8.loss_cls: 2.2202  decode.d8.loss_mask: 1.2317  decode.d8.loss_dice: 1.0412
09/30 00:40:36 - mmengine - INFO - Iter(train) [   250/320000]  base_lr: 9.9930e-05 lr: 9.9930e-06  eta: 60 days, 23:20:28  time: 16.1768  data_time: 0.0318  grad_norm: 311.4670  loss: 47.8077  decode.loss_cls: 2.2192  decode.loss_mask: 1.0166  decode.loss_dice: 1.0845  decode.d0.loss_cls: 7.4315  decode.d0.loss_mask: 1.1180  decode.d0.loss_dice: 1.4419  decode.d1.loss_cls: 2.2107  decode.d1.loss_mask: 0.9675  decode.d1.loss_dice: 1.1210  decode.d2.loss_cls: 2.0345  decode.d2.loss_mask: 1.0257  decode.d2.loss_dice: 1.0236  decode.d3.loss_cls: 2.0772  decode.d3.loss_mask: 1.0129  decode.d3.loss_dice: 1.0639  decode.d4.loss_cls: 2.0923  decode.d4.loss_mask: 1.0692  decode.d4.loss_dice: 1.0740  decode.d5.loss_cls: 2.1300  decode.d5.loss_mask: 1.0038  decode.d5.loss_dice: 1.0756  decode.d6.loss_cls: 2.1871  decode.d6.loss_mask: 0.9301  decode.d6.loss_dice: 1.0318  decode.d7.loss_cls: 2.1550  decode.d7.loss_mask: 0.9620  decode.d7.loss_dice: 1.0111  decode.d8.loss_cls: 2.1842  decode.d8.loss_mask: 1.0040  decode.d8.loss_dice: 1.0487
09/30 00:54:22 - mmengine - INFO - Iter(train) [   300/320000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 60 days, 23:49:13  time: 16.4965  data_time: 0.0356  grad_norm: 284.5637  loss: 45.7265  decode.loss_cls: 2.2122  decode.loss_mask: 0.8585  decode.loss_dice: 0.9795  decode.d0.loss_cls: 7.3754  decode.d0.loss_mask: 0.8403  decode.d0.loss_dice: 1.1974  decode.d1.loss_cls: 2.2630  decode.d1.loss_mask: 0.7266  decode.d1.loss_dice: 0.9762  decode.d2.loss_cls: 2.1628  decode.d2.loss_mask: 0.7778  decode.d2.loss_dice: 0.9099  decode.d3.loss_cls: 2.1549  decode.d3.loss_mask: 0.8665  decode.d3.loss_dice: 0.9187  decode.d4.loss_cls: 2.2295  decode.d4.loss_mask: 0.8707  decode.d4.loss_dice: 0.9833  decode.d5.loss_cls: 2.3100  decode.d5.loss_mask: 0.8200  decode.d5.loss_dice: 0.9784  decode.d6.loss_cls: 2.2695  decode.d6.loss_mask: 0.8605  decode.d6.loss_dice: 0.9992  decode.d7.loss_cls: 2.2873  decode.d7.loss_mask: 0.8357  decode.d7.loss_dice: 1.0138  decode.d8.loss_cls: 2.1650  decode.d8.loss_mask: 0.8639  decode.d8.loss_dice: 1.0199
09/30 01:08:02 - mmengine - INFO - Iter(train) [   350/320000]  base_lr: 9.9902e-05 lr: 9.9902e-06  eta: 60 days, 22:28:51  time: 16.4025  data_time: 0.0341  grad_norm: 277.6808  loss: 40.9899  decode.loss_cls: 1.9204  decode.loss_mask: 0.9237  decode.loss_dice: 0.8107  decode.d0.loss_cls: 7.1547  decode.d0.loss_mask: 0.9890  decode.d0.loss_dice: 1.0817  decode.d1.loss_cls: 1.8232  decode.d1.loss_mask: 0.9772  decode.d1.loss_dice: 0.8408  decode.d2.loss_cls: 1.7079  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 0.8168  decode.d3.loss_cls: 1.6588  decode.d3.loss_mask: 0.9476  decode.d3.loss_dice: 0.7548  decode.d4.loss_cls: 1.6710  decode.d4.loss_mask: 0.9978  decode.d4.loss_dice: 0.7863  decode.d5.loss_cls: 1.7610  decode.d5.loss_mask: 0.9489  decode.d5.loss_dice: 0.7483  decode.d6.loss_cls: 1.7837  decode.d6.loss_mask: 0.9412  decode.d6.loss_dice: 0.7832  decode.d7.loss_cls: 1.8858  decode.d7.loss_mask: 0.8723  decode.d7.loss_dice: 0.7608  decode.d8.loss_cls: 1.9520  decode.d8.loss_mask: 0.9226  decode.d8.loss_dice: 0.7967
09/30 01:21:46 - mmengine - INFO - Iter(train) [   400/320000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 60 days, 22:23:22  time: 16.6001  data_time: 0.0466  grad_norm: 336.6047  loss: 44.6992  decode.loss_cls: 2.2464  decode.loss_mask: 0.9994  decode.loss_dice: 0.8243  decode.d0.loss_cls: 6.9845  decode.d0.loss_mask: 0.9949  decode.d0.loss_dice: 1.1025  decode.d1.loss_cls: 1.9818  decode.d1.loss_mask: 0.9931  decode.d1.loss_dice: 0.8379  decode.d2.loss_cls: 1.9642  decode.d2.loss_mask: 0.8819  decode.d2.loss_dice: 0.8436  decode.d3.loss_cls: 1.9694  decode.d3.loss_mask: 0.9937  decode.d3.loss_dice: 0.8783  decode.d4.loss_cls: 2.0154  decode.d4.loss_mask: 1.0552  decode.d4.loss_dice: 0.9227  decode.d5.loss_cls: 2.0273  decode.d5.loss_mask: 1.1487  decode.d5.loss_dice: 0.9293  decode.d6.loss_cls: 2.0412  decode.d6.loss_mask: 1.1700  decode.d6.loss_dice: 0.9065  decode.d7.loss_cls: 2.1222  decode.d7.loss_mask: 0.9805  decode.d7.loss_dice: 0.7919  decode.d8.loss_cls: 2.2974  decode.d8.loss_mask: 0.9770  decode.d8.loss_dice: 0.8182
09/30 01:31:59 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250929_233151
09/30 01:35:35 - mmengine - INFO - Iter(train) [   450/320000]  base_lr: 9.9874e-05 lr: 9.9874e-06  eta: 60 days, 23:06:26  time: 16.4958  data_time: 0.0493  grad_norm: 354.2402  loss: 36.0654  decode.loss_cls: 1.7907  decode.loss_mask: 0.8957  decode.loss_dice: 0.5337  decode.d0.loss_cls: 6.7544  decode.d0.loss_mask: 0.8911  decode.d0.loss_dice: 0.7614  decode.d1.loss_cls: 1.5616  decode.d1.loss_mask: 0.8972  decode.d1.loss_dice: 0.6601  decode.d2.loss_cls: 1.5372  decode.d2.loss_mask: 0.8079  decode.d2.loss_dice: 0.5625  decode.d3.loss_cls: 1.5981  decode.d3.loss_mask: 0.8422  decode.d3.loss_dice: 0.5197  decode.d4.loss_cls: 1.6164  decode.d4.loss_mask: 0.9309  decode.d4.loss_dice: 0.5295  decode.d5.loss_cls: 1.6008  decode.d5.loss_mask: 0.8869  decode.d5.loss_dice: 0.5371  decode.d6.loss_cls: 1.7057  decode.d6.loss_mask: 0.8935  decode.d6.loss_dice: 0.5222  decode.d7.loss_cls: 1.7078  decode.d7.loss_mask: 0.8147  decode.d7.loss_dice: 0.5316  decode.d8.loss_cls: 1.7952  decode.d8.loss_mask: 0.8550  decode.d8.loss_dice: 0.5250
09/30 01:49:21 - mmengine - INFO - Iter(train) [   500/320000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 60 days, 23:14:15  time: 16.5743  data_time: 0.0531  grad_norm: 302.6742  loss: 34.9354  decode.loss_cls: 1.6874  decode.loss_mask: 0.7419  decode.loss_dice: 0.6231  decode.d0.loss_cls: 6.5722  decode.d0.loss_mask: 0.7132  decode.d0.loss_dice: 0.7975  decode.d1.loss_cls: 1.7231  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 0.6808  decode.d2.loss_cls: 1.6670  decode.d2.loss_mask: 0.6751  decode.d2.loss_dice: 0.5987  decode.d3.loss_cls: 1.6051  decode.d3.loss_mask: 0.7156  decode.d3.loss_dice: 0.5806  decode.d4.loss_cls: 1.6259  decode.d4.loss_mask: 0.7518  decode.d4.loss_dice: 0.6067  decode.d5.loss_cls: 1.6234  decode.d5.loss_mask: 0.7465  decode.d5.loss_dice: 0.5363  decode.d6.loss_cls: 1.6186  decode.d6.loss_mask: 0.7237  decode.d6.loss_dice: 0.5469  decode.d7.loss_cls: 1.6958  decode.d7.loss_mask: 0.7256  decode.d7.loss_dice: 0.5418  decode.d8.loss_cls: 1.6801  decode.d8.loss_mask: 0.7556  decode.d8.loss_dice: 0.6348
09/30 02:03:04 - mmengine - INFO - Iter(train) [   550/320000]  base_lr: 9.9846e-05 lr: 9.9846e-06  eta: 60 days, 22:52:58  time: 16.3085  data_time: 0.0357  grad_norm: 238.4045  loss: 33.2067  decode.loss_cls: 1.5586  decode.loss_mask: 0.7282  decode.loss_dice: 0.5568  decode.d0.loss_cls: 6.3590  decode.d0.loss_mask: 0.7448  decode.d0.loss_dice: 0.7042  decode.d1.loss_cls: 1.6099  decode.d1.loss_mask: 0.7699  decode.d1.loss_dice: 0.5778  decode.d2.loss_cls: 1.4848  decode.d2.loss_mask: 0.7321  decode.d2.loss_dice: 0.5477  decode.d3.loss_cls: 1.5146  decode.d3.loss_mask: 0.7115  decode.d3.loss_dice: 0.5260  decode.d4.loss_cls: 1.5246  decode.d4.loss_mask: 0.7093  decode.d4.loss_dice: 0.5647  decode.d5.loss_cls: 1.5014  decode.d5.loss_mask: 0.7555  decode.d5.loss_dice: 0.5548  decode.d6.loss_cls: 1.5363  decode.d6.loss_mask: 0.7515  decode.d6.loss_dice: 0.5617  decode.d7.loss_cls: 1.5346  decode.d7.loss_mask: 0.7753  decode.d7.loss_dice: 0.5522  decode.d8.loss_cls: 1.5104  decode.d8.loss_mask: 0.7127  decode.d8.loss_dice: 0.5359
09/30 02:16:48 - mmengine - INFO - Iter(train) [   600/320000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 60 days, 22:31:29  time: 16.4930  data_time: 0.0457  grad_norm: 206.2066  loss: 32.5805  decode.loss_cls: 1.8146  decode.loss_mask: 0.5730  decode.loss_dice: 0.4554  decode.d0.loss_cls: 6.2479  decode.d0.loss_mask: 0.6663  decode.d0.loss_dice: 0.6454  decode.d1.loss_cls: 1.6819  decode.d1.loss_mask: 0.6633  decode.d1.loss_dice: 0.5117  decode.d2.loss_cls: 1.6049  decode.d2.loss_mask: 0.5811  decode.d2.loss_dice: 0.4852  decode.d3.loss_cls: 1.7116  decode.d3.loss_mask: 0.5498  decode.d3.loss_dice: 0.4926  decode.d4.loss_cls: 1.6937  decode.d4.loss_mask: 0.5511  decode.d4.loss_dice: 0.5055  decode.d5.loss_cls: 1.7091  decode.d5.loss_mask: 0.5455  decode.d5.loss_dice: 0.5021  decode.d6.loss_cls: 1.7241  decode.d6.loss_mask: 0.5421  decode.d6.loss_dice: 0.4984  decode.d7.loss_cls: 1.7104  decode.d7.loss_mask: 0.5527  decode.d7.loss_dice: 0.5344  decode.d8.loss_cls: 1.8048  decode.d8.loss_mask: 0.5657  decode.d8.loss_dice: 0.4561
09/30 02:30:34 - mmengine - INFO - Iter(train) [   650/320000]  base_lr: 9.9817e-05 lr: 9.9817e-06  eta: 60 days, 22:35:06  time: 16.5759  data_time: 0.0497  grad_norm: 417.5867  loss: 34.9397  decode.loss_cls: 1.6549  decode.loss_mask: 0.9151  decode.loss_dice: 0.5655  decode.d0.loss_cls: 6.0168  decode.d0.loss_mask: 0.8676  decode.d0.loss_dice: 0.6595  decode.d1.loss_cls: 1.5085  decode.d1.loss_mask: 0.8876  decode.d1.loss_dice: 0.5796  decode.d2.loss_cls: 1.3605  decode.d2.loss_mask: 0.9060  decode.d2.loss_dice: 0.5838  decode.d3.loss_cls: 1.4020  decode.d3.loss_mask: 0.8916  decode.d3.loss_dice: 0.6155  decode.d4.loss_cls: 1.4316  decode.d4.loss_mask: 0.9762  decode.d4.loss_dice: 0.6707  decode.d5.loss_cls: 1.5373  decode.d5.loss_mask: 0.8671  decode.d5.loss_dice: 0.6844  decode.d6.loss_cls: 1.6451  decode.d6.loss_mask: 0.9245  decode.d6.loss_dice: 0.5994  decode.d7.loss_cls: 1.6352  decode.d7.loss_mask: 0.8812  decode.d7.loss_dice: 0.5510  decode.d8.loss_cls: 1.6381  decode.d8.loss_mask: 0.9003  decode.d8.loss_dice: 0.5831
09/30 02:44:21 - mmengine - INFO - Iter(train) [   700/320000]  base_lr: 9.9803e-05 lr: 9.9803e-06  eta: 60 days, 22:42:53  time: 16.5126  data_time: 0.0410  grad_norm: 213.5432  loss: 29.2652  decode.loss_cls: 1.6786  decode.loss_mask: 0.4139  decode.loss_dice: 0.3800  decode.d0.loss_cls: 5.9909  decode.d0.loss_mask: 0.4867  decode.d0.loss_dice: 0.5564  decode.d1.loss_cls: 1.6884  decode.d1.loss_mask: 0.3807  decode.d1.loss_dice: 0.4695  decode.d2.loss_cls: 1.6454  decode.d2.loss_mask: 0.3705  decode.d2.loss_dice: 0.4045  decode.d3.loss_cls: 1.6298  decode.d3.loss_mask: 0.3834  decode.d3.loss_dice: 0.3902  decode.d4.loss_cls: 1.6810  decode.d4.loss_mask: 0.3639  decode.d4.loss_dice: 0.4040  decode.d5.loss_cls: 1.7004  decode.d5.loss_mask: 0.3727  decode.d5.loss_dice: 0.3822  decode.d6.loss_cls: 1.7285  decode.d6.loss_mask: 0.3562  decode.d6.loss_dice: 0.3643  decode.d7.loss_cls: 1.7501  decode.d7.loss_mask: 0.3850  decode.d7.loss_dice: 0.3777  decode.d8.loss_cls: 1.7131  decode.d8.loss_mask: 0.4603  decode.d8.loss_dice: 0.3570
09/30 02:58:09 - mmengine - INFO - Iter(train) [   750/320000]  base_lr: 9.9789e-05 lr: 9.9789e-06  eta: 60 days, 22:50:48  time: 16.4984  data_time: 0.0430  grad_norm: 396.0892  loss: 30.8933  decode.loss_cls: 1.5911  decode.loss_mask: 0.6832  decode.loss_dice: 0.5681  decode.d0.loss_cls: 5.6477  decode.d0.loss_mask: 0.6181  decode.d0.loss_dice: 0.5996  decode.d1.loss_cls: 1.5588  decode.d1.loss_mask: 0.6157  decode.d1.loss_dice: 0.5758  decode.d2.loss_cls: 1.4706  decode.d2.loss_mask: 0.6527  decode.d2.loss_dice: 0.5167  decode.d3.loss_cls: 1.4944  decode.d3.loss_mask: 0.6002  decode.d3.loss_dice: 0.4551  decode.d4.loss_cls: 1.5464  decode.d4.loss_mask: 0.5579  decode.d4.loss_dice: 0.4516  decode.d5.loss_cls: 1.5554  decode.d5.loss_mask: 0.5613  decode.d5.loss_dice: 0.4580  decode.d6.loss_cls: 1.5449  decode.d6.loss_mask: 0.5874  decode.d6.loss_dice: 0.4909  decode.d7.loss_cls: 1.5517  decode.d7.loss_mask: 0.6385  decode.d7.loss_dice: 0.5631  decode.d8.loss_cls: 1.5582  decode.d8.loss_mask: 0.6262  decode.d8.loss_dice: 0.5540
09/30 03:11:54 - mmengine - INFO - Iter(train) [   800/320000]  base_lr: 9.9775e-05 lr: 9.9775e-06  eta: 60 days, 22:38:11  time: 16.3578  data_time: 0.0339  grad_norm: 214.7061  loss: 31.8411  decode.loss_cls: 1.5759  decode.loss_mask: 0.7359  decode.loss_dice: 0.4777  decode.d0.loss_cls: 5.4689  decode.d0.loss_mask: 0.6384  decode.d0.loss_dice: 0.5948  decode.d1.loss_cls: 1.6731  decode.d1.loss_mask: 0.6246  decode.d1.loss_dice: 0.4601  decode.d2.loss_cls: 1.6730  decode.d2.loss_mask: 0.6615  decode.d2.loss_dice: 0.4730  decode.d3.loss_cls: 1.6454  decode.d3.loss_mask: 0.6691  decode.d3.loss_dice: 0.4474  decode.d4.loss_cls: 1.6629  decode.d4.loss_mask: 0.7093  decode.d4.loss_dice: 0.4675  decode.d5.loss_cls: 1.6041  decode.d5.loss_mask: 0.7170  decode.d5.loss_dice: 0.4336  decode.d6.loss_cls: 1.6714  decode.d6.loss_mask: 0.7177  decode.d6.loss_dice: 0.4344  decode.d7.loss_cls: 1.6716  decode.d7.loss_mask: 0.7323  decode.d7.loss_dice: 0.4674  decode.d8.loss_cls: 1.5853  decode.d8.loss_mask: 0.7021  decode.d8.loss_dice: 0.4456
09/30 03:25:44 - mmengine - INFO - Iter(train) [   850/320000]  base_lr: 9.9761e-05 lr: 9.9761e-06  eta: 60 days, 22:54:09  time: 16.7463  data_time: 0.0511  grad_norm: 287.6446  loss: 30.8848  decode.loss_cls: 1.5099  decode.loss_mask: 0.7335  decode.loss_dice: 0.4832  decode.d0.loss_cls: 5.1784  decode.d0.loss_mask: 0.6930  decode.d0.loss_dice: 0.6215  decode.d1.loss_cls: 1.6004  decode.d1.loss_mask: 0.6241  decode.d1.loss_dice: 0.4418  decode.d2.loss_cls: 1.5347  decode.d2.loss_mask: 0.6714  decode.d2.loss_dice: 0.4416  decode.d3.loss_cls: 1.5918  decode.d3.loss_mask: 0.6280  decode.d3.loss_dice: 0.4334  decode.d4.loss_cls: 1.6530  decode.d4.loss_mask: 0.6831  decode.d4.loss_dice: 0.4282  decode.d5.loss_cls: 1.6337  decode.d5.loss_mask: 0.6739  decode.d5.loss_dice: 0.4284  decode.d6.loss_cls: 1.6327  decode.d6.loss_mask: 0.6624  decode.d6.loss_dice: 0.4258  decode.d7.loss_cls: 1.6714  decode.d7.loss_mask: 0.6666  decode.d7.loss_dice: 0.4279  decode.d8.loss_cls: 1.4854  decode.d8.loss_mask: 0.7425  decode.d8.loss_dice: 0.4829
09/30 03:39:29 - mmengine - INFO - Iter(train) [   900/320000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 60 days, 22:39:51  time: 16.4736  data_time: 0.0431  grad_norm: 441.7498  loss: 35.7590  decode.loss_cls: 1.9786  decode.loss_mask: 0.7328  decode.loss_dice: 0.7119  decode.d0.loss_cls: 5.1206  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 0.7962  decode.d1.loss_cls: 1.8837  decode.d1.loss_mask: 0.6806  decode.d1.loss_dice: 0.7527  decode.d2.loss_cls: 1.7773  decode.d2.loss_mask: 0.6782  decode.d2.loss_dice: 0.6472  decode.d3.loss_cls: 1.8032  decode.d3.loss_mask: 0.6123  decode.d3.loss_dice: 0.5933  decode.d4.loss_cls: 1.8211  decode.d4.loss_mask: 0.6600  decode.d4.loss_dice: 0.5878  decode.d5.loss_cls: 1.9451  decode.d5.loss_mask: 0.6881  decode.d5.loss_dice: 0.6088  decode.d6.loss_cls: 1.8501  decode.d6.loss_mask: 0.6946  decode.d6.loss_dice: 0.6611  decode.d7.loss_cls: 1.9348  decode.d7.loss_mask: 0.6886  decode.d7.loss_dice: 0.6428  decode.d8.loss_cls: 1.8789  decode.d8.loss_mask: 0.8061  decode.d8.loss_dice: 0.7514
09/30 03:53:15 - mmengine - INFO - Iter(train) [   950/320000]  base_lr: 9.9733e-05 lr: 9.9733e-06  eta: 60 days, 22:36:34  time: 16.4245  data_time: 0.0431  grad_norm: 167.0884  loss: 23.1192  decode.loss_cls: 1.1445  decode.loss_mask: 0.4584  decode.loss_dice: 0.3854  decode.d0.loss_cls: 4.7412  decode.d0.loss_mask: 0.4269  decode.d0.loss_dice: 0.4009  decode.d1.loss_cls: 1.1024  decode.d1.loss_mask: 0.4015  decode.d1.loss_dice: 0.3577  decode.d2.loss_cls: 1.0605  decode.d2.loss_mask: 0.4380  decode.d2.loss_dice: 0.3735  decode.d3.loss_cls: 1.1947  decode.d3.loss_mask: 0.4101  decode.d3.loss_dice: 0.3701  decode.d4.loss_cls: 1.2254  decode.d4.loss_mask: 0.4056  decode.d4.loss_dice: 0.3734  decode.d5.loss_cls: 1.2106  decode.d5.loss_mask: 0.3990  decode.d5.loss_dice: 0.3682  decode.d6.loss_cls: 1.2529  decode.d6.loss_mask: 0.3688  decode.d6.loss_dice: 0.3304  decode.d7.loss_cls: 1.2276  decode.d7.loss_mask: 0.3964  decode.d7.loss_dice: 0.3330  decode.d8.loss_cls: 1.1906  decode.d8.loss_mask: 0.4126  decode.d8.loss_dice: 0.3588
09/30 04:07:01 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250929_233151
09/30 04:07:01 - mmengine - INFO - Iter(train) [  1000/320000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 60 days, 22:23:13  time: 16.4048  data_time: 0.0521  grad_norm: 289.7679  loss: 29.9090  decode.loss_cls: 1.3615  decode.loss_mask: 0.7174  decode.loss_dice: 0.5502  decode.d0.loss_cls: 4.6172  decode.d0.loss_mask: 0.6930  decode.d0.loss_dice: 0.6804  decode.d1.loss_cls: 1.3827  decode.d1.loss_mask: 0.6417  decode.d1.loss_dice: 0.5506  decode.d2.loss_cls: 1.3463  decode.d2.loss_mask: 0.6727  decode.d2.loss_dice: 0.5486  decode.d3.loss_cls: 1.3069  decode.d3.loss_mask: 0.7407  decode.d3.loss_dice: 0.5711  decode.d4.loss_cls: 1.5282  decode.d4.loss_mask: 0.6555  decode.d4.loss_dice: 0.5719  decode.d5.loss_cls: 1.5550  decode.d5.loss_mask: 0.6842  decode.d5.loss_dice: 0.5622  decode.d6.loss_cls: 1.4001  decode.d6.loss_mask: 0.6695  decode.d6.loss_dice: 0.5988  decode.d7.loss_cls: 1.4101  decode.d7.loss_mask: 0.6805  decode.d7.loss_dice: 0.5559  decode.d8.loss_cls: 1.3433  decode.d8.loss_mask: 0.7082  decode.d8.loss_dice: 0.6048
09/30 04:20:44 - mmengine - INFO - Iter(train) [  1050/320000]  base_lr: 9.9705e-05 lr: 9.9705e-06  eta: 60 days, 22:01:49  time: 16.4574  data_time: 0.0412  grad_norm: 118.1981  loss: 24.8242  decode.loss_cls: 1.6703  decode.loss_mask: 0.3125  decode.loss_dice: 0.3207  decode.d0.loss_cls: 4.5548  decode.d0.loss_mask: 0.2905  decode.d0.loss_dice: 0.3686  decode.d1.loss_cls: 1.4950  decode.d1.loss_mask: 0.2955  decode.d1.loss_dice: 0.3466  decode.d2.loss_cls: 1.4912  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.3554  decode.d3.loss_cls: 1.4326  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.3628  decode.d4.loss_cls: 1.4310  decode.d4.loss_mask: 0.3034  decode.d4.loss_dice: 0.3011  decode.d5.loss_cls: 1.5322  decode.d5.loss_mask: 0.2751  decode.d5.loss_dice: 0.2898  decode.d6.loss_cls: 1.5276  decode.d6.loss_mask: 0.2964  decode.d6.loss_dice: 0.3179  decode.d7.loss_cls: 1.6551  decode.d7.loss_mask: 0.3055  decode.d7.loss_dice: 0.3349  decode.d8.loss_cls: 1.7272  decode.d8.loss_mask: 0.3027  decode.d8.loss_dice: 0.3356
09/30 04:34:28 - mmengine - INFO - Iter(train) [  1100/320000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 60 days, 21:42:23  time: 16.4631  data_time: 0.0407  grad_norm: 141.1642  loss: 22.1406  decode.loss_cls: 1.2065  decode.loss_mask: 0.3690  decode.loss_dice: 0.3396  decode.d0.loss_cls: 4.1336  decode.d0.loss_mask: 0.3819  decode.d0.loss_dice: 0.4501  decode.d1.loss_cls: 1.2507  decode.d1.loss_mask: 0.3923  decode.d1.loss_dice: 0.3555  decode.d2.loss_cls: 1.1360  decode.d2.loss_mask: 0.3927  decode.d2.loss_dice: 0.3350  decode.d3.loss_cls: 1.0916  decode.d3.loss_mask: 0.3796  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 1.1421  decode.d4.loss_mask: 0.3890  decode.d4.loss_dice: 0.3494  decode.d5.loss_cls: 1.1783  decode.d5.loss_mask: 0.3943  decode.d5.loss_dice: 0.3440  decode.d6.loss_cls: 1.2099  decode.d6.loss_mask: 0.3936  decode.d6.loss_dice: 0.3645  decode.d7.loss_cls: 1.2043  decode.d7.loss_mask: 0.3804  decode.d7.loss_dice: 0.3395  decode.d8.loss_cls: 1.1760  decode.d8.loss_mask: 0.3878  decode.d8.loss_dice: 0.3443
09/30 04:48:11 - mmengine - INFO - Iter(train) [  1150/320000]  base_lr: 9.9677e-05 lr: 9.9677e-06  eta: 60 days, 21:16:38  time: 16.5292  data_time: 0.0467  grad_norm: 214.1536  loss: 26.0981  decode.loss_cls: 1.5046  decode.loss_mask: 0.4945  decode.loss_dice: 0.4452  decode.d0.loss_cls: 3.9979  decode.d0.loss_mask: 0.5606  decode.d0.loss_dice: 0.5255  decode.d1.loss_cls: 1.3798  decode.d1.loss_mask: 0.4610  decode.d1.loss_dice: 0.4548  decode.d2.loss_cls: 1.2844  decode.d2.loss_mask: 0.4616  decode.d2.loss_dice: 0.4392  decode.d3.loss_cls: 1.3595  decode.d3.loss_mask: 0.4605  decode.d3.loss_dice: 0.4279  decode.d4.loss_cls: 1.4090  decode.d4.loss_mask: 0.4727  decode.d4.loss_dice: 0.4366  decode.d5.loss_cls: 1.4491  decode.d5.loss_mask: 0.4429  decode.d5.loss_dice: 0.4360  decode.d6.loss_cls: 1.5053  decode.d6.loss_mask: 0.4693  decode.d6.loss_dice: 0.4422  decode.d7.loss_cls: 1.4618  decode.d7.loss_mask: 0.4517  decode.d7.loss_dice: 0.4309  decode.d8.loss_cls: 1.5102  decode.d8.loss_mask: 0.4744  decode.d8.loss_dice: 0.4490
09/30 05:01:57 - mmengine - INFO - Iter(train) [  1200/320000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 60 days, 21:08:19  time: 16.4728  data_time: 0.0423  grad_norm: 171.8360  loss: 26.4785  decode.loss_cls: 1.4289  decode.loss_mask: 0.4791  decode.loss_dice: 0.4715  decode.d0.loss_cls: 3.8859  decode.d0.loss_mask: 0.4773  decode.d0.loss_dice: 0.5248  decode.d1.loss_cls: 1.4618  decode.d1.loss_mask: 0.5052  decode.d1.loss_dice: 0.4312  decode.d2.loss_cls: 1.4651  decode.d2.loss_mask: 0.4892  decode.d2.loss_dice: 0.4508  decode.d3.loss_cls: 1.4190  decode.d3.loss_mask: 0.5410  decode.d3.loss_dice: 0.4431  decode.d4.loss_cls: 1.4889  decode.d4.loss_mask: 0.4946  decode.d4.loss_dice: 0.4639  decode.d5.loss_cls: 1.4251  decode.d5.loss_mask: 0.5099  decode.d5.loss_dice: 0.4647  decode.d6.loss_cls: 1.4009  decode.d6.loss_mask: 0.4832  decode.d6.loss_dice: 0.4252  decode.d7.loss_cls: 1.4626  decode.d7.loss_mask: 0.5114  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 1.4737  decode.d8.loss_mask: 0.4917  decode.d8.loss_dice: 0.4522
09/30 05:15:43 - mmengine - INFO - Iter(train) [  1250/320000]  base_lr: 9.9649e-05 lr: 9.9649e-06  eta: 60 days, 21:00:47  time: 16.5262  data_time: 0.0465  grad_norm: 268.2266  loss: 23.1452  decode.loss_cls: 1.1578  decode.loss_mask: 0.5149  decode.loss_dice: 0.3680  decode.d0.loss_cls: 3.6204  decode.d0.loss_mask: 0.5161  decode.d0.loss_dice: 0.4765  decode.d1.loss_cls: 1.1426  decode.d1.loss_mask: 0.4731  decode.d1.loss_dice: 0.3745  decode.d2.loss_cls: 1.1052  decode.d2.loss_mask: 0.4986  decode.d2.loss_dice: 0.3777  decode.d3.loss_cls: 1.1890  decode.d3.loss_mask: 0.4464  decode.d3.loss_dice: 0.3608  decode.d4.loss_cls: 1.1878  decode.d4.loss_mask: 0.5109  decode.d4.loss_dice: 0.4048  decode.d5.loss_cls: 1.2234  decode.d5.loss_mask: 0.5206  decode.d5.loss_dice: 0.3878  decode.d6.loss_cls: 1.1873  decode.d6.loss_mask: 0.4800  decode.d6.loss_dice: 0.3987  decode.d7.loss_cls: 1.1749  decode.d7.loss_mask: 0.5569  decode.d7.loss_dice: 0.4033  decode.d8.loss_cls: 1.2384  decode.d8.loss_mask: 0.4842  decode.d8.loss_dice: 0.3645
09/30 05:29:34 - mmengine - INFO - Iter(train) [  1300/320000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 60 days, 21:09:13  time: 16.7605  data_time: 0.0508  grad_norm: 313.8157  loss: 23.5659  decode.loss_cls: 1.3007  decode.loss_mask: 0.4145  decode.loss_dice: 0.4165  decode.d0.loss_cls: 3.4396  decode.d0.loss_mask: 0.4710  decode.d0.loss_dice: 0.5546  decode.d1.loss_cls: 1.2577  decode.d1.loss_mask: 0.4292  decode.d1.loss_dice: 0.4263  decode.d2.loss_cls: 1.2449  decode.d2.loss_mask: 0.4204  decode.d2.loss_dice: 0.3923  decode.d3.loss_cls: 1.2480  decode.d3.loss_mask: 0.4175  decode.d3.loss_dice: 0.3932  decode.d4.loss_cls: 1.3013  decode.d4.loss_mask: 0.4120  decode.d4.loss_dice: 0.4251  decode.d5.loss_cls: 1.3076  decode.d5.loss_mask: 0.4347  decode.d5.loss_dice: 0.4341  decode.d6.loss_cls: 1.2419  decode.d6.loss_mask: 0.4624  decode.d6.loss_dice: 0.4247  decode.d7.loss_cls: 1.2943  decode.d7.loss_mask: 0.4161  decode.d7.loss_dice: 0.4098  decode.d8.loss_cls: 1.3155  decode.d8.loss_mask: 0.4377  decode.d8.loss_dice: 0.4224
09/30 05:43:19 - mmengine - INFO - Iter(train) [  1350/320000]  base_lr: 9.9621e-05 lr: 9.9621e-06  eta: 60 days, 20:56:11  time: 16.4525  data_time: 0.0502  grad_norm: 143.3520  loss: 22.6890  decode.loss_cls: 1.1316  decode.loss_mask: 0.5621  decode.loss_dice: 0.3857  decode.d0.loss_cls: 3.1784  decode.d0.loss_mask: 0.4776  decode.d0.loss_dice: 0.4282  decode.d1.loss_cls: 1.1631  decode.d1.loss_mask: 0.5138  decode.d1.loss_dice: 0.3960  decode.d2.loss_cls: 1.1082  decode.d2.loss_mask: 0.5017  decode.d2.loss_dice: 0.3831  decode.d3.loss_cls: 1.0860  decode.d3.loss_mask: 0.5106  decode.d3.loss_dice: 0.3857  decode.d4.loss_cls: 1.0726  decode.d4.loss_mask: 0.5165  decode.d4.loss_dice: 0.4153  decode.d5.loss_cls: 1.1172  decode.d5.loss_mask: 0.5278  decode.d5.loss_dice: 0.4190  decode.d6.loss_cls: 1.1350  decode.d6.loss_mask: 0.5453  decode.d6.loss_dice: 0.4234  decode.d7.loss_cls: 1.1364  decode.d7.loss_mask: 0.5769  decode.d7.loss_dice: 0.4287  decode.d8.loss_cls: 1.1808  decode.d8.loss_mask: 0.5821  decode.d8.loss_dice: 0.4002
09/30 05:57:04 - mmengine - INFO - Iter(train) [  1400/320000]  base_lr: 9.9606e-05 lr: 9.9606e-06  eta: 60 days, 20:40:01  time: 16.4300  data_time: 0.0445  grad_norm: 105.6839  loss: 17.9108  decode.loss_cls: 0.8689  decode.loss_mask: 0.2944  decode.loss_dice: 0.3371  decode.d0.loss_cls: 3.0041  decode.d0.loss_mask: 0.3143  decode.d0.loss_dice: 0.4218  decode.d1.loss_cls: 1.0030  decode.d1.loss_mask: 0.3077  decode.d1.loss_dice: 0.3162  decode.d2.loss_cls: 0.8946  decode.d2.loss_mask: 0.2997  decode.d2.loss_dice: 0.3168  decode.d3.loss_cls: 0.8979  decode.d3.loss_mask: 0.2960  decode.d3.loss_dice: 0.3127  decode.d4.loss_cls: 0.9500  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.3055  decode.d5.loss_cls: 0.9678  decode.d5.loss_mask: 0.2923  decode.d5.loss_dice: 0.3212  decode.d6.loss_cls: 1.0056  decode.d6.loss_mask: 0.2955  decode.d6.loss_dice: 0.3334  decode.d7.loss_cls: 1.0057  decode.d7.loss_mask: 0.2908  decode.d7.loss_dice: 0.3383  decode.d8.loss_cls: 0.9271  decode.d8.loss_mask: 0.3448  decode.d8.loss_dice: 0.3608
09/30 06:10:49 - mmengine - INFO - Iter(train) [  1450/320000]  base_lr: 9.9592e-05 lr: 9.9592e-06  eta: 60 days, 20:24:11  time: 16.2953  data_time: 0.0254  grad_norm: 212.0123  loss: 18.1426  decode.loss_cls: 0.8778  decode.loss_mask: 0.3854  decode.loss_dice: 0.3603  decode.d0.loss_cls: 2.6879  decode.d0.loss_mask: 0.3959  decode.d0.loss_dice: 0.3966  decode.d1.loss_cls: 0.8026  decode.d1.loss_mask: 0.3967  decode.d1.loss_dice: 0.3747  decode.d2.loss_cls: 0.8591  decode.d2.loss_mask: 0.3857  decode.d2.loss_dice: 0.3961  decode.d3.loss_cls: 0.8280  decode.d3.loss_mask: 0.3879  decode.d3.loss_dice: 0.3759  decode.d4.loss_cls: 0.9154  decode.d4.loss_mask: 0.3753  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.9485  decode.d5.loss_mask: 0.3756  decode.d5.loss_dice: 0.3467  decode.d6.loss_cls: 0.8623  decode.d6.loss_mask: 0.3897  decode.d6.loss_dice: 0.3665  decode.d7.loss_cls: 0.8996  decode.d7.loss_mask: 0.3829  decode.d7.loss_dice: 0.3543  decode.d8.loss_cls: 0.8969  decode.d8.loss_mask: 0.3847  decode.d8.loss_dice: 0.3744
09/30 06:24:31 - mmengine - INFO - Iter(train) [  1500/320000]  base_lr: 9.9578e-05 lr: 9.9578e-06  eta: 60 days, 19:59:04  time: 16.5117  data_time: 0.0506  grad_norm: 135.4417  loss: 20.6805  decode.loss_cls: 1.1484  decode.loss_mask: 0.4022  decode.loss_dice: 0.3491  decode.d0.loss_cls: 2.8170  decode.d0.loss_mask: 0.3612  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 1.2042  decode.d1.loss_mask: 0.3620  decode.d1.loss_dice: 0.3477  decode.d2.loss_cls: 1.0679  decode.d2.loss_mask: 0.3810  decode.d2.loss_dice: 0.3500  decode.d3.loss_cls: 1.2565  decode.d3.loss_mask: 0.3305  decode.d3.loss_dice: 0.3566  decode.d4.loss_cls: 1.1718  decode.d4.loss_mask: 0.3352  decode.d4.loss_dice: 0.4093  decode.d5.loss_cls: 1.3068  decode.d5.loss_mask: 0.3346  decode.d5.loss_dice: 0.3414  decode.d6.loss_cls: 1.2120  decode.d6.loss_mask: 0.3652  decode.d6.loss_dice: 0.3353  decode.d7.loss_cls: 1.1052  decode.d7.loss_mask: 0.3599  decode.d7.loss_dice: 0.3655  decode.d8.loss_cls: 1.1815  decode.d8.loss_mask: 0.3683  decode.d8.loss_dice: 0.3358
09/30 06:38:19 - mmengine - INFO - Iter(train) [  1550/320000]  base_lr: 9.9564e-05 lr: 9.9564e-06  eta: 60 days, 19:56:15  time: 16.5206  data_time: 0.0415  grad_norm: 222.5956  loss: 21.9042  decode.loss_cls: 1.0784  decode.loss_mask: 0.5440  decode.loss_dice: 0.4008  decode.d0.loss_cls: 2.6033  decode.d0.loss_mask: 0.5432  decode.d0.loss_dice: 0.4845  decode.d1.loss_cls: 1.1385  decode.d1.loss_mask: 0.5386  decode.d1.loss_dice: 0.4089  decode.d2.loss_cls: 1.0233  decode.d2.loss_mask: 0.5394  decode.d2.loss_dice: 0.4034  decode.d3.loss_cls: 1.0217  decode.d3.loss_mask: 0.5701  decode.d3.loss_dice: 0.4111  decode.d4.loss_cls: 1.0679  decode.d4.loss_mask: 0.5590  decode.d4.loss_dice: 0.4092  decode.d5.loss_cls: 1.1083  decode.d5.loss_mask: 0.5312  decode.d5.loss_dice: 0.4038  decode.d6.loss_cls: 1.0615  decode.d6.loss_mask: 0.5541  decode.d6.loss_dice: 0.3892  decode.d7.loss_cls: 1.0953  decode.d7.loss_mask: 0.5749  decode.d7.loss_dice: 0.4056  decode.d8.loss_cls: 1.1116  decode.d8.loss_mask: 0.5383  decode.d8.loss_dice: 0.3853
09/30 06:52:05 - mmengine - INFO - Iter(train) [  1600/320000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 60 days, 19:46:22  time: 16.3897  data_time: 0.0360  grad_norm: 132.1448  loss: 18.9798  decode.loss_cls: 0.9063  decode.loss_mask: 0.4378  decode.loss_dice: 0.3585  decode.d0.loss_cls: 2.3426  decode.d0.loss_mask: 0.4671  decode.d0.loss_dice: 0.4731  decode.d1.loss_cls: 1.0429  decode.d1.loss_mask: 0.4284  decode.d1.loss_dice: 0.3739  decode.d2.loss_cls: 0.8735  decode.d2.loss_mask: 0.4466  decode.d2.loss_dice: 0.4017  decode.d3.loss_cls: 0.8559  decode.d3.loss_mask: 0.4943  decode.d3.loss_dice: 0.3986  decode.d4.loss_cls: 0.8349  decode.d4.loss_mask: 0.4865  decode.d4.loss_dice: 0.3921  decode.d5.loss_cls: 0.8852  decode.d5.loss_mask: 0.4354  decode.d5.loss_dice: 0.4391  decode.d6.loss_cls: 0.8395  decode.d6.loss_mask: 0.4521  decode.d6.loss_dice: 0.4420  decode.d7.loss_cls: 0.8712  decode.d7.loss_mask: 0.4373  decode.d7.loss_dice: 0.4110  decode.d8.loss_cls: 0.9355  decode.d8.loss_mask: 0.4348  decode.d8.loss_dice: 0.3821
09/30 07:05:43 - mmengine - INFO - Iter(train) [  1650/320000]  base_lr: 9.9536e-05 lr: 9.9536e-06  eta: 60 days, 19:09:01  time: 16.4524  data_time: 0.0400  grad_norm: 116.0191  loss: 18.4884  decode.loss_cls: 0.9261  decode.loss_mask: 0.4110  decode.loss_dice: 0.4191  decode.d0.loss_cls: 2.2892  decode.d0.loss_mask: 0.4449  decode.d0.loss_dice: 0.3994  decode.d1.loss_cls: 0.9312  decode.d1.loss_mask: 0.4364  decode.d1.loss_dice: 0.3493  decode.d2.loss_cls: 0.8898  decode.d2.loss_mask: 0.4321  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 0.8855  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.3517  decode.d4.loss_cls: 0.9214  decode.d4.loss_mask: 0.4287  decode.d4.loss_dice: 0.3649  decode.d5.loss_cls: 0.9039  decode.d5.loss_mask: 0.4295  decode.d5.loss_dice: 0.3665  decode.d6.loss_cls: 0.8769  decode.d6.loss_mask: 0.4311  decode.d6.loss_dice: 0.3676  decode.d7.loss_cls: 0.9084  decode.d7.loss_mask: 0.4206  decode.d7.loss_dice: 0.3637  decode.d8.loss_cls: 0.9492  decode.d8.loss_mask: 0.4155  decode.d8.loss_dice: 0.4120
09/30 07:19:31 - mmengine - INFO - Iter(train) [  1700/320000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 60 days, 19:03:53  time: 16.5103  data_time: 0.0458  grad_norm: 153.3745  loss: 15.3465  decode.loss_cls: 0.8823  decode.loss_mask: 0.2820  decode.loss_dice: 0.2740  decode.d0.loss_cls: 2.2685  decode.d0.loss_mask: 0.2689  decode.d0.loss_dice: 0.2968  decode.d1.loss_cls: 0.7974  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.2792  decode.d2.loss_cls: 0.8158  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.2643  decode.d3.loss_cls: 0.7636  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.2552  decode.d4.loss_cls: 0.7489  decode.d4.loss_mask: 0.2786  decode.d4.loss_dice: 0.2561  decode.d5.loss_cls: 0.8551  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.2498  decode.d6.loss_cls: 0.9384  decode.d6.loss_mask: 0.2688  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.9156  decode.d7.loss_mask: 0.2693  decode.d7.loss_dice: 0.2544  decode.d8.loss_cls: 0.9515  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2731
09/30 07:33:15 - mmengine - INFO - Iter(train) [  1750/320000]  base_lr: 9.9508e-05 lr: 9.9508e-06  eta: 60 days, 18:48:09  time: 16.3899  data_time: 0.0559  grad_norm: 171.3061  loss: 18.4622  decode.loss_cls: 0.8960  decode.loss_mask: 0.4444  decode.loss_dice: 0.3056  decode.d0.loss_cls: 2.1121  decode.d0.loss_mask: 0.4375  decode.d0.loss_dice: 0.4172  decode.d1.loss_cls: 1.1213  decode.d1.loss_mask: 0.3917  decode.d1.loss_dice: 0.3716  decode.d2.loss_cls: 1.0022  decode.d2.loss_mask: 0.3800  decode.d2.loss_dice: 0.3746  decode.d3.loss_cls: 0.9760  decode.d3.loss_mask: 0.3653  decode.d3.loss_dice: 0.3401  decode.d4.loss_cls: 1.0250  decode.d4.loss_mask: 0.3479  decode.d4.loss_dice: 0.3321  decode.d5.loss_cls: 1.0011  decode.d5.loss_mask: 0.3529  decode.d5.loss_dice: 0.3717  decode.d6.loss_cls: 1.0459  decode.d6.loss_mask: 0.3593  decode.d6.loss_dice: 0.3078  decode.d7.loss_cls: 1.0174  decode.d7.loss_mask: 0.3785  decode.d7.loss_dice: 0.2998  decode.d8.loss_cls: 0.9564  decode.d8.loss_mask: 0.4451  decode.d8.loss_dice: 0.2857
09/30 07:47:00 - mmengine - INFO - Iter(train) [  1800/320000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 60 days, 18:34:20  time: 16.4106  data_time: 0.0458  grad_norm: 216.9715  loss: 19.8246  decode.loss_cls: 1.0956  decode.loss_mask: 0.3889  decode.loss_dice: 0.4626  decode.d0.loss_cls: 2.0780  decode.d0.loss_mask: 0.3990  decode.d0.loss_dice: 0.4753  decode.d1.loss_cls: 0.9413  decode.d1.loss_mask: 0.3967  decode.d1.loss_dice: 0.4608  decode.d2.loss_cls: 1.0701  decode.d2.loss_mask: 0.3788  decode.d2.loss_dice: 0.4508  decode.d3.loss_cls: 0.9715  decode.d3.loss_mask: 0.3874  decode.d3.loss_dice: 0.4381  decode.d4.loss_cls: 0.9737  decode.d4.loss_mask: 0.3838  decode.d4.loss_dice: 0.4480  decode.d5.loss_cls: 0.9883  decode.d5.loss_mask: 0.3994  decode.d5.loss_dice: 0.4385  decode.d6.loss_cls: 1.0073  decode.d6.loss_mask: 0.4076  decode.d6.loss_dice: 0.4725  decode.d7.loss_cls: 1.1098  decode.d7.loss_mask: 0.3693  decode.d7.loss_dice: 0.4596  decode.d8.loss_cls: 1.1005  decode.d8.loss_mask: 0.3881  decode.d8.loss_dice: 0.4831
09/30 08:00:47 - mmengine - INFO - Iter(train) [  1850/320000]  base_lr: 9.9480e-05 lr: 9.9480e-06  eta: 60 days, 18:24:21  time: 16.4549  data_time: 0.0444  grad_norm: 295.0436  loss: 20.4575  decode.loss_cls: 0.9197  decode.loss_mask: 0.6463  decode.loss_dice: 0.4765  decode.d0.loss_cls: 2.0043  decode.d0.loss_mask: 0.6450  decode.d0.loss_dice: 0.4942  decode.d1.loss_cls: 0.8730  decode.d1.loss_mask: 0.5771  decode.d1.loss_dice: 0.5083  decode.d2.loss_cls: 0.8292  decode.d2.loss_mask: 0.5687  decode.d2.loss_dice: 0.4981  decode.d3.loss_cls: 0.7914  decode.d3.loss_mask: 0.5783  decode.d3.loss_dice: 0.4798  decode.d4.loss_cls: 0.7730  decode.d4.loss_mask: 0.5553  decode.d4.loss_dice: 0.5120  decode.d5.loss_cls: 0.7793  decode.d5.loss_mask: 0.5550  decode.d5.loss_dice: 0.4772  decode.d6.loss_cls: 0.8380  decode.d6.loss_mask: 0.5533  decode.d6.loss_dice: 0.4956  decode.d7.loss_cls: 0.9081  decode.d7.loss_mask: 0.5129  decode.d7.loss_dice: 0.4690  decode.d8.loss_cls: 0.9863  decode.d8.loss_mask: 0.6470  decode.d8.loss_dice: 0.5056
09/30 08:14:22 - mmengine - INFO - Iter(train) [  1900/320000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 60 days, 17:41:52  time: 16.2734  data_time: 0.0297  grad_norm: 187.8165  loss: 19.9186  decode.loss_cls: 1.0862  decode.loss_mask: 0.4640  decode.loss_dice: 0.4260  decode.d0.loss_cls: 1.9585  decode.d0.loss_mask: 0.4401  decode.d0.loss_dice: 0.4202  decode.d1.loss_cls: 1.0590  decode.d1.loss_mask: 0.4058  decode.d1.loss_dice: 0.3938  decode.d2.loss_cls: 0.9493  decode.d2.loss_mask: 0.4362  decode.d2.loss_dice: 0.3909  decode.d3.loss_cls: 0.9786  decode.d3.loss_mask: 0.4193  decode.d3.loss_dice: 0.4028  decode.d4.loss_cls: 0.9792  decode.d4.loss_mask: 0.4133  decode.d4.loss_dice: 0.4090  decode.d5.loss_cls: 1.0190  decode.d5.loss_mask: 0.4337  decode.d5.loss_dice: 0.4271  decode.d6.loss_cls: 1.0717  decode.d6.loss_mask: 0.4410  decode.d6.loss_dice: 0.4304  decode.d7.loss_cls: 1.0880  decode.d7.loss_mask: 0.4633  decode.d7.loss_dice: 0.4901  decode.d8.loss_cls: 1.1228  decode.d8.loss_mask: 0.4575  decode.d8.loss_dice: 0.4414
09/30 08:28:03 - mmengine - INFO - Iter(train) [  1950/320000]  base_lr: 9.9452e-05 lr: 9.9452e-06  eta: 60 days, 17:18:37  time: 16.3957  data_time: 0.0309  grad_norm: 145.3722  loss: 14.3954  decode.loss_cls: 0.5724  decode.loss_mask: 0.3815  decode.loss_dice: 0.3598  decode.d0.loss_cls: 1.6352  decode.d0.loss_mask: 0.4449  decode.d0.loss_dice: 0.3818  decode.d1.loss_cls: 0.6896  decode.d1.loss_mask: 0.3728  decode.d1.loss_dice: 0.3444  decode.d2.loss_cls: 0.6206  decode.d2.loss_mask: 0.3712  decode.d2.loss_dice: 0.3185  decode.d3.loss_cls: 0.6269  decode.d3.loss_mask: 0.3655  decode.d3.loss_dice: 0.3273  decode.d4.loss_cls: 0.5754  decode.d4.loss_mask: 0.3693  decode.d4.loss_dice: 0.3368  decode.d5.loss_cls: 0.6662  decode.d5.loss_mask: 0.3669  decode.d5.loss_dice: 0.3155  decode.d6.loss_cls: 0.6045  decode.d6.loss_mask: 0.3740  decode.d6.loss_dice: 0.3046  decode.d7.loss_cls: 0.6626  decode.d7.loss_mask: 0.3658  decode.d7.loss_dice: 0.3124  decode.d8.loss_cls: 0.6119  decode.d8.loss_mask: 0.3622  decode.d8.loss_dice: 0.3547
09/30 08:41:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250929_233151
09/30 08:41:35 - mmengine - INFO - Iter(train) [  2000/320000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 60 days, 16:32:09  time: 16.3516  data_time: 0.0353  grad_norm: 129.1456  loss: 17.0982  decode.loss_cls: 0.8140  decode.loss_mask: 0.3858  decode.loss_dice: 0.3752  decode.d0.loss_cls: 1.9995  decode.d0.loss_mask: 0.3897  decode.d0.loss_dice: 0.3823  decode.d1.loss_cls: 0.9450  decode.d1.loss_mask: 0.3865  decode.d1.loss_dice: 0.3582  decode.d2.loss_cls: 0.8017  decode.d2.loss_mask: 0.3921  decode.d2.loss_dice: 0.3589  decode.d3.loss_cls: 0.8027  decode.d3.loss_mask: 0.3817  decode.d3.loss_dice: 0.3492  decode.d4.loss_cls: 0.7745  decode.d4.loss_mask: 0.3959  decode.d4.loss_dice: 0.3724  decode.d5.loss_cls: 0.7895  decode.d5.loss_mask: 0.4087  decode.d5.loss_dice: 0.3749  decode.d6.loss_cls: 0.8481  decode.d6.loss_mask: 0.3936  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.8869  decode.d7.loss_mask: 0.3958  decode.d7.loss_dice: 0.3712  decode.d8.loss_cls: 0.8426  decode.d8.loss_mask: 0.3988  decode.d8.loss_dice: 0.3636
