==========================================
SLURM_JOB_ID = 2504929
SLURM_NODELIST = gnode079
SLURM_JOB_GPUS = 2
==========================================
09/28 14:27:02 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 268722126
    GPU 0: NVIDIA GeForce RTX 2080 Ti
    CUDA_HOME: /opt/cuda-12.1/
    NVCC: Cuda compilation tools, release 12.1, V12.1.66
    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
    PyTorch: 2.1.2
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 268722126
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

09/28 14:27:02 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=2, enable=False)
crop_size = (
    512,
    1024,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = '/scratch/segmentation_benchmark/final_data_resized/'
dataset_type = 'YourDataset_BIG'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=40000,
        save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmseg'
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
img_suffix = '.jpg'
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        deep_stem=False,
        depth=50,
        frozen_stages=-1,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        norm_cfg=dict(requires_grad=False, type='SyncBN'),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        style='pytorch',
        type='ResNet'),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            256,
            512,
            1024,
            2048,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=50,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 50
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(decay_mult=1.0, lr_mult=0.1),
            level_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_embed=dict(decay_mult=0.0, lr_mult=1.0),
            query_feat=dict(decay_mult=0.0, lr_mult=1.0)),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=320000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
randomness = dict(seed=268722126)
resume = False
seg_map_suffix = '.png'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/final_data_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    classwise=True, iou_metrics=[
        'mIoU',
    ], type='IoUNanAbsent')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=320000, type='IterBasedTrainLoop', val_interval=40000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(img_path='train/images', seg_map_path='train/masks'),
        data_root='/scratch/segmentation_benchmark/final_data_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='test/images', seg_map_path='test/masks'),
        data_root='/scratch/segmentation_benchmark/final_data_resized/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='YourDataset_BIG'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '/scratch/segmentation_benchmark/mmseg_work_dir/mask2former'

09/28 14:27:08 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
09/28 14:27:08 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1e-05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.1
09/28 14:27:08 - mmengine - INFO - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - WARNING - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
09/28 14:27:08 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
09/28 14:27:09 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
09/28 14:27:09 - mmengine - INFO - load model from: torchvision://resnet50
09/28 14:27:09 - mmengine - INFO - Loads checkpoint by torchvision backend from path: torchvision://resnet50
09/28 14:27:10 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

09/28 14:27:11 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
09/28 14:27:11 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
09/28 14:27:11 - mmengine - INFO - Checkpoints will be saved to /scratch/segmentation_benchmark/mmseg_work_dir/mask2former.
/home2/yasharora120/miniconda3/envs/mmseg/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400441250/work/aten/src/ATen/native/TensorShape.cpp:3526.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
09/28 14:27:43 - mmengine - INFO - Iter(train) [    50/320000]  base_lr: 9.9986e-05 lr: 9.9986e-06  eta: 2 days, 8:57:26  time: 0.4271  data_time: 0.0086  memory: 10587  grad_norm: 177.5521  loss: 90.9342  decode.loss_cls: 3.2232  decode.loss_mask: 2.9717  decode.loss_dice: 3.7885  decode.d0.loss_cls: 8.1100  decode.d0.loss_mask: 2.2376  decode.d0.loss_dice: 2.9238  decode.d1.loss_cls: 3.0931  decode.d1.loss_mask: 2.1099  decode.d1.loss_dice: 2.7866  decode.d2.loss_cls: 2.9102  decode.d2.loss_mask: 2.0732  decode.d2.loss_dice: 2.7221  decode.d3.loss_cls: 2.8603  decode.d3.loss_mask: 2.1005  decode.d3.loss_dice: 2.8162  decode.d4.loss_cls: 2.9092  decode.d4.loss_mask: 2.1455  decode.d4.loss_dice: 2.9204  decode.d5.loss_cls: 2.9609  decode.d5.loss_mask: 2.3079  decode.d5.loss_dice: 2.9710  decode.d6.loss_cls: 3.0719  decode.d6.loss_mask: 2.6173  decode.d6.loss_dice: 3.1718  decode.d7.loss_cls: 3.1372  decode.d7.loss_mask: 2.9296  decode.d7.loss_dice: 3.3352  decode.d8.loss_cls: 3.2003  decode.d8.loss_mask: 2.9323  decode.d8.loss_dice: 3.5965
09/28 14:28:04 - mmengine - INFO - Iter(train) [   100/320000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 1 day, 23:29:58  time: 0.4283  data_time: 0.0084  memory: 5167  grad_norm: 285.4363  loss: 76.9943  decode.loss_cls: 2.9100  decode.loss_mask: 2.2419  decode.loss_dice: 2.5521  decode.d0.loss_cls: 7.8491  decode.d0.loss_mask: 1.8771  decode.d0.loss_dice: 2.2742  decode.d1.loss_cls: 2.6289  decode.d1.loss_mask: 1.9766  decode.d1.loss_dice: 2.2498  decode.d2.loss_cls: 2.6145  decode.d2.loss_mask: 2.0079  decode.d2.loss_dice: 2.2630  decode.d3.loss_cls: 2.6642  decode.d3.loss_mask: 2.0473  decode.d3.loss_dice: 2.3090  decode.d4.loss_cls: 2.6527  decode.d4.loss_mask: 2.1411  decode.d4.loss_dice: 2.3440  decode.d5.loss_cls: 2.7404  decode.d5.loss_mask: 2.1906  decode.d5.loss_dice: 2.3391  decode.d6.loss_cls: 2.8257  decode.d6.loss_mask: 2.1274  decode.d6.loss_dice: 2.3553  decode.d7.loss_cls: 2.7668  decode.d7.loss_mask: 2.2169  decode.d7.loss_dice: 2.3924  decode.d8.loss_cls: 2.7812  decode.d8.loss_mask: 2.2327  decode.d8.loss_dice: 2.4223
09/28 14:28:26 - mmengine - INFO - Iter(train) [   150/320000]  base_lr: 9.9958e-05 lr: 9.9958e-06  eta: 1 day, 20:22:51  time: 0.4286  data_time: 0.0083  memory: 5167  grad_norm: 237.2254  loss: 52.2227  decode.loss_cls: 2.4055  decode.loss_mask: 1.1775  decode.loss_dice: 1.4964  decode.d0.loss_cls: 7.7196  decode.d0.loss_mask: 1.1192  decode.d0.loss_dice: 1.5912  decode.d1.loss_cls: 2.1771  decode.d1.loss_mask: 1.0645  decode.d1.loss_dice: 1.3648  decode.d2.loss_cls: 2.1013  decode.d2.loss_mask: 1.0181  decode.d2.loss_dice: 1.3414  decode.d3.loss_cls: 2.0253  decode.d3.loss_mask: 0.9932  decode.d3.loss_dice: 1.3389  decode.d4.loss_cls: 2.0647  decode.d4.loss_mask: 1.0245  decode.d4.loss_dice: 1.3847  decode.d5.loss_cls: 2.2002  decode.d5.loss_mask: 1.0104  decode.d5.loss_dice: 1.3366  decode.d6.loss_cls: 2.2645  decode.d6.loss_mask: 1.0624  decode.d6.loss_dice: 1.3307  decode.d7.loss_cls: 2.2389  decode.d7.loss_mask: 1.1276  decode.d7.loss_dice: 1.3955  decode.d8.loss_cls: 2.3035  decode.d8.loss_mask: 1.1632  decode.d8.loss_dice: 1.3812
09/28 14:28:47 - mmengine - INFO - Iter(train) [   200/320000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 1 day, 18:49:27  time: 0.4295  data_time: 0.0082  memory: 5167  grad_norm: 268.3747  loss: 48.2187  decode.loss_cls: 2.2993  decode.loss_mask: 1.0555  decode.loss_dice: 1.0714  decode.d0.loss_cls: 7.5958  decode.d0.loss_mask: 1.0854  decode.d0.loss_dice: 1.3238  decode.d1.loss_cls: 2.2377  decode.d1.loss_mask: 1.0480  decode.d1.loss_dice: 1.0835  decode.d2.loss_cls: 2.1503  decode.d2.loss_mask: 0.9731  decode.d2.loss_dice: 1.0379  decode.d3.loss_cls: 2.1316  decode.d3.loss_mask: 1.0463  decode.d3.loss_dice: 0.9932  decode.d4.loss_cls: 2.1921  decode.d4.loss_mask: 0.9833  decode.d4.loss_dice: 0.9726  decode.d5.loss_cls: 2.1945  decode.d5.loss_mask: 0.9994  decode.d5.loss_dice: 0.9810  decode.d6.loss_cls: 2.2167  decode.d6.loss_mask: 0.9701  decode.d6.loss_dice: 0.9893  decode.d7.loss_cls: 2.2307  decode.d7.loss_mask: 0.9685  decode.d7.loss_dice: 1.0318  decode.d8.loss_cls: 2.2422  decode.d8.loss_mask: 1.0344  decode.d8.loss_dice: 1.0794
09/28 14:29:09 - mmengine - INFO - Iter(train) [   250/320000]  base_lr: 9.9930e-05 lr: 9.9930e-06  eta: 1 day, 17:54:06  time: 0.4303  data_time: 0.0085  memory: 5167  grad_norm: 261.7530  loss: 44.1653  decode.loss_cls: 2.0282  decode.loss_mask: 1.0154  decode.loss_dice: 0.9695  decode.d0.loss_cls: 7.3890  decode.d0.loss_mask: 0.9123  decode.d0.loss_dice: 1.1302  decode.d1.loss_cls: 2.0916  decode.d1.loss_mask: 0.9291  decode.d1.loss_dice: 0.9363  decode.d2.loss_cls: 2.0325  decode.d2.loss_mask: 0.8982  decode.d2.loss_dice: 0.9027  decode.d3.loss_cls: 2.0298  decode.d3.loss_mask: 0.9292  decode.d3.loss_dice: 0.8776  decode.d4.loss_cls: 1.9899  decode.d4.loss_mask: 0.9487  decode.d4.loss_dice: 0.8678  decode.d5.loss_cls: 1.9861  decode.d5.loss_mask: 0.9159  decode.d5.loss_dice: 0.8439  decode.d6.loss_cls: 2.0077  decode.d6.loss_mask: 1.0362  decode.d6.loss_dice: 0.8995  decode.d7.loss_cls: 1.9959  decode.d7.loss_mask: 0.9688  decode.d7.loss_dice: 0.8631  decode.d8.loss_cls: 1.9776  decode.d8.loss_mask: 0.9410  decode.d8.loss_dice: 0.8515
09/28 14:29:31 - mmengine - INFO - Iter(train) [   300/320000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 1 day, 17:25:21  time: 0.4381  data_time: 0.0089  memory: 5186  grad_norm: 357.7036  loss: 48.4240  decode.loss_cls: 2.1659  decode.loss_mask: 1.1553  decode.loss_dice: 1.0540  decode.d0.loss_cls: 7.2655  decode.d0.loss_mask: 1.0125  decode.d0.loss_dice: 1.3057  decode.d1.loss_cls: 2.1683  decode.d1.loss_mask: 1.0564  decode.d1.loss_dice: 1.1105  decode.d2.loss_cls: 2.1234  decode.d2.loss_mask: 0.9507  decode.d2.loss_dice: 0.9971  decode.d3.loss_cls: 2.1764  decode.d3.loss_mask: 0.9334  decode.d3.loss_dice: 0.9406  decode.d4.loss_cls: 2.1957  decode.d4.loss_mask: 1.0540  decode.d4.loss_dice: 0.9951  decode.d5.loss_cls: 2.2363  decode.d5.loss_mask: 1.1027  decode.d5.loss_dice: 1.0032  decode.d6.loss_cls: 2.2289  decode.d6.loss_mask: 1.2054  decode.d6.loss_dice: 1.0637  decode.d7.loss_cls: 2.1137  decode.d7.loss_mask: 1.1561  decode.d7.loss_dice: 1.0146  decode.d8.loss_cls: 2.1647  decode.d8.loss_mask: 1.3324  decode.d8.loss_dice: 1.1420
09/28 14:29:53 - mmengine - INFO - Iter(train) [   350/320000]  base_lr: 9.9902e-05 lr: 9.9902e-06  eta: 1 day, 17:05:29  time: 0.4689  data_time: 0.0090  memory: 5167  grad_norm: 330.3361  loss: 37.1563  decode.loss_cls: 2.0096  decode.loss_mask: 0.6820  decode.loss_dice: 0.6430  decode.d0.loss_cls: 7.0238  decode.d0.loss_mask: 0.6835  decode.d0.loss_dice: 0.7668  decode.d1.loss_cls: 1.8804  decode.d1.loss_mask: 0.6490  decode.d1.loss_dice: 0.5966  decode.d2.loss_cls: 1.7818  decode.d2.loss_mask: 0.6538  decode.d2.loss_dice: 0.5856  decode.d3.loss_cls: 1.8623  decode.d3.loss_mask: 0.7017  decode.d3.loss_dice: 0.6123  decode.d4.loss_cls: 1.8969  decode.d4.loss_mask: 0.6725  decode.d4.loss_dice: 0.6276  decode.d5.loss_cls: 2.0177  decode.d5.loss_mask: 0.6153  decode.d5.loss_dice: 0.5591  decode.d6.loss_cls: 2.0128  decode.d6.loss_mask: 0.6051  decode.d6.loss_dice: 0.5498  decode.d7.loss_cls: 1.9654  decode.d7.loss_mask: 0.6170  decode.d7.loss_dice: 0.6129  decode.d8.loss_cls: 1.9962  decode.d8.loss_mask: 0.6501  decode.d8.loss_dice: 0.6257
09/28 14:30:15 - mmengine - INFO - Iter(train) [   400/320000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 1 day, 17:01:15  time: 0.4288  data_time: 0.0085  memory: 5186  grad_norm: 298.0719  loss: 37.3444  decode.loss_cls: 1.8494  decode.loss_mask: 0.8404  decode.loss_dice: 0.5849  decode.d0.loss_cls: 6.8807  decode.d0.loss_mask: 0.7634  decode.d0.loss_dice: 0.7253  decode.d1.loss_cls: 1.8994  decode.d1.loss_mask: 0.7271  decode.d1.loss_dice: 0.5762  decode.d2.loss_cls: 1.8407  decode.d2.loss_mask: 0.7890  decode.d2.loss_dice: 0.5468  decode.d3.loss_cls: 1.8371  decode.d3.loss_mask: 0.8198  decode.d3.loss_dice: 0.5506  decode.d4.loss_cls: 1.8547  decode.d4.loss_mask: 0.8156  decode.d4.loss_dice: 0.5746  decode.d5.loss_cls: 1.8935  decode.d5.loss_mask: 0.7324  decode.d5.loss_dice: 0.5132  decode.d6.loss_cls: 1.8615  decode.d6.loss_mask: 0.8348  decode.d6.loss_dice: 0.5433  decode.d7.loss_cls: 1.8953  decode.d7.loss_mask: 0.7690  decode.d7.loss_dice: 0.5730  decode.d8.loss_cls: 1.8544  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 0.5506
09/28 14:30:19 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 14:30:37 - mmengine - INFO - Iter(train) [   450/320000]  base_lr: 9.9874e-05 lr: 9.9874e-06  eta: 1 day, 16:41:05  time: 0.4291  data_time: 0.0083  memory: 5150  grad_norm: 348.6494  loss: 43.6069  decode.loss_cls: 1.9703  decode.loss_mask: 1.1103  decode.loss_dice: 0.8775  decode.d0.loss_cls: 6.7632  decode.d0.loss_mask: 1.0301  decode.d0.loss_dice: 0.9520  decode.d1.loss_cls: 2.0847  decode.d1.loss_mask: 1.0372  decode.d1.loss_dice: 0.8536  decode.d2.loss_cls: 1.9865  decode.d2.loss_mask: 1.0044  decode.d2.loss_dice: 0.8405  decode.d3.loss_cls: 1.9998  decode.d3.loss_mask: 0.9732  decode.d3.loss_dice: 0.8158  decode.d4.loss_cls: 2.0158  decode.d4.loss_mask: 1.0406  decode.d4.loss_dice: 0.8166  decode.d5.loss_cls: 1.9505  decode.d5.loss_mask: 1.0674  decode.d5.loss_dice: 0.8312  decode.d6.loss_cls: 1.9739  decode.d6.loss_mask: 1.0202  decode.d6.loss_dice: 0.8397  decode.d7.loss_cls: 1.9797  decode.d7.loss_mask: 1.0506  decode.d7.loss_dice: 0.8296  decode.d8.loss_cls: 1.9772  decode.d8.loss_mask: 1.0563  decode.d8.loss_dice: 0.8587
09/28 14:30:58 - mmengine - INFO - Iter(train) [   500/320000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 1 day, 16:27:10  time: 0.4309  data_time: 0.0085  memory: 5167  grad_norm: 325.5304  loss: 40.3479  decode.loss_cls: 2.0446  decode.loss_mask: 0.8586  decode.loss_dice: 0.8491  decode.d0.loss_cls: 6.5485  decode.d0.loss_mask: 0.9780  decode.d0.loss_dice: 1.0253  decode.d1.loss_cls: 1.9165  decode.d1.loss_mask: 0.8950  decode.d1.loss_dice: 0.7820  decode.d2.loss_cls: 1.8860  decode.d2.loss_mask: 0.8547  decode.d2.loss_dice: 0.7195  decode.d3.loss_cls: 1.8770  decode.d3.loss_mask: 0.8396  decode.d3.loss_dice: 0.6894  decode.d4.loss_cls: 1.8927  decode.d4.loss_mask: 0.8972  decode.d4.loss_dice: 0.7091  decode.d5.loss_cls: 1.8936  decode.d5.loss_mask: 0.8864  decode.d5.loss_dice: 0.7129  decode.d6.loss_cls: 1.9249  decode.d6.loss_mask: 0.9000  decode.d6.loss_dice: 0.7541  decode.d7.loss_cls: 1.9456  decode.d7.loss_mask: 0.8343  decode.d7.loss_dice: 0.7165  decode.d8.loss_cls: 1.9722  decode.d8.loss_mask: 0.8099  decode.d8.loss_dice: 0.7346
09/28 14:31:20 - mmengine - INFO - Iter(train) [   550/320000]  base_lr: 9.9846e-05 lr: 9.9846e-06  eta: 1 day, 16:15:08  time: 0.4318  data_time: 0.0087  memory: 5167  grad_norm: 235.5362  loss: 32.4415  decode.loss_cls: 1.7382  decode.loss_mask: 0.5579  decode.loss_dice: 0.5811  decode.d0.loss_cls: 6.4746  decode.d0.loss_mask: 0.5219  decode.d0.loss_dice: 0.7002  decode.d1.loss_cls: 1.7986  decode.d1.loss_mask: 0.4922  decode.d1.loss_dice: 0.5561  decode.d2.loss_cls: 1.7257  decode.d2.loss_mask: 0.4705  decode.d2.loss_dice: 0.5226  decode.d3.loss_cls: 1.7265  decode.d3.loss_mask: 0.4620  decode.d3.loss_dice: 0.5306  decode.d4.loss_cls: 1.7336  decode.d4.loss_mask: 0.4506  decode.d4.loss_dice: 0.4991  decode.d5.loss_cls: 1.7286  decode.d5.loss_mask: 0.4932  decode.d5.loss_dice: 0.5309  decode.d6.loss_cls: 1.6575  decode.d6.loss_mask: 0.5493  decode.d6.loss_dice: 0.5255  decode.d7.loss_cls: 1.7093  decode.d7.loss_mask: 0.4622  decode.d7.loss_dice: 0.5423  decode.d8.loss_cls: 1.7013  decode.d8.loss_mask: 0.4725  decode.d8.loss_dice: 0.5266
09/28 14:31:42 - mmengine - INFO - Iter(train) [   600/320000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 1 day, 16:05:00  time: 0.4321  data_time: 0.0088  memory: 5167  grad_norm: 265.2519  loss: 34.8471  decode.loss_cls: 1.8217  decode.loss_mask: 0.6982  decode.loss_dice: 0.5632  decode.d0.loss_cls: 6.2746  decode.d0.loss_mask: 0.7327  decode.d0.loss_dice: 0.6178  decode.d1.loss_cls: 1.7759  decode.d1.loss_mask: 0.7288  decode.d1.loss_dice: 0.5286  decode.d2.loss_cls: 1.7494  decode.d2.loss_mask: 0.7169  decode.d2.loss_dice: 0.5030  decode.d3.loss_cls: 1.8602  decode.d3.loss_mask: 0.6792  decode.d3.loss_dice: 0.5086  decode.d4.loss_cls: 1.7593  decode.d4.loss_mask: 0.6990  decode.d4.loss_dice: 0.5079  decode.d5.loss_cls: 1.7800  decode.d5.loss_mask: 0.6902  decode.d5.loss_dice: 0.4956  decode.d6.loss_cls: 1.8470  decode.d6.loss_mask: 0.6615  decode.d6.loss_dice: 0.5219  decode.d7.loss_cls: 1.8349  decode.d7.loss_mask: 0.6626  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 1.8295  decode.d8.loss_mask: 0.7285  decode.d8.loss_dice: 0.5451
09/28 14:32:03 - mmengine - INFO - Iter(train) [   650/320000]  base_lr: 9.9817e-05 lr: 9.9817e-06  eta: 1 day, 15:56:36  time: 0.4328  data_time: 0.0088  memory: 5186  grad_norm: 238.5529  loss: 31.3167  decode.loss_cls: 1.4542  decode.loss_mask: 0.6541  decode.loss_dice: 0.4728  decode.d0.loss_cls: 6.1627  decode.d0.loss_mask: 0.6382  decode.d0.loss_dice: 0.6311  decode.d1.loss_cls: 1.6061  decode.d1.loss_mask: 0.6369  decode.d1.loss_dice: 0.5436  decode.d2.loss_cls: 1.5641  decode.d2.loss_mask: 0.6079  decode.d2.loss_dice: 0.4566  decode.d3.loss_cls: 1.5564  decode.d3.loss_mask: 0.6107  decode.d3.loss_dice: 0.4861  decode.d4.loss_cls: 1.5623  decode.d4.loss_mask: 0.6067  decode.d4.loss_dice: 0.5070  decode.d5.loss_cls: 1.5032  decode.d5.loss_mask: 0.6659  decode.d5.loss_dice: 0.5091  decode.d6.loss_cls: 1.5574  decode.d6.loss_mask: 0.6029  decode.d6.loss_dice: 0.4916  decode.d7.loss_cls: 1.5585  decode.d7.loss_mask: 0.6593  decode.d7.loss_dice: 0.4862  decode.d8.loss_cls: 1.4746  decode.d8.loss_mask: 0.5849  decode.d8.loss_dice: 0.4656
09/28 14:32:25 - mmengine - INFO - Iter(train) [   700/320000]  base_lr: 9.9803e-05 lr: 9.9803e-06  eta: 1 day, 15:49:29  time: 0.4330  data_time: 0.0085  memory: 5186  grad_norm: 328.4273  loss: 33.0203  decode.loss_cls: 1.5895  decode.loss_mask: 0.6347  decode.loss_dice: 0.6551  decode.d0.loss_cls: 5.9215  decode.d0.loss_mask: 0.6626  decode.d0.loss_dice: 0.7349  decode.d1.loss_cls: 1.7521  decode.d1.loss_mask: 0.5989  decode.d1.loss_dice: 0.5805  decode.d2.loss_cls: 1.7082  decode.d2.loss_mask: 0.6143  decode.d2.loss_dice: 0.5608  decode.d3.loss_cls: 1.6914  decode.d3.loss_mask: 0.5825  decode.d3.loss_dice: 0.5050  decode.d4.loss_cls: 1.6980  decode.d4.loss_mask: 0.5997  decode.d4.loss_dice: 0.5626  decode.d5.loss_cls: 1.7246  decode.d5.loss_mask: 0.5834  decode.d5.loss_dice: 0.5003  decode.d6.loss_cls: 1.6503  decode.d6.loss_mask: 0.6359  decode.d6.loss_dice: 0.5086  decode.d7.loss_cls: 1.6504  decode.d7.loss_mask: 0.6536  decode.d7.loss_dice: 0.5681  decode.d8.loss_cls: 1.6281  decode.d8.loss_mask: 0.6513  decode.d8.loss_dice: 0.6135
09/28 14:32:47 - mmengine - INFO - Iter(train) [   750/320000]  base_lr: 9.9789e-05 lr: 9.9789e-06  eta: 1 day, 15:43:14  time: 0.4321  data_time: 0.0088  memory: 5186  grad_norm: 195.3326  loss: 29.9722  decode.loss_cls: 1.4290  decode.loss_mask: 0.6724  decode.loss_dice: 0.6183  decode.d0.loss_cls: 5.7070  decode.d0.loss_mask: 0.5318  decode.d0.loss_dice: 0.6071  decode.d1.loss_cls: 1.4859  decode.d1.loss_mask: 0.5677  decode.d1.loss_dice: 0.5867  decode.d2.loss_cls: 1.3740  decode.d2.loss_mask: 0.6204  decode.d2.loss_dice: 0.5410  decode.d3.loss_cls: 1.3906  decode.d3.loss_mask: 0.5869  decode.d3.loss_dice: 0.5205  decode.d4.loss_cls: 1.4025  decode.d4.loss_mask: 0.5632  decode.d4.loss_dice: 0.5571  decode.d5.loss_cls: 1.4661  decode.d5.loss_mask: 0.5396  decode.d5.loss_dice: 0.5481  decode.d6.loss_cls: 1.4608  decode.d6.loss_mask: 0.5546  decode.d6.loss_dice: 0.5243  decode.d7.loss_cls: 1.4184  decode.d7.loss_mask: 0.5618  decode.d7.loss_dice: 0.5797  decode.d8.loss_cls: 1.3835  decode.d8.loss_mask: 0.5943  decode.d8.loss_dice: 0.5790
09/28 14:33:08 - mmengine - INFO - Iter(train) [   800/320000]  base_lr: 9.9775e-05 lr: 9.9775e-06  eta: 1 day, 15:37:42  time: 0.4321  data_time: 0.0088  memory: 5150  grad_norm: 298.5887  loss: 30.8489  decode.loss_cls: 1.2728  decode.loss_mask: 0.7520  decode.loss_dice: 0.6726  decode.d0.loss_cls: 5.4211  decode.d0.loss_mask: 0.7065  decode.d0.loss_dice: 0.7317  decode.d1.loss_cls: 1.3231  decode.d1.loss_mask: 0.6216  decode.d1.loss_dice: 0.6726  decode.d2.loss_cls: 1.2879  decode.d2.loss_mask: 0.7106  decode.d2.loss_dice: 0.7001  decode.d3.loss_cls: 1.2234  decode.d3.loss_mask: 0.7250  decode.d3.loss_dice: 0.6838  decode.d4.loss_cls: 1.2849  decode.d4.loss_mask: 0.7128  decode.d4.loss_dice: 0.6547  decode.d5.loss_cls: 1.2973  decode.d5.loss_mask: 0.7196  decode.d5.loss_dice: 0.6534  decode.d6.loss_cls: 1.2761  decode.d6.loss_mask: 0.7476  decode.d6.loss_dice: 0.6778  decode.d7.loss_cls: 1.2029  decode.d7.loss_mask: 0.7467  decode.d7.loss_dice: 0.6970  decode.d8.loss_cls: 1.2983  decode.d8.loss_mask: 0.7032  decode.d8.loss_dice: 0.6719
09/28 14:33:30 - mmengine - INFO - Iter(train) [   850/320000]  base_lr: 9.9761e-05 lr: 9.9761e-06  eta: 1 day, 15:32:35  time: 0.4316  data_time: 0.0087  memory: 5166  grad_norm: 168.0263  loss: 24.4218  decode.loss_cls: 1.1912  decode.loss_mask: 0.4050  decode.loss_dice: 0.4565  decode.d0.loss_cls: 5.3621  decode.d0.loss_mask: 0.3944  decode.d0.loss_dice: 0.4134  decode.d1.loss_cls: 1.2419  decode.d1.loss_mask: 0.3455  decode.d1.loss_dice: 0.4113  decode.d2.loss_cls: 1.2006  decode.d2.loss_mask: 0.3932  decode.d2.loss_dice: 0.4192  decode.d3.loss_cls: 1.2283  decode.d3.loss_mask: 0.3967  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 1.2765  decode.d4.loss_mask: 0.4159  decode.d4.loss_dice: 0.3912  decode.d5.loss_cls: 1.2480  decode.d5.loss_mask: 0.4011  decode.d5.loss_dice: 0.3842  decode.d6.loss_cls: 1.2262  decode.d6.loss_mask: 0.3888  decode.d6.loss_dice: 0.3877  decode.d7.loss_cls: 1.2229  decode.d7.loss_mask: 0.4028  decode.d7.loss_dice: 0.4040  decode.d8.loss_cls: 1.1796  decode.d8.loss_mask: 0.3983  decode.d8.loss_dice: 0.4416
09/28 14:33:51 - mmengine - INFO - Iter(train) [   900/320000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 1 day, 15:28:09  time: 0.4317  data_time: 0.0085  memory: 5167  grad_norm: 200.3658  loss: 23.6190  decode.loss_cls: 1.2042  decode.loss_mask: 0.4160  decode.loss_dice: 0.3101  decode.d0.loss_cls: 5.1124  decode.d0.loss_mask: 0.4170  decode.d0.loss_dice: 0.3656  decode.d1.loss_cls: 1.2517  decode.d1.loss_mask: 0.4153  decode.d1.loss_dice: 0.3489  decode.d2.loss_cls: 1.2273  decode.d2.loss_mask: 0.4205  decode.d2.loss_dice: 0.3099  decode.d3.loss_cls: 1.2272  decode.d3.loss_mask: 0.4162  decode.d3.loss_dice: 0.3103  decode.d4.loss_cls: 1.2528  decode.d4.loss_mask: 0.4007  decode.d4.loss_dice: 0.3106  decode.d5.loss_cls: 1.2601  decode.d5.loss_mask: 0.4308  decode.d5.loss_dice: 0.3199  decode.d6.loss_cls: 1.1850  decode.d6.loss_mask: 0.4339  decode.d6.loss_dice: 0.3323  decode.d7.loss_cls: 1.2268  decode.d7.loss_mask: 0.4207  decode.d7.loss_dice: 0.3363  decode.d8.loss_cls: 1.2033  decode.d8.loss_mask: 0.4309  decode.d8.loss_dice: 0.3223
09/28 14:34:13 - mmengine - INFO - Iter(train) [   950/320000]  base_lr: 9.9733e-05 lr: 9.9733e-06  eta: 1 day, 15:24:13  time: 0.4327  data_time: 0.0087  memory: 5167  grad_norm: 140.5037  loss: 26.3782  decode.loss_cls: 1.3247  decode.loss_mask: 0.4804  decode.loss_dice: 0.5587  decode.d0.loss_cls: 4.8332  decode.d0.loss_mask: 0.4377  decode.d0.loss_dice: 0.5552  decode.d1.loss_cls: 1.3457  decode.d1.loss_mask: 0.4386  decode.d1.loss_dice: 0.5103  decode.d2.loss_cls: 1.2888  decode.d2.loss_mask: 0.4018  decode.d2.loss_dice: 0.4908  decode.d3.loss_cls: 1.3134  decode.d3.loss_mask: 0.4130  decode.d3.loss_dice: 0.4913  decode.d4.loss_cls: 1.3455  decode.d4.loss_mask: 0.4555  decode.d4.loss_dice: 0.5197  decode.d5.loss_cls: 1.3227  decode.d5.loss_mask: 0.4620  decode.d5.loss_dice: 0.4924  decode.d6.loss_cls: 1.2533  decode.d6.loss_mask: 0.5466  decode.d6.loss_dice: 0.4986  decode.d7.loss_cls: 1.2509  decode.d7.loss_mask: 0.5209  decode.d7.loss_dice: 0.5290  decode.d8.loss_cls: 1.3048  decode.d8.loss_mask: 0.4646  decode.d8.loss_dice: 0.5279
09/28 14:34:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 14:34:35 - mmengine - INFO - Iter(train) [  1000/320000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 1 day, 15:20:37  time: 0.4330  data_time: 0.0088  memory: 5167  grad_norm: 381.9807  loss: 28.6846  decode.loss_cls: 1.5268  decode.loss_mask: 0.5270  decode.loss_dice: 0.4692  decode.d0.loss_cls: 4.8348  decode.d0.loss_mask: 0.5626  decode.d0.loss_dice: 0.6167  decode.d1.loss_cls: 1.5141  decode.d1.loss_mask: 0.4869  decode.d1.loss_dice: 0.5268  decode.d2.loss_cls: 1.5588  decode.d2.loss_mask: 0.5183  decode.d2.loss_dice: 0.5103  decode.d3.loss_cls: 1.5244  decode.d3.loss_mask: 0.5017  decode.d3.loss_dice: 0.4766  decode.d4.loss_cls: 1.4579  decode.d4.loss_mask: 0.4944  decode.d4.loss_dice: 0.4876  decode.d5.loss_cls: 1.5185  decode.d5.loss_mask: 0.5250  decode.d5.loss_dice: 0.4930  decode.d6.loss_cls: 1.5283  decode.d6.loss_mask: 0.5698  decode.d6.loss_dice: 0.4749  decode.d7.loss_cls: 1.5261  decode.d7.loss_mask: 0.4962  decode.d7.loss_dice: 0.4463  decode.d8.loss_cls: 1.4824  decode.d8.loss_mask: 0.5499  decode.d8.loss_dice: 0.4793
09/28 14:34:56 - mmengine - INFO - Iter(train) [  1050/320000]  base_lr: 9.9705e-05 lr: 9.9705e-06  eta: 1 day, 15:17:22  time: 0.4322  data_time: 0.0088  memory: 5166  grad_norm: 393.1517  loss: 25.1826  decode.loss_cls: 1.0812  decode.loss_mask: 0.7762  decode.loss_dice: 0.4390  decode.d0.loss_cls: 4.6080  decode.d0.loss_mask: 0.6201  decode.d0.loss_dice: 0.4608  decode.d1.loss_cls: 1.2560  decode.d1.loss_mask: 0.5937  decode.d1.loss_dice: 0.3814  decode.d2.loss_cls: 1.1684  decode.d2.loss_mask: 0.5007  decode.d2.loss_dice: 0.3676  decode.d3.loss_cls: 1.1347  decode.d3.loss_mask: 0.5207  decode.d3.loss_dice: 0.4020  decode.d4.loss_cls: 1.1963  decode.d4.loss_mask: 0.5592  decode.d4.loss_dice: 0.4078  decode.d5.loss_cls: 1.1967  decode.d5.loss_mask: 0.5077  decode.d5.loss_dice: 0.3769  decode.d6.loss_cls: 1.1354  decode.d6.loss_mask: 0.6186  decode.d6.loss_dice: 0.4082  decode.d7.loss_cls: 1.0902  decode.d7.loss_mask: 0.7024  decode.d7.loss_dice: 0.4382  decode.d8.loss_cls: 1.0842  decode.d8.loss_mask: 0.7247  decode.d8.loss_dice: 0.4258
09/28 14:35:18 - mmengine - INFO - Iter(train) [  1100/320000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 1 day, 15:14:27  time: 0.4328  data_time: 0.0087  memory: 5166  grad_norm: 337.2761  loss: 22.0916  decode.loss_cls: 1.0387  decode.loss_mask: 0.4556  decode.loss_dice: 0.3438  decode.d0.loss_cls: 4.4469  decode.d0.loss_mask: 0.4610  decode.d0.loss_dice: 0.4070  decode.d1.loss_cls: 1.0788  decode.d1.loss_mask: 0.4626  decode.d1.loss_dice: 0.3452  decode.d2.loss_cls: 1.0707  decode.d2.loss_mask: 0.4659  decode.d2.loss_dice: 0.3402  decode.d3.loss_cls: 1.0577  decode.d3.loss_mask: 0.4616  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 1.0665  decode.d4.loss_mask: 0.4509  decode.d4.loss_dice: 0.3325  decode.d5.loss_cls: 1.0594  decode.d5.loss_mask: 0.4560  decode.d5.loss_dice: 0.3501  decode.d6.loss_cls: 1.0924  decode.d6.loss_mask: 0.4593  decode.d6.loss_dice: 0.3469  decode.d7.loss_cls: 1.0906  decode.d7.loss_mask: 0.4383  decode.d7.loss_dice: 0.3518  decode.d8.loss_cls: 1.0277  decode.d8.loss_mask: 0.4532  decode.d8.loss_dice: 0.3455
09/28 14:35:40 - mmengine - INFO - Iter(train) [  1150/320000]  base_lr: 9.9677e-05 lr: 9.9677e-06  eta: 1 day, 15:11:41  time: 0.4324  data_time: 0.0088  memory: 5186  grad_norm: 267.0592  loss: 27.7254  decode.loss_cls: 1.3138  decode.loss_mask: 0.6234  decode.loss_dice: 0.4789  decode.d0.loss_cls: 4.2697  decode.d0.loss_mask: 0.6195  decode.d0.loss_dice: 0.5427  decode.d1.loss_cls: 1.3746  decode.d1.loss_mask: 0.6468  decode.d1.loss_dice: 0.5071  decode.d2.loss_cls: 1.4460  decode.d2.loss_mask: 0.6281  decode.d2.loss_dice: 0.4735  decode.d3.loss_cls: 1.4117  decode.d3.loss_mask: 0.6187  decode.d3.loss_dice: 0.4875  decode.d4.loss_cls: 1.3494  decode.d4.loss_mask: 0.6292  decode.d4.loss_dice: 0.4947  decode.d5.loss_cls: 1.3621  decode.d5.loss_mask: 0.6119  decode.d5.loss_dice: 0.4725  decode.d6.loss_cls: 1.3666  decode.d6.loss_mask: 0.6139  decode.d6.loss_dice: 0.4611  decode.d7.loss_cls: 1.3626  decode.d7.loss_mask: 0.6255  decode.d7.loss_dice: 0.4786  decode.d8.loss_cls: 1.3559  decode.d8.loss_mask: 0.6103  decode.d8.loss_dice: 0.4891
09/28 14:36:01 - mmengine - INFO - Iter(train) [  1200/320000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 1 day, 15:09:08  time: 0.4331  data_time: 0.0088  memory: 5167  grad_norm: 169.5943  loss: 26.7893  decode.loss_cls: 1.5708  decode.loss_mask: 0.4242  decode.loss_dice: 0.4263  decode.d0.loss_cls: 4.0640  decode.d0.loss_mask: 0.4565  decode.d0.loss_dice: 0.5027  decode.d1.loss_cls: 1.5166  decode.d1.loss_mask: 0.4854  decode.d1.loss_dice: 0.4460  decode.d2.loss_cls: 1.4659  decode.d2.loss_mask: 0.4771  decode.d2.loss_dice: 0.4317  decode.d3.loss_cls: 1.5802  decode.d3.loss_mask: 0.4137  decode.d3.loss_dice: 0.4306  decode.d4.loss_cls: 1.5605  decode.d4.loss_mask: 0.4427  decode.d4.loss_dice: 0.4243  decode.d5.loss_cls: 1.4874  decode.d5.loss_mask: 0.4753  decode.d5.loss_dice: 0.4166  decode.d6.loss_cls: 1.5198  decode.d6.loss_mask: 0.4590  decode.d6.loss_dice: 0.4423  decode.d7.loss_cls: 1.5304  decode.d7.loss_mask: 0.4570  decode.d7.loss_dice: 0.4910  decode.d8.loss_cls: 1.5670  decode.d8.loss_mask: 0.4213  decode.d8.loss_dice: 0.4031
09/28 14:36:23 - mmengine - INFO - Iter(train) [  1250/320000]  base_lr: 9.9649e-05 lr: 9.9649e-06  eta: 1 day, 15:07:31  time: 0.4321  data_time: 0.0086  memory: 5167  grad_norm: 189.8777  loss: 23.1595  decode.loss_cls: 1.2007  decode.loss_mask: 0.4676  decode.loss_dice: 0.4359  decode.d0.loss_cls: 3.7351  decode.d0.loss_mask: 0.4930  decode.d0.loss_dice: 0.4347  decode.d1.loss_cls: 1.0937  decode.d1.loss_mask: 0.5082  decode.d1.loss_dice: 0.4039  decode.d2.loss_cls: 1.0978  decode.d2.loss_mask: 0.4944  decode.d2.loss_dice: 0.4292  decode.d3.loss_cls: 1.1136  decode.d3.loss_mask: 0.4911  decode.d3.loss_dice: 0.3805  decode.d4.loss_cls: 1.1824  decode.d4.loss_mask: 0.5099  decode.d4.loss_dice: 0.4008  decode.d5.loss_cls: 1.1559  decode.d5.loss_mask: 0.4966  decode.d5.loss_dice: 0.3919  decode.d6.loss_cls: 1.1348  decode.d6.loss_mask: 0.5133  decode.d6.loss_dice: 0.4163  decode.d7.loss_cls: 1.1942  decode.d7.loss_mask: 0.4717  decode.d7.loss_dice: 0.4270  decode.d8.loss_cls: 1.1456  decode.d8.loss_mask: 0.5021  decode.d8.loss_dice: 0.4377
09/28 14:36:45 - mmengine - INFO - Iter(train) [  1300/320000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 1 day, 15:05:15  time: 0.4328  data_time: 0.0088  memory: 5186  grad_norm: 204.2771  loss: 23.2486  decode.loss_cls: 1.0276  decode.loss_mask: 0.5793  decode.loss_dice: 0.4245  decode.d0.loss_cls: 3.5718  decode.d0.loss_mask: 0.5826  decode.d0.loss_dice: 0.4449  decode.d1.loss_cls: 1.1241  decode.d1.loss_mask: 0.5377  decode.d1.loss_dice: 0.4103  decode.d2.loss_cls: 1.0978  decode.d2.loss_mask: 0.5578  decode.d2.loss_dice: 0.4333  decode.d3.loss_cls: 1.1484  decode.d3.loss_mask: 0.5392  decode.d3.loss_dice: 0.4043  decode.d4.loss_cls: 1.1564  decode.d4.loss_mask: 0.5628  decode.d4.loss_dice: 0.4046  decode.d5.loss_cls: 1.1459  decode.d5.loss_mask: 0.5431  decode.d5.loss_dice: 0.4328  decode.d6.loss_cls: 1.1361  decode.d6.loss_mask: 0.5199  decode.d6.loss_dice: 0.4346  decode.d7.loss_cls: 1.0502  decode.d7.loss_mask: 0.5316  decode.d7.loss_dice: 0.4364  decode.d8.loss_cls: 1.0300  decode.d8.loss_mask: 0.5422  decode.d8.loss_dice: 0.4384
09/28 14:37:06 - mmengine - INFO - Iter(train) [  1350/320000]  base_lr: 9.9621e-05 lr: 9.9621e-06  eta: 1 day, 15:03:08  time: 0.4327  data_time: 0.0087  memory: 5186  grad_norm: 220.4741  loss: 22.6588  decode.loss_cls: 1.0594  decode.loss_mask: 0.4664  decode.loss_dice: 0.4742  decode.d0.loss_cls: 3.3343  decode.d0.loss_mask: 0.5500  decode.d0.loss_dice: 0.6113  decode.d1.loss_cls: 1.0443  decode.d1.loss_mask: 0.5285  decode.d1.loss_dice: 0.5153  decode.d2.loss_cls: 0.9855  decode.d2.loss_mask: 0.5112  decode.d2.loss_dice: 0.4900  decode.d3.loss_cls: 1.0535  decode.d3.loss_mask: 0.4902  decode.d3.loss_dice: 0.4686  decode.d4.loss_cls: 1.0500  decode.d4.loss_mask: 0.4933  decode.d4.loss_dice: 0.5041  decode.d5.loss_cls: 1.0510  decode.d5.loss_mask: 0.4826  decode.d5.loss_dice: 0.4560  decode.d6.loss_cls: 1.0872  decode.d6.loss_mask: 0.4955  decode.d6.loss_dice: 0.4793  decode.d7.loss_cls: 1.0422  decode.d7.loss_mask: 0.4825  decode.d7.loss_dice: 0.4540  decode.d8.loss_cls: 1.0549  decode.d8.loss_mask: 0.4709  decode.d8.loss_dice: 0.4727
09/28 14:37:28 - mmengine - INFO - Iter(train) [  1400/320000]  base_lr: 9.9606e-05 lr: 9.9606e-06  eta: 1 day, 15:01:12  time: 0.4322  data_time: 0.0087  memory: 5167  grad_norm: 221.4878  loss: 18.8212  decode.loss_cls: 0.8768  decode.loss_mask: 0.4519  decode.loss_dice: 0.3246  decode.d0.loss_cls: 3.1032  decode.d0.loss_mask: 0.4052  decode.d0.loss_dice: 0.3744  decode.d1.loss_cls: 0.8282  decode.d1.loss_mask: 0.4468  decode.d1.loss_dice: 0.3533  decode.d2.loss_cls: 0.8415  decode.d2.loss_mask: 0.4572  decode.d2.loss_dice: 0.3499  decode.d3.loss_cls: 0.8641  decode.d3.loss_mask: 0.4377  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.8835  decode.d4.loss_mask: 0.4515  decode.d4.loss_dice: 0.3223  decode.d5.loss_cls: 0.8753  decode.d5.loss_mask: 0.4664  decode.d5.loss_dice: 0.3477  decode.d6.loss_cls: 0.9105  decode.d6.loss_mask: 0.4408  decode.d6.loss_dice: 0.3178  decode.d7.loss_cls: 0.8689  decode.d7.loss_mask: 0.4655  decode.d7.loss_dice: 0.3315  decode.d8.loss_cls: 0.9185  decode.d8.loss_mask: 0.4511  decode.d8.loss_dice: 0.3252
09/28 14:37:49 - mmengine - INFO - Iter(train) [  1450/320000]  base_lr: 9.9592e-05 lr: 9.9592e-06  eta: 1 day, 14:59:18  time: 0.4326  data_time: 0.0087  memory: 5166  grad_norm: 167.6332  loss: 20.1986  decode.loss_cls: 1.0022  decode.loss_mask: 0.5057  decode.loss_dice: 0.3319  decode.d0.loss_cls: 2.9419  decode.d0.loss_mask: 0.4770  decode.d0.loss_dice: 0.4034  decode.d1.loss_cls: 1.0704  decode.d1.loss_mask: 0.4335  decode.d1.loss_dice: 0.3542  decode.d2.loss_cls: 0.9148  decode.d2.loss_mask: 0.4273  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 0.9272  decode.d3.loss_mask: 0.4680  decode.d3.loss_dice: 0.3575  decode.d4.loss_cls: 0.9517  decode.d4.loss_mask: 0.4581  decode.d4.loss_dice: 0.3564  decode.d5.loss_cls: 1.0192  decode.d5.loss_mask: 0.5030  decode.d5.loss_dice: 0.3505  decode.d6.loss_cls: 1.0166  decode.d6.loss_mask: 0.4340  decode.d6.loss_dice: 0.3399  decode.d7.loss_cls: 1.0156  decode.d7.loss_mask: 0.5020  decode.d7.loss_dice: 0.3600  decode.d8.loss_cls: 1.0067  decode.d8.loss_mask: 0.5539  decode.d8.loss_dice: 0.3658
09/28 14:38:11 - mmengine - INFO - Iter(train) [  1500/320000]  base_lr: 9.9578e-05 lr: 9.9578e-06  eta: 1 day, 14:57:30  time: 0.4329  data_time: 0.0087  memory: 5186  grad_norm: 424.8219  loss: 22.5417  decode.loss_cls: 1.1995  decode.loss_mask: 0.5142  decode.loss_dice: 0.3686  decode.d0.loss_cls: 3.0216  decode.d0.loss_mask: 0.5044  decode.d0.loss_dice: 0.4213  decode.d1.loss_cls: 1.2165  decode.d1.loss_mask: 0.4859  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 1.1720  decode.d2.loss_mask: 0.5242  decode.d2.loss_dice: 0.3705  decode.d3.loss_cls: 1.2192  decode.d3.loss_mask: 0.5163  decode.d3.loss_dice: 0.3931  decode.d4.loss_cls: 1.2016  decode.d4.loss_mask: 0.5068  decode.d4.loss_dice: 0.3794  decode.d5.loss_cls: 1.1971  decode.d5.loss_mask: 0.4745  decode.d5.loss_dice: 0.3746  decode.d6.loss_cls: 1.2051  decode.d6.loss_mask: 0.4944  decode.d6.loss_dice: 0.3524  decode.d7.loss_cls: 1.2240  decode.d7.loss_mask: 0.4768  decode.d7.loss_dice: 0.3544  decode.d8.loss_cls: 1.1677  decode.d8.loss_mask: 0.4891  decode.d8.loss_dice: 0.3431
09/28 14:38:33 - mmengine - INFO - Iter(train) [  1550/320000]  base_lr: 9.9564e-05 lr: 9.9564e-06  eta: 1 day, 14:55:47  time: 0.4325  data_time: 0.0088  memory: 5167  grad_norm: 320.8545  loss: 21.6255  decode.loss_cls: 0.9202  decode.loss_mask: 0.6131  decode.loss_dice: 0.4440  decode.d0.loss_cls: 2.8800  decode.d0.loss_mask: 0.4635  decode.d0.loss_dice: 0.4464  decode.d1.loss_cls: 1.0333  decode.d1.loss_mask: 0.5608  decode.d1.loss_dice: 0.4614  decode.d2.loss_cls: 1.0863  decode.d2.loss_mask: 0.5463  decode.d2.loss_dice: 0.4107  decode.d3.loss_cls: 1.0289  decode.d3.loss_mask: 0.5792  decode.d3.loss_dice: 0.4641  decode.d4.loss_cls: 1.0632  decode.d4.loss_mask: 0.5642  decode.d4.loss_dice: 0.4386  decode.d5.loss_cls: 0.9178  decode.d5.loss_mask: 0.5300  decode.d5.loss_dice: 0.4522  decode.d6.loss_cls: 0.9073  decode.d6.loss_mask: 0.5458  decode.d6.loss_dice: 0.4249  decode.d7.loss_cls: 0.9647  decode.d7.loss_mask: 0.5518  decode.d7.loss_dice: 0.4080  decode.d8.loss_cls: 0.9519  decode.d8.loss_mask: 0.5557  decode.d8.loss_dice: 0.4111
09/28 14:38:54 - mmengine - INFO - Iter(train) [  1600/320000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 1 day, 14:54:09  time: 0.4329  data_time: 0.0088  memory: 5186  grad_norm: 113.1074  loss: 19.3462  decode.loss_cls: 1.0908  decode.loss_mask: 0.3820  decode.loss_dice: 0.3207  decode.d0.loss_cls: 2.6842  decode.d0.loss_mask: 0.3508  decode.d0.loss_dice: 0.3776  decode.d1.loss_cls: 1.1394  decode.d1.loss_mask: 0.3724  decode.d1.loss_dice: 0.3415  decode.d2.loss_cls: 1.0274  decode.d2.loss_mask: 0.3757  decode.d2.loss_dice: 0.3374  decode.d3.loss_cls: 1.0317  decode.d3.loss_mask: 0.3627  decode.d3.loss_dice: 0.3298  decode.d4.loss_cls: 1.0169  decode.d4.loss_mask: 0.3680  decode.d4.loss_dice: 0.3434  decode.d5.loss_cls: 1.0170  decode.d5.loss_mask: 0.3794  decode.d5.loss_dice: 0.2971  decode.d6.loss_cls: 1.0743  decode.d6.loss_mask: 0.3779  decode.d6.loss_dice: 0.3408  decode.d7.loss_cls: 1.0930  decode.d7.loss_mask: 0.3801  decode.d7.loss_dice: 0.3455  decode.d8.loss_cls: 1.0709  decode.d8.loss_mask: 0.3870  decode.d8.loss_dice: 0.3308
09/28 14:39:16 - mmengine - INFO - Iter(train) [  1650/320000]  base_lr: 9.9536e-05 lr: 9.9536e-06  eta: 1 day, 14:52:36  time: 0.4326  data_time: 0.0088  memory: 5166  grad_norm: 175.9770  loss: 17.9586  decode.loss_cls: 0.8617  decode.loss_mask: 0.4562  decode.loss_dice: 0.3088  decode.d0.loss_cls: 2.5236  decode.d0.loss_mask: 0.3741  decode.d0.loss_dice: 0.3585  decode.d1.loss_cls: 0.9679  decode.d1.loss_mask: 0.3699  decode.d1.loss_dice: 0.3313  decode.d2.loss_cls: 0.9089  decode.d2.loss_mask: 0.3872  decode.d2.loss_dice: 0.3369  decode.d3.loss_cls: 0.8537  decode.d3.loss_mask: 0.4043  decode.d3.loss_dice: 0.3256  decode.d4.loss_cls: 0.9153  decode.d4.loss_mask: 0.4127  decode.d4.loss_dice: 0.3155  decode.d5.loss_cls: 0.9255  decode.d5.loss_mask: 0.4165  decode.d5.loss_dice: 0.3330  decode.d6.loss_cls: 0.8607  decode.d6.loss_mask: 0.4136  decode.d6.loss_dice: 0.3147  decode.d7.loss_cls: 0.8814  decode.d7.loss_mask: 0.4731  decode.d7.loss_dice: 0.3300  decode.d8.loss_cls: 0.8342  decode.d8.loss_mask: 0.4394  decode.d8.loss_dice: 0.3245
09/28 14:39:38 - mmengine - INFO - Iter(train) [  1700/320000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 1 day, 14:51:08  time: 0.4320  data_time: 0.0088  memory: 5136  grad_norm: 215.9908  loss: 24.1032  decode.loss_cls: 0.8755  decode.loss_mask: 0.7925  decode.loss_dice: 0.6070  decode.d0.loss_cls: 2.3301  decode.d0.loss_mask: 0.6483  decode.d0.loss_dice: 0.6198  decode.d1.loss_cls: 1.0820  decode.d1.loss_mask: 0.6329  decode.d1.loss_dice: 0.5766  decode.d2.loss_cls: 1.0089  decode.d2.loss_mask: 0.6620  decode.d2.loss_dice: 0.5702  decode.d3.loss_cls: 0.9398  decode.d3.loss_mask: 0.6825  decode.d3.loss_dice: 0.6107  decode.d4.loss_cls: 0.9533  decode.d4.loss_mask: 0.6779  decode.d4.loss_dice: 0.6153  decode.d5.loss_cls: 1.0171  decode.d5.loss_mask: 0.6816  decode.d5.loss_dice: 0.6287  decode.d6.loss_cls: 1.0277  decode.d6.loss_mask: 0.6815  decode.d6.loss_dice: 0.5892  decode.d7.loss_cls: 0.9588  decode.d7.loss_mask: 0.7373  decode.d7.loss_dice: 0.6088  decode.d8.loss_cls: 0.8864  decode.d8.loss_mask: 0.8144  decode.d8.loss_dice: 0.5862
09/28 14:39:59 - mmengine - INFO - Iter(train) [  1750/320000]  base_lr: 9.9508e-05 lr: 9.9508e-06  eta: 1 day, 14:49:44  time: 0.4327  data_time: 0.0086  memory: 5150  grad_norm: 91.2070  loss: 16.5907  decode.loss_cls: 0.8416  decode.loss_mask: 0.3619  decode.loss_dice: 0.3373  decode.d0.loss_cls: 2.2086  decode.d0.loss_mask: 0.3565  decode.d0.loss_dice: 0.3209  decode.d1.loss_cls: 0.8994  decode.d1.loss_mask: 0.3609  decode.d1.loss_dice: 0.3556  decode.d2.loss_cls: 0.7816  decode.d2.loss_mask: 0.3690  decode.d2.loss_dice: 0.3450  decode.d3.loss_cls: 0.7762  decode.d3.loss_mask: 0.3731  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 0.8030  decode.d4.loss_mask: 0.3721  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 0.7703  decode.d5.loss_mask: 0.3668  decode.d5.loss_dice: 0.3329  decode.d6.loss_cls: 0.8184  decode.d6.loss_mask: 0.3574  decode.d6.loss_dice: 0.3357  decode.d7.loss_cls: 0.8316  decode.d7.loss_mask: 0.3620  decode.d7.loss_dice: 0.3444  decode.d8.loss_cls: 0.8259  decode.d8.loss_mask: 0.3634  decode.d8.loss_dice: 0.3435
09/28 14:40:21 - mmengine - INFO - Iter(train) [  1800/320000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 1 day, 14:48:20  time: 0.4325  data_time: 0.0086  memory: 5167  grad_norm: 164.6762  loss: 18.6518  decode.loss_cls: 0.9893  decode.loss_mask: 0.4454  decode.loss_dice: 0.3302  decode.d0.loss_cls: 2.2622  decode.d0.loss_mask: 0.3622  decode.d0.loss_dice: 0.3714  decode.d1.loss_cls: 1.0304  decode.d1.loss_mask: 0.3299  decode.d1.loss_dice: 0.3151  decode.d2.loss_cls: 0.9991  decode.d2.loss_mask: 0.3307  decode.d2.loss_dice: 0.3354  decode.d3.loss_cls: 1.0023  decode.d3.loss_mask: 0.3497  decode.d3.loss_dice: 0.3285  decode.d4.loss_cls: 1.0863  decode.d4.loss_mask: 0.3731  decode.d4.loss_dice: 0.3282  decode.d5.loss_cls: 1.1380  decode.d5.loss_mask: 0.3188  decode.d5.loss_dice: 0.3218  decode.d6.loss_cls: 1.1010  decode.d6.loss_mask: 0.3373  decode.d6.loss_dice: 0.3327  decode.d7.loss_cls: 1.0686  decode.d7.loss_mask: 0.3710  decode.d7.loss_dice: 0.3579  decode.d8.loss_cls: 1.0278  decode.d8.loss_mask: 0.3888  decode.d8.loss_dice: 0.3184
09/28 14:40:42 - mmengine - INFO - Iter(train) [  1850/320000]  base_lr: 9.9480e-05 lr: 9.9480e-06  eta: 1 day, 14:47:00  time: 0.4315  data_time: 0.0085  memory: 5167  grad_norm: 197.0044  loss: 18.2649  decode.loss_cls: 0.9039  decode.loss_mask: 0.4271  decode.loss_dice: 0.2956  decode.d0.loss_cls: 2.1186  decode.d0.loss_mask: 0.4266  decode.d0.loss_dice: 0.3673  decode.d1.loss_cls: 1.0739  decode.d1.loss_mask: 0.3894  decode.d1.loss_dice: 0.2929  decode.d2.loss_cls: 0.9866  decode.d2.loss_mask: 0.3895  decode.d2.loss_dice: 0.2770  decode.d3.loss_cls: 0.9916  decode.d3.loss_mask: 0.3905  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 1.0039  decode.d4.loss_mask: 0.4241  decode.d4.loss_dice: 0.3152  decode.d5.loss_cls: 0.9593  decode.d5.loss_mask: 0.4517  decode.d5.loss_dice: 0.3719  decode.d6.loss_cls: 0.9289  decode.d6.loss_mask: 0.4913  decode.d6.loss_dice: 0.3242  decode.d7.loss_cls: 0.9143  decode.d7.loss_mask: 0.4721  decode.d7.loss_dice: 0.3028  decode.d8.loss_cls: 0.8847  decode.d8.loss_mask: 0.4820  decode.d8.loss_dice: 0.3163
09/28 14:41:04 - mmengine - INFO - Iter(train) [  1900/320000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 1 day, 14:45:42  time: 0.4317  data_time: 0.0088  memory: 5186  grad_norm: 514.2938  loss: 23.7959  decode.loss_cls: 0.9898  decode.loss_mask: 0.6189  decode.loss_dice: 0.5768  decode.d0.loss_cls: 2.0187  decode.d0.loss_mask: 0.5890  decode.d0.loss_dice: 0.6016  decode.d1.loss_cls: 1.1710  decode.d1.loss_mask: 0.5569  decode.d1.loss_dice: 0.5770  decode.d2.loss_cls: 1.1523  decode.d2.loss_mask: 0.5736  decode.d2.loss_dice: 0.5522  decode.d3.loss_cls: 1.0877  decode.d3.loss_mask: 0.5884  decode.d3.loss_dice: 0.5480  decode.d4.loss_cls: 1.1908  decode.d4.loss_mask: 0.5782  decode.d4.loss_dice: 0.5502  decode.d5.loss_cls: 1.1539  decode.d5.loss_mask: 0.6192  decode.d5.loss_dice: 0.5718  decode.d6.loss_cls: 1.1230  decode.d6.loss_mask: 0.6314  decode.d6.loss_dice: 0.5756  decode.d7.loss_cls: 1.1415  decode.d7.loss_mask: 0.6162  decode.d7.loss_dice: 0.5675  decode.d8.loss_cls: 1.0587  decode.d8.loss_mask: 0.6468  decode.d8.loss_dice: 0.5691
09/28 14:41:26 - mmengine - INFO - Iter(train) [  1950/320000]  base_lr: 9.9452e-05 lr: 9.9452e-06  eta: 1 day, 14:44:27  time: 0.4323  data_time: 0.0087  memory: 5167  grad_norm: 188.7319  loss: 19.6997  decode.loss_cls: 1.0068  decode.loss_mask: 0.4554  decode.loss_dice: 0.3793  decode.d0.loss_cls: 2.0225  decode.d0.loss_mask: 0.4687  decode.d0.loss_dice: 0.4107  decode.d1.loss_cls: 1.0967  decode.d1.loss_mask: 0.4007  decode.d1.loss_dice: 0.3865  decode.d2.loss_cls: 1.0302  decode.d2.loss_mask: 0.3988  decode.d2.loss_dice: 0.3817  decode.d3.loss_cls: 1.0028  decode.d3.loss_mask: 0.4165  decode.d3.loss_dice: 0.4023  decode.d4.loss_cls: 0.9948  decode.d4.loss_mask: 0.4030  decode.d4.loss_dice: 0.3992  decode.d5.loss_cls: 0.9708  decode.d5.loss_mask: 0.4851  decode.d5.loss_dice: 0.4302  decode.d6.loss_cls: 1.0857  decode.d6.loss_mask: 0.4655  decode.d6.loss_dice: 0.4062  decode.d7.loss_cls: 1.0859  decode.d7.loss_mask: 0.4674  decode.d7.loss_dice: 0.3917  decode.d8.loss_cls: 1.0731  decode.d8.loss_mask: 0.4125  decode.d8.loss_dice: 0.3687
09/28 14:41:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 14:41:47 - mmengine - INFO - Iter(train) [  2000/320000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 1 day, 14:43:16  time: 0.4323  data_time: 0.0085  memory: 5167  grad_norm: 373.2268  loss: 19.4928  decode.loss_cls: 0.9353  decode.loss_mask: 0.5251  decode.loss_dice: 0.4358  decode.d0.loss_cls: 1.8808  decode.d0.loss_mask: 0.5402  decode.d0.loss_dice: 0.4086  decode.d1.loss_cls: 0.9817  decode.d1.loss_mask: 0.5285  decode.d1.loss_dice: 0.4059  decode.d2.loss_cls: 0.8051  decode.d2.loss_mask: 0.5285  decode.d2.loss_dice: 0.4244  decode.d3.loss_cls: 0.8340  decode.d3.loss_mask: 0.5311  decode.d3.loss_dice: 0.4364  decode.d4.loss_cls: 0.8413  decode.d4.loss_mask: 0.5493  decode.d4.loss_dice: 0.4390  decode.d5.loss_cls: 0.8431  decode.d5.loss_mask: 0.5663  decode.d5.loss_dice: 0.4401  decode.d6.loss_cls: 0.8523  decode.d6.loss_mask: 0.5596  decode.d6.loss_dice: 0.4666  decode.d7.loss_cls: 0.8718  decode.d7.loss_mask: 0.5567  decode.d7.loss_dice: 0.4348  decode.d8.loss_cls: 0.9310  decode.d8.loss_mask: 0.5342  decode.d8.loss_dice: 0.4053
09/28 14:42:09 - mmengine - INFO - Iter(train) [  2050/320000]  base_lr: 9.9424e-05 lr: 9.9424e-06  eta: 1 day, 14:42:06  time: 0.4319  data_time: 0.0088  memory: 5150  grad_norm: 89.3777  loss: 16.1387  decode.loss_cls: 0.8714  decode.loss_mask: 0.4129  decode.loss_dice: 0.3647  decode.d0.loss_cls: 1.8678  decode.d0.loss_mask: 0.3709  decode.d0.loss_dice: 0.3596  decode.d1.loss_cls: 0.8408  decode.d1.loss_mask: 0.3827  decode.d1.loss_dice: 0.3464  decode.d2.loss_cls: 0.6718  decode.d2.loss_mask: 0.3826  decode.d2.loss_dice: 0.3614  decode.d3.loss_cls: 0.6842  decode.d3.loss_mask: 0.3827  decode.d3.loss_dice: 0.3458  decode.d4.loss_cls: 0.7143  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.3368  decode.d5.loss_cls: 0.7886  decode.d5.loss_mask: 0.3806  decode.d5.loss_dice: 0.3277  decode.d6.loss_cls: 0.8131  decode.d6.loss_mask: 0.3605  decode.d6.loss_dice: 0.3361  decode.d7.loss_cls: 0.7503  decode.d7.loss_mask: 0.3780  decode.d7.loss_dice: 0.3572  decode.d8.loss_cls: 0.8134  decode.d8.loss_mask: 0.3964  decode.d8.loss_dice: 0.3558
09/28 14:42:31 - mmengine - INFO - Iter(train) [  2100/320000]  base_lr: 9.9409e-05 lr: 9.9409e-06  eta: 1 day, 14:41:01  time: 0.4322  data_time: 0.0088  memory: 5167  grad_norm: 278.3244  loss: 19.9173  decode.loss_cls: 0.9558  decode.loss_mask: 0.5321  decode.loss_dice: 0.3716  decode.d0.loss_cls: 1.8257  decode.d0.loss_mask: 0.5518  decode.d0.loss_dice: 0.4148  decode.d1.loss_cls: 1.0542  decode.d1.loss_mask: 0.5241  decode.d1.loss_dice: 0.3970  decode.d2.loss_cls: 1.0369  decode.d2.loss_mask: 0.5159  decode.d2.loss_dice: 0.3805  decode.d3.loss_cls: 0.9438  decode.d3.loss_mask: 0.5246  decode.d3.loss_dice: 0.4070  decode.d4.loss_cls: 0.9280  decode.d4.loss_mask: 0.5485  decode.d4.loss_dice: 0.4268  decode.d5.loss_cls: 0.9765  decode.d5.loss_mask: 0.5427  decode.d5.loss_dice: 0.4495  decode.d6.loss_cls: 0.9575  decode.d6.loss_mask: 0.5316  decode.d6.loss_dice: 0.3956  decode.d7.loss_cls: 1.0168  decode.d7.loss_mask: 0.5033  decode.d7.loss_dice: 0.3637  decode.d8.loss_cls: 0.9571  decode.d8.loss_mask: 0.5217  decode.d8.loss_dice: 0.3621
09/28 14:42:52 - mmengine - INFO - Iter(train) [  2150/320000]  base_lr: 9.9395e-05 lr: 9.9395e-06  eta: 1 day, 14:40:04  time: 0.4323  data_time: 0.0087  memory: 5186  grad_norm: 105.0425  loss: 14.4744  decode.loss_cls: 0.6441  decode.loss_mask: 0.3362  decode.loss_dice: 0.3555  decode.d0.loss_cls: 1.6648  decode.d0.loss_mask: 0.3378  decode.d0.loss_dice: 0.3637  decode.d1.loss_cls: 0.7082  decode.d1.loss_mask: 0.3443  decode.d1.loss_dice: 0.3428  decode.d2.loss_cls: 0.6273  decode.d2.loss_mask: 0.3459  decode.d2.loss_dice: 0.3534  decode.d3.loss_cls: 0.6619  decode.d3.loss_mask: 0.3430  decode.d3.loss_dice: 0.3728  decode.d4.loss_cls: 0.6151  decode.d4.loss_mask: 0.3321  decode.d4.loss_dice: 0.3659  decode.d5.loss_cls: 0.6207  decode.d5.loss_mask: 0.3365  decode.d5.loss_dice: 0.3535  decode.d6.loss_cls: 0.6252  decode.d6.loss_mask: 0.3479  decode.d6.loss_dice: 0.3623  decode.d7.loss_cls: 0.6575  decode.d7.loss_mask: 0.3396  decode.d7.loss_dice: 0.3715  decode.d8.loss_cls: 0.6662  decode.d8.loss_mask: 0.3381  decode.d8.loss_dice: 0.3406
09/28 14:43:14 - mmengine - INFO - Iter(train) [  2200/320000]  base_lr: 9.9381e-05 lr: 9.9381e-06  eta: 1 day, 14:39:00  time: 0.4317  data_time: 0.0088  memory: 5150  grad_norm: 160.6810  loss: 14.5762  decode.loss_cls: 0.6732  decode.loss_mask: 0.4643  decode.loss_dice: 0.3879  decode.d0.loss_cls: 1.4837  decode.d0.loss_mask: 0.4108  decode.d0.loss_dice: 0.3922  decode.d1.loss_cls: 0.6591  decode.d1.loss_mask: 0.3938  decode.d1.loss_dice: 0.3370  decode.d2.loss_cls: 0.6534  decode.d2.loss_mask: 0.3881  decode.d2.loss_dice: 0.3193  decode.d3.loss_cls: 0.5998  decode.d3.loss_mask: 0.3670  decode.d3.loss_dice: 0.2968  decode.d4.loss_cls: 0.5831  decode.d4.loss_mask: 0.4270  decode.d4.loss_dice: 0.3304  decode.d5.loss_cls: 0.5818  decode.d5.loss_mask: 0.4497  decode.d5.loss_dice: 0.3367  decode.d6.loss_cls: 0.5736  decode.d6.loss_mask: 0.4009  decode.d6.loss_dice: 0.3273  decode.d7.loss_cls: 0.6009  decode.d7.loss_mask: 0.4009  decode.d7.loss_dice: 0.3328  decode.d8.loss_cls: 0.6170  decode.d8.loss_mask: 0.4362  decode.d8.loss_dice: 0.3515
09/28 14:43:35 - mmengine - INFO - Iter(train) [  2250/320000]  base_lr: 9.9367e-05 lr: 9.9367e-06  eta: 1 day, 14:38:00  time: 0.4327  data_time: 0.0088  memory: 5150  grad_norm: 109.0536  loss: 17.5895  decode.loss_cls: 0.9219  decode.loss_mask: 0.4294  decode.loss_dice: 0.2948  decode.d0.loss_cls: 1.7798  decode.d0.loss_mask: 0.3931  decode.d0.loss_dice: 0.3806  decode.d1.loss_cls: 0.9764  decode.d1.loss_mask: 0.4022  decode.d1.loss_dice: 0.3618  decode.d2.loss_cls: 0.8956  decode.d2.loss_mask: 0.4134  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.9478  decode.d3.loss_mask: 0.4170  decode.d3.loss_dice: 0.3186  decode.d4.loss_cls: 0.9513  decode.d4.loss_mask: 0.4301  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.9344  decode.d5.loss_mask: 0.4097  decode.d5.loss_dice: 0.3182  decode.d6.loss_cls: 0.9065  decode.d6.loss_mask: 0.4074  decode.d6.loss_dice: 0.3051  decode.d7.loss_cls: 0.9589  decode.d7.loss_mask: 0.4166  decode.d7.loss_dice: 0.3094  decode.d8.loss_cls: 0.9304  decode.d8.loss_mask: 0.4244  decode.d8.loss_dice: 0.3077
09/28 14:43:58 - mmengine - INFO - Iter(train) [  2300/320000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 1 day, 14:38:24  time: 0.4672  data_time: 0.0086  memory: 5186  grad_norm: 241.0514  loss: 20.0052  decode.loss_cls: 1.0755  decode.loss_mask: 0.5917  decode.loss_dice: 0.4286  decode.d0.loss_cls: 1.6277  decode.d0.loss_mask: 0.5381  decode.d0.loss_dice: 0.4874  decode.d1.loss_cls: 0.9976  decode.d1.loss_mask: 0.4712  decode.d1.loss_dice: 0.4379  decode.d2.loss_cls: 0.9055  decode.d2.loss_mask: 0.4771  decode.d2.loss_dice: 0.3955  decode.d3.loss_cls: 0.9204  decode.d3.loss_mask: 0.4877  decode.d3.loss_dice: 0.4107  decode.d4.loss_cls: 0.9912  decode.d4.loss_mask: 0.5046  decode.d4.loss_dice: 0.4167  decode.d5.loss_cls: 0.9254  decode.d5.loss_mask: 0.5464  decode.d5.loss_dice: 0.4286  decode.d6.loss_cls: 1.0304  decode.d6.loss_mask: 0.5156  decode.d6.loss_dice: 0.4229  decode.d7.loss_cls: 1.0327  decode.d7.loss_mask: 0.5115  decode.d7.loss_dice: 0.4012  decode.d8.loss_cls: 1.0754  decode.d8.loss_mask: 0.5431  decode.d8.loss_dice: 0.4070
09/28 14:44:21 - mmengine - INFO - Iter(train) [  2350/320000]  base_lr: 9.9339e-05 lr: 9.9339e-06  eta: 1 day, 14:41:30  time: 0.4687  data_time: 0.0088  memory: 5150  grad_norm: 251.2128  loss: 24.4858  decode.loss_cls: 1.1727  decode.loss_mask: 0.5556  decode.loss_dice: 0.5937  decode.d0.loss_cls: 1.8119  decode.d0.loss_mask: 0.6042  decode.d0.loss_dice: 0.7304  decode.d1.loss_cls: 1.3329  decode.d1.loss_mask: 0.5809  decode.d1.loss_dice: 0.6601  decode.d2.loss_cls: 1.3028  decode.d2.loss_mask: 0.5632  decode.d2.loss_dice: 0.5737  decode.d3.loss_cls: 1.1201  decode.d3.loss_mask: 0.5768  decode.d3.loss_dice: 0.5764  decode.d4.loss_cls: 1.1133  decode.d4.loss_mask: 0.5841  decode.d4.loss_dice: 0.5784  decode.d5.loss_cls: 1.2180  decode.d5.loss_mask: 0.5613  decode.d5.loss_dice: 0.5638  decode.d6.loss_cls: 1.2345  decode.d6.loss_mask: 0.5621  decode.d6.loss_dice: 0.5512  decode.d7.loss_cls: 1.2798  decode.d7.loss_mask: 0.5616  decode.d7.loss_dice: 0.5742  decode.d8.loss_cls: 1.1540  decode.d8.loss_mask: 0.6146  decode.d8.loss_dice: 0.5796
09/28 14:44:44 - mmengine - INFO - Iter(train) [  2400/320000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 1 day, 14:44:22  time: 0.4663  data_time: 0.0088  memory: 5166  grad_norm: 122.9882  loss: 17.4366  decode.loss_cls: 0.8321  decode.loss_mask: 0.4309  decode.loss_dice: 0.3658  decode.d0.loss_cls: 1.5215  decode.d0.loss_mask: 0.4743  decode.d0.loss_dice: 0.4565  decode.d1.loss_cls: 0.9317  decode.d1.loss_mask: 0.4319  decode.d1.loss_dice: 0.3827  decode.d2.loss_cls: 0.8543  decode.d2.loss_mask: 0.4411  decode.d2.loss_dice: 0.3656  decode.d3.loss_cls: 0.8560  decode.d3.loss_mask: 0.4487  decode.d3.loss_dice: 0.3555  decode.d4.loss_cls: 0.8568  decode.d4.loss_mask: 0.4492  decode.d4.loss_dice: 0.3511  decode.d5.loss_cls: 0.8481  decode.d5.loss_mask: 0.4281  decode.d5.loss_dice: 0.3486  decode.d6.loss_cls: 0.8787  decode.d6.loss_mask: 0.4350  decode.d6.loss_dice: 0.3570  decode.d7.loss_cls: 0.8376  decode.d7.loss_mask: 0.4452  decode.d7.loss_dice: 0.3768  decode.d8.loss_cls: 0.8811  decode.d8.loss_mask: 0.4340  decode.d8.loss_dice: 0.3604
09/28 14:45:08 - mmengine - INFO - Iter(train) [  2450/320000]  base_lr: 9.9311e-05 lr: 9.9311e-06  eta: 1 day, 14:47:06  time: 0.4680  data_time: 0.0090  memory: 5167  grad_norm: 146.4205  loss: 18.2943  decode.loss_cls: 0.9153  decode.loss_mask: 0.4157  decode.loss_dice: 0.3850  decode.d0.loss_cls: 1.5687  decode.d0.loss_mask: 0.4493  decode.d0.loss_dice: 0.4299  decode.d1.loss_cls: 1.0428  decode.d1.loss_mask: 0.4237  decode.d1.loss_dice: 0.4427  decode.d2.loss_cls: 1.0415  decode.d2.loss_mask: 0.4137  decode.d2.loss_dice: 0.4189  decode.d3.loss_cls: 0.9542  decode.d3.loss_mask: 0.3982  decode.d3.loss_dice: 0.3989  decode.d4.loss_cls: 0.9105  decode.d4.loss_mask: 0.4128  decode.d4.loss_dice: 0.3859  decode.d5.loss_cls: 0.8915  decode.d5.loss_mask: 0.3963  decode.d5.loss_dice: 0.3953  decode.d6.loss_cls: 0.9164  decode.d6.loss_mask: 0.4008  decode.d6.loss_dice: 0.4097  decode.d7.loss_cls: 0.9158  decode.d7.loss_mask: 0.4011  decode.d7.loss_dice: 0.3927  decode.d8.loss_cls: 0.9644  decode.d8.loss_mask: 0.4158  decode.d8.loss_dice: 0.3866
09/28 14:45:31 - mmengine - INFO - Iter(train) [  2500/320000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 1 day, 14:49:42  time: 0.4667  data_time: 0.0087  memory: 5186  grad_norm: 103.2814  loss: 18.2776  decode.loss_cls: 0.9065  decode.loss_mask: 0.5841  decode.loss_dice: 0.3616  decode.d0.loss_cls: 1.7254  decode.d0.loss_mask: 0.3990  decode.d0.loss_dice: 0.4292  decode.d1.loss_cls: 1.1091  decode.d1.loss_mask: 0.3767  decode.d1.loss_dice: 0.3351  decode.d2.loss_cls: 0.9300  decode.d2.loss_mask: 0.4002  decode.d2.loss_dice: 0.3312  decode.d3.loss_cls: 0.9535  decode.d3.loss_mask: 0.3800  decode.d3.loss_dice: 0.3290  decode.d4.loss_cls: 0.9448  decode.d4.loss_mask: 0.3798  decode.d4.loss_dice: 0.3341  decode.d5.loss_cls: 0.9521  decode.d5.loss_mask: 0.4292  decode.d5.loss_dice: 0.3475  decode.d6.loss_cls: 0.9752  decode.d6.loss_mask: 0.4406  decode.d6.loss_dice: 0.3482  decode.d7.loss_cls: 0.9876  decode.d7.loss_mask: 0.4365  decode.d7.loss_dice: 0.3476  decode.d8.loss_cls: 0.8814  decode.d8.loss_mask: 0.5496  decode.d8.loss_dice: 0.3728
09/28 14:45:55 - mmengine - INFO - Iter(train) [  2550/320000]  base_lr: 9.9283e-05 lr: 9.9283e-06  eta: 1 day, 14:52:11  time: 0.4694  data_time: 0.0089  memory: 5186  grad_norm: 181.0552  loss: 19.0669  decode.loss_cls: 1.0691  decode.loss_mask: 0.3943  decode.loss_dice: 0.3756  decode.d0.loss_cls: 1.7133  decode.d0.loss_mask: 0.3632  decode.d0.loss_dice: 0.3447  decode.d1.loss_cls: 1.1493  decode.d1.loss_mask: 0.3733  decode.d1.loss_dice: 0.3591  decode.d2.loss_cls: 1.0454  decode.d2.loss_mask: 0.3625  decode.d2.loss_dice: 0.3286  decode.d3.loss_cls: 1.0287  decode.d3.loss_mask: 0.3717  decode.d3.loss_dice: 0.3556  decode.d4.loss_cls: 1.0543  decode.d4.loss_mask: 0.3997  decode.d4.loss_dice: 0.3541  decode.d5.loss_cls: 1.0764  decode.d5.loss_mask: 0.4269  decode.d5.loss_dice: 0.3677  decode.d6.loss_cls: 1.0289  decode.d6.loss_mask: 0.4695  decode.d6.loss_dice: 0.3627  decode.d7.loss_cls: 1.0784  decode.d7.loss_mask: 0.4853  decode.d7.loss_dice: 0.3657  decode.d8.loss_cls: 1.1307  decode.d8.loss_mask: 0.4834  decode.d8.loss_dice: 0.3489
09/28 14:46:18 - mmengine - INFO - Iter(train) [  2600/320000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 1 day, 14:54:37  time: 0.4669  data_time: 0.0088  memory: 5186  grad_norm: 151.3134  loss: 14.6942  decode.loss_cls: 0.6578  decode.loss_mask: 0.3991  decode.loss_dice: 0.3772  decode.d0.loss_cls: 1.4803  decode.d0.loss_mask: 0.3534  decode.d0.loss_dice: 0.3877  decode.d1.loss_cls: 0.7580  decode.d1.loss_mask: 0.3324  decode.d1.loss_dice: 0.3465  decode.d2.loss_cls: 0.6400  decode.d2.loss_mask: 0.3546  decode.d2.loss_dice: 0.3401  decode.d3.loss_cls: 0.5576  decode.d3.loss_mask: 0.3861  decode.d3.loss_dice: 0.3281  decode.d4.loss_cls: 0.5735  decode.d4.loss_mask: 0.3872  decode.d4.loss_dice: 0.3398  decode.d5.loss_cls: 0.5695  decode.d5.loss_mask: 0.4555  decode.d5.loss_dice: 0.3775  decode.d6.loss_cls: 0.5648  decode.d6.loss_mask: 0.4913  decode.d6.loss_dice: 0.3668  decode.d7.loss_cls: 0.5698  decode.d7.loss_mask: 0.4721  decode.d7.loss_dice: 0.3700  decode.d8.loss_cls: 0.6321  decode.d8.loss_mask: 0.4211  decode.d8.loss_dice: 0.4043
09/28 14:46:41 - mmengine - INFO - Iter(train) [  2650/320000]  base_lr: 9.9255e-05 lr: 9.9255e-06  eta: 1 day, 14:56:56  time: 0.4686  data_time: 0.0090  memory: 5167  grad_norm: 77.9526  loss: 13.6218  decode.loss_cls: 0.6480  decode.loss_mask: 0.3342  decode.loss_dice: 0.3015  decode.d0.loss_cls: 1.3498  decode.d0.loss_mask: 0.3381  decode.d0.loss_dice: 0.3461  decode.d1.loss_cls: 0.7201  decode.d1.loss_mask: 0.3277  decode.d1.loss_dice: 0.3099  decode.d2.loss_cls: 0.6581  decode.d2.loss_mask: 0.3378  decode.d2.loss_dice: 0.3166  decode.d3.loss_cls: 0.6154  decode.d3.loss_mask: 0.3338  decode.d3.loss_dice: 0.2975  decode.d4.loss_cls: 0.6193  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.2982  decode.d5.loss_cls: 0.6285  decode.d5.loss_mask: 0.3194  decode.d5.loss_dice: 0.2941  decode.d6.loss_cls: 0.6499  decode.d6.loss_mask: 0.3264  decode.d6.loss_dice: 0.3069  decode.d7.loss_cls: 0.6789  decode.d7.loss_mask: 0.3200  decode.d7.loss_dice: 0.3052  decode.d8.loss_cls: 0.6757  decode.d8.loss_mask: 0.3229  decode.d8.loss_dice: 0.3070
09/28 14:47:05 - mmengine - INFO - Iter(train) [  2700/320000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 1 day, 14:59:06  time: 0.4667  data_time: 0.0087  memory: 5150  grad_norm: 307.4230  loss: 23.5490  decode.loss_cls: 0.9677  decode.loss_mask: 0.8537  decode.loss_dice: 0.6038  decode.d0.loss_cls: 1.5231  decode.d0.loss_mask: 0.6783  decode.d0.loss_dice: 0.6355  decode.d1.loss_cls: 1.0165  decode.d1.loss_mask: 0.7126  decode.d1.loss_dice: 0.5672  decode.d2.loss_cls: 0.8599  decode.d2.loss_mask: 0.7164  decode.d2.loss_dice: 0.5683  decode.d3.loss_cls: 0.8981  decode.d3.loss_mask: 0.8549  decode.d3.loss_dice: 0.5496  decode.d4.loss_cls: 0.9029  decode.d4.loss_mask: 0.8533  decode.d4.loss_dice: 0.5108  decode.d5.loss_cls: 0.9943  decode.d5.loss_mask: 0.7172  decode.d5.loss_dice: 0.5408  decode.d6.loss_cls: 0.9146  decode.d6.loss_mask: 0.7532  decode.d6.loss_dice: 0.6066  decode.d7.loss_cls: 0.8978  decode.d7.loss_mask: 0.9303  decode.d7.loss_dice: 0.5862  decode.d8.loss_cls: 1.0019  decode.d8.loss_mask: 0.7624  decode.d8.loss_dice: 0.5710
09/28 14:47:28 - mmengine - INFO - Iter(train) [  2750/320000]  base_lr: 9.9227e-05 lr: 9.9227e-06  eta: 1 day, 15:01:12  time: 0.4677  data_time: 0.0082  memory: 5167  grad_norm: 115.2758  loss: 13.8826  decode.loss_cls: 0.6626  decode.loss_mask: 0.4002  decode.loss_dice: 0.2765  decode.d0.loss_cls: 1.4348  decode.d0.loss_mask: 0.4224  decode.d0.loss_dice: 0.2890  decode.d1.loss_cls: 0.8059  decode.d1.loss_mask: 0.4068  decode.d1.loss_dice: 0.2765  decode.d2.loss_cls: 0.5164  decode.d2.loss_mask: 0.4243  decode.d2.loss_dice: 0.3033  decode.d3.loss_cls: 0.6129  decode.d3.loss_mask: 0.4001  decode.d3.loss_dice: 0.2700  decode.d4.loss_cls: 0.5800  decode.d4.loss_mask: 0.4077  decode.d4.loss_dice: 0.2803  decode.d5.loss_cls: 0.5624  decode.d5.loss_mask: 0.3883  decode.d5.loss_dice: 0.2632  decode.d6.loss_cls: 0.6268  decode.d6.loss_mask: 0.4120  decode.d6.loss_dice: 0.2655  decode.d7.loss_cls: 0.6170  decode.d7.loss_mask: 0.4048  decode.d7.loss_dice: 0.2630  decode.d8.loss_cls: 0.6488  decode.d8.loss_mask: 0.4029  decode.d8.loss_dice: 0.2584
09/28 14:47:52 - mmengine - INFO - Iter(train) [  2800/320000]  base_lr: 9.9212e-05 lr: 9.9212e-06  eta: 1 day, 15:03:12  time: 0.4686  data_time: 0.0089  memory: 5186  grad_norm: 325.8585  loss: 18.4644  decode.loss_cls: 0.9295  decode.loss_mask: 0.4553  decode.loss_dice: 0.3912  decode.d0.loss_cls: 1.6538  decode.d0.loss_mask: 0.4481  decode.d0.loss_dice: 0.5094  decode.d1.loss_cls: 0.9269  decode.d1.loss_mask: 0.4589  decode.d1.loss_dice: 0.4201  decode.d2.loss_cls: 0.8946  decode.d2.loss_mask: 0.4253  decode.d2.loss_dice: 0.3553  decode.d3.loss_cls: 0.8596  decode.d3.loss_mask: 0.4642  decode.d3.loss_dice: 0.3781  decode.d4.loss_cls: 0.9009  decode.d4.loss_mask: 0.4836  decode.d4.loss_dice: 0.4095  decode.d5.loss_cls: 0.8533  decode.d5.loss_mask: 0.5263  decode.d5.loss_dice: 0.4283  decode.d6.loss_cls: 0.8927  decode.d6.loss_mask: 0.5062  decode.d6.loss_dice: 0.4006  decode.d7.loss_cls: 0.8870  decode.d7.loss_mask: 0.4614  decode.d7.loss_dice: 0.3818  decode.d8.loss_cls: 0.9226  decode.d8.loss_mask: 0.4496  decode.d8.loss_dice: 0.3906
09/28 14:48:15 - mmengine - INFO - Iter(train) [  2850/320000]  base_lr: 9.9198e-05 lr: 9.9198e-06  eta: 1 day, 15:05:09  time: 0.4685  data_time: 0.0084  memory: 5167  grad_norm: 127.2233  loss: 14.5457  decode.loss_cls: 0.7184  decode.loss_mask: 0.3027  decode.loss_dice: 0.3019  decode.d0.loss_cls: 1.5715  decode.d0.loss_mask: 0.3089  decode.d0.loss_dice: 0.3222  decode.d1.loss_cls: 0.8322  decode.d1.loss_mask: 0.3036  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.7180  decode.d2.loss_mask: 0.3212  decode.d2.loss_dice: 0.3411  decode.d3.loss_cls: 0.7983  decode.d3.loss_mask: 0.3046  decode.d3.loss_dice: 0.2933  decode.d4.loss_cls: 0.7803  decode.d4.loss_mask: 0.2996  decode.d4.loss_dice: 0.3056  decode.d5.loss_cls: 0.7444  decode.d5.loss_mask: 0.3030  decode.d5.loss_dice: 0.3175  decode.d6.loss_cls: 0.7770  decode.d6.loss_mask: 0.3247  decode.d6.loss_dice: 0.3042  decode.d7.loss_cls: 0.7108  decode.d7.loss_mask: 0.3244  decode.d7.loss_dice: 0.3063  decode.d8.loss_cls: 0.7184  decode.d8.loss_mask: 0.3045  decode.d8.loss_dice: 0.3035
09/28 14:48:39 - mmengine - INFO - Iter(train) [  2900/320000]  base_lr: 9.9184e-05 lr: 9.9184e-06  eta: 1 day, 15:07:19  time: 0.4677  data_time: 0.0087  memory: 5166  grad_norm: 64.0564  loss: 11.6764  decode.loss_cls: 0.4824  decode.loss_mask: 0.3760  decode.loss_dice: 0.2687  decode.d0.loss_cls: 1.3773  decode.d0.loss_mask: 0.2773  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.5875  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.2235  decode.d2.loss_cls: 0.5304  decode.d2.loss_mask: 0.2769  decode.d2.loss_dice: 0.2477  decode.d3.loss_cls: 0.5414  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.2878  decode.d4.loss_cls: 0.4576  decode.d4.loss_mask: 0.3398  decode.d4.loss_dice: 0.2673  decode.d5.loss_cls: 0.4587  decode.d5.loss_mask: 0.3722  decode.d5.loss_dice: 0.2752  decode.d6.loss_cls: 0.4294  decode.d6.loss_mask: 0.3482  decode.d6.loss_dice: 0.2479  decode.d7.loss_cls: 0.4225  decode.d7.loss_mask: 0.3715  decode.d7.loss_dice: 0.2681  decode.d8.loss_cls: 0.4602  decode.d8.loss_mask: 0.3862  decode.d8.loss_dice: 0.2746
09/28 14:49:02 - mmengine - INFO - Iter(train) [  2950/320000]  base_lr: 9.9170e-05 lr: 9.9170e-06  eta: 1 day, 15:09:07  time: 0.4692  data_time: 0.0092  memory: 5186  grad_norm: 201.7993  loss: 19.6774  decode.loss_cls: 1.1103  decode.loss_mask: 0.4434  decode.loss_dice: 0.3784  decode.d0.loss_cls: 1.7384  decode.d0.loss_mask: 0.4280  decode.d0.loss_dice: 0.4777  decode.d1.loss_cls: 1.0847  decode.d1.loss_mask: 0.3606  decode.d1.loss_dice: 0.3381  decode.d2.loss_cls: 0.9576  decode.d2.loss_mask: 0.5378  decode.d2.loss_dice: 0.3650  decode.d3.loss_cls: 1.0174  decode.d3.loss_mask: 0.5305  decode.d3.loss_dice: 0.3696  decode.d4.loss_cls: 0.9973  decode.d4.loss_mask: 0.5815  decode.d4.loss_dice: 0.3669  decode.d5.loss_cls: 1.1570  decode.d5.loss_mask: 0.4074  decode.d5.loss_dice: 0.3717  decode.d6.loss_cls: 1.0683  decode.d6.loss_mask: 0.5325  decode.d6.loss_dice: 0.3866  decode.d7.loss_cls: 1.0445  decode.d7.loss_mask: 0.4424  decode.d7.loss_dice: 0.3690  decode.d8.loss_cls: 1.0362  decode.d8.loss_mask: 0.4046  decode.d8.loss_dice: 0.3740
09/28 14:49:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 14:49:25 - mmengine - INFO - Iter(train) [  3000/320000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 1 day, 15:10:47  time: 0.4667  data_time: 0.0088  memory: 5150  grad_norm: 169.4401  loss: 12.8504  decode.loss_cls: 0.5814  decode.loss_mask: 0.3691  decode.loss_dice: 0.3281  decode.d0.loss_cls: 1.0766  decode.d0.loss_mask: 0.3897  decode.d0.loss_dice: 0.3563  decode.d1.loss_cls: 0.5557  decode.d1.loss_mask: 0.3572  decode.d1.loss_dice: 0.3063  decode.d2.loss_cls: 0.5188  decode.d2.loss_mask: 0.3647  decode.d2.loss_dice: 0.3190  decode.d3.loss_cls: 0.4947  decode.d3.loss_mask: 0.3652  decode.d3.loss_dice: 0.3094  decode.d4.loss_cls: 0.4958  decode.d4.loss_mask: 0.3681  decode.d4.loss_dice: 0.3213  decode.d5.loss_cls: 0.5550  decode.d5.loss_mask: 0.3665  decode.d5.loss_dice: 0.3477  decode.d6.loss_cls: 0.5223  decode.d6.loss_mask: 0.3687  decode.d6.loss_dice: 0.3210  decode.d7.loss_cls: 0.5583  decode.d7.loss_mask: 0.3602  decode.d7.loss_dice: 0.3175  decode.d8.loss_cls: 0.5573  decode.d8.loss_mask: 0.3693  decode.d8.loss_dice: 0.3291
09/28 14:49:47 - mmengine - INFO - Iter(train) [  3050/320000]  base_lr: 9.9142e-05 lr: 9.9142e-06  eta: 1 day, 15:09:04  time: 0.4299  data_time: 0.0085  memory: 5166  grad_norm: 306.6483  loss: 21.7581  decode.loss_cls: 1.1206  decode.loss_mask: 0.5970  decode.loss_dice: 0.4834  decode.d0.loss_cls: 1.6919  decode.d0.loss_mask: 0.5430  decode.d0.loss_dice: 0.4574  decode.d1.loss_cls: 1.1325  decode.d1.loss_mask: 0.4844  decode.d1.loss_dice: 0.4391  decode.d2.loss_cls: 1.0087  decode.d2.loss_mask: 0.5044  decode.d2.loss_dice: 0.4268  decode.d3.loss_cls: 1.0428  decode.d3.loss_mask: 0.4922  decode.d3.loss_dice: 0.4334  decode.d4.loss_cls: 1.0411  decode.d4.loss_mask: 0.5655  decode.d4.loss_dice: 0.4962  decode.d5.loss_cls: 1.1325  decode.d5.loss_mask: 0.5630  decode.d5.loss_dice: 0.4656  decode.d6.loss_cls: 1.0113  decode.d6.loss_mask: 0.7016  decode.d6.loss_dice: 0.4786  decode.d7.loss_cls: 1.0336  decode.d7.loss_mask: 0.7580  decode.d7.loss_dice: 0.5072  decode.d8.loss_cls: 1.0543  decode.d8.loss_mask: 0.6170  decode.d8.loss_dice: 0.4750
09/28 14:50:08 - mmengine - INFO - Iter(train) [  3100/320000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 1 day, 15:07:23  time: 0.4293  data_time: 0.0086  memory: 5166  grad_norm: 90.3641  loss: 16.1652  decode.loss_cls: 0.8646  decode.loss_mask: 0.4113  decode.loss_dice: 0.3003  decode.d0.loss_cls: 1.4472  decode.d0.loss_mask: 0.4464  decode.d0.loss_dice: 0.3847  decode.d1.loss_cls: 0.9409  decode.d1.loss_mask: 0.3110  decode.d1.loss_dice: 0.3042  decode.d2.loss_cls: 0.7624  decode.d2.loss_mask: 0.3701  decode.d2.loss_dice: 0.2945  decode.d3.loss_cls: 0.8097  decode.d3.loss_mask: 0.3763  decode.d3.loss_dice: 0.3032  decode.d4.loss_cls: 0.8501  decode.d4.loss_mask: 0.3189  decode.d4.loss_dice: 0.2925  decode.d5.loss_cls: 0.8459  decode.d5.loss_mask: 0.3899  decode.d5.loss_dice: 0.3109  decode.d6.loss_cls: 0.9242  decode.d6.loss_mask: 0.4104  decode.d6.loss_dice: 0.3102  decode.d7.loss_cls: 0.8984  decode.d7.loss_mask: 0.4192  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.8445  decode.d8.loss_mask: 0.4128  decode.d8.loss_dice: 0.3162
09/28 14:50:30 - mmengine - INFO - Iter(train) [  3150/320000]  base_lr: 9.9114e-05 lr: 9.9114e-06  eta: 1 day, 15:05:45  time: 0.4295  data_time: 0.0086  memory: 5166  grad_norm: 124.8729  loss: 11.5951  decode.loss_cls: 0.5649  decode.loss_mask: 0.2540  decode.loss_dice: 0.2427  decode.d0.loss_cls: 1.3854  decode.d0.loss_mask: 0.2549  decode.d0.loss_dice: 0.2490  decode.d1.loss_cls: 0.6238  decode.d1.loss_mask: 0.2602  decode.d1.loss_dice: 0.2346  decode.d2.loss_cls: 0.6185  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.5388  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2300  decode.d4.loss_cls: 0.6063  decode.d4.loss_mask: 0.2599  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.6033  decode.d5.loss_mask: 0.2460  decode.d5.loss_dice: 0.2188  decode.d6.loss_cls: 0.6096  decode.d6.loss_mask: 0.2468  decode.d6.loss_dice: 0.2177  decode.d7.loss_cls: 0.5595  decode.d7.loss_mask: 0.2828  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.5531  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.2240
09/28 14:50:51 - mmengine - INFO - Iter(train) [  3200/320000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 1 day, 15:04:11  time: 0.4301  data_time: 0.0087  memory: 5167  grad_norm: 263.2057  loss: 21.4554  decode.loss_cls: 1.0240  decode.loss_mask: 0.5367  decode.loss_dice: 0.5238  decode.d0.loss_cls: 1.6109  decode.d0.loss_mask: 0.5811  decode.d0.loss_dice: 0.5252  decode.d1.loss_cls: 1.0369  decode.d1.loss_mask: 0.5887  decode.d1.loss_dice: 0.4995  decode.d2.loss_cls: 1.0055  decode.d2.loss_mask: 0.5601  decode.d2.loss_dice: 0.4880  decode.d3.loss_cls: 0.9926  decode.d3.loss_mask: 0.5790  decode.d3.loss_dice: 0.4768  decode.d4.loss_cls: 1.0409  decode.d4.loss_mask: 0.5432  decode.d4.loss_dice: 0.4999  decode.d5.loss_cls: 1.0093  decode.d5.loss_mask: 0.5319  decode.d5.loss_dice: 0.4804  decode.d6.loss_cls: 1.0938  decode.d6.loss_mask: 0.5110  decode.d6.loss_dice: 0.5069  decode.d7.loss_cls: 1.0875  decode.d7.loss_mask: 0.5162  decode.d7.loss_dice: 0.4813  decode.d8.loss_cls: 1.1213  decode.d8.loss_mask: 0.5328  decode.d8.loss_dice: 0.4701
09/28 14:51:13 - mmengine - INFO - Iter(train) [  3250/320000]  base_lr: 9.9086e-05 lr: 9.9086e-06  eta: 1 day, 15:02:42  time: 0.4301  data_time: 0.0087  memory: 5167  grad_norm: 126.7867  loss: 14.1359  decode.loss_cls: 0.8500  decode.loss_mask: 0.3093  decode.loss_dice: 0.3006  decode.d0.loss_cls: 1.3319  decode.d0.loss_mask: 0.3094  decode.d0.loss_dice: 0.3313  decode.d1.loss_cls: 0.7370  decode.d1.loss_mask: 0.3303  decode.d1.loss_dice: 0.2761  decode.d2.loss_cls: 0.6834  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.2861  decode.d3.loss_cls: 0.7127  decode.d3.loss_mask: 0.3421  decode.d3.loss_dice: 0.2980  decode.d4.loss_cls: 0.7395  decode.d4.loss_mask: 0.3039  decode.d4.loss_dice: 0.3352  decode.d5.loss_cls: 0.7001  decode.d5.loss_mask: 0.3216  decode.d5.loss_dice: 0.3284  decode.d6.loss_cls: 0.6782  decode.d6.loss_mask: 0.3103  decode.d6.loss_dice: 0.3222  decode.d7.loss_cls: 0.6715  decode.d7.loss_mask: 0.3274  decode.d7.loss_dice: 0.3218  decode.d8.loss_cls: 0.7121  decode.d8.loss_mask: 0.3461  decode.d8.loss_dice: 0.2773
09/28 14:51:34 - mmengine - INFO - Iter(train) [  3300/320000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 1 day, 15:01:15  time: 0.4300  data_time: 0.0087  memory: 5186  grad_norm: 104.5331  loss: 11.9376  decode.loss_cls: 0.5557  decode.loss_mask: 0.3283  decode.loss_dice: 0.2704  decode.d0.loss_cls: 1.2533  decode.d0.loss_mask: 0.2937  decode.d0.loss_dice: 0.2542  decode.d1.loss_cls: 0.5628  decode.d1.loss_mask: 0.3089  decode.d1.loss_dice: 0.2751  decode.d2.loss_cls: 0.5127  decode.d2.loss_mask: 0.2926  decode.d2.loss_dice: 0.2542  decode.d3.loss_cls: 0.5386  decode.d3.loss_mask: 0.2902  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.5871  decode.d4.loss_mask: 0.2923  decode.d4.loss_dice: 0.2473  decode.d5.loss_cls: 0.5940  decode.d5.loss_mask: 0.2880  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.5321  decode.d6.loss_mask: 0.3442  decode.d6.loss_dice: 0.2778  decode.d7.loss_cls: 0.5536  decode.d7.loss_mask: 0.3164  decode.d7.loss_dice: 0.2603  decode.d8.loss_cls: 0.5885  decode.d8.loss_mask: 0.3094  decode.d8.loss_dice: 0.2581
09/28 14:51:56 - mmengine - INFO - Iter(train) [  3350/320000]  base_lr: 9.9058e-05 lr: 9.9058e-06  eta: 1 day, 14:59:48  time: 0.4295  data_time: 0.0086  memory: 5150  grad_norm: 122.3841  loss: 15.5070  decode.loss_cls: 0.7010  decode.loss_mask: 0.4420  decode.loss_dice: 0.3217  decode.d0.loss_cls: 1.4984  decode.d0.loss_mask: 0.4633  decode.d0.loss_dice: 0.3611  decode.d1.loss_cls: 0.8516  decode.d1.loss_mask: 0.3996  decode.d1.loss_dice: 0.3096  decode.d2.loss_cls: 0.7939  decode.d2.loss_mask: 0.3938  decode.d2.loss_dice: 0.2914  decode.d3.loss_cls: 0.6875  decode.d3.loss_mask: 0.3930  decode.d3.loss_dice: 0.3077  decode.d4.loss_cls: 0.7066  decode.d4.loss_mask: 0.3754  decode.d4.loss_dice: 0.3031  decode.d5.loss_cls: 0.7308  decode.d5.loss_mask: 0.4116  decode.d5.loss_dice: 0.3211  decode.d6.loss_cls: 0.7579  decode.d6.loss_mask: 0.3888  decode.d6.loss_dice: 0.3156  decode.d7.loss_cls: 0.7395  decode.d7.loss_mask: 0.4066  decode.d7.loss_dice: 0.3190  decode.d8.loss_cls: 0.7955  decode.d8.loss_mask: 0.4080  decode.d8.loss_dice: 0.3118
09/28 14:52:17 - mmengine - INFO - Iter(train) [  3400/320000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 1 day, 14:58:22  time: 0.4295  data_time: 0.0087  memory: 5167  grad_norm: 90.6540  loss: 12.4481  decode.loss_cls: 0.6079  decode.loss_mask: 0.3042  decode.loss_dice: 0.3091  decode.d0.loss_cls: 1.3312  decode.d0.loss_mask: 0.2943  decode.d0.loss_dice: 0.3126  decode.d1.loss_cls: 0.6506  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.2901  decode.d2.loss_cls: 0.5806  decode.d2.loss_mask: 0.2940  decode.d2.loss_dice: 0.2772  decode.d3.loss_cls: 0.5552  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.2653  decode.d4.loss_cls: 0.5466  decode.d4.loss_mask: 0.2926  decode.d4.loss_dice: 0.2758  decode.d5.loss_cls: 0.5813  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.2931  decode.d6.loss_cls: 0.5316  decode.d6.loss_mask: 0.2906  decode.d6.loss_dice: 0.2805  decode.d7.loss_cls: 0.5703  decode.d7.loss_mask: 0.3032  decode.d7.loss_dice: 0.3035  decode.d8.loss_cls: 0.6212  decode.d8.loss_mask: 0.3027  decode.d8.loss_dice: 0.2944
09/28 14:52:39 - mmengine - INFO - Iter(train) [  3450/320000]  base_lr: 9.9029e-05 lr: 9.9029e-06  eta: 1 day, 14:56:58  time: 0.4298  data_time: 0.0089  memory: 5166  grad_norm: 199.0949  loss: 15.0948  decode.loss_cls: 0.7092  decode.loss_mask: 0.4180  decode.loss_dice: 0.4208  decode.d0.loss_cls: 1.2649  decode.d0.loss_mask: 0.4843  decode.d0.loss_dice: 0.4162  decode.d1.loss_cls: 0.6478  decode.d1.loss_mask: 0.3969  decode.d1.loss_dice: 0.3935  decode.d2.loss_cls: 0.5391  decode.d2.loss_mask: 0.3915  decode.d2.loss_dice: 0.3888  decode.d3.loss_cls: 0.5662  decode.d3.loss_mask: 0.4034  decode.d3.loss_dice: 0.3797  decode.d4.loss_cls: 0.5638  decode.d4.loss_mask: 0.4807  decode.d4.loss_dice: 0.4005  decode.d5.loss_cls: 0.5623  decode.d5.loss_mask: 0.4347  decode.d5.loss_dice: 0.3941  decode.d6.loss_cls: 0.6082  decode.d6.loss_mask: 0.4130  decode.d6.loss_dice: 0.3775  decode.d7.loss_cls: 0.6300  decode.d7.loss_mask: 0.4570  decode.d7.loss_dice: 0.4044  decode.d8.loss_cls: 0.6638  decode.d8.loss_mask: 0.4590  decode.d8.loss_dice: 0.4257
09/28 14:53:00 - mmengine - INFO - Iter(train) [  3500/320000]  base_lr: 9.9015e-05 lr: 9.9015e-06  eta: 1 day, 14:55:36  time: 0.4304  data_time: 0.0087  memory: 5150  grad_norm: 180.2299  loss: 15.6110  decode.loss_cls: 0.7100  decode.loss_mask: 0.5179  decode.loss_dice: 0.3721  decode.d0.loss_cls: 1.3397  decode.d0.loss_mask: 0.4757  decode.d0.loss_dice: 0.3909  decode.d1.loss_cls: 0.7176  decode.d1.loss_mask: 0.4828  decode.d1.loss_dice: 0.3747  decode.d2.loss_cls: 0.6293  decode.d2.loss_mask: 0.4508  decode.d2.loss_dice: 0.3656  decode.d3.loss_cls: 0.6479  decode.d3.loss_mask: 0.4413  decode.d3.loss_dice: 0.3368  decode.d4.loss_cls: 0.6343  decode.d4.loss_mask: 0.4473  decode.d4.loss_dice: 0.3514  decode.d5.loss_cls: 0.6766  decode.d5.loss_mask: 0.4606  decode.d5.loss_dice: 0.3393  decode.d6.loss_cls: 0.6622  decode.d6.loss_mask: 0.4425  decode.d6.loss_dice: 0.3639  decode.d7.loss_cls: 0.7032  decode.d7.loss_mask: 0.4172  decode.d7.loss_dice: 0.3360  decode.d8.loss_cls: 0.6963  decode.d8.loss_mask: 0.4633  decode.d8.loss_dice: 0.3638
09/28 14:53:22 - mmengine - INFO - Iter(train) [  3550/320000]  base_lr: 9.9001e-05 lr: 9.9001e-06  eta: 1 day, 14:54:22  time: 0.4308  data_time: 0.0088  memory: 5167  grad_norm: 314.2751  loss: 16.8832  decode.loss_cls: 0.7041  decode.loss_mask: 0.5978  decode.loss_dice: 0.3560  decode.d0.loss_cls: 1.2602  decode.d0.loss_mask: 0.6248  decode.d0.loss_dice: 0.4069  decode.d1.loss_cls: 0.7456  decode.d1.loss_mask: 0.5438  decode.d1.loss_dice: 0.3567  decode.d2.loss_cls: 0.6694  decode.d2.loss_mask: 0.5876  decode.d2.loss_dice: 0.3678  decode.d3.loss_cls: 0.6764  decode.d3.loss_mask: 0.5774  decode.d3.loss_dice: 0.3601  decode.d4.loss_cls: 0.6142  decode.d4.loss_mask: 0.5828  decode.d4.loss_dice: 0.3751  decode.d5.loss_cls: 0.5521  decode.d5.loss_mask: 0.6041  decode.d5.loss_dice: 0.3783  decode.d6.loss_cls: 0.6742  decode.d6.loss_mask: 0.6156  decode.d6.loss_dice: 0.3678  decode.d7.loss_cls: 0.6289  decode.d7.loss_mask: 0.6190  decode.d7.loss_dice: 0.3684  decode.d8.loss_cls: 0.6832  decode.d8.loss_mask: 0.6210  decode.d8.loss_dice: 0.3642
09/28 14:53:43 - mmengine - INFO - Iter(train) [  3600/320000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 1 day, 14:53:05  time: 0.4299  data_time: 0.0088  memory: 5186  grad_norm: 162.0402  loss: 10.9957  decode.loss_cls: 0.4652  decode.loss_mask: 0.3122  decode.loss_dice: 0.2663  decode.d0.loss_cls: 1.1274  decode.d0.loss_mask: 0.3175  decode.d0.loss_dice: 0.3211  decode.d1.loss_cls: 0.4947  decode.d1.loss_mask: 0.3207  decode.d1.loss_dice: 0.2740  decode.d2.loss_cls: 0.4754  decode.d2.loss_mask: 0.3126  decode.d2.loss_dice: 0.2722  decode.d3.loss_cls: 0.4603  decode.d3.loss_mask: 0.3109  decode.d3.loss_dice: 0.2740  decode.d4.loss_cls: 0.4784  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.2659  decode.d5.loss_cls: 0.4293  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.2642  decode.d6.loss_cls: 0.3828  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.2716  decode.d7.loss_cls: 0.4369  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.2773  decode.d8.loss_cls: 0.3974  decode.d8.loss_mask: 0.3076  decode.d8.loss_dice: 0.2557
09/28 14:54:05 - mmengine - INFO - Iter(train) [  3650/320000]  base_lr: 9.8973e-05 lr: 9.8973e-06  eta: 1 day, 14:51:50  time: 0.4300  data_time: 0.0088  memory: 5166  grad_norm: 130.9601  loss: 16.3164  decode.loss_cls: 0.8105  decode.loss_mask: 0.4446  decode.loss_dice: 0.3598  decode.d0.loss_cls: 1.3866  decode.d0.loss_mask: 0.4099  decode.d0.loss_dice: 0.3964  decode.d1.loss_cls: 0.7709  decode.d1.loss_mask: 0.4361  decode.d1.loss_dice: 0.4005  decode.d2.loss_cls: 0.7867  decode.d2.loss_mask: 0.4504  decode.d2.loss_dice: 0.3653  decode.d3.loss_cls: 0.7167  decode.d3.loss_mask: 0.4292  decode.d3.loss_dice: 0.3585  decode.d4.loss_cls: 0.7888  decode.d4.loss_mask: 0.4338  decode.d4.loss_dice: 0.3697  decode.d5.loss_cls: 0.7017  decode.d5.loss_mask: 0.4990  decode.d5.loss_dice: 0.3524  decode.d6.loss_cls: 0.7895  decode.d6.loss_mask: 0.4396  decode.d6.loss_dice: 0.3478  decode.d7.loss_cls: 0.7821  decode.d7.loss_mask: 0.4231  decode.d7.loss_dice: 0.3459  decode.d8.loss_cls: 0.7564  decode.d8.loss_mask: 0.4129  decode.d8.loss_dice: 0.3517
09/28 14:54:26 - mmengine - INFO - Iter(train) [  3700/320000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 1 day, 14:50:35  time: 0.4304  data_time: 0.0088  memory: 5167  grad_norm: 115.6198  loss: 11.7720  decode.loss_cls: 0.5186  decode.loss_mask: 0.2881  decode.loss_dice: 0.2450  decode.d0.loss_cls: 1.3077  decode.d0.loss_mask: 0.2918  decode.d0.loss_dice: 0.2688  decode.d1.loss_cls: 0.6619  decode.d1.loss_mask: 0.2857  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.6049  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.2291  decode.d3.loss_cls: 0.5369  decode.d3.loss_mask: 0.2884  decode.d3.loss_dice: 0.2295  decode.d4.loss_cls: 0.5641  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.5523  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.2532  decode.d6.loss_cls: 0.5651  decode.d6.loss_mask: 0.3430  decode.d6.loss_dice: 0.2432  decode.d7.loss_cls: 0.5597  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.2319  decode.d8.loss_cls: 0.5971  decode.d8.loss_mask: 0.2833  decode.d8.loss_dice: 0.2249
09/28 14:54:48 - mmengine - INFO - Iter(train) [  3750/320000]  base_lr: 9.8945e-05 lr: 9.8945e-06  eta: 1 day, 14:49:22  time: 0.4304  data_time: 0.0088  memory: 5186  grad_norm: 86.9365  loss: 13.3158  decode.loss_cls: 0.6351  decode.loss_mask: 0.2875  decode.loss_dice: 0.3464  decode.d0.loss_cls: 1.2805  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.4074  decode.d1.loss_cls: 0.5887  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.3428  decode.d2.loss_cls: 0.5353  decode.d2.loss_mask: 0.2847  decode.d2.loss_dice: 0.3394  decode.d3.loss_cls: 0.5296  decode.d3.loss_mask: 0.2894  decode.d3.loss_dice: 0.3527  decode.d4.loss_cls: 0.6179  decode.d4.loss_mask: 0.2911  decode.d4.loss_dice: 0.3783  decode.d5.loss_cls: 0.6469  decode.d5.loss_mask: 0.2873  decode.d5.loss_dice: 0.3727  decode.d6.loss_cls: 0.6402  decode.d6.loss_mask: 0.2943  decode.d6.loss_dice: 0.3685  decode.d7.loss_cls: 0.6391  decode.d7.loss_mask: 0.2951  decode.d7.loss_dice: 0.3500  decode.d8.loss_cls: 0.6371  decode.d8.loss_mask: 0.3082  decode.d8.loss_dice: 0.3913
09/28 14:55:09 - mmengine - INFO - Iter(train) [  3800/320000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 1 day, 14:48:12  time: 0.4297  data_time: 0.0088  memory: 5166  grad_norm: 89.8014  loss: 10.1620  decode.loss_cls: 0.4372  decode.loss_mask: 0.2471  decode.loss_dice: 0.3065  decode.d0.loss_cls: 1.1320  decode.d0.loss_mask: 0.2557  decode.d0.loss_dice: 0.3255  decode.d1.loss_cls: 0.4146  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.2795  decode.d2.loss_cls: 0.3751  decode.d2.loss_mask: 0.2533  decode.d2.loss_dice: 0.3283  decode.d3.loss_cls: 0.3718  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.3025  decode.d4.loss_cls: 0.3390  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.3512  decode.d5.loss_mask: 0.2464  decode.d5.loss_dice: 0.2986  decode.d6.loss_cls: 0.3979  decode.d6.loss_mask: 0.2475  decode.d6.loss_dice: 0.3046  decode.d7.loss_cls: 0.4007  decode.d7.loss_mask: 0.2511  decode.d7.loss_dice: 0.2998  decode.d8.loss_cls: 0.4134  decode.d8.loss_mask: 0.2541  decode.d8.loss_dice: 0.2859
09/28 14:55:31 - mmengine - INFO - Iter(train) [  3850/320000]  base_lr: 9.8917e-05 lr: 9.8917e-06  eta: 1 day, 14:47:01  time: 0.4294  data_time: 0.0088  memory: 5167  grad_norm: 164.1934  loss: 13.9838  decode.loss_cls: 0.6133  decode.loss_mask: 0.3135  decode.loss_dice: 0.3629  decode.d0.loss_cls: 1.2939  decode.d0.loss_mask: 0.3390  decode.d0.loss_dice: 0.4162  decode.d1.loss_cls: 0.7259  decode.d1.loss_mask: 0.2743  decode.d1.loss_dice: 0.3348  decode.d2.loss_cls: 0.6033  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.3263  decode.d3.loss_cls: 0.5726  decode.d3.loss_mask: 0.3366  decode.d3.loss_dice: 0.3516  decode.d4.loss_cls: 0.5873  decode.d4.loss_mask: 0.3748  decode.d4.loss_dice: 0.3679  decode.d5.loss_cls: 0.6106  decode.d5.loss_mask: 0.3392  decode.d5.loss_dice: 0.3874  decode.d6.loss_cls: 0.6478  decode.d6.loss_mask: 0.3362  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.6232  decode.d7.loss_mask: 0.4317  decode.d7.loss_dice: 0.4113  decode.d8.loss_cls: 0.5570  decode.d8.loss_mask: 0.3772  decode.d8.loss_dice: 0.4160
09/28 14:55:52 - mmengine - INFO - Iter(train) [  3900/320000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 1 day, 14:45:51  time: 0.4296  data_time: 0.0087  memory: 5201  grad_norm: 105.0493  loss: 14.9877  decode.loss_cls: 0.7164  decode.loss_mask: 0.3705  decode.loss_dice: 0.3336  decode.d0.loss_cls: 1.4455  decode.d0.loss_mask: 0.3448  decode.d0.loss_dice: 0.3264  decode.d1.loss_cls: 0.7503  decode.d1.loss_mask: 0.3438  decode.d1.loss_dice: 0.3412  decode.d2.loss_cls: 0.7299  decode.d2.loss_mask: 0.3364  decode.d2.loss_dice: 0.3428  decode.d3.loss_cls: 0.7534  decode.d3.loss_mask: 0.3502  decode.d3.loss_dice: 0.3466  decode.d4.loss_cls: 0.7282  decode.d4.loss_mask: 0.3559  decode.d4.loss_dice: 0.3377  decode.d5.loss_cls: 0.7214  decode.d5.loss_mask: 0.3547  decode.d5.loss_dice: 0.3515  decode.d6.loss_cls: 0.7318  decode.d6.loss_mask: 0.3754  decode.d6.loss_dice: 0.3427  decode.d7.loss_cls: 0.7478  decode.d7.loss_mask: 0.3497  decode.d7.loss_dice: 0.3444  decode.d8.loss_cls: 0.7051  decode.d8.loss_mask: 0.3592  decode.d8.loss_dice: 0.3505
09/28 14:56:14 - mmengine - INFO - Iter(train) [  3950/320000]  base_lr: 9.8889e-05 lr: 9.8889e-06  eta: 1 day, 14:44:44  time: 0.4301  data_time: 0.0088  memory: 5186  grad_norm: 128.8459  loss: 15.5511  decode.loss_cls: 0.5982  decode.loss_mask: 0.5047  decode.loss_dice: 0.3077  decode.d0.loss_cls: 1.4637  decode.d0.loss_mask: 0.4655  decode.d0.loss_dice: 0.3950  decode.d1.loss_cls: 0.7254  decode.d1.loss_mask: 0.3946  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.7171  decode.d2.loss_mask: 0.5064  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.8015  decode.d3.loss_mask: 0.4286  decode.d3.loss_dice: 0.3245  decode.d4.loss_cls: 0.6664  decode.d4.loss_mask: 0.5263  decode.d4.loss_dice: 0.3160  decode.d5.loss_cls: 0.6827  decode.d5.loss_mask: 0.5086  decode.d5.loss_dice: 0.3247  decode.d6.loss_cls: 0.6509  decode.d6.loss_mask: 0.4637  decode.d6.loss_dice: 0.3045  decode.d7.loss_cls: 0.6588  decode.d7.loss_mask: 0.4469  decode.d7.loss_dice: 0.3142  decode.d8.loss_cls: 0.5902  decode.d8.loss_mask: 0.4989  decode.d8.loss_dice: 0.2960
09/28 14:56:35 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 14:56:35 - mmengine - INFO - Iter(train) [  4000/320000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 1 day, 14:43:35  time: 0.4297  data_time: 0.0087  memory: 5186  grad_norm: 122.4164  loss: 12.5179  decode.loss_cls: 0.5946  decode.loss_mask: 0.3293  decode.loss_dice: 0.2834  decode.d0.loss_cls: 1.1794  decode.d0.loss_mask: 0.3537  decode.d0.loss_dice: 0.2758  decode.d1.loss_cls: 0.6472  decode.d1.loss_mask: 0.3122  decode.d1.loss_dice: 0.2887  decode.d2.loss_cls: 0.5437  decode.d2.loss_mask: 0.3260  decode.d2.loss_dice: 0.2852  decode.d3.loss_cls: 0.5354  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.5752  decode.d4.loss_mask: 0.3231  decode.d4.loss_dice: 0.2942  decode.d5.loss_cls: 0.5379  decode.d5.loss_mask: 0.3285  decode.d5.loss_dice: 0.2717  decode.d6.loss_cls: 0.5727  decode.d6.loss_mask: 0.3373  decode.d6.loss_dice: 0.2748  decode.d7.loss_cls: 0.6236  decode.d7.loss_mask: 0.3282  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.6132  decode.d8.loss_mask: 0.3363  decode.d8.loss_dice: 0.2761
09/28 14:56:57 - mmengine - INFO - Iter(train) [  4050/320000]  base_lr: 9.8860e-05 lr: 9.8860e-06  eta: 1 day, 14:42:29  time: 0.4298  data_time: 0.0087  memory: 5166  grad_norm: 143.8885  loss: 12.8406  decode.loss_cls: 0.5562  decode.loss_mask: 0.3384  decode.loss_dice: 0.2942  decode.d0.loss_cls: 1.2573  decode.d0.loss_mask: 0.3232  decode.d0.loss_dice: 0.3331  decode.d1.loss_cls: 0.6616  decode.d1.loss_mask: 0.3166  decode.d1.loss_dice: 0.2852  decode.d2.loss_cls: 0.6328  decode.d2.loss_mask: 0.3202  decode.d2.loss_dice: 0.2818  decode.d3.loss_cls: 0.5617  decode.d3.loss_mask: 0.3190  decode.d3.loss_dice: 0.2711  decode.d4.loss_cls: 0.6305  decode.d4.loss_mask: 0.3211  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.6406  decode.d5.loss_mask: 0.3099  decode.d5.loss_dice: 0.2675  decode.d6.loss_cls: 0.5740  decode.d6.loss_mask: 0.3251  decode.d6.loss_dice: 0.2856  decode.d7.loss_cls: 0.5857  decode.d7.loss_mask: 0.3276  decode.d7.loss_dice: 0.2803  decode.d8.loss_cls: 0.6287  decode.d8.loss_mask: 0.3302  decode.d8.loss_dice: 0.3049
09/28 14:57:19 - mmengine - INFO - Iter(train) [  4100/320000]  base_lr: 9.8846e-05 lr: 9.8846e-06  eta: 1 day, 14:42:26  time: 0.4685  data_time: 0.0088  memory: 5186  grad_norm: 111.3340  loss: 11.8920  decode.loss_cls: 0.5182  decode.loss_mask: 0.3309  decode.loss_dice: 0.2401  decode.d0.loss_cls: 1.5063  decode.d0.loss_mask: 0.3226  decode.d0.loss_dice: 0.3139  decode.d1.loss_cls: 0.6845  decode.d1.loss_mask: 0.3197  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.5132  decode.d2.loss_mask: 0.3368  decode.d2.loss_dice: 0.2424  decode.d3.loss_cls: 0.4930  decode.d3.loss_mask: 0.3287  decode.d3.loss_dice: 0.2386  decode.d4.loss_cls: 0.4092  decode.d4.loss_mask: 0.3473  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.4687  decode.d5.loss_mask: 0.3225  decode.d5.loss_dice: 0.2389  decode.d6.loss_cls: 0.4764  decode.d6.loss_mask: 0.3213  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.4908  decode.d7.loss_mask: 0.3266  decode.d7.loss_dice: 0.2623  decode.d8.loss_cls: 0.5176  decode.d8.loss_mask: 0.3326  decode.d8.loss_dice: 0.2485
09/28 14:57:43 - mmengine - INFO - Iter(train) [  4150/320000]  base_lr: 9.8832e-05 lr: 9.8832e-06  eta: 1 day, 14:43:49  time: 0.4687  data_time: 0.0084  memory: 5167  grad_norm: 225.3725  loss: 14.6353  decode.loss_cls: 0.6774  decode.loss_mask: 0.4334  decode.loss_dice: 0.3150  decode.d0.loss_cls: 1.4095  decode.d0.loss_mask: 0.4217  decode.d0.loss_dice: 0.3176  decode.d1.loss_cls: 0.6087  decode.d1.loss_mask: 0.4643  decode.d1.loss_dice: 0.3684  decode.d2.loss_cls: 0.4874  decode.d2.loss_mask: 0.5057  decode.d2.loss_dice: 0.3415  decode.d3.loss_cls: 0.5554  decode.d3.loss_mask: 0.5215  decode.d3.loss_dice: 0.3299  decode.d4.loss_cls: 0.5911  decode.d4.loss_mask: 0.4378  decode.d4.loss_dice: 0.3205  decode.d5.loss_cls: 0.5885  decode.d5.loss_mask: 0.4298  decode.d5.loss_dice: 0.3144  decode.d6.loss_cls: 0.6233  decode.d6.loss_mask: 0.4403  decode.d6.loss_dice: 0.3209  decode.d7.loss_cls: 0.6199  decode.d7.loss_mask: 0.4458  decode.d7.loss_dice: 0.3206  decode.d8.loss_cls: 0.6959  decode.d8.loss_mask: 0.4144  decode.d8.loss_dice: 0.3147
09/28 14:58:06 - mmengine - INFO - Iter(train) [  4200/320000]  base_lr: 9.8818e-05 lr: 9.8818e-06  eta: 1 day, 14:45:06  time: 0.4690  data_time: 0.0091  memory: 5166  grad_norm: 153.2791  loss: 10.4112  decode.loss_cls: 0.4247  decode.loss_mask: 0.3168  decode.loss_dice: 0.2347  decode.d0.loss_cls: 1.0987  decode.d0.loss_mask: 0.3361  decode.d0.loss_dice: 0.2933  decode.d1.loss_cls: 0.4969  decode.d1.loss_mask: 0.3250  decode.d1.loss_dice: 0.2398  decode.d2.loss_cls: 0.4173  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.3670  decode.d3.loss_mask: 0.3245  decode.d3.loss_dice: 0.2304  decode.d4.loss_cls: 0.3847  decode.d4.loss_mask: 0.3220  decode.d4.loss_dice: 0.2406  decode.d5.loss_cls: 0.3723  decode.d5.loss_mask: 0.3298  decode.d5.loss_dice: 0.2457  decode.d6.loss_cls: 0.3838  decode.d6.loss_mask: 0.3209  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.4436  decode.d7.loss_mask: 0.3143  decode.d7.loss_dice: 0.2282  decode.d8.loss_cls: 0.4053  decode.d8.loss_mask: 0.3138  decode.d8.loss_dice: 0.2182
09/28 14:58:29 - mmengine - INFO - Iter(train) [  4250/320000]  base_lr: 9.8804e-05 lr: 9.8804e-06  eta: 1 day, 14:45:57  time: 0.4367  data_time: 0.0086  memory: 5167  grad_norm: 118.7185  loss: 12.2602  decode.loss_cls: 0.5755  decode.loss_mask: 0.2737  decode.loss_dice: 0.2520  decode.d0.loss_cls: 1.2762  decode.d0.loss_mask: 0.3015  decode.d0.loss_dice: 0.3261  decode.d1.loss_cls: 0.5725  decode.d1.loss_mask: 0.3014  decode.d1.loss_dice: 0.2677  decode.d2.loss_cls: 0.5375  decode.d2.loss_mask: 0.3253  decode.d2.loss_dice: 0.2738  decode.d3.loss_cls: 0.5506  decode.d3.loss_mask: 0.3445  decode.d3.loss_dice: 0.2751  decode.d4.loss_cls: 0.5608  decode.d4.loss_mask: 0.3134  decode.d4.loss_dice: 0.2668  decode.d5.loss_cls: 0.5433  decode.d5.loss_mask: 0.3369  decode.d5.loss_dice: 0.2557  decode.d6.loss_cls: 0.6289  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.2596  decode.d7.loss_cls: 0.5903  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.2673  decode.d8.loss_cls: 0.5729  decode.d8.loss_mask: 0.3160  decode.d8.loss_dice: 0.2480
09/28 14:58:51 - mmengine - INFO - Iter(train) [  4300/320000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 1 day, 14:44:51  time: 0.4298  data_time: 0.0089  memory: 5167  grad_norm: 190.1470  loss: 16.0382  decode.loss_cls: 0.7070  decode.loss_mask: 0.4451  decode.loss_dice: 0.4708  decode.d0.loss_cls: 1.0395  decode.d0.loss_mask: 0.4179  decode.d0.loss_dice: 0.4302  decode.d1.loss_cls: 0.7614  decode.d1.loss_mask: 0.3908  decode.d1.loss_dice: 0.4180  decode.d2.loss_cls: 0.6957  decode.d2.loss_mask: 0.4074  decode.d2.loss_dice: 0.4357  decode.d3.loss_cls: 0.6257  decode.d3.loss_mask: 0.4142  decode.d3.loss_dice: 0.4330  decode.d4.loss_cls: 0.5724  decode.d4.loss_mask: 0.4152  decode.d4.loss_dice: 0.4542  decode.d5.loss_cls: 0.6072  decode.d5.loss_mask: 0.3973  decode.d5.loss_dice: 0.4438  decode.d6.loss_cls: 0.7214  decode.d6.loss_mask: 0.4082  decode.d6.loss_dice: 0.4578  decode.d7.loss_cls: 0.7444  decode.d7.loss_mask: 0.4895  decode.d7.loss_dice: 0.4777  decode.d8.loss_cls: 0.6924  decode.d8.loss_mask: 0.5742  decode.d8.loss_dice: 0.4899
09/28 14:59:12 - mmengine - INFO - Iter(train) [  4350/320000]  base_lr: 9.8776e-05 lr: 9.8776e-06  eta: 1 day, 14:43:46  time: 0.4299  data_time: 0.0088  memory: 5150  grad_norm: 168.3925  loss: 17.3190  decode.loss_cls: 0.9096  decode.loss_mask: 0.4765  decode.loss_dice: 0.3754  decode.d0.loss_cls: 1.5124  decode.d0.loss_mask: 0.4422  decode.d0.loss_dice: 0.3919  decode.d1.loss_cls: 0.7930  decode.d1.loss_mask: 0.4373  decode.d1.loss_dice: 0.3467  decode.d2.loss_cls: 0.8694  decode.d2.loss_mask: 0.4097  decode.d2.loss_dice: 0.3485  decode.d3.loss_cls: 0.7966  decode.d3.loss_mask: 0.4285  decode.d3.loss_dice: 0.3440  decode.d4.loss_cls: 0.8161  decode.d4.loss_mask: 0.4622  decode.d4.loss_dice: 0.3570  decode.d5.loss_cls: 0.8299  decode.d5.loss_mask: 0.5097  decode.d5.loss_dice: 0.3619  decode.d6.loss_cls: 0.8289  decode.d6.loss_mask: 0.4919  decode.d6.loss_dice: 0.3730  decode.d7.loss_cls: 0.8075  decode.d7.loss_mask: 0.4922  decode.d7.loss_dice: 0.4089  decode.d8.loss_cls: 0.8387  decode.d8.loss_mask: 0.4801  decode.d8.loss_dice: 0.3795
09/28 14:59:34 - mmengine - INFO - Iter(train) [  4400/320000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 1 day, 14:42:41  time: 0.4298  data_time: 0.0087  memory: 5167  grad_norm: 93.7796  loss: 11.1051  decode.loss_cls: 0.5223  decode.loss_mask: 0.2773  decode.loss_dice: 0.2777  decode.d0.loss_cls: 1.2471  decode.d0.loss_mask: 0.3171  decode.d0.loss_dice: 0.3267  decode.d1.loss_cls: 0.5131  decode.d1.loss_mask: 0.2760  decode.d1.loss_dice: 0.2895  decode.d2.loss_cls: 0.4317  decode.d2.loss_mask: 0.2732  decode.d2.loss_dice: 0.2766  decode.d3.loss_cls: 0.3609  decode.d3.loss_mask: 0.2723  decode.d3.loss_dice: 0.2870  decode.d4.loss_cls: 0.4233  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.2819  decode.d5.loss_cls: 0.4787  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.2961  decode.d6.loss_cls: 0.4615  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.2869  decode.d7.loss_cls: 0.5065  decode.d7.loss_mask: 0.2751  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.4696  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.2817
09/28 14:59:55 - mmengine - INFO - Iter(train) [  4450/320000]  base_lr: 9.8748e-05 lr: 9.8748e-06  eta: 1 day, 14:41:38  time: 0.4298  data_time: 0.0087  memory: 5166  grad_norm: 210.8577  loss: 16.5855  decode.loss_cls: 0.7937  decode.loss_mask: 0.5633  decode.loss_dice: 0.3706  decode.d0.loss_cls: 1.2233  decode.d0.loss_mask: 0.4514  decode.d0.loss_dice: 0.3739  decode.d1.loss_cls: 0.7269  decode.d1.loss_mask: 0.4784  decode.d1.loss_dice: 0.3666  decode.d2.loss_cls: 0.6730  decode.d2.loss_mask: 0.4764  decode.d2.loss_dice: 0.3619  decode.d3.loss_cls: 0.6867  decode.d3.loss_mask: 0.4593  decode.d3.loss_dice: 0.3616  decode.d4.loss_cls: 0.6940  decode.d4.loss_mask: 0.4920  decode.d4.loss_dice: 0.3503  decode.d5.loss_cls: 0.7491  decode.d5.loss_mask: 0.4994  decode.d5.loss_dice: 0.3457  decode.d6.loss_cls: 0.7283  decode.d6.loss_mask: 0.5442  decode.d6.loss_dice: 0.3770  decode.d7.loss_cls: 0.7681  decode.d7.loss_mask: 0.5195  decode.d7.loss_dice: 0.3719  decode.d8.loss_cls: 0.7971  decode.d8.loss_mask: 0.6133  decode.d8.loss_dice: 0.3686
09/28 15:00:17 - mmengine - INFO - Iter(train) [  4500/320000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 1 day, 14:40:36  time: 0.4310  data_time: 0.0088  memory: 5166  grad_norm: 99.5761  loss: 11.4974  decode.loss_cls: 0.4464  decode.loss_mask: 0.4283  decode.loss_dice: 0.3367  decode.d0.loss_cls: 1.1655  decode.d0.loss_mask: 0.2790  decode.d0.loss_dice: 0.2902  decode.d1.loss_cls: 0.5944  decode.d1.loss_mask: 0.2805  decode.d1.loss_dice: 0.2818  decode.d2.loss_cls: 0.4753  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.3020  decode.d3.loss_cls: 0.4771  decode.d3.loss_mask: 0.2813  decode.d3.loss_dice: 0.2654  decode.d4.loss_cls: 0.4466  decode.d4.loss_mask: 0.2953  decode.d4.loss_dice: 0.2880  decode.d5.loss_cls: 0.4598  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.2865  decode.d6.loss_cls: 0.4729  decode.d6.loss_mask: 0.2782  decode.d6.loss_dice: 0.2995  decode.d7.loss_cls: 0.4674  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.2797  decode.d8.loss_cls: 0.4600  decode.d8.loss_mask: 0.3924  decode.d8.loss_dice: 0.3103
09/28 15:00:38 - mmengine - INFO - Iter(train) [  4550/320000]  base_lr: 9.8720e-05 lr: 9.8720e-06  eta: 1 day, 14:39:47  time: 0.4300  data_time: 0.0087  memory: 5167  grad_norm: 106.2744  loss: 15.4198  decode.loss_cls: 0.7588  decode.loss_mask: 0.4512  decode.loss_dice: 0.3211  decode.d0.loss_cls: 1.4211  decode.d0.loss_mask: 0.4005  decode.d0.loss_dice: 0.3375  decode.d1.loss_cls: 0.7085  decode.d1.loss_mask: 0.3871  decode.d1.loss_dice: 0.3181  decode.d2.loss_cls: 0.7236  decode.d2.loss_mask: 0.3846  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.7730  decode.d3.loss_mask: 0.4239  decode.d3.loss_dice: 0.3137  decode.d4.loss_cls: 0.7250  decode.d4.loss_mask: 0.3973  decode.d4.loss_dice: 0.3264  decode.d5.loss_cls: 0.8111  decode.d5.loss_mask: 0.3762  decode.d5.loss_dice: 0.3185  decode.d6.loss_cls: 0.8337  decode.d6.loss_mask: 0.3876  decode.d6.loss_dice: 0.3024  decode.d7.loss_cls: 0.7330  decode.d7.loss_mask: 0.3875  decode.d7.loss_dice: 0.2975  decode.d8.loss_cls: 0.7659  decode.d8.loss_mask: 0.3954  decode.d8.loss_dice: 0.3276
09/28 15:01:00 - mmengine - INFO - Iter(train) [  4600/320000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 1 day, 14:38:45  time: 0.4290  data_time: 0.0087  memory: 5167  grad_norm: 126.8438  loss: 12.9779  decode.loss_cls: 0.6603  decode.loss_mask: 0.3392  decode.loss_dice: 0.2661  decode.d0.loss_cls: 1.2724  decode.d0.loss_mask: 0.3524  decode.d0.loss_dice: 0.2681  decode.d1.loss_cls: 0.7622  decode.d1.loss_mask: 0.3336  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.6327  decode.d2.loss_mask: 0.3399  decode.d2.loss_dice: 0.2887  decode.d3.loss_cls: 0.6040  decode.d3.loss_mask: 0.3253  decode.d3.loss_dice: 0.2750  decode.d4.loss_cls: 0.6188  decode.d4.loss_mask: 0.3306  decode.d4.loss_dice: 0.2697  decode.d5.loss_cls: 0.6003  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.2766  decode.d6.loss_cls: 0.5897  decode.d6.loss_mask: 0.3258  decode.d6.loss_dice: 0.2656  decode.d7.loss_cls: 0.5775  decode.d7.loss_mask: 0.3335  decode.d7.loss_dice: 0.2784  decode.d8.loss_cls: 0.6001  decode.d8.loss_mask: 0.3381  decode.d8.loss_dice: 0.2465
09/28 15:01:21 - mmengine - INFO - Iter(train) [  4650/320000]  base_lr: 9.8692e-05 lr: 9.8692e-06  eta: 1 day, 14:37:45  time: 0.4302  data_time: 0.0088  memory: 5166  grad_norm: 109.6605  loss: 13.9598  decode.loss_cls: 0.5031  decode.loss_mask: 0.4241  decode.loss_dice: 0.4610  decode.d0.loss_cls: 1.1797  decode.d0.loss_mask: 0.4399  decode.d0.loss_dice: 0.4765  decode.d1.loss_cls: 0.5036  decode.d1.loss_mask: 0.4407  decode.d1.loss_dice: 0.4737  decode.d2.loss_cls: 0.4288  decode.d2.loss_mask: 0.4275  decode.d2.loss_dice: 0.4401  decode.d3.loss_cls: 0.3936  decode.d3.loss_mask: 0.4196  decode.d3.loss_dice: 0.4264  decode.d4.loss_cls: 0.4138  decode.d4.loss_mask: 0.4368  decode.d4.loss_dice: 0.4273  decode.d5.loss_cls: 0.4257  decode.d5.loss_mask: 0.4184  decode.d5.loss_dice: 0.4299  decode.d6.loss_cls: 0.4786  decode.d6.loss_mask: 0.4222  decode.d6.loss_dice: 0.4508  decode.d7.loss_cls: 0.4792  decode.d7.loss_mask: 0.4139  decode.d7.loss_dice: 0.4330  decode.d8.loss_cls: 0.4394  decode.d8.loss_mask: 0.4132  decode.d8.loss_dice: 0.4395
09/28 15:01:43 - mmengine - INFO - Iter(train) [  4700/320000]  base_lr: 9.8677e-05 lr: 9.8677e-06  eta: 1 day, 14:36:44  time: 0.4294  data_time: 0.0087  memory: 5167  grad_norm: 135.0924  loss: 13.7479  decode.loss_cls: 0.6058  decode.loss_mask: 0.3106  decode.loss_dice: 0.3905  decode.d0.loss_cls: 1.2794  decode.d0.loss_mask: 0.2902  decode.d0.loss_dice: 0.4275  decode.d1.loss_cls: 0.6552  decode.d1.loss_mask: 0.3210  decode.d1.loss_dice: 0.3882  decode.d2.loss_cls: 0.5974  decode.d2.loss_mask: 0.3094  decode.d2.loss_dice: 0.3833  decode.d3.loss_cls: 0.5738  decode.d3.loss_mask: 0.2999  decode.d3.loss_dice: 0.3765  decode.d4.loss_cls: 0.6387  decode.d4.loss_mask: 0.3067  decode.d4.loss_dice: 0.3670  decode.d5.loss_cls: 0.5932  decode.d5.loss_mask: 0.3087  decode.d5.loss_dice: 0.4024  decode.d6.loss_cls: 0.6136  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.3872  decode.d7.loss_cls: 0.6090  decode.d7.loss_mask: 0.3097  decode.d7.loss_dice: 0.3890  decode.d8.loss_cls: 0.6225  decode.d8.loss_mask: 0.3015  decode.d8.loss_dice: 0.3857
09/28 15:02:04 - mmengine - INFO - Iter(train) [  4750/320000]  base_lr: 9.8663e-05 lr: 9.8663e-06  eta: 1 day, 14:35:46  time: 0.4306  data_time: 0.0090  memory: 5186  grad_norm: 150.6472  loss: 11.8431  decode.loss_cls: 0.5204  decode.loss_mask: 0.2937  decode.loss_dice: 0.2666  decode.d0.loss_cls: 1.4513  decode.d0.loss_mask: 0.3022  decode.d0.loss_dice: 0.3002  decode.d1.loss_cls: 0.5799  decode.d1.loss_mask: 0.2974  decode.d1.loss_dice: 0.2499  decode.d2.loss_cls: 0.5703  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.2656  decode.d3.loss_cls: 0.5184  decode.d3.loss_mask: 0.2818  decode.d3.loss_dice: 0.2537  decode.d4.loss_cls: 0.4906  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.5467  decode.d5.loss_mask: 0.2811  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.5035  decode.d6.loss_mask: 0.2852  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.5449  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.2810  decode.d8.loss_cls: 0.5339  decode.d8.loss_mask: 0.2921  decode.d8.loss_dice: 0.2621
09/28 15:02:26 - mmengine - INFO - Iter(train) [  4800/320000]  base_lr: 9.8649e-05 lr: 9.8649e-06  eta: 1 day, 14:34:46  time: 0.4288  data_time: 0.0088  memory: 5150  grad_norm: 69.5979  loss: 10.4143  decode.loss_cls: 0.4335  decode.loss_mask: 0.2820  decode.loss_dice: 0.3210  decode.d0.loss_cls: 0.9918  decode.d0.loss_mask: 0.2775  decode.d0.loss_dice: 0.3240  decode.d1.loss_cls: 0.4559  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.3020  decode.d2.loss_cls: 0.3894  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.3196  decode.d3.loss_cls: 0.3002  decode.d3.loss_mask: 0.2688  decode.d3.loss_dice: 0.3185  decode.d4.loss_cls: 0.3293  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.3210  decode.d5.loss_cls: 0.3781  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.3122  decode.d6.loss_cls: 0.4477  decode.d6.loss_mask: 0.2752  decode.d6.loss_dice: 0.3094  decode.d7.loss_cls: 0.3856  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.3121  decode.d8.loss_cls: 0.4160  decode.d8.loss_mask: 0.2748  decode.d8.loss_dice: 0.3159
09/28 15:02:47 - mmengine - INFO - Iter(train) [  4850/320000]  base_lr: 9.8635e-05 lr: 9.8635e-06  eta: 1 day, 14:33:50  time: 0.4301  data_time: 0.0087  memory: 5167  grad_norm: 117.5360  loss: 13.4926  decode.loss_cls: 0.5836  decode.loss_mask: 0.3580  decode.loss_dice: 0.3131  decode.d0.loss_cls: 1.4087  decode.d0.loss_mask: 0.3882  decode.d0.loss_dice: 0.3904  decode.d1.loss_cls: 0.5706  decode.d1.loss_mask: 0.3542  decode.d1.loss_dice: 0.3508  decode.d2.loss_cls: 0.5389  decode.d2.loss_mask: 0.3521  decode.d2.loss_dice: 0.3394  decode.d3.loss_cls: 0.5695  decode.d3.loss_mask: 0.3562  decode.d3.loss_dice: 0.3225  decode.d4.loss_cls: 0.5556  decode.d4.loss_mask: 0.3423  decode.d4.loss_dice: 0.3774  decode.d5.loss_cls: 0.6145  decode.d5.loss_mask: 0.3735  decode.d5.loss_dice: 0.3442  decode.d6.loss_cls: 0.5141  decode.d6.loss_mask: 0.3572  decode.d6.loss_dice: 0.3121  decode.d7.loss_cls: 0.5131  decode.d7.loss_mask: 0.3661  decode.d7.loss_dice: 0.3368  decode.d8.loss_cls: 0.5770  decode.d8.loss_mask: 0.3754  decode.d8.loss_dice: 0.3371
09/28 15:03:09 - mmengine - INFO - Iter(train) [  4900/320000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 1 day, 14:32:53  time: 0.4306  data_time: 0.0088  memory: 5186  grad_norm: 167.7029  loss: 14.3509  decode.loss_cls: 0.5799  decode.loss_mask: 0.3639  decode.loss_dice: 0.3527  decode.d0.loss_cls: 1.3362  decode.d0.loss_mask: 0.3659  decode.d0.loss_dice: 0.4396  decode.d1.loss_cls: 0.6577  decode.d1.loss_mask: 0.3461  decode.d1.loss_dice: 0.3791  decode.d2.loss_cls: 0.5888  decode.d2.loss_mask: 0.3739  decode.d2.loss_dice: 0.3622  decode.d3.loss_cls: 0.6121  decode.d3.loss_mask: 0.3614  decode.d3.loss_dice: 0.3636  decode.d4.loss_cls: 0.6009  decode.d4.loss_mask: 0.3747  decode.d4.loss_dice: 0.3982  decode.d5.loss_cls: 0.6100  decode.d5.loss_mask: 0.3576  decode.d5.loss_dice: 0.3681  decode.d6.loss_cls: 0.6370  decode.d6.loss_mask: 0.3994  decode.d6.loss_dice: 0.3962  decode.d7.loss_cls: 0.6187  decode.d7.loss_mask: 0.3825  decode.d7.loss_dice: 0.3738  decode.d8.loss_cls: 0.5873  decode.d8.loss_mask: 0.3794  decode.d8.loss_dice: 0.3841
09/28 15:03:30 - mmengine - INFO - Iter(train) [  4950/320000]  base_lr: 9.8607e-05 lr: 9.8607e-06  eta: 1 day, 14:31:56  time: 0.4292  data_time: 0.0087  memory: 5167  grad_norm: 88.4582  loss: 13.2669  decode.loss_cls: 0.4062  decode.loss_mask: 0.4159  decode.loss_dice: 0.4852  decode.d0.loss_cls: 1.1906  decode.d0.loss_mask: 0.2826  decode.d0.loss_dice: 0.4128  decode.d1.loss_cls: 0.5534  decode.d1.loss_mask: 0.3304  decode.d1.loss_dice: 0.4215  decode.d2.loss_cls: 0.4675  decode.d2.loss_mask: 0.3062  decode.d2.loss_dice: 0.4578  decode.d3.loss_cls: 0.4806  decode.d3.loss_mask: 0.2829  decode.d3.loss_dice: 0.4074  decode.d4.loss_cls: 0.4511  decode.d4.loss_mask: 0.4633  decode.d4.loss_dice: 0.4266  decode.d5.loss_cls: 0.4284  decode.d5.loss_mask: 0.3601  decode.d5.loss_dice: 0.4231  decode.d6.loss_cls: 0.4437  decode.d6.loss_mask: 0.3586  decode.d6.loss_dice: 0.4658  decode.d7.loss_cls: 0.4565  decode.d7.loss_mask: 0.4451  decode.d7.loss_dice: 0.3983  decode.d8.loss_cls: 0.4023  decode.d8.loss_mask: 0.4119  decode.d8.loss_dice: 0.4311
09/28 15:03:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:03:52 - mmengine - INFO - Iter(train) [  5000/320000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 1 day, 14:31:01  time: 0.4304  data_time: 0.0087  memory: 5167  grad_norm: 178.6637  loss: 15.1612  decode.loss_cls: 0.6153  decode.loss_mask: 0.4366  decode.loss_dice: 0.3961  decode.d0.loss_cls: 1.2449  decode.d0.loss_mask: 0.4285  decode.d0.loss_dice: 0.4175  decode.d1.loss_cls: 0.6799  decode.d1.loss_mask: 0.4794  decode.d1.loss_dice: 0.3981  decode.d2.loss_cls: 0.6082  decode.d2.loss_mask: 0.4292  decode.d2.loss_dice: 0.3941  decode.d3.loss_cls: 0.6094  decode.d3.loss_mask: 0.4167  decode.d3.loss_dice: 0.3517  decode.d4.loss_cls: 0.5963  decode.d4.loss_mask: 0.4250  decode.d4.loss_dice: 0.3515  decode.d5.loss_cls: 0.5520  decode.d5.loss_mask: 0.4448  decode.d5.loss_dice: 0.3743  decode.d6.loss_cls: 0.5895  decode.d6.loss_mask: 0.4745  decode.d6.loss_dice: 0.3908  decode.d7.loss_cls: 0.7128  decode.d7.loss_mask: 0.4640  decode.d7.loss_dice: 0.4321  decode.d8.loss_cls: 0.6487  decode.d8.loss_mask: 0.4339  decode.d8.loss_dice: 0.3652
09/28 15:04:13 - mmengine - INFO - Iter(train) [  5050/320000]  base_lr: 9.8579e-05 lr: 9.8579e-06  eta: 1 day, 14:30:05  time: 0.4293  data_time: 0.0086  memory: 5166  grad_norm: 96.7093  loss: 12.4048  decode.loss_cls: 0.5465  decode.loss_mask: 0.2640  decode.loss_dice: 0.3848  decode.d0.loss_cls: 1.1310  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.4130  decode.d1.loss_cls: 0.5090  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.3948  decode.d2.loss_cls: 0.4813  decode.d2.loss_mask: 0.2678  decode.d2.loss_dice: 0.3777  decode.d3.loss_cls: 0.4847  decode.d3.loss_mask: 0.2643  decode.d3.loss_dice: 0.3594  decode.d4.loss_cls: 0.5241  decode.d4.loss_mask: 0.2763  decode.d4.loss_dice: 0.3890  decode.d5.loss_cls: 0.4505  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.3958  decode.d6.loss_cls: 0.5385  decode.d6.loss_mask: 0.2701  decode.d6.loss_dice: 0.4080  decode.d7.loss_cls: 0.5540  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.3995  decode.d8.loss_cls: 0.5719  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.3946
09/28 15:04:35 - mmengine - INFO - Iter(train) [  5100/320000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 1 day, 14:29:11  time: 0.4300  data_time: 0.0088  memory: 5186  grad_norm: 170.3099  loss: 11.3009  decode.loss_cls: 0.3621  decode.loss_mask: 0.3472  decode.loss_dice: 0.2731  decode.d0.loss_cls: 1.0975  decode.d0.loss_mask: 0.4546  decode.d0.loss_dice: 0.3076  decode.d1.loss_cls: 0.4460  decode.d1.loss_mask: 0.3348  decode.d1.loss_dice: 0.2366  decode.d2.loss_cls: 0.3909  decode.d2.loss_mask: 0.3837  decode.d2.loss_dice: 0.2557  decode.d3.loss_cls: 0.3783  decode.d3.loss_mask: 0.4772  decode.d3.loss_dice: 0.3248  decode.d4.loss_cls: 0.3707  decode.d4.loss_mask: 0.4856  decode.d4.loss_dice: 0.2741  decode.d5.loss_cls: 0.3632  decode.d5.loss_mask: 0.3763  decode.d5.loss_dice: 0.2906  decode.d6.loss_cls: 0.3722  decode.d6.loss_mask: 0.3909  decode.d6.loss_dice: 0.2949  decode.d7.loss_cls: 0.3671  decode.d7.loss_mask: 0.3623  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.3606  decode.d8.loss_mask: 0.3870  decode.d8.loss_dice: 0.2770
09/28 15:04:56 - mmengine - INFO - Iter(train) [  5150/320000]  base_lr: 9.8551e-05 lr: 9.8551e-06  eta: 1 day, 14:28:18  time: 0.4305  data_time: 0.0090  memory: 5186  grad_norm: 105.6096  loss: 16.0889  decode.loss_cls: 0.7828  decode.loss_mask: 0.3902  decode.loss_dice: 0.3536  decode.d0.loss_cls: 1.5074  decode.d0.loss_mask: 0.3645  decode.d0.loss_dice: 0.3827  decode.d1.loss_cls: 0.8632  decode.d1.loss_mask: 0.3720  decode.d1.loss_dice: 0.3851  decode.d2.loss_cls: 0.8236  decode.d2.loss_mask: 0.3596  decode.d2.loss_dice: 0.3663  decode.d3.loss_cls: 0.7487  decode.d3.loss_mask: 0.3554  decode.d3.loss_dice: 0.3309  decode.d4.loss_cls: 0.8049  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.3450  decode.d5.loss_cls: 0.8297  decode.d5.loss_mask: 0.3571  decode.d5.loss_dice: 0.3427  decode.d6.loss_cls: 0.8198  decode.d6.loss_mask: 0.3781  decode.d6.loss_dice: 0.3636  decode.d7.loss_cls: 0.8138  decode.d7.loss_mask: 0.3544  decode.d7.loss_dice: 0.3442  decode.d8.loss_cls: 0.8419  decode.d8.loss_mask: 0.3619  decode.d8.loss_dice: 0.3615
09/28 15:05:18 - mmengine - INFO - Iter(train) [  5200/320000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 1 day, 14:27:26  time: 0.4303  data_time: 0.0089  memory: 5186  grad_norm: 128.8046  loss: 13.9711  decode.loss_cls: 0.5694  decode.loss_mask: 0.3794  decode.loss_dice: 0.3088  decode.d0.loss_cls: 1.4106  decode.d0.loss_mask: 0.4021  decode.d0.loss_dice: 0.3563  decode.d1.loss_cls: 0.6388  decode.d1.loss_mask: 0.3749  decode.d1.loss_dice: 0.3427  decode.d2.loss_cls: 0.5177  decode.d2.loss_mask: 0.4673  decode.d2.loss_dice: 0.3411  decode.d3.loss_cls: 0.5456  decode.d3.loss_mask: 0.4006  decode.d3.loss_dice: 0.3500  decode.d4.loss_cls: 0.5412  decode.d4.loss_mask: 0.4083  decode.d4.loss_dice: 0.3488  decode.d5.loss_cls: 0.5220  decode.d5.loss_mask: 0.4183  decode.d5.loss_dice: 0.3421  decode.d6.loss_cls: 0.5552  decode.d6.loss_mask: 0.4285  decode.d6.loss_dice: 0.3304  decode.d7.loss_cls: 0.5869  decode.d7.loss_mask: 0.4202  decode.d7.loss_dice: 0.3230  decode.d8.loss_cls: 0.5652  decode.d8.loss_mask: 0.4546  decode.d8.loss_dice: 0.3211
09/28 15:05:39 - mmengine - INFO - Iter(train) [  5250/320000]  base_lr: 9.8522e-05 lr: 9.8522e-06  eta: 1 day, 14:26:33  time: 0.4302  data_time: 0.0087  memory: 5150  grad_norm: 107.4692  loss: 9.2818  decode.loss_cls: 0.3695  decode.loss_mask: 0.2410  decode.loss_dice: 0.2413  decode.d0.loss_cls: 1.2434  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.2318  decode.d1.loss_cls: 0.3789  decode.d1.loss_mask: 0.2447  decode.d1.loss_dice: 0.2347  decode.d2.loss_cls: 0.3085  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2293  decode.d3.loss_cls: 0.3522  decode.d3.loss_mask: 0.2427  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.3576  decode.d4.loss_mask: 0.2419  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.3547  decode.d5.loss_mask: 0.2410  decode.d5.loss_dice: 0.2328  decode.d6.loss_cls: 0.3814  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2415  decode.d7.loss_cls: 0.3731  decode.d7.loss_mask: 0.2452  decode.d7.loss_dice: 0.2288  decode.d8.loss_cls: 0.3769  decode.d8.loss_mask: 0.2442  decode.d8.loss_dice: 0.2505
09/28 15:06:01 - mmengine - INFO - Iter(train) [  5300/320000]  base_lr: 9.8508e-05 lr: 9.8508e-06  eta: 1 day, 14:25:42  time: 0.4301  data_time: 0.0089  memory: 5167  grad_norm: 257.1227  loss: 14.4423  decode.loss_cls: 0.5083  decode.loss_mask: 0.5219  decode.loss_dice: 0.3867  decode.d0.loss_cls: 1.2150  decode.d0.loss_mask: 0.5582  decode.d0.loss_dice: 0.4054  decode.d1.loss_cls: 0.5061  decode.d1.loss_mask: 0.5125  decode.d1.loss_dice: 0.3948  decode.d2.loss_cls: 0.4538  decode.d2.loss_mask: 0.5162  decode.d2.loss_dice: 0.3876  decode.d3.loss_cls: 0.4299  decode.d3.loss_mask: 0.5222  decode.d3.loss_dice: 0.3668  decode.d4.loss_cls: 0.4173  decode.d4.loss_mask: 0.5072  decode.d4.loss_dice: 0.4010  decode.d5.loss_cls: 0.4550  decode.d5.loss_mask: 0.5215  decode.d5.loss_dice: 0.3876  decode.d6.loss_cls: 0.4250  decode.d6.loss_mask: 0.5303  decode.d6.loss_dice: 0.3735  decode.d7.loss_cls: 0.4380  decode.d7.loss_mask: 0.5311  decode.d7.loss_dice: 0.4003  decode.d8.loss_cls: 0.4517  decode.d8.loss_mask: 0.5288  decode.d8.loss_dice: 0.3884
09/28 15:06:22 - mmengine - INFO - Iter(train) [  5350/320000]  base_lr: 9.8494e-05 lr: 9.8494e-06  eta: 1 day, 14:24:52  time: 0.4302  data_time: 0.0088  memory: 5167  grad_norm: 74.4394  loss: 8.3791  decode.loss_cls: 0.2443  decode.loss_mask: 0.2904  decode.loss_dice: 0.2347  decode.d0.loss_cls: 1.0262  decode.d0.loss_mask: 0.3043  decode.d0.loss_dice: 0.2482  decode.d1.loss_cls: 0.2753  decode.d1.loss_mask: 0.2955  decode.d1.loss_dice: 0.2408  decode.d2.loss_cls: 0.2323  decode.d2.loss_mask: 0.2949  decode.d2.loss_dice: 0.2446  decode.d3.loss_cls: 0.1984  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.2320  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.2974  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.2075  decode.d5.loss_mask: 0.2899  decode.d5.loss_dice: 0.2405  decode.d6.loss_cls: 0.2224  decode.d6.loss_mask: 0.2948  decode.d6.loss_dice: 0.2484  decode.d7.loss_cls: 0.2171  decode.d7.loss_mask: 0.2925  decode.d7.loss_dice: 0.2328  decode.d8.loss_cls: 0.1952  decode.d8.loss_mask: 0.2938  decode.d8.loss_dice: 0.2476
09/28 15:06:44 - mmengine - INFO - Iter(train) [  5400/320000]  base_lr: 9.8480e-05 lr: 9.8480e-06  eta: 1 day, 14:24:03  time: 0.4307  data_time: 0.0090  memory: 5150  grad_norm: 139.2865  loss: 13.2306  decode.loss_cls: 0.5881  decode.loss_mask: 0.3714  decode.loss_dice: 0.3153  decode.d0.loss_cls: 1.3108  decode.d0.loss_mask: 0.3563  decode.d0.loss_dice: 0.3407  decode.d1.loss_cls: 0.6403  decode.d1.loss_mask: 0.3822  decode.d1.loss_dice: 0.3307  decode.d2.loss_cls: 0.5752  decode.d2.loss_mask: 0.3606  decode.d2.loss_dice: 0.3089  decode.d3.loss_cls: 0.6193  decode.d3.loss_mask: 0.3549  decode.d3.loss_dice: 0.2806  decode.d4.loss_cls: 0.5715  decode.d4.loss_mask: 0.3653  decode.d4.loss_dice: 0.3041  decode.d5.loss_cls: 0.5278  decode.d5.loss_mask: 0.3641  decode.d5.loss_dice: 0.3185  decode.d6.loss_cls: 0.5512  decode.d6.loss_mask: 0.3791  decode.d6.loss_dice: 0.3091  decode.d7.loss_cls: 0.4822  decode.d7.loss_mask: 0.3597  decode.d7.loss_dice: 0.3145  decode.d8.loss_cls: 0.5660  decode.d8.loss_mask: 0.3647  decode.d8.loss_dice: 0.3179
09/28 15:07:05 - mmengine - INFO - Iter(train) [  5450/320000]  base_lr: 9.8466e-05 lr: 9.8466e-06  eta: 1 day, 14:23:16  time: 0.4296  data_time: 0.0088  memory: 5166  grad_norm: 266.0462  loss: 14.2016  decode.loss_cls: 0.7174  decode.loss_mask: 0.3285  decode.loss_dice: 0.3198  decode.d0.loss_cls: 1.3743  decode.d0.loss_mask: 0.3970  decode.d0.loss_dice: 0.3606  decode.d1.loss_cls: 0.7078  decode.d1.loss_mask: 0.3330  decode.d1.loss_dice: 0.3532  decode.d2.loss_cls: 0.6629  decode.d2.loss_mask: 0.3288  decode.d2.loss_dice: 0.3247  decode.d3.loss_cls: 0.6544  decode.d3.loss_mask: 0.3742  decode.d3.loss_dice: 0.3087  decode.d4.loss_cls: 0.6562  decode.d4.loss_mask: 0.3400  decode.d4.loss_dice: 0.3214  decode.d5.loss_cls: 0.6222  decode.d5.loss_mask: 0.3395  decode.d5.loss_dice: 0.3236  decode.d6.loss_cls: 0.6750  decode.d6.loss_mask: 0.3354  decode.d6.loss_dice: 0.3277  decode.d7.loss_cls: 0.7217  decode.d7.loss_mask: 0.3230  decode.d7.loss_dice: 0.3168  decode.d8.loss_cls: 0.6954  decode.d8.loss_mask: 0.3416  decode.d8.loss_dice: 0.3170
09/28 15:07:27 - mmengine - INFO - Iter(train) [  5500/320000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 1 day, 14:22:27  time: 0.4303  data_time: 0.0088  memory: 5166  grad_norm: 110.5737  loss: 10.3988  decode.loss_cls: 0.3710  decode.loss_mask: 0.2981  decode.loss_dice: 0.2813  decode.d0.loss_cls: 1.2435  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.3269  decode.d1.loss_cls: 0.4182  decode.d1.loss_mask: 0.2905  decode.d1.loss_dice: 0.2961  decode.d2.loss_cls: 0.3016  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.2840  decode.d3.loss_cls: 0.3177  decode.d3.loss_mask: 0.2980  decode.d3.loss_dice: 0.2781  decode.d4.loss_cls: 0.3486  decode.d4.loss_mask: 0.2999  decode.d4.loss_dice: 0.2967  decode.d5.loss_cls: 0.3438  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.2935  decode.d6.loss_cls: 0.3655  decode.d6.loss_mask: 0.3064  decode.d6.loss_dice: 0.3143  decode.d7.loss_cls: 0.3807  decode.d7.loss_mask: 0.2944  decode.d7.loss_dice: 0.3070  decode.d8.loss_cls: 0.3744  decode.d8.loss_mask: 0.2924  decode.d8.loss_dice: 0.2881
09/28 15:07:48 - mmengine - INFO - Iter(train) [  5550/320000]  base_lr: 9.8438e-05 lr: 9.8438e-06  eta: 1 day, 14:21:39  time: 0.4297  data_time: 0.0088  memory: 5150  grad_norm: 151.5219  loss: 11.3531  decode.loss_cls: 0.4123  decode.loss_mask: 0.3518  decode.loss_dice: 0.3136  decode.d0.loss_cls: 1.0618  decode.d0.loss_mask: 0.3824  decode.d0.loss_dice: 0.3147  decode.d1.loss_cls: 0.3322  decode.d1.loss_mask: 0.3623  decode.d1.loss_dice: 0.3315  decode.d2.loss_cls: 0.3148  decode.d2.loss_mask: 0.3789  decode.d2.loss_dice: 0.3381  decode.d3.loss_cls: 0.3149  decode.d3.loss_mask: 0.3683  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.3272  decode.d4.loss_mask: 0.3845  decode.d4.loss_dice: 0.3401  decode.d5.loss_cls: 0.3355  decode.d5.loss_mask: 0.4885  decode.d5.loss_dice: 0.3776  decode.d6.loss_cls: 0.3646  decode.d6.loss_mask: 0.3568  decode.d6.loss_dice: 0.3383  decode.d7.loss_cls: 0.3555  decode.d7.loss_mask: 0.3459  decode.d7.loss_dice: 0.3340  decode.d8.loss_cls: 0.4194  decode.d8.loss_mask: 0.3497  decode.d8.loss_dice: 0.3277
09/28 15:08:10 - mmengine - INFO - Iter(train) [  5600/320000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 1 day, 14:20:51  time: 0.4294  data_time: 0.0087  memory: 5186  grad_norm: 136.2973  loss: 14.0384  decode.loss_cls: 0.4530  decode.loss_mask: 0.4844  decode.loss_dice: 0.4226  decode.d0.loss_cls: 1.1395  decode.d0.loss_mask: 0.4973  decode.d0.loss_dice: 0.4493  decode.d1.loss_cls: 0.4727  decode.d1.loss_mask: 0.4683  decode.d1.loss_dice: 0.3730  decode.d2.loss_cls: 0.3605  decode.d2.loss_mask: 0.4785  decode.d2.loss_dice: 0.4041  decode.d3.loss_cls: 0.4006  decode.d3.loss_mask: 0.4942  decode.d3.loss_dice: 0.3764  decode.d4.loss_cls: 0.4141  decode.d4.loss_mask: 0.4924  decode.d4.loss_dice: 0.4124  decode.d5.loss_cls: 0.4486  decode.d5.loss_mask: 0.4974  decode.d5.loss_dice: 0.4077  decode.d6.loss_cls: 0.4864  decode.d6.loss_mask: 0.5136  decode.d6.loss_dice: 0.3884  decode.d7.loss_cls: 0.4344  decode.d7.loss_mask: 0.5020  decode.d7.loss_dice: 0.4031  decode.d8.loss_cls: 0.4621  decode.d8.loss_mask: 0.4838  decode.d8.loss_dice: 0.4175
09/28 15:08:31 - mmengine - INFO - Iter(train) [  5650/320000]  base_lr: 9.8410e-05 lr: 9.8410e-06  eta: 1 day, 14:20:05  time: 0.4306  data_time: 0.0087  memory: 5167  grad_norm: 134.1523  loss: 11.3115  decode.loss_cls: 0.4772  decode.loss_mask: 0.3393  decode.loss_dice: 0.2745  decode.d0.loss_cls: 1.2628  decode.d0.loss_mask: 0.3217  decode.d0.loss_dice: 0.2893  decode.d1.loss_cls: 0.4174  decode.d1.loss_mask: 0.3324  decode.d1.loss_dice: 0.2808  decode.d2.loss_cls: 0.3898  decode.d2.loss_mask: 0.3428  decode.d2.loss_dice: 0.2779  decode.d3.loss_cls: 0.3686  decode.d3.loss_mask: 0.3142  decode.d3.loss_dice: 0.2628  decode.d4.loss_cls: 0.4104  decode.d4.loss_mask: 0.3549  decode.d4.loss_dice: 0.2998  decode.d5.loss_cls: 0.4547  decode.d5.loss_mask: 0.3480  decode.d5.loss_dice: 0.2839  decode.d6.loss_cls: 0.4345  decode.d6.loss_mask: 0.3436  decode.d6.loss_dice: 0.2687  decode.d7.loss_cls: 0.4260  decode.d7.loss_mask: 0.3408  decode.d7.loss_dice: 0.2751  decode.d8.loss_cls: 0.5136  decode.d8.loss_mask: 0.3371  decode.d8.loss_dice: 0.2692
09/28 15:08:53 - mmengine - INFO - Iter(train) [  5700/320000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 1 day, 14:19:19  time: 0.4304  data_time: 0.0088  memory: 5148  grad_norm: 202.2402  loss: 13.7069  decode.loss_cls: 0.6146  decode.loss_mask: 0.3066  decode.loss_dice: 0.2840  decode.d0.loss_cls: 1.5188  decode.d0.loss_mask: 0.3053  decode.d0.loss_dice: 0.3115  decode.d1.loss_cls: 0.7452  decode.d1.loss_mask: 0.3275  decode.d1.loss_dice: 0.3207  decode.d2.loss_cls: 0.6910  decode.d2.loss_mask: 0.3399  decode.d2.loss_dice: 0.3340  decode.d3.loss_cls: 0.7311  decode.d3.loss_mask: 0.3272  decode.d3.loss_dice: 0.2977  decode.d4.loss_cls: 0.7000  decode.d4.loss_mask: 0.3334  decode.d4.loss_dice: 0.3114  decode.d5.loss_cls: 0.6401  decode.d5.loss_mask: 0.3134  decode.d5.loss_dice: 0.2997  decode.d6.loss_cls: 0.5733  decode.d6.loss_mask: 0.3099  decode.d6.loss_dice: 0.3075  decode.d7.loss_cls: 0.5468  decode.d7.loss_mask: 0.3610  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.6105  decode.d8.loss_mask: 0.3059  decode.d8.loss_dice: 0.2989
09/28 15:09:14 - mmengine - INFO - Iter(train) [  5750/320000]  base_lr: 9.8382e-05 lr: 9.8382e-06  eta: 1 day, 14:18:33  time: 0.4311  data_time: 0.0088  memory: 5186  grad_norm: 126.0736  loss: 14.1303  decode.loss_cls: 0.5214  decode.loss_mask: 0.4077  decode.loss_dice: 0.3796  decode.d0.loss_cls: 1.2961  decode.d0.loss_mask: 0.3806  decode.d0.loss_dice: 0.4271  decode.d1.loss_cls: 0.5925  decode.d1.loss_mask: 0.3742  decode.d1.loss_dice: 0.3817  decode.d2.loss_cls: 0.5440  decode.d2.loss_mask: 0.3717  decode.d2.loss_dice: 0.3832  decode.d3.loss_cls: 0.5323  decode.d3.loss_mask: 0.3735  decode.d3.loss_dice: 0.4011  decode.d4.loss_cls: 0.5561  decode.d4.loss_mask: 0.3883  decode.d4.loss_dice: 0.3849  decode.d5.loss_cls: 0.5539  decode.d5.loss_mask: 0.3808  decode.d5.loss_dice: 0.3826  decode.d6.loss_cls: 0.6311  decode.d6.loss_mask: 0.3901  decode.d6.loss_dice: 0.3824  decode.d7.loss_cls: 0.6216  decode.d7.loss_mask: 0.3887  decode.d7.loss_dice: 0.3729  decode.d8.loss_cls: 0.5471  decode.d8.loss_mask: 0.4040  decode.d8.loss_dice: 0.3792
09/28 15:09:36 - mmengine - INFO - Iter(train) [  5800/320000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 1 day, 14:17:47  time: 0.4300  data_time: 0.0088  memory: 5186  grad_norm: 121.9445  loss: 14.4159  decode.loss_cls: 0.7363  decode.loss_mask: 0.3689  decode.loss_dice: 0.3063  decode.d0.loss_cls: 1.3844  decode.d0.loss_mask: 0.3468  decode.d0.loss_dice: 0.3273  decode.d1.loss_cls: 0.6864  decode.d1.loss_mask: 0.3333  decode.d1.loss_dice: 0.2837  decode.d2.loss_cls: 0.6707  decode.d2.loss_mask: 0.3636  decode.d2.loss_dice: 0.3077  decode.d3.loss_cls: 0.6226  decode.d3.loss_mask: 0.3424  decode.d3.loss_dice: 0.3009  decode.d4.loss_cls: 0.7510  decode.d4.loss_mask: 0.3501  decode.d4.loss_dice: 0.3165  decode.d5.loss_cls: 0.7220  decode.d5.loss_mask: 0.3466  decode.d5.loss_dice: 0.3044  decode.d6.loss_cls: 0.7615  decode.d6.loss_mask: 0.3448  decode.d6.loss_dice: 0.3313  decode.d7.loss_cls: 0.7435  decode.d7.loss_mask: 0.3510  decode.d7.loss_dice: 0.3441  decode.d8.loss_cls: 0.7247  decode.d8.loss_mask: 0.3338  decode.d8.loss_dice: 0.3091
09/28 15:09:57 - mmengine - INFO - Iter(train) [  5850/320000]  base_lr: 9.8353e-05 lr: 9.8353e-06  eta: 1 day, 14:17:01  time: 0.4296  data_time: 0.0088  memory: 5167  grad_norm: 55.8304  loss: 7.8736  decode.loss_cls: 0.2279  decode.loss_mask: 0.2467  decode.loss_dice: 0.2162  decode.d0.loss_cls: 1.0139  decode.d0.loss_mask: 0.2676  decode.d0.loss_dice: 0.2594  decode.d1.loss_cls: 0.2509  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2330  decode.d2.loss_cls: 0.1928  decode.d2.loss_mask: 0.2535  decode.d2.loss_dice: 0.2218  decode.d3.loss_cls: 0.1850  decode.d3.loss_mask: 0.2495  decode.d3.loss_dice: 0.2253  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 0.2515  decode.d4.loss_dice: 0.2318  decode.d5.loss_cls: 0.2126  decode.d5.loss_mask: 0.2535  decode.d5.loss_dice: 0.2364  decode.d6.loss_cls: 0.2372  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.2294  decode.d7.loss_cls: 0.2209  decode.d7.loss_mask: 0.2590  decode.d7.loss_dice: 0.2597  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2330
09/28 15:10:19 - mmengine - INFO - Iter(train) [  5900/320000]  base_lr: 9.8339e-05 lr: 9.8339e-06  eta: 1 day, 14:16:17  time: 0.4301  data_time: 0.0088  memory: 5167  grad_norm: 96.5734  loss: 10.7666  decode.loss_cls: 0.3857  decode.loss_mask: 0.2916  decode.loss_dice: 0.2415  decode.d0.loss_cls: 1.1964  decode.d0.loss_mask: 0.3100  decode.d0.loss_dice: 0.2742  decode.d1.loss_cls: 0.6439  decode.d1.loss_mask: 0.2879  decode.d1.loss_dice: 0.2329  decode.d2.loss_cls: 0.5474  decode.d2.loss_mask: 0.2908  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.4884  decode.d3.loss_mask: 0.2762  decode.d3.loss_dice: 0.2232  decode.d4.loss_cls: 0.5295  decode.d4.loss_mask: 0.2905  decode.d4.loss_dice: 0.2428  decode.d5.loss_cls: 0.4617  decode.d5.loss_mask: 0.2908  decode.d5.loss_dice: 0.2252  decode.d6.loss_cls: 0.4372  decode.d6.loss_mask: 0.2803  decode.d6.loss_dice: 0.2355  decode.d7.loss_cls: 0.3683  decode.d7.loss_mask: 0.2972  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.3835  decode.d8.loss_mask: 0.3008  decode.d8.loss_dice: 0.2548
09/28 15:10:40 - mmengine - INFO - Iter(train) [  5950/320000]  base_lr: 9.8325e-05 lr: 9.8325e-06  eta: 1 day, 14:15:32  time: 0.4299  data_time: 0.0089  memory: 5166  grad_norm: 167.1609  loss: 8.0972  decode.loss_cls: 0.0875  decode.loss_mask: 0.4222  decode.loss_dice: 0.2318  decode.d0.loss_cls: 0.8395  decode.d0.loss_mask: 0.4259  decode.d0.loss_dice: 0.2558  decode.d1.loss_cls: 0.0980  decode.d1.loss_mask: 0.4133  decode.d1.loss_dice: 0.2254  decode.d2.loss_cls: 0.0859  decode.d2.loss_mask: 0.4195  decode.d2.loss_dice: 0.2215  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 0.4152  decode.d3.loss_dice: 0.2329  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.2232  decode.d5.loss_cls: 0.0989  decode.d5.loss_mask: 0.4083  decode.d5.loss_dice: 0.2267  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.4084  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.4094  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.0999  decode.d8.loss_mask: 0.4116  decode.d8.loss_dice: 0.2299
09/28 15:11:02 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:11:02 - mmengine - INFO - Iter(train) [  6000/320000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 1 day, 14:14:48  time: 0.4304  data_time: 0.0088  memory: 5186  grad_norm: 144.3630  loss: 9.9566  decode.loss_cls: 0.3449  decode.loss_mask: 0.3504  decode.loss_dice: 0.2941  decode.d0.loss_cls: 0.8900  decode.d0.loss_mask: 0.3566  decode.d0.loss_dice: 0.2748  decode.d1.loss_cls: 0.2384  decode.d1.loss_mask: 0.3555  decode.d1.loss_dice: 0.2543  decode.d2.loss_cls: 0.2403  decode.d2.loss_mask: 0.3542  decode.d2.loss_dice: 0.2656  decode.d3.loss_cls: 0.2736  decode.d3.loss_mask: 0.3485  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.2871  decode.d4.loss_mask: 0.3618  decode.d4.loss_dice: 0.2708  decode.d5.loss_cls: 0.3780  decode.d5.loss_mask: 0.3580  decode.d5.loss_dice: 0.3036  decode.d6.loss_cls: 0.3689  decode.d6.loss_mask: 0.3507  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.2951  decode.d7.loss_mask: 0.3500  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.3093  decode.d8.loss_mask: 0.3456  decode.d8.loss_dice: 0.2626
09/28 15:11:23 - mmengine - INFO - Iter(train) [  6050/320000]  base_lr: 9.8297e-05 lr: 9.8297e-06  eta: 1 day, 14:14:05  time: 0.4295  data_time: 0.0087  memory: 5167  grad_norm: 63.6687  loss: 8.2588  decode.loss_cls: 0.1783  decode.loss_mask: 0.2981  decode.loss_dice: 0.2485  decode.d0.loss_cls: 1.2092  decode.d0.loss_mask: 0.2773  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.2753  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.1492  decode.d2.loss_mask: 0.2997  decode.d2.loss_dice: 0.2467  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 0.3075  decode.d3.loss_dice: 0.2585  decode.d4.loss_cls: 0.1385  decode.d4.loss_mask: 0.3071  decode.d4.loss_dice: 0.2499  decode.d5.loss_cls: 0.1472  decode.d5.loss_mask: 0.3012  decode.d5.loss_dice: 0.2513  decode.d6.loss_cls: 0.1597  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.2535  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 0.2895  decode.d7.loss_dice: 0.2554  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 0.2826  decode.d8.loss_dice: 0.2517
09/28 15:11:45 - mmengine - INFO - Iter(train) [  6100/320000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 1 day, 14:13:22  time: 0.4300  data_time: 0.0088  memory: 5167  grad_norm: 114.7925  loss: 12.0919  decode.loss_cls: 0.3993  decode.loss_mask: 0.3838  decode.loss_dice: 0.3577  decode.d0.loss_cls: 1.0965  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.3014  decode.d1.loss_cls: 0.5090  decode.d1.loss_mask: 0.3111  decode.d1.loss_dice: 0.3577  decode.d2.loss_cls: 0.4204  decode.d2.loss_mask: 0.3507  decode.d2.loss_dice: 0.3734  decode.d3.loss_cls: 0.3926  decode.d3.loss_mask: 0.3956  decode.d3.loss_dice: 0.3426  decode.d4.loss_cls: 0.4265  decode.d4.loss_mask: 0.3854  decode.d4.loss_dice: 0.3408  decode.d5.loss_cls: 0.4226  decode.d5.loss_mask: 0.3501  decode.d5.loss_dice: 0.3514  decode.d6.loss_cls: 0.4220  decode.d6.loss_mask: 0.4001  decode.d6.loss_dice: 0.3345  decode.d7.loss_cls: 0.4098  decode.d7.loss_mask: 0.4374  decode.d7.loss_dice: 0.3451  decode.d8.loss_cls: 0.4333  decode.d8.loss_mask: 0.4156  decode.d8.loss_dice: 0.3332
09/28 15:12:06 - mmengine - INFO - Iter(train) [  6150/320000]  base_lr: 9.8269e-05 lr: 9.8269e-06  eta: 1 day, 14:12:38  time: 0.4297  data_time: 0.0087  memory: 5150  grad_norm: 171.5074  loss: 10.8626  decode.loss_cls: 0.4452  decode.loss_mask: 0.2908  decode.loss_dice: 0.2640  decode.d0.loss_cls: 1.1910  decode.d0.loss_mask: 0.2845  decode.d0.loss_dice: 0.2786  decode.d1.loss_cls: 0.4595  decode.d1.loss_mask: 0.3112  decode.d1.loss_dice: 0.2685  decode.d2.loss_cls: 0.4023  decode.d2.loss_mask: 0.3382  decode.d2.loss_dice: 0.3088  decode.d3.loss_cls: 0.3873  decode.d3.loss_mask: 0.3037  decode.d3.loss_dice: 0.2867  decode.d4.loss_cls: 0.3747  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.3813  decode.d5.loss_mask: 0.3176  decode.d5.loss_dice: 0.2984  decode.d6.loss_cls: 0.3552  decode.d6.loss_mask: 0.3361  decode.d6.loss_dice: 0.2947  decode.d7.loss_cls: 0.4156  decode.d7.loss_mask: 0.3304  decode.d7.loss_dice: 0.2889  decode.d8.loss_cls: 0.3902  decode.d8.loss_mask: 0.3701  decode.d8.loss_dice: 0.2833
09/28 15:12:28 - mmengine - INFO - Iter(train) [  6200/320000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 1 day, 14:12:03  time: 0.4299  data_time: 0.0088  memory: 5167  grad_norm: 153.8184  loss: 10.7590  decode.loss_cls: 0.3671  decode.loss_mask: 0.3923  decode.loss_dice: 0.2911  decode.d0.loss_cls: 1.1745  decode.d0.loss_mask: 0.3378  decode.d0.loss_dice: 0.3182  decode.d1.loss_cls: 0.3849  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.2950  decode.d2.loss_cls: 0.3183  decode.d2.loss_mask: 0.3374  decode.d2.loss_dice: 0.2886  decode.d3.loss_cls: 0.3498  decode.d3.loss_mask: 0.3303  decode.d3.loss_dice: 0.2789  decode.d4.loss_cls: 0.3892  decode.d4.loss_mask: 0.3293  decode.d4.loss_dice: 0.2521  decode.d5.loss_cls: 0.3662  decode.d5.loss_mask: 0.3349  decode.d5.loss_dice: 0.2822  decode.d6.loss_cls: 0.3496  decode.d6.loss_mask: 0.3338  decode.d6.loss_dice: 0.2854  decode.d7.loss_cls: 0.3623  decode.d7.loss_mask: 0.3330  decode.d7.loss_dice: 0.2938  decode.d8.loss_cls: 0.3528  decode.d8.loss_mask: 0.4060  decode.d8.loss_dice: 0.2948
09/28 15:12:49 - mmengine - INFO - Iter(train) [  6250/320000]  base_lr: 9.8241e-05 lr: 9.8241e-06  eta: 1 day, 14:11:21  time: 0.4306  data_time: 0.0089  memory: 5186  grad_norm: 152.3328  loss: 11.4933  decode.loss_cls: 0.4890  decode.loss_mask: 0.3476  decode.loss_dice: 0.3164  decode.d0.loss_cls: 0.9743  decode.d0.loss_mask: 0.3623  decode.d0.loss_dice: 0.2787  decode.d1.loss_cls: 0.4666  decode.d1.loss_mask: 0.3416  decode.d1.loss_dice: 0.2810  decode.d2.loss_cls: 0.4339  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.2473  decode.d3.loss_cls: 0.4256  decode.d3.loss_mask: 0.3366  decode.d3.loss_dice: 0.2532  decode.d4.loss_cls: 0.4200  decode.d4.loss_mask: 0.3715  decode.d4.loss_dice: 0.2815  decode.d5.loss_cls: 0.4141  decode.d5.loss_mask: 0.3479  decode.d5.loss_dice: 0.2989  decode.d6.loss_cls: 0.4774  decode.d6.loss_mask: 0.3467  decode.d6.loss_dice: 0.2790  decode.d7.loss_cls: 0.4799  decode.d7.loss_mask: 0.3750  decode.d7.loss_dice: 0.3377  decode.d8.loss_cls: 0.4813  decode.d8.loss_mask: 0.3615  decode.d8.loss_dice: 0.3247
09/28 15:13:11 - mmengine - INFO - Iter(train) [  6300/320000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 1 day, 14:10:40  time: 0.4303  data_time: 0.0089  memory: 5186  grad_norm: 122.3649  loss: 10.2851  decode.loss_cls: 0.3367  decode.loss_mask: 0.3159  decode.loss_dice: 0.3009  decode.d0.loss_cls: 1.1162  decode.d0.loss_mask: 0.3436  decode.d0.loss_dice: 0.3524  decode.d1.loss_cls: 0.3785  decode.d1.loss_mask: 0.2954  decode.d1.loss_dice: 0.3080  decode.d2.loss_cls: 0.3331  decode.d2.loss_mask: 0.3015  decode.d2.loss_dice: 0.3074  decode.d3.loss_cls: 0.2526  decode.d3.loss_mask: 0.3110  decode.d3.loss_dice: 0.3105  decode.d4.loss_cls: 0.3044  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.3077  decode.d5.loss_cls: 0.3061  decode.d5.loss_mask: 0.3118  decode.d5.loss_dice: 0.3141  decode.d6.loss_cls: 0.3601  decode.d6.loss_mask: 0.3073  decode.d6.loss_dice: 0.3158  decode.d7.loss_cls: 0.3140  decode.d7.loss_mask: 0.3190  decode.d7.loss_dice: 0.3309  decode.d8.loss_cls: 0.3121  decode.d8.loss_mask: 0.3144  decode.d8.loss_dice: 0.3052
09/28 15:13:32 - mmengine - INFO - Iter(train) [  6350/320000]  base_lr: 9.8213e-05 lr: 9.8213e-06  eta: 1 day, 14:09:57  time: 0.4296  data_time: 0.0088  memory: 5166  grad_norm: 62.7903  loss: 8.1453  decode.loss_cls: 0.2577  decode.loss_mask: 0.2565  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.9879  decode.d0.loss_mask: 0.2595  decode.d0.loss_dice: 0.2388  decode.d1.loss_cls: 0.3369  decode.d1.loss_mask: 0.2525  decode.d1.loss_dice: 0.2312  decode.d2.loss_cls: 0.2740  decode.d2.loss_mask: 0.2493  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.2452  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.2250  decode.d4.loss_cls: 0.2258  decode.d4.loss_mask: 0.2520  decode.d4.loss_dice: 0.2308  decode.d5.loss_cls: 0.2599  decode.d5.loss_mask: 0.2511  decode.d5.loss_dice: 0.2283  decode.d6.loss_cls: 0.2234  decode.d6.loss_mask: 0.2548  decode.d6.loss_dice: 0.2277  decode.d7.loss_cls: 0.2465  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.2208  decode.d8.loss_cls: 0.2555  decode.d8.loss_mask: 0.2556  decode.d8.loss_dice: 0.2319
09/28 15:13:54 - mmengine - INFO - Iter(train) [  6400/320000]  base_lr: 9.8198e-05 lr: 9.8198e-06  eta: 1 day, 14:09:15  time: 0.4303  data_time: 0.0089  memory: 5166  grad_norm: 199.6173  loss: 11.1354  decode.loss_cls: 0.3803  decode.loss_mask: 0.4163  decode.loss_dice: 0.2789  decode.d0.loss_cls: 1.1566  decode.d0.loss_mask: 0.3920  decode.d0.loss_dice: 0.3059  decode.d1.loss_cls: 0.3744  decode.d1.loss_mask: 0.3936  decode.d1.loss_dice: 0.2630  decode.d2.loss_cls: 0.3011  decode.d2.loss_mask: 0.4032  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.3688  decode.d3.loss_mask: 0.3853  decode.d3.loss_dice: 0.2603  decode.d4.loss_cls: 0.3545  decode.d4.loss_mask: 0.3742  decode.d4.loss_dice: 0.2581  decode.d5.loss_cls: 0.3134  decode.d5.loss_mask: 0.4439  decode.d5.loss_dice: 0.2934  decode.d6.loss_cls: 0.3759  decode.d6.loss_mask: 0.3983  decode.d6.loss_dice: 0.2956  decode.d7.loss_cls: 0.3372  decode.d7.loss_mask: 0.4435  decode.d7.loss_dice: 0.2919  decode.d8.loss_cls: 0.3218  decode.d8.loss_mask: 0.4281  decode.d8.loss_dice: 0.2736
09/28 15:14:15 - mmengine - INFO - Iter(train) [  6450/320000]  base_lr: 9.8184e-05 lr: 9.8184e-06  eta: 1 day, 14:08:33  time: 0.4296  data_time: 0.0089  memory: 5167  grad_norm: 92.5243  loss: 10.1440  decode.loss_cls: 0.3366  decode.loss_mask: 0.2607  decode.loss_dice: 0.2734  decode.d0.loss_cls: 1.3027  decode.d0.loss_mask: 0.2659  decode.d0.loss_dice: 0.3033  decode.d1.loss_cls: 0.4871  decode.d1.loss_mask: 0.2545  decode.d1.loss_dice: 0.2548  decode.d2.loss_cls: 0.5107  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.2701  decode.d3.loss_cls: 0.3596  decode.d3.loss_mask: 0.2680  decode.d3.loss_dice: 0.3005  decode.d4.loss_cls: 0.3599  decode.d4.loss_mask: 0.2676  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.3981  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.2824  decode.d6.loss_cls: 0.3252  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2590  decode.d7.loss_cls: 0.3106  decode.d7.loss_mask: 0.2833  decode.d7.loss_dice: 0.2841  decode.d8.loss_cls: 0.3166  decode.d8.loss_mask: 0.2566  decode.d8.loss_dice: 0.2751
09/28 15:14:37 - mmengine - INFO - Iter(train) [  6500/320000]  base_lr: 9.8170e-05 lr: 9.8170e-06  eta: 1 day, 14:07:51  time: 0.4298  data_time: 0.0089  memory: 5150  grad_norm: 127.8889  loss: 13.2638  decode.loss_cls: 0.6035  decode.loss_mask: 0.2849  decode.loss_dice: 0.3231  decode.d0.loss_cls: 1.2597  decode.d0.loss_mask: 0.3178  decode.d0.loss_dice: 0.3762  decode.d1.loss_cls: 0.7390  decode.d1.loss_mask: 0.3018  decode.d1.loss_dice: 0.3313  decode.d2.loss_cls: 0.7033  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.6550  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.3301  decode.d4.loss_cls: 0.5979  decode.d4.loss_mask: 0.2967  decode.d4.loss_dice: 0.3105  decode.d5.loss_cls: 0.6786  decode.d5.loss_mask: 0.2911  decode.d5.loss_dice: 0.3147  decode.d6.loss_cls: 0.6420  decode.d6.loss_mask: 0.2888  decode.d6.loss_dice: 0.3191  decode.d7.loss_cls: 0.6021  decode.d7.loss_mask: 0.2786  decode.d7.loss_dice: 0.2873  decode.d8.loss_cls: 0.6047  decode.d8.loss_mask: 0.3019  decode.d8.loss_dice: 0.3462
09/28 15:14:58 - mmengine - INFO - Iter(train) [  6550/320000]  base_lr: 9.8156e-05 lr: 9.8156e-06  eta: 1 day, 14:07:09  time: 0.4298  data_time: 0.0090  memory: 5150  grad_norm: 160.2929  loss: 11.3542  decode.loss_cls: 0.4380  decode.loss_mask: 0.4033  decode.loss_dice: 0.2578  decode.d0.loss_cls: 1.2038  decode.d0.loss_mask: 0.4279  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.5227  decode.d1.loss_mask: 0.4140  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.4245  decode.d2.loss_mask: 0.3964  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.3605  decode.d3.loss_mask: 0.3899  decode.d3.loss_dice: 0.2533  decode.d4.loss_cls: 0.3304  decode.d4.loss_mask: 0.3902  decode.d4.loss_dice: 0.2500  decode.d5.loss_cls: 0.3283  decode.d5.loss_mask: 0.3899  decode.d5.loss_dice: 0.2458  decode.d6.loss_cls: 0.3556  decode.d6.loss_mask: 0.3953  decode.d6.loss_dice: 0.2529  decode.d7.loss_cls: 0.3875  decode.d7.loss_mask: 0.3967  decode.d7.loss_dice: 0.2552  decode.d8.loss_cls: 0.4158  decode.d8.loss_mask: 0.4048  decode.d8.loss_dice: 0.2528
09/28 15:15:20 - mmengine - INFO - Iter(train) [  6600/320000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 1 day, 14:06:28  time: 0.4296  data_time: 0.0088  memory: 5149  grad_norm: 108.1326  loss: 8.2444  decode.loss_cls: 0.1822  decode.loss_mask: 0.2802  decode.loss_dice: 0.2739  decode.d0.loss_cls: 0.8577  decode.d0.loss_mask: 0.2935  decode.d0.loss_dice: 0.3062  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 0.2774  decode.d1.loss_dice: 0.2655  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 0.2740  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.1458  decode.d3.loss_mask: 0.2743  decode.d3.loss_dice: 0.2648  decode.d4.loss_cls: 0.1733  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.2721  decode.d5.loss_cls: 0.2383  decode.d5.loss_mask: 0.2764  decode.d5.loss_dice: 0.2457  decode.d6.loss_cls: 0.2407  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.2660  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.2769  decode.d7.loss_dice: 0.2704  decode.d8.loss_cls: 0.2132  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.2769
09/28 15:15:41 - mmengine - INFO - Iter(train) [  6650/320000]  base_lr: 9.8128e-05 lr: 9.8128e-06  eta: 1 day, 14:05:48  time: 0.4293  data_time: 0.0088  memory: 5166  grad_norm: 66.7097  loss: 9.4352  decode.loss_cls: 0.4241  decode.loss_mask: 0.2332  decode.loss_dice: 0.2133  decode.d0.loss_cls: 1.2039  decode.d0.loss_mask: 0.2456  decode.d0.loss_dice: 0.2359  decode.d1.loss_cls: 0.5552  decode.d1.loss_mask: 0.2386  decode.d1.loss_dice: 0.2279  decode.d2.loss_cls: 0.4489  decode.d2.loss_mask: 0.2382  decode.d2.loss_dice: 0.2278  decode.d3.loss_cls: 0.3412  decode.d3.loss_mask: 0.2388  decode.d3.loss_dice: 0.2080  decode.d4.loss_cls: 0.3508  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.2057  decode.d5.loss_cls: 0.3981  decode.d5.loss_mask: 0.2377  decode.d5.loss_dice: 0.2108  decode.d6.loss_cls: 0.3736  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.2173  decode.d7.loss_cls: 0.3835  decode.d7.loss_mask: 0.2282  decode.d7.loss_dice: 0.2221  decode.d8.loss_cls: 0.3967  decode.d8.loss_mask: 0.2349  decode.d8.loss_dice: 0.2272
09/28 15:16:03 - mmengine - INFO - Iter(train) [  6700/320000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 1 day, 14:05:08  time: 0.4296  data_time: 0.0089  memory: 5166  grad_norm: 65.5346  loss: 10.1539  decode.loss_cls: 0.3514  decode.loss_mask: 0.2870  decode.loss_dice: 0.2838  decode.d0.loss_cls: 0.9810  decode.d0.loss_mask: 0.2969  decode.d0.loss_dice: 0.3000  decode.d1.loss_cls: 0.4633  decode.d1.loss_mask: 0.2877  decode.d1.loss_dice: 0.2505  decode.d2.loss_cls: 0.4412  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.2558  decode.d3.loss_cls: 0.3446  decode.d3.loss_mask: 0.2869  decode.d3.loss_dice: 0.2763  decode.d4.loss_cls: 0.3987  decode.d4.loss_mask: 0.2821  decode.d4.loss_dice: 0.2662  decode.d5.loss_cls: 0.4267  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.2639  decode.d6.loss_cls: 0.4353  decode.d6.loss_mask: 0.2800  decode.d6.loss_dice: 0.2545  decode.d7.loss_cls: 0.3679  decode.d7.loss_mask: 0.2843  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.3834  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.2659
09/28 15:16:24 - mmengine - INFO - Iter(train) [  6750/320000]  base_lr: 9.8100e-05 lr: 9.8100e-06  eta: 1 day, 14:04:28  time: 0.4301  data_time: 0.0087  memory: 5186  grad_norm: 103.9025  loss: 9.2804  decode.loss_cls: 0.3571  decode.loss_mask: 0.2840  decode.loss_dice: 0.2560  decode.d0.loss_cls: 1.1410  decode.d0.loss_mask: 0.2537  decode.d0.loss_dice: 0.2518  decode.d1.loss_cls: 0.4190  decode.d1.loss_mask: 0.2783  decode.d1.loss_dice: 0.2386  decode.d2.loss_cls: 0.3069  decode.d2.loss_mask: 0.2922  decode.d2.loss_dice: 0.2503  decode.d3.loss_cls: 0.3691  decode.d3.loss_mask: 0.2517  decode.d3.loss_dice: 0.2330  decode.d4.loss_cls: 0.3168  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.2504  decode.d5.loss_cls: 0.2682  decode.d5.loss_mask: 0.2630  decode.d5.loss_dice: 0.2386  decode.d6.loss_cls: 0.2775  decode.d6.loss_mask: 0.2855  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2934  decode.d7.loss_mask: 0.2923  decode.d7.loss_dice: 0.2668  decode.d8.loss_cls: 0.3092  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.2464
09/28 15:16:46 - mmengine - INFO - Iter(train) [  6800/320000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 1 day, 14:03:49  time: 0.4299  data_time: 0.0088  memory: 5149  grad_norm: 47.8502  loss: 7.5847  decode.loss_cls: 0.2625  decode.loss_mask: 0.2333  decode.loss_dice: 0.2260  decode.d0.loss_cls: 0.8531  decode.d0.loss_mask: 0.2319  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 0.2255  decode.d1.loss_dice: 0.2057  decode.d2.loss_cls: 0.2296  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.2117  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 0.2301  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.2869  decode.d4.loss_mask: 0.2290  decode.d4.loss_dice: 0.2177  decode.d5.loss_cls: 0.3314  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.1968  decode.d6.loss_cls: 0.2819  decode.d6.loss_mask: 0.2302  decode.d6.loss_dice: 0.2080  decode.d7.loss_cls: 0.2641  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.2073  decode.d8.loss_cls: 0.2503  decode.d8.loss_mask: 0.2315  decode.d8.loss_dice: 0.2055
09/28 15:17:07 - mmengine - INFO - Iter(train) [  6850/320000]  base_lr: 9.8072e-05 lr: 9.8072e-06  eta: 1 day, 14:03:10  time: 0.4317  data_time: 0.0088  memory: 5167  grad_norm: 151.3486  loss: 9.2449  decode.loss_cls: 0.2331  decode.loss_mask: 0.3514  decode.loss_dice: 0.2731  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 0.3970  decode.d0.loss_dice: 0.2917  decode.d1.loss_cls: 0.1899  decode.d1.loss_mask: 0.3743  decode.d1.loss_dice: 0.2884  decode.d2.loss_cls: 0.1916  decode.d2.loss_mask: 0.3851  decode.d2.loss_dice: 0.2854  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 0.3668  decode.d3.loss_dice: 0.2837  decode.d4.loss_cls: 0.1867  decode.d4.loss_mask: 0.3556  decode.d4.loss_dice: 0.2810  decode.d5.loss_cls: 0.1942  decode.d5.loss_mask: 0.3581  decode.d5.loss_dice: 0.2724  decode.d6.loss_cls: 0.2054  decode.d6.loss_mask: 0.3594  decode.d6.loss_dice: 0.2779  decode.d7.loss_cls: 0.2563  decode.d7.loss_mask: 0.3619  decode.d7.loss_dice: 0.2822  decode.d8.loss_cls: 0.2516  decode.d8.loss_mask: 0.3638  decode.d8.loss_dice: 0.2827
09/28 15:17:29 - mmengine - INFO - Iter(train) [  6900/320000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 1 day, 14:02:32  time: 0.4299  data_time: 0.0087  memory: 5167  grad_norm: 67.3890  loss: 9.7744  decode.loss_cls: 0.2925  decode.loss_mask: 0.2541  decode.loss_dice: 0.2863  decode.d0.loss_cls: 0.9657  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.3198  decode.d1.loss_cls: 0.5818  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.2957  decode.d2.loss_cls: 0.3946  decode.d2.loss_mask: 0.2546  decode.d2.loss_dice: 0.2965  decode.d3.loss_cls: 0.3191  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.2765  decode.d4.loss_mask: 0.2552  decode.d4.loss_dice: 0.3225  decode.d5.loss_cls: 0.3272  decode.d5.loss_mask: 0.2537  decode.d5.loss_dice: 0.3034  decode.d6.loss_cls: 0.2847  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.3218  decode.d7.loss_cls: 0.3424  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.3082  decode.d8.loss_cls: 0.3651  decode.d8.loss_mask: 0.2601  decode.d8.loss_dice: 0.3053
09/28 15:17:50 - mmengine - INFO - Iter(train) [  6950/320000]  base_lr: 9.8043e-05 lr: 9.8043e-06  eta: 1 day, 14:01:54  time: 0.4303  data_time: 0.0088  memory: 5150  grad_norm: 125.2120  loss: 12.2792  decode.loss_cls: 0.3354  decode.loss_mask: 0.3894  decode.loss_dice: 0.3730  decode.d0.loss_cls: 1.2107  decode.d0.loss_mask: 0.4240  decode.d0.loss_dice: 0.3538  decode.d1.loss_cls: 0.4914  decode.d1.loss_mask: 0.3915  decode.d1.loss_dice: 0.3527  decode.d2.loss_cls: 0.4007  decode.d2.loss_mask: 0.3878  decode.d2.loss_dice: 0.3528  decode.d3.loss_cls: 0.4172  decode.d3.loss_mask: 0.3887  decode.d3.loss_dice: 0.3688  decode.d4.loss_cls: 0.3724  decode.d4.loss_mask: 0.3853  decode.d4.loss_dice: 0.3556  decode.d5.loss_cls: 0.4009  decode.d5.loss_mask: 0.3870  decode.d5.loss_dice: 0.3538  decode.d6.loss_cls: 0.3504  decode.d6.loss_mask: 0.3881  decode.d6.loss_dice: 0.3546  decode.d7.loss_cls: 0.3556  decode.d7.loss_mask: 0.4073  decode.d7.loss_dice: 0.3926  decode.d8.loss_cls: 0.3413  decode.d8.loss_mask: 0.4048  decode.d8.loss_dice: 0.3915
09/28 15:18:12 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:18:12 - mmengine - INFO - Iter(train) [  7000/320000]  base_lr: 9.8029e-05 lr: 9.8029e-06  eta: 1 day, 14:01:17  time: 0.4299  data_time: 0.0087  memory: 5167  grad_norm: 109.7652  loss: 9.9093  decode.loss_cls: 0.3666  decode.loss_mask: 0.2963  decode.loss_dice: 0.2556  decode.d0.loss_cls: 1.1701  decode.d0.loss_mask: 0.3092  decode.d0.loss_dice: 0.2815  decode.d1.loss_cls: 0.4097  decode.d1.loss_mask: 0.2996  decode.d1.loss_dice: 0.2504  decode.d2.loss_cls: 0.3660  decode.d2.loss_mask: 0.3021  decode.d2.loss_dice: 0.2705  decode.d3.loss_cls: 0.3153  decode.d3.loss_mask: 0.2908  decode.d3.loss_dice: 0.2660  decode.d4.loss_cls: 0.2917  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.2667  decode.d5.loss_cls: 0.3609  decode.d5.loss_mask: 0.2904  decode.d5.loss_dice: 0.2495  decode.d6.loss_cls: 0.3863  decode.d6.loss_mask: 0.2960  decode.d6.loss_dice: 0.2500  decode.d7.loss_cls: 0.3217  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.2556  decode.d8.loss_cls: 0.3396  decode.d8.loss_mask: 0.3008  decode.d8.loss_dice: 0.2555
09/28 15:18:33 - mmengine - INFO - Iter(train) [  7050/320000]  base_lr: 9.8015e-05 lr: 9.8015e-06  eta: 1 day, 14:00:40  time: 0.4308  data_time: 0.0089  memory: 5167  grad_norm: 143.6934  loss: 10.7861  decode.loss_cls: 0.4492  decode.loss_mask: 0.2870  decode.loss_dice: 0.3158  decode.d0.loss_cls: 1.1711  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.3784  decode.d1.loss_cls: 0.4728  decode.d1.loss_mask: 0.2417  decode.d1.loss_dice: 0.2902  decode.d2.loss_cls: 0.3978  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2788  decode.d3.loss_cls: 0.4412  decode.d3.loss_mask: 0.2601  decode.d3.loss_dice: 0.2713  decode.d4.loss_cls: 0.4295  decode.d4.loss_mask: 0.2691  decode.d4.loss_dice: 0.3333  decode.d5.loss_cls: 0.4538  decode.d5.loss_mask: 0.2530  decode.d5.loss_dice: 0.2398  decode.d6.loss_cls: 0.4372  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2912  decode.d7.loss_cls: 0.4550  decode.d7.loss_mask: 0.3007  decode.d7.loss_dice: 0.3493  decode.d8.loss_cls: 0.4382  decode.d8.loss_mask: 0.2465  decode.d8.loss_dice: 0.2642
09/28 15:18:55 - mmengine - INFO - Iter(train) [  7100/320000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 1 day, 14:00:05  time: 0.4300  data_time: 0.0088  memory: 5166  grad_norm: 121.6369  loss: 9.1741  decode.loss_cls: 0.2514  decode.loss_mask: 0.3269  decode.loss_dice: 0.2779  decode.d0.loss_cls: 0.8008  decode.d0.loss_mask: 0.3455  decode.d0.loss_dice: 0.3506  decode.d1.loss_cls: 0.3495  decode.d1.loss_mask: 0.3158  decode.d1.loss_dice: 0.2782  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.3229  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.2510  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.2862  decode.d4.loss_cls: 0.2359  decode.d4.loss_mask: 0.3197  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.2388  decode.d5.loss_mask: 0.3256  decode.d5.loss_dice: 0.2817  decode.d6.loss_cls: 0.2496  decode.d6.loss_mask: 0.3198  decode.d6.loss_dice: 0.2773  decode.d7.loss_cls: 0.1973  decode.d7.loss_mask: 0.3257  decode.d7.loss_dice: 0.2771  decode.d8.loss_cls: 0.2417  decode.d8.loss_mask: 0.3213  decode.d8.loss_dice: 0.2837
09/28 15:19:16 - mmengine - INFO - Iter(train) [  7150/320000]  base_lr: 9.7987e-05 lr: 9.7987e-06  eta: 1 day, 13:59:29  time: 0.4302  data_time: 0.0088  memory: 5166  grad_norm: 79.1799  loss: 8.7973  decode.loss_cls: 0.3564  decode.loss_mask: 0.2518  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.8347  decode.d0.loss_mask: 0.2811  decode.d0.loss_dice: 0.2604  decode.d1.loss_cls: 0.3401  decode.d1.loss_mask: 0.2490  decode.d1.loss_dice: 0.2280  decode.d2.loss_cls: 0.2630  decode.d2.loss_mask: 0.2532  decode.d2.loss_dice: 0.2566  decode.d3.loss_cls: 0.2881  decode.d3.loss_mask: 0.2507  decode.d3.loss_dice: 0.2277  decode.d4.loss_cls: 0.3575  decode.d4.loss_mask: 0.2476  decode.d4.loss_dice: 0.2436  decode.d5.loss_cls: 0.4365  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.3457  decode.d6.loss_mask: 0.2460  decode.d6.loss_dice: 0.2208  decode.d7.loss_cls: 0.3469  decode.d7.loss_mask: 0.2440  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.3166  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.2231
09/28 15:19:38 - mmengine - INFO - Iter(train) [  7200/320000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 1 day, 13:58:53  time: 0.4314  data_time: 0.0090  memory: 5166  grad_norm: 96.6453  loss: 9.2060  decode.loss_cls: 0.2918  decode.loss_mask: 0.3089  decode.loss_dice: 0.2564  decode.d0.loss_cls: 1.0268  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.2573  decode.d1.loss_cls: 0.2740  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.2400  decode.d2.loss_cls: 0.2404  decode.d2.loss_mask: 0.4801  decode.d2.loss_dice: 0.2670  decode.d3.loss_cls: 0.3045  decode.d3.loss_mask: 0.2852  decode.d3.loss_dice: 0.2250  decode.d4.loss_cls: 0.3153  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.2237  decode.d5.loss_cls: 0.3134  decode.d5.loss_mask: 0.2863  decode.d5.loss_dice: 0.2062  decode.d6.loss_cls: 0.3608  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.2135  decode.d7.loss_cls: 0.3267  decode.d7.loss_mask: 0.2801  decode.d7.loss_dice: 0.2130  decode.d8.loss_cls: 0.2906  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.2292
09/28 15:20:00 - mmengine - INFO - Iter(train) [  7250/320000]  base_lr: 9.7959e-05 lr: 9.7959e-06  eta: 1 day, 13:58:17  time: 0.4309  data_time: 0.0088  memory: 5167  grad_norm: 144.4027  loss: 14.5766  decode.loss_cls: 0.5798  decode.loss_mask: 0.3902  decode.loss_dice: 0.4051  decode.d0.loss_cls: 1.3426  decode.d0.loss_mask: 0.3725  decode.d0.loss_dice: 0.3813  decode.d1.loss_cls: 0.5875  decode.d1.loss_mask: 0.4124  decode.d1.loss_dice: 0.4156  decode.d2.loss_cls: 0.5695  decode.d2.loss_mask: 0.3957  decode.d2.loss_dice: 0.4297  decode.d3.loss_cls: 0.5525  decode.d3.loss_mask: 0.3846  decode.d3.loss_dice: 0.4442  decode.d4.loss_cls: 0.5659  decode.d4.loss_mask: 0.3667  decode.d4.loss_dice: 0.4307  decode.d5.loss_cls: 0.5966  decode.d5.loss_mask: 0.3550  decode.d5.loss_dice: 0.3648  decode.d6.loss_cls: 0.5820  decode.d6.loss_mask: 0.3945  decode.d6.loss_dice: 0.4329  decode.d7.loss_cls: 0.5797  decode.d7.loss_mask: 0.3770  decode.d7.loss_dice: 0.4240  decode.d8.loss_cls: 0.6007  decode.d8.loss_mask: 0.4210  decode.d8.loss_dice: 0.4219
09/28 15:20:21 - mmengine - INFO - Iter(train) [  7300/320000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 1 day, 13:57:40  time: 0.4296  data_time: 0.0089  memory: 5166  grad_norm: 80.7816  loss: 10.1078  decode.loss_cls: 0.3315  decode.loss_mask: 0.3149  decode.loss_dice: 0.2396  decode.d0.loss_cls: 1.1183  decode.d0.loss_mask: 0.2985  decode.d0.loss_dice: 0.2845  decode.d1.loss_cls: 0.4374  decode.d1.loss_mask: 0.3026  decode.d1.loss_dice: 0.2432  decode.d2.loss_cls: 0.3561  decode.d2.loss_mask: 0.3205  decode.d2.loss_dice: 0.2408  decode.d3.loss_cls: 0.3288  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.2442  decode.d4.loss_cls: 0.4391  decode.d4.loss_mask: 0.3125  decode.d4.loss_dice: 0.2542  decode.d5.loss_cls: 0.3896  decode.d5.loss_mask: 0.3276  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.3645  decode.d6.loss_mask: 0.3088  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.3798  decode.d7.loss_mask: 0.2904  decode.d7.loss_dice: 0.2421  decode.d8.loss_cls: 0.3465  decode.d8.loss_mask: 0.2985  decode.d8.loss_dice: 0.2696
09/28 15:20:43 - mmengine - INFO - Iter(train) [  7350/320000]  base_lr: 9.7931e-05 lr: 9.7931e-06  eta: 1 day, 13:57:04  time: 0.4299  data_time: 0.0088  memory: 5167  grad_norm: 160.5326  loss: 14.0539  decode.loss_cls: 0.5869  decode.loss_mask: 0.3913  decode.loss_dice: 0.4260  decode.d0.loss_cls: 1.3167  decode.d0.loss_mask: 0.4222  decode.d0.loss_dice: 0.4820  decode.d1.loss_cls: 0.5522  decode.d1.loss_mask: 0.3681  decode.d1.loss_dice: 0.3659  decode.d2.loss_cls: 0.5448  decode.d2.loss_mask: 0.3852  decode.d2.loss_dice: 0.3730  decode.d3.loss_cls: 0.4817  decode.d3.loss_mask: 0.3863  decode.d3.loss_dice: 0.3649  decode.d4.loss_cls: 0.4965  decode.d4.loss_mask: 0.4110  decode.d4.loss_dice: 0.3938  decode.d5.loss_cls: 0.4759  decode.d5.loss_mask: 0.4310  decode.d5.loss_dice: 0.3933  decode.d6.loss_cls: 0.4355  decode.d6.loss_mask: 0.4067  decode.d6.loss_dice: 0.4023  decode.d7.loss_cls: 0.5112  decode.d7.loss_mask: 0.4119  decode.d7.loss_dice: 0.4409  decode.d8.loss_cls: 0.5395  decode.d8.loss_mask: 0.4117  decode.d8.loss_dice: 0.4458
09/28 15:21:04 - mmengine - INFO - Iter(train) [  7400/320000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 1 day, 13:56:28  time: 0.4305  data_time: 0.0089  memory: 5186  grad_norm: 113.8245  loss: 9.4495  decode.loss_cls: 0.2903  decode.loss_mask: 0.3296  decode.loss_dice: 0.2662  decode.d0.loss_cls: 1.1958  decode.d0.loss_mask: 0.3240  decode.d0.loss_dice: 0.2726  decode.d1.loss_cls: 0.2405  decode.d1.loss_mask: 0.3206  decode.d1.loss_dice: 0.2806  decode.d2.loss_cls: 0.2229  decode.d2.loss_mask: 0.3373  decode.d2.loss_dice: 0.2907  decode.d3.loss_cls: 0.2071  decode.d3.loss_mask: 0.3214  decode.d3.loss_dice: 0.2866  decode.d4.loss_cls: 0.1950  decode.d4.loss_mask: 0.3231  decode.d4.loss_dice: 0.2809  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 0.3318  decode.d5.loss_dice: 0.2767  decode.d6.loss_cls: 0.2834  decode.d6.loss_mask: 0.3286  decode.d6.loss_dice: 0.2791  decode.d7.loss_cls: 0.2645  decode.d7.loss_mask: 0.3301  decode.d7.loss_dice: 0.2717  decode.d8.loss_cls: 0.2614  decode.d8.loss_mask: 0.3342  decode.d8.loss_dice: 0.2749
09/28 15:21:26 - mmengine - INFO - Iter(train) [  7450/320000]  base_lr: 9.7903e-05 lr: 9.7903e-06  eta: 1 day, 13:55:53  time: 0.4301  data_time: 0.0089  memory: 5149  grad_norm: 74.5998  loss: 9.5928  decode.loss_cls: 0.4264  decode.loss_mask: 0.2295  decode.loss_dice: 0.2607  decode.d0.loss_cls: 1.1691  decode.d0.loss_mask: 0.2346  decode.d0.loss_dice: 0.2416  decode.d1.loss_cls: 0.4844  decode.d1.loss_mask: 0.2214  decode.d1.loss_dice: 0.2308  decode.d2.loss_cls: 0.4366  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.2187  decode.d3.loss_cls: 0.3448  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.2266  decode.d4.loss_cls: 0.3988  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.2198  decode.d5.loss_cls: 0.4053  decode.d5.loss_mask: 0.2218  decode.d5.loss_dice: 0.2209  decode.d6.loss_cls: 0.4263  decode.d6.loss_mask: 0.2213  decode.d6.loss_dice: 0.2146  decode.d7.loss_cls: 0.4454  decode.d7.loss_mask: 0.2244  decode.d7.loss_dice: 0.2246  decode.d8.loss_cls: 0.4720  decode.d8.loss_mask: 0.2331  decode.d8.loss_dice: 0.2674
09/28 15:21:47 - mmengine - INFO - Iter(train) [  7500/320000]  base_lr: 9.7888e-05 lr: 9.7888e-06  eta: 1 day, 13:55:18  time: 0.4312  data_time: 0.0088  memory: 5186  grad_norm: 81.9513  loss: 11.5687  decode.loss_cls: 0.4973  decode.loss_mask: 0.3250  decode.loss_dice: 0.2801  decode.d0.loss_cls: 1.2915  decode.d0.loss_mask: 0.3120  decode.d0.loss_dice: 0.2945  decode.d1.loss_cls: 0.5130  decode.d1.loss_mask: 0.3115  decode.d1.loss_dice: 0.2774  decode.d2.loss_cls: 0.4881  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.2694  decode.d3.loss_cls: 0.4971  decode.d3.loss_mask: 0.3016  decode.d3.loss_dice: 0.2904  decode.d4.loss_cls: 0.4116  decode.d4.loss_mask: 0.3082  decode.d4.loss_dice: 0.2822  decode.d5.loss_cls: 0.4553  decode.d5.loss_mask: 0.3091  decode.d5.loss_dice: 0.2722  decode.d6.loss_cls: 0.5001  decode.d6.loss_mask: 0.3371  decode.d6.loss_dice: 0.2781  decode.d7.loss_cls: 0.4716  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.4821  decode.d8.loss_mask: 0.3097  decode.d8.loss_dice: 0.2779
09/28 15:22:09 - mmengine - INFO - Iter(train) [  7550/320000]  base_lr: 9.7874e-05 lr: 9.7874e-06  eta: 1 day, 13:54:43  time: 0.4306  data_time: 0.0088  memory: 5167  grad_norm: 126.7655  loss: 9.6251  decode.loss_cls: 0.2598  decode.loss_mask: 0.3329  decode.loss_dice: 0.2608  decode.d0.loss_cls: 1.1318  decode.d0.loss_mask: 0.3445  decode.d0.loss_dice: 0.2925  decode.d1.loss_cls: 0.3465  decode.d1.loss_mask: 0.3418  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.3093  decode.d2.loss_mask: 0.3365  decode.d2.loss_dice: 0.2446  decode.d3.loss_cls: 0.2639  decode.d3.loss_mask: 0.3314  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.2674  decode.d4.loss_mask: 0.3387  decode.d4.loss_dice: 0.2473  decode.d5.loss_cls: 0.3176  decode.d5.loss_mask: 0.3367  decode.d5.loss_dice: 0.2338  decode.d6.loss_cls: 0.2824  decode.d6.loss_mask: 0.3382  decode.d6.loss_dice: 0.2404  decode.d7.loss_cls: 0.2772  decode.d7.loss_mask: 0.3362  decode.d7.loss_dice: 0.2336  decode.d8.loss_cls: 0.2874  decode.d8.loss_mask: 0.3354  decode.d8.loss_dice: 0.2531
09/28 15:22:30 - mmengine - INFO - Iter(train) [  7600/320000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 1 day, 13:54:08  time: 0.4308  data_time: 0.0089  memory: 5166  grad_norm: 109.5680  loss: 12.0631  decode.loss_cls: 0.4422  decode.loss_mask: 0.2959  decode.loss_dice: 0.3474  decode.d0.loss_cls: 1.2276  decode.d0.loss_mask: 0.3399  decode.d0.loss_dice: 0.4076  decode.d1.loss_cls: 0.5099  decode.d1.loss_mask: 0.3021  decode.d1.loss_dice: 0.3692  decode.d2.loss_cls: 0.4842  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.4642  decode.d3.loss_mask: 0.3017  decode.d3.loss_dice: 0.3568  decode.d4.loss_cls: 0.5011  decode.d4.loss_mask: 0.2987  decode.d4.loss_dice: 0.3534  decode.d5.loss_cls: 0.5249  decode.d5.loss_mask: 0.3037  decode.d5.loss_dice: 0.3680  decode.d6.loss_cls: 0.4798  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.3324  decode.d7.loss_cls: 0.4310  decode.d7.loss_mask: 0.2947  decode.d7.loss_dice: 0.3437  decode.d8.loss_cls: 0.4272  decode.d8.loss_mask: 0.2934  decode.d8.loss_dice: 0.3388
09/28 15:22:52 - mmengine - INFO - Iter(train) [  7650/320000]  base_lr: 9.7846e-05 lr: 9.7846e-06  eta: 1 day, 13:53:33  time: 0.4306  data_time: 0.0088  memory: 5167  grad_norm: 128.5263  loss: 9.4120  decode.loss_cls: 0.3114  decode.loss_mask: 0.3152  decode.loss_dice: 0.3062  decode.d0.loss_cls: 1.1191  decode.d0.loss_mask: 0.3058  decode.d0.loss_dice: 0.2991  decode.d1.loss_cls: 0.2715  decode.d1.loss_mask: 0.3059  decode.d1.loss_dice: 0.2987  decode.d2.loss_cls: 0.1951  decode.d2.loss_mask: 0.3169  decode.d2.loss_dice: 0.2946  decode.d3.loss_cls: 0.2000  decode.d3.loss_mask: 0.3079  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.2095  decode.d4.loss_mask: 0.3021  decode.d4.loss_dice: 0.2765  decode.d5.loss_cls: 0.2410  decode.d5.loss_mask: 0.3020  decode.d5.loss_dice: 0.2742  decode.d6.loss_cls: 0.2634  decode.d6.loss_mask: 0.3043  decode.d6.loss_dice: 0.2874  decode.d7.loss_cls: 0.2664  decode.d7.loss_mask: 0.3252  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.3160  decode.d8.loss_mask: 0.3182  decode.d8.loss_dice: 0.3006
09/28 15:23:13 - mmengine - INFO - Iter(train) [  7700/320000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 1 day, 13:52:58  time: 0.4303  data_time: 0.0090  memory: 5166  grad_norm: 253.5241  loss: 11.1173  decode.loss_cls: 0.4133  decode.loss_mask: 0.3566  decode.loss_dice: 0.2885  decode.d0.loss_cls: 1.0612  decode.d0.loss_mask: 0.3797  decode.d0.loss_dice: 0.3097  decode.d1.loss_cls: 0.3190  decode.d1.loss_mask: 0.3856  decode.d1.loss_dice: 0.3090  decode.d2.loss_cls: 0.2990  decode.d2.loss_mask: 0.3662  decode.d2.loss_dice: 0.2618  decode.d3.loss_cls: 0.3571  decode.d3.loss_mask: 0.3634  decode.d3.loss_dice: 0.2913  decode.d4.loss_cls: 0.4039  decode.d4.loss_mask: 0.3671  decode.d4.loss_dice: 0.2871  decode.d5.loss_cls: 0.3968  decode.d5.loss_mask: 0.3720  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.3496  decode.d6.loss_mask: 0.3663  decode.d6.loss_dice: 0.3074  decode.d7.loss_cls: 0.3833  decode.d7.loss_mask: 0.3865  decode.d7.loss_dice: 0.3320  decode.d8.loss_cls: 0.3906  decode.d8.loss_mask: 0.3791  decode.d8.loss_dice: 0.3352
09/28 15:23:35 - mmengine - INFO - Iter(train) [  7750/320000]  base_lr: 9.7818e-05 lr: 9.7818e-06  eta: 1 day, 13:52:23  time: 0.4299  data_time: 0.0089  memory: 5150  grad_norm: 124.4728  loss: 12.8899  decode.loss_cls: 0.4940  decode.loss_mask: 0.3288  decode.loss_dice: 0.3953  decode.d0.loss_cls: 1.1801  decode.d0.loss_mask: 0.3025  decode.d0.loss_dice: 0.3689  decode.d1.loss_cls: 0.6116  decode.d1.loss_mask: 0.2827  decode.d1.loss_dice: 0.3428  decode.d2.loss_cls: 0.4503  decode.d2.loss_mask: 0.3790  decode.d2.loss_dice: 0.3827  decode.d3.loss_cls: 0.4671  decode.d3.loss_mask: 0.4076  decode.d3.loss_dice: 0.3562  decode.d4.loss_cls: 0.5379  decode.d4.loss_mask: 0.3930  decode.d4.loss_dice: 0.3677  decode.d5.loss_cls: 0.5410  decode.d5.loss_mask: 0.4062  decode.d5.loss_dice: 0.3567  decode.d6.loss_cls: 0.5352  decode.d6.loss_mask: 0.3546  decode.d6.loss_dice: 0.3552  decode.d7.loss_cls: 0.5142  decode.d7.loss_mask: 0.3389  decode.d7.loss_dice: 0.3436  decode.d8.loss_cls: 0.4289  decode.d8.loss_mask: 0.3268  decode.d8.loss_dice: 0.3401
09/28 15:23:56 - mmengine - INFO - Iter(train) [  7800/320000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 1 day, 13:51:48  time: 0.4296  data_time: 0.0087  memory: 5186  grad_norm: 128.7845  loss: 10.6709  decode.loss_cls: 0.4154  decode.loss_mask: 0.3067  decode.loss_dice: 0.2557  decode.d0.loss_cls: 1.1167  decode.d0.loss_mask: 0.3227  decode.d0.loss_dice: 0.2469  decode.d1.loss_cls: 0.4516  decode.d1.loss_mask: 0.3124  decode.d1.loss_dice: 0.2717  decode.d2.loss_cls: 0.3929  decode.d2.loss_mask: 0.3002  decode.d2.loss_dice: 0.2291  decode.d3.loss_cls: 0.4209  decode.d3.loss_mask: 0.3000  decode.d3.loss_dice: 0.2104  decode.d4.loss_cls: 0.5089  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.2153  decode.d5.loss_cls: 0.5594  decode.d5.loss_mask: 0.3130  decode.d5.loss_dice: 0.2325  decode.d6.loss_cls: 0.5182  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.4978  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.2219  decode.d8.loss_cls: 0.4075  decode.d8.loss_mask: 0.2984  decode.d8.loss_dice: 0.2298
09/28 15:24:18 - mmengine - INFO - Iter(train) [  7850/320000]  base_lr: 9.7790e-05 lr: 9.7790e-06  eta: 1 day, 13:51:21  time: 0.4304  data_time: 0.0088  memory: 5186  grad_norm: 119.5149  loss: 10.3066  decode.loss_cls: 0.4583  decode.loss_mask: 0.2480  decode.loss_dice: 0.2740  decode.d0.loss_cls: 1.1960  decode.d0.loss_mask: 0.2537  decode.d0.loss_dice: 0.3096  decode.d1.loss_cls: 0.3923  decode.d1.loss_mask: 0.2421  decode.d1.loss_dice: 0.2847  decode.d2.loss_cls: 0.4182  decode.d2.loss_mask: 0.2436  decode.d2.loss_dice: 0.2700  decode.d3.loss_cls: 0.3773  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.2914  decode.d4.loss_cls: 0.3965  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.3309  decode.d5.loss_mask: 0.2661  decode.d5.loss_dice: 0.2841  decode.d6.loss_cls: 0.3984  decode.d6.loss_mask: 0.2718  decode.d6.loss_dice: 0.2953  decode.d7.loss_cls: 0.4513  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2743  decode.d8.loss_cls: 0.4829  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2636
09/28 15:24:39 - mmengine - INFO - Iter(train) [  7900/320000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 1 day, 13:50:47  time: 0.4303  data_time: 0.0088  memory: 5186  grad_norm: 263.1483  loss: 11.7180  decode.loss_cls: 0.2702  decode.loss_mask: 0.4014  decode.loss_dice: 0.3576  decode.d0.loss_cls: 1.1554  decode.d0.loss_mask: 0.4584  decode.d0.loss_dice: 0.4084  decode.d1.loss_cls: 0.4366  decode.d1.loss_mask: 0.4127  decode.d1.loss_dice: 0.3728  decode.d2.loss_cls: 0.3331  decode.d2.loss_mask: 0.4277  decode.d2.loss_dice: 0.3598  decode.d3.loss_cls: 0.3148  decode.d3.loss_mask: 0.4129  decode.d3.loss_dice: 0.3473  decode.d4.loss_cls: 0.3083  decode.d4.loss_mask: 0.4049  decode.d4.loss_dice: 0.3484  decode.d5.loss_cls: 0.3293  decode.d5.loss_mask: 0.4155  decode.d5.loss_dice: 0.3509  decode.d6.loss_cls: 0.2388  decode.d6.loss_mask: 0.4109  decode.d6.loss_dice: 0.3395  decode.d7.loss_cls: 0.2785  decode.d7.loss_mask: 0.4106  decode.d7.loss_dice: 0.3480  decode.d8.loss_cls: 0.2767  decode.d8.loss_mask: 0.4403  decode.d8.loss_dice: 0.3483
09/28 15:25:01 - mmengine - INFO - Iter(train) [  7950/320000]  base_lr: 9.7762e-05 lr: 9.7762e-06  eta: 1 day, 13:50:14  time: 0.4306  data_time: 0.0089  memory: 5150  grad_norm: 146.8158  loss: 10.4080  decode.loss_cls: 0.3761  decode.loss_mask: 0.3622  decode.loss_dice: 0.2565  decode.d0.loss_cls: 1.0003  decode.d0.loss_mask: 0.3769  decode.d0.loss_dice: 0.3518  decode.d1.loss_cls: 0.3793  decode.d1.loss_mask: 0.3760  decode.d1.loss_dice: 0.2898  decode.d2.loss_cls: 0.2882  decode.d2.loss_mask: 0.3777  decode.d2.loss_dice: 0.2890  decode.d3.loss_cls: 0.2656  decode.d3.loss_mask: 0.3957  decode.d3.loss_dice: 0.2771  decode.d4.loss_cls: 0.2474  decode.d4.loss_mask: 0.4233  decode.d4.loss_dice: 0.2909  decode.d5.loss_cls: 0.2512  decode.d5.loss_mask: 0.4006  decode.d5.loss_dice: 0.2872  decode.d6.loss_cls: 0.2521  decode.d6.loss_mask: 0.3872  decode.d6.loss_dice: 0.2843  decode.d7.loss_cls: 0.2650  decode.d7.loss_mask: 0.3957  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.3625  decode.d8.loss_mask: 0.3601  decode.d8.loss_dice: 0.2532
09/28 15:25:23 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:25:23 - mmengine - INFO - Iter(train) [  8000/320000]  base_lr: 9.7747e-05 lr: 9.7747e-06  eta: 1 day, 13:49:40  time: 0.4297  data_time: 0.0089  memory: 5166  grad_norm: 120.9720  loss: 9.6507  decode.loss_cls: 0.3745  decode.loss_mask: 0.3681  decode.loss_dice: 0.3142  decode.d0.loss_cls: 1.0460  decode.d0.loss_mask: 0.2891  decode.d0.loss_dice: 0.2925  decode.d1.loss_cls: 0.2802  decode.d1.loss_mask: 0.2916  decode.d1.loss_dice: 0.2436  decode.d2.loss_cls: 0.2785  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.2390  decode.d3.loss_cls: 0.2729  decode.d3.loss_mask: 0.2981  decode.d3.loss_dice: 0.2375  decode.d4.loss_cls: 0.3159  decode.d4.loss_mask: 0.3152  decode.d4.loss_dice: 0.2506  decode.d5.loss_cls: 0.3235  decode.d5.loss_mask: 0.3074  decode.d5.loss_dice: 0.2645  decode.d6.loss_cls: 0.2579  decode.d6.loss_mask: 0.2978  decode.d6.loss_dice: 0.2801  decode.d7.loss_cls: 0.2706  decode.d7.loss_mask: 0.3087  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.2862  decode.d8.loss_mask: 0.4274  decode.d8.loss_dice: 0.3263
09/28 15:25:44 - mmengine - INFO - Iter(train) [  8050/320000]  base_lr: 9.7733e-05 lr: 9.7733e-06  eta: 1 day, 13:49:06  time: 0.4300  data_time: 0.0088  memory: 5166  grad_norm: 94.6883  loss: 11.0007  decode.loss_cls: 0.4843  decode.loss_mask: 0.2534  decode.loss_dice: 0.2683  decode.d0.loss_cls: 1.0343  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.2757  decode.d1.loss_cls: 0.6107  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.2396  decode.d2.loss_cls: 0.6559  decode.d2.loss_mask: 0.2428  decode.d2.loss_dice: 0.2424  decode.d3.loss_cls: 0.6353  decode.d3.loss_mask: 0.2439  decode.d3.loss_dice: 0.2575  decode.d4.loss_cls: 0.5575  decode.d4.loss_mask: 0.2464  decode.d4.loss_dice: 0.2787  decode.d5.loss_cls: 0.4726  decode.d5.loss_mask: 0.2490  decode.d5.loss_dice: 0.3050  decode.d6.loss_cls: 0.4292  decode.d6.loss_mask: 0.2466  decode.d6.loss_dice: 0.2810  decode.d7.loss_cls: 0.4504  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2695  decode.d8.loss_cls: 0.4874  decode.d8.loss_mask: 0.2492  decode.d8.loss_dice: 0.2910
09/28 15:26:06 - mmengine - INFO - Iter(train) [  8100/320000]  base_lr: 9.7719e-05 lr: 9.7719e-06  eta: 1 day, 13:48:33  time: 0.4308  data_time: 0.0090  memory: 5166  grad_norm: 106.3855  loss: 10.5899  decode.loss_cls: 0.3861  decode.loss_mask: 0.3005  decode.loss_dice: 0.2708  decode.d0.loss_cls: 0.9479  decode.d0.loss_mask: 0.2766  decode.d0.loss_dice: 0.2610  decode.d1.loss_cls: 0.5952  decode.d1.loss_mask: 0.2881  decode.d1.loss_dice: 0.2675  decode.d2.loss_cls: 0.4936  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.2584  decode.d3.loss_cls: 0.4814  decode.d3.loss_mask: 0.2939  decode.d3.loss_dice: 0.2628  decode.d4.loss_cls: 0.5122  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.2650  decode.d5.loss_cls: 0.4225  decode.d5.loss_mask: 0.2876  decode.d5.loss_dice: 0.2800  decode.d6.loss_cls: 0.3750  decode.d6.loss_mask: 0.2765  decode.d6.loss_dice: 0.2615  decode.d7.loss_cls: 0.4538  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.2610  decode.d8.loss_cls: 0.4187  decode.d8.loss_mask: 0.2921  decode.d8.loss_dice: 0.2567
09/28 15:26:27 - mmengine - INFO - Iter(train) [  8150/320000]  base_lr: 9.7705e-05 lr: 9.7705e-06  eta: 1 day, 13:47:59  time: 0.4301  data_time: 0.0089  memory: 5186  grad_norm: 127.1079  loss: 8.4726  decode.loss_cls: 0.2425  decode.loss_mask: 0.3206  decode.loss_dice: 0.1971  decode.d0.loss_cls: 0.9844  decode.d0.loss_mask: 0.3309  decode.d0.loss_dice: 0.2204  decode.d1.loss_cls: 0.3091  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.2043  decode.d2.loss_cls: 0.2430  decode.d2.loss_mask: 0.3154  decode.d2.loss_dice: 0.2032  decode.d3.loss_cls: 0.2418  decode.d3.loss_mask: 0.3115  decode.d3.loss_dice: 0.1976  decode.d4.loss_cls: 0.2446  decode.d4.loss_mask: 0.3126  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.2267  decode.d5.loss_mask: 0.3270  decode.d5.loss_dice: 0.2069  decode.d6.loss_cls: 0.2702  decode.d6.loss_mask: 0.3124  decode.d6.loss_dice: 0.1923  decode.d7.loss_cls: 0.2559  decode.d7.loss_mask: 0.3240  decode.d7.loss_dice: 0.1971  decode.d8.loss_cls: 0.2428  decode.d8.loss_mask: 0.3197  decode.d8.loss_dice: 0.2004
09/28 15:26:49 - mmengine - INFO - Iter(train) [  8200/320000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 1 day, 13:47:26  time: 0.4302  data_time: 0.0089  memory: 5150  grad_norm: 128.3672  loss: 12.2358  decode.loss_cls: 0.4927  decode.loss_mask: 0.4274  decode.loss_dice: 0.3427  decode.d0.loss_cls: 0.9974  decode.d0.loss_mask: 0.3465  decode.d0.loss_dice: 0.3200  decode.d1.loss_cls: 0.5687  decode.d1.loss_mask: 0.3816  decode.d1.loss_dice: 0.3087  decode.d2.loss_cls: 0.4377  decode.d2.loss_mask: 0.3747  decode.d2.loss_dice: 0.3212  decode.d3.loss_cls: 0.4607  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.2990  decode.d4.loss_cls: 0.3941  decode.d4.loss_mask: 0.3791  decode.d4.loss_dice: 0.2820  decode.d5.loss_cls: 0.4326  decode.d5.loss_mask: 0.3890  decode.d5.loss_dice: 0.2648  decode.d6.loss_cls: 0.4995  decode.d6.loss_mask: 0.3850  decode.d6.loss_dice: 0.3132  decode.d7.loss_cls: 0.4528  decode.d7.loss_mask: 0.4410  decode.d7.loss_dice: 0.3543  decode.d8.loss_cls: 0.4256  decode.d8.loss_mask: 0.4229  decode.d8.loss_dice: 0.3433
09/28 15:27:10 - mmengine - INFO - Iter(train) [  8250/320000]  base_lr: 9.7677e-05 lr: 9.7677e-06  eta: 1 day, 13:46:53  time: 0.4303  data_time: 0.0090  memory: 5166  grad_norm: 105.0728  loss: 9.3043  decode.loss_cls: 0.3868  decode.loss_mask: 0.2567  decode.loss_dice: 0.2168  decode.d0.loss_cls: 1.0439  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.2401  decode.d1.loss_cls: 0.3614  decode.d1.loss_mask: 0.3469  decode.d1.loss_dice: 0.2393  decode.d2.loss_cls: 0.3136  decode.d2.loss_mask: 0.3344  decode.d2.loss_dice: 0.2248  decode.d3.loss_cls: 0.2430  decode.d3.loss_mask: 0.3275  decode.d3.loss_dice: 0.2201  decode.d4.loss_cls: 0.2357  decode.d4.loss_mask: 0.3393  decode.d4.loss_dice: 0.2276  decode.d5.loss_cls: 0.2680  decode.d5.loss_mask: 0.3359  decode.d5.loss_dice: 0.2261  decode.d6.loss_cls: 0.3209  decode.d6.loss_mask: 0.3690  decode.d6.loss_dice: 0.2280  decode.d7.loss_cls: 0.3034  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.3856  decode.d8.loss_mask: 0.2657  decode.d8.loss_dice: 0.2158
09/28 15:27:32 - mmengine - INFO - Iter(train) [  8300/320000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 1 day, 13:46:20  time: 0.4312  data_time: 0.0090  memory: 5186  grad_norm: 83.7723  loss: 10.9297  decode.loss_cls: 0.4414  decode.loss_mask: 0.3280  decode.loss_dice: 0.2807  decode.d0.loss_cls: 1.1551  decode.d0.loss_mask: 0.3370  decode.d0.loss_dice: 0.2929  decode.d1.loss_cls: 0.4826  decode.d1.loss_mask: 0.3208  decode.d1.loss_dice: 0.2450  decode.d2.loss_cls: 0.4030  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.2614  decode.d3.loss_cls: 0.4075  decode.d3.loss_mask: 0.3236  decode.d3.loss_dice: 0.2760  decode.d4.loss_cls: 0.4711  decode.d4.loss_mask: 0.3391  decode.d4.loss_dice: 0.2655  decode.d5.loss_cls: 0.3904  decode.d5.loss_mask: 0.3384  decode.d5.loss_dice: 0.2789  decode.d6.loss_cls: 0.4736  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.2596  decode.d7.loss_cls: 0.3425  decode.d7.loss_mask: 0.3189  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.3650  decode.d8.loss_mask: 0.3477  decode.d8.loss_dice: 0.2852
09/28 15:27:53 - mmengine - INFO - Iter(train) [  8350/320000]  base_lr: 9.7649e-05 lr: 9.7649e-06  eta: 1 day, 13:45:48  time: 0.4302  data_time: 0.0089  memory: 5186  grad_norm: 55.7912  loss: 7.5196  decode.loss_cls: 0.2561  decode.loss_mask: 0.2154  decode.loss_dice: 0.1773  decode.d0.loss_cls: 1.0330  decode.d0.loss_mask: 0.2315  decode.d0.loss_dice: 0.1947  decode.d1.loss_cls: 0.2075  decode.d1.loss_mask: 0.2488  decode.d1.loss_dice: 0.2178  decode.d2.loss_cls: 0.2466  decode.d2.loss_mask: 0.2531  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.2569  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.1794  decode.d4.loss_cls: 0.2855  decode.d4.loss_mask: 0.2150  decode.d4.loss_dice: 0.1738  decode.d5.loss_cls: 0.2772  decode.d5.loss_mask: 0.2213  decode.d5.loss_dice: 0.1814  decode.d6.loss_cls: 0.2511  decode.d6.loss_mask: 0.2152  decode.d6.loss_dice: 0.1749  decode.d7.loss_cls: 0.2807  decode.d7.loss_mask: 0.2158  decode.d7.loss_dice: 0.1973  decode.d8.loss_cls: 0.2797  decode.d8.loss_mask: 0.2156  decode.d8.loss_dice: 0.1883
09/28 15:28:15 - mmengine - INFO - Iter(train) [  8400/320000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 1 day, 13:45:15  time: 0.4309  data_time: 0.0089  memory: 5150  grad_norm: 177.8460  loss: 11.9072  decode.loss_cls: 0.4451  decode.loss_mask: 0.3747  decode.loss_dice: 0.2750  decode.d0.loss_cls: 1.3398  decode.d0.loss_mask: 0.3485  decode.d0.loss_dice: 0.3146  decode.d1.loss_cls: 0.4839  decode.d1.loss_mask: 0.3219  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.4863  decode.d2.loss_mask: 0.3334  decode.d2.loss_dice: 0.2541  decode.d3.loss_cls: 0.3675  decode.d3.loss_mask: 0.4093  decode.d3.loss_dice: 0.2633  decode.d4.loss_cls: 0.3000  decode.d4.loss_mask: 0.4389  decode.d4.loss_dice: 0.2769  decode.d5.loss_cls: 0.3875  decode.d5.loss_mask: 0.4753  decode.d5.loss_dice: 0.3097  decode.d6.loss_cls: 0.4687  decode.d6.loss_mask: 0.4804  decode.d6.loss_dice: 0.3137  decode.d7.loss_cls: 0.3776  decode.d7.loss_mask: 0.3976  decode.d7.loss_dice: 0.3115  decode.d8.loss_cls: 0.3426  decode.d8.loss_mask: 0.4451  decode.d8.loss_dice: 0.3095
09/28 15:28:38 - mmengine - INFO - Iter(train) [  8450/320000]  base_lr: 9.7621e-05 lr: 9.7621e-06  eta: 1 day, 13:45:44  time: 0.4702  data_time: 0.0093  memory: 5150  grad_norm: 76.2495  loss: 11.0990  decode.loss_cls: 0.3326  decode.loss_mask: 0.3427  decode.loss_dice: 0.3302  decode.d0.loss_cls: 1.2827  decode.d0.loss_mask: 0.3337  decode.d0.loss_dice: 0.3561  decode.d1.loss_cls: 0.4174  decode.d1.loss_mask: 0.3285  decode.d1.loss_dice: 0.3383  decode.d2.loss_cls: 0.3255  decode.d2.loss_mask: 0.3583  decode.d2.loss_dice: 0.3168  decode.d3.loss_cls: 0.3174  decode.d3.loss_mask: 0.3288  decode.d3.loss_dice: 0.3189  decode.d4.loss_cls: 0.3511  decode.d4.loss_mask: 0.3267  decode.d4.loss_dice: 0.3187  decode.d5.loss_cls: 0.4081  decode.d5.loss_mask: 0.3286  decode.d5.loss_dice: 0.3219  decode.d6.loss_cls: 0.3602  decode.d6.loss_mask: 0.3287  decode.d6.loss_dice: 0.3166  decode.d7.loss_cls: 0.3425  decode.d7.loss_mask: 0.3269  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.3573  decode.d8.loss_mask: 0.3310  decode.d8.loss_dice: 0.3131
09/28 15:29:01 - mmengine - INFO - Iter(train) [  8500/320000]  base_lr: 9.7606e-05 lr: 9.7606e-06  eta: 1 day, 13:46:22  time: 0.4706  data_time: 0.0093  memory: 5167  grad_norm: 234.9218  loss: 12.7305  decode.loss_cls: 0.4764  decode.loss_mask: 0.3392  decode.loss_dice: 0.3353  decode.d0.loss_cls: 1.3897  decode.d0.loss_mask: 0.3525  decode.d0.loss_dice: 0.3424  decode.d1.loss_cls: 0.6093  decode.d1.loss_mask: 0.3508  decode.d1.loss_dice: 0.3462  decode.d2.loss_cls: 0.5652  decode.d2.loss_mask: 0.3445  decode.d2.loss_dice: 0.3217  decode.d3.loss_cls: 0.5464  decode.d3.loss_mask: 0.3409  decode.d3.loss_dice: 0.3121  decode.d4.loss_cls: 0.5602  decode.d4.loss_mask: 0.3418  decode.d4.loss_dice: 0.3432  decode.d5.loss_cls: 0.4352  decode.d5.loss_mask: 0.3422  decode.d5.loss_dice: 0.3272  decode.d6.loss_cls: 0.4490  decode.d6.loss_mask: 0.3453  decode.d6.loss_dice: 0.3150  decode.d7.loss_cls: 0.5053  decode.d7.loss_mask: 0.3401  decode.d7.loss_dice: 0.3397  decode.d8.loss_cls: 0.4921  decode.d8.loss_mask: 0.3403  decode.d8.loss_dice: 0.2814
09/28 15:29:25 - mmengine - INFO - Iter(train) [  8550/320000]  base_lr: 9.7592e-05 lr: 9.7592e-06  eta: 1 day, 13:46:59  time: 0.4667  data_time: 0.0087  memory: 5167  grad_norm: 43.5286  loss: 7.1020  decode.loss_cls: 0.1455  decode.loss_mask: 0.2736  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.9577  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.2174  decode.d1.loss_cls: 0.1713  decode.d1.loss_mask: 0.2780  decode.d1.loss_dice: 0.2127  decode.d2.loss_cls: 0.1399  decode.d2.loss_mask: 0.2664  decode.d2.loss_dice: 0.2085  decode.d3.loss_cls: 0.1252  decode.d3.loss_mask: 0.2643  decode.d3.loss_dice: 0.2174  decode.d4.loss_cls: 0.1361  decode.d4.loss_mask: 0.2697  decode.d4.loss_dice: 0.2087  decode.d5.loss_cls: 0.1758  decode.d5.loss_mask: 0.2696  decode.d5.loss_dice: 0.2029  decode.d6.loss_cls: 0.1575  decode.d6.loss_mask: 0.2663  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.1402  decode.d7.loss_mask: 0.2722  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.2057
09/28 15:29:48 - mmengine - INFO - Iter(train) [  8600/320000]  base_lr: 9.7578e-05 lr: 9.7578e-06  eta: 1 day, 13:47:10  time: 0.4294  data_time: 0.0087  memory: 5150  grad_norm: 105.0199  loss: 9.9367  decode.loss_cls: 0.2608  decode.loss_mask: 0.3631  decode.loss_dice: 0.2639  decode.d0.loss_cls: 0.9669  decode.d0.loss_mask: 0.3631  decode.d0.loss_dice: 0.3021  decode.d1.loss_cls: 0.3514  decode.d1.loss_mask: 0.3575  decode.d1.loss_dice: 0.2626  decode.d2.loss_cls: 0.2919  decode.d2.loss_mask: 0.3697  decode.d2.loss_dice: 0.2605  decode.d3.loss_cls: 0.3597  decode.d3.loss_mask: 0.3517  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.3327  decode.d4.loss_mask: 0.3667  decode.d4.loss_dice: 0.2558  decode.d5.loss_cls: 0.3259  decode.d5.loss_mask: 0.3792  decode.d5.loss_dice: 0.2666  decode.d6.loss_cls: 0.2732  decode.d6.loss_mask: 0.3716  decode.d6.loss_dice: 0.2543  decode.d7.loss_cls: 0.2553  decode.d7.loss_mask: 0.3747  decode.d7.loss_dice: 0.2532  decode.d8.loss_cls: 0.2363  decode.d8.loss_mask: 0.3687  decode.d8.loss_dice: 0.2501
09/28 15:30:09 - mmengine - INFO - Iter(train) [  8650/320000]  base_lr: 9.7564e-05 lr: 9.7564e-06  eta: 1 day, 13:46:36  time: 0.4301  data_time: 0.0088  memory: 5186  grad_norm: 150.8774  loss: 12.5274  decode.loss_cls: 0.4881  decode.loss_mask: 0.3337  decode.loss_dice: 0.3827  decode.d0.loss_cls: 1.1918  decode.d0.loss_mask: 0.3481  decode.d0.loss_dice: 0.3691  decode.d1.loss_cls: 0.5299  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.3596  decode.d2.loss_cls: 0.5056  decode.d2.loss_mask: 0.3034  decode.d2.loss_dice: 0.3613  decode.d3.loss_cls: 0.4842  decode.d3.loss_mask: 0.3125  decode.d3.loss_dice: 0.3454  decode.d4.loss_cls: 0.4645  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.3461  decode.d5.loss_cls: 0.4941  decode.d5.loss_mask: 0.3201  decode.d5.loss_dice: 0.3735  decode.d6.loss_cls: 0.5192  decode.d6.loss_mask: 0.3236  decode.d6.loss_dice: 0.3758  decode.d7.loss_cls: 0.5100  decode.d7.loss_mask: 0.3188  decode.d7.loss_dice: 0.3716  decode.d8.loss_cls: 0.5105  decode.d8.loss_mask: 0.3053  decode.d8.loss_dice: 0.3465
09/28 15:30:31 - mmengine - INFO - Iter(train) [  8700/320000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 1 day, 13:46:03  time: 0.4307  data_time: 0.0089  memory: 5166  grad_norm: 114.1344  loss: 10.6158  decode.loss_cls: 0.4340  decode.loss_mask: 0.2870  decode.loss_dice: 0.2761  decode.d0.loss_cls: 1.3294  decode.d0.loss_mask: 0.2978  decode.d0.loss_dice: 0.3147  decode.d1.loss_cls: 0.4223  decode.d1.loss_mask: 0.2861  decode.d1.loss_dice: 0.2701  decode.d2.loss_cls: 0.3913  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.2640  decode.d3.loss_cls: 0.3601  decode.d3.loss_mask: 0.2886  decode.d3.loss_dice: 0.2732  decode.d4.loss_cls: 0.4012  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.2688  decode.d5.loss_cls: 0.3250  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.3055  decode.d6.loss_cls: 0.3108  decode.d6.loss_mask: 0.2950  decode.d6.loss_dice: 0.2929  decode.d7.loss_cls: 0.4418  decode.d7.loss_mask: 0.3204  decode.d7.loss_dice: 0.3192  decode.d8.loss_cls: 0.3845  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.2918
09/28 15:30:52 - mmengine - INFO - Iter(train) [  8750/320000]  base_lr: 9.7536e-05 lr: 9.7536e-06  eta: 1 day, 13:45:31  time: 0.4300  data_time: 0.0090  memory: 5150  grad_norm: 126.3699  loss: 13.2858  decode.loss_cls: 0.5036  decode.loss_mask: 0.2974  decode.loss_dice: 0.3774  decode.d0.loss_cls: 1.2981  decode.d0.loss_mask: 0.3075  decode.d0.loss_dice: 0.4349  decode.d1.loss_cls: 0.7916  decode.d1.loss_mask: 0.2872  decode.d1.loss_dice: 0.3909  decode.d2.loss_cls: 0.5749  decode.d2.loss_mask: 0.2881  decode.d2.loss_dice: 0.3870  decode.d3.loss_cls: 0.4524  decode.d3.loss_mask: 0.2887  decode.d3.loss_dice: 0.3937  decode.d4.loss_cls: 0.5241  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.3928  decode.d5.loss_cls: 0.5796  decode.d5.loss_mask: 0.2916  decode.d5.loss_dice: 0.3815  decode.d6.loss_cls: 0.5543  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.4016  decode.d7.loss_cls: 0.5733  decode.d7.loss_mask: 0.3003  decode.d7.loss_dice: 0.3869  decode.d8.loss_cls: 0.5411  decode.d8.loss_mask: 0.3002  decode.d8.loss_dice: 0.3907
09/28 15:31:14 - mmengine - INFO - Iter(train) [  8800/320000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 1 day, 13:44:58  time: 0.4300  data_time: 0.0088  memory: 5167  grad_norm: 66.0353  loss: 9.7455  decode.loss_cls: 0.3762  decode.loss_mask: 0.3351  decode.loss_dice: 0.2663  decode.d0.loss_cls: 1.1626  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.2783  decode.d1.loss_cls: 0.2291  decode.d1.loss_mask: 0.3378  decode.d1.loss_dice: 0.2534  decode.d2.loss_cls: 0.2552  decode.d2.loss_mask: 0.3301  decode.d2.loss_dice: 0.2732  decode.d3.loss_cls: 0.2482  decode.d3.loss_mask: 0.3254  decode.d3.loss_dice: 0.2655  decode.d4.loss_cls: 0.2678  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.2778  decode.d5.loss_cls: 0.2869  decode.d5.loss_mask: 0.3238  decode.d5.loss_dice: 0.2963  decode.d6.loss_cls: 0.3496  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.2734  decode.d7.loss_cls: 0.2731  decode.d7.loss_mask: 0.3322  decode.d7.loss_dice: 0.2916  decode.d8.loss_cls: 0.2904  decode.d8.loss_mask: 0.3290  decode.d8.loss_dice: 0.2588
09/28 15:31:35 - mmengine - INFO - Iter(train) [  8850/320000]  base_lr: 9.7508e-05 lr: 9.7508e-06  eta: 1 day, 13:44:24  time: 0.4298  data_time: 0.0088  memory: 5167  grad_norm: 95.6449  loss: 9.0392  decode.loss_cls: 0.2491  decode.loss_mask: 0.2944  decode.loss_dice: 0.2184  decode.d0.loss_cls: 1.0802  decode.d0.loss_mask: 0.3275  decode.d0.loss_dice: 0.2405  decode.d1.loss_cls: 0.3786  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.2180  decode.d2.loss_cls: 0.2613  decode.d2.loss_mask: 0.2945  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.2894  decode.d3.loss_mask: 0.2906  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.3166  decode.d4.loss_mask: 0.2925  decode.d4.loss_dice: 0.2376  decode.d5.loss_cls: 0.3194  decode.d5.loss_mask: 0.3020  decode.d5.loss_dice: 0.2459  decode.d6.loss_cls: 0.2966  decode.d6.loss_mask: 0.2964  decode.d6.loss_dice: 0.2229  decode.d7.loss_cls: 0.2679  decode.d7.loss_mask: 0.3012  decode.d7.loss_dice: 0.2267  decode.d8.loss_cls: 0.2680  decode.d8.loss_mask: 0.2984  decode.d8.loss_dice: 0.2460
09/28 15:31:57 - mmengine - INFO - Iter(train) [  8900/320000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 1 day, 13:43:51  time: 0.4312  data_time: 0.0090  memory: 5166  grad_norm: 119.5643  loss: 10.4085  decode.loss_cls: 0.3364  decode.loss_mask: 0.3094  decode.loss_dice: 0.3086  decode.d0.loss_cls: 1.1420  decode.d0.loss_mask: 0.3336  decode.d0.loss_dice: 0.3290  decode.d1.loss_cls: 0.4709  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.3104  decode.d2.loss_cls: 0.3557  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.3103  decode.d3.loss_mask: 0.3083  decode.d3.loss_dice: 0.3049  decode.d4.loss_cls: 0.3265  decode.d4.loss_mask: 0.3126  decode.d4.loss_dice: 0.3100  decode.d5.loss_cls: 0.3101  decode.d5.loss_mask: 0.3320  decode.d5.loss_dice: 0.3130  decode.d6.loss_cls: 0.2742  decode.d6.loss_mask: 0.3387  decode.d6.loss_dice: 0.2997  decode.d7.loss_cls: 0.2916  decode.d7.loss_mask: 0.3251  decode.d7.loss_dice: 0.3179  decode.d8.loss_cls: 0.3098  decode.d8.loss_mask: 0.3169  decode.d8.loss_dice: 0.3067
09/28 15:32:18 - mmengine - INFO - Iter(train) [  8950/320000]  base_lr: 9.7480e-05 lr: 9.7480e-06  eta: 1 day, 13:43:19  time: 0.4306  data_time: 0.0090  memory: 5167  grad_norm: 147.9175  loss: 10.1940  decode.loss_cls: 0.2770  decode.loss_mask: 0.4242  decode.loss_dice: 0.2577  decode.d0.loss_cls: 1.0969  decode.d0.loss_mask: 0.3994  decode.d0.loss_dice: 0.2652  decode.d1.loss_cls: 0.2936  decode.d1.loss_mask: 0.3803  decode.d1.loss_dice: 0.2524  decode.d2.loss_cls: 0.3022  decode.d2.loss_mask: 0.3849  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.2832  decode.d3.loss_mask: 0.3873  decode.d3.loss_dice: 0.2328  decode.d4.loss_cls: 0.2619  decode.d4.loss_mask: 0.3991  decode.d4.loss_dice: 0.2466  decode.d5.loss_cls: 0.2538  decode.d5.loss_mask: 0.4041  decode.d5.loss_dice: 0.2566  decode.d6.loss_cls: 0.2526  decode.d6.loss_mask: 0.4075  decode.d6.loss_dice: 0.2519  decode.d7.loss_cls: 0.3162  decode.d7.loss_mask: 0.4197  decode.d7.loss_dice: 0.2595  decode.d8.loss_cls: 0.3181  decode.d8.loss_mask: 0.4000  decode.d8.loss_dice: 0.2655
09/28 15:32:40 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:32:40 - mmengine - INFO - Iter(train) [  9000/320000]  base_lr: 9.7465e-05 lr: 9.7465e-06  eta: 1 day, 13:42:46  time: 0.4296  data_time: 0.0089  memory: 5150  grad_norm: 64.7851  loss: 7.3686  decode.loss_cls: 0.1837  decode.loss_mask: 0.2828  decode.loss_dice: 0.1745  decode.d0.loss_cls: 0.8641  decode.d0.loss_mask: 0.2964  decode.d0.loss_dice: 0.1834  decode.d1.loss_cls: 0.2641  decode.d1.loss_mask: 0.2855  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.1988  decode.d2.loss_mask: 0.2898  decode.d2.loss_dice: 0.1723  decode.d3.loss_cls: 0.2079  decode.d3.loss_mask: 0.2854  decode.d3.loss_dice: 0.1724  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.1662  decode.d5.loss_cls: 0.2229  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.1709  decode.d6.loss_cls: 0.1973  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.1749  decode.d7.loss_cls: 0.2143  decode.d7.loss_mask: 0.2903  decode.d7.loss_dice: 0.1778  decode.d8.loss_cls: 0.1975  decode.d8.loss_mask: 0.2830  decode.d8.loss_dice: 0.1759
09/28 15:33:03 - mmengine - INFO - Iter(train) [  9050/320000]  base_lr: 9.7451e-05 lr: 9.7451e-06  eta: 1 day, 13:43:07  time: 0.4694  data_time: 0.0091  memory: 5167  grad_norm: 100.2046  loss: 11.5739  decode.loss_cls: 0.4484  decode.loss_mask: 0.2944  decode.loss_dice: 0.2837  decode.d0.loss_cls: 1.1553  decode.d0.loss_mask: 0.2615  decode.d0.loss_dice: 0.3079  decode.d1.loss_cls: 0.5242  decode.d1.loss_mask: 0.2826  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.4629  decode.d2.loss_mask: 0.3003  decode.d2.loss_dice: 0.2841  decode.d3.loss_cls: 0.3547  decode.d3.loss_mask: 0.3494  decode.d3.loss_dice: 0.3316  decode.d4.loss_cls: 0.3945  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.2942  decode.d5.loss_cls: 0.4350  decode.d5.loss_mask: 0.4044  decode.d5.loss_dice: 0.3367  decode.d6.loss_cls: 0.5880  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.3250  decode.d7.loss_cls: 0.5504  decode.d7.loss_mask: 0.3197  decode.d7.loss_dice: 0.3045  decode.d8.loss_cls: 0.4714  decode.d8.loss_mask: 0.3176  decode.d8.loss_dice: 0.3005
09/28 15:33:26 - mmengine - INFO - Iter(train) [  9100/320000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 1 day, 13:43:40  time: 0.4683  data_time: 0.0088  memory: 5167  grad_norm: 81.2569  loss: 7.2687  decode.loss_cls: 0.1474  decode.loss_mask: 0.2755  decode.loss_dice: 0.2069  decode.d0.loss_cls: 0.8984  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.2379  decode.d1.loss_cls: 0.1797  decode.d1.loss_mask: 0.2708  decode.d1.loss_dice: 0.2062  decode.d2.loss_cls: 0.1918  decode.d2.loss_mask: 0.2795  decode.d2.loss_dice: 0.2155  decode.d3.loss_cls: 0.1519  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.2352  decode.d4.loss_cls: 0.1928  decode.d4.loss_mask: 0.2769  decode.d4.loss_dice: 0.2142  decode.d5.loss_cls: 0.1591  decode.d5.loss_mask: 0.2681  decode.d5.loss_dice: 0.2048  decode.d6.loss_cls: 0.1512  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.2210  decode.d7.loss_cls: 0.1310  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.2141  decode.d8.loss_cls: 0.1325  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.2186
09/28 15:33:50 - mmengine - INFO - Iter(train) [  9150/320000]  base_lr: 9.7423e-05 lr: 9.7423e-06  eta: 1 day, 13:44:13  time: 0.4683  data_time: 0.0087  memory: 5166  grad_norm: 74.7330  loss: 7.3552  decode.loss_cls: 0.1596  decode.loss_mask: 0.2306  decode.loss_dice: 0.2260  decode.d0.loss_cls: 1.0000  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.2322  decode.d1.loss_mask: 0.2288  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 0.2332  decode.d2.loss_dice: 0.2206  decode.d3.loss_cls: 0.1716  decode.d3.loss_mask: 0.2323  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.2112  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.2099  decode.d5.loss_mask: 0.2304  decode.d5.loss_dice: 0.2192  decode.d6.loss_cls: 0.2455  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.2032  decode.d7.loss_cls: 0.2322  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.2054  decode.d8.loss_cls: 0.1796  decode.d8.loss_mask: 0.2323  decode.d8.loss_dice: 0.2233
09/28 15:34:13 - mmengine - INFO - Iter(train) [  9200/320000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 1 day, 13:44:46  time: 0.4706  data_time: 0.0095  memory: 5167  grad_norm: 129.4522  loss: 10.2643  decode.loss_cls: 0.3128  decode.loss_mask: 0.2800  decode.loss_dice: 0.2909  decode.d0.loss_cls: 1.0878  decode.d0.loss_mask: 0.2912  decode.d0.loss_dice: 0.3376  decode.d1.loss_cls: 0.4494  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.2937  decode.d2.loss_cls: 0.3460  decode.d2.loss_mask: 0.2840  decode.d2.loss_dice: 0.3156  decode.d3.loss_cls: 0.2897  decode.d3.loss_mask: 0.2891  decode.d3.loss_dice: 0.3136  decode.d4.loss_cls: 0.3267  decode.d4.loss_mask: 0.2765  decode.d4.loss_dice: 0.3204  decode.d5.loss_cls: 0.4440  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3038  decode.d6.loss_cls: 0.3732  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.2963  decode.d7.loss_cls: 0.3442  decode.d7.loss_mask: 0.2795  decode.d7.loss_dice: 0.3122  decode.d8.loss_cls: 0.3748  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.3056
09/28 15:34:35 - mmengine - INFO - Iter(train) [  9250/320000]  base_lr: 9.7395e-05 lr: 9.7395e-06  eta: 1 day, 13:44:21  time: 0.4307  data_time: 0.0088  memory: 5186  grad_norm: 95.7638  loss: 10.5803  decode.loss_cls: 0.3672  decode.loss_mask: 0.3317  decode.loss_dice: 0.3251  decode.d0.loss_cls: 1.0934  decode.d0.loss_mask: 0.3154  decode.d0.loss_dice: 0.3426  decode.d1.loss_cls: 0.4213  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.3072  decode.d2.loss_cls: 0.3133  decode.d2.loss_mask: 0.3327  decode.d2.loss_dice: 0.3181  decode.d3.loss_cls: 0.2953  decode.d3.loss_mask: 0.3413  decode.d3.loss_dice: 0.3254  decode.d4.loss_cls: 0.2542  decode.d4.loss_mask: 0.3412  decode.d4.loss_dice: 0.3085  decode.d5.loss_cls: 0.3464  decode.d5.loss_mask: 0.3330  decode.d5.loss_dice: 0.3176  decode.d6.loss_cls: 0.3073  decode.d6.loss_mask: 0.3091  decode.d6.loss_dice: 0.3153  decode.d7.loss_cls: 0.4236  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.3562  decode.d8.loss_mask: 0.3326  decode.d8.loss_dice: 0.3077
09/28 15:34:56 - mmengine - INFO - Iter(train) [  9300/320000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 1 day, 13:43:47  time: 0.4300  data_time: 0.0087  memory: 5149  grad_norm: 103.0966  loss: 13.6038  decode.loss_cls: 0.5850  decode.loss_mask: 0.3262  decode.loss_dice: 0.3489  decode.d0.loss_cls: 1.2220  decode.d0.loss_mask: 0.3296  decode.d0.loss_dice: 0.3714  decode.d1.loss_cls: 0.8066  decode.d1.loss_mask: 0.3099  decode.d1.loss_dice: 0.3437  decode.d2.loss_cls: 0.6639  decode.d2.loss_mask: 0.3231  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.6058  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.3516  decode.d4.loss_cls: 0.5956  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.3277  decode.d5.loss_cls: 0.6797  decode.d5.loss_mask: 0.3088  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.5922  decode.d6.loss_mask: 0.3299  decode.d6.loss_dice: 0.3652  decode.d7.loss_cls: 0.6140  decode.d7.loss_mask: 0.3276  decode.d7.loss_dice: 0.3645  decode.d8.loss_cls: 0.5775  decode.d8.loss_mask: 0.3332  decode.d8.loss_dice: 0.3385
09/28 15:35:18 - mmengine - INFO - Iter(train) [  9350/320000]  base_lr: 9.7367e-05 lr: 9.7367e-06  eta: 1 day, 13:43:13  time: 0.4292  data_time: 0.0085  memory: 5167  grad_norm: 99.3737  loss: 12.0960  decode.loss_cls: 0.4108  decode.loss_mask: 0.3136  decode.loss_dice: 0.3838  decode.d0.loss_cls: 1.2470  decode.d0.loss_mask: 0.3039  decode.d0.loss_dice: 0.3825  decode.d1.loss_cls: 0.5747  decode.d1.loss_mask: 0.2981  decode.d1.loss_dice: 0.3453  decode.d2.loss_cls: 0.5168  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.3693  decode.d3.loss_cls: 0.4557  decode.d3.loss_mask: 0.2949  decode.d3.loss_dice: 0.3594  decode.d4.loss_cls: 0.5159  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.3647  decode.d5.loss_cls: 0.5277  decode.d5.loss_mask: 0.2902  decode.d5.loss_dice: 0.3753  decode.d6.loss_cls: 0.4612  decode.d6.loss_mask: 0.2918  decode.d6.loss_dice: 0.3525  decode.d7.loss_cls: 0.4467  decode.d7.loss_mask: 0.2889  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.4352  decode.d8.loss_mask: 0.2942  decode.d8.loss_dice: 0.3034
09/28 15:35:39 - mmengine - INFO - Iter(train) [  9400/320000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 1 day, 13:42:41  time: 0.4303  data_time: 0.0089  memory: 5186  grad_norm: 149.4364  loss: 10.5541  decode.loss_cls: 0.3970  decode.loss_mask: 0.3268  decode.loss_dice: 0.2362  decode.d0.loss_cls: 1.2672  decode.d0.loss_mask: 0.3705  decode.d0.loss_dice: 0.2939  decode.d1.loss_cls: 0.4390  decode.d1.loss_mask: 0.3390  decode.d1.loss_dice: 0.2465  decode.d2.loss_cls: 0.3924  decode.d2.loss_mask: 0.3356  decode.d2.loss_dice: 0.2348  decode.d3.loss_cls: 0.3039  decode.d3.loss_mask: 0.3393  decode.d3.loss_dice: 0.2416  decode.d4.loss_cls: 0.2880  decode.d4.loss_mask: 0.3338  decode.d4.loss_dice: 0.2430  decode.d5.loss_cls: 0.3654  decode.d5.loss_mask: 0.3489  decode.d5.loss_dice: 0.2546  decode.d6.loss_cls: 0.3754  decode.d6.loss_mask: 0.3365  decode.d6.loss_dice: 0.2506  decode.d7.loss_cls: 0.4200  decode.d7.loss_mask: 0.3347  decode.d7.loss_dice: 0.2297  decode.d8.loss_cls: 0.4387  decode.d8.loss_mask: 0.3343  decode.d8.loss_dice: 0.2365
09/28 15:36:01 - mmengine - INFO - Iter(train) [  9450/320000]  base_lr: 9.7338e-05 lr: 9.7338e-06  eta: 1 day, 13:42:08  time: 0.4314  data_time: 0.0089  memory: 5185  grad_norm: 89.1032  loss: 9.1353  decode.loss_cls: 0.2385  decode.loss_mask: 0.2531  decode.loss_dice: 0.2892  decode.d0.loss_cls: 1.2028  decode.d0.loss_mask: 0.2630  decode.d0.loss_dice: 0.2955  decode.d1.loss_cls: 0.3933  decode.d1.loss_mask: 0.2562  decode.d1.loss_dice: 0.2751  decode.d2.loss_cls: 0.3366  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2829  decode.d3.loss_cls: 0.2766  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.2700  decode.d4.loss_cls: 0.2823  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2660  decode.d5.loss_cls: 0.2894  decode.d5.loss_mask: 0.2482  decode.d5.loss_dice: 0.2721  decode.d6.loss_cls: 0.2868  decode.d6.loss_mask: 0.2549  decode.d6.loss_dice: 0.2754  decode.d7.loss_cls: 0.2536  decode.d7.loss_mask: 0.2531  decode.d7.loss_dice: 0.2757  decode.d8.loss_cls: 0.2679  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.2681
09/28 15:36:23 - mmengine - INFO - Iter(train) [  9500/320000]  base_lr: 9.7324e-05 lr: 9.7324e-06  eta: 1 day, 13:41:42  time: 0.4491  data_time: 0.0088  memory: 5186  grad_norm: 147.2663  loss: 10.3017  decode.loss_cls: 0.3574  decode.loss_mask: 0.3178  decode.loss_dice: 0.2657  decode.d0.loss_cls: 1.3529  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.2915  decode.d1.loss_cls: 0.4692  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.2603  decode.d2.loss_cls: 0.4475  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.2457  decode.d3.loss_cls: 0.4333  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.2584  decode.d4.loss_cls: 0.3861  decode.d4.loss_mask: 0.2615  decode.d4.loss_dice: 0.2376  decode.d5.loss_cls: 0.3415  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2716  decode.d6.loss_cls: 0.3633  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.2563  decode.d7.loss_cls: 0.3590  decode.d7.loss_mask: 0.2915  decode.d7.loss_dice: 0.2583  decode.d8.loss_cls: 0.3503  decode.d8.loss_mask: 0.3170  decode.d8.loss_dice: 0.2717
09/28 15:36:44 - mmengine - INFO - Iter(train) [  9550/320000]  base_lr: 9.7310e-05 lr: 9.7310e-06  eta: 1 day, 13:41:10  time: 0.4302  data_time: 0.0089  memory: 5186  grad_norm: 161.8022  loss: 10.7341  decode.loss_cls: 0.4181  decode.loss_mask: 0.3835  decode.loss_dice: 0.2638  decode.d0.loss_cls: 0.8785  decode.d0.loss_mask: 0.4135  decode.d0.loss_dice: 0.2851  decode.d1.loss_cls: 0.3002  decode.d1.loss_mask: 0.3819  decode.d1.loss_dice: 0.2727  decode.d2.loss_cls: 0.3645  decode.d2.loss_mask: 0.3875  decode.d2.loss_dice: 0.2607  decode.d3.loss_cls: 0.4370  decode.d3.loss_mask: 0.3757  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.3533  decode.d4.loss_mask: 0.3829  decode.d4.loss_dice: 0.2740  decode.d5.loss_cls: 0.3615  decode.d5.loss_mask: 0.3849  decode.d5.loss_dice: 0.2825  decode.d6.loss_cls: 0.3337  decode.d6.loss_mask: 0.3778  decode.d6.loss_dice: 0.2780  decode.d7.loss_cls: 0.3508  decode.d7.loss_mask: 0.3819  decode.d7.loss_dice: 0.2600  decode.d8.loss_cls: 0.3242  decode.d8.loss_mask: 0.3852  decode.d8.loss_dice: 0.2907
09/28 15:37:07 - mmengine - INFO - Iter(train) [  9600/320000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 1 day, 13:41:12  time: 0.4692  data_time: 0.0090  memory: 5186  grad_norm: 88.0614  loss: 7.9636  decode.loss_cls: 0.1566  decode.loss_mask: 0.3194  decode.loss_dice: 0.2087  decode.d0.loss_cls: 0.9024  decode.d0.loss_mask: 0.3300  decode.d0.loss_dice: 0.2459  decode.d1.loss_cls: 0.2240  decode.d1.loss_mask: 0.3204  decode.d1.loss_dice: 0.2399  decode.d2.loss_cls: 0.1602  decode.d2.loss_mask: 0.3259  decode.d2.loss_dice: 0.2336  decode.d3.loss_cls: 0.1462  decode.d3.loss_mask: 0.3290  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 0.3260  decode.d4.loss_dice: 0.2292  decode.d5.loss_cls: 0.1495  decode.d5.loss_mask: 0.3263  decode.d5.loss_dice: 0.2535  decode.d6.loss_cls: 0.1556  decode.d6.loss_mask: 0.3349  decode.d6.loss_dice: 0.2311  decode.d7.loss_cls: 0.1523  decode.d7.loss_mask: 0.3181  decode.d7.loss_dice: 0.2223  decode.d8.loss_cls: 0.1516  decode.d8.loss_mask: 0.3456  decode.d8.loss_dice: 0.2374
09/28 15:37:30 - mmengine - INFO - Iter(train) [  9650/320000]  base_lr: 9.7282e-05 lr: 9.7282e-06  eta: 1 day, 13:41:41  time: 0.4676  data_time: 0.0088  memory: 5166  grad_norm: 210.5135  loss: 13.6936  decode.loss_cls: 0.4208  decode.loss_mask: 0.5047  decode.loss_dice: 0.3654  decode.d0.loss_cls: 1.2090  decode.d0.loss_mask: 0.4853  decode.d0.loss_dice: 0.3478  decode.d1.loss_cls: 0.4858  decode.d1.loss_mask: 0.5346  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.4795  decode.d2.loss_mask: 0.4859  decode.d2.loss_dice: 0.3717  decode.d3.loss_cls: 0.4534  decode.d3.loss_mask: 0.4454  decode.d3.loss_dice: 0.3492  decode.d4.loss_cls: 0.4737  decode.d4.loss_mask: 0.4527  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 0.4675  decode.d5.loss_mask: 0.4133  decode.d5.loss_dice: 0.3590  decode.d6.loss_cls: 0.4199  decode.d6.loss_mask: 0.5166  decode.d6.loss_dice: 0.3716  decode.d7.loss_cls: 0.4195  decode.d7.loss_mask: 0.5232  decode.d7.loss_dice: 0.3531  decode.d8.loss_cls: 0.4341  decode.d8.loss_mask: 0.5053  decode.d8.loss_dice: 0.3570
09/28 15:37:54 - mmengine - INFO - Iter(train) [  9700/320000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 1 day, 13:42:09  time: 0.4688  data_time: 0.0091  memory: 5186  grad_norm: 209.4318  loss: 10.1368  decode.loss_cls: 0.3887  decode.loss_mask: 0.3626  decode.loss_dice: 0.2466  decode.d0.loss_cls: 0.9457  decode.d0.loss_mask: 0.3964  decode.d0.loss_dice: 0.2660  decode.d1.loss_cls: 0.2739  decode.d1.loss_mask: 0.3801  decode.d1.loss_dice: 0.2591  decode.d2.loss_cls: 0.3239  decode.d2.loss_mask: 0.3102  decode.d2.loss_dice: 0.2448  decode.d3.loss_cls: 0.3170  decode.d3.loss_mask: 0.3685  decode.d3.loss_dice: 0.2562  decode.d4.loss_cls: 0.3119  decode.d4.loss_mask: 0.3862  decode.d4.loss_dice: 0.2498  decode.d5.loss_cls: 0.3289  decode.d5.loss_mask: 0.3707  decode.d5.loss_dice: 0.2489  decode.d6.loss_cls: 0.3644  decode.d6.loss_mask: 0.3472  decode.d6.loss_dice: 0.2523  decode.d7.loss_cls: 0.3580  decode.d7.loss_mask: 0.3600  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.3621  decode.d8.loss_mask: 0.3597  decode.d8.loss_dice: 0.2465
09/28 15:38:17 - mmengine - INFO - Iter(train) [  9750/320000]  base_lr: 9.7254e-05 lr: 9.7254e-06  eta: 1 day, 13:42:37  time: 0.4695  data_time: 0.0093  memory: 5166  grad_norm: 70.0053  loss: 6.6577  decode.loss_cls: 0.1275  decode.loss_mask: 0.2421  decode.loss_dice: 0.2294  decode.d0.loss_cls: 0.8933  decode.d0.loss_mask: 0.2444  decode.d0.loss_dice: 0.2127  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2149  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.2434  decode.d2.loss_dice: 0.2230  decode.d3.loss_cls: 0.1659  decode.d3.loss_mask: 0.2396  decode.d3.loss_dice: 0.2275  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2246  decode.d5.loss_cls: 0.1385  decode.d5.loss_mask: 0.2378  decode.d5.loss_dice: 0.2179  decode.d6.loss_cls: 0.1324  decode.d6.loss_mask: 0.2373  decode.d6.loss_dice: 0.2173  decode.d7.loss_cls: 0.1099  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.2165  decode.d8.loss_cls: 0.1237  decode.d8.loss_mask: 0.2385  decode.d8.loss_dice: 0.2192
09/28 15:38:41 - mmengine - INFO - Iter(train) [  9800/320000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 1 day, 13:43:03  time: 0.4668  data_time: 0.0089  memory: 5167  grad_norm: 128.9123  loss: 9.5895  decode.loss_cls: 0.2976  decode.loss_mask: 0.2985  decode.loss_dice: 0.2711  decode.d0.loss_cls: 1.1729  decode.d0.loss_mask: 0.3109  decode.d0.loss_dice: 0.2965  decode.d1.loss_cls: 0.3907  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.2506  decode.d2.loss_cls: 0.3368  decode.d2.loss_mask: 0.3099  decode.d2.loss_dice: 0.2498  decode.d3.loss_cls: 0.3286  decode.d3.loss_mask: 0.2784  decode.d3.loss_dice: 0.2473  decode.d4.loss_cls: 0.3161  decode.d4.loss_mask: 0.3058  decode.d4.loss_dice: 0.2552  decode.d5.loss_cls: 0.3211  decode.d5.loss_mask: 0.3045  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.3422  decode.d6.loss_mask: 0.3019  decode.d6.loss_dice: 0.2673  decode.d7.loss_cls: 0.2631  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.2802  decode.d8.loss_cls: 0.2132  decode.d8.loss_mask: 0.2856  decode.d8.loss_dice: 0.2595
09/28 15:39:04 - mmengine - INFO - Iter(train) [  9850/320000]  base_lr: 9.7226e-05 lr: 9.7226e-06  eta: 1 day, 13:43:30  time: 0.4687  data_time: 0.0086  memory: 5166  grad_norm: 104.5681  loss: 9.8790  decode.loss_cls: 0.3715  decode.loss_mask: 0.3334  decode.loss_dice: 0.2806  decode.d0.loss_cls: 1.2121  decode.d0.loss_mask: 0.3459  decode.d0.loss_dice: 0.2888  decode.d1.loss_cls: 0.3378  decode.d1.loss_mask: 0.3440  decode.d1.loss_dice: 0.2729  decode.d2.loss_cls: 0.3058  decode.d2.loss_mask: 0.3359  decode.d2.loss_dice: 0.2673  decode.d3.loss_cls: 0.2619  decode.d3.loss_mask: 0.3319  decode.d3.loss_dice: 0.2712  decode.d4.loss_cls: 0.2576  decode.d4.loss_mask: 0.3364  decode.d4.loss_dice: 0.2795  decode.d5.loss_cls: 0.3013  decode.d5.loss_mask: 0.3291  decode.d5.loss_dice: 0.2753  decode.d6.loss_cls: 0.2530  decode.d6.loss_mask: 0.3302  decode.d6.loss_dice: 0.2804  decode.d7.loss_cls: 0.2118  decode.d7.loss_mask: 0.3259  decode.d7.loss_dice: 0.2582  decode.d8.loss_cls: 0.2901  decode.d8.loss_mask: 0.3376  decode.d8.loss_dice: 0.2517
09/28 15:39:27 - mmengine - INFO - Iter(train) [  9900/320000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 1 day, 13:43:56  time: 0.4704  data_time: 0.0090  memory: 5166  grad_norm: 172.3444  loss: 7.7860  decode.loss_cls: 0.2339  decode.loss_mask: 0.2390  decode.loss_dice: 0.2326  decode.d0.loss_cls: 0.9861  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.2637  decode.d1.loss_cls: 0.2427  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.2434  decode.d2.loss_cls: 0.2419  decode.d2.loss_mask: 0.2467  decode.d2.loss_dice: 0.2483  decode.d3.loss_cls: 0.1831  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.2647  decode.d4.loss_cls: 0.2053  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 0.2441  decode.d5.loss_dice: 0.2417  decode.d6.loss_cls: 0.2022  decode.d6.loss_mask: 0.2427  decode.d6.loss_dice: 0.2555  decode.d7.loss_cls: 0.1867  decode.d7.loss_mask: 0.2418  decode.d7.loss_dice: 0.2463  decode.d8.loss_cls: 0.2245  decode.d8.loss_mask: 0.2407  decode.d8.loss_dice: 0.2317
09/28 15:39:51 - mmengine - INFO - Iter(train) [  9950/320000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 1 day, 13:44:21  time: 0.4672  data_time: 0.0088  memory: 5167  grad_norm: 162.6673  loss: 8.1747  decode.loss_cls: 0.1636  decode.loss_mask: 0.3240  decode.loss_dice: 0.2208  decode.d0.loss_cls: 0.9340  decode.d0.loss_mask: 0.3842  decode.d0.loss_dice: 0.2506  decode.d1.loss_cls: 0.2800  decode.d1.loss_mask: 0.3330  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.1848  decode.d2.loss_mask: 0.3329  decode.d2.loss_dice: 0.2401  decode.d3.loss_cls: 0.1513  decode.d3.loss_mask: 0.3307  decode.d3.loss_dice: 0.2286  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 0.3243  decode.d4.loss_dice: 0.2217  decode.d5.loss_cls: 0.1657  decode.d5.loss_mask: 0.3243  decode.d5.loss_dice: 0.2267  decode.d6.loss_cls: 0.1715  decode.d6.loss_mask: 0.3320  decode.d6.loss_dice: 0.2295  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 0.3286  decode.d7.loss_dice: 0.2247  decode.d8.loss_cls: 0.1614  decode.d8.loss_mask: 0.3245  decode.d8.loss_dice: 0.2300
09/28 15:40:14 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:40:14 - mmengine - INFO - Iter(train) [ 10000/320000]  base_lr: 9.7183e-05 lr: 9.7183e-06  eta: 1 day, 13:44:45  time: 0.4687  data_time: 0.0087  memory: 5167  grad_norm: 69.5161  loss: 7.9188  decode.loss_cls: 0.1571  decode.loss_mask: 0.3129  decode.loss_dice: 0.2289  decode.d0.loss_cls: 1.1501  decode.d0.loss_mask: 0.3325  decode.d0.loss_dice: 0.2384  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 0.3099  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.2193  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 0.3167  decode.d3.loss_dice: 0.2106  decode.d4.loss_cls: 0.1382  decode.d4.loss_mask: 0.3097  decode.d4.loss_dice: 0.2260  decode.d5.loss_cls: 0.1431  decode.d5.loss_mask: 0.3136  decode.d5.loss_dice: 0.2122  decode.d6.loss_cls: 0.1717  decode.d6.loss_mask: 0.3118  decode.d6.loss_dice: 0.2187  decode.d7.loss_cls: 0.2054  decode.d7.loss_mask: 0.3074  decode.d7.loss_dice: 0.2186  decode.d8.loss_cls: 0.1666  decode.d8.loss_mask: 0.3064  decode.d8.loss_dice: 0.2141
09/28 15:40:38 - mmengine - INFO - Iter(train) [ 10050/320000]  base_lr: 9.7169e-05 lr: 9.7169e-06  eta: 1 day, 13:45:10  time: 0.4691  data_time: 0.0091  memory: 5167  grad_norm: 140.2247  loss: 11.7828  decode.loss_cls: 0.3062  decode.loss_mask: 0.4608  decode.loss_dice: 0.3731  decode.d0.loss_cls: 1.0256  decode.d0.loss_mask: 0.4214  decode.d0.loss_dice: 0.3471  decode.d1.loss_cls: 0.4369  decode.d1.loss_mask: 0.4413  decode.d1.loss_dice: 0.3797  decode.d2.loss_cls: 0.4565  decode.d2.loss_mask: 0.4091  decode.d2.loss_dice: 0.3558  decode.d3.loss_cls: 0.3191  decode.d3.loss_mask: 0.4125  decode.d3.loss_dice: 0.3361  decode.d4.loss_cls: 0.3674  decode.d4.loss_mask: 0.4165  decode.d4.loss_dice: 0.3475  decode.d5.loss_cls: 0.2554  decode.d5.loss_mask: 0.4123  decode.d5.loss_dice: 0.3270  decode.d6.loss_cls: 0.2770  decode.d6.loss_mask: 0.4107  decode.d6.loss_dice: 0.3424  decode.d7.loss_cls: 0.2975  decode.d7.loss_mask: 0.4079  decode.d7.loss_dice: 0.3296  decode.d8.loss_cls: 0.3029  decode.d8.loss_mask: 0.4273  decode.d8.loss_dice: 0.3801
09/28 15:41:01 - mmengine - INFO - Iter(train) [ 10100/320000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 1 day, 13:45:34  time: 0.4684  data_time: 0.0088  memory: 5186  grad_norm: 94.2691  loss: 7.5003  decode.loss_cls: 0.2259  decode.loss_mask: 0.2210  decode.loss_dice: 0.2362  decode.d0.loss_cls: 0.7347  decode.d0.loss_mask: 0.2247  decode.d0.loss_dice: 0.2761  decode.d1.loss_cls: 0.2481  decode.d1.loss_mask: 0.2209  decode.d1.loss_dice: 0.2406  decode.d2.loss_cls: 0.2930  decode.d2.loss_mask: 0.2236  decode.d2.loss_dice: 0.2439  decode.d3.loss_cls: 0.2505  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2302  decode.d4.loss_cls: 0.2052  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.2271  decode.d5.loss_mask: 0.2182  decode.d5.loss_dice: 0.2290  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 0.2208  decode.d6.loss_dice: 0.2297  decode.d7.loss_cls: 0.2528  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.2180  decode.d8.loss_mask: 0.2158  decode.d8.loss_dice: 0.2412
09/28 15:41:25 - mmengine - INFO - Iter(train) [ 10150/320000]  base_lr: 9.7141e-05 lr: 9.7141e-06  eta: 1 day, 13:45:59  time: 0.4689  data_time: 0.0088  memory: 5167  grad_norm: 141.9320  loss: 9.7555  decode.loss_cls: 0.2006  decode.loss_mask: 0.3838  decode.loss_dice: 0.2820  decode.d0.loss_cls: 0.9957  decode.d0.loss_mask: 0.3924  decode.d0.loss_dice: 0.2736  decode.d1.loss_cls: 0.2432  decode.d1.loss_mask: 0.3756  decode.d1.loss_dice: 0.2718  decode.d2.loss_cls: 0.3351  decode.d2.loss_mask: 0.3575  decode.d2.loss_dice: 0.2534  decode.d3.loss_cls: 0.2736  decode.d3.loss_mask: 0.3822  decode.d3.loss_dice: 0.2719  decode.d4.loss_cls: 0.2608  decode.d4.loss_mask: 0.3983  decode.d4.loss_dice: 0.2859  decode.d5.loss_cls: 0.2305  decode.d5.loss_mask: 0.3903  decode.d5.loss_dice: 0.2801  decode.d6.loss_cls: 0.2257  decode.d6.loss_mask: 0.3947  decode.d6.loss_dice: 0.2816  decode.d7.loss_cls: 0.1905  decode.d7.loss_mask: 0.3871  decode.d7.loss_dice: 0.2742  decode.d8.loss_cls: 0.2003  decode.d8.loss_mask: 0.3861  decode.d8.loss_dice: 0.2771
09/28 15:41:48 - mmengine - INFO - Iter(train) [ 10200/320000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 1 day, 13:46:22  time: 0.4687  data_time: 0.0090  memory: 5186  grad_norm: 121.4905  loss: 10.6744  decode.loss_cls: 0.3946  decode.loss_mask: 0.3280  decode.loss_dice: 0.2555  decode.d0.loss_cls: 1.1418  decode.d0.loss_mask: 0.3257  decode.d0.loss_dice: 0.2755  decode.d1.loss_cls: 0.4459  decode.d1.loss_mask: 0.3251  decode.d1.loss_dice: 0.2548  decode.d2.loss_cls: 0.4264  decode.d2.loss_mask: 0.3229  decode.d2.loss_dice: 0.2622  decode.d3.loss_cls: 0.3701  decode.d3.loss_mask: 0.3369  decode.d3.loss_dice: 0.2664  decode.d4.loss_cls: 0.3958  decode.d4.loss_mask: 0.3361  decode.d4.loss_dice: 0.2758  decode.d5.loss_cls: 0.3863  decode.d5.loss_mask: 0.3215  decode.d5.loss_dice: 0.2499  decode.d6.loss_cls: 0.3815  decode.d6.loss_mask: 0.3277  decode.d6.loss_dice: 0.2705  decode.d7.loss_cls: 0.4222  decode.d7.loss_mask: 0.3345  decode.d7.loss_dice: 0.2727  decode.d8.loss_cls: 0.3675  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.2735
09/28 15:42:11 - mmengine - INFO - Iter(train) [ 10250/320000]  base_lr: 9.7113e-05 lr: 9.7113e-06  eta: 1 day, 13:46:44  time: 0.4675  data_time: 0.0087  memory: 5150  grad_norm: 57.7940  loss: 8.7929  decode.loss_cls: 0.2334  decode.loss_mask: 0.3189  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.9909  decode.d0.loss_mask: 0.3372  decode.d0.loss_dice: 0.2299  decode.d1.loss_cls: 0.2154  decode.d1.loss_mask: 0.3313  decode.d1.loss_dice: 0.2374  decode.d2.loss_cls: 0.2676  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.2404  decode.d3.loss_cls: 0.2610  decode.d3.loss_mask: 0.3240  decode.d3.loss_dice: 0.2491  decode.d4.loss_cls: 0.2363  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.2399  decode.d5.loss_cls: 0.2176  decode.d5.loss_mask: 0.3315  decode.d5.loss_dice: 0.2518  decode.d6.loss_cls: 0.2335  decode.d6.loss_mask: 0.3243  decode.d6.loss_dice: 0.2520  decode.d7.loss_cls: 0.2191  decode.d7.loss_mask: 0.3224  decode.d7.loss_dice: 0.2456  decode.d8.loss_cls: 0.2198  decode.d8.loss_mask: 0.3193  decode.d8.loss_dice: 0.2444
09/28 15:42:35 - mmengine - INFO - Iter(train) [ 10300/320000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 1 day, 13:47:06  time: 0.4684  data_time: 0.0086  memory: 5150  grad_norm: 98.3194  loss: 10.8952  decode.loss_cls: 0.3302  decode.loss_mask: 0.3441  decode.loss_dice: 0.2707  decode.d0.loss_cls: 1.2941  decode.d0.loss_mask: 0.3405  decode.d0.loss_dice: 0.3143  decode.d1.loss_cls: 0.3685  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.2883  decode.d2.loss_cls: 0.3602  decode.d2.loss_mask: 0.3386  decode.d2.loss_dice: 0.3085  decode.d3.loss_cls: 0.3464  decode.d3.loss_mask: 0.4078  decode.d3.loss_dice: 0.2931  decode.d4.loss_cls: 0.3326  decode.d4.loss_mask: 0.3709  decode.d4.loss_dice: 0.3183  decode.d5.loss_cls: 0.3602  decode.d5.loss_mask: 0.3273  decode.d5.loss_dice: 0.2859  decode.d6.loss_cls: 0.4148  decode.d6.loss_mask: 0.3128  decode.d6.loss_dice: 0.2883  decode.d7.loss_cls: 0.3728  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.3775  decode.d8.loss_mask: 0.3244  decode.d8.loss_dice: 0.2861
09/28 15:42:58 - mmengine - INFO - Iter(train) [ 10350/320000]  base_lr: 9.7085e-05 lr: 9.7085e-06  eta: 1 day, 13:47:27  time: 0.4686  data_time: 0.0092  memory: 5186  grad_norm: 84.0686  loss: 8.0519  decode.loss_cls: 0.1555  decode.loss_mask: 0.2579  decode.loss_dice: 0.2739  decode.d0.loss_cls: 1.0997  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.3107  decode.d1.loss_cls: 0.2025  decode.d1.loss_mask: 0.2557  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.1876  decode.d2.loss_mask: 0.2607  decode.d2.loss_dice: 0.2865  decode.d3.loss_cls: 0.1668  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.2785  decode.d4.loss_cls: 0.1353  decode.d4.loss_mask: 0.2554  decode.d4.loss_dice: 0.2925  decode.d5.loss_cls: 0.1630  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2704  decode.d6.loss_cls: 0.2144  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.2720  decode.d7.loss_cls: 0.1852  decode.d7.loss_mask: 0.2624  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.2675
09/28 15:43:22 - mmengine - INFO - Iter(train) [ 10400/320000]  base_lr: 9.7070e-05 lr: 9.7070e-06  eta: 1 day, 13:47:50  time: 0.4672  data_time: 0.0089  memory: 5166  grad_norm: 161.6720  loss: 8.7341  decode.loss_cls: 0.2170  decode.loss_mask: 0.3303  decode.loss_dice: 0.2580  decode.d0.loss_cls: 0.9250  decode.d0.loss_mask: 0.3112  decode.d0.loss_dice: 0.2644  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.2342  decode.d2.loss_cls: 0.2706  decode.d2.loss_mask: 0.3142  decode.d2.loss_dice: 0.2405  decode.d3.loss_cls: 0.2087  decode.d3.loss_mask: 0.3216  decode.d3.loss_dice: 0.2325  decode.d4.loss_cls: 0.1944  decode.d4.loss_mask: 0.3242  decode.d4.loss_dice: 0.2319  decode.d5.loss_cls: 0.2648  decode.d5.loss_mask: 0.3182  decode.d5.loss_dice: 0.2316  decode.d6.loss_cls: 0.2581  decode.d6.loss_mask: 0.3234  decode.d6.loss_dice: 0.2398  decode.d7.loss_cls: 0.2550  decode.d7.loss_mask: 0.3313  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.2782  decode.d8.loss_mask: 0.3327  decode.d8.loss_dice: 0.2406
09/28 15:43:45 - mmengine - INFO - Iter(train) [ 10450/320000]  base_lr: 9.7056e-05 lr: 9.7056e-06  eta: 1 day, 13:48:11  time: 0.4682  data_time: 0.0086  memory: 5167  grad_norm: 184.4048  loss: 10.6373  decode.loss_cls: 0.2371  decode.loss_mask: 0.4754  decode.loss_dice: 0.3044  decode.d0.loss_cls: 0.8931  decode.d0.loss_mask: 0.4814  decode.d0.loss_dice: 0.2932  decode.d1.loss_cls: 0.2714  decode.d1.loss_mask: 0.4553  decode.d1.loss_dice: 0.2781  decode.d2.loss_cls: 0.2608  decode.d2.loss_mask: 0.4396  decode.d2.loss_dice: 0.2704  decode.d3.loss_cls: 0.2527  decode.d3.loss_mask: 0.4454  decode.d3.loss_dice: 0.2787  decode.d4.loss_cls: 0.2316  decode.d4.loss_mask: 0.4470  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.2572  decode.d5.loss_mask: 0.4419  decode.d5.loss_dice: 0.2714  decode.d6.loss_cls: 0.2627  decode.d6.loss_mask: 0.4695  decode.d6.loss_dice: 0.3089  decode.d7.loss_cls: 0.2623  decode.d7.loss_mask: 0.4556  decode.d7.loss_dice: 0.2951  decode.d8.loss_cls: 0.2399  decode.d8.loss_mask: 0.4708  decode.d8.loss_dice: 0.3061
09/28 15:44:09 - mmengine - INFO - Iter(train) [ 10500/320000]  base_lr: 9.7042e-05 lr: 9.7042e-06  eta: 1 day, 13:48:32  time: 0.4701  data_time: 0.0094  memory: 5186  grad_norm: 138.3096  loss: 10.2791  decode.loss_cls: 0.2809  decode.loss_mask: 0.3497  decode.loss_dice: 0.3193  decode.d0.loss_cls: 1.2580  decode.d0.loss_mask: 0.3148  decode.d0.loss_dice: 0.3322  decode.d1.loss_cls: 0.4125  decode.d1.loss_mask: 0.2871  decode.d1.loss_dice: 0.2868  decode.d2.loss_cls: 0.3429  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.2586  decode.d3.loss_cls: 0.3055  decode.d3.loss_mask: 0.3189  decode.d3.loss_dice: 0.2864  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 0.3187  decode.d4.loss_dice: 0.2772  decode.d5.loss_cls: 0.3001  decode.d5.loss_mask: 0.3071  decode.d5.loss_dice: 0.3067  decode.d6.loss_cls: 0.2737  decode.d6.loss_mask: 0.3080  decode.d6.loss_dice: 0.3199  decode.d7.loss_cls: 0.2532  decode.d7.loss_mask: 0.3763  decode.d7.loss_dice: 0.3191  decode.d8.loss_cls: 0.2930  decode.d8.loss_mask: 0.3622  decode.d8.loss_dice: 0.3038
09/28 15:44:32 - mmengine - INFO - Iter(train) [ 10550/320000]  base_lr: 9.7028e-05 lr: 9.7028e-06  eta: 1 day, 13:48:52  time: 0.4676  data_time: 0.0088  memory: 5166  grad_norm: 126.2176  loss: 9.7980  decode.loss_cls: 0.3936  decode.loss_mask: 0.2594  decode.loss_dice: 0.2635  decode.d0.loss_cls: 1.0228  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.4527  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.2579  decode.d2.loss_cls: 0.3760  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.2528  decode.d3.loss_cls: 0.3956  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.2489  decode.d4.loss_cls: 0.3391  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.2560  decode.d5.loss_cls: 0.3847  decode.d5.loss_mask: 0.2662  decode.d5.loss_dice: 0.2567  decode.d6.loss_cls: 0.3801  decode.d6.loss_mask: 0.2667  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.4252  decode.d7.loss_mask: 0.2696  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.3872  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.2620
09/28 15:44:55 - mmengine - INFO - Iter(train) [ 10600/320000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 1 day, 13:49:13  time: 0.4697  data_time: 0.0086  memory: 5186  grad_norm: 66.4351  loss: 7.5092  decode.loss_cls: 0.1891  decode.loss_mask: 0.2356  decode.loss_dice: 0.2689  decode.d0.loss_cls: 0.8714  decode.d0.loss_mask: 0.2451  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.1991  decode.d1.loss_mask: 0.2433  decode.d1.loss_dice: 0.2460  decode.d2.loss_cls: 0.1779  decode.d2.loss_mask: 0.2350  decode.d2.loss_dice: 0.2550  decode.d3.loss_cls: 0.2248  decode.d3.loss_mask: 0.2367  decode.d3.loss_dice: 0.2332  decode.d4.loss_cls: 0.2239  decode.d4.loss_mask: 0.2332  decode.d4.loss_dice: 0.2677  decode.d5.loss_cls: 0.1938  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.1971  decode.d6.loss_mask: 0.2337  decode.d6.loss_dice: 0.2327  decode.d7.loss_cls: 0.2171  decode.d7.loss_mask: 0.2346  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.1781  decode.d8.loss_mask: 0.2383  decode.d8.loss_dice: 0.2338
09/28 15:45:19 - mmengine - INFO - Iter(train) [ 10650/320000]  base_lr: 9.7000e-05 lr: 9.7000e-06  eta: 1 day, 13:49:33  time: 0.4709  data_time: 0.0092  memory: 5167  grad_norm: 65.7330  loss: 7.8880  decode.loss_cls: 0.1904  decode.loss_mask: 0.2675  decode.loss_dice: 0.2420  decode.d0.loss_cls: 0.9625  decode.d0.loss_mask: 0.2702  decode.d0.loss_dice: 0.2281  decode.d1.loss_cls: 0.2401  decode.d1.loss_mask: 0.2670  decode.d1.loss_dice: 0.2350  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 0.2605  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.1888  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.2367  decode.d4.loss_cls: 0.2595  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.2408  decode.d5.loss_mask: 0.2656  decode.d5.loss_dice: 0.2249  decode.d6.loss_cls: 0.2512  decode.d6.loss_mask: 0.2632  decode.d6.loss_dice: 0.2504  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 0.2627  decode.d7.loss_dice: 0.2167  decode.d8.loss_cls: 0.2189  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2010
09/28 15:45:42 - mmengine - INFO - Iter(train) [ 10700/320000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 1 day, 13:49:52  time: 0.4699  data_time: 0.0090  memory: 5166  grad_norm: 63.6017  loss: 9.3383  decode.loss_cls: 0.4160  decode.loss_mask: 0.2773  decode.loss_dice: 0.2647  decode.d0.loss_cls: 1.1667  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.2431  decode.d1.loss_cls: 0.3052  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.2099  decode.d2.loss_cls: 0.2644  decode.d2.loss_mask: 0.2915  decode.d2.loss_dice: 0.2318  decode.d3.loss_cls: 0.3290  decode.d3.loss_mask: 0.2836  decode.d3.loss_dice: 0.2270  decode.d4.loss_cls: 0.3371  decode.d4.loss_mask: 0.2863  decode.d4.loss_dice: 0.2203  decode.d5.loss_cls: 0.3202  decode.d5.loss_mask: 0.2926  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.3605  decode.d6.loss_mask: 0.2881  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.3139  decode.d7.loss_mask: 0.2905  decode.d7.loss_dice: 0.2225  decode.d8.loss_cls: 0.3662  decode.d8.loss_mask: 0.2729  decode.d8.loss_dice: 0.2270
09/28 15:46:06 - mmengine - INFO - Iter(train) [ 10750/320000]  base_lr: 9.6972e-05 lr: 9.6972e-06  eta: 1 day, 13:50:11  time: 0.4684  data_time: 0.0088  memory: 5186  grad_norm: 172.1641  loss: 11.4976  decode.loss_cls: 0.3275  decode.loss_mask: 0.4928  decode.loss_dice: 0.2576  decode.d0.loss_cls: 0.9101  decode.d0.loss_mask: 0.4913  decode.d0.loss_dice: 0.2869  decode.d1.loss_cls: 0.4581  decode.d1.loss_mask: 0.4761  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.3216  decode.d2.loss_mask: 0.4799  decode.d2.loss_dice: 0.2561  decode.d3.loss_cls: 0.3113  decode.d3.loss_mask: 0.4807  decode.d3.loss_dice: 0.2584  decode.d4.loss_cls: 0.3026  decode.d4.loss_mask: 0.4820  decode.d4.loss_dice: 0.2575  decode.d5.loss_cls: 0.3453  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.2565  decode.d6.loss_cls: 0.3732  decode.d6.loss_mask: 0.4852  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.3469  decode.d7.loss_mask: 0.4871  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.3604  decode.d8.loss_mask: 0.4898  decode.d8.loss_dice: 0.2512
09/28 15:46:29 - mmengine - INFO - Iter(train) [ 10800/320000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 1 day, 13:50:30  time: 0.4691  data_time: 0.0091  memory: 5186  grad_norm: 87.0026  loss: 9.1456  decode.loss_cls: 0.3699  decode.loss_mask: 0.5275  decode.loss_dice: 0.2972  decode.d0.loss_cls: 1.1291  decode.d0.loss_mask: 0.2396  decode.d0.loss_dice: 0.2469  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 0.2331  decode.d1.loss_dice: 0.2490  decode.d2.loss_cls: 0.2682  decode.d2.loss_mask: 0.2334  decode.d2.loss_dice: 0.2277  decode.d3.loss_cls: 0.2635  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.2403  decode.d4.loss_mask: 0.2325  decode.d4.loss_dice: 0.2354  decode.d5.loss_cls: 0.2459  decode.d5.loss_mask: 0.2315  decode.d5.loss_dice: 0.2236  decode.d6.loss_cls: 0.3495  decode.d6.loss_mask: 0.2365  decode.d6.loss_dice: 0.2443  decode.d7.loss_cls: 0.3860  decode.d7.loss_mask: 0.2935  decode.d7.loss_dice: 0.2944  decode.d8.loss_cls: 0.3347  decode.d8.loss_mask: 0.2729  decode.d8.loss_dice: 0.2906
09/28 15:46:53 - mmengine - INFO - Iter(train) [ 10850/320000]  base_lr: 9.6943e-05 lr: 9.6943e-06  eta: 1 day, 13:50:48  time: 0.4678  data_time: 0.0089  memory: 5186  grad_norm: 66.1485  loss: 9.9312  decode.loss_cls: 0.3427  decode.loss_mask: 0.2474  decode.loss_dice: 0.3033  decode.d0.loss_cls: 1.0848  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.3376  decode.d1.loss_cls: 0.4450  decode.d1.loss_mask: 0.2403  decode.d1.loss_dice: 0.3047  decode.d2.loss_cls: 0.3676  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.3004  decode.d3.loss_cls: 0.3343  decode.d3.loss_mask: 0.2516  decode.d3.loss_dice: 0.2979  decode.d4.loss_cls: 0.3339  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.2884  decode.d5.loss_cls: 0.3908  decode.d5.loss_mask: 0.2525  decode.d5.loss_dice: 0.2965  decode.d6.loss_cls: 0.3645  decode.d6.loss_mask: 0.2485  decode.d6.loss_dice: 0.3161  decode.d7.loss_cls: 0.3483  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.3127  decode.d8.loss_cls: 0.3693  decode.d8.loss_mask: 0.2490  decode.d8.loss_dice: 0.3072
09/28 15:47:16 - mmengine - INFO - Iter(train) [ 10900/320000]  base_lr: 9.6929e-05 lr: 9.6929e-06  eta: 1 day, 13:51:06  time: 0.4691  data_time: 0.0086  memory: 5150  grad_norm: 110.0112  loss: 11.0271  decode.loss_cls: 0.2803  decode.loss_mask: 0.3890  decode.loss_dice: 0.2975  decode.d0.loss_cls: 1.0814  decode.d0.loss_mask: 0.4039  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.4211  decode.d1.loss_mask: 0.3537  decode.d1.loss_dice: 0.2929  decode.d2.loss_cls: 0.4662  decode.d2.loss_mask: 0.3677  decode.d2.loss_dice: 0.2939  decode.d3.loss_cls: 0.3518  decode.d3.loss_mask: 0.3816  decode.d3.loss_dice: 0.3202  decode.d4.loss_cls: 0.3501  decode.d4.loss_mask: 0.3654  decode.d4.loss_dice: 0.2957  decode.d5.loss_cls: 0.3393  decode.d5.loss_mask: 0.3652  decode.d5.loss_dice: 0.2880  decode.d6.loss_cls: 0.3066  decode.d6.loss_mask: 0.3853  decode.d6.loss_dice: 0.3170  decode.d7.loss_cls: 0.3466  decode.d7.loss_mask: 0.3709  decode.d7.loss_dice: 0.2857  decode.d8.loss_cls: 0.3384  decode.d8.loss_mask: 0.3647  decode.d8.loss_dice: 0.2732
09/28 15:47:40 - mmengine - INFO - Iter(train) [ 10950/320000]  base_lr: 9.6915e-05 lr: 9.6915e-06  eta: 1 day, 13:51:23  time: 0.4695  data_time: 0.0092  memory: 5150  grad_norm: 98.1788  loss: 8.5272  decode.loss_cls: 0.3117  decode.loss_mask: 0.2582  decode.loss_dice: 0.2057  decode.d0.loss_cls: 1.3087  decode.d0.loss_mask: 0.2682  decode.d0.loss_dice: 0.2480  decode.d1.loss_cls: 0.3041  decode.d1.loss_mask: 0.2592  decode.d1.loss_dice: 0.2084  decode.d2.loss_cls: 0.2722  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.1886  decode.d3.loss_cls: 0.2394  decode.d3.loss_mask: 0.2902  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.2867  decode.d4.loss_mask: 0.2949  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.3087  decode.d5.loss_mask: 0.2522  decode.d5.loss_dice: 0.1836  decode.d6.loss_cls: 0.2626  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.2654  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.1895  decode.d8.loss_cls: 0.2930  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.2029
09/28 15:48:03 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:48:03 - mmengine - INFO - Iter(train) [ 11000/320000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 1 day, 13:51:40  time: 0.4671  data_time: 0.0090  memory: 5185  grad_norm: 92.5315  loss: 9.0945  decode.loss_cls: 0.1941  decode.loss_mask: 0.3806  decode.loss_dice: 0.2621  decode.d0.loss_cls: 0.8394  decode.d0.loss_mask: 0.3961  decode.d0.loss_dice: 0.2637  decode.d1.loss_cls: 0.2473  decode.d1.loss_mask: 0.3826  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 0.3939  decode.d2.loss_dice: 0.2601  decode.d3.loss_cls: 0.1772  decode.d3.loss_mask: 0.3816  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.2122  decode.d4.loss_mask: 0.4042  decode.d4.loss_dice: 0.2728  decode.d5.loss_cls: 0.1763  decode.d5.loss_mask: 0.3946  decode.d5.loss_dice: 0.2563  decode.d6.loss_cls: 0.2411  decode.d6.loss_mask: 0.3781  decode.d6.loss_dice: 0.2676  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 0.3733  decode.d7.loss_dice: 0.2657  decode.d8.loss_cls: 0.1931  decode.d8.loss_mask: 0.3820  decode.d8.loss_dice: 0.2613
09/28 15:48:25 - mmengine - INFO - Iter(train) [ 11050/320000]  base_lr: 9.6887e-05 lr: 9.6887e-06  eta: 1 day, 13:51:20  time: 0.4314  data_time: 0.0089  memory: 5167  grad_norm: 94.8829  loss: 12.0372  decode.loss_cls: 0.4065  decode.loss_mask: 0.4035  decode.loss_dice: 0.3095  decode.d0.loss_cls: 1.3101  decode.d0.loss_mask: 0.3741  decode.d0.loss_dice: 0.3257  decode.d1.loss_cls: 0.3978  decode.d1.loss_mask: 0.4155  decode.d1.loss_dice: 0.3338  decode.d2.loss_cls: 0.3844  decode.d2.loss_mask: 0.4282  decode.d2.loss_dice: 0.3066  decode.d3.loss_cls: 0.3678  decode.d3.loss_mask: 0.4037  decode.d3.loss_dice: 0.3206  decode.d4.loss_cls: 0.3489  decode.d4.loss_mask: 0.4128  decode.d4.loss_dice: 0.3290  decode.d5.loss_cls: 0.3696  decode.d5.loss_mask: 0.3853  decode.d5.loss_dice: 0.3245  decode.d6.loss_cls: 0.4036  decode.d6.loss_mask: 0.4115  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.3869  decode.d7.loss_mask: 0.4090  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.4415  decode.d8.loss_mask: 0.4065  decode.d8.loss_dice: 0.2999
09/28 15:48:47 - mmengine - INFO - Iter(train) [ 11100/320000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 1 day, 13:50:44  time: 0.4307  data_time: 0.0088  memory: 5186  grad_norm: 69.7385  loss: 9.3172  decode.loss_cls: 0.2691  decode.loss_mask: 0.3130  decode.loss_dice: 0.2814  decode.d0.loss_cls: 1.3391  decode.d0.loss_mask: 0.2914  decode.d0.loss_dice: 0.2358  decode.d1.loss_cls: 0.2871  decode.d1.loss_mask: 0.3062  decode.d1.loss_dice: 0.2493  decode.d2.loss_cls: 0.2111  decode.d2.loss_mask: 0.3027  decode.d2.loss_dice: 0.2447  decode.d3.loss_cls: 0.1910  decode.d3.loss_mask: 0.3030  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.2226  decode.d4.loss_mask: 0.2952  decode.d4.loss_dice: 0.3005  decode.d5.loss_cls: 0.2411  decode.d5.loss_mask: 0.2981  decode.d5.loss_dice: 0.2854  decode.d6.loss_cls: 0.2379  decode.d6.loss_mask: 0.3305  decode.d6.loss_dice: 0.2914  decode.d7.loss_cls: 0.2221  decode.d7.loss_mask: 0.3259  decode.d7.loss_dice: 0.3002  decode.d8.loss_cls: 0.2547  decode.d8.loss_mask: 0.3207  decode.d8.loss_dice: 0.3242
09/28 15:49:08 - mmengine - INFO - Iter(train) [ 11150/320000]  base_lr: 9.6859e-05 lr: 9.6859e-06  eta: 1 day, 13:50:12  time: 0.4484  data_time: 0.0088  memory: 5166  grad_norm: 142.9582  loss: 8.3719  decode.loss_cls: 0.1388  decode.loss_mask: 0.3172  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.8766  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.2721  decode.d1.loss_cls: 0.1955  decode.d1.loss_mask: 0.3528  decode.d1.loss_dice: 0.2491  decode.d2.loss_cls: 0.1867  decode.d2.loss_mask: 0.3146  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.1955  decode.d4.loss_mask: 0.3356  decode.d4.loss_dice: 0.2494  decode.d5.loss_cls: 0.2227  decode.d5.loss_mask: 0.3485  decode.d5.loss_dice: 0.2447  decode.d6.loss_cls: 0.2096  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.2335  decode.d7.loss_cls: 0.1550  decode.d7.loss_mask: 0.3643  decode.d7.loss_dice: 0.2333  decode.d8.loss_cls: 0.1147  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.2599
09/28 15:49:30 - mmengine - INFO - Iter(train) [ 11200/320000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 1 day, 13:49:36  time: 0.4314  data_time: 0.0089  memory: 5167  grad_norm: 129.0558  loss: 11.3571  decode.loss_cls: 0.3238  decode.loss_mask: 0.3529  decode.loss_dice: 0.3310  decode.d0.loss_cls: 1.1448  decode.d0.loss_mask: 0.3867  decode.d0.loss_dice: 0.4214  decode.d1.loss_cls: 0.4331  decode.d1.loss_mask: 0.3555  decode.d1.loss_dice: 0.3463  decode.d2.loss_cls: 0.3542  decode.d2.loss_mask: 0.3566  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 0.4266  decode.d3.loss_mask: 0.3530  decode.d3.loss_dice: 0.3409  decode.d4.loss_cls: 0.3189  decode.d4.loss_mask: 0.3473  decode.d4.loss_dice: 0.3355  decode.d5.loss_cls: 0.3412  decode.d5.loss_mask: 0.3558  decode.d5.loss_dice: 0.3454  decode.d6.loss_cls: 0.3477  decode.d6.loss_mask: 0.3562  decode.d6.loss_dice: 0.3362  decode.d7.loss_cls: 0.3072  decode.d7.loss_mask: 0.3589  decode.d7.loss_dice: 0.3397  decode.d8.loss_cls: 0.3116  decode.d8.loss_mask: 0.3547  decode.d8.loss_dice: 0.3259
09/28 15:49:51 - mmengine - INFO - Iter(train) [ 11250/320000]  base_lr: 9.6831e-05 lr: 9.6831e-06  eta: 1 day, 13:48:59  time: 0.4303  data_time: 0.0087  memory: 5199  grad_norm: 391.8294  loss: 16.2255  decode.loss_cls: 0.6653  decode.loss_mask: 0.5477  decode.loss_dice: 0.4189  decode.d0.loss_cls: 1.4814  decode.d0.loss_mask: 0.4313  decode.d0.loss_dice: 0.4287  decode.d1.loss_cls: 0.5622  decode.d1.loss_mask: 0.4441  decode.d1.loss_dice: 0.4009  decode.d2.loss_cls: 0.5539  decode.d2.loss_mask: 0.4484  decode.d2.loss_dice: 0.3886  decode.d3.loss_cls: 0.6173  decode.d3.loss_mask: 0.4626  decode.d3.loss_dice: 0.4327  decode.d4.loss_cls: 0.5873  decode.d4.loss_mask: 0.4889  decode.d4.loss_dice: 0.4114  decode.d5.loss_cls: 0.6145  decode.d5.loss_mask: 0.5196  decode.d5.loss_dice: 0.4535  decode.d6.loss_cls: 0.6713  decode.d6.loss_mask: 0.5595  decode.d6.loss_dice: 0.3945  decode.d7.loss_cls: 0.7284  decode.d7.loss_mask: 0.4755  decode.d7.loss_dice: 0.4073  decode.d8.loss_cls: 0.6994  decode.d8.loss_mask: 0.5097  decode.d8.loss_dice: 0.4205
09/28 15:50:13 - mmengine - INFO - Iter(train) [ 11300/320000]  base_lr: 9.6816e-05 lr: 9.6816e-06  eta: 1 day, 13:48:23  time: 0.4297  data_time: 0.0090  memory: 5167  grad_norm: 165.4711  loss: 10.0326  decode.loss_cls: 0.3192  decode.loss_mask: 0.3200  decode.loss_dice: 0.2763  decode.d0.loss_cls: 1.1135  decode.d0.loss_mask: 0.3422  decode.d0.loss_dice: 0.2878  decode.d1.loss_cls: 0.3785  decode.d1.loss_mask: 0.3182  decode.d1.loss_dice: 0.2669  decode.d2.loss_cls: 0.3075  decode.d2.loss_mask: 0.3176  decode.d2.loss_dice: 0.2739  decode.d3.loss_cls: 0.3175  decode.d3.loss_mask: 0.3237  decode.d3.loss_dice: 0.2821  decode.d4.loss_cls: 0.3042  decode.d4.loss_mask: 0.3168  decode.d4.loss_dice: 0.2863  decode.d5.loss_cls: 0.3280  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.2857  decode.d6.loss_cls: 0.3250  decode.d6.loss_mask: 0.3177  decode.d6.loss_dice: 0.2671  decode.d7.loss_cls: 0.3343  decode.d7.loss_mask: 0.3235  decode.d7.loss_dice: 0.2318  decode.d8.loss_cls: 0.3503  decode.d8.loss_mask: 0.3219  decode.d8.loss_dice: 0.2761
09/28 15:50:34 - mmengine - INFO - Iter(train) [ 11350/320000]  base_lr: 9.6802e-05 lr: 9.6802e-06  eta: 1 day, 13:47:46  time: 0.4301  data_time: 0.0088  memory: 5186  grad_norm: 87.2450  loss: 11.1574  decode.loss_cls: 0.3437  decode.loss_mask: 0.4234  decode.loss_dice: 0.3282  decode.d0.loss_cls: 1.0929  decode.d0.loss_mask: 0.3131  decode.d0.loss_dice: 0.3307  decode.d1.loss_cls: 0.4010  decode.d1.loss_mask: 0.2992  decode.d1.loss_dice: 0.2997  decode.d2.loss_cls: 0.3476  decode.d2.loss_mask: 0.2976  decode.d2.loss_dice: 0.2928  decode.d3.loss_cls: 0.3328  decode.d3.loss_mask: 0.3085  decode.d3.loss_dice: 0.3000  decode.d4.loss_cls: 0.3189  decode.d4.loss_mask: 0.3059  decode.d4.loss_dice: 0.2623  decode.d5.loss_cls: 0.3498  decode.d5.loss_mask: 0.3036  decode.d5.loss_dice: 0.2894  decode.d6.loss_cls: 0.2871  decode.d6.loss_mask: 0.3183  decode.d6.loss_dice: 0.3127  decode.d7.loss_cls: 0.3749  decode.d7.loss_mask: 0.6069  decode.d7.loss_dice: 0.3460  decode.d8.loss_cls: 0.3719  decode.d8.loss_mask: 0.6343  decode.d8.loss_dice: 0.3645
09/28 15:50:56 - mmengine - INFO - Iter(train) [ 11400/320000]  base_lr: 9.6788e-05 lr: 9.6788e-06  eta: 1 day, 13:47:10  time: 0.4296  data_time: 0.0088  memory: 5167  grad_norm: 228.5999  loss: 12.4086  decode.loss_cls: 0.3697  decode.loss_mask: 0.4368  decode.loss_dice: 0.3530  decode.d0.loss_cls: 1.2158  decode.d0.loss_mask: 0.4189  decode.d0.loss_dice: 0.3212  decode.d1.loss_cls: 0.6014  decode.d1.loss_mask: 0.3801  decode.d1.loss_dice: 0.3000  decode.d2.loss_cls: 0.4424  decode.d2.loss_mask: 0.3867  decode.d2.loss_dice: 0.3027  decode.d3.loss_cls: 0.3672  decode.d3.loss_mask: 0.3859  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.4202  decode.d4.loss_mask: 0.4325  decode.d4.loss_dice: 0.3388  decode.d5.loss_cls: 0.4308  decode.d5.loss_mask: 0.3784  decode.d5.loss_dice: 0.3300  decode.d6.loss_cls: 0.3214  decode.d6.loss_mask: 0.4334  decode.d6.loss_dice: 0.3731  decode.d7.loss_cls: 0.3957  decode.d7.loss_mask: 0.4145  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.4141  decode.d8.loss_mask: 0.4553  decode.d8.loss_dice: 0.3527
09/28 15:51:18 - mmengine - INFO - Iter(train) [ 11450/320000]  base_lr: 9.6774e-05 lr: 9.6774e-06  eta: 1 day, 13:46:57  time: 0.4689  data_time: 0.0092  memory: 5166  grad_norm: 146.9056  loss: 9.2643  decode.loss_cls: 0.3132  decode.loss_mask: 0.3356  decode.loss_dice: 0.2276  decode.d0.loss_cls: 0.9933  decode.d0.loss_mask: 0.3471  decode.d0.loss_dice: 0.2498  decode.d1.loss_cls: 0.3068  decode.d1.loss_mask: 0.3395  decode.d1.loss_dice: 0.2177  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.3398  decode.d2.loss_dice: 0.2180  decode.d3.loss_cls: 0.2632  decode.d3.loss_mask: 0.3386  decode.d3.loss_dice: 0.2285  decode.d4.loss_cls: 0.1975  decode.d4.loss_mask: 0.3962  decode.d4.loss_dice: 0.2411  decode.d5.loss_cls: 0.2677  decode.d5.loss_mask: 0.3509  decode.d5.loss_dice: 0.2434  decode.d6.loss_cls: 0.2312  decode.d6.loss_mask: 0.3925  decode.d6.loss_dice: 0.2465  decode.d7.loss_cls: 0.2905  decode.d7.loss_mask: 0.3402  decode.d7.loss_dice: 0.2191  decode.d8.loss_cls: 0.3019  decode.d8.loss_mask: 0.3410  decode.d8.loss_dice: 0.2249
09/28 15:51:42 - mmengine - INFO - Iter(train) [ 11500/320000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 1 day, 13:47:12  time: 0.4672  data_time: 0.0088  memory: 5186  grad_norm: 449.6338  loss: 13.6257  decode.loss_cls: 0.5019  decode.loss_mask: 0.4496  decode.loss_dice: 0.3579  decode.d0.loss_cls: 1.3350  decode.d0.loss_mask: 0.4510  decode.d0.loss_dice: 0.3864  decode.d1.loss_cls: 0.4048  decode.d1.loss_mask: 0.4306  decode.d1.loss_dice: 0.3541  decode.d2.loss_cls: 0.4098  decode.d2.loss_mask: 0.6900  decode.d2.loss_dice: 0.3763  decode.d3.loss_cls: 0.4484  decode.d3.loss_mask: 0.4225  decode.d3.loss_dice: 0.3549  decode.d4.loss_cls: 0.4426  decode.d4.loss_mask: 0.4654  decode.d4.loss_dice: 0.3669  decode.d5.loss_cls: 0.4105  decode.d5.loss_mask: 0.4782  decode.d5.loss_dice: 0.3489  decode.d6.loss_cls: 0.3875  decode.d6.loss_mask: 0.4603  decode.d6.loss_dice: 0.3433  decode.d7.loss_cls: 0.4138  decode.d7.loss_mask: 0.5012  decode.d7.loss_dice: 0.3719  decode.d8.loss_cls: 0.4057  decode.d8.loss_mask: 0.4862  decode.d8.loss_dice: 0.3701
09/28 15:52:05 - mmengine - INFO - Iter(train) [ 11550/320000]  base_lr: 9.6746e-05 lr: 9.6746e-06  eta: 1 day, 13:47:28  time: 0.4695  data_time: 0.0088  memory: 5167  grad_norm: 53.8919  loss: 7.4389  decode.loss_cls: 0.1981  decode.loss_mask: 0.2977  decode.loss_dice: 0.2477  decode.d0.loss_cls: 0.8573  decode.d0.loss_mask: 0.2714  decode.d0.loss_dice: 0.2499  decode.d1.loss_cls: 0.1924  decode.d1.loss_mask: 0.2549  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.1437  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2508  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.2552  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.2561  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.1692  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.2284  decode.d6.loss_cls: 0.1674  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.1612  decode.d7.loss_mask: 0.2558  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.1791  decode.d8.loss_mask: 0.2595  decode.d8.loss_dice: 0.2450
09/28 15:52:29 - mmengine - INFO - Iter(train) [ 11600/320000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 1 day, 13:47:42  time: 0.4671  data_time: 0.0090  memory: 5186  grad_norm: 92.9396  loss: 8.0357  decode.loss_cls: 0.2251  decode.loss_mask: 0.2325  decode.loss_dice: 0.2355  decode.d0.loss_cls: 1.0532  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.2340  decode.d1.loss_cls: 0.3741  decode.d1.loss_mask: 0.2201  decode.d1.loss_dice: 0.2025  decode.d2.loss_cls: 0.2741  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.2010  decode.d3.loss_cls: 0.2505  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.2058  decode.d4.loss_cls: 0.2711  decode.d4.loss_mask: 0.2269  decode.d4.loss_dice: 0.2260  decode.d5.loss_cls: 0.2625  decode.d5.loss_mask: 0.2234  decode.d5.loss_dice: 0.2228  decode.d6.loss_cls: 0.2967  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2214  decode.d7.loss_cls: 0.2957  decode.d7.loss_mask: 0.2325  decode.d7.loss_dice: 0.2089  decode.d8.loss_cls: 0.2923  decode.d8.loss_mask: 0.2246  decode.d8.loss_dice: 0.2169
09/28 15:52:52 - mmengine - INFO - Iter(train) [ 11650/320000]  base_lr: 9.6718e-05 lr: 9.6718e-06  eta: 1 day, 13:47:57  time: 0.4690  data_time: 0.0086  memory: 5186  grad_norm: 78.7380  loss: 8.5022  decode.loss_cls: 0.2195  decode.loss_mask: 0.2470  decode.loss_dice: 0.2581  decode.d0.loss_cls: 1.1636  decode.d0.loss_mask: 0.2526  decode.d0.loss_dice: 0.3015  decode.d1.loss_cls: 0.2452  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.2391  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.2949  decode.d3.loss_cls: 0.2267  decode.d3.loss_mask: 0.2731  decode.d3.loss_dice: 0.2625  decode.d4.loss_cls: 0.2201  decode.d4.loss_mask: 0.2568  decode.d4.loss_dice: 0.2870  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.2650  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.2308  decode.d6.loss_mask: 0.2541  decode.d6.loss_dice: 0.2732  decode.d7.loss_cls: 0.2509  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2701  decode.d8.loss_cls: 0.2039  decode.d8.loss_mask: 0.2464  decode.d8.loss_dice: 0.2421
09/28 15:53:16 - mmengine - INFO - Iter(train) [ 11700/320000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 1 day, 13:48:11  time: 0.4703  data_time: 0.0090  memory: 5167  grad_norm: 197.6834  loss: 10.4146  decode.loss_cls: 0.4007  decode.loss_mask: 0.2609  decode.loss_dice: 0.2453  decode.d0.loss_cls: 1.5502  decode.d0.loss_mask: 0.2298  decode.d0.loss_dice: 0.2845  decode.d1.loss_cls: 0.5498  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.4253  decode.d2.loss_mask: 0.2480  decode.d2.loss_dice: 0.2407  decode.d3.loss_cls: 0.3495  decode.d3.loss_mask: 0.2284  decode.d3.loss_dice: 0.2502  decode.d4.loss_cls: 0.4442  decode.d4.loss_mask: 0.2290  decode.d4.loss_dice: 0.2398  decode.d5.loss_cls: 0.4047  decode.d5.loss_mask: 0.2336  decode.d5.loss_dice: 0.2611  decode.d6.loss_cls: 0.4226  decode.d6.loss_mask: 0.2513  decode.d6.loss_dice: 0.2484  decode.d7.loss_cls: 0.3899  decode.d7.loss_mask: 0.2950  decode.d7.loss_dice: 0.2523  decode.d8.loss_cls: 0.4402  decode.d8.loss_mask: 0.2644  decode.d8.loss_dice: 0.2436
09/28 15:53:39 - mmengine - INFO - Iter(train) [ 11750/320000]  base_lr: 9.6689e-05 lr: 9.6689e-06  eta: 1 day, 13:48:27  time: 0.4698  data_time: 0.0087  memory: 5186  grad_norm: 87.8898  loss: 8.2666  decode.loss_cls: 0.1568  decode.loss_mask: 0.3362  decode.loss_dice: 0.2350  decode.d0.loss_cls: 0.9831  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.2706  decode.d1.loss_cls: 0.2798  decode.d1.loss_mask: 0.3357  decode.d1.loss_dice: 0.2578  decode.d2.loss_cls: 0.2130  decode.d2.loss_mask: 0.3190  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.1686  decode.d3.loss_mask: 0.3220  decode.d3.loss_dice: 0.2459  decode.d4.loss_cls: 0.1766  decode.d4.loss_mask: 0.3242  decode.d4.loss_dice: 0.2524  decode.d5.loss_cls: 0.1586  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.1555  decode.d6.loss_mask: 0.3269  decode.d6.loss_dice: 0.2534  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 0.3238  decode.d7.loss_dice: 0.2427  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 0.3313  decode.d8.loss_dice: 0.2330
09/28 15:54:03 - mmengine - INFO - Iter(train) [ 11800/320000]  base_lr: 9.6675e-05 lr: 9.6675e-06  eta: 1 day, 13:48:41  time: 0.4696  data_time: 0.0092  memory: 5166  grad_norm: 173.0449  loss: 12.8241  decode.loss_cls: 0.3749  decode.loss_mask: 0.5585  decode.loss_dice: 0.4179  decode.d0.loss_cls: 1.2362  decode.d0.loss_mask: 0.3245  decode.d0.loss_dice: 0.3241  decode.d1.loss_cls: 0.4700  decode.d1.loss_mask: 0.3109  decode.d1.loss_dice: 0.3021  decode.d2.loss_cls: 0.4526  decode.d2.loss_mask: 0.3695  decode.d2.loss_dice: 0.3385  decode.d3.loss_cls: 0.4573  decode.d3.loss_mask: 0.3502  decode.d3.loss_dice: 0.3535  decode.d4.loss_cls: 0.5702  decode.d4.loss_mask: 0.3239  decode.d4.loss_dice: 0.3468  decode.d5.loss_cls: 0.5531  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.3595  decode.d6.loss_cls: 0.4624  decode.d6.loss_mask: 0.3280  decode.d6.loss_dice: 0.4069  decode.d7.loss_cls: 0.5112  decode.d7.loss_mask: 0.3417  decode.d7.loss_dice: 0.3757  decode.d8.loss_cls: 0.4996  decode.d8.loss_mask: 0.3553  decode.d8.loss_dice: 0.4155
09/28 15:54:26 - mmengine - INFO - Iter(train) [ 11850/320000]  base_lr: 9.6661e-05 lr: 9.6661e-06  eta: 1 day, 13:48:55  time: 0.4679  data_time: 0.0090  memory: 5148  grad_norm: 174.2978  loss: 12.1180  decode.loss_cls: 0.4599  decode.loss_mask: 0.3283  decode.loss_dice: 0.3037  decode.d0.loss_cls: 1.0994  decode.d0.loss_mask: 0.3525  decode.d0.loss_dice: 0.3481  decode.d1.loss_cls: 0.4994  decode.d1.loss_mask: 0.3274  decode.d1.loss_dice: 0.3348  decode.d2.loss_cls: 0.5593  decode.d2.loss_mask: 0.3243  decode.d2.loss_dice: 0.3205  decode.d3.loss_cls: 0.4933  decode.d3.loss_mask: 0.3284  decode.d3.loss_dice: 0.3323  decode.d4.loss_cls: 0.5067  decode.d4.loss_mask: 0.3330  decode.d4.loss_dice: 0.3130  decode.d5.loss_cls: 0.4798  decode.d5.loss_mask: 0.3316  decode.d5.loss_dice: 0.3656  decode.d6.loss_cls: 0.4289  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.3283  decode.d7.loss_cls: 0.4726  decode.d7.loss_mask: 0.3313  decode.d7.loss_dice: 0.3138  decode.d8.loss_cls: 0.4847  decode.d8.loss_mask: 0.3255  decode.d8.loss_dice: 0.3505
09/28 15:54:49 - mmengine - INFO - Iter(train) [ 11900/320000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 1 day, 13:49:09  time: 0.4690  data_time: 0.0086  memory: 5186  grad_norm: 292.7292  loss: 10.7199  decode.loss_cls: 0.3919  decode.loss_mask: 0.3229  decode.loss_dice: 0.2888  decode.d0.loss_cls: 0.9777  decode.d0.loss_mask: 0.3564  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.4504  decode.d1.loss_mask: 0.3176  decode.d1.loss_dice: 0.2710  decode.d2.loss_cls: 0.4195  decode.d2.loss_mask: 0.3057  decode.d2.loss_dice: 0.2797  decode.d3.loss_cls: 0.4841  decode.d3.loss_mask: 0.3007  decode.d3.loss_dice: 0.2736  decode.d4.loss_cls: 0.3937  decode.d4.loss_mask: 0.3126  decode.d4.loss_dice: 0.2836  decode.d5.loss_cls: 0.3531  decode.d5.loss_mask: 0.3157  decode.d5.loss_dice: 0.2830  decode.d6.loss_cls: 0.3569  decode.d6.loss_mask: 0.3258  decode.d6.loss_dice: 0.2930  decode.d7.loss_cls: 0.4153  decode.d7.loss_mask: 0.3186  decode.d7.loss_dice: 0.2894  decode.d8.loss_cls: 0.4119  decode.d8.loss_mask: 0.3094  decode.d8.loss_dice: 0.2901
09/28 15:55:13 - mmengine - INFO - Iter(train) [ 11950/320000]  base_lr: 9.6633e-05 lr: 9.6633e-06  eta: 1 day, 13:49:22  time: 0.4700  data_time: 0.0093  memory: 5166  grad_norm: 46.3840  loss: 7.3154  decode.loss_cls: 0.1467  decode.loss_mask: 0.2471  decode.loss_dice: 0.2382  decode.d0.loss_cls: 1.0348  decode.d0.loss_mask: 0.2535  decode.d0.loss_dice: 0.2462  decode.d1.loss_cls: 0.1506  decode.d1.loss_mask: 0.2459  decode.d1.loss_dice: 0.2608  decode.d2.loss_cls: 0.1561  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2620  decode.d3.loss_cls: 0.1287  decode.d3.loss_mask: 0.2452  decode.d3.loss_dice: 0.2536  decode.d4.loss_cls: 0.1226  decode.d4.loss_mask: 0.2491  decode.d4.loss_dice: 0.2486  decode.d5.loss_cls: 0.1265  decode.d5.loss_mask: 0.2503  decode.d5.loss_dice: 0.2525  decode.d6.loss_cls: 0.1387  decode.d6.loss_mask: 0.2476  decode.d6.loss_dice: 0.2579  decode.d7.loss_cls: 0.1523  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.2543  decode.d8.loss_cls: 0.1461  decode.d8.loss_mask: 0.2504  decode.d8.loss_dice: 0.2533
09/28 15:55:36 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 15:55:36 - mmengine - INFO - Iter(train) [ 12000/320000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 1 day, 13:49:34  time: 0.4677  data_time: 0.0090  memory: 5167  grad_norm: 162.4954  loss: 9.1163  decode.loss_cls: 0.2110  decode.loss_mask: 0.3745  decode.loss_dice: 0.2675  decode.d0.loss_cls: 1.0215  decode.d0.loss_mask: 0.3777  decode.d0.loss_dice: 0.2884  decode.d1.loss_cls: 0.2941  decode.d1.loss_mask: 0.3696  decode.d1.loss_dice: 0.2567  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 0.3730  decode.d2.loss_dice: 0.2754  decode.d3.loss_cls: 0.1756  decode.d3.loss_mask: 0.3764  decode.d3.loss_dice: 0.2709  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 0.3779  decode.d4.loss_dice: 0.2876  decode.d5.loss_cls: 0.1411  decode.d5.loss_mask: 0.3752  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.1502  decode.d6.loss_mask: 0.3652  decode.d6.loss_dice: 0.2578  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 0.3685  decode.d7.loss_dice: 0.2616  decode.d8.loss_cls: 0.1513  decode.d8.loss_mask: 0.3807  decode.d8.loss_dice: 0.2682
09/28 15:56:00 - mmengine - INFO - Iter(train) [ 12050/320000]  base_lr: 9.6605e-05 lr: 9.6605e-06  eta: 1 day, 13:49:48  time: 0.4703  data_time: 0.0091  memory: 5150  grad_norm: 88.3844  loss: 9.7163  decode.loss_cls: 0.3170  decode.loss_mask: 0.2785  decode.loss_dice: 0.3598  decode.d0.loss_cls: 1.0634  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.3624  decode.d1.loss_cls: 0.3697  decode.d1.loss_mask: 0.2428  decode.d1.loss_dice: 0.3227  decode.d2.loss_cls: 0.3349  decode.d2.loss_mask: 0.2578  decode.d2.loss_dice: 0.2922  decode.d3.loss_cls: 0.2946  decode.d3.loss_mask: 0.2657  decode.d3.loss_dice: 0.3371  decode.d4.loss_cls: 0.2392  decode.d4.loss_mask: 0.2554  decode.d4.loss_dice: 0.3470  decode.d5.loss_cls: 0.2381  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.3516  decode.d6.loss_cls: 0.2860  decode.d6.loss_mask: 0.2674  decode.d6.loss_dice: 0.3568  decode.d7.loss_cls: 0.3443  decode.d7.loss_mask: 0.2602  decode.d7.loss_dice: 0.2929  decode.d8.loss_cls: 0.2737  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.3364
09/28 15:56:23 - mmengine - INFO - Iter(train) [ 12100/320000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 1 day, 13:50:01  time: 0.4694  data_time: 0.0090  memory: 5186  grad_norm: 150.7779  loss: 9.9648  decode.loss_cls: 0.2949  decode.loss_mask: 0.3627  decode.loss_dice: 0.3402  decode.d0.loss_cls: 1.0792  decode.d0.loss_mask: 0.3039  decode.d0.loss_dice: 0.3601  decode.d1.loss_cls: 0.3406  decode.d1.loss_mask: 0.3026  decode.d1.loss_dice: 0.2929  decode.d2.loss_cls: 0.2443  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.3172  decode.d3.loss_cls: 0.2694  decode.d3.loss_mask: 0.2979  decode.d3.loss_dice: 0.2998  decode.d4.loss_cls: 0.2700  decode.d4.loss_mask: 0.3129  decode.d4.loss_dice: 0.3030  decode.d5.loss_cls: 0.2008  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.2919  decode.d6.loss_cls: 0.2229  decode.d6.loss_mask: 0.3655  decode.d6.loss_dice: 0.3119  decode.d7.loss_cls: 0.2675  decode.d7.loss_mask: 0.3642  decode.d7.loss_dice: 0.3151  decode.d8.loss_cls: 0.2939  decode.d8.loss_mask: 0.3823  decode.d8.loss_dice: 0.3460
09/28 15:56:46 - mmengine - INFO - Iter(train) [ 12150/320000]  base_lr: 9.6577e-05 lr: 9.6577e-06  eta: 1 day, 13:49:54  time: 0.4317  data_time: 0.0089  memory: 5167  grad_norm: 61.2376  loss: 6.4412  decode.loss_cls: 0.0785  decode.loss_mask: 0.2542  decode.loss_dice: 0.2018  decode.d0.loss_cls: 0.9034  decode.d0.loss_mask: 0.2503  decode.d0.loss_dice: 0.2101  decode.d1.loss_cls: 0.1711  decode.d1.loss_mask: 0.2758  decode.d1.loss_dice: 0.2119  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.2551  decode.d2.loss_dice: 0.2197  decode.d3.loss_cls: 0.0977  decode.d3.loss_mask: 0.2495  decode.d3.loss_dice: 0.2193  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.2486  decode.d4.loss_dice: 0.2145  decode.d5.loss_cls: 0.1127  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0957  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.2100  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.0903  decode.d8.loss_mask: 0.2478  decode.d8.loss_dice: 0.1970
09/28 15:57:08 - mmengine - INFO - Iter(train) [ 12200/320000]  base_lr: 9.6562e-05 lr: 9.6562e-06  eta: 1 day, 13:49:18  time: 0.4307  data_time: 0.0089  memory: 5166  grad_norm: 128.7886  loss: 11.3155  decode.loss_cls: 0.3494  decode.loss_mask: 0.3413  decode.loss_dice: 0.3128  decode.d0.loss_cls: 1.3222  decode.d0.loss_mask: 0.3647  decode.d0.loss_dice: 0.3277  decode.d1.loss_cls: 0.4782  decode.d1.loss_mask: 0.3439  decode.d1.loss_dice: 0.3117  decode.d2.loss_cls: 0.4521  decode.d2.loss_mask: 0.3173  decode.d2.loss_dice: 0.2744  decode.d3.loss_cls: 0.4468  decode.d3.loss_mask: 0.3184  decode.d3.loss_dice: 0.2918  decode.d4.loss_cls: 0.4189  decode.d4.loss_mask: 0.3205  decode.d4.loss_dice: 0.2797  decode.d5.loss_cls: 0.4053  decode.d5.loss_mask: 0.3200  decode.d5.loss_dice: 0.2811  decode.d6.loss_cls: 0.4062  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.3060  decode.d7.loss_cls: 0.3521  decode.d7.loss_mask: 0.3226  decode.d7.loss_dice: 0.2868  decode.d8.loss_cls: 0.3901  decode.d8.loss_mask: 0.3323  decode.d8.loss_dice: 0.3215
09/28 15:57:29 - mmengine - INFO - Iter(train) [ 12250/320000]  base_lr: 9.6548e-05 lr: 9.6548e-06  eta: 1 day, 13:48:41  time: 0.4314  data_time: 0.0088  memory: 5149  grad_norm: 68.1807  loss: 8.7376  decode.loss_cls: 0.2292  decode.loss_mask: 0.3031  decode.loss_dice: 0.2423  decode.d0.loss_cls: 1.1731  decode.d0.loss_mask: 0.3213  decode.d0.loss_dice: 0.2662  decode.d1.loss_cls: 0.2773  decode.d1.loss_mask: 0.2974  decode.d1.loss_dice: 0.2448  decode.d2.loss_cls: 0.2189  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.2488  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 0.3056  decode.d3.loss_dice: 0.2435  decode.d4.loss_cls: 0.2339  decode.d4.loss_mask: 0.3030  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.2220  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.2448  decode.d6.loss_cls: 0.2231  decode.d6.loss_mask: 0.3017  decode.d6.loss_dice: 0.2412  decode.d7.loss_cls: 0.2043  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.2302  decode.d8.loss_mask: 0.3035  decode.d8.loss_dice: 0.2394
09/28 15:57:51 - mmengine - INFO - Iter(train) [ 12300/320000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 1 day, 13:48:05  time: 0.4327  data_time: 0.0087  memory: 5186  grad_norm: 81.8869  loss: 8.7883  decode.loss_cls: 0.2963  decode.loss_mask: 0.2977  decode.loss_dice: 0.2524  decode.d0.loss_cls: 0.9713  decode.d0.loss_mask: 0.3225  decode.d0.loss_dice: 0.2640  decode.d1.loss_cls: 0.2562  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.2333  decode.d2.loss_cls: 0.2256  decode.d2.loss_mask: 0.3034  decode.d2.loss_dice: 0.2477  decode.d3.loss_cls: 0.2296  decode.d3.loss_mask: 0.2957  decode.d3.loss_dice: 0.2454  decode.d4.loss_cls: 0.2543  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.2487  decode.d5.loss_cls: 0.2476  decode.d5.loss_mask: 0.2997  decode.d5.loss_dice: 0.2530  decode.d6.loss_cls: 0.2568  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.2516  decode.d7.loss_cls: 0.2862  decode.d7.loss_mask: 0.2973  decode.d7.loss_dice: 0.2522  decode.d8.loss_cls: 0.2578  decode.d8.loss_mask: 0.2950  decode.d8.loss_dice: 0.2557
09/28 15:58:12 - mmengine - INFO - Iter(train) [ 12350/320000]  base_lr: 9.6520e-05 lr: 9.6520e-06  eta: 1 day, 13:47:30  time: 0.4304  data_time: 0.0089  memory: 5186  grad_norm: 63.5636  loss: 8.8706  decode.loss_cls: 0.2516  decode.loss_mask: 0.3099  decode.loss_dice: 0.2678  decode.d0.loss_cls: 0.8771  decode.d0.loss_mask: 0.3106  decode.d0.loss_dice: 0.2823  decode.d1.loss_cls: 0.2730  decode.d1.loss_mask: 0.3105  decode.d1.loss_dice: 0.2572  decode.d2.loss_cls: 0.2090  decode.d2.loss_mask: 0.3060  decode.d2.loss_dice: 0.2556  decode.d3.loss_cls: 0.2356  decode.d3.loss_mask: 0.3119  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.2446  decode.d4.loss_mask: 0.3110  decode.d4.loss_dice: 0.2571  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.3156  decode.d5.loss_dice: 0.2664  decode.d6.loss_cls: 0.3121  decode.d6.loss_mask: 0.3086  decode.d6.loss_dice: 0.2575  decode.d7.loss_cls: 0.2519  decode.d7.loss_mask: 0.3110  decode.d7.loss_dice: 0.2605  decode.d8.loss_cls: 0.2347  decode.d8.loss_mask: 0.3132  decode.d8.loss_dice: 0.2662
09/28 15:58:34 - mmengine - INFO - Iter(train) [ 12400/320000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 1 day, 13:46:54  time: 0.4312  data_time: 0.0090  memory: 5167  grad_norm: 101.6442  loss: 10.0587  decode.loss_cls: 0.3810  decode.loss_mask: 0.2874  decode.loss_dice: 0.3023  decode.d0.loss_cls: 1.1502  decode.d0.loss_mask: 0.3012  decode.d0.loss_dice: 0.3186  decode.d1.loss_cls: 0.2601  decode.d1.loss_mask: 0.3107  decode.d1.loss_dice: 0.3269  decode.d2.loss_cls: 0.3241  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.3065  decode.d3.loss_cls: 0.2905  decode.d3.loss_mask: 0.2947  decode.d3.loss_dice: 0.3108  decode.d4.loss_cls: 0.3050  decode.d4.loss_mask: 0.2969  decode.d4.loss_dice: 0.3163  decode.d5.loss_cls: 0.2333  decode.d5.loss_mask: 0.2931  decode.d5.loss_dice: 0.3083  decode.d6.loss_cls: 0.2985  decode.d6.loss_mask: 0.3099  decode.d6.loss_dice: 0.3236  decode.d7.loss_cls: 0.3640  decode.d7.loss_mask: 0.2993  decode.d7.loss_dice: 0.3003  decode.d8.loss_cls: 0.3479  decode.d8.loss_mask: 0.3002  decode.d8.loss_dice: 0.2990
09/28 15:58:55 - mmengine - INFO - Iter(train) [ 12450/320000]  base_lr: 9.6492e-05 lr: 9.6492e-06  eta: 1 day, 13:46:18  time: 0.4305  data_time: 0.0089  memory: 5167  grad_norm: 89.1314  loss: 7.6417  decode.loss_cls: 0.1729  decode.loss_mask: 0.2550  decode.loss_dice: 0.2595  decode.d0.loss_cls: 0.9847  decode.d0.loss_mask: 0.2608  decode.d0.loss_dice: 0.2718  decode.d1.loss_cls: 0.2396  decode.d1.loss_mask: 0.2586  decode.d1.loss_dice: 0.2608  decode.d2.loss_cls: 0.1860  decode.d2.loss_mask: 0.2538  decode.d2.loss_dice: 0.2548  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 0.2524  decode.d3.loss_dice: 0.2548  decode.d4.loss_cls: 0.1550  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2499  decode.d5.loss_cls: 0.1424  decode.d5.loss_mask: 0.2554  decode.d5.loss_dice: 0.2617  decode.d6.loss_cls: 0.1612  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.2540  decode.d7.loss_cls: 0.1876  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.2542  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 0.2545  decode.d8.loss_dice: 0.2501
09/28 15:59:17 - mmengine - INFO - Iter(train) [ 12500/320000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 1 day, 13:45:42  time: 0.4316  data_time: 0.0089  memory: 5166  grad_norm: 110.7973  loss: 7.7333  decode.loss_cls: 0.2516  decode.loss_mask: 0.2063  decode.loss_dice: 0.2320  decode.d0.loss_cls: 1.2254  decode.d0.loss_mask: 0.2138  decode.d0.loss_dice: 0.2289  decode.d1.loss_cls: 0.4466  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.2277  decode.d2.loss_cls: 0.2057  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.1840  decode.d3.loss_mask: 0.2120  decode.d3.loss_dice: 0.2217  decode.d4.loss_cls: 0.1932  decode.d4.loss_mask: 0.2093  decode.d4.loss_dice: 0.2281  decode.d5.loss_cls: 0.1565  decode.d5.loss_mask: 0.2069  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.1915  decode.d6.loss_mask: 0.2080  decode.d6.loss_dice: 0.2356  decode.d7.loss_cls: 0.2569  decode.d7.loss_mask: 0.2073  decode.d7.loss_dice: 0.2458  decode.d8.loss_cls: 0.2074  decode.d8.loss_mask: 0.2062  decode.d8.loss_dice: 0.2316
09/28 15:59:39 - mmengine - INFO - Iter(train) [ 12550/320000]  base_lr: 9.6464e-05 lr: 9.6464e-06  eta: 1 day, 13:45:06  time: 0.4299  data_time: 0.0088  memory: 5150  grad_norm: 102.6748  loss: 8.6125  decode.loss_cls: 0.1730  decode.loss_mask: 0.3156  decode.loss_dice: 0.2891  decode.d0.loss_cls: 0.8430  decode.d0.loss_mask: 0.3198  decode.d0.loss_dice: 0.2817  decode.d1.loss_cls: 0.1819  decode.d1.loss_mask: 0.3067  decode.d1.loss_dice: 0.2914  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 0.3194  decode.d2.loss_dice: 0.2956  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.3110  decode.d3.loss_dice: 0.2885  decode.d4.loss_cls: 0.1878  decode.d4.loss_mask: 0.3197  decode.d4.loss_dice: 0.2944  decode.d5.loss_cls: 0.1780  decode.d5.loss_mask: 0.3137  decode.d5.loss_dice: 0.2858  decode.d6.loss_cls: 0.1907  decode.d6.loss_mask: 0.3163  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.2006  decode.d7.loss_mask: 0.3204  decode.d7.loss_dice: 0.2944  decode.d8.loss_cls: 0.1765  decode.d8.loss_mask: 0.3143  decode.d8.loss_dice: 0.2930
09/28 16:00:00 - mmengine - INFO - Iter(train) [ 12600/320000]  base_lr: 9.6449e-05 lr: 9.6449e-06  eta: 1 day, 13:44:31  time: 0.4316  data_time: 0.0090  memory: 5186  grad_norm: 112.9402  loss: 9.3105  decode.loss_cls: 0.2043  decode.loss_mask: 0.3170  decode.loss_dice: 0.3237  decode.d0.loss_cls: 0.9820  decode.d0.loss_mask: 0.3124  decode.d0.loss_dice: 0.3504  decode.d1.loss_cls: 0.2075  decode.d1.loss_mask: 0.3319  decode.d1.loss_dice: 0.3419  decode.d2.loss_cls: 0.2180  decode.d2.loss_mask: 0.3170  decode.d2.loss_dice: 0.3216  decode.d3.loss_cls: 0.1998  decode.d3.loss_mask: 0.3233  decode.d3.loss_dice: 0.3207  decode.d4.loss_cls: 0.1864  decode.d4.loss_mask: 0.3241  decode.d4.loss_dice: 0.3119  decode.d5.loss_cls: 0.1868  decode.d5.loss_mask: 0.3375  decode.d5.loss_dice: 0.3264  decode.d6.loss_cls: 0.2173  decode.d6.loss_mask: 0.3253  decode.d6.loss_dice: 0.3528  decode.d7.loss_cls: 0.2044  decode.d7.loss_mask: 0.3076  decode.d7.loss_dice: 0.3225  decode.d8.loss_cls: 0.2122  decode.d8.loss_mask: 0.3068  decode.d8.loss_dice: 0.3170
09/28 16:00:22 - mmengine - INFO - Iter(train) [ 12650/320000]  base_lr: 9.6435e-05 lr: 9.6435e-06  eta: 1 day, 13:43:56  time: 0.4304  data_time: 0.0090  memory: 5186  grad_norm: 275.2224  loss: 13.2575  decode.loss_cls: 0.4071  decode.loss_mask: 0.4258  decode.loss_dice: 0.3695  decode.d0.loss_cls: 1.0858  decode.d0.loss_mask: 0.4418  decode.d0.loss_dice: 0.4142  decode.d1.loss_cls: 0.5271  decode.d1.loss_mask: 0.4351  decode.d1.loss_dice: 0.3692  decode.d2.loss_cls: 0.5064  decode.d2.loss_mask: 0.4154  decode.d2.loss_dice: 0.3518  decode.d3.loss_cls: 0.3502  decode.d3.loss_mask: 0.4801  decode.d3.loss_dice: 0.3927  decode.d4.loss_cls: 0.4930  decode.d4.loss_mask: 0.4450  decode.d4.loss_dice: 0.3944  decode.d5.loss_cls: 0.4105  decode.d5.loss_mask: 0.4340  decode.d5.loss_dice: 0.3774  decode.d6.loss_cls: 0.4471  decode.d6.loss_mask: 0.4311  decode.d6.loss_dice: 0.3528  decode.d7.loss_cls: 0.4210  decode.d7.loss_mask: 0.4629  decode.d7.loss_dice: 0.3952  decode.d8.loss_cls: 0.3911  decode.d8.loss_mask: 0.4513  decode.d8.loss_dice: 0.3785
09/28 16:00:43 - mmengine - INFO - Iter(train) [ 12700/320000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 1 day, 13:43:20  time: 0.4306  data_time: 0.0087  memory: 5150  grad_norm: 159.7910  loss: 12.1278  decode.loss_cls: 0.5284  decode.loss_mask: 0.3668  decode.loss_dice: 0.2441  decode.d0.loss_cls: 1.3549  decode.d0.loss_mask: 0.3075  decode.d0.loss_dice: 0.3062  decode.d1.loss_cls: 0.6592  decode.d1.loss_mask: 0.2837  decode.d1.loss_dice: 0.2390  decode.d2.loss_cls: 0.5330  decode.d2.loss_mask: 0.2914  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.5525  decode.d3.loss_mask: 0.3124  decode.d3.loss_dice: 0.2745  decode.d4.loss_cls: 0.5071  decode.d4.loss_mask: 0.3111  decode.d4.loss_dice: 0.2815  decode.d5.loss_cls: 0.4985  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.2598  decode.d6.loss_cls: 0.5092  decode.d6.loss_mask: 0.3327  decode.d6.loss_dice: 0.2843  decode.d7.loss_cls: 0.5863  decode.d7.loss_mask: 0.3585  decode.d7.loss_dice: 0.2663  decode.d8.loss_cls: 0.4966  decode.d8.loss_mask: 0.3649  decode.d8.loss_dice: 0.2472
09/28 16:01:05 - mmengine - INFO - Iter(train) [ 12750/320000]  base_lr: 9.6407e-05 lr: 9.6407e-06  eta: 1 day, 13:42:45  time: 0.4312  data_time: 0.0090  memory: 5186  grad_norm: 178.4359  loss: 9.4733  decode.loss_cls: 0.2256  decode.loss_mask: 0.3724  decode.loss_dice: 0.2604  decode.d0.loss_cls: 1.0103  decode.d0.loss_mask: 0.3206  decode.d0.loss_dice: 0.2662  decode.d1.loss_cls: 0.2807  decode.d1.loss_mask: 0.3785  decode.d1.loss_dice: 0.2566  decode.d2.loss_cls: 0.2246  decode.d2.loss_mask: 0.3782  decode.d2.loss_dice: 0.2697  decode.d3.loss_cls: 0.2442  decode.d3.loss_mask: 0.3721  decode.d3.loss_dice: 0.2550  decode.d4.loss_cls: 0.2188  decode.d4.loss_mask: 0.3746  decode.d4.loss_dice: 0.2505  decode.d5.loss_cls: 0.2384  decode.d5.loss_mask: 0.3739  decode.d5.loss_dice: 0.2667  decode.d6.loss_cls: 0.2237  decode.d6.loss_mask: 0.3826  decode.d6.loss_dice: 0.2457  decode.d7.loss_cls: 0.2584  decode.d7.loss_mask: 0.3763  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.2409  decode.d8.loss_mask: 0.3864  decode.d8.loss_dice: 0.2658
09/28 16:01:27 - mmengine - INFO - Iter(train) [ 12800/320000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 1 day, 13:42:15  time: 0.4495  data_time: 0.0090  memory: 5150  grad_norm: 65.8619  loss: 6.0644  decode.loss_cls: 0.0674  decode.loss_mask: 0.2356  decode.loss_dice: 0.2103  decode.d0.loss_cls: 0.8314  decode.d0.loss_mask: 0.2390  decode.d0.loss_dice: 0.2313  decode.d1.loss_cls: 0.1650  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 0.2348  decode.d3.loss_dice: 0.2121  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2121  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.2382  decode.d5.loss_dice: 0.2171  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.2393  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.2101  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.2342  decode.d8.loss_dice: 0.2091
09/28 16:01:48 - mmengine - INFO - Iter(train) [ 12850/320000]  base_lr: 9.6379e-05 lr: 9.6379e-06  eta: 1 day, 13:41:40  time: 0.4311  data_time: 0.0091  memory: 5166  grad_norm: 61.7260  loss: 7.4421  decode.loss_cls: 0.1630  decode.loss_mask: 0.2739  decode.loss_dice: 0.2279  decode.d0.loss_cls: 0.8659  decode.d0.loss_mask: 0.2749  decode.d0.loss_dice: 0.2451  decode.d1.loss_cls: 0.3147  decode.d1.loss_mask: 0.2670  decode.d1.loss_dice: 0.2235  decode.d2.loss_cls: 0.2041  decode.d2.loss_mask: 0.2711  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.2059  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.2137  decode.d4.loss_cls: 0.1779  decode.d4.loss_mask: 0.2638  decode.d4.loss_dice: 0.2143  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.2215  decode.d6.loss_cls: 0.1304  decode.d6.loss_mask: 0.2820  decode.d6.loss_dice: 0.2258  decode.d7.loss_cls: 0.1511  decode.d7.loss_mask: 0.2808  decode.d7.loss_dice: 0.2160  decode.d8.loss_cls: 0.1330  decode.d8.loss_mask: 0.2824  decode.d8.loss_dice: 0.2249
09/28 16:02:10 - mmengine - INFO - Iter(train) [ 12900/320000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 1 day, 13:41:06  time: 0.4307  data_time: 0.0090  memory: 5166  grad_norm: 137.8850  loss: 10.1368  decode.loss_cls: 0.3036  decode.loss_mask: 0.3689  decode.loss_dice: 0.3052  decode.d0.loss_cls: 1.1136  decode.d0.loss_mask: 0.3480  decode.d0.loss_dice: 0.3557  decode.d1.loss_cls: 0.3402  decode.d1.loss_mask: 0.3218  decode.d1.loss_dice: 0.2912  decode.d2.loss_cls: 0.3429  decode.d2.loss_mask: 0.3317  decode.d2.loss_dice: 0.3036  decode.d3.loss_cls: 0.2475  decode.d3.loss_mask: 0.3311  decode.d3.loss_dice: 0.3381  decode.d4.loss_cls: 0.2566  decode.d4.loss_mask: 0.3230  decode.d4.loss_dice: 0.2980  decode.d5.loss_cls: 0.2200  decode.d5.loss_mask: 0.3390  decode.d5.loss_dice: 0.3033  decode.d6.loss_cls: 0.2341  decode.d6.loss_mask: 0.3306  decode.d6.loss_dice: 0.2947  decode.d7.loss_cls: 0.2799  decode.d7.loss_mask: 0.3460  decode.d7.loss_dice: 0.2915  decode.d8.loss_cls: 0.2540  decode.d8.loss_mask: 0.3771  decode.d8.loss_dice: 0.3461
09/28 16:02:31 - mmengine - INFO - Iter(train) [ 12950/320000]  base_lr: 9.6351e-05 lr: 9.6351e-06  eta: 1 day, 13:40:31  time: 0.4319  data_time: 0.0091  memory: 5186  grad_norm: 79.9299  loss: 10.0208  decode.loss_cls: 0.3627  decode.loss_mask: 0.2776  decode.loss_dice: 0.2714  decode.d0.loss_cls: 1.1431  decode.d0.loss_mask: 0.2879  decode.d0.loss_dice: 0.2909  decode.d1.loss_cls: 0.4991  decode.d1.loss_mask: 0.2854  decode.d1.loss_dice: 0.2679  decode.d2.loss_cls: 0.3037  decode.d2.loss_mask: 0.2881  decode.d2.loss_dice: 0.2613  decode.d3.loss_cls: 0.3104  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.2663  decode.d4.loss_cls: 0.3753  decode.d4.loss_mask: 0.2777  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.3800  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.2560  decode.d6.loss_cls: 0.3546  decode.d6.loss_mask: 0.2795  decode.d6.loss_dice: 0.2512  decode.d7.loss_cls: 0.4104  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.2519  decode.d8.loss_cls: 0.4222  decode.d8.loss_mask: 0.2761  decode.d8.loss_dice: 0.2539
09/28 16:02:53 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:02:53 - mmengine - INFO - Iter(train) [ 13000/320000]  base_lr: 9.6336e-05 lr: 9.6336e-06  eta: 1 day, 13:39:56  time: 0.4312  data_time: 0.0089  memory: 5186  grad_norm: 46.5477  loss: 6.3983  decode.loss_cls: 0.1088  decode.loss_mask: 0.2644  decode.loss_dice: 0.1933  decode.d0.loss_cls: 0.7883  decode.d0.loss_mask: 0.2763  decode.d0.loss_dice: 0.2300  decode.d1.loss_cls: 0.1004  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.2114  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.2638  decode.d2.loss_dice: 0.2059  decode.d3.loss_cls: 0.0721  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.2113  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.2653  decode.d4.loss_dice: 0.2209  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.2685  decode.d5.loss_dice: 0.1957  decode.d6.loss_cls: 0.1263  decode.d6.loss_mask: 0.2749  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.2678  decode.d7.loss_dice: 0.1908  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.2666  decode.d8.loss_dice: 0.1978
09/28 16:03:15 - mmengine - INFO - Iter(train) [ 13050/320000]  base_lr: 9.6322e-05 lr: 9.6322e-06  eta: 1 day, 13:39:41  time: 0.4670  data_time: 0.0089  memory: 5186  grad_norm: 210.5141  loss: 12.2715  decode.loss_cls: 0.4117  decode.loss_mask: 0.3107  decode.loss_dice: 0.3262  decode.d0.loss_cls: 1.1723  decode.d0.loss_mask: 0.3655  decode.d0.loss_dice: 0.3419  decode.d1.loss_cls: 0.5250  decode.d1.loss_mask: 0.4070  decode.d1.loss_dice: 0.3719  decode.d2.loss_cls: 0.4289  decode.d2.loss_mask: 0.3557  decode.d2.loss_dice: 0.3278  decode.d3.loss_cls: 0.4088  decode.d3.loss_mask: 0.4105  decode.d3.loss_dice: 0.3284  decode.d4.loss_cls: 0.4681  decode.d4.loss_mask: 0.4396  decode.d4.loss_dice: 0.3191  decode.d5.loss_cls: 0.4696  decode.d5.loss_mask: 0.3699  decode.d5.loss_dice: 0.3325  decode.d6.loss_cls: 0.4721  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.3516  decode.d7.loss_cls: 0.4312  decode.d7.loss_mask: 0.3622  decode.d7.loss_dice: 0.3331  decode.d8.loss_cls: 0.4329  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.3427
09/28 16:03:39 - mmengine - INFO - Iter(train) [ 13100/320000]  base_lr: 9.6308e-05 lr: 9.6308e-06  eta: 1 day, 13:39:51  time: 0.4700  data_time: 0.0088  memory: 5150  grad_norm: 38.8628  loss: 7.0344  decode.loss_cls: 0.1339  decode.loss_mask: 0.2437  decode.loss_dice: 0.2035  decode.d0.loss_cls: 1.0444  decode.d0.loss_mask: 0.2464  decode.d0.loss_dice: 0.2208  decode.d1.loss_cls: 0.2327  decode.d1.loss_mask: 0.2445  decode.d1.loss_dice: 0.2142  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 0.2479  decode.d2.loss_dice: 0.2120  decode.d3.loss_cls: 0.1160  decode.d3.loss_mask: 0.2460  decode.d3.loss_dice: 0.2214  decode.d4.loss_cls: 0.1765  decode.d4.loss_mask: 0.2445  decode.d4.loss_dice: 0.2184  decode.d5.loss_cls: 0.1435  decode.d5.loss_mask: 0.2455  decode.d5.loss_dice: 0.2167  decode.d6.loss_cls: 0.1663  decode.d6.loss_mask: 0.2424  decode.d6.loss_dice: 0.2192  decode.d7.loss_cls: 0.1132  decode.d7.loss_mask: 0.2471  decode.d7.loss_dice: 0.2090  decode.d8.loss_cls: 0.1379  decode.d8.loss_mask: 0.2461  decode.d8.loss_dice: 0.2115
09/28 16:04:02 - mmengine - INFO - Iter(train) [ 13150/320000]  base_lr: 9.6294e-05 lr: 9.6294e-06  eta: 1 day, 13:40:02  time: 0.4701  data_time: 0.0088  memory: 5167  grad_norm: 122.1200  loss: 8.4616  decode.loss_cls: 0.2888  decode.loss_mask: 0.2959  decode.loss_dice: 0.2401  decode.d0.loss_cls: 0.8849  decode.d0.loss_mask: 0.3059  decode.d0.loss_dice: 0.2824  decode.d1.loss_cls: 0.2848  decode.d1.loss_mask: 0.2985  decode.d1.loss_dice: 0.2421  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.1747  decode.d3.loss_mask: 0.2971  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.2510  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.2186  decode.d5.loss_cls: 0.2981  decode.d5.loss_mask: 0.2810  decode.d5.loss_dice: 0.2301  decode.d6.loss_cls: 0.2361  decode.d6.loss_mask: 0.2882  decode.d6.loss_dice: 0.2179  decode.d7.loss_cls: 0.2523  decode.d7.loss_mask: 0.3004  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.2566  decode.d8.loss_mask: 0.2886  decode.d8.loss_dice: 0.2177
09/28 16:04:26 - mmengine - INFO - Iter(train) [ 13200/320000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 1 day, 13:40:11  time: 0.4704  data_time: 0.0094  memory: 5150  grad_norm: 95.3231  loss: 9.2436  decode.loss_cls: 0.2429  decode.loss_mask: 0.3504  decode.loss_dice: 0.2446  decode.d0.loss_cls: 1.0683  decode.d0.loss_mask: 0.3512  decode.d0.loss_dice: 0.2564  decode.d1.loss_cls: 0.2359  decode.d1.loss_mask: 0.3431  decode.d1.loss_dice: 0.2512  decode.d2.loss_cls: 0.2281  decode.d2.loss_mask: 0.3460  decode.d2.loss_dice: 0.2399  decode.d3.loss_cls: 0.2646  decode.d3.loss_mask: 0.3576  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.2107  decode.d4.loss_mask: 0.3587  decode.d4.loss_dice: 0.2467  decode.d5.loss_cls: 0.1996  decode.d5.loss_mask: 0.3409  decode.d5.loss_dice: 0.2284  decode.d6.loss_cls: 0.3013  decode.d6.loss_mask: 0.3484  decode.d6.loss_dice: 0.2319  decode.d7.loss_cls: 0.2918  decode.d7.loss_mask: 0.3498  decode.d7.loss_dice: 0.2279  decode.d8.loss_cls: 0.3007  decode.d8.loss_mask: 0.3467  decode.d8.loss_dice: 0.2388
09/28 16:04:49 - mmengine - INFO - Iter(train) [ 13250/320000]  base_lr: 9.6266e-05 lr: 9.6266e-06  eta: 1 day, 13:40:21  time: 0.4682  data_time: 0.0089  memory: 5166  grad_norm: 58.8893  loss: 7.7934  decode.loss_cls: 0.1504  decode.loss_mask: 0.2931  decode.loss_dice: 0.2309  decode.d0.loss_cls: 0.9945  decode.d0.loss_mask: 0.2882  decode.d0.loss_dice: 0.2395  decode.d1.loss_cls: 0.2653  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.2220  decode.d2.loss_cls: 0.1857  decode.d2.loss_mask: 0.3021  decode.d2.loss_dice: 0.2396  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 0.2979  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.1425  decode.d4.loss_mask: 0.2985  decode.d4.loss_dice: 0.2311  decode.d5.loss_cls: 0.1419  decode.d5.loss_mask: 0.2980  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 0.3050  decode.d6.loss_dice: 0.2382  decode.d7.loss_cls: 0.1476  decode.d7.loss_mask: 0.2964  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.1699  decode.d8.loss_mask: 0.2943  decode.d8.loss_dice: 0.2320
09/28 16:05:13 - mmengine - INFO - Iter(train) [ 13300/320000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 1 day, 13:40:30  time: 0.4705  data_time: 0.0090  memory: 5167  grad_norm: 95.6756  loss: 10.3327  decode.loss_cls: 0.3356  decode.loss_mask: 0.3614  decode.loss_dice: 0.2459  decode.d0.loss_cls: 1.2124  decode.d0.loss_mask: 0.2896  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.4536  decode.d1.loss_mask: 0.2887  decode.d1.loss_dice: 0.2625  decode.d2.loss_cls: 0.3873  decode.d2.loss_mask: 0.3281  decode.d2.loss_dice: 0.2712  decode.d3.loss_cls: 0.4106  decode.d3.loss_mask: 0.3812  decode.d3.loss_dice: 0.2698  decode.d4.loss_cls: 0.3121  decode.d4.loss_mask: 0.3232  decode.d4.loss_dice: 0.2612  decode.d5.loss_cls: 0.3518  decode.d5.loss_mask: 0.3250  decode.d5.loss_dice: 0.2826  decode.d6.loss_cls: 0.3374  decode.d6.loss_mask: 0.3397  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.3355  decode.d7.loss_mask: 0.3271  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.3055  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.2692
09/28 16:05:36 - mmengine - INFO - Iter(train) [ 13350/320000]  base_lr: 9.6238e-05 lr: 9.6238e-06  eta: 1 day, 13:40:40  time: 0.4707  data_time: 0.0093  memory: 5150  grad_norm: 107.0965  loss: 11.2035  decode.loss_cls: 0.3553  decode.loss_mask: 0.3728  decode.loss_dice: 0.2978  decode.d0.loss_cls: 1.1080  decode.d0.loss_mask: 0.3730  decode.d0.loss_dice: 0.2944  decode.d1.loss_cls: 0.3912  decode.d1.loss_mask: 0.4301  decode.d1.loss_dice: 0.2918  decode.d2.loss_cls: 0.3009  decode.d2.loss_mask: 0.4192  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.4024  decode.d3.loss_mask: 0.4124  decode.d3.loss_dice: 0.2589  decode.d4.loss_cls: 0.3957  decode.d4.loss_mask: 0.4017  decode.d4.loss_dice: 0.2718  decode.d5.loss_cls: 0.4014  decode.d5.loss_mask: 0.3579  decode.d5.loss_dice: 0.2783  decode.d6.loss_cls: 0.3345  decode.d6.loss_mask: 0.4649  decode.d6.loss_dice: 0.2719  decode.d7.loss_cls: 0.2906  decode.d7.loss_mask: 0.4746  decode.d7.loss_dice: 0.2700  decode.d8.loss_cls: 0.3347  decode.d8.loss_mask: 0.3849  decode.d8.loss_dice: 0.3017
09/28 16:06:00 - mmengine - INFO - Iter(train) [ 13400/320000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 1 day, 13:40:49  time: 0.4698  data_time: 0.0088  memory: 5186  grad_norm: 150.7424  loss: 11.9073  decode.loss_cls: 0.3725  decode.loss_mask: 0.4273  decode.loss_dice: 0.3786  decode.d0.loss_cls: 1.5570  decode.d0.loss_mask: 0.3349  decode.d0.loss_dice: 0.3555  decode.d1.loss_cls: 0.5333  decode.d1.loss_mask: 0.3299  decode.d1.loss_dice: 0.3418  decode.d2.loss_cls: 0.4732  decode.d2.loss_mask: 0.3163  decode.d2.loss_dice: 0.3220  decode.d3.loss_cls: 0.4163  decode.d3.loss_mask: 0.3418  decode.d3.loss_dice: 0.3350  decode.d4.loss_cls: 0.3779  decode.d4.loss_mask: 0.3266  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.3082  decode.d5.loss_mask: 0.3551  decode.d5.loss_dice: 0.3577  decode.d6.loss_cls: 0.3783  decode.d6.loss_mask: 0.3127  decode.d6.loss_dice: 0.3275  decode.d7.loss_cls: 0.3010  decode.d7.loss_mask: 0.3169  decode.d7.loss_dice: 0.3443  decode.d8.loss_cls: 0.3200  decode.d8.loss_mask: 0.3581  decode.d8.loss_dice: 0.3749
09/28 16:06:23 - mmengine - INFO - Iter(train) [ 13450/320000]  base_lr: 9.6209e-05 lr: 9.6209e-06  eta: 1 day, 13:40:58  time: 0.4699  data_time: 0.0094  memory: 5167  grad_norm: 90.2953  loss: 7.7216  decode.loss_cls: 0.1136  decode.loss_mask: 0.2828  decode.loss_dice: 0.2703  decode.d0.loss_cls: 0.8719  decode.d0.loss_mask: 0.3086  decode.d0.loss_dice: 0.2873  decode.d1.loss_cls: 0.1885  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.2682  decode.d2.loss_cls: 0.1441  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.2859  decode.d3.loss_cls: 0.1083  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.2699  decode.d4.loss_cls: 0.1136  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.2753  decode.d5.loss_cls: 0.1598  decode.d5.loss_mask: 0.2846  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.2753  decode.d7.loss_cls: 0.1770  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.2540  decode.d8.loss_cls: 0.1797  decode.d8.loss_mask: 0.2843  decode.d8.loss_dice: 0.2511
09/28 16:06:46 - mmengine - INFO - Iter(train) [ 13500/320000]  base_lr: 9.6195e-05 lr: 9.6195e-06  eta: 1 day, 13:41:06  time: 0.4677  data_time: 0.0090  memory: 5186  grad_norm: 97.1477  loss: 8.7555  decode.loss_cls: 0.2048  decode.loss_mask: 0.3113  decode.loss_dice: 0.2671  decode.d0.loss_cls: 1.0515  decode.d0.loss_mask: 0.3044  decode.d0.loss_dice: 0.2998  decode.d1.loss_cls: 0.3006  decode.d1.loss_mask: 0.3023  decode.d1.loss_dice: 0.2739  decode.d2.loss_cls: 0.2134  decode.d2.loss_mask: 0.2916  decode.d2.loss_dice: 0.2630  decode.d3.loss_cls: 0.1799  decode.d3.loss_mask: 0.3005  decode.d3.loss_dice: 0.2636  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 0.3205  decode.d4.loss_dice: 0.2664  decode.d5.loss_cls: 0.2169  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.2174  decode.d6.loss_mask: 0.2995  decode.d6.loss_dice: 0.2546  decode.d7.loss_cls: 0.2078  decode.d7.loss_mask: 0.3032  decode.d7.loss_dice: 0.2694  decode.d8.loss_cls: 0.2245  decode.d8.loss_mask: 0.3145  decode.d8.loss_dice: 0.2657
09/28 16:07:10 - mmengine - INFO - Iter(train) [ 13550/320000]  base_lr: 9.6181e-05 lr: 9.6181e-06  eta: 1 day, 13:41:14  time: 0.4695  data_time: 0.0091  memory: 5166  grad_norm: 40.3257  loss: 6.4169  decode.loss_cls: 0.1001  decode.loss_mask: 0.2592  decode.loss_dice: 0.1766  decode.d0.loss_cls: 1.1291  decode.d0.loss_mask: 0.2805  decode.d0.loss_dice: 0.1862  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.1848  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.1816  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.2699  decode.d3.loss_dice: 0.1793  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.2631  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.2661  decode.d5.loss_dice: 0.1768  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.2678  decode.d6.loss_dice: 0.1787  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.2673  decode.d7.loss_dice: 0.1800  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.1817
09/28 16:07:33 - mmengine - INFO - Iter(train) [ 13600/320000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 1 day, 13:41:21  time: 0.4687  data_time: 0.0090  memory: 5166  grad_norm: 76.3231  loss: 9.0742  decode.loss_cls: 0.1785  decode.loss_mask: 0.3186  decode.loss_dice: 0.2981  decode.d0.loss_cls: 1.0842  decode.d0.loss_mask: 0.2918  decode.d0.loss_dice: 0.2894  decode.d1.loss_cls: 0.3525  decode.d1.loss_mask: 0.2860  decode.d1.loss_dice: 0.2691  decode.d2.loss_cls: 0.2683  decode.d2.loss_mask: 0.2875  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.2886  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.2600  decode.d4.loss_cls: 0.2120  decode.d4.loss_mask: 0.2851  decode.d4.loss_dice: 0.2683  decode.d5.loss_cls: 0.2501  decode.d5.loss_mask: 0.3514  decode.d5.loss_dice: 0.3137  decode.d6.loss_cls: 0.2041  decode.d6.loss_mask: 0.3107  decode.d6.loss_dice: 0.2884  decode.d7.loss_cls: 0.1857  decode.d7.loss_mask: 0.3212  decode.d7.loss_dice: 0.2999  decode.d8.loss_cls: 0.1903  decode.d8.loss_mask: 0.3017  decode.d8.loss_dice: 0.2757
09/28 16:07:57 - mmengine - INFO - Iter(train) [ 13650/320000]  base_lr: 9.6153e-05 lr: 9.6153e-06  eta: 1 day, 13:41:29  time: 0.4688  data_time: 0.0087  memory: 5167  grad_norm: 75.4771  loss: 8.2049  decode.loss_cls: 0.2235  decode.loss_mask: 0.2984  decode.loss_dice: 0.2710  decode.d0.loss_cls: 1.0205  decode.d0.loss_mask: 0.3103  decode.d0.loss_dice: 0.2607  decode.d1.loss_cls: 0.1852  decode.d1.loss_mask: 0.2894  decode.d1.loss_dice: 0.2348  decode.d2.loss_cls: 0.1739  decode.d2.loss_mask: 0.2929  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.1200  decode.d3.loss_mask: 0.2985  decode.d3.loss_dice: 0.2479  decode.d4.loss_cls: 0.1344  decode.d4.loss_mask: 0.3005  decode.d4.loss_dice: 0.2437  decode.d5.loss_cls: 0.1740  decode.d5.loss_mask: 0.3021  decode.d5.loss_dice: 0.2582  decode.d6.loss_cls: 0.1831  decode.d6.loss_mask: 0.2963  decode.d6.loss_dice: 0.2490  decode.d7.loss_cls: 0.1809  decode.d7.loss_mask: 0.3026  decode.d7.loss_dice: 0.2822  decode.d8.loss_cls: 0.2500  decode.d8.loss_mask: 0.3040  decode.d8.loss_dice: 0.2766
09/28 16:08:20 - mmengine - INFO - Iter(train) [ 13700/320000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 1 day, 13:41:37  time: 0.4693  data_time: 0.0089  memory: 5150  grad_norm: 85.3044  loss: 8.2133  decode.loss_cls: 0.1784  decode.loss_mask: 0.2780  decode.loss_dice: 0.2763  decode.d0.loss_cls: 0.9207  decode.d0.loss_mask: 0.2954  decode.d0.loss_dice: 0.3055  decode.d1.loss_cls: 0.2535  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.2767  decode.d2.loss_cls: 0.1906  decode.d2.loss_mask: 0.2816  decode.d2.loss_dice: 0.2576  decode.d3.loss_cls: 0.1882  decode.d3.loss_mask: 0.2791  decode.d3.loss_dice: 0.2605  decode.d4.loss_cls: 0.2060  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.1884  decode.d5.loss_mask: 0.2816  decode.d5.loss_dice: 0.2654  decode.d6.loss_cls: 0.1793  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.2667  decode.d7.loss_cls: 0.2011  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.2618  decode.d8.loss_cls: 0.1805  decode.d8.loss_mask: 0.2798  decode.d8.loss_dice: 0.2557
09/28 16:08:42 - mmengine - INFO - Iter(train) [ 13750/320000]  base_lr: 9.6125e-05 lr: 9.6125e-06  eta: 1 day, 13:41:11  time: 0.4312  data_time: 0.0089  memory: 5199  grad_norm: 117.2615  loss: 9.3302  decode.loss_cls: 0.2275  decode.loss_mask: 0.3540  decode.loss_dice: 0.2799  decode.d0.loss_cls: 1.0100  decode.d0.loss_mask: 0.3333  decode.d0.loss_dice: 0.2958  decode.d1.loss_cls: 0.2564  decode.d1.loss_mask: 0.3165  decode.d1.loss_dice: 0.2782  decode.d2.loss_cls: 0.2641  decode.d2.loss_mask: 0.3117  decode.d2.loss_dice: 0.2755  decode.d3.loss_cls: 0.2305  decode.d3.loss_mask: 0.3160  decode.d3.loss_dice: 0.2748  decode.d4.loss_cls: 0.2409  decode.d4.loss_mask: 0.3182  decode.d4.loss_dice: 0.2895  decode.d5.loss_cls: 0.2259  decode.d5.loss_mask: 0.3269  decode.d5.loss_dice: 0.2907  decode.d6.loss_cls: 0.2564  decode.d6.loss_mask: 0.3320  decode.d6.loss_dice: 0.2903  decode.d7.loss_cls: 0.2494  decode.d7.loss_mask: 0.3205  decode.d7.loss_dice: 0.2930  decode.d8.loss_cls: 0.2444  decode.d8.loss_mask: 0.3433  decode.d8.loss_dice: 0.2846
09/28 16:09:04 - mmengine - INFO - Iter(train) [ 13800/320000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 1 day, 13:40:35  time: 0.4305  data_time: 0.0088  memory: 5167  grad_norm: 117.6842  loss: 8.1500  decode.loss_cls: 0.1261  decode.loss_mask: 0.3231  decode.loss_dice: 0.2281  decode.d0.loss_cls: 1.3067  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.2101  decode.d1.loss_cls: 0.2775  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.2449  decode.d2.loss_cls: 0.1882  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.2216  decode.d3.loss_cls: 0.1840  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.2034  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 0.2866  decode.d4.loss_dice: 0.2475  decode.d5.loss_cls: 0.1618  decode.d5.loss_mask: 0.3211  decode.d5.loss_dice: 0.2412  decode.d6.loss_cls: 0.1202  decode.d6.loss_mask: 0.3326  decode.d6.loss_dice: 0.2359  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 0.3269  decode.d7.loss_dice: 0.2273  decode.d8.loss_cls: 0.1423  decode.d8.loss_mask: 0.3283  decode.d8.loss_dice: 0.2302
09/28 16:09:25 - mmengine - INFO - Iter(train) [ 13850/320000]  base_lr: 9.6096e-05 lr: 9.6096e-06  eta: 1 day, 13:39:58  time: 0.4305  data_time: 0.0087  memory: 5166  grad_norm: 109.5376  loss: 8.4246  decode.loss_cls: 0.2284  decode.loss_mask: 0.2794  decode.loss_dice: 0.2285  decode.d0.loss_cls: 1.1562  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.2386  decode.d1.loss_cls: 0.2825  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2306  decode.d2.loss_cls: 0.2127  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.2419  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 0.2871  decode.d3.loss_dice: 0.2420  decode.d4.loss_cls: 0.2197  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.2391  decode.d5.loss_cls: 0.2123  decode.d5.loss_mask: 0.2817  decode.d5.loss_dice: 0.2381  decode.d6.loss_cls: 0.2381  decode.d6.loss_mask: 0.2822  decode.d6.loss_dice: 0.2313  decode.d7.loss_cls: 0.2309  decode.d7.loss_mask: 0.2894  decode.d7.loss_dice: 0.2401  decode.d8.loss_cls: 0.2556  decode.d8.loss_mask: 0.2787  decode.d8.loss_dice: 0.2345
09/28 16:09:47 - mmengine - INFO - Iter(train) [ 13900/320000]  base_lr: 9.6082e-05 lr: 9.6082e-06  eta: 1 day, 13:39:23  time: 0.4307  data_time: 0.0089  memory: 5150  grad_norm: 101.5354  loss: 10.4715  decode.loss_cls: 0.2946  decode.loss_mask: 0.4134  decode.loss_dice: 0.2786  decode.d0.loss_cls: 1.1089  decode.d0.loss_mask: 0.3081  decode.d0.loss_dice: 0.3068  decode.d1.loss_cls: 0.3789  decode.d1.loss_mask: 0.3133  decode.d1.loss_dice: 0.2760  decode.d2.loss_cls: 0.4466  decode.d2.loss_mask: 0.3201  decode.d2.loss_dice: 0.2472  decode.d3.loss_cls: 0.4225  decode.d3.loss_mask: 0.2878  decode.d3.loss_dice: 0.2588  decode.d4.loss_cls: 0.3097  decode.d4.loss_mask: 0.3966  decode.d4.loss_dice: 0.2842  decode.d5.loss_cls: 0.2895  decode.d5.loss_mask: 0.3818  decode.d5.loss_dice: 0.2809  decode.d6.loss_cls: 0.2696  decode.d6.loss_mask: 0.3407  decode.d6.loss_dice: 0.2811  decode.d7.loss_cls: 0.3195  decode.d7.loss_mask: 0.4089  decode.d7.loss_dice: 0.2671  decode.d8.loss_cls: 0.2979  decode.d8.loss_mask: 0.3973  decode.d8.loss_dice: 0.2851
09/28 16:10:08 - mmengine - INFO - Iter(train) [ 13950/320000]  base_lr: 9.6068e-05 lr: 9.6068e-06  eta: 1 day, 13:38:47  time: 0.4302  data_time: 0.0087  memory: 5166  grad_norm: 52.6961  loss: 6.5260  decode.loss_cls: 0.0614  decode.loss_mask: 0.2539  decode.loss_dice: 0.2252  decode.d0.loss_cls: 0.9792  decode.d0.loss_mask: 0.2588  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.2147  decode.d2.loss_cls: 0.1239  decode.d2.loss_mask: 0.2504  decode.d2.loss_dice: 0.2204  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.2144  decode.d4.loss_cls: 0.1158  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2194  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 0.2515  decode.d5.loss_dice: 0.2086  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2538  decode.d6.loss_dice: 0.2079  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.2567  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.1160  decode.d8.loss_mask: 0.2534  decode.d8.loss_dice: 0.2166
09/28 16:10:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:10:30 - mmengine - INFO - Iter(train) [ 14000/320000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 1 day, 13:38:12  time: 0.4323  data_time: 0.0091  memory: 5167  grad_norm: 125.3909  loss: 11.9414  decode.loss_cls: 0.4001  decode.loss_mask: 0.3961  decode.loss_dice: 0.3178  decode.d0.loss_cls: 1.1494  decode.d0.loss_mask: 0.3752  decode.d0.loss_dice: 0.3124  decode.d1.loss_cls: 0.4185  decode.d1.loss_mask: 0.4225  decode.d1.loss_dice: 0.3333  decode.d2.loss_cls: 0.4402  decode.d2.loss_mask: 0.4019  decode.d2.loss_dice: 0.3032  decode.d3.loss_cls: 0.3854  decode.d3.loss_mask: 0.4002  decode.d3.loss_dice: 0.3237  decode.d4.loss_cls: 0.3808  decode.d4.loss_mask: 0.3947  decode.d4.loss_dice: 0.3259  decode.d5.loss_cls: 0.3590  decode.d5.loss_mask: 0.3968  decode.d5.loss_dice: 0.3260  decode.d6.loss_cls: 0.4696  decode.d6.loss_mask: 0.3813  decode.d6.loss_dice: 0.2982  decode.d7.loss_cls: 0.4216  decode.d7.loss_mask: 0.3842  decode.d7.loss_dice: 0.3033  decode.d8.loss_cls: 0.4079  decode.d8.loss_mask: 0.3977  decode.d8.loss_dice: 0.3145
09/28 16:10:51 - mmengine - INFO - Iter(train) [ 14050/320000]  base_lr: 9.6040e-05 lr: 9.6040e-06  eta: 1 day, 13:37:36  time: 0.4303  data_time: 0.0090  memory: 5186  grad_norm: 134.0371  loss: 8.0098  decode.loss_cls: 0.2151  decode.loss_mask: 0.3011  decode.loss_dice: 0.2421  decode.d0.loss_cls: 0.9525  decode.d0.loss_mask: 0.3315  decode.d0.loss_dice: 0.2519  decode.d1.loss_cls: 0.1744  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.2414  decode.d2.loss_cls: 0.1308  decode.d2.loss_mask: 0.3046  decode.d2.loss_dice: 0.2475  decode.d3.loss_cls: 0.1333  decode.d3.loss_mask: 0.3073  decode.d3.loss_dice: 0.2359  decode.d4.loss_cls: 0.1382  decode.d4.loss_mask: 0.3091  decode.d4.loss_dice: 0.2826  decode.d5.loss_cls: 0.1187  decode.d5.loss_mask: 0.3070  decode.d5.loss_dice: 0.2423  decode.d6.loss_cls: 0.1591  decode.d6.loss_mask: 0.3138  decode.d6.loss_dice: 0.2408  decode.d7.loss_cls: 0.1930  decode.d7.loss_mask: 0.3164  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.2162  decode.d8.loss_mask: 0.3085  decode.d8.loss_dice: 0.2483
09/28 16:11:13 - mmengine - INFO - Iter(train) [ 14100/320000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 1 day, 13:37:02  time: 0.4308  data_time: 0.0088  memory: 5186  grad_norm: 87.5156  loss: 7.6480  decode.loss_cls: 0.2288  decode.loss_mask: 0.2648  decode.loss_dice: 0.2086  decode.d0.loss_cls: 1.0334  decode.d0.loss_mask: 0.2567  decode.d0.loss_dice: 0.2043  decode.d1.loss_cls: 0.3387  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.1995  decode.d2.loss_cls: 0.2033  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2025  decode.d3.loss_cls: 0.1673  decode.d3.loss_mask: 0.2810  decode.d3.loss_dice: 0.2084  decode.d4.loss_cls: 0.1471  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.1576  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.2183  decode.d6.loss_cls: 0.1758  decode.d6.loss_mask: 0.2864  decode.d6.loss_dice: 0.2036  decode.d7.loss_cls: 0.1601  decode.d7.loss_mask: 0.3090  decode.d7.loss_dice: 0.2221  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 0.2736  decode.d8.loss_dice: 0.2267
09/28 16:11:35 - mmengine - INFO - Iter(train) [ 14150/320000]  base_lr: 9.6012e-05 lr: 9.6012e-06  eta: 1 day, 13:36:27  time: 0.4301  data_time: 0.0088  memory: 5166  grad_norm: 162.1270  loss: 9.3232  decode.loss_cls: 0.2564  decode.loss_mask: 0.4103  decode.loss_dice: 0.2751  decode.d0.loss_cls: 0.8937  decode.d0.loss_mask: 0.3387  decode.d0.loss_dice: 0.2501  decode.d1.loss_cls: 0.2386  decode.d1.loss_mask: 0.3260  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.2136  decode.d3.loss_mask: 0.3312  decode.d3.loss_dice: 0.2389  decode.d4.loss_cls: 0.2284  decode.d4.loss_mask: 0.3613  decode.d4.loss_dice: 0.2743  decode.d5.loss_cls: 0.2843  decode.d5.loss_mask: 0.3963  decode.d5.loss_dice: 0.2777  decode.d6.loss_cls: 0.2577  decode.d6.loss_mask: 0.3911  decode.d6.loss_dice: 0.2861  decode.d7.loss_cls: 0.2640  decode.d7.loss_mask: 0.3382  decode.d7.loss_dice: 0.2684  decode.d8.loss_cls: 0.2909  decode.d8.loss_mask: 0.3459  decode.d8.loss_dice: 0.2606
09/28 16:11:56 - mmengine - INFO - Iter(train) [ 14200/320000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 1 day, 13:35:52  time: 0.4307  data_time: 0.0087  memory: 5150  grad_norm: 71.3851  loss: 7.1269  decode.loss_cls: 0.2203  decode.loss_mask: 0.1955  decode.loss_dice: 0.2409  decode.d0.loss_cls: 0.9808  decode.d0.loss_mask: 0.1987  decode.d0.loss_dice: 0.2223  decode.d1.loss_cls: 0.2144  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.1868  decode.d2.loss_mask: 0.1955  decode.d2.loss_dice: 0.2301  decode.d3.loss_cls: 0.2392  decode.d3.loss_mask: 0.1945  decode.d3.loss_dice: 0.2107  decode.d4.loss_cls: 0.2441  decode.d4.loss_mask: 0.1957  decode.d4.loss_dice: 0.2111  decode.d5.loss_cls: 0.2751  decode.d5.loss_mask: 0.1937  decode.d5.loss_dice: 0.2267  decode.d6.loss_cls: 0.1867  decode.d6.loss_mask: 0.1952  decode.d6.loss_dice: 0.2217  decode.d7.loss_cls: 0.1898  decode.d7.loss_mask: 0.1944  decode.d7.loss_dice: 0.2347  decode.d8.loss_cls: 0.2062  decode.d8.loss_mask: 0.1959  decode.d8.loss_dice: 0.2140
09/28 16:12:18 - mmengine - INFO - Iter(train) [ 14250/320000]  base_lr: 9.5983e-05 lr: 9.5983e-06  eta: 1 day, 13:35:17  time: 0.4310  data_time: 0.0091  memory: 5150  grad_norm: 110.9227  loss: 9.7182  decode.loss_cls: 0.4155  decode.loss_mask: 0.2779  decode.loss_dice: 0.2533  decode.d0.loss_cls: 1.0324  decode.d0.loss_mask: 0.2903  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.3870  decode.d1.loss_mask: 0.2812  decode.d1.loss_dice: 0.2371  decode.d2.loss_cls: 0.4291  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.2304  decode.d3.loss_cls: 0.3292  decode.d3.loss_mask: 0.2781  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.2924  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.2444  decode.d5.loss_cls: 0.3150  decode.d5.loss_mask: 0.2771  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.3995  decode.d6.loss_mask: 0.2802  decode.d6.loss_dice: 0.2369  decode.d7.loss_cls: 0.4402  decode.d7.loss_mask: 0.2819  decode.d7.loss_dice: 0.2537  decode.d8.loss_cls: 0.3956  decode.d8.loss_mask: 0.2791  decode.d8.loss_dice: 0.2302
09/28 16:12:39 - mmengine - INFO - Iter(train) [ 14300/320000]  base_lr: 9.5969e-05 lr: 9.5969e-06  eta: 1 day, 13:34:42  time: 0.4310  data_time: 0.0091  memory: 5167  grad_norm: 165.7936  loss: 9.4772  decode.loss_cls: 0.1816  decode.loss_mask: 0.3499  decode.loss_dice: 0.2437  decode.d0.loss_cls: 1.1542  decode.d0.loss_mask: 0.3605  decode.d0.loss_dice: 0.2691  decode.d1.loss_cls: 0.4150  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.2558  decode.d2.loss_cls: 0.3592  decode.d2.loss_mask: 0.3476  decode.d2.loss_dice: 0.2522  decode.d3.loss_cls: 0.2369  decode.d3.loss_mask: 0.3603  decode.d3.loss_dice: 0.2658  decode.d4.loss_cls: 0.2147  decode.d4.loss_mask: 0.3513  decode.d4.loss_dice: 0.2694  decode.d5.loss_cls: 0.2774  decode.d5.loss_mask: 0.3468  decode.d5.loss_dice: 0.2451  decode.d6.loss_cls: 0.2137  decode.d6.loss_mask: 0.3463  decode.d6.loss_dice: 0.2433  decode.d7.loss_cls: 0.1984  decode.d7.loss_mask: 0.3450  decode.d7.loss_dice: 0.2445  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 0.3689  decode.d8.loss_dice: 0.2709
09/28 16:13:01 - mmengine - INFO - Iter(train) [ 14350/320000]  base_lr: 9.5955e-05 lr: 9.5955e-06  eta: 1 day, 13:34:08  time: 0.4308  data_time: 0.0091  memory: 5167  grad_norm: 87.4509  loss: 6.1273  decode.loss_cls: 0.1435  decode.loss_mask: 0.2316  decode.loss_dice: 0.1943  decode.d0.loss_cls: 0.7573  decode.d0.loss_mask: 0.2401  decode.d0.loss_dice: 0.2159  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.2301  decode.d1.loss_dice: 0.1996  decode.d2.loss_cls: 0.0827  decode.d2.loss_mask: 0.2257  decode.d2.loss_dice: 0.1873  decode.d3.loss_cls: 0.1169  decode.d3.loss_mask: 0.2286  decode.d3.loss_dice: 0.1921  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.2266  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.1193  decode.d5.loss_mask: 0.2215  decode.d5.loss_dice: 0.1929  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 0.2294  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.1289  decode.d7.loss_mask: 0.2277  decode.d7.loss_dice: 0.1952  decode.d8.loss_cls: 0.1406  decode.d8.loss_mask: 0.2265  decode.d8.loss_dice: 0.1969
09/28 16:13:22 - mmengine - INFO - Iter(train) [ 14400/320000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 1 day, 13:33:35  time: 0.4315  data_time: 0.0091  memory: 5166  grad_norm: 126.8258  loss: 9.1670  decode.loss_cls: 0.2072  decode.loss_mask: 0.3823  decode.loss_dice: 0.2780  decode.d0.loss_cls: 1.1162  decode.d0.loss_mask: 0.3592  decode.d0.loss_dice: 0.2982  decode.d1.loss_cls: 0.1211  decode.d1.loss_mask: 0.3537  decode.d1.loss_dice: 0.2624  decode.d2.loss_cls: 0.1132  decode.d2.loss_mask: 0.3628  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.1299  decode.d3.loss_mask: 0.3379  decode.d3.loss_dice: 0.2286  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.3874  decode.d4.loss_dice: 0.2696  decode.d5.loss_cls: 0.1319  decode.d5.loss_mask: 0.4516  decode.d5.loss_dice: 0.3073  decode.d6.loss_cls: 0.1660  decode.d6.loss_mask: 0.4758  decode.d6.loss_dice: 0.3051  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.4257  decode.d7.loss_dice: 0.3187  decode.d8.loss_cls: 0.2206  decode.d8.loss_mask: 0.3962  decode.d8.loss_dice: 0.2958
09/28 16:13:44 - mmengine - INFO - Iter(train) [ 14450/320000]  base_lr: 9.5927e-05 lr: 9.5927e-06  eta: 1 day, 13:33:05  time: 0.4497  data_time: 0.0090  memory: 5150  grad_norm: 301.1032  loss: 8.2029  decode.loss_cls: 0.2693  decode.loss_mask: 0.2289  decode.loss_dice: 0.2472  decode.d0.loss_cls: 1.1032  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.2353  decode.d1.loss_cls: 0.3064  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.2281  decode.d2.loss_cls: 0.2753  decode.d2.loss_mask: 0.2396  decode.d2.loss_dice: 0.2410  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2227  decode.d4.loss_cls: 0.3309  decode.d4.loss_mask: 0.2427  decode.d4.loss_dice: 0.2450  decode.d5.loss_cls: 0.2403  decode.d5.loss_mask: 0.2399  decode.d5.loss_dice: 0.2506  decode.d6.loss_cls: 0.2634  decode.d6.loss_mask: 0.2351  decode.d6.loss_dice: 0.2515  decode.d7.loss_cls: 0.2246  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.2574  decode.d8.loss_cls: 0.1586  decode.d8.loss_mask: 0.2445  decode.d8.loss_dice: 0.2734
09/28 16:14:06 - mmengine - INFO - Iter(train) [ 14500/320000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 1 day, 13:32:31  time: 0.4311  data_time: 0.0090  memory: 5150  grad_norm: 48.7647  loss: 6.3123  decode.loss_cls: 0.1040  decode.loss_mask: 0.2437  decode.loss_dice: 0.2061  decode.d0.loss_cls: 0.7749  decode.d0.loss_mask: 0.2508  decode.d0.loss_dice: 0.2066  decode.d1.loss_cls: 0.1207  decode.d1.loss_mask: 0.2432  decode.d1.loss_dice: 0.1943  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.2435  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.0844  decode.d3.loss_mask: 0.2449  decode.d3.loss_dice: 0.2039  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2457  decode.d4.loss_dice: 0.2045  decode.d5.loss_cls: 0.1412  decode.d5.loss_mask: 0.2459  decode.d5.loss_dice: 0.2066  decode.d6.loss_cls: 0.1250  decode.d6.loss_mask: 0.2449  decode.d6.loss_dice: 0.2086  decode.d7.loss_cls: 0.1066  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.2170  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 0.2447  decode.d8.loss_dice: 0.2084
09/28 16:14:27 - mmengine - INFO - Iter(train) [ 14550/320000]  base_lr: 9.5899e-05 lr: 9.5899e-06  eta: 1 day, 13:31:57  time: 0.4312  data_time: 0.0089  memory: 5150  grad_norm: 75.6538  loss: 8.1867  decode.loss_cls: 0.2268  decode.loss_mask: 0.2527  decode.loss_dice: 0.2401  decode.d0.loss_cls: 0.9171  decode.d0.loss_mask: 0.2646  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.2448  decode.d1.loss_mask: 0.2571  decode.d1.loss_dice: 0.2637  decode.d2.loss_cls: 0.2124  decode.d2.loss_mask: 0.2548  decode.d2.loss_dice: 0.2539  decode.d3.loss_cls: 0.2334  decode.d3.loss_mask: 0.2570  decode.d3.loss_dice: 0.2544  decode.d4.loss_cls: 0.2541  decode.d4.loss_mask: 0.2498  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.2738  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.2396  decode.d6.loss_cls: 0.2538  decode.d6.loss_mask: 0.2556  decode.d6.loss_dice: 0.2453  decode.d7.loss_cls: 0.2757  decode.d7.loss_mask: 0.2538  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.2406  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.2399
09/28 16:14:49 - mmengine - INFO - Iter(train) [ 14600/320000]  base_lr: 9.5884e-05 lr: 9.5884e-06  eta: 1 day, 13:31:22  time: 0.4313  data_time: 0.0090  memory: 5186  grad_norm: 94.0020  loss: 9.7314  decode.loss_cls: 0.2978  decode.loss_mask: 0.2870  decode.loss_dice: 0.3148  decode.d0.loss_cls: 1.1695  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.3102  decode.d1.loss_cls: 0.3014  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.3118  decode.d2.loss_cls: 0.2699  decode.d2.loss_mask: 0.2814  decode.d2.loss_dice: 0.3135  decode.d3.loss_cls: 0.3291  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.3156  decode.d4.loss_cls: 0.2610  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.3104  decode.d5.loss_cls: 0.2419  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.3062  decode.d6.loss_cls: 0.3167  decode.d6.loss_mask: 0.2773  decode.d6.loss_dice: 0.3116  decode.d7.loss_cls: 0.3187  decode.d7.loss_mask: 0.2813  decode.d7.loss_dice: 0.3091  decode.d8.loss_cls: 0.2953  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.3126
09/28 16:15:10 - mmengine - INFO - Iter(train) [ 14650/320000]  base_lr: 9.5870e-05 lr: 9.5870e-06  eta: 1 day, 13:30:48  time: 0.4307  data_time: 0.0089  memory: 5186  grad_norm: 102.0961  loss: 7.9501  decode.loss_cls: 0.2702  decode.loss_mask: 0.2824  decode.loss_dice: 0.2122  decode.d0.loss_cls: 0.9795  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.2531  decode.d1.loss_cls: 0.2009  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.2247  decode.d3.loss_cls: 0.2099  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.2169  decode.d4.loss_cls: 0.2148  decode.d4.loss_mask: 0.2924  decode.d4.loss_dice: 0.2184  decode.d5.loss_cls: 0.2607  decode.d5.loss_mask: 0.2642  decode.d5.loss_dice: 0.2297  decode.d6.loss_cls: 0.2685  decode.d6.loss_mask: 0.2677  decode.d6.loss_dice: 0.2138  decode.d7.loss_cls: 0.1999  decode.d7.loss_mask: 0.2674  decode.d7.loss_dice: 0.2041  decode.d8.loss_cls: 0.2046  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.2313
09/28 16:15:33 - mmengine - INFO - Iter(train) [ 14700/320000]  base_lr: 9.5856e-05 lr: 9.5856e-06  eta: 1 day, 13:30:44  time: 0.4706  data_time: 0.0089  memory: 5186  grad_norm: 74.6077  loss: 7.5273  decode.loss_cls: 0.1602  decode.loss_mask: 0.2792  decode.loss_dice: 0.2842  decode.d0.loss_cls: 0.9420  decode.d0.loss_mask: 0.2422  decode.d0.loss_dice: 0.2708  decode.d1.loss_cls: 0.2114  decode.d1.loss_mask: 0.2246  decode.d1.loss_dice: 0.2352  decode.d2.loss_cls: 0.1656  decode.d2.loss_mask: 0.2313  decode.d2.loss_dice: 0.2583  decode.d3.loss_cls: 0.1251  decode.d3.loss_mask: 0.2278  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.1365  decode.d4.loss_mask: 0.2248  decode.d4.loss_dice: 0.2674  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 0.2455  decode.d5.loss_dice: 0.2887  decode.d6.loss_cls: 0.1363  decode.d6.loss_mask: 0.2322  decode.d6.loss_dice: 0.2775  decode.d7.loss_cls: 0.1460  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.2898  decode.d8.loss_cls: 0.1506  decode.d8.loss_mask: 0.3604  decode.d8.loss_dice: 0.2948
09/28 16:15:57 - mmengine - INFO - Iter(train) [ 14750/320000]  base_lr: 9.5842e-05 lr: 9.5842e-06  eta: 1 day, 13:30:50  time: 0.4706  data_time: 0.0088  memory: 5167  grad_norm: 60.7207  loss: 7.6592  decode.loss_cls: 0.3079  decode.loss_mask: 0.2148  decode.loss_dice: 0.1866  decode.d0.loss_cls: 1.0097  decode.d0.loss_mask: 0.2412  decode.d0.loss_dice: 0.2537  decode.d1.loss_cls: 0.3240  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.2555  decode.d2.loss_mask: 0.2164  decode.d2.loss_dice: 0.2363  decode.d3.loss_cls: 0.2399  decode.d3.loss_mask: 0.2098  decode.d3.loss_dice: 0.1916  decode.d4.loss_cls: 0.2236  decode.d4.loss_mask: 0.2136  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.2124  decode.d5.loss_mask: 0.2171  decode.d5.loss_dice: 0.2534  decode.d6.loss_cls: 0.2382  decode.d6.loss_mask: 0.2104  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.2482  decode.d7.loss_mask: 0.2100  decode.d7.loss_dice: 0.1782  decode.d8.loss_cls: 0.2884  decode.d8.loss_mask: 0.2124  decode.d8.loss_dice: 0.2396
09/28 16:16:20 - mmengine - INFO - Iter(train) [ 14800/320000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 1 day, 13:30:56  time: 0.4705  data_time: 0.0093  memory: 5186  grad_norm: 45.4621  loss: 7.6723  decode.loss_cls: 0.1224  decode.loss_mask: 0.2875  decode.loss_dice: 0.2002  decode.d0.loss_cls: 1.2725  decode.d0.loss_mask: 0.2726  decode.d0.loss_dice: 0.2254  decode.d1.loss_cls: 0.1943  decode.d1.loss_mask: 0.2725  decode.d1.loss_dice: 0.2140  decode.d2.loss_cls: 0.1990  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.1833  decode.d3.loss_mask: 0.2893  decode.d3.loss_dice: 0.2049  decode.d4.loss_cls: 0.1730  decode.d4.loss_mask: 0.2879  decode.d4.loss_dice: 0.2028  decode.d5.loss_cls: 0.1749  decode.d5.loss_mask: 0.2951  decode.d5.loss_dice: 0.2093  decode.d6.loss_cls: 0.1584  decode.d6.loss_mask: 0.2777  decode.d6.loss_dice: 0.1921  decode.d7.loss_cls: 0.1386  decode.d7.loss_mask: 0.2808  decode.d7.loss_dice: 0.2047  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 0.3036  decode.d8.loss_dice: 0.2007
09/28 16:16:44 - mmengine - INFO - Iter(train) [ 14850/320000]  base_lr: 9.5814e-05 lr: 9.5814e-06  eta: 1 day, 13:31:02  time: 0.4694  data_time: 0.0090  memory: 5186  grad_norm: 130.0470  loss: 10.7669  decode.loss_cls: 0.3909  decode.loss_mask: 0.3323  decode.loss_dice: 0.2820  decode.d0.loss_cls: 1.2875  decode.d0.loss_mask: 0.3112  decode.d0.loss_dice: 0.2668  decode.d1.loss_cls: 0.4253  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.2520  decode.d2.loss_cls: 0.3970  decode.d2.loss_mask: 0.3303  decode.d2.loss_dice: 0.2760  decode.d3.loss_cls: 0.3809  decode.d3.loss_mask: 0.3481  decode.d3.loss_dice: 0.2765  decode.d4.loss_cls: 0.3599  decode.d4.loss_mask: 0.3779  decode.d4.loss_dice: 0.2808  decode.d5.loss_cls: 0.3901  decode.d5.loss_mask: 0.3447  decode.d5.loss_dice: 0.2808  decode.d6.loss_cls: 0.3657  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.2524  decode.d7.loss_cls: 0.3898  decode.d7.loss_mask: 0.3143  decode.d7.loss_dice: 0.2499  decode.d8.loss_cls: 0.3959  decode.d8.loss_mask: 0.3291  decode.d8.loss_dice: 0.2525
09/28 16:17:07 - mmengine - INFO - Iter(train) [ 14900/320000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 1 day, 13:31:08  time: 0.4712  data_time: 0.0094  memory: 5167  grad_norm: 53.2864  loss: 9.2219  decode.loss_cls: 0.1603  decode.loss_mask: 0.4170  decode.loss_dice: 0.2849  decode.d0.loss_cls: 0.9112  decode.d0.loss_mask: 0.2918  decode.d0.loss_dice: 0.2781  decode.d1.loss_cls: 0.2700  decode.d1.loss_mask: 0.2784  decode.d1.loss_dice: 0.2683  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.4220  decode.d2.loss_dice: 0.2932  decode.d3.loss_cls: 0.2443  decode.d3.loss_mask: 0.3070  decode.d3.loss_dice: 0.2814  decode.d4.loss_cls: 0.1166  decode.d4.loss_mask: 0.4348  decode.d4.loss_dice: 0.3076  decode.d5.loss_cls: 0.1510  decode.d5.loss_mask: 0.4261  decode.d5.loss_dice: 0.2802  decode.d6.loss_cls: 0.1552  decode.d6.loss_mask: 0.4269  decode.d6.loss_dice: 0.2837  decode.d7.loss_cls: 0.1798  decode.d7.loss_mask: 0.4256  decode.d7.loss_dice: 0.2762  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 0.4148  decode.d8.loss_dice: 0.2819
09/28 16:17:31 - mmengine - INFO - Iter(train) [ 14950/320000]  base_lr: 9.5786e-05 lr: 9.5786e-06  eta: 1 day, 13:31:14  time: 0.4688  data_time: 0.0089  memory: 5166  grad_norm: 78.7400  loss: 8.9465  decode.loss_cls: 0.2969  decode.loss_mask: 0.2879  decode.loss_dice: 0.2624  decode.d0.loss_cls: 1.2125  decode.d0.loss_mask: 0.3015  decode.d0.loss_dice: 0.2787  decode.d1.loss_cls: 0.2624  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.2505  decode.d2.loss_cls: 0.2351  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.2602  decode.d3.loss_cls: 0.2743  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.2447  decode.d4.loss_cls: 0.2266  decode.d4.loss_mask: 0.2879  decode.d4.loss_dice: 0.2394  decode.d5.loss_cls: 0.2877  decode.d5.loss_mask: 0.2864  decode.d5.loss_dice: 0.2380  decode.d6.loss_cls: 0.2512  decode.d6.loss_mask: 0.2931  decode.d6.loss_dice: 0.2496  decode.d7.loss_cls: 0.2015  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.2477  decode.d8.loss_cls: 0.2730  decode.d8.loss_mask: 0.2892  decode.d8.loss_dice: 0.2556
09/28 16:17:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:17:54 - mmengine - INFO - Iter(train) [ 15000/320000]  base_lr: 9.5771e-05 lr: 9.5771e-06  eta: 1 day, 13:31:19  time: 0.4699  data_time: 0.0093  memory: 5186  grad_norm: 122.2099  loss: 8.3250  decode.loss_cls: 0.2791  decode.loss_mask: 0.3145  decode.loss_dice: 0.2802  decode.d0.loss_cls: 0.9246  decode.d0.loss_mask: 0.2698  decode.d0.loss_dice: 0.2528  decode.d1.loss_cls: 0.3097  decode.d1.loss_mask: 0.2626  decode.d1.loss_dice: 0.2230  decode.d2.loss_cls: 0.1905  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2201  decode.d3.loss_cls: 0.1812  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.2262  decode.d4.loss_cls: 0.2427  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.2461  decode.d5.loss_cls: 0.2471  decode.d5.loss_mask: 0.2710  decode.d5.loss_dice: 0.2570  decode.d6.loss_cls: 0.2226  decode.d6.loss_mask: 0.2805  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.2608  decode.d7.loss_mask: 0.2755  decode.d7.loss_dice: 0.2509  decode.d8.loss_cls: 0.2983  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.2247
09/28 16:18:18 - mmengine - INFO - Iter(train) [ 15050/320000]  base_lr: 9.5757e-05 lr: 9.5757e-06  eta: 1 day, 13:31:24  time: 0.4691  data_time: 0.0090  memory: 5165  grad_norm: 141.4667  loss: 8.7901  decode.loss_cls: 0.2077  decode.loss_mask: 0.3024  decode.loss_dice: 0.2404  decode.d0.loss_cls: 1.1138  decode.d0.loss_mask: 0.3104  decode.d0.loss_dice: 0.2651  decode.d1.loss_cls: 0.3316  decode.d1.loss_mask: 0.3042  decode.d1.loss_dice: 0.2414  decode.d2.loss_cls: 0.2670  decode.d2.loss_mask: 0.2997  decode.d2.loss_dice: 0.2348  decode.d3.loss_cls: 0.2198  decode.d3.loss_mask: 0.2890  decode.d3.loss_dice: 0.2341  decode.d4.loss_cls: 0.2513  decode.d4.loss_mask: 0.2939  decode.d4.loss_dice: 0.2316  decode.d5.loss_cls: 0.2868  decode.d5.loss_mask: 0.2928  decode.d5.loss_dice: 0.2312  decode.d6.loss_cls: 0.2377  decode.d6.loss_mask: 0.3368  decode.d6.loss_dice: 0.2503  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.3534  decode.d7.loss_dice: 0.2589  decode.d8.loss_cls: 0.2011  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.2575
09/28 16:18:41 - mmengine - INFO - Iter(train) [ 15100/320000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 1 day, 13:31:30  time: 0.4712  data_time: 0.0088  memory: 5186  grad_norm: 44.0646  loss: 5.6254  decode.loss_cls: 0.0841  decode.loss_mask: 0.1654  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.9582  decode.d0.loss_mask: 0.1720  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.1410  decode.d1.loss_mask: 0.1680  decode.d1.loss_dice: 0.1960  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.1672  decode.d2.loss_dice: 0.1946  decode.d3.loss_cls: 0.1022  decode.d3.loss_mask: 0.1668  decode.d3.loss_dice: 0.1883  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.1679  decode.d4.loss_dice: 0.1894  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.1690  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.1048  decode.d6.loss_mask: 0.1690  decode.d6.loss_dice: 0.2196  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.1681  decode.d7.loss_dice: 0.1879  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.1701  decode.d8.loss_dice: 0.2294
09/28 16:19:05 - mmengine - INFO - Iter(train) [ 15150/320000]  base_lr: 9.5729e-05 lr: 9.5729e-06  eta: 1 day, 13:31:34  time: 0.4708  data_time: 0.0093  memory: 5150  grad_norm: 109.3700  loss: 7.8183  decode.loss_cls: 0.1604  decode.loss_mask: 0.2626  decode.loss_dice: 0.2471  decode.d0.loss_cls: 1.1200  decode.d0.loss_mask: 0.2716  decode.d0.loss_dice: 0.2402  decode.d1.loss_cls: 0.2319  decode.d1.loss_mask: 0.2848  decode.d1.loss_dice: 0.2500  decode.d2.loss_cls: 0.1854  decode.d2.loss_mask: 0.3052  decode.d2.loss_dice: 0.2415  decode.d3.loss_cls: 0.1029  decode.d3.loss_mask: 0.2862  decode.d3.loss_dice: 0.2603  decode.d4.loss_cls: 0.1349  decode.d4.loss_mask: 0.3088  decode.d4.loss_dice: 0.2891  decode.d5.loss_cls: 0.1133  decode.d5.loss_mask: 0.2577  decode.d5.loss_dice: 0.2568  decode.d6.loss_cls: 0.1001  decode.d6.loss_mask: 0.2896  decode.d6.loss_dice: 0.2693  decode.d7.loss_cls: 0.1132  decode.d7.loss_mask: 0.2953  decode.d7.loss_dice: 0.2718  decode.d8.loss_cls: 0.1687  decode.d8.loss_mask: 0.2547  decode.d8.loss_dice: 0.2451
09/28 16:19:28 - mmengine - INFO - Iter(train) [ 15200/320000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 1 day, 13:31:39  time: 0.4705  data_time: 0.0089  memory: 5167  grad_norm: 70.3497  loss: 9.6845  decode.loss_cls: 0.2968  decode.loss_mask: 0.3140  decode.loss_dice: 0.3100  decode.d0.loss_cls: 0.8691  decode.d0.loss_mask: 0.2596  decode.d0.loss_dice: 0.2716  decode.d1.loss_cls: 0.3295  decode.d1.loss_mask: 0.2708  decode.d1.loss_dice: 0.3008  decode.d2.loss_cls: 0.3012  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.2776  decode.d3.loss_cls: 0.3184  decode.d3.loss_mask: 0.2858  decode.d3.loss_dice: 0.2990  decode.d4.loss_cls: 0.3765  decode.d4.loss_mask: 0.3268  decode.d4.loss_dice: 0.2676  decode.d5.loss_cls: 0.3465  decode.d5.loss_mask: 0.3254  decode.d5.loss_dice: 0.2742  decode.d6.loss_cls: 0.3124  decode.d6.loss_mask: 0.3333  decode.d6.loss_dice: 0.2612  decode.d7.loss_cls: 0.3970  decode.d7.loss_mask: 0.3232  decode.d7.loss_dice: 0.2781  decode.d8.loss_cls: 0.2801  decode.d8.loss_mask: 0.3375  decode.d8.loss_dice: 0.2738
09/28 16:19:52 - mmengine - INFO - Iter(train) [ 15250/320000]  base_lr: 9.5701e-05 lr: 9.5701e-06  eta: 1 day, 13:31:43  time: 0.4710  data_time: 0.0095  memory: 5167  grad_norm: 58.6469  loss: 7.1155  decode.loss_cls: 0.1192  decode.loss_mask: 0.2640  decode.loss_dice: 0.2338  decode.d0.loss_cls: 0.9284  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.2489  decode.d1.loss_cls: 0.1571  decode.d1.loss_mask: 0.2629  decode.d1.loss_dice: 0.2023  decode.d2.loss_cls: 0.1449  decode.d2.loss_mask: 0.2620  decode.d2.loss_dice: 0.2292  decode.d3.loss_cls: 0.1600  decode.d3.loss_mask: 0.2625  decode.d3.loss_dice: 0.2054  decode.d4.loss_cls: 0.1488  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.1323  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2047  decode.d6.loss_cls: 0.1441  decode.d6.loss_mask: 0.2650  decode.d6.loss_dice: 0.2479  decode.d7.loss_cls: 0.1211  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.2313  decode.d8.loss_cls: 0.1258  decode.d8.loss_mask: 0.2763  decode.d8.loss_dice: 0.2451
09/28 16:20:15 - mmengine - INFO - Iter(train) [ 15300/320000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 1 day, 13:31:48  time: 0.4706  data_time: 0.0092  memory: 5149  grad_norm: 56.6897  loss: 9.3422  decode.loss_cls: 0.3177  decode.loss_mask: 0.2691  decode.loss_dice: 0.2703  decode.d0.loss_cls: 0.8679  decode.d0.loss_mask: 0.2745  decode.d0.loss_dice: 0.2911  decode.d1.loss_cls: 0.3911  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.2857  decode.d2.loss_cls: 0.3869  decode.d2.loss_mask: 0.2711  decode.d2.loss_dice: 0.2876  decode.d3.loss_cls: 0.3017  decode.d3.loss_mask: 0.2686  decode.d3.loss_dice: 0.2899  decode.d4.loss_cls: 0.2885  decode.d4.loss_mask: 0.2777  decode.d4.loss_dice: 0.2951  decode.d5.loss_cls: 0.2883  decode.d5.loss_mask: 0.2740  decode.d5.loss_dice: 0.2979  decode.d6.loss_cls: 0.2994  decode.d6.loss_mask: 0.2774  decode.d6.loss_dice: 0.2916  decode.d7.loss_cls: 0.3094  decode.d7.loss_mask: 0.2722  decode.d7.loss_dice: 0.2868  decode.d8.loss_cls: 0.2879  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2756
09/28 16:20:38 - mmengine - INFO - Iter(train) [ 15350/320000]  base_lr: 9.5673e-05 lr: 9.5673e-06  eta: 1 day, 13:31:30  time: 0.4311  data_time: 0.0091  memory: 5166  grad_norm: 102.8750  loss: 9.7473  decode.loss_cls: 0.2512  decode.loss_mask: 0.3523  decode.loss_dice: 0.3114  decode.d0.loss_cls: 1.0471  decode.d0.loss_mask: 0.3265  decode.d0.loss_dice: 0.3422  decode.d1.loss_cls: 0.3093  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.2989  decode.d2.loss_cls: 0.2755  decode.d2.loss_mask: 0.3104  decode.d2.loss_dice: 0.2988  decode.d3.loss_cls: 0.2185  decode.d3.loss_mask: 0.3217  decode.d3.loss_dice: 0.2988  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 0.3065  decode.d4.loss_dice: 0.2887  decode.d5.loss_cls: 0.1850  decode.d5.loss_mask: 0.3543  decode.d5.loss_dice: 0.2990  decode.d6.loss_cls: 0.3084  decode.d6.loss_mask: 0.3096  decode.d6.loss_dice: 0.3043  decode.d7.loss_cls: 0.2598  decode.d7.loss_mask: 0.3229  decode.d7.loss_dice: 0.3079  decode.d8.loss_cls: 0.2869  decode.d8.loss_mask: 0.3590  decode.d8.loss_dice: 0.3147
09/28 16:20:59 - mmengine - INFO - Iter(train) [ 15400/320000]  base_lr: 9.5658e-05 lr: 9.5658e-06  eta: 1 day, 13:30:56  time: 0.4314  data_time: 0.0089  memory: 5150  grad_norm: 87.0140  loss: 6.6076  decode.loss_cls: 0.0993  decode.loss_mask: 0.2045  decode.loss_dice: 0.2210  decode.d0.loss_cls: 1.0072  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.2339  decode.d1.loss_cls: 0.2459  decode.d1.loss_mask: 0.2120  decode.d1.loss_dice: 0.2299  decode.d2.loss_cls: 0.1852  decode.d2.loss_mask: 0.2091  decode.d2.loss_dice: 0.2174  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.2083  decode.d3.loss_dice: 0.2258  decode.d4.loss_cls: 0.1183  decode.d4.loss_mask: 0.2027  decode.d4.loss_dice: 0.2235  decode.d5.loss_cls: 0.1649  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.2221  decode.d6.loss_cls: 0.1271  decode.d6.loss_mask: 0.2021  decode.d6.loss_dice: 0.2070  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.2036  decode.d7.loss_dice: 0.2110  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.2026  decode.d8.loss_dice: 0.2251
09/28 16:21:21 - mmengine - INFO - Iter(train) [ 15450/320000]  base_lr: 9.5644e-05 lr: 9.5644e-06  eta: 1 day, 13:30:21  time: 0.4307  data_time: 0.0088  memory: 5167  grad_norm: 65.2230  loss: 7.2569  decode.loss_cls: 0.1775  decode.loss_mask: 0.2552  decode.loss_dice: 0.2142  decode.d0.loss_cls: 0.9943  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2509  decode.d1.loss_cls: 0.2328  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.2175  decode.d2.loss_cls: 0.2080  decode.d2.loss_mask: 0.2590  decode.d2.loss_dice: 0.2159  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 0.2538  decode.d3.loss_dice: 0.2089  decode.d4.loss_cls: 0.1198  decode.d4.loss_mask: 0.2602  decode.d4.loss_dice: 0.2121  decode.d5.loss_cls: 0.1551  decode.d5.loss_mask: 0.2503  decode.d5.loss_dice: 0.2174  decode.d6.loss_cls: 0.1149  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.2325  decode.d7.loss_cls: 0.1147  decode.d7.loss_mask: 0.2610  decode.d7.loss_dice: 0.2230  decode.d8.loss_cls: 0.1572  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.2101
09/28 16:21:42 - mmengine - INFO - Iter(train) [ 15500/320000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 1 day, 13:29:47  time: 0.4310  data_time: 0.0089  memory: 5167  grad_norm: 69.8157  loss: 9.0348  decode.loss_cls: 0.2752  decode.loss_mask: 0.2542  decode.loss_dice: 0.3167  decode.d0.loss_cls: 1.0986  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.3121  decode.d1.loss_cls: 0.2687  decode.d1.loss_mask: 0.2500  decode.d1.loss_dice: 0.2533  decode.d2.loss_cls: 0.3296  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2618  decode.d3.loss_cls: 0.2639  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.2836  decode.d4.loss_cls: 0.3309  decode.d4.loss_mask: 0.2509  decode.d4.loss_dice: 0.2460  decode.d5.loss_cls: 0.2955  decode.d5.loss_mask: 0.2564  decode.d5.loss_dice: 0.2760  decode.d6.loss_cls: 0.2473  decode.d6.loss_mask: 0.2542  decode.d6.loss_dice: 0.2799  decode.d7.loss_cls: 0.3075  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.2721  decode.d8.loss_cls: 0.2773  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.3025
09/28 16:22:04 - mmengine - INFO - Iter(train) [ 15550/320000]  base_lr: 9.5616e-05 lr: 9.5616e-06  eta: 1 day, 13:29:13  time: 0.4310  data_time: 0.0088  memory: 5166  grad_norm: 86.8428  loss: 7.8224  decode.loss_cls: 0.2513  decode.loss_mask: 0.2725  decode.loss_dice: 0.1899  decode.d0.loss_cls: 1.0243  decode.d0.loss_mask: 0.2505  decode.d0.loss_dice: 0.1971  decode.d1.loss_cls: 0.2409  decode.d1.loss_mask: 0.2114  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.2208  decode.d2.loss_mask: 0.2401  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.2965  decode.d3.loss_mask: 0.2126  decode.d3.loss_dice: 0.1919  decode.d4.loss_cls: 0.2720  decode.d4.loss_mask: 0.2287  decode.d4.loss_dice: 0.1817  decode.d5.loss_cls: 0.2751  decode.d5.loss_mask: 0.2254  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.2711  decode.d6.loss_mask: 0.2662  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.2858  decode.d7.loss_mask: 0.2828  decode.d7.loss_dice: 0.1911  decode.d8.loss_cls: 0.2894  decode.d8.loss_mask: 0.2960  decode.d8.loss_dice: 0.1896
09/28 16:22:25 - mmengine - INFO - Iter(train) [ 15600/320000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 1 day, 13:28:39  time: 0.4313  data_time: 0.0088  memory: 5186  grad_norm: 59.6175  loss: 6.7159  decode.loss_cls: 0.1578  decode.loss_mask: 0.2331  decode.loss_dice: 0.2185  decode.d0.loss_cls: 1.0389  decode.d0.loss_mask: 0.2412  decode.d0.loss_dice: 0.2385  decode.d1.loss_cls: 0.1083  decode.d1.loss_mask: 0.2371  decode.d1.loss_dice: 0.2139  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 0.2341  decode.d2.loss_dice: 0.2017  decode.d3.loss_cls: 0.1106  decode.d3.loss_mask: 0.2310  decode.d3.loss_dice: 0.2064  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.2046  decode.d5.loss_cls: 0.1403  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.2043  decode.d6.loss_cls: 0.1661  decode.d6.loss_mask: 0.2345  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.1571  decode.d7.loss_mask: 0.2331  decode.d7.loss_dice: 0.2025  decode.d8.loss_cls: 0.1387  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.2135
09/28 16:22:47 - mmengine - INFO - Iter(train) [ 15650/320000]  base_lr: 9.5588e-05 lr: 9.5588e-06  eta: 1 day, 13:28:04  time: 0.4309  data_time: 0.0088  memory: 5186  grad_norm: 72.3865  loss: 6.5695  decode.loss_cls: 0.0909  decode.loss_mask: 0.2689  decode.loss_dice: 0.1865  decode.d0.loss_cls: 0.9349  decode.d0.loss_mask: 0.2846  decode.d0.loss_dice: 0.2013  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.2030  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.2720  decode.d2.loss_dice: 0.1932  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.2764  decode.d3.loss_dice: 0.1836  decode.d4.loss_cls: 0.1252  decode.d4.loss_mask: 0.2754  decode.d4.loss_dice: 0.2032  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 0.2815  decode.d5.loss_dice: 0.2216  decode.d6.loss_cls: 0.1200  decode.d6.loss_mask: 0.2935  decode.d6.loss_dice: 0.2146  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.2760  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.2716  decode.d8.loss_dice: 0.1871
09/28 16:23:09 - mmengine - INFO - Iter(train) [ 15700/320000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 1 day, 13:27:30  time: 0.4305  data_time: 0.0089  memory: 5166  grad_norm: 84.6506  loss: 8.6552  decode.loss_cls: 0.1650  decode.loss_mask: 0.3231  decode.loss_dice: 0.3181  decode.d0.loss_cls: 0.8602  decode.d0.loss_mask: 0.3481  decode.d0.loss_dice: 0.3159  decode.d1.loss_cls: 0.2050  decode.d1.loss_mask: 0.3262  decode.d1.loss_dice: 0.3273  decode.d2.loss_cls: 0.1179  decode.d2.loss_mask: 0.3349  decode.d2.loss_dice: 0.3070  decode.d3.loss_cls: 0.1285  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.3155  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.3192  decode.d4.loss_dice: 0.2980  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.3507  decode.d5.loss_dice: 0.3303  decode.d6.loss_cls: 0.1467  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.3136  decode.d7.loss_cls: 0.1420  decode.d7.loss_mask: 0.3250  decode.d7.loss_dice: 0.3134  decode.d8.loss_cls: 0.1492  decode.d8.loss_mask: 0.3314  decode.d8.loss_dice: 0.3172
09/28 16:23:30 - mmengine - INFO - Iter(train) [ 15750/320000]  base_lr: 9.5559e-05 lr: 9.5559e-06  eta: 1 day, 13:26:57  time: 0.4312  data_time: 0.0090  memory: 5149  grad_norm: 101.5124  loss: 8.8540  decode.loss_cls: 0.1480  decode.loss_mask: 0.3859  decode.loss_dice: 0.2525  decode.d0.loss_cls: 1.1363  decode.d0.loss_mask: 0.3311  decode.d0.loss_dice: 0.2549  decode.d1.loss_cls: 0.2389  decode.d1.loss_mask: 0.3231  decode.d1.loss_dice: 0.2426  decode.d2.loss_cls: 0.1780  decode.d2.loss_mask: 0.3220  decode.d2.loss_dice: 0.2282  decode.d3.loss_cls: 0.2090  decode.d3.loss_mask: 0.3480  decode.d3.loss_dice: 0.2471  decode.d4.loss_cls: 0.2527  decode.d4.loss_mask: 0.3513  decode.d4.loss_dice: 0.2574  decode.d5.loss_cls: 0.2516  decode.d5.loss_mask: 0.3336  decode.d5.loss_dice: 0.2513  decode.d6.loss_cls: 0.1656  decode.d6.loss_mask: 0.3662  decode.d6.loss_dice: 0.2552  decode.d7.loss_cls: 0.1497  decode.d7.loss_mask: 0.3666  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.1207  decode.d8.loss_mask: 0.3869  decode.d8.loss_dice: 0.2513
09/28 16:23:52 - mmengine - INFO - Iter(train) [ 15800/320000]  base_lr: 9.5545e-05 lr: 9.5545e-06  eta: 1 day, 13:26:23  time: 0.4323  data_time: 0.0090  memory: 5186  grad_norm: 115.4034  loss: 9.2596  decode.loss_cls: 0.2389  decode.loss_mask: 0.3078  decode.loss_dice: 0.2612  decode.d0.loss_cls: 1.2150  decode.d0.loss_mask: 0.3296  decode.d0.loss_dice: 0.2963  decode.d1.loss_cls: 0.2521  decode.d1.loss_mask: 0.3110  decode.d1.loss_dice: 0.2593  decode.d2.loss_cls: 0.2440  decode.d2.loss_mask: 0.3148  decode.d2.loss_dice: 0.2680  decode.d3.loss_cls: 0.2648  decode.d3.loss_mask: 0.3071  decode.d3.loss_dice: 0.2723  decode.d4.loss_cls: 0.2734  decode.d4.loss_mask: 0.3057  decode.d4.loss_dice: 0.2528  decode.d5.loss_cls: 0.2582  decode.d5.loss_mask: 0.3060  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 0.3075  decode.d6.loss_dice: 0.2711  decode.d7.loss_cls: 0.2545  decode.d7.loss_mask: 0.3063  decode.d7.loss_dice: 0.2716  decode.d8.loss_cls: 0.2550  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.2565
09/28 16:24:13 - mmengine - INFO - Iter(train) [ 15850/320000]  base_lr: 9.5531e-05 lr: 9.5531e-06  eta: 1 day, 13:25:50  time: 0.4315  data_time: 0.0091  memory: 5148  grad_norm: 226.4391  loss: 14.0277  decode.loss_cls: 0.5151  decode.loss_mask: 0.4621  decode.loss_dice: 0.3512  decode.d0.loss_cls: 0.9967  decode.d0.loss_mask: 0.5237  decode.d0.loss_dice: 0.4310  decode.d1.loss_cls: 0.6583  decode.d1.loss_mask: 0.4526  decode.d1.loss_dice: 0.4116  decode.d2.loss_cls: 0.5102  decode.d2.loss_mask: 0.3937  decode.d2.loss_dice: 0.3670  decode.d3.loss_cls: 0.5514  decode.d3.loss_mask: 0.3966  decode.d3.loss_dice: 0.3783  decode.d4.loss_cls: 0.4780  decode.d4.loss_mask: 0.4585  decode.d4.loss_dice: 0.4007  decode.d5.loss_cls: 0.4489  decode.d5.loss_mask: 0.5057  decode.d5.loss_dice: 0.3968  decode.d6.loss_cls: 0.4255  decode.d6.loss_mask: 0.4725  decode.d6.loss_dice: 0.3657  decode.d7.loss_cls: 0.3910  decode.d7.loss_mask: 0.4703  decode.d7.loss_dice: 0.3631  decode.d8.loss_cls: 0.5938  decode.d8.loss_mask: 0.4627  decode.d8.loss_dice: 0.3949
09/28 16:24:35 - mmengine - INFO - Iter(train) [ 15900/320000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 1 day, 13:25:17  time: 0.4318  data_time: 0.0090  memory: 5186  grad_norm: 47.8141  loss: 7.4270  decode.loss_cls: 0.1448  decode.loss_mask: 0.2558  decode.loss_dice: 0.2087  decode.d0.loss_cls: 1.0905  decode.d0.loss_mask: 0.2751  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1959  decode.d1.loss_mask: 0.2578  decode.d1.loss_dice: 0.2100  decode.d2.loss_cls: 0.1832  decode.d2.loss_mask: 0.2647  decode.d2.loss_dice: 0.2130  decode.d3.loss_cls: 0.2192  decode.d3.loss_mask: 0.2603  decode.d3.loss_dice: 0.2050  decode.d4.loss_cls: 0.1974  decode.d4.loss_mask: 0.2605  decode.d4.loss_dice: 0.2049  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 0.2648  decode.d5.loss_dice: 0.2065  decode.d6.loss_cls: 0.1562  decode.d6.loss_mask: 0.2595  decode.d6.loss_dice: 0.2163  decode.d7.loss_cls: 0.1405  decode.d7.loss_mask: 0.2614  decode.d7.loss_dice: 0.2163  decode.d8.loss_cls: 0.1376  decode.d8.loss_mask: 0.2614  decode.d8.loss_dice: 0.2105
09/28 16:24:56 - mmengine - INFO - Iter(train) [ 15950/320000]  base_lr: 9.5503e-05 lr: 9.5503e-06  eta: 1 day, 13:24:43  time: 0.4313  data_time: 0.0088  memory: 5167  grad_norm: 87.8492  loss: 7.6064  decode.loss_cls: 0.1489  decode.loss_mask: 0.2506  decode.loss_dice: 0.2319  decode.d0.loss_cls: 1.1471  decode.d0.loss_mask: 0.2755  decode.d0.loss_dice: 0.2603  decode.d1.loss_cls: 0.2248  decode.d1.loss_mask: 0.2611  decode.d1.loss_dice: 0.2231  decode.d2.loss_cls: 0.1876  decode.d2.loss_mask: 0.2756  decode.d2.loss_dice: 0.2228  decode.d3.loss_cls: 0.1862  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2246  decode.d4.loss_cls: 0.2170  decode.d4.loss_mask: 0.2502  decode.d4.loss_dice: 0.2257  decode.d5.loss_cls: 0.1205  decode.d5.loss_mask: 0.2743  decode.d5.loss_dice: 0.2243  decode.d6.loss_cls: 0.1835  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.1504  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.2242  decode.d8.loss_cls: 0.1448  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2357
09/28 16:25:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:25:18 - mmengine - INFO - Iter(train) [ 16000/320000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 1 day, 13:24:11  time: 0.4308  data_time: 0.0090  memory: 5167  grad_norm: 265.3531  loss: 10.7375  decode.loss_cls: 0.1657  decode.loss_mask: 0.4807  decode.loss_dice: 0.3423  decode.d0.loss_cls: 0.7340  decode.d0.loss_mask: 0.5037  decode.d0.loss_dice: 0.3692  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 0.4702  decode.d1.loss_dice: 0.3328  decode.d2.loss_cls: 0.1712  decode.d2.loss_mask: 0.4717  decode.d2.loss_dice: 0.3220  decode.d3.loss_cls: 0.3125  decode.d3.loss_mask: 0.4694  decode.d3.loss_dice: 0.3401  decode.d4.loss_cls: 0.1723  decode.d4.loss_mask: 0.4827  decode.d4.loss_dice: 0.3565  decode.d5.loss_cls: 0.1675  decode.d5.loss_mask: 0.4767  decode.d5.loss_dice: 0.3352  decode.d6.loss_cls: 0.1517  decode.d6.loss_mask: 0.4843  decode.d6.loss_dice: 0.3638  decode.d7.loss_cls: 0.1457  decode.d7.loss_mask: 0.4959  decode.d7.loss_dice: 0.3601  decode.d8.loss_cls: 0.1897  decode.d8.loss_mask: 0.4841  decode.d8.loss_dice: 0.3596
09/28 16:25:40 - mmengine - INFO - Iter(train) [ 16050/320000]  base_lr: 9.5475e-05 lr: 9.5475e-06  eta: 1 day, 13:23:38  time: 0.4316  data_time: 0.0091  memory: 5186  grad_norm: 42.8179  loss: 6.9208  decode.loss_cls: 0.0935  decode.loss_mask: 0.2364  decode.loss_dice: 0.2202  decode.d0.loss_cls: 0.7652  decode.d0.loss_mask: 0.2378  decode.d0.loss_dice: 0.2222  decode.d1.loss_cls: 0.2705  decode.d1.loss_mask: 0.2299  decode.d1.loss_dice: 0.2143  decode.d2.loss_cls: 0.2710  decode.d2.loss_mask: 0.2338  decode.d2.loss_dice: 0.2093  decode.d3.loss_cls: 0.2022  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.1608  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.1800  decode.d5.loss_mask: 0.2343  decode.d5.loss_dice: 0.2110  decode.d6.loss_cls: 0.1526  decode.d6.loss_mask: 0.2343  decode.d6.loss_dice: 0.2173  decode.d7.loss_cls: 0.1624  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.2215  decode.d8.loss_cls: 0.1626  decode.d8.loss_mask: 0.2328  decode.d8.loss_dice: 0.2146
09/28 16:26:01 - mmengine - INFO - Iter(train) [ 16100/320000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 1 day, 13:23:08  time: 0.4500  data_time: 0.0091  memory: 5150  grad_norm: 75.6320  loss: 9.5043  decode.loss_cls: 0.2226  decode.loss_mask: 0.3177  decode.loss_dice: 0.3529  decode.d0.loss_cls: 0.7892  decode.d0.loss_mask: 0.3189  decode.d0.loss_dice: 0.3481  decode.d1.loss_cls: 0.3613  decode.d1.loss_mask: 0.3186  decode.d1.loss_dice: 0.3480  decode.d2.loss_cls: 0.2409  decode.d2.loss_mask: 0.3163  decode.d2.loss_dice: 0.3545  decode.d3.loss_cls: 0.1952  decode.d3.loss_mask: 0.3188  decode.d3.loss_dice: 0.3572  decode.d4.loss_cls: 0.1649  decode.d4.loss_mask: 0.3175  decode.d4.loss_dice: 0.3448  decode.d5.loss_cls: 0.1658  decode.d5.loss_mask: 0.3129  decode.d5.loss_dice: 0.3614  decode.d6.loss_cls: 0.2136  decode.d6.loss_mask: 0.3171  decode.d6.loss_dice: 0.3453  decode.d7.loss_cls: 0.2397  decode.d7.loss_mask: 0.3159  decode.d7.loss_dice: 0.3498  decode.d8.loss_cls: 0.2336  decode.d8.loss_mask: 0.3161  decode.d8.loss_dice: 0.3459
09/28 16:26:23 - mmengine - INFO - Iter(train) [ 16150/320000]  base_lr: 9.5446e-05 lr: 9.5446e-06  eta: 1 day, 13:22:35  time: 0.4305  data_time: 0.0090  memory: 5167  grad_norm: 86.8573  loss: 7.3213  decode.loss_cls: 0.1533  decode.loss_mask: 0.2568  decode.loss_dice: 0.2269  decode.d0.loss_cls: 1.2640  decode.d0.loss_mask: 0.2593  decode.d0.loss_dice: 0.2315  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2318  decode.d2.loss_cls: 0.1171  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.1191  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 0.2557  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.1320  decode.d5.loss_mask: 0.2548  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 0.2557  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.1310  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.2153  decode.d8.loss_cls: 0.1346  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.2222
09/28 16:26:44 - mmengine - INFO - Iter(train) [ 16200/320000]  base_lr: 9.5432e-05 lr: 9.5432e-06  eta: 1 day, 13:22:02  time: 0.4313  data_time: 0.0089  memory: 5166  grad_norm: 70.3546  loss: 7.8072  decode.loss_cls: 0.2130  decode.loss_mask: 0.2577  decode.loss_dice: 0.2366  decode.d0.loss_cls: 1.1938  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.2601  decode.d1.loss_cls: 0.2221  decode.d1.loss_mask: 0.2577  decode.d1.loss_dice: 0.2416  decode.d2.loss_cls: 0.1837  decode.d2.loss_mask: 0.2584  decode.d2.loss_dice: 0.2351  decode.d3.loss_cls: 0.1099  decode.d3.loss_mask: 0.2575  decode.d3.loss_dice: 0.2467  decode.d4.loss_cls: 0.1582  decode.d4.loss_mask: 0.2612  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.1350  decode.d5.loss_mask: 0.2672  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.1737  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.2432  decode.d7.loss_cls: 0.1506  decode.d7.loss_mask: 0.2570  decode.d7.loss_dice: 0.2502  decode.d8.loss_cls: 0.1994  decode.d8.loss_mask: 0.2554  decode.d8.loss_dice: 0.2475
09/28 16:27:06 - mmengine - INFO - Iter(train) [ 16250/320000]  base_lr: 9.5418e-05 lr: 9.5418e-06  eta: 1 day, 13:21:29  time: 0.4312  data_time: 0.0090  memory: 5167  grad_norm: 106.4819  loss: 7.6883  decode.loss_cls: 0.2122  decode.loss_mask: 0.2510  decode.loss_dice: 0.2070  decode.d0.loss_cls: 1.0257  decode.d0.loss_mask: 0.2436  decode.d0.loss_dice: 0.2306  decode.d1.loss_cls: 0.3029  decode.d1.loss_mask: 0.2399  decode.d1.loss_dice: 0.2115  decode.d2.loss_cls: 0.3121  decode.d2.loss_mask: 0.2365  decode.d2.loss_dice: 0.2118  decode.d3.loss_cls: 0.2171  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.2093  decode.d4.loss_cls: 0.1870  decode.d4.loss_mask: 0.2404  decode.d4.loss_dice: 0.2100  decode.d5.loss_cls: 0.1735  decode.d5.loss_mask: 0.2396  decode.d5.loss_dice: 0.2067  decode.d6.loss_cls: 0.2221  decode.d6.loss_mask: 0.2329  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.2779  decode.d7.loss_mask: 0.2411  decode.d7.loss_dice: 0.2150  decode.d8.loss_cls: 0.2476  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.2020
09/28 16:27:28 - mmengine - INFO - Iter(train) [ 16300/320000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 1 day, 13:20:57  time: 0.4314  data_time: 0.0090  memory: 5186  grad_norm: 55.7652  loss: 7.8329  decode.loss_cls: 0.1476  decode.loss_mask: 0.2696  decode.loss_dice: 0.2911  decode.d0.loss_cls: 0.9816  decode.d0.loss_mask: 0.2623  decode.d0.loss_dice: 0.2756  decode.d1.loss_cls: 0.2151  decode.d1.loss_mask: 0.2691  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.2011  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2530  decode.d3.loss_cls: 0.1377  decode.d3.loss_mask: 0.2624  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 0.2679  decode.d4.loss_dice: 0.2625  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.2607  decode.d6.loss_cls: 0.1739  decode.d6.loss_mask: 0.2649  decode.d6.loss_dice: 0.2548  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.2650  decode.d7.loss_dice: 0.2777  decode.d8.loss_cls: 0.1560  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.2879
09/28 16:27:49 - mmengine - INFO - Iter(train) [ 16350/320000]  base_lr: 9.5390e-05 lr: 9.5390e-06  eta: 1 day, 13:20:25  time: 0.4340  data_time: 0.0088  memory: 5167  grad_norm: 67.2783  loss: 7.3677  decode.loss_cls: 0.1226  decode.loss_mask: 0.2734  decode.loss_dice: 0.2498  decode.d0.loss_cls: 0.8808  decode.d0.loss_mask: 0.2755  decode.d0.loss_dice: 0.2220  decode.d1.loss_cls: 0.2098  decode.d1.loss_mask: 0.2699  decode.d1.loss_dice: 0.2285  decode.d2.loss_cls: 0.1855  decode.d2.loss_mask: 0.2714  decode.d2.loss_dice: 0.2222  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 0.2692  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.1986  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.2423  decode.d5.loss_cls: 0.1854  decode.d5.loss_mask: 0.2721  decode.d5.loss_dice: 0.2248  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.2727  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.1244  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.1444  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.2404
09/28 16:28:11 - mmengine - INFO - Iter(train) [ 16400/320000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 1 day, 13:19:54  time: 0.4340  data_time: 0.0087  memory: 5186  grad_norm: 181.0264  loss: 10.0902  decode.loss_cls: 0.2599  decode.loss_mask: 0.3602  decode.loss_dice: 0.2830  decode.d0.loss_cls: 1.0529  decode.d0.loss_mask: 0.3497  decode.d0.loss_dice: 0.2991  decode.d1.loss_cls: 0.3887  decode.d1.loss_mask: 0.3059  decode.d1.loss_dice: 0.2570  decode.d2.loss_cls: 0.4012  decode.d2.loss_mask: 0.3393  decode.d2.loss_dice: 0.2830  decode.d3.loss_cls: 0.3713  decode.d3.loss_mask: 0.3057  decode.d3.loss_dice: 0.2567  decode.d4.loss_cls: 0.3376  decode.d4.loss_mask: 0.3206  decode.d4.loss_dice: 0.2542  decode.d5.loss_cls: 0.2787  decode.d5.loss_mask: 0.3581  decode.d5.loss_dice: 0.2896  decode.d6.loss_cls: 0.3117  decode.d6.loss_mask: 0.3327  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.3011  decode.d7.loss_mask: 0.3125  decode.d7.loss_dice: 0.2878  decode.d8.loss_cls: 0.2573  decode.d8.loss_mask: 0.3560  decode.d8.loss_dice: 0.2785
09/28 16:28:33 - mmengine - INFO - Iter(train) [ 16450/320000]  base_lr: 9.5362e-05 lr: 9.5362e-06  eta: 1 day, 13:19:24  time: 0.4337  data_time: 0.0088  memory: 5186  grad_norm: 95.0897  loss: 6.4140  decode.loss_cls: 0.1157  decode.loss_mask: 0.2090  decode.loss_dice: 0.2324  decode.d0.loss_cls: 0.8131  decode.d0.loss_mask: 0.2118  decode.d0.loss_dice: 0.2497  decode.d1.loss_cls: 0.1410  decode.d1.loss_mask: 0.2131  decode.d1.loss_dice: 0.2444  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2469  decode.d3.loss_cls: 0.1309  decode.d3.loss_mask: 0.2349  decode.d3.loss_dice: 0.2526  decode.d4.loss_cls: 0.1047  decode.d4.loss_mask: 0.2262  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.1215  decode.d5.loss_mask: 0.2078  decode.d5.loss_dice: 0.2380  decode.d6.loss_cls: 0.1109  decode.d6.loss_mask: 0.2091  decode.d6.loss_dice: 0.2392  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.2078  decode.d7.loss_dice: 0.2249  decode.d8.loss_cls: 0.1098  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2331
09/28 16:28:54 - mmengine - INFO - Iter(train) [ 16500/320000]  base_lr: 9.5347e-05 lr: 9.5347e-06  eta: 1 day, 13:18:53  time: 0.4326  data_time: 0.0087  memory: 5167  grad_norm: 182.8250  loss: 9.0963  decode.loss_cls: 0.1625  decode.loss_mask: 0.3205  decode.loss_dice: 0.2969  decode.d0.loss_cls: 1.2013  decode.d0.loss_mask: 0.3359  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.2778  decode.d1.loss_mask: 0.3241  decode.d1.loss_dice: 0.3026  decode.d2.loss_cls: 0.2111  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.3080  decode.d3.loss_cls: 0.1811  decode.d3.loss_mask: 0.3255  decode.d3.loss_dice: 0.2984  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 0.3286  decode.d4.loss_dice: 0.3065  decode.d5.loss_cls: 0.1545  decode.d5.loss_mask: 0.3222  decode.d5.loss_dice: 0.3141  decode.d6.loss_cls: 0.1461  decode.d6.loss_mask: 0.3206  decode.d6.loss_dice: 0.3075  decode.d7.loss_cls: 0.1440  decode.d7.loss_mask: 0.3240  decode.d7.loss_dice: 0.2970  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 0.3218  decode.d8.loss_dice: 0.2979
09/28 16:29:16 - mmengine - INFO - Iter(train) [ 16550/320000]  base_lr: 9.5333e-05 lr: 9.5333e-06  eta: 1 day, 13:18:23  time: 0.4344  data_time: 0.0087  memory: 5167  grad_norm: 79.3658  loss: 9.9449  decode.loss_cls: 0.3733  decode.loss_mask: 0.2495  decode.loss_dice: 0.2843  decode.d0.loss_cls: 1.1756  decode.d0.loss_mask: 0.2773  decode.d0.loss_dice: 0.3236  decode.d1.loss_cls: 0.3414  decode.d1.loss_mask: 0.2822  decode.d1.loss_dice: 0.2964  decode.d2.loss_cls: 0.4268  decode.d2.loss_mask: 0.2527  decode.d2.loss_dice: 0.2543  decode.d3.loss_cls: 0.4302  decode.d3.loss_mask: 0.2526  decode.d3.loss_dice: 0.2708  decode.d4.loss_cls: 0.3744  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2695  decode.d5.loss_cls: 0.3841  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.2899  decode.d6.loss_cls: 0.3365  decode.d6.loss_mask: 0.2564  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.3779  decode.d7.loss_mask: 0.2560  decode.d7.loss_dice: 0.2837  decode.d8.loss_cls: 0.3521  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.2614
09/28 16:29:38 - mmengine - INFO - Iter(train) [ 16600/320000]  base_lr: 9.5319e-05 lr: 9.5319e-06  eta: 1 day, 13:17:53  time: 0.4337  data_time: 0.0090  memory: 5186  grad_norm: 76.7651  loss: 8.9450  decode.loss_cls: 0.2212  decode.loss_mask: 0.2692  decode.loss_dice: 0.2561  decode.d0.loss_cls: 1.2606  decode.d0.loss_mask: 0.2776  decode.d0.loss_dice: 0.2367  decode.d1.loss_cls: 0.3780  decode.d1.loss_mask: 0.2724  decode.d1.loss_dice: 0.2570  decode.d2.loss_cls: 0.3304  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.2387  decode.d3.loss_cls: 0.2685  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2442  decode.d4.loss_cls: 0.2288  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.2408  decode.d5.loss_cls: 0.3135  decode.d5.loss_mask: 0.2741  decode.d5.loss_dice: 0.2524  decode.d6.loss_cls: 0.3004  decode.d6.loss_mask: 0.2690  decode.d6.loss_dice: 0.2450  decode.d7.loss_cls: 0.2342  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.2397  decode.d8.loss_cls: 0.2340  decode.d8.loss_mask: 0.2717  decode.d8.loss_dice: 0.2386
09/28 16:29:59 - mmengine - INFO - Iter(train) [ 16650/320000]  base_lr: 9.5305e-05 lr: 9.5305e-06  eta: 1 day, 13:17:23  time: 0.4314  data_time: 0.0090  memory: 5167  grad_norm: 176.4210  loss: 9.6807  decode.loss_cls: 0.2405  decode.loss_mask: 0.2648  decode.loss_dice: 0.3045  decode.d0.loss_cls: 1.3563  decode.d0.loss_mask: 0.2542  decode.d0.loss_dice: 0.3196  decode.d1.loss_cls: 0.4450  decode.d1.loss_mask: 0.2571  decode.d1.loss_dice: 0.2771  decode.d2.loss_cls: 0.3497  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.2779  decode.d3.loss_cls: 0.3574  decode.d3.loss_mask: 0.2578  decode.d3.loss_dice: 0.2807  decode.d4.loss_cls: 0.3262  decode.d4.loss_mask: 0.2518  decode.d4.loss_dice: 0.3019  decode.d5.loss_cls: 0.3087  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.3032  decode.d6.loss_cls: 0.2524  decode.d6.loss_mask: 0.2651  decode.d6.loss_dice: 0.2936  decode.d7.loss_cls: 0.2833  decode.d7.loss_mask: 0.2597  decode.d7.loss_dice: 0.2960  decode.d8.loss_cls: 0.2081  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.3031
09/28 16:30:21 - mmengine - INFO - Iter(train) [ 16700/320000]  base_lr: 9.5291e-05 lr: 9.5291e-06  eta: 1 day, 13:16:51  time: 0.4350  data_time: 0.0087  memory: 5186  grad_norm: 150.6056  loss: 11.4977  decode.loss_cls: 0.4020  decode.loss_mask: 0.2412  decode.loss_dice: 0.3446  decode.d0.loss_cls: 1.2564  decode.d0.loss_mask: 0.2426  decode.d0.loss_dice: 0.3443  decode.d1.loss_cls: 0.7242  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.3278  decode.d2.loss_cls: 0.5618  decode.d2.loss_mask: 0.2377  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.5562  decode.d3.loss_mask: 0.2333  decode.d3.loss_dice: 0.3263  decode.d4.loss_cls: 0.4786  decode.d4.loss_mask: 0.2350  decode.d4.loss_dice: 0.3713  decode.d5.loss_cls: 0.4826  decode.d5.loss_mask: 0.2319  decode.d5.loss_dice: 0.3478  decode.d6.loss_cls: 0.4811  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.3103  decode.d7.loss_cls: 0.4330  decode.d7.loss_mask: 0.2659  decode.d7.loss_dice: 0.3187  decode.d8.loss_cls: 0.3948  decode.d8.loss_mask: 0.2338  decode.d8.loss_dice: 0.3256
09/28 16:30:43 - mmengine - INFO - Iter(train) [ 16750/320000]  base_lr: 9.5277e-05 lr: 9.5277e-06  eta: 1 day, 13:16:21  time: 0.4337  data_time: 0.0087  memory: 5167  grad_norm: 38.3712  loss: 5.7779  decode.loss_cls: 0.0459  decode.loss_mask: 0.2237  decode.loss_dice: 0.2137  decode.d0.loss_cls: 0.9494  decode.d0.loss_mask: 0.2253  decode.d0.loss_dice: 0.2327  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 0.2247  decode.d1.loss_dice: 0.1986  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.2213  decode.d2.loss_dice: 0.1957  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.2253  decode.d3.loss_dice: 0.1970  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.2257  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.2278  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.1964  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.2250  decode.d8.loss_dice: 0.2048
09/28 16:31:04 - mmengine - INFO - Iter(train) [ 16800/320000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 1 day, 13:15:51  time: 0.4345  data_time: 0.0088  memory: 5149  grad_norm: 44.1708  loss: 5.5918  decode.loss_cls: 0.0346  decode.loss_mask: 0.2225  decode.loss_dice: 0.1854  decode.d0.loss_cls: 0.8853  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.1488  decode.d1.loss_mask: 0.2335  decode.d1.loss_dice: 0.1828  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.2268  decode.d2.loss_dice: 0.1829  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.2261  decode.d3.loss_dice: 0.1834  decode.d4.loss_cls: 0.0981  decode.d4.loss_mask: 0.2246  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.1860  decode.d6.loss_cls: 0.0353  decode.d6.loss_mask: 0.2267  decode.d6.loss_dice: 0.1852  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.2247  decode.d7.loss_dice: 0.1860  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.2226  decode.d8.loss_dice: 0.1839
09/28 16:31:26 - mmengine - INFO - Iter(train) [ 16850/320000]  base_lr: 9.5248e-05 lr: 9.5248e-06  eta: 1 day, 13:15:21  time: 0.4331  data_time: 0.0087  memory: 5186  grad_norm: 57.1385  loss: 7.1452  decode.loss_cls: 0.1199  decode.loss_mask: 0.2465  decode.loss_dice: 0.2487  decode.d0.loss_cls: 0.9428  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.2653  decode.d1.loss_cls: 0.2224  decode.d1.loss_mask: 0.2415  decode.d1.loss_dice: 0.2391  decode.d2.loss_cls: 0.1380  decode.d2.loss_mask: 0.2418  decode.d2.loss_dice: 0.2597  decode.d3.loss_cls: 0.1562  decode.d3.loss_mask: 0.2468  decode.d3.loss_dice: 0.2418  decode.d4.loss_cls: 0.1536  decode.d4.loss_mask: 0.2462  decode.d4.loss_dice: 0.2645  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.2453  decode.d5.loss_dice: 0.2506  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.2436  decode.d6.loss_dice: 0.2480  decode.d7.loss_cls: 0.1045  decode.d7.loss_mask: 0.2460  decode.d7.loss_dice: 0.2423  decode.d8.loss_cls: 0.1655  decode.d8.loss_mask: 0.2485  decode.d8.loss_dice: 0.2510
09/28 16:31:48 - mmengine - INFO - Iter(train) [ 16900/320000]  base_lr: 9.5234e-05 lr: 9.5234e-06  eta: 1 day, 13:14:51  time: 0.4338  data_time: 0.0087  memory: 5150  grad_norm: 224.7860  loss: 12.4775  decode.loss_cls: 0.3825  decode.loss_mask: 0.4018  decode.loss_dice: 0.3373  decode.d0.loss_cls: 1.1830  decode.d0.loss_mask: 0.3419  decode.d0.loss_dice: 0.3499  decode.d1.loss_cls: 0.4743  decode.d1.loss_mask: 0.3350  decode.d1.loss_dice: 0.3161  decode.d2.loss_cls: 0.5281  decode.d2.loss_mask: 0.3669  decode.d2.loss_dice: 0.3378  decode.d3.loss_cls: 0.4818  decode.d3.loss_mask: 0.3834  decode.d3.loss_dice: 0.3212  decode.d4.loss_cls: 0.4367  decode.d4.loss_mask: 0.3822  decode.d4.loss_dice: 0.3195  decode.d5.loss_cls: 0.4143  decode.d5.loss_mask: 0.4069  decode.d5.loss_dice: 0.3131  decode.d6.loss_cls: 0.4510  decode.d6.loss_mask: 0.4258  decode.d6.loss_dice: 0.3572  decode.d7.loss_cls: 0.4160  decode.d7.loss_mask: 0.4105  decode.d7.loss_dice: 0.3722  decode.d8.loss_cls: 0.4450  decode.d8.loss_mask: 0.4311  decode.d8.loss_dice: 0.3550
09/28 16:32:09 - mmengine - INFO - Iter(train) [ 16950/320000]  base_lr: 9.5220e-05 lr: 9.5220e-06  eta: 1 day, 13:14:21  time: 0.4340  data_time: 0.0087  memory: 5186  grad_norm: 118.7585  loss: 11.7261  decode.loss_cls: 0.3729  decode.loss_mask: 0.3129  decode.loss_dice: 0.3231  decode.d0.loss_cls: 1.4026  decode.d0.loss_mask: 0.3298  decode.d0.loss_dice: 0.3694  decode.d1.loss_cls: 0.5135  decode.d1.loss_mask: 0.3269  decode.d1.loss_dice: 0.3164  decode.d2.loss_cls: 0.5431  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.3106  decode.d3.loss_cls: 0.3841  decode.d3.loss_mask: 0.3142  decode.d3.loss_dice: 0.3329  decode.d4.loss_cls: 0.4686  decode.d4.loss_mask: 0.3060  decode.d4.loss_dice: 0.3113  decode.d5.loss_cls: 0.3650  decode.d5.loss_mask: 0.3191  decode.d5.loss_dice: 0.3179  decode.d6.loss_cls: 0.3923  decode.d6.loss_mask: 0.3180  decode.d6.loss_dice: 0.3390  decode.d7.loss_cls: 0.4467  decode.d7.loss_mask: 0.3146  decode.d7.loss_dice: 0.3058  decode.d8.loss_cls: 0.4257  decode.d8.loss_mask: 0.3172  decode.d8.loss_dice: 0.3171
09/28 16:32:31 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:32:31 - mmengine - INFO - Iter(train) [ 17000/320000]  base_lr: 9.5206e-05 lr: 9.5206e-06  eta: 1 day, 13:13:52  time: 0.4336  data_time: 0.0087  memory: 5186  grad_norm: 84.8421  loss: 9.7862  decode.loss_cls: 0.2268  decode.loss_mask: 0.3458  decode.loss_dice: 0.2370  decode.d0.loss_cls: 1.1284  decode.d0.loss_mask: 0.3566  decode.d0.loss_dice: 0.2949  decode.d1.loss_cls: 0.3188  decode.d1.loss_mask: 0.3454  decode.d1.loss_dice: 0.2359  decode.d2.loss_cls: 0.2933  decode.d2.loss_mask: 0.3632  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.3237  decode.d3.loss_mask: 0.3375  decode.d3.loss_dice: 0.2513  decode.d4.loss_cls: 0.3131  decode.d4.loss_mask: 0.3477  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.2563  decode.d5.loss_mask: 0.3591  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.2960  decode.d6.loss_mask: 0.3448  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.2544  decode.d7.loss_mask: 0.3549  decode.d7.loss_dice: 0.2345  decode.d8.loss_cls: 0.3107  decode.d8.loss_mask: 0.3603  decode.d8.loss_dice: 0.2635
09/28 16:32:53 - mmengine - INFO - Iter(train) [ 17050/320000]  base_lr: 9.5192e-05 lr: 9.5192e-06  eta: 1 day, 13:13:23  time: 0.4334  data_time: 0.0086  memory: 5186  grad_norm: 41.6580  loss: 6.5407  decode.loss_cls: 0.1413  decode.loss_mask: 0.2172  decode.loss_dice: 0.2230  decode.d0.loss_cls: 0.9005  decode.d0.loss_mask: 0.2217  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.2250  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.2229  decode.d2.loss_cls: 0.1628  decode.d2.loss_mask: 0.2170  decode.d2.loss_dice: 0.2084  decode.d3.loss_cls: 0.1148  decode.d3.loss_mask: 0.2169  decode.d3.loss_dice: 0.2144  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.2058  decode.d5.loss_cls: 0.1072  decode.d5.loss_mask: 0.2190  decode.d5.loss_dice: 0.2258  decode.d6.loss_cls: 0.1409  decode.d6.loss_mask: 0.2180  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.1224  decode.d7.loss_mask: 0.2180  decode.d7.loss_dice: 0.2401  decode.d8.loss_cls: 0.1407  decode.d8.loss_mask: 0.2174  decode.d8.loss_dice: 0.2055
09/28 16:33:14 - mmengine - INFO - Iter(train) [ 17100/320000]  base_lr: 9.5178e-05 lr: 9.5178e-06  eta: 1 day, 13:12:53  time: 0.4340  data_time: 0.0087  memory: 5167  grad_norm: 61.0176  loss: 7.8378  decode.loss_cls: 0.1800  decode.loss_mask: 0.2612  decode.loss_dice: 0.2520  decode.d0.loss_cls: 0.9619  decode.d0.loss_mask: 0.2604  decode.d0.loss_dice: 0.2655  decode.d1.loss_cls: 0.2378  decode.d1.loss_mask: 0.2530  decode.d1.loss_dice: 0.2283  decode.d2.loss_cls: 0.1857  decode.d2.loss_mask: 0.2740  decode.d2.loss_dice: 0.2780  decode.d3.loss_cls: 0.1098  decode.d3.loss_mask: 0.2810  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.1344  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.2730  decode.d5.loss_cls: 0.1769  decode.d5.loss_mask: 0.2682  decode.d5.loss_dice: 0.2832  decode.d6.loss_cls: 0.1313  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2287  decode.d7.loss_cls: 0.2366  decode.d7.loss_mask: 0.2579  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.2611  decode.d8.loss_mask: 0.2496  decode.d8.loss_dice: 0.2418
09/28 16:33:36 - mmengine - INFO - Iter(train) [ 17150/320000]  base_lr: 9.5164e-05 lr: 9.5164e-06  eta: 1 day, 13:12:24  time: 0.4358  data_time: 0.0091  memory: 5166  grad_norm: 76.7583  loss: 8.0833  decode.loss_cls: 0.2660  decode.loss_mask: 0.2440  decode.loss_dice: 0.2326  decode.d0.loss_cls: 0.9950  decode.d0.loss_mask: 0.2493  decode.d0.loss_dice: 0.2537  decode.d1.loss_cls: 0.2487  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.2216  decode.d2.loss_cls: 0.2480  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2342  decode.d3.loss_cls: 0.2518  decode.d3.loss_mask: 0.2443  decode.d3.loss_dice: 0.2219  decode.d4.loss_cls: 0.2283  decode.d4.loss_mask: 0.2454  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.2942  decode.d5.loss_mask: 0.2453  decode.d5.loss_dice: 0.2370  decode.d6.loss_cls: 0.2512  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2198  decode.d7.loss_cls: 0.2329  decode.d7.loss_mask: 0.2514  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.2701  decode.d8.loss_mask: 0.2417  decode.d8.loss_dice: 0.2357
09/28 16:33:58 - mmengine - INFO - Iter(train) [ 17200/320000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 1 day, 13:11:56  time: 0.4346  data_time: 0.0090  memory: 5167  grad_norm: 62.3080  loss: 8.5054  decode.loss_cls: 0.1473  decode.loss_mask: 0.3202  decode.loss_dice: 0.2491  decode.d0.loss_cls: 1.0759  decode.d0.loss_mask: 0.3013  decode.d0.loss_dice: 0.2227  decode.d1.loss_cls: 0.1592  decode.d1.loss_mask: 0.2951  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.1523  decode.d2.loss_mask: 0.3790  decode.d2.loss_dice: 0.2644  decode.d3.loss_cls: 0.1702  decode.d3.loss_mask: 0.3508  decode.d3.loss_dice: 0.2619  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.4735  decode.d4.loss_dice: 0.2703  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.4573  decode.d5.loss_dice: 0.2693  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.2542  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 0.3732  decode.d7.loss_dice: 0.2933  decode.d8.loss_cls: 0.2056  decode.d8.loss_mask: 0.2921  decode.d8.loss_dice: 0.2271
09/28 16:34:20 - mmengine - INFO - Iter(train) [ 17250/320000]  base_lr: 9.5135e-05 lr: 9.5135e-06  eta: 1 day, 13:11:27  time: 0.4345  data_time: 0.0090  memory: 5166  grad_norm: 102.2265  loss: 8.9962  decode.loss_cls: 0.3137  decode.loss_mask: 0.2488  decode.loss_dice: 0.2600  decode.d0.loss_cls: 1.1226  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.3179  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 0.2652  decode.d1.loss_dice: 0.3009  decode.d2.loss_cls: 0.2792  decode.d2.loss_mask: 0.2542  decode.d2.loss_dice: 0.3023  decode.d3.loss_cls: 0.2747  decode.d3.loss_mask: 0.2606  decode.d3.loss_dice: 0.2790  decode.d4.loss_cls: 0.2580  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2647  decode.d5.loss_cls: 0.2483  decode.d5.loss_mask: 0.2568  decode.d5.loss_dice: 0.2762  decode.d6.loss_cls: 0.2737  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2595  decode.d7.loss_cls: 0.2577  decode.d7.loss_mask: 0.2528  decode.d7.loss_dice: 0.2753  decode.d8.loss_cls: 0.3397  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2639
09/28 16:34:41 - mmengine - INFO - Iter(train) [ 17300/320000]  base_lr: 9.5121e-05 lr: 9.5121e-06  eta: 1 day, 13:10:58  time: 0.4350  data_time: 0.0091  memory: 5186  grad_norm: 111.6608  loss: 6.5242  decode.loss_cls: 0.0489  decode.loss_mask: 0.2730  decode.loss_dice: 0.2193  decode.d0.loss_cls: 0.9688  decode.d0.loss_mask: 0.2762  decode.d0.loss_dice: 0.2391  decode.d1.loss_cls: 0.1099  decode.d1.loss_mask: 0.2708  decode.d1.loss_dice: 0.2319  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.3234  decode.d2.loss_dice: 0.2415  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.2932  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.0446  decode.d4.loss_mask: 0.2802  decode.d4.loss_dice: 0.2195  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.2755  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.0456  decode.d6.loss_mask: 0.2743  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.2714  decode.d7.loss_dice: 0.2257  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2209
09/28 16:35:03 - mmengine - INFO - Iter(train) [ 17350/320000]  base_lr: 9.5107e-05 lr: 9.5107e-06  eta: 1 day, 13:10:30  time: 0.4345  data_time: 0.0091  memory: 5150  grad_norm: 66.3890  loss: 6.4259  decode.loss_cls: 0.0432  decode.loss_mask: 0.2906  decode.loss_dice: 0.1947  decode.d0.loss_cls: 0.8511  decode.d0.loss_mask: 0.2973  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.1551  decode.d1.loss_mask: 0.2928  decode.d1.loss_dice: 0.2152  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.2879  decode.d2.loss_dice: 0.2084  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.2953  decode.d3.loss_dice: 0.2065  decode.d4.loss_cls: 0.0854  decode.d4.loss_mask: 0.2903  decode.d4.loss_dice: 0.2007  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 0.2900  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.2929  decode.d6.loss_dice: 0.2109  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.2929  decode.d7.loss_dice: 0.2014  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.2911  decode.d8.loss_dice: 0.1983
09/28 16:35:25 - mmengine - INFO - Iter(train) [ 17400/320000]  base_lr: 9.5093e-05 lr: 9.5093e-06  eta: 1 day, 13:10:01  time: 0.4345  data_time: 0.0091  memory: 5150  grad_norm: 126.0413  loss: 7.2658  decode.loss_cls: 0.1623  decode.loss_mask: 0.2089  decode.loss_dice: 0.2111  decode.d0.loss_cls: 1.1139  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2251  decode.d1.loss_cls: 0.1971  decode.d1.loss_mask: 0.2124  decode.d1.loss_dice: 0.2236  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 0.2070  decode.d2.loss_dice: 0.1949  decode.d3.loss_cls: 0.1377  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2369  decode.d4.loss_cls: 0.1842  decode.d4.loss_mask: 0.2513  decode.d4.loss_dice: 0.2282  decode.d5.loss_cls: 0.2151  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.2346  decode.d6.loss_cls: 0.1938  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.2587  decode.d7.loss_cls: 0.1952  decode.d7.loss_mask: 0.2093  decode.d7.loss_dice: 0.2095  decode.d8.loss_cls: 0.1603  decode.d8.loss_mask: 0.2081  decode.d8.loss_dice: 0.2322
09/28 16:35:47 - mmengine - INFO - Iter(train) [ 17450/320000]  base_lr: 9.5079e-05 lr: 9.5079e-06  eta: 1 day, 13:09:33  time: 0.4344  data_time: 0.0091  memory: 5150  grad_norm: 49.9735  loss: 7.4617  decode.loss_cls: 0.1681  decode.loss_mask: 0.2867  decode.loss_dice: 0.2475  decode.d0.loss_cls: 0.8639  decode.d0.loss_mask: 0.2968  decode.d0.loss_dice: 0.2814  decode.d1.loss_cls: 0.1956  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.2543  decode.d2.loss_cls: 0.1406  decode.d2.loss_mask: 0.2902  decode.d2.loss_dice: 0.2367  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.2835  decode.d4.loss_dice: 0.2572  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 0.2846  decode.d5.loss_dice: 0.2502  decode.d6.loss_cls: 0.1466  decode.d6.loss_mask: 0.2865  decode.d6.loss_dice: 0.2559  decode.d7.loss_cls: 0.0945  decode.d7.loss_mask: 0.2823  decode.d7.loss_dice: 0.2440  decode.d8.loss_cls: 0.0961  decode.d8.loss_mask: 0.2839  decode.d8.loss_dice: 0.2495
09/28 16:36:08 - mmengine - INFO - Iter(train) [ 17500/320000]  base_lr: 9.5065e-05 lr: 9.5065e-06  eta: 1 day, 13:09:03  time: 0.4332  data_time: 0.0091  memory: 5150  grad_norm: 236.3378  loss: 10.7701  decode.loss_cls: 0.3109  decode.loss_mask: 0.2820  decode.loss_dice: 0.3830  decode.d0.loss_cls: 1.3590  decode.d0.loss_mask: 0.2936  decode.d0.loss_dice: 0.3738  decode.d1.loss_cls: 0.3903  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3246  decode.d2.loss_cls: 0.3274  decode.d2.loss_mask: 0.2797  decode.d2.loss_dice: 0.3828  decode.d3.loss_cls: 0.3739  decode.d3.loss_mask: 0.2765  decode.d3.loss_dice: 0.3256  decode.d4.loss_cls: 0.3192  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.3616  decode.d5.loss_cls: 0.3467  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.3673  decode.d6.loss_cls: 0.3274  decode.d6.loss_mask: 0.2781  decode.d6.loss_dice: 0.3710  decode.d7.loss_cls: 0.2855  decode.d7.loss_mask: 0.2933  decode.d7.loss_dice: 0.3528  decode.d8.loss_cls: 0.2716  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.3965
09/28 16:36:30 - mmengine - INFO - Iter(train) [ 17550/320000]  base_lr: 9.5051e-05 lr: 9.5051e-06  eta: 1 day, 13:08:32  time: 0.4311  data_time: 0.0090  memory: 5150  grad_norm: 180.9401  loss: 10.9748  decode.loss_cls: 0.4242  decode.loss_mask: 0.3282  decode.loss_dice: 0.3235  decode.d0.loss_cls: 1.0448  decode.d0.loss_mask: 0.3363  decode.d0.loss_dice: 0.3260  decode.d1.loss_cls: 0.4795  decode.d1.loss_mask: 0.3143  decode.d1.loss_dice: 0.3259  decode.d2.loss_cls: 0.3444  decode.d2.loss_mask: 0.3134  decode.d2.loss_dice: 0.2839  decode.d3.loss_cls: 0.4582  decode.d3.loss_mask: 0.3071  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.4462  decode.d4.loss_mask: 0.3229  decode.d4.loss_dice: 0.3039  decode.d5.loss_cls: 0.3261  decode.d5.loss_mask: 0.3337  decode.d5.loss_dice: 0.2830  decode.d6.loss_cls: 0.3437  decode.d6.loss_mask: 0.3181  decode.d6.loss_dice: 0.2960  decode.d7.loss_cls: 0.4228  decode.d7.loss_mask: 0.3240  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.4100  decode.d8.loss_mask: 0.3144  decode.d8.loss_dice: 0.3066
09/28 16:36:52 - mmengine - INFO - Iter(train) [ 17600/320000]  base_lr: 9.5036e-05 lr: 9.5036e-06  eta: 1 day, 13:08:01  time: 0.4318  data_time: 0.0091  memory: 5186  grad_norm: 145.3406  loss: 7.2452  decode.loss_cls: 0.1225  decode.loss_mask: 0.2859  decode.loss_dice: 0.2370  decode.d0.loss_cls: 0.9761  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.1530  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.2882  decode.d2.loss_dice: 0.2398  decode.d3.loss_cls: 0.1185  decode.d3.loss_mask: 0.2851  decode.d3.loss_dice: 0.2430  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.2875  decode.d4.loss_dice: 0.2441  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.2890  decode.d5.loss_dice: 0.2462  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.2421  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 0.2842  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 0.2869  decode.d8.loss_dice: 0.2384
09/28 16:37:13 - mmengine - INFO - Iter(train) [ 17650/320000]  base_lr: 9.5022e-05 lr: 9.5022e-06  eta: 1 day, 13:07:30  time: 0.4322  data_time: 0.0091  memory: 5167  grad_norm: 60.4915  loss: 5.5243  decode.loss_cls: 0.0141  decode.loss_mask: 0.2518  decode.loss_dice: 0.1929  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 0.2559  decode.d0.loss_dice: 0.1974  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.2594  decode.d1.loss_dice: 0.2017  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.2506  decode.d2.loss_dice: 0.1932  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.1903  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.2549  decode.d4.loss_dice: 0.1959  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.2531  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.2535  decode.d6.loss_dice: 0.1941  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.2502  decode.d7.loss_dice: 0.1917  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.1943
09/28 16:37:35 - mmengine - INFO - Iter(train) [ 17700/320000]  base_lr: 9.5008e-05 lr: 9.5008e-06  eta: 1 day, 13:06:59  time: 0.4322  data_time: 0.0089  memory: 5166  grad_norm: 161.3343  loss: 7.7928  decode.loss_cls: 0.1181  decode.loss_mask: 0.2848  decode.loss_dice: 0.2522  decode.d0.loss_cls: 1.0568  decode.d0.loss_mask: 0.2959  decode.d0.loss_dice: 0.2847  decode.d1.loss_cls: 0.1539  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.2876  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.2913  decode.d2.loss_dice: 0.2608  decode.d3.loss_cls: 0.0979  decode.d3.loss_mask: 0.2852  decode.d3.loss_dice: 0.2672  decode.d4.loss_cls: 0.1038  decode.d4.loss_mask: 0.2931  decode.d4.loss_dice: 0.2670  decode.d5.loss_cls: 0.1163  decode.d5.loss_mask: 0.2928  decode.d5.loss_dice: 0.2796  decode.d6.loss_cls: 0.1808  decode.d6.loss_mask: 0.2845  decode.d6.loss_dice: 0.2810  decode.d7.loss_cls: 0.1208  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.2590  decode.d8.loss_cls: 0.1349  decode.d8.loss_mask: 0.2859  decode.d8.loss_dice: 0.2736
09/28 16:37:57 - mmengine - INFO - Iter(train) [ 17750/320000]  base_lr: 9.4994e-05 lr: 9.4994e-06  eta: 1 day, 13:06:32  time: 0.4497  data_time: 0.0090  memory: 5166  grad_norm: 100.9536  loss: 7.5922  decode.loss_cls: 0.2404  decode.loss_mask: 0.2485  decode.loss_dice: 0.2120  decode.d0.loss_cls: 0.9681  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.2281  decode.d1.loss_cls: 0.2244  decode.d1.loss_mask: 0.2513  decode.d1.loss_dice: 0.2078  decode.d2.loss_cls: 0.2523  decode.d2.loss_mask: 0.2474  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.2470  decode.d3.loss_dice: 0.2179  decode.d4.loss_cls: 0.1915  decode.d4.loss_mask: 0.2485  decode.d4.loss_dice: 0.2155  decode.d5.loss_cls: 0.1809  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2059  decode.d6.loss_cls: 0.2115  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.2110  decode.d7.loss_cls: 0.2353  decode.d7.loss_mask: 0.2516  decode.d7.loss_dice: 0.2112  decode.d8.loss_cls: 0.2440  decode.d8.loss_mask: 0.2466  decode.d8.loss_dice: 0.2126
09/28 16:38:18 - mmengine - INFO - Iter(train) [ 17800/320000]  base_lr: 9.4980e-05 lr: 9.4980e-06  eta: 1 day, 13:06:01  time: 0.4313  data_time: 0.0090  memory: 5166  grad_norm: 50.0181  loss: 7.5039  decode.loss_cls: 0.1444  decode.loss_mask: 0.3175  decode.loss_dice: 0.1887  decode.d0.loss_cls: 0.9364  decode.d0.loss_mask: 0.3276  decode.d0.loss_dice: 0.2011  decode.d1.loss_cls: 0.2373  decode.d1.loss_mask: 0.3185  decode.d1.loss_dice: 0.1870  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.3164  decode.d2.loss_dice: 0.1944  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 0.3135  decode.d3.loss_dice: 0.1892  decode.d4.loss_cls: 0.1644  decode.d4.loss_mask: 0.3105  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.1706  decode.d5.loss_mask: 0.3107  decode.d5.loss_dice: 0.1896  decode.d6.loss_cls: 0.1801  decode.d6.loss_mask: 0.3167  decode.d6.loss_dice: 0.1904  decode.d7.loss_cls: 0.1698  decode.d7.loss_mask: 0.3194  decode.d7.loss_dice: 0.1909  decode.d8.loss_cls: 0.1411  decode.d8.loss_mask: 0.3160  decode.d8.loss_dice: 0.1845
09/28 16:38:40 - mmengine - INFO - Iter(train) [ 17850/320000]  base_lr: 9.4966e-05 lr: 9.4966e-06  eta: 1 day, 13:05:30  time: 0.4324  data_time: 0.0092  memory: 5167  grad_norm: 79.2189  loss: 7.9399  decode.loss_cls: 0.2687  decode.loss_mask: 0.2513  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.9972  decode.d0.loss_mask: 0.2620  decode.d0.loss_dice: 0.2183  decode.d1.loss_cls: 0.2323  decode.d1.loss_mask: 0.2467  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.2858  decode.d2.loss_mask: 0.2580  decode.d2.loss_dice: 0.1928  decode.d3.loss_cls: 0.2818  decode.d3.loss_mask: 0.2565  decode.d3.loss_dice: 0.1921  decode.d4.loss_cls: 0.2839  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.1931  decode.d5.loss_cls: 0.2471  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.1913  decode.d6.loss_cls: 0.2975  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.1899  decode.d7.loss_cls: 0.2722  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.1928  decode.d8.loss_cls: 0.2772  decode.d8.loss_mask: 0.2515  decode.d8.loss_dice: 0.1861
09/28 16:39:01 - mmengine - INFO - Iter(train) [ 17900/320000]  base_lr: 9.4952e-05 lr: 9.4952e-06  eta: 1 day, 13:05:00  time: 0.4321  data_time: 0.0091  memory: 5167  grad_norm: 22.0911  loss: 5.6596  decode.loss_cls: 0.0451  decode.loss_mask: 0.2386  decode.loss_dice: 0.1979  decode.d0.loss_cls: 0.8853  decode.d0.loss_mask: 0.2360  decode.d0.loss_dice: 0.2054  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.2372  decode.d1.loss_dice: 0.1897  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.1908  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.2369  decode.d4.loss_dice: 0.1965  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.1940  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.2371  decode.d7.loss_dice: 0.1930  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.1915
09/28 16:39:23 - mmengine - INFO - Iter(train) [ 17950/320000]  base_lr: 9.4937e-05 lr: 9.4937e-06  eta: 1 day, 13:04:30  time: 0.4314  data_time: 0.0089  memory: 5186  grad_norm: 67.2662  loss: 8.3437  decode.loss_cls: 0.2575  decode.loss_mask: 0.2918  decode.loss_dice: 0.2666  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 0.2364  decode.d0.loss_dice: 0.2338  decode.d1.loss_cls: 0.2065  decode.d1.loss_mask: 0.2575  decode.d1.loss_dice: 0.2425  decode.d2.loss_cls: 0.2167  decode.d2.loss_mask: 0.2628  decode.d2.loss_dice: 0.2341  decode.d3.loss_cls: 0.2472  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.2530  decode.d4.loss_cls: 0.2732  decode.d4.loss_mask: 0.2737  decode.d4.loss_dice: 0.2383  decode.d5.loss_cls: 0.2305  decode.d5.loss_mask: 0.3234  decode.d5.loss_dice: 0.2498  decode.d6.loss_cls: 0.2419  decode.d6.loss_mask: 0.3000  decode.d6.loss_dice: 0.2498  decode.d7.loss_cls: 0.2411  decode.d7.loss_mask: 0.2764  decode.d7.loss_dice: 0.2441  decode.d8.loss_cls: 0.2289  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.2471
09/28 16:39:45 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:39:45 - mmengine - INFO - Iter(train) [ 18000/320000]  base_lr: 9.4923e-05 lr: 9.4923e-06  eta: 1 day, 13:04:01  time: 0.4355  data_time: 0.0091  memory: 5148  grad_norm: 80.3178  loss: 7.5991  decode.loss_cls: 0.1441  decode.loss_mask: 0.2877  decode.loss_dice: 0.2385  decode.d0.loss_cls: 1.1502  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.2367  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 0.2872  decode.d1.loss_dice: 0.2360  decode.d2.loss_cls: 0.1346  decode.d2.loss_mask: 0.3107  decode.d2.loss_dice: 0.2477  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.3148  decode.d3.loss_dice: 0.2400  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 0.3258  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.3201  decode.d5.loss_dice: 0.2524  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.3195  decode.d6.loss_dice: 0.2399  decode.d7.loss_cls: 0.1251  decode.d7.loss_mask: 0.2914  decode.d7.loss_dice: 0.2388  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 0.2969  decode.d8.loss_dice: 0.2408
09/28 16:40:06 - mmengine - INFO - Iter(train) [ 18050/320000]  base_lr: 9.4909e-05 lr: 9.4909e-06  eta: 1 day, 13:03:33  time: 0.4349  data_time: 0.0090  memory: 5167  grad_norm: 98.3831  loss: 8.0059  decode.loss_cls: 0.1448  decode.loss_mask: 0.3144  decode.loss_dice: 0.2635  decode.d0.loss_cls: 0.9322  decode.d0.loss_mask: 0.3102  decode.d0.loss_dice: 0.2588  decode.d1.loss_cls: 0.2352  decode.d1.loss_mask: 0.3010  decode.d1.loss_dice: 0.2309  decode.d2.loss_cls: 0.1959  decode.d2.loss_mask: 0.3061  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 0.2953  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.1810  decode.d4.loss_mask: 0.2960  decode.d4.loss_dice: 0.2486  decode.d5.loss_cls: 0.1198  decode.d5.loss_mask: 0.2967  decode.d5.loss_dice: 0.2314  decode.d6.loss_cls: 0.1874  decode.d6.loss_mask: 0.3122  decode.d6.loss_dice: 0.2661  decode.d7.loss_cls: 0.1941  decode.d7.loss_mask: 0.3020  decode.d7.loss_dice: 0.2559  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 0.3149  decode.d8.loss_dice: 0.2669
09/28 16:40:28 - mmengine - INFO - Iter(train) [ 18100/320000]  base_lr: 9.4895e-05 lr: 9.4895e-06  eta: 1 day, 13:03:05  time: 0.4352  data_time: 0.0092  memory: 5186  grad_norm: 57.9547  loss: 7.5075  decode.loss_cls: 0.1129  decode.loss_mask: 0.3027  decode.loss_dice: 0.2363  decode.d0.loss_cls: 0.8884  decode.d0.loss_mask: 0.3096  decode.d0.loss_dice: 0.2562  decode.d1.loss_cls: 0.1454  decode.d1.loss_mask: 0.2977  decode.d1.loss_dice: 0.2479  decode.d2.loss_cls: 0.1510  decode.d2.loss_mask: 0.3026  decode.d2.loss_dice: 0.2367  decode.d3.loss_cls: 0.1652  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.2324  decode.d4.loss_cls: 0.1143  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.2529  decode.d5.loss_cls: 0.1291  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.2304  decode.d6.loss_cls: 0.1354  decode.d6.loss_mask: 0.2917  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.1406  decode.d7.loss_mask: 0.2933  decode.d7.loss_dice: 0.2323  decode.d8.loss_cls: 0.1352  decode.d8.loss_mask: 0.3001  decode.d8.loss_dice: 0.2279
09/28 16:40:50 - mmengine - INFO - Iter(train) [ 18150/320000]  base_lr: 9.4881e-05 lr: 9.4881e-06  eta: 1 day, 13:02:37  time: 0.4348  data_time: 0.0092  memory: 5167  grad_norm: 73.2217  loss: 8.1986  decode.loss_cls: 0.1227  decode.loss_mask: 0.3234  decode.loss_dice: 0.2705  decode.d0.loss_cls: 0.9144  decode.d0.loss_mask: 0.3247  decode.d0.loss_dice: 0.3048  decode.d1.loss_cls: 0.1638  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.2817  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.3044  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 0.3158  decode.d3.loss_dice: 0.2853  decode.d4.loss_cls: 0.1400  decode.d4.loss_mask: 0.3192  decode.d4.loss_dice: 0.2944  decode.d5.loss_cls: 0.1448  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.2789  decode.d6.loss_cls: 0.1192  decode.d6.loss_mask: 0.3204  decode.d6.loss_dice: 0.2992  decode.d7.loss_cls: 0.1183  decode.d7.loss_mask: 0.3206  decode.d7.loss_dice: 0.2660  decode.d8.loss_cls: 0.1131  decode.d8.loss_mask: 0.3180  decode.d8.loss_dice: 0.2934
09/28 16:41:12 - mmengine - INFO - Iter(train) [ 18200/320000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 1 day, 13:02:10  time: 0.4346  data_time: 0.0092  memory: 5167  grad_norm: 179.7962  loss: 9.7574  decode.loss_cls: 0.2719  decode.loss_mask: 0.3568  decode.loss_dice: 0.2884  decode.d0.loss_cls: 0.8760  decode.d0.loss_mask: 0.3503  decode.d0.loss_dice: 0.2876  decode.d1.loss_cls: 0.2615  decode.d1.loss_mask: 0.3469  decode.d1.loss_dice: 0.2815  decode.d2.loss_cls: 0.2180  decode.d2.loss_mask: 0.3621  decode.d2.loss_dice: 0.2804  decode.d3.loss_cls: 0.3679  decode.d3.loss_mask: 0.3460  decode.d3.loss_dice: 0.2784  decode.d4.loss_cls: 0.2231  decode.d4.loss_mask: 0.3738  decode.d4.loss_dice: 0.2916  decode.d5.loss_cls: 0.2688  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.2759  decode.d6.loss_mask: 0.3496  decode.d6.loss_dice: 0.2800  decode.d7.loss_cls: 0.2949  decode.d7.loss_mask: 0.3442  decode.d7.loss_dice: 0.2770  decode.d8.loss_cls: 0.3406  decode.d8.loss_mask: 0.3403  decode.d8.loss_dice: 0.3002
09/28 16:41:33 - mmengine - INFO - Iter(train) [ 18250/320000]  base_lr: 9.4853e-05 lr: 9.4853e-06  eta: 1 day, 13:01:42  time: 0.4351  data_time: 0.0091  memory: 5186  grad_norm: 61.7589  loss: 6.8131  decode.loss_cls: 0.1271  decode.loss_mask: 0.2969  decode.loss_dice: 0.1891  decode.d0.loss_cls: 1.0332  decode.d0.loss_mask: 0.2946  decode.d0.loss_dice: 0.2155  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.1959  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.2925  decode.d2.loss_dice: 0.1922  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.3011  decode.d3.loss_dice: 0.1962  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.2960  decode.d4.loss_dice: 0.1976  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.2923  decode.d5.loss_dice: 0.1899  decode.d6.loss_cls: 0.1207  decode.d6.loss_mask: 0.2975  decode.d6.loss_dice: 0.1975  decode.d7.loss_cls: 0.1345  decode.d7.loss_mask: 0.2931  decode.d7.loss_dice: 0.1914  decode.d8.loss_cls: 0.1194  decode.d8.loss_mask: 0.2930  decode.d8.loss_dice: 0.1917
09/28 16:41:55 - mmengine - INFO - Iter(train) [ 18300/320000]  base_lr: 9.4838e-05 lr: 9.4838e-06  eta: 1 day, 13:01:14  time: 0.4350  data_time: 0.0092  memory: 5186  grad_norm: 65.4966  loss: 7.3528  decode.loss_cls: 0.1147  decode.loss_mask: 0.2589  decode.loss_dice: 0.1961  decode.d0.loss_cls: 1.3085  decode.d0.loss_mask: 0.2802  decode.d0.loss_dice: 0.2482  decode.d1.loss_cls: 0.2670  decode.d1.loss_mask: 0.2567  decode.d1.loss_dice: 0.2094  decode.d2.loss_cls: 0.1744  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.1964  decode.d3.loss_cls: 0.1707  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.1978  decode.d4.loss_cls: 0.1503  decode.d4.loss_mask: 0.2652  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.1178  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.1138  decode.d6.loss_mask: 0.2637  decode.d6.loss_dice: 0.2071  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.2647  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.1125  decode.d8.loss_mask: 0.2615  decode.d8.loss_dice: 0.1982
09/28 16:42:17 - mmengine - INFO - Iter(train) [ 18350/320000]  base_lr: 9.4824e-05 lr: 9.4824e-06  eta: 1 day, 13:00:45  time: 0.4319  data_time: 0.0091  memory: 5150  grad_norm: 111.8669  loss: 7.8927  decode.loss_cls: 0.1135  decode.loss_mask: 0.3441  decode.loss_dice: 0.2538  decode.d0.loss_cls: 1.0171  decode.d0.loss_mask: 0.3368  decode.d0.loss_dice: 0.2686  decode.d1.loss_cls: 0.1601  decode.d1.loss_mask: 0.3331  decode.d1.loss_dice: 0.2488  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.3388  decode.d2.loss_dice: 0.2555  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.3353  decode.d3.loss_dice: 0.2546  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.3391  decode.d4.loss_dice: 0.2516  decode.d5.loss_cls: 0.0966  decode.d5.loss_mask: 0.3359  decode.d5.loss_dice: 0.2607  decode.d6.loss_cls: 0.1089  decode.d6.loss_mask: 0.3430  decode.d6.loss_dice: 0.2569  decode.d7.loss_cls: 0.1050  decode.d7.loss_mask: 0.3368  decode.d7.loss_dice: 0.2469  decode.d8.loss_cls: 0.1184  decode.d8.loss_mask: 0.3396  decode.d8.loss_dice: 0.2542
09/28 16:42:38 - mmengine - INFO - Iter(train) [ 18400/320000]  base_lr: 9.4810e-05 lr: 9.4810e-06  eta: 1 day, 13:00:15  time: 0.4322  data_time: 0.0091  memory: 5167  grad_norm: 41.9765  loss: 7.2649  decode.loss_cls: 0.1802  decode.loss_mask: 0.2503  decode.loss_dice: 0.1922  decode.d0.loss_cls: 0.9426  decode.d0.loss_mask: 0.3480  decode.d0.loss_dice: 0.2202  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.3441  decode.d1.loss_dice: 0.1988  decode.d2.loss_cls: 0.1431  decode.d2.loss_mask: 0.2575  decode.d2.loss_dice: 0.2015  decode.d3.loss_cls: 0.1632  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.1959  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 0.3427  decode.d4.loss_dice: 0.2067  decode.d5.loss_cls: 0.1108  decode.d5.loss_mask: 0.3445  decode.d5.loss_dice: 0.2065  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.3438  decode.d6.loss_dice: 0.2042  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 0.2561  decode.d7.loss_dice: 0.1974  decode.d8.loss_cls: 0.1767  decode.d8.loss_mask: 0.2554  decode.d8.loss_dice: 0.1973
09/28 16:43:00 - mmengine - INFO - Iter(train) [ 18450/320000]  base_lr: 9.4796e-05 lr: 9.4796e-06  eta: 1 day, 12:59:45  time: 0.4320  data_time: 0.0090  memory: 5167  grad_norm: 102.0739  loss: 9.6042  decode.loss_cls: 0.1618  decode.loss_mask: 0.4092  decode.loss_dice: 0.2703  decode.d0.loss_cls: 1.1515  decode.d0.loss_mask: 0.4103  decode.d0.loss_dice: 0.2725  decode.d1.loss_cls: 0.1860  decode.d1.loss_mask: 0.4269  decode.d1.loss_dice: 0.2649  decode.d2.loss_cls: 0.1669  decode.d2.loss_mask: 0.4212  decode.d2.loss_dice: 0.2538  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 0.4219  decode.d3.loss_dice: 0.2757  decode.d4.loss_cls: 0.1532  decode.d4.loss_mask: 0.4115  decode.d4.loss_dice: 0.2570  decode.d5.loss_cls: 0.1694  decode.d5.loss_mask: 0.4069  decode.d5.loss_dice: 0.2713  decode.d6.loss_cls: 0.1703  decode.d6.loss_mask: 0.4056  decode.d6.loss_dice: 0.2641  decode.d7.loss_cls: 0.1828  decode.d7.loss_mask: 0.4306  decode.d7.loss_dice: 0.3028  decode.d8.loss_cls: 0.1562  decode.d8.loss_mask: 0.4670  decode.d8.loss_dice: 0.3187
09/28 16:43:22 - mmengine - INFO - Iter(train) [ 18500/320000]  base_lr: 9.4782e-05 lr: 9.4782e-06  eta: 1 day, 12:59:15  time: 0.4316  data_time: 0.0089  memory: 5186  grad_norm: 63.2320  loss: 7.3582  decode.loss_cls: 0.0571  decode.loss_mask: 0.3309  decode.loss_dice: 0.2259  decode.d0.loss_cls: 0.9320  decode.d0.loss_mask: 0.3407  decode.d0.loss_dice: 0.2341  decode.d1.loss_cls: 0.1299  decode.d1.loss_mask: 0.3295  decode.d1.loss_dice: 0.2294  decode.d2.loss_cls: 0.1158  decode.d2.loss_mask: 0.3255  decode.d2.loss_dice: 0.2337  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.3301  decode.d3.loss_dice: 0.2350  decode.d4.loss_cls: 0.1120  decode.d4.loss_mask: 0.3313  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.1129  decode.d5.loss_mask: 0.3320  decode.d5.loss_dice: 0.2343  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.3283  decode.d6.loss_dice: 0.2309  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.3236  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.3305  decode.d8.loss_dice: 0.2281
09/28 16:43:43 - mmengine - INFO - Iter(train) [ 18550/320000]  base_lr: 9.4768e-05 lr: 9.4768e-06  eta: 1 day, 12:58:44  time: 0.4321  data_time: 0.0089  memory: 5166  grad_norm: 72.1079  loss: 8.8626  decode.loss_cls: 0.2340  decode.loss_mask: 0.2642  decode.loss_dice: 0.2758  decode.d0.loss_cls: 1.1718  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.3225  decode.d1.loss_cls: 0.3466  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.2610  decode.d2.loss_cls: 0.2438  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2798  decode.d3.loss_cls: 0.2057  decode.d3.loss_mask: 0.2594  decode.d3.loss_dice: 0.2653  decode.d4.loss_cls: 0.2180  decode.d4.loss_mask: 0.2580  decode.d4.loss_dice: 0.2904  decode.d5.loss_cls: 0.2022  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.2902  decode.d6.loss_cls: 0.3009  decode.d6.loss_mask: 0.2670  decode.d6.loss_dice: 0.2894  decode.d7.loss_cls: 0.2554  decode.d7.loss_mask: 0.2577  decode.d7.loss_dice: 0.2993  decode.d8.loss_cls: 0.2070  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.2921
09/28 16:44:05 - mmengine - INFO - Iter(train) [ 18600/320000]  base_lr: 9.4753e-05 lr: 9.4753e-06  eta: 1 day, 12:58:14  time: 0.4315  data_time: 0.0089  memory: 5167  grad_norm: 50.7457  loss: 6.9541  decode.loss_cls: 0.0837  decode.loss_mask: 0.2594  decode.loss_dice: 0.2684  decode.d0.loss_cls: 1.0108  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2789  decode.d1.loss_cls: 0.1476  decode.d1.loss_mask: 0.2580  decode.d1.loss_dice: 0.2637  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 0.2568  decode.d2.loss_dice: 0.2657  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.2557  decode.d3.loss_dice: 0.2620  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.2544  decode.d4.loss_dice: 0.2669  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.2553  decode.d5.loss_dice: 0.2720  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.2567  decode.d6.loss_dice: 0.2597  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.2613  decode.d7.loss_dice: 0.2557  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.2645
09/28 16:44:26 - mmengine - INFO - Iter(train) [ 18650/320000]  base_lr: 9.4739e-05 lr: 9.4739e-06  eta: 1 day, 12:57:45  time: 0.4318  data_time: 0.0090  memory: 5185  grad_norm: 61.4055  loss: 7.1847  decode.loss_cls: 0.1889  decode.loss_mask: 0.2590  decode.loss_dice: 0.2001  decode.d0.loss_cls: 0.8994  decode.d0.loss_mask: 0.3199  decode.d0.loss_dice: 0.2065  decode.d1.loss_cls: 0.1825  decode.d1.loss_mask: 0.2393  decode.d1.loss_dice: 0.2007  decode.d2.loss_cls: 0.2616  decode.d2.loss_mask: 0.2504  decode.d2.loss_dice: 0.1931  decode.d3.loss_cls: 0.2271  decode.d3.loss_mask: 0.2442  decode.d3.loss_dice: 0.1932  decode.d4.loss_cls: 0.1942  decode.d4.loss_mask: 0.2256  decode.d4.loss_dice: 0.1824  decode.d5.loss_cls: 0.1632  decode.d5.loss_mask: 0.2351  decode.d5.loss_dice: 0.1910  decode.d6.loss_cls: 0.1738  decode.d6.loss_mask: 0.3246  decode.d6.loss_dice: 0.2040  decode.d7.loss_cls: 0.2083  decode.d7.loss_mask: 0.2338  decode.d7.loss_dice: 0.1844  decode.d8.loss_cls: 0.1456  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.2016
09/28 16:44:48 - mmengine - INFO - Iter(train) [ 18700/320000]  base_lr: 9.4725e-05 lr: 9.4725e-06  eta: 1 day, 12:57:14  time: 0.4311  data_time: 0.0090  memory: 5186  grad_norm: 102.9321  loss: 7.3974  decode.loss_cls: 0.0968  decode.loss_mask: 0.2869  decode.loss_dice: 0.2430  decode.d0.loss_cls: 0.8620  decode.d0.loss_mask: 0.2995  decode.d0.loss_dice: 0.2400  decode.d1.loss_cls: 0.1675  decode.d1.loss_mask: 0.2908  decode.d1.loss_dice: 0.2374  decode.d2.loss_cls: 0.1436  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.2944  decode.d3.loss_cls: 0.1331  decode.d3.loss_mask: 0.2866  decode.d3.loss_dice: 0.2566  decode.d4.loss_cls: 0.1638  decode.d4.loss_mask: 0.2918  decode.d4.loss_dice: 0.2760  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.2810  decode.d5.loss_dice: 0.2315  decode.d6.loss_cls: 0.0954  decode.d6.loss_mask: 0.2955  decode.d6.loss_dice: 0.2712  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.2866  decode.d7.loss_dice: 0.2362  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.2877  decode.d8.loss_dice: 0.2350
09/28 16:45:10 - mmengine - INFO - Iter(train) [ 18750/320000]  base_lr: 9.4711e-05 lr: 9.4711e-06  eta: 1 day, 12:56:44  time: 0.4318  data_time: 0.0090  memory: 5167  grad_norm: 96.5602  loss: 12.2370  decode.loss_cls: 0.4207  decode.loss_mask: 0.6195  decode.loss_dice: 0.3056  decode.d0.loss_cls: 1.0088  decode.d0.loss_mask: 0.4020  decode.d0.loss_dice: 0.3008  decode.d1.loss_cls: 0.5105  decode.d1.loss_mask: 0.3957  decode.d1.loss_dice: 0.3041  decode.d2.loss_cls: 0.3756  decode.d2.loss_mask: 0.4259  decode.d2.loss_dice: 0.3368  decode.d3.loss_cls: 0.3558  decode.d3.loss_mask: 0.4649  decode.d3.loss_dice: 0.3429  decode.d4.loss_cls: 0.3027  decode.d4.loss_mask: 0.4661  decode.d4.loss_dice: 0.3224  decode.d5.loss_cls: 0.3404  decode.d5.loss_mask: 0.4521  decode.d5.loss_dice: 0.3173  decode.d6.loss_cls: 0.3510  decode.d6.loss_mask: 0.4062  decode.d6.loss_dice: 0.3013  decode.d7.loss_cls: 0.4271  decode.d7.loss_mask: 0.4401  decode.d7.loss_dice: 0.3097  decode.d8.loss_cls: 0.3799  decode.d8.loss_mask: 0.5222  decode.d8.loss_dice: 0.3291
09/28 16:45:31 - mmengine - INFO - Iter(train) [ 18800/320000]  base_lr: 9.4697e-05 lr: 9.4697e-06  eta: 1 day, 12:56:15  time: 0.4320  data_time: 0.0092  memory: 5166  grad_norm: 69.5809  loss: 7.4784  decode.loss_cls: 0.1732  decode.loss_mask: 0.2707  decode.loss_dice: 0.2228  decode.d0.loss_cls: 0.9347  decode.d0.loss_mask: 0.2720  decode.d0.loss_dice: 0.2362  decode.d1.loss_cls: 0.1978  decode.d1.loss_mask: 0.2687  decode.d1.loss_dice: 0.2259  decode.d2.loss_cls: 0.1355  decode.d2.loss_mask: 0.2735  decode.d2.loss_dice: 0.2228  decode.d3.loss_cls: 0.1858  decode.d3.loss_mask: 0.2731  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.1510  decode.d4.loss_mask: 0.2697  decode.d4.loss_dice: 0.2288  decode.d5.loss_cls: 0.1892  decode.d5.loss_mask: 0.2684  decode.d5.loss_dice: 0.2363  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.2211  decode.d7.loss_cls: 0.1728  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.2230  decode.d8.loss_cls: 0.1834  decode.d8.loss_mask: 0.2752  decode.d8.loss_dice: 0.2286
09/28 16:45:53 - mmengine - INFO - Iter(train) [ 18850/320000]  base_lr: 9.4683e-05 lr: 9.4683e-06  eta: 1 day, 12:55:45  time: 0.4318  data_time: 0.0092  memory: 5166  grad_norm: 124.9174  loss: 8.0192  decode.loss_cls: 0.1559  decode.loss_mask: 0.3007  decode.loss_dice: 0.2659  decode.d0.loss_cls: 0.9910  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.3082  decode.d1.loss_cls: 0.1560  decode.d1.loss_mask: 0.3038  decode.d1.loss_dice: 0.2880  decode.d2.loss_cls: 0.1431  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.2681  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 0.3060  decode.d3.loss_dice: 0.3042  decode.d4.loss_cls: 0.1177  decode.d4.loss_mask: 0.3078  decode.d4.loss_dice: 0.2911  decode.d5.loss_cls: 0.0931  decode.d5.loss_mask: 0.3020  decode.d5.loss_dice: 0.2862  decode.d6.loss_cls: 0.1023  decode.d6.loss_mask: 0.3024  decode.d6.loss_dice: 0.2851  decode.d7.loss_cls: 0.1126  decode.d7.loss_mask: 0.3013  decode.d7.loss_dice: 0.2848  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 0.3034  decode.d8.loss_dice: 0.2691
09/28 16:46:14 - mmengine - INFO - Iter(train) [ 18900/320000]  base_lr: 9.4669e-05 lr: 9.4669e-06  eta: 1 day, 12:55:15  time: 0.4325  data_time: 0.0090  memory: 5186  grad_norm: 114.9754  loss: 9.3421  decode.loss_cls: 0.2667  decode.loss_mask: 0.3273  decode.loss_dice: 0.2437  decode.d0.loss_cls: 1.0378  decode.d0.loss_mask: 0.3374  decode.d0.loss_dice: 0.2627  decode.d1.loss_cls: 0.3279  decode.d1.loss_mask: 0.3185  decode.d1.loss_dice: 0.2465  decode.d2.loss_cls: 0.2762  decode.d2.loss_mask: 0.3129  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.2471  decode.d3.loss_mask: 0.3166  decode.d3.loss_dice: 0.2606  decode.d4.loss_cls: 0.2492  decode.d4.loss_mask: 0.3186  decode.d4.loss_dice: 0.2638  decode.d5.loss_cls: 0.3425  decode.d5.loss_mask: 0.3336  decode.d5.loss_dice: 0.2558  decode.d6.loss_cls: 0.2880  decode.d6.loss_mask: 0.3332  decode.d6.loss_dice: 0.2480  decode.d7.loss_cls: 0.2779  decode.d7.loss_mask: 0.3289  decode.d7.loss_dice: 0.2498  decode.d8.loss_cls: 0.2611  decode.d8.loss_mask: 0.3176  decode.d8.loss_dice: 0.2388
09/28 16:46:36 - mmengine - INFO - Iter(train) [ 18950/320000]  base_lr: 9.4654e-05 lr: 9.4654e-06  eta: 1 day, 12:54:46  time: 0.4332  data_time: 0.0092  memory: 5167  grad_norm: 161.2654  loss: 10.5247  decode.loss_cls: 0.3910  decode.loss_mask: 0.3842  decode.loss_dice: 0.2895  decode.d0.loss_cls: 1.0384  decode.d0.loss_mask: 0.4096  decode.d0.loss_dice: 0.3138  decode.d1.loss_cls: 0.2551  decode.d1.loss_mask: 0.4068  decode.d1.loss_dice: 0.3047  decode.d2.loss_cls: 0.2648  decode.d2.loss_mask: 0.4089  decode.d2.loss_dice: 0.2763  decode.d3.loss_cls: 0.2447  decode.d3.loss_mask: 0.4070  decode.d3.loss_dice: 0.3088  decode.d4.loss_cls: 0.2474  decode.d4.loss_mask: 0.4072  decode.d4.loss_dice: 0.2785  decode.d5.loss_cls: 0.2061  decode.d5.loss_mask: 0.4058  decode.d5.loss_dice: 0.2972  decode.d6.loss_cls: 0.3067  decode.d6.loss_mask: 0.3885  decode.d6.loss_dice: 0.2974  decode.d7.loss_cls: 0.3249  decode.d7.loss_mask: 0.3882  decode.d7.loss_dice: 0.2793  decode.d8.loss_cls: 0.3052  decode.d8.loss_mask: 0.3820  decode.d8.loss_dice: 0.3068
09/28 16:46:58 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:46:58 - mmengine - INFO - Iter(train) [ 19000/320000]  base_lr: 9.4640e-05 lr: 9.4640e-06  eta: 1 day, 12:54:16  time: 0.4321  data_time: 0.0092  memory: 5167  grad_norm: 129.3080  loss: 7.0740  decode.loss_cls: 0.1477  decode.loss_mask: 0.2687  decode.loss_dice: 0.2724  decode.d0.loss_cls: 1.0469  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 0.2691  decode.d1.loss_dice: 0.2428  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.2322  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.2582  decode.d3.loss_dice: 0.2275  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2504  decode.d5.loss_cls: 0.1249  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.2539  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 0.2518  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.2520  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.1409  decode.d8.loss_mask: 0.2682  decode.d8.loss_dice: 0.2722
09/28 16:47:19 - mmengine - INFO - Iter(train) [ 19050/320000]  base_lr: 9.4626e-05 lr: 9.4626e-06  eta: 1 day, 12:53:47  time: 0.4316  data_time: 0.0092  memory: 5186  grad_norm: 117.1205  loss: 9.4452  decode.loss_cls: 0.2283  decode.loss_mask: 0.4318  decode.loss_dice: 0.2992  decode.d0.loss_cls: 1.0736  decode.d0.loss_mask: 0.3578  decode.d0.loss_dice: 0.3022  decode.d1.loss_cls: 0.1980  decode.d1.loss_mask: 0.3644  decode.d1.loss_dice: 0.2686  decode.d2.loss_cls: 0.2193  decode.d2.loss_mask: 0.3610  decode.d2.loss_dice: 0.2576  decode.d3.loss_cls: 0.2079  decode.d3.loss_mask: 0.3569  decode.d3.loss_dice: 0.2631  decode.d4.loss_cls: 0.2169  decode.d4.loss_mask: 0.3569  decode.d4.loss_dice: 0.2659  decode.d5.loss_cls: 0.2037  decode.d5.loss_mask: 0.3541  decode.d5.loss_dice: 0.2872  decode.d6.loss_cls: 0.2149  decode.d6.loss_mask: 0.3594  decode.d6.loss_dice: 0.2794  decode.d7.loss_cls: 0.2094  decode.d7.loss_mask: 0.3591  decode.d7.loss_dice: 0.2759  decode.d8.loss_cls: 0.2054  decode.d8.loss_mask: 0.3815  decode.d8.loss_dice: 0.2860
09/28 16:47:41 - mmengine - INFO - Iter(train) [ 19100/320000]  base_lr: 9.4612e-05 lr: 9.4612e-06  eta: 1 day, 12:53:17  time: 0.4315  data_time: 0.0091  memory: 5166  grad_norm: 85.4386  loss: 7.5332  decode.loss_cls: 0.1234  decode.loss_mask: 0.2704  decode.loss_dice: 0.2555  decode.d0.loss_cls: 1.0939  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.2678  decode.d1.loss_cls: 0.1204  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.1434  decode.d2.loss_mask: 0.2683  decode.d2.loss_dice: 0.2648  decode.d3.loss_cls: 0.1337  decode.d3.loss_mask: 0.2613  decode.d3.loss_dice: 0.2283  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.2649  decode.d4.loss_dice: 0.2539  decode.d5.loss_cls: 0.1233  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.2660  decode.d6.loss_cls: 0.1401  decode.d6.loss_mask: 0.2736  decode.d6.loss_dice: 0.2578  decode.d7.loss_cls: 0.1357  decode.d7.loss_mask: 0.2711  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.2469
09/28 16:48:02 - mmengine - INFO - Iter(train) [ 19150/320000]  base_lr: 9.4598e-05 lr: 9.4598e-06  eta: 1 day, 12:52:48  time: 0.4320  data_time: 0.0092  memory: 5167  grad_norm: 66.8176  loss: 7.7341  decode.loss_cls: 0.1683  decode.loss_mask: 0.2643  decode.loss_dice: 0.2733  decode.d0.loss_cls: 1.0209  decode.d0.loss_mask: 0.2747  decode.d0.loss_dice: 0.3283  decode.d1.loss_cls: 0.1896  decode.d1.loss_mask: 0.2631  decode.d1.loss_dice: 0.2940  decode.d2.loss_cls: 0.1236  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.2775  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.2643  decode.d3.loss_dice: 0.2674  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.2625  decode.d4.loss_dice: 0.2797  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.2874  decode.d6.loss_cls: 0.1206  decode.d6.loss_mask: 0.2684  decode.d6.loss_dice: 0.2832  decode.d7.loss_cls: 0.1216  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.1911  decode.d8.loss_mask: 0.2666  decode.d8.loss_dice: 0.3018
09/28 16:48:24 - mmengine - INFO - Iter(train) [ 19200/320000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 1 day, 12:52:19  time: 0.4324  data_time: 0.0093  memory: 5167  grad_norm: 161.8218  loss: 9.0534  decode.loss_cls: 0.2340  decode.loss_mask: 0.3319  decode.loss_dice: 0.2738  decode.d0.loss_cls: 1.0534  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.3037  decode.d1.loss_cls: 0.1573  decode.d1.loss_mask: 0.3207  decode.d1.loss_dice: 0.2593  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.2699  decode.d3.loss_cls: 0.1568  decode.d3.loss_mask: 0.3240  decode.d3.loss_dice: 0.2505  decode.d4.loss_cls: 0.2262  decode.d4.loss_mask: 0.3208  decode.d4.loss_dice: 0.2538  decode.d5.loss_cls: 0.2651  decode.d5.loss_mask: 0.3198  decode.d5.loss_dice: 0.2536  decode.d6.loss_cls: 0.2988  decode.d6.loss_mask: 0.3814  decode.d6.loss_dice: 0.3198  decode.d7.loss_cls: 0.2270  decode.d7.loss_mask: 0.3273  decode.d7.loss_dice: 0.3001  decode.d8.loss_cls: 0.2660  decode.d8.loss_mask: 0.3282  decode.d8.loss_dice: 0.2617
09/28 16:48:46 - mmengine - INFO - Iter(train) [ 19250/320000]  base_lr: 9.4570e-05 lr: 9.4570e-06  eta: 1 day, 12:51:50  time: 0.4322  data_time: 0.0092  memory: 5166  grad_norm: 187.5300  loss: 12.3322  decode.loss_cls: 0.3049  decode.loss_mask: 0.5099  decode.loss_dice: 0.3342  decode.d0.loss_cls: 1.3831  decode.d0.loss_mask: 0.4342  decode.d0.loss_dice: 0.3257  decode.d1.loss_cls: 0.5971  decode.d1.loss_mask: 0.4115  decode.d1.loss_dice: 0.2973  decode.d2.loss_cls: 0.4213  decode.d2.loss_mask: 0.4701  decode.d2.loss_dice: 0.3211  decode.d3.loss_cls: 0.3481  decode.d3.loss_mask: 0.4350  decode.d3.loss_dice: 0.3319  decode.d4.loss_cls: 0.4086  decode.d4.loss_mask: 0.4344  decode.d4.loss_dice: 0.3146  decode.d5.loss_cls: 0.3200  decode.d5.loss_mask: 0.4677  decode.d5.loss_dice: 0.3361  decode.d6.loss_cls: 0.2559  decode.d6.loss_mask: 0.4491  decode.d6.loss_dice: 0.3203  decode.d7.loss_cls: 0.2735  decode.d7.loss_mask: 0.4506  decode.d7.loss_dice: 0.3215  decode.d8.loss_cls: 0.3505  decode.d8.loss_mask: 0.4098  decode.d8.loss_dice: 0.2944
09/28 16:49:07 - mmengine - INFO - Iter(train) [ 19300/320000]  base_lr: 9.4555e-05 lr: 9.4555e-06  eta: 1 day, 12:51:20  time: 0.4319  data_time: 0.0091  memory: 5167  grad_norm: 76.1310  loss: 8.6042  decode.loss_cls: 0.2691  decode.loss_mask: 0.2761  decode.loss_dice: 0.2651  decode.d0.loss_cls: 1.0413  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.2563  decode.d1.loss_cls: 0.2555  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2631  decode.d2.loss_cls: 0.2542  decode.d2.loss_mask: 0.2764  decode.d2.loss_dice: 0.2674  decode.d3.loss_cls: 0.2671  decode.d3.loss_mask: 0.2770  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.2743  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.2547  decode.d5.loss_cls: 0.2098  decode.d5.loss_mask: 0.2726  decode.d5.loss_dice: 0.2533  decode.d6.loss_cls: 0.2309  decode.d6.loss_mask: 0.2722  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.2079  decode.d7.loss_mask: 0.2757  decode.d7.loss_dice: 0.2709  decode.d8.loss_cls: 0.2290  decode.d8.loss_mask: 0.2719  decode.d8.loss_dice: 0.2953
09/28 16:49:29 - mmengine - INFO - Iter(train) [ 19350/320000]  base_lr: 9.4541e-05 lr: 9.4541e-06  eta: 1 day, 12:50:51  time: 0.4317  data_time: 0.0092  memory: 5186  grad_norm: 130.6459  loss: 10.9642  decode.loss_cls: 0.2213  decode.loss_mask: 0.4192  decode.loss_dice: 0.3248  decode.d0.loss_cls: 1.1445  decode.d0.loss_mask: 0.4214  decode.d0.loss_dice: 0.3302  decode.d1.loss_cls: 0.4130  decode.d1.loss_mask: 0.3542  decode.d1.loss_dice: 0.2951  decode.d2.loss_cls: 0.3134  decode.d2.loss_mask: 0.3989  decode.d2.loss_dice: 0.3143  decode.d3.loss_cls: 0.2797  decode.d3.loss_mask: 0.4039  decode.d3.loss_dice: 0.2935  decode.d4.loss_cls: 0.2344  decode.d4.loss_mask: 0.5245  decode.d4.loss_dice: 0.3070  decode.d5.loss_cls: 0.2200  decode.d5.loss_mask: 0.4089  decode.d5.loss_dice: 0.2847  decode.d6.loss_cls: 0.2387  decode.d6.loss_mask: 0.4196  decode.d6.loss_dice: 0.2857  decode.d7.loss_cls: 0.2891  decode.d7.loss_mask: 0.3747  decode.d7.loss_dice: 0.2983  decode.d8.loss_cls: 0.1674  decode.d8.loss_mask: 0.6578  decode.d8.loss_dice: 0.3261
09/28 16:49:51 - mmengine - INFO - Iter(train) [ 19400/320000]  base_lr: 9.4527e-05 lr: 9.4527e-06  eta: 1 day, 12:50:25  time: 0.4483  data_time: 0.0092  memory: 5167  grad_norm: 45.6897  loss: 6.9188  decode.loss_cls: 0.0809  decode.loss_mask: 0.2498  decode.loss_dice: 0.2644  decode.d0.loss_cls: 0.9296  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2427  decode.d1.loss_cls: 0.1839  decode.d1.loss_mask: 0.2491  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.1669  decode.d2.loss_mask: 0.2613  decode.d2.loss_dice: 0.2536  decode.d3.loss_cls: 0.1584  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.1230  decode.d4.loss_mask: 0.2478  decode.d4.loss_dice: 0.2430  decode.d5.loss_cls: 0.1070  decode.d5.loss_mask: 0.2477  decode.d5.loss_dice: 0.2555  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.0682  decode.d7.loss_mask: 0.2491  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.2457  decode.d8.loss_dice: 0.2196
09/28 16:50:12 - mmengine - INFO - Iter(train) [ 19450/320000]  base_lr: 9.4513e-05 lr: 9.4513e-06  eta: 1 day, 12:49:55  time: 0.4317  data_time: 0.0091  memory: 5167  grad_norm: 68.9443  loss: 8.1604  decode.loss_cls: 0.2653  decode.loss_mask: 0.2355  decode.loss_dice: 0.2209  decode.d0.loss_cls: 1.0939  decode.d0.loss_mask: 0.2351  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.2105  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2210  decode.d2.loss_cls: 0.2191  decode.d2.loss_mask: 0.2450  decode.d2.loss_dice: 0.2140  decode.d3.loss_cls: 0.2116  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.2193  decode.d4.loss_cls: 0.2844  decode.d4.loss_mask: 0.2361  decode.d4.loss_dice: 0.2229  decode.d5.loss_cls: 0.3023  decode.d5.loss_mask: 0.2366  decode.d5.loss_dice: 0.2211  decode.d6.loss_cls: 0.3025  decode.d6.loss_mask: 0.2410  decode.d6.loss_dice: 0.2169  decode.d7.loss_cls: 0.3183  decode.d7.loss_mask: 0.2419  decode.d7.loss_dice: 0.2192  decode.d8.loss_cls: 0.3703  decode.d8.loss_mask: 0.2344  decode.d8.loss_dice: 0.2186
09/28 16:50:34 - mmengine - INFO - Iter(train) [ 19500/320000]  base_lr: 9.4499e-05 lr: 9.4499e-06  eta: 1 day, 12:49:26  time: 0.4320  data_time: 0.0093  memory: 5167  grad_norm: 147.5616  loss: 8.3440  decode.loss_cls: 0.2440  decode.loss_mask: 0.2573  decode.loss_dice: 0.2660  decode.d0.loss_cls: 1.0115  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.2874  decode.d1.loss_cls: 0.1614  decode.d1.loss_mask: 0.2626  decode.d1.loss_dice: 0.2841  decode.d2.loss_cls: 0.1922  decode.d2.loss_mask: 0.2621  decode.d2.loss_dice: 0.2693  decode.d3.loss_cls: 0.1924  decode.d3.loss_mask: 0.2623  decode.d3.loss_dice: 0.2697  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.2617  decode.d4.loss_dice: 0.2818  decode.d5.loss_cls: 0.2326  decode.d5.loss_mask: 0.2614  decode.d5.loss_dice: 0.2859  decode.d6.loss_cls: 0.2336  decode.d6.loss_mask: 0.2666  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.2241  decode.d7.loss_mask: 0.2610  decode.d7.loss_dice: 0.2811  decode.d8.loss_cls: 0.2484  decode.d8.loss_mask: 0.2603  decode.d8.loss_dice: 0.2683
09/28 16:50:55 - mmengine - INFO - Iter(train) [ 19550/320000]  base_lr: 9.4485e-05 lr: 9.4485e-06  eta: 1 day, 12:48:57  time: 0.4322  data_time: 0.0091  memory: 5186  grad_norm: 38.7801  loss: 5.3222  decode.loss_cls: 0.0382  decode.loss_mask: 0.1861  decode.loss_dice: 0.2045  decode.d0.loss_cls: 0.8414  decode.d0.loss_mask: 0.1955  decode.d0.loss_dice: 0.2196  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.1874  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.1869  decode.d2.loss_dice: 0.1787  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.1860  decode.d3.loss_dice: 0.1935  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.1885  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.0663  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.2043  decode.d7.loss_cls: 0.0836  decode.d7.loss_mask: 0.1901  decode.d7.loss_dice: 0.2130  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.1891  decode.d8.loss_dice: 0.2074
09/28 16:51:17 - mmengine - INFO - Iter(train) [ 19600/320000]  base_lr: 9.4470e-05 lr: 9.4470e-06  eta: 1 day, 12:48:28  time: 0.4327  data_time: 0.0091  memory: 5167  grad_norm: 133.2747  loss: 8.7693  decode.loss_cls: 0.1759  decode.loss_mask: 0.3178  decode.loss_dice: 0.2465  decode.d0.loss_cls: 1.1132  decode.d0.loss_mask: 0.3354  decode.d0.loss_dice: 0.2287  decode.d1.loss_cls: 0.2053  decode.d1.loss_mask: 0.3364  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.2618  decode.d2.loss_mask: 0.2963  decode.d2.loss_dice: 0.2568  decode.d3.loss_cls: 0.2566  decode.d3.loss_mask: 0.3043  decode.d3.loss_dice: 0.2450  decode.d4.loss_cls: 0.2544  decode.d4.loss_mask: 0.2933  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.2222  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.2350  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 0.3328  decode.d6.loss_dice: 0.2375  decode.d7.loss_cls: 0.2208  decode.d7.loss_mask: 0.3330  decode.d7.loss_dice: 0.2515  decode.d8.loss_cls: 0.2356  decode.d8.loss_mask: 0.3329  decode.d8.loss_dice: 0.2286
09/28 16:51:39 - mmengine - INFO - Iter(train) [ 19650/320000]  base_lr: 9.4456e-05 lr: 9.4456e-06  eta: 1 day, 12:48:01  time: 0.4337  data_time: 0.0090  memory: 5167  grad_norm: 133.1686  loss: 11.4765  decode.loss_cls: 0.1825  decode.loss_mask: 0.4198  decode.loss_dice: 0.4047  decode.d0.loss_cls: 0.9766  decode.d0.loss_mask: 0.3564  decode.d0.loss_dice: 0.4449  decode.d1.loss_cls: 0.5844  decode.d1.loss_mask: 0.3721  decode.d1.loss_dice: 0.4147  decode.d2.loss_cls: 0.3764  decode.d2.loss_mask: 0.3523  decode.d2.loss_dice: 0.3840  decode.d3.loss_cls: 0.2797  decode.d3.loss_mask: 0.3848  decode.d3.loss_dice: 0.3956  decode.d4.loss_cls: 0.2564  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.4020  decode.d5.loss_cls: 0.1511  decode.d5.loss_mask: 0.4155  decode.d5.loss_dice: 0.3979  decode.d6.loss_cls: 0.1567  decode.d6.loss_mask: 0.4180  decode.d6.loss_dice: 0.3997  decode.d7.loss_cls: 0.2897  decode.d7.loss_mask: 0.4736  decode.d7.loss_dice: 0.3978  decode.d8.loss_cls: 0.1865  decode.d8.loss_mask: 0.4390  decode.d8.loss_dice: 0.3953
09/28 16:52:00 - mmengine - INFO - Iter(train) [ 19700/320000]  base_lr: 9.4442e-05 lr: 9.4442e-06  eta: 1 day, 12:47:34  time: 0.4343  data_time: 0.0091  memory: 5167  grad_norm: 107.5022  loss: 8.3541  decode.loss_cls: 0.2336  decode.loss_mask: 0.2701  decode.loss_dice: 0.2500  decode.d0.loss_cls: 1.0687  decode.d0.loss_mask: 0.2787  decode.d0.loss_dice: 0.2796  decode.d1.loss_cls: 0.3092  decode.d1.loss_mask: 0.2913  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.1707  decode.d2.loss_mask: 0.2737  decode.d2.loss_dice: 0.2654  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.2794  decode.d3.loss_dice: 0.2732  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 0.2780  decode.d4.loss_dice: 0.2629  decode.d5.loss_cls: 0.1604  decode.d5.loss_mask: 0.2714  decode.d5.loss_dice: 0.2556  decode.d6.loss_cls: 0.1711  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2120  decode.d7.loss_mask: 0.2891  decode.d7.loss_dice: 0.2534  decode.d8.loss_cls: 0.2395  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.2567
09/28 16:52:22 - mmengine - INFO - Iter(train) [ 19750/320000]  base_lr: 9.4428e-05 lr: 9.4428e-06  eta: 1 day, 12:47:07  time: 0.4347  data_time: 0.0091  memory: 5167  grad_norm: 43.0764  loss: 5.8615  decode.loss_cls: 0.0251  decode.loss_mask: 0.2425  decode.loss_dice: 0.2308  decode.d0.loss_cls: 1.0239  decode.d0.loss_mask: 0.2433  decode.d0.loss_dice: 0.2149  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.2434  decode.d1.loss_dice: 0.2205  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.2170  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.2068  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 0.2382  decode.d5.loss_dice: 0.2201  decode.d6.loss_cls: 0.0230  decode.d6.loss_mask: 0.2433  decode.d6.loss_dice: 0.2237  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.2285  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.2468  decode.d8.loss_dice: 0.2204
09/28 16:52:44 - mmengine - INFO - Iter(train) [ 19800/320000]  base_lr: 9.4414e-05 lr: 9.4414e-06  eta: 1 day, 12:46:40  time: 0.4357  data_time: 0.0089  memory: 5186  grad_norm: 116.5068  loss: 6.5771  decode.loss_cls: 0.1190  decode.loss_mask: 0.2514  decode.loss_dice: 0.2066  decode.d0.loss_cls: 0.9983  decode.d0.loss_mask: 0.2679  decode.d0.loss_dice: 0.2205  decode.d1.loss_cls: 0.1215  decode.d1.loss_mask: 0.2560  decode.d1.loss_dice: 0.1995  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.2019  decode.d3.loss_cls: 0.0844  decode.d3.loss_mask: 0.2544  decode.d3.loss_dice: 0.2008  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 0.2496  decode.d4.loss_dice: 0.2008  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.2506  decode.d5.loss_dice: 0.2046  decode.d6.loss_cls: 0.1145  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.2008  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.2501  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.2021
09/28 16:53:06 - mmengine - INFO - Iter(train) [ 19850/320000]  base_lr: 9.4400e-05 lr: 9.4400e-06  eta: 1 day, 12:46:13  time: 0.4340  data_time: 0.0091  memory: 5167  grad_norm: 60.4335  loss: 7.7701  decode.loss_cls: 0.1363  decode.loss_mask: 0.2594  decode.loss_dice: 0.2629  decode.d0.loss_cls: 1.0091  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.2366  decode.d1.loss_cls: 0.3053  decode.d1.loss_mask: 0.2777  decode.d1.loss_dice: 0.2123  decode.d2.loss_cls: 0.1736  decode.d2.loss_mask: 0.2743  decode.d2.loss_dice: 0.2978  decode.d3.loss_cls: 0.1980  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.2690  decode.d4.loss_cls: 0.1749  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2279  decode.d5.loss_cls: 0.1716  decode.d5.loss_mask: 0.2654  decode.d5.loss_dice: 0.2444  decode.d6.loss_cls: 0.1419  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.2546  decode.d7.loss_cls: 0.1790  decode.d7.loss_mask: 0.2623  decode.d7.loss_dice: 0.2083  decode.d8.loss_cls: 0.1839  decode.d8.loss_mask: 0.2598  decode.d8.loss_dice: 0.2180
09/28 16:53:27 - mmengine - INFO - Iter(train) [ 19900/320000]  base_lr: 9.4386e-05 lr: 9.4386e-06  eta: 1 day, 12:45:46  time: 0.4343  data_time: 0.0090  memory: 5167  grad_norm: 62.8940  loss: 7.8254  decode.loss_cls: 0.1489  decode.loss_mask: 0.2564  decode.loss_dice: 0.2462  decode.d0.loss_cls: 1.0299  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.2719  decode.d1.loss_cls: 0.2399  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.2399  decode.d2.loss_cls: 0.1467  decode.d2.loss_mask: 0.2642  decode.d2.loss_dice: 0.2654  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 0.2640  decode.d3.loss_dice: 0.2459  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.2587  decode.d5.loss_cls: 0.2128  decode.d5.loss_mask: 0.2619  decode.d5.loss_dice: 0.2689  decode.d6.loss_cls: 0.1888  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.2510  decode.d8.loss_cls: 0.1618  decode.d8.loss_mask: 0.2610  decode.d8.loss_dice: 0.2488
09/28 16:53:49 - mmengine - INFO - Iter(train) [ 19950/320000]  base_lr: 9.4371e-05 lr: 9.4371e-06  eta: 1 day, 12:45:19  time: 0.4345  data_time: 0.0089  memory: 5166  grad_norm: 87.7681  loss: 8.1848  decode.loss_cls: 0.2528  decode.loss_mask: 0.2364  decode.loss_dice: 0.2540  decode.d0.loss_cls: 1.0278  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.2845  decode.d1.loss_cls: 0.2394  decode.d1.loss_mask: 0.2409  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2438  decode.d3.loss_cls: 0.2416  decode.d3.loss_mask: 0.2302  decode.d3.loss_dice: 0.2584  decode.d4.loss_cls: 0.2619  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2588  decode.d5.loss_cls: 0.2264  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.2614  decode.d6.loss_cls: 0.2292  decode.d6.loss_mask: 0.2379  decode.d6.loss_dice: 0.2544  decode.d7.loss_cls: 0.2502  decode.d7.loss_mask: 0.2376  decode.d7.loss_dice: 0.2550  decode.d8.loss_cls: 0.2723  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.2576
09/28 16:54:11 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 16:54:11 - mmengine - INFO - Iter(train) [ 20000/320000]  base_lr: 9.4357e-05 lr: 9.4357e-06  eta: 1 day, 12:44:52  time: 0.4339  data_time: 0.0090  memory: 5186  grad_norm: 49.1628  loss: 7.6809  decode.loss_cls: 0.1056  decode.loss_mask: 0.2759  decode.loss_dice: 0.2792  decode.d0.loss_cls: 0.9407  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.3349  decode.d1.loss_cls: 0.1715  decode.d1.loss_mask: 0.2767  decode.d1.loss_dice: 0.2709  decode.d2.loss_cls: 0.1749  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.2765  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.2870  decode.d4.loss_cls: 0.1051  decode.d4.loss_mask: 0.2767  decode.d4.loss_dice: 0.2869  decode.d5.loss_cls: 0.1111  decode.d5.loss_mask: 0.2781  decode.d5.loss_dice: 0.2996  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.2876  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.2726  decode.d7.loss_dice: 0.2827  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.2773  decode.d8.loss_dice: 0.2955
09/28 16:54:33 - mmengine - INFO - Iter(train) [ 20050/320000]  base_lr: 9.4343e-05 lr: 9.4343e-06  eta: 1 day, 12:44:25  time: 0.4343  data_time: 0.0091  memory: 5167  grad_norm: 74.3088  loss: 7.7121  decode.loss_cls: 0.1728  decode.loss_mask: 0.2990  decode.loss_dice: 0.2374  decode.d0.loss_cls: 1.1546  decode.d0.loss_mask: 0.3145  decode.d0.loss_dice: 0.2470  decode.d1.loss_cls: 0.2081  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.2274  decode.d2.loss_cls: 0.1267  decode.d2.loss_mask: 0.3006  decode.d2.loss_dice: 0.2369  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.2999  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.2972  decode.d4.loss_dice: 0.2404  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.3135  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.3056  decode.d6.loss_dice: 0.2389  decode.d7.loss_cls: 0.1314  decode.d7.loss_mask: 0.2986  decode.d7.loss_dice: 0.2406  decode.d8.loss_cls: 0.1382  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.2394
09/28 16:54:54 - mmengine - INFO - Iter(train) [ 20100/320000]  base_lr: 9.4329e-05 lr: 9.4329e-06  eta: 1 day, 12:43:59  time: 0.4341  data_time: 0.0092  memory: 5167  grad_norm: 201.1337  loss: 8.9362  decode.loss_cls: 0.2764  decode.loss_mask: 0.3319  decode.loss_dice: 0.2230  decode.d0.loss_cls: 1.0850  decode.d0.loss_mask: 0.3472  decode.d0.loss_dice: 0.2301  decode.d1.loss_cls: 0.2398  decode.d1.loss_mask: 0.3323  decode.d1.loss_dice: 0.2241  decode.d2.loss_cls: 0.2518  decode.d2.loss_mask: 0.3383  decode.d2.loss_dice: 0.2224  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 0.3426  decode.d3.loss_dice: 0.2233  decode.d4.loss_cls: 0.2222  decode.d4.loss_mask: 0.3404  decode.d4.loss_dice: 0.2237  decode.d5.loss_cls: 0.2176  decode.d5.loss_mask: 0.3437  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.2471  decode.d6.loss_mask: 0.3362  decode.d6.loss_dice: 0.2300  decode.d7.loss_cls: 0.2732  decode.d7.loss_mask: 0.3387  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.2825  decode.d8.loss_mask: 0.3378  decode.d8.loss_dice: 0.2207
09/28 16:55:16 - mmengine - INFO - Iter(train) [ 20150/320000]  base_lr: 9.4315e-05 lr: 9.4315e-06  eta: 1 day, 12:43:32  time: 0.4350  data_time: 0.0088  memory: 5186  grad_norm: 50.4101  loss: 5.5875  decode.loss_cls: 0.0906  decode.loss_mask: 0.1899  decode.loss_dice: 0.1736  decode.d0.loss_cls: 0.9768  decode.d0.loss_mask: 0.2006  decode.d0.loss_dice: 0.1811  decode.d1.loss_cls: 0.1615  decode.d1.loss_mask: 0.1946  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.1946  decode.d2.loss_dice: 0.1731  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.1950  decode.d3.loss_dice: 0.1717  decode.d4.loss_cls: 0.0785  decode.d4.loss_mask: 0.1950  decode.d4.loss_dice: 0.1785  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.1949  decode.d5.loss_dice: 0.1674  decode.d6.loss_cls: 0.1105  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.1770  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.1942  decode.d7.loss_dice: 0.1760  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.1933  decode.d8.loss_dice: 0.1725
09/28 16:55:38 - mmengine - INFO - Iter(train) [ 20200/320000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 1 day, 12:43:05  time: 0.4346  data_time: 0.0089  memory: 5167  grad_norm: 43.5545  loss: 8.5072  decode.loss_cls: 0.1733  decode.loss_mask: 0.3697  decode.loss_dice: 0.2505  decode.d0.loss_cls: 0.9743  decode.d0.loss_mask: 0.3764  decode.d0.loss_dice: 0.2407  decode.d1.loss_cls: 0.1622  decode.d1.loss_mask: 0.3584  decode.d1.loss_dice: 0.2485  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 0.3621  decode.d2.loss_dice: 0.2554  decode.d3.loss_cls: 0.1505  decode.d3.loss_mask: 0.3631  decode.d3.loss_dice: 0.2451  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 0.3625  decode.d4.loss_dice: 0.2422  decode.d5.loss_cls: 0.1367  decode.d5.loss_mask: 0.3615  decode.d5.loss_dice: 0.2585  decode.d6.loss_cls: 0.1355  decode.d6.loss_mask: 0.3591  decode.d6.loss_dice: 0.2458  decode.d7.loss_cls: 0.1549  decode.d7.loss_mask: 0.3643  decode.d7.loss_dice: 0.2505  decode.d8.loss_cls: 0.1608  decode.d8.loss_mask: 0.3636  decode.d8.loss_dice: 0.2523
09/28 16:55:59 - mmengine - INFO - Iter(train) [ 20250/320000]  base_lr: 9.4286e-05 lr: 9.4286e-06  eta: 1 day, 12:42:37  time: 0.4320  data_time: 0.0089  memory: 5166  grad_norm: 61.0739  loss: 6.9560  decode.loss_cls: 0.1771  decode.loss_mask: 0.2356  decode.loss_dice: 0.1934  decode.d0.loss_cls: 0.9921  decode.d0.loss_mask: 0.2488  decode.d0.loss_dice: 0.2204  decode.d1.loss_cls: 0.1678  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.2086  decode.d2.loss_cls: 0.1680  decode.d2.loss_mask: 0.2397  decode.d2.loss_dice: 0.2039  decode.d3.loss_cls: 0.1650  decode.d3.loss_mask: 0.2377  decode.d3.loss_dice: 0.2094  decode.d4.loss_cls: 0.1743  decode.d4.loss_mask: 0.2362  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.1796  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2033  decode.d6.loss_cls: 0.1613  decode.d6.loss_mask: 0.2379  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.1682  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.2061  decode.d8.loss_cls: 0.1646  decode.d8.loss_mask: 0.2360  decode.d8.loss_dice: 0.2000
09/28 16:56:21 - mmengine - INFO - Iter(train) [ 20300/320000]  base_lr: 9.4272e-05 lr: 9.4272e-06  eta: 1 day, 12:42:09  time: 0.4321  data_time: 0.0090  memory: 5167  grad_norm: 69.6341  loss: 8.2083  decode.loss_cls: 0.1295  decode.loss_mask: 0.2945  decode.loss_dice: 0.2583  decode.d0.loss_cls: 0.9455  decode.d0.loss_mask: 0.2997  decode.d0.loss_dice: 0.2936  decode.d1.loss_cls: 0.1850  decode.d1.loss_mask: 0.2956  decode.d1.loss_dice: 0.2915  decode.d2.loss_cls: 0.1582  decode.d2.loss_mask: 0.3130  decode.d2.loss_dice: 0.3076  decode.d3.loss_cls: 0.1551  decode.d3.loss_mask: 0.2929  decode.d3.loss_dice: 0.2998  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 0.3057  decode.d4.loss_dice: 0.3368  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.2933  decode.d5.loss_dice: 0.2861  decode.d6.loss_cls: 0.1927  decode.d6.loss_mask: 0.2976  decode.d6.loss_dice: 0.3088  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.2999  decode.d7.loss_dice: 0.2877  decode.d8.loss_cls: 0.1141  decode.d8.loss_mask: 0.2916  decode.d8.loss_dice: 0.2741
09/28 16:56:43 - mmengine - INFO - Iter(train) [ 20350/320000]  base_lr: 9.4258e-05 lr: 9.4258e-06  eta: 1 day, 12:41:40  time: 0.4310  data_time: 0.0090  memory: 5167  grad_norm: 71.0741  loss: 8.5809  decode.loss_cls: 0.2880  decode.loss_mask: 0.2780  decode.loss_dice: 0.2720  decode.d0.loss_cls: 0.9120  decode.d0.loss_mask: 0.2928  decode.d0.loss_dice: 0.2671  decode.d1.loss_cls: 0.2737  decode.d1.loss_mask: 0.2763  decode.d1.loss_dice: 0.2380  decode.d2.loss_cls: 0.2422  decode.d2.loss_mask: 0.2816  decode.d2.loss_dice: 0.2706  decode.d3.loss_cls: 0.2315  decode.d3.loss_mask: 0.2793  decode.d3.loss_dice: 0.2787  decode.d4.loss_cls: 0.2299  decode.d4.loss_mask: 0.2841  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.2524  decode.d5.loss_mask: 0.2758  decode.d5.loss_dice: 0.2362  decode.d6.loss_cls: 0.2566  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2682  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.2398  decode.d8.loss_cls: 0.2390  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.2734
09/28 16:57:04 - mmengine - INFO - Iter(train) [ 20400/320000]  base_lr: 9.4244e-05 lr: 9.4244e-06  eta: 1 day, 12:41:11  time: 0.4316  data_time: 0.0089  memory: 5186  grad_norm: 66.9920  loss: 7.6748  decode.loss_cls: 0.1667  decode.loss_mask: 0.2523  decode.loss_dice: 0.2328  decode.d0.loss_cls: 0.9434  decode.d0.loss_mask: 0.2574  decode.d0.loss_dice: 0.2472  decode.d1.loss_cls: 0.2554  decode.d1.loss_mask: 0.2554  decode.d1.loss_dice: 0.2514  decode.d2.loss_cls: 0.2575  decode.d2.loss_mask: 0.2552  decode.d2.loss_dice: 0.2435  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 0.2528  decode.d3.loss_dice: 0.2362  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2330  decode.d5.loss_cls: 0.1689  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.2425  decode.d6.loss_cls: 0.2244  decode.d6.loss_mask: 0.2512  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.1726  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2411  decode.d8.loss_cls: 0.1570  decode.d8.loss_mask: 0.2532  decode.d8.loss_dice: 0.2323
09/28 16:57:26 - mmengine - INFO - Iter(train) [ 20450/320000]  base_lr: 9.4230e-05 lr: 9.4230e-06  eta: 1 day, 12:40:42  time: 0.4321  data_time: 0.0093  memory: 5186  grad_norm: 236.9788  loss: 13.0494  decode.loss_cls: 0.4077  decode.loss_mask: 0.4569  decode.loss_dice: 0.3801  decode.d0.loss_cls: 1.3245  decode.d0.loss_mask: 0.4108  decode.d0.loss_dice: 0.3755  decode.d1.loss_cls: 0.4936  decode.d1.loss_mask: 0.4186  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.4436  decode.d2.loss_mask: 0.4318  decode.d2.loss_dice: 0.3560  decode.d3.loss_cls: 0.3969  decode.d3.loss_mask: 0.4171  decode.d3.loss_dice: 0.3617  decode.d4.loss_cls: 0.4075  decode.d4.loss_mask: 0.4419  decode.d4.loss_dice: 0.3878  decode.d5.loss_cls: 0.3377  decode.d5.loss_mask: 0.4289  decode.d5.loss_dice: 0.3570  decode.d6.loss_cls: 0.3851  decode.d6.loss_mask: 0.4419  decode.d6.loss_dice: 0.3683  decode.d7.loss_cls: 0.4478  decode.d7.loss_mask: 0.4338  decode.d7.loss_dice: 0.3708  decode.d8.loss_cls: 0.3610  decode.d8.loss_mask: 0.4521  decode.d8.loss_dice: 0.3958
09/28 16:57:47 - mmengine - INFO - Iter(train) [ 20500/320000]  base_lr: 9.4216e-05 lr: 9.4216e-06  eta: 1 day, 12:40:14  time: 0.4327  data_time: 0.0092  memory: 5167  grad_norm: 87.7338  loss: 10.0533  decode.loss_cls: 0.0922  decode.loss_mask: 0.6825  decode.loss_dice: 0.3171  decode.d0.loss_cls: 1.2932  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.2867  decode.d1.loss_cls: 0.3033  decode.d1.loss_mask: 0.2844  decode.d1.loss_dice: 0.2666  decode.d2.loss_cls: 0.3160  decode.d2.loss_mask: 0.2859  decode.d2.loss_dice: 0.2576  decode.d3.loss_cls: 0.2892  decode.d3.loss_mask: 0.2928  decode.d3.loss_dice: 0.2791  decode.d4.loss_cls: 0.3400  decode.d4.loss_mask: 0.2946  decode.d4.loss_dice: 0.2658  decode.d5.loss_cls: 0.3094  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.2562  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 0.4141  decode.d6.loss_dice: 0.2770  decode.d7.loss_cls: 0.1683  decode.d7.loss_mask: 0.4301  decode.d7.loss_dice: 0.2894  decode.d8.loss_cls: 0.1933  decode.d8.loss_mask: 0.4847  decode.d8.loss_dice: 0.2971
09/28 16:58:09 - mmengine - INFO - Iter(train) [ 20550/320000]  base_lr: 9.4202e-05 lr: 9.4202e-06  eta: 1 day, 12:39:47  time: 0.4356  data_time: 0.0092  memory: 5186  grad_norm: 64.3938  loss: 9.4979  decode.loss_cls: 0.2572  decode.loss_mask: 0.2329  decode.loss_dice: 0.3347  decode.d0.loss_cls: 1.0199  decode.d0.loss_mask: 0.2415  decode.d0.loss_dice: 0.3489  decode.d1.loss_cls: 0.4082  decode.d1.loss_mask: 0.2375  decode.d1.loss_dice: 0.3667  decode.d2.loss_cls: 0.2653  decode.d2.loss_mask: 0.2373  decode.d2.loss_dice: 0.3603  decode.d3.loss_cls: 0.2797  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.3469  decode.d4.loss_cls: 0.3345  decode.d4.loss_mask: 0.2344  decode.d4.loss_dice: 0.3443  decode.d5.loss_cls: 0.3384  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.3686  decode.d6.loss_cls: 0.2394  decode.d6.loss_mask: 0.2367  decode.d6.loss_dice: 0.3508  decode.d7.loss_cls: 0.2829  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.3150  decode.d8.loss_cls: 0.2432  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.3406
09/28 16:58:31 - mmengine - INFO - Iter(train) [ 20600/320000]  base_lr: 9.4187e-05 lr: 9.4187e-06  eta: 1 day, 12:39:20  time: 0.4321  data_time: 0.0091  memory: 5186  grad_norm: 45.3800  loss: 7.0234  decode.loss_cls: 0.1617  decode.loss_mask: 0.3063  decode.loss_dice: 0.2214  decode.d0.loss_cls: 0.9660  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.2187  decode.d1.loss_cls: 0.1779  decode.d1.loss_mask: 0.2911  decode.d1.loss_dice: 0.1991  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.2923  decode.d2.loss_dice: 0.1962  decode.d3.loss_cls: 0.0730  decode.d3.loss_mask: 0.2961  decode.d3.loss_dice: 0.2052  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.2981  decode.d4.loss_dice: 0.2107  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.2961  decode.d5.loss_dice: 0.2026  decode.d6.loss_cls: 0.1017  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.1971  decode.d7.loss_cls: 0.1242  decode.d7.loss_mask: 0.2976  decode.d7.loss_dice: 0.2051  decode.d8.loss_cls: 0.1300  decode.d8.loss_mask: 0.2996  decode.d8.loss_dice: 0.2172
09/28 16:58:52 - mmengine - INFO - Iter(train) [ 20650/320000]  base_lr: 9.4173e-05 lr: 9.4173e-06  eta: 1 day, 12:38:52  time: 0.4322  data_time: 0.0090  memory: 5167  grad_norm: 83.1018  loss: 6.7386  decode.loss_cls: 0.0621  decode.loss_mask: 0.3035  decode.loss_dice: 0.2219  decode.d0.loss_cls: 0.7833  decode.d0.loss_mask: 0.3117  decode.d0.loss_dice: 0.2474  decode.d1.loss_cls: 0.0870  decode.d1.loss_mask: 0.2961  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.2277  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.3012  decode.d4.loss_dice: 0.2325  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.3042  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.2984  decode.d6.loss_dice: 0.2197  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.3038  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.2314
09/28 16:59:14 - mmengine - INFO - Iter(train) [ 20700/320000]  base_lr: 9.4159e-05 lr: 9.4159e-06  eta: 1 day, 12:38:24  time: 0.4321  data_time: 0.0090  memory: 5166  grad_norm: 36.0845  loss: 5.6470  decode.loss_cls: 0.1255  decode.loss_mask: 0.1869  decode.loss_dice: 0.1977  decode.d0.loss_cls: 0.9753  decode.d0.loss_mask: 0.1879  decode.d0.loss_dice: 0.1986  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 0.1863  decode.d1.loss_dice: 0.2112  decode.d2.loss_cls: 0.1102  decode.d2.loss_mask: 0.1846  decode.d2.loss_dice: 0.1974  decode.d3.loss_cls: 0.1058  decode.d3.loss_mask: 0.1861  decode.d3.loss_dice: 0.1932  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.1891  decode.d4.loss_dice: 0.1922  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.1867  decode.d5.loss_dice: 0.1899  decode.d6.loss_cls: 0.0934  decode.d6.loss_mask: 0.1867  decode.d6.loss_dice: 0.1879  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.1867  decode.d7.loss_dice: 0.1945  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.1853  decode.d8.loss_dice: 0.1955
09/28 16:59:36 - mmengine - INFO - Iter(train) [ 20750/320000]  base_lr: 9.4145e-05 lr: 9.4145e-06  eta: 1 day, 12:37:56  time: 0.4323  data_time: 0.0092  memory: 5166  grad_norm: 64.5549  loss: 5.9230  decode.loss_cls: 0.0516  decode.loss_mask: 0.2403  decode.loss_dice: 0.2078  decode.d0.loss_cls: 0.8362  decode.d0.loss_mask: 0.2471  decode.d0.loss_dice: 0.2192  decode.d1.loss_cls: 0.1384  decode.d1.loss_mask: 0.2456  decode.d1.loss_dice: 0.2178  decode.d2.loss_cls: 0.0300  decode.d2.loss_mask: 0.2409  decode.d2.loss_dice: 0.2104  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.2414  decode.d3.loss_dice: 0.2031  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.2431  decode.d4.loss_dice: 0.2116  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.2441  decode.d5.loss_dice: 0.2188  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2115  decode.d7.loss_cls: 0.0404  decode.d7.loss_mask: 0.2444  decode.d7.loss_dice: 0.2163  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2180
09/28 16:59:57 - mmengine - INFO - Iter(train) [ 20800/320000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 1 day, 12:37:28  time: 0.4328  data_time: 0.0092  memory: 5186  grad_norm: 51.2119  loss: 7.2317  decode.loss_cls: 0.1407  decode.loss_mask: 0.2349  decode.loss_dice: 0.2693  decode.d0.loss_cls: 0.8894  decode.d0.loss_mask: 0.2343  decode.d0.loss_dice: 0.2868  decode.d1.loss_cls: 0.1521  decode.d1.loss_mask: 0.2332  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.1769  decode.d2.loss_mask: 0.2369  decode.d2.loss_dice: 0.2481  decode.d3.loss_cls: 0.1812  decode.d3.loss_mask: 0.2336  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.1896  decode.d4.loss_mask: 0.2341  decode.d4.loss_dice: 0.2511  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 0.2339  decode.d5.loss_dice: 0.2530  decode.d6.loss_cls: 0.1266  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2378  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.2309  decode.d7.loss_dice: 0.2567  decode.d8.loss_cls: 0.1388  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2579
09/28 17:00:19 - mmengine - INFO - Iter(train) [ 20850/320000]  base_lr: 9.4117e-05 lr: 9.4117e-06  eta: 1 day, 12:37:00  time: 0.4324  data_time: 0.0091  memory: 5166  grad_norm: 67.9534  loss: 7.3674  decode.loss_cls: 0.1350  decode.loss_mask: 0.2283  decode.loss_dice: 0.2397  decode.d0.loss_cls: 1.1179  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.2592  decode.d1.loss_cls: 0.2412  decode.d1.loss_mask: 0.2483  decode.d1.loss_dice: 0.2486  decode.d2.loss_cls: 0.1793  decode.d2.loss_mask: 0.2361  decode.d2.loss_dice: 0.2394  decode.d3.loss_cls: 0.1613  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.2388  decode.d4.loss_cls: 0.2172  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2414  decode.d5.loss_cls: 0.1469  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.2419  decode.d6.loss_cls: 0.1465  decode.d6.loss_mask: 0.2311  decode.d6.loss_dice: 0.2372  decode.d7.loss_cls: 0.1240  decode.d7.loss_mask: 0.2293  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.2267  decode.d8.loss_dice: 0.2565
09/28 17:00:40 - mmengine - INFO - Iter(train) [ 20900/320000]  base_lr: 9.4102e-05 lr: 9.4102e-06  eta: 1 day, 12:36:32  time: 0.4324  data_time: 0.0091  memory: 5167  grad_norm: 43.9633  loss: 7.5532  decode.loss_cls: 0.1954  decode.loss_mask: 0.2070  decode.loss_dice: 0.2206  decode.d0.loss_cls: 1.1162  decode.d0.loss_mask: 0.2157  decode.d0.loss_dice: 0.2232  decode.d1.loss_cls: 0.2974  decode.d1.loss_mask: 0.2108  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.2677  decode.d2.loss_mask: 0.2095  decode.d2.loss_dice: 0.2256  decode.d3.loss_cls: 0.1855  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2238  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.2098  decode.d4.loss_dice: 0.2303  decode.d5.loss_cls: 0.2694  decode.d5.loss_mask: 0.2114  decode.d5.loss_dice: 0.2221  decode.d6.loss_cls: 0.2427  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.2181  decode.d7.loss_cls: 0.2370  decode.d7.loss_mask: 0.2090  decode.d7.loss_dice: 0.2198  decode.d8.loss_cls: 0.2368  decode.d8.loss_mask: 0.2091  decode.d8.loss_dice: 0.2170
09/28 17:01:02 - mmengine - INFO - Iter(train) [ 20950/320000]  base_lr: 9.4088e-05 lr: 9.4088e-06  eta: 1 day, 12:36:04  time: 0.4327  data_time: 0.0092  memory: 5166  grad_norm: 82.1544  loss: 7.4291  decode.loss_cls: 0.1459  decode.loss_mask: 0.2808  decode.loss_dice: 0.2638  decode.d0.loss_cls: 1.0202  decode.d0.loss_mask: 0.2881  decode.d0.loss_dice: 0.2835  decode.d1.loss_cls: 0.1454  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 0.2807  decode.d2.loss_dice: 0.2357  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.2794  decode.d3.loss_dice: 0.2343  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.2860  decode.d4.loss_dice: 0.2376  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.1091  decode.d6.loss_mask: 0.2840  decode.d6.loss_dice: 0.2514  decode.d7.loss_cls: 0.1217  decode.d7.loss_mask: 0.2822  decode.d7.loss_dice: 0.2499  decode.d8.loss_cls: 0.1181  decode.d8.loss_mask: 0.2808  decode.d8.loss_dice: 0.2478
09/28 17:01:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:01:24 - mmengine - INFO - Iter(train) [ 21000/320000]  base_lr: 9.4074e-05 lr: 9.4074e-06  eta: 1 day, 12:35:36  time: 0.4325  data_time: 0.0092  memory: 5167  grad_norm: 85.6637  loss: 7.4057  decode.loss_cls: 0.1439  decode.loss_mask: 0.2672  decode.loss_dice: 0.2585  decode.d0.loss_cls: 1.0330  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.2618  decode.d1.loss_cls: 0.1622  decode.d1.loss_mask: 0.2769  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.1585  decode.d2.loss_mask: 0.2703  decode.d2.loss_dice: 0.2566  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.2767  decode.d4.loss_dice: 0.2567  decode.d5.loss_cls: 0.1448  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2565  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.2640  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.2616  decode.d7.loss_dice: 0.2544  decode.d8.loss_cls: 0.1377  decode.d8.loss_mask: 0.2679  decode.d8.loss_dice: 0.2489
09/28 17:01:46 - mmengine - INFO - Iter(train) [ 21050/320000]  base_lr: 9.4060e-05 lr: 9.4060e-06  eta: 1 day, 12:35:10  time: 0.4513  data_time: 0.0093  memory: 5148  grad_norm: 104.0526  loss: 9.1108  decode.loss_cls: 0.1931  decode.loss_mask: 0.3566  decode.loss_dice: 0.2386  decode.d0.loss_cls: 0.9055  decode.d0.loss_mask: 0.3650  decode.d0.loss_dice: 0.2403  decode.d1.loss_cls: 0.2759  decode.d1.loss_mask: 0.3488  decode.d1.loss_dice: 0.2274  decode.d2.loss_cls: 0.2913  decode.d2.loss_mask: 0.3585  decode.d2.loss_dice: 0.2310  decode.d3.loss_cls: 0.3292  decode.d3.loss_mask: 0.3428  decode.d3.loss_dice: 0.2281  decode.d4.loss_cls: 0.2247  decode.d4.loss_mask: 0.3555  decode.d4.loss_dice: 0.2369  decode.d5.loss_cls: 0.2248  decode.d5.loss_mask: 0.3538  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.2926  decode.d6.loss_mask: 0.3561  decode.d6.loss_dice: 0.2299  decode.d7.loss_cls: 0.2712  decode.d7.loss_mask: 0.3533  decode.d7.loss_dice: 0.2294  decode.d8.loss_cls: 0.2405  decode.d8.loss_mask: 0.3481  decode.d8.loss_dice: 0.2291
09/28 17:02:07 - mmengine - INFO - Iter(train) [ 21100/320000]  base_lr: 9.4046e-05 lr: 9.4046e-06  eta: 1 day, 12:34:42  time: 0.4319  data_time: 0.0091  memory: 5186  grad_norm: 98.6834  loss: 6.8778  decode.loss_cls: 0.1052  decode.loss_mask: 0.2585  decode.loss_dice: 0.2456  decode.d0.loss_cls: 0.8739  decode.d0.loss_mask: 0.2745  decode.d0.loss_dice: 0.2561  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.2721  decode.d1.loss_dice: 0.2404  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.2689  decode.d2.loss_dice: 0.2281  decode.d3.loss_cls: 0.1150  decode.d3.loss_mask: 0.2551  decode.d3.loss_dice: 0.2214  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.2527  decode.d4.loss_dice: 0.2237  decode.d5.loss_cls: 0.1166  decode.d5.loss_mask: 0.2552  decode.d5.loss_dice: 0.2247  decode.d6.loss_cls: 0.1210  decode.d6.loss_mask: 0.2540  decode.d6.loss_dice: 0.2404  decode.d7.loss_cls: 0.1034  decode.d7.loss_mask: 0.2667  decode.d7.loss_dice: 0.2464  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.2489
09/28 17:02:29 - mmengine - INFO - Iter(train) [ 21150/320000]  base_lr: 9.4032e-05 lr: 9.4032e-06  eta: 1 day, 12:34:14  time: 0.4323  data_time: 0.0092  memory: 5186  grad_norm: 140.2137  loss: 10.6461  decode.loss_cls: 0.2752  decode.loss_mask: 0.2959  decode.loss_dice: 0.3872  decode.d0.loss_cls: 1.0454  decode.d0.loss_mask: 0.2953  decode.d0.loss_dice: 0.3748  decode.d1.loss_cls: 0.3272  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.3724  decode.d2.loss_cls: 0.3546  decode.d2.loss_mask: 0.2920  decode.d2.loss_dice: 0.3596  decode.d3.loss_cls: 0.2695  decode.d3.loss_mask: 0.2903  decode.d3.loss_dice: 0.3364  decode.d4.loss_cls: 0.2905  decode.d4.loss_mask: 0.2912  decode.d4.loss_dice: 0.3520  decode.d5.loss_cls: 0.2889  decode.d5.loss_mask: 0.2891  decode.d5.loss_dice: 0.3760  decode.d6.loss_cls: 0.4054  decode.d6.loss_mask: 0.2933  decode.d6.loss_dice: 0.3391  decode.d7.loss_cls: 0.4663  decode.d7.loss_mask: 0.2865  decode.d7.loss_dice: 0.3748  decode.d8.loss_cls: 0.3780  decode.d8.loss_mask: 0.2904  decode.d8.loss_dice: 0.3544
09/28 17:02:50 - mmengine - INFO - Iter(train) [ 21200/320000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 1 day, 12:33:46  time: 0.4319  data_time: 0.0091  memory: 5186  grad_norm: 101.1781  loss: 10.3956  decode.loss_cls: 0.2495  decode.loss_mask: 0.3342  decode.loss_dice: 0.3524  decode.d0.loss_cls: 0.9500  decode.d0.loss_mask: 0.3456  decode.d0.loss_dice: 0.3465  decode.d1.loss_cls: 0.4014  decode.d1.loss_mask: 0.3627  decode.d1.loss_dice: 0.3533  decode.d2.loss_cls: 0.3668  decode.d2.loss_mask: 0.3427  decode.d2.loss_dice: 0.3368  decode.d3.loss_cls: 0.2982  decode.d3.loss_mask: 0.3518  decode.d3.loss_dice: 0.3495  decode.d4.loss_cls: 0.2332  decode.d4.loss_mask: 0.3462  decode.d4.loss_dice: 0.3785  decode.d5.loss_cls: 0.2290  decode.d5.loss_mask: 0.3385  decode.d5.loss_dice: 0.3530  decode.d6.loss_cls: 0.2796  decode.d6.loss_mask: 0.3328  decode.d6.loss_dice: 0.3344  decode.d7.loss_cls: 0.2234  decode.d7.loss_mask: 0.3314  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.2608  decode.d8.loss_mask: 0.3311  decode.d8.loss_dice: 0.3370
09/28 17:03:12 - mmengine - INFO - Iter(train) [ 21250/320000]  base_lr: 9.4003e-05 lr: 9.4003e-06  eta: 1 day, 12:33:18  time: 0.4318  data_time: 0.0092  memory: 5149  grad_norm: 87.0995  loss: 6.7751  decode.loss_cls: 0.1168  decode.loss_mask: 0.2803  decode.loss_dice: 0.2139  decode.d0.loss_cls: 0.8090  decode.d0.loss_mask: 0.2879  decode.d0.loss_dice: 0.2255  decode.d1.loss_cls: 0.1620  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.1990  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.2806  decode.d2.loss_dice: 0.1975  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 0.2794  decode.d3.loss_dice: 0.1986  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 0.2830  decode.d4.loss_dice: 0.2038  decode.d5.loss_cls: 0.1078  decode.d5.loss_mask: 0.2881  decode.d5.loss_dice: 0.1971  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.2798  decode.d6.loss_dice: 0.2037  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.2845  decode.d7.loss_dice: 0.2070  decode.d8.loss_cls: 0.1606  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.2055
09/28 17:03:34 - mmengine - INFO - Iter(train) [ 21300/320000]  base_lr: 9.3989e-05 lr: 9.3989e-06  eta: 1 day, 12:32:50  time: 0.4323  data_time: 0.0092  memory: 5186  grad_norm: 67.6140  loss: 6.4506  decode.loss_cls: 0.0558  decode.loss_mask: 0.2692  decode.loss_dice: 0.2353  decode.d0.loss_cls: 0.7839  decode.d0.loss_mask: 0.2731  decode.d0.loss_dice: 0.2311  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.2716  decode.d1.loss_dice: 0.2280  decode.d2.loss_cls: 0.0723  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2224  decode.d3.loss_cls: 0.0846  decode.d3.loss_mask: 0.2706  decode.d3.loss_dice: 0.2188  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.2734  decode.d4.loss_dice: 0.2379  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.2718  decode.d5.loss_dice: 0.2351  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.2330  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.2701  decode.d7.loss_dice: 0.2352  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.2309
09/28 17:03:55 - mmengine - INFO - Iter(train) [ 21350/320000]  base_lr: 9.3975e-05 lr: 9.3975e-06  eta: 1 day, 12:32:22  time: 0.4324  data_time: 0.0091  memory: 5167  grad_norm: 171.5530  loss: 10.1557  decode.loss_cls: 0.3728  decode.loss_mask: 0.3322  decode.loss_dice: 0.2933  decode.d0.loss_cls: 1.0508  decode.d0.loss_mask: 0.3498  decode.d0.loss_dice: 0.3163  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.2908  decode.d2.loss_cls: 0.2801  decode.d2.loss_mask: 0.3324  decode.d2.loss_dice: 0.2900  decode.d3.loss_cls: 0.2424  decode.d3.loss_mask: 0.3415  decode.d3.loss_dice: 0.2856  decode.d4.loss_cls: 0.2372  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3028  decode.d5.loss_cls: 0.2832  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.2955  decode.d6.loss_cls: 0.3258  decode.d6.loss_mask: 0.3293  decode.d6.loss_dice: 0.3037  decode.d7.loss_cls: 0.3279  decode.d7.loss_mask: 0.3349  decode.d7.loss_dice: 0.3347  decode.d8.loss_cls: 0.3877  decode.d8.loss_mask: 0.3320  decode.d8.loss_dice: 0.3046
09/28 17:04:17 - mmengine - INFO - Iter(train) [ 21400/320000]  base_lr: 9.3961e-05 lr: 9.3961e-06  eta: 1 day, 12:31:55  time: 0.4321  data_time: 0.0093  memory: 5186  grad_norm: 27.4956  loss: 6.2090  decode.loss_cls: 0.0988  decode.loss_mask: 0.2799  decode.loss_dice: 0.1989  decode.d0.loss_cls: 0.9608  decode.d0.loss_mask: 0.2416  decode.d0.loss_dice: 0.2024  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.2416  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.1853  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.2766  decode.d3.loss_dice: 0.1924  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.2435  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.1798  decode.d6.loss_cls: 0.1043  decode.d6.loss_mask: 0.2385  decode.d6.loss_dice: 0.1826  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.1876  decode.d8.loss_cls: 0.0966  decode.d8.loss_mask: 0.2793  decode.d8.loss_dice: 0.2044
09/28 17:04:38 - mmengine - INFO - Iter(train) [ 21450/320000]  base_lr: 9.3947e-05 lr: 9.3947e-06  eta: 1 day, 12:31:27  time: 0.4324  data_time: 0.0092  memory: 5167  grad_norm: 89.4908  loss: 6.8823  decode.loss_cls: 0.1321  decode.loss_mask: 0.2492  decode.loss_dice: 0.2108  decode.d0.loss_cls: 1.0418  decode.d0.loss_mask: 0.2609  decode.d0.loss_dice: 0.2366  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 0.2457  decode.d1.loss_dice: 0.2052  decode.d2.loss_cls: 0.1093  decode.d2.loss_mask: 0.2527  decode.d2.loss_dice: 0.2139  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.2482  decode.d3.loss_dice: 0.2022  decode.d4.loss_cls: 0.1593  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.1704  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.2230  decode.d6.loss_cls: 0.1181  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.2122  decode.d7.loss_cls: 0.1078  decode.d7.loss_mask: 0.2485  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2141
09/28 17:05:00 - mmengine - INFO - Iter(train) [ 21500/320000]  base_lr: 9.3933e-05 lr: 9.3933e-06  eta: 1 day, 12:30:59  time: 0.4327  data_time: 0.0092  memory: 5186  grad_norm: 53.9923  loss: 8.1369  decode.loss_cls: 0.2017  decode.loss_mask: 0.2819  decode.loss_dice: 0.2697  decode.d0.loss_cls: 0.8829  decode.d0.loss_mask: 0.2957  decode.d0.loss_dice: 0.2843  decode.d1.loss_cls: 0.2158  decode.d1.loss_mask: 0.2838  decode.d1.loss_dice: 0.2413  decode.d2.loss_cls: 0.1952  decode.d2.loss_mask: 0.2869  decode.d2.loss_dice: 0.2634  decode.d3.loss_cls: 0.1773  decode.d3.loss_mask: 0.2857  decode.d3.loss_dice: 0.2542  decode.d4.loss_cls: 0.1763  decode.d4.loss_mask: 0.2845  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 0.2847  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.1666  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.2705  decode.d7.loss_cls: 0.2034  decode.d7.loss_mask: 0.2843  decode.d7.loss_dice: 0.2734  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.2839  decode.d8.loss_dice: 0.2744
09/28 17:05:22 - mmengine - INFO - Iter(train) [ 21550/320000]  base_lr: 9.3918e-05 lr: 9.3918e-06  eta: 1 day, 12:30:31  time: 0.4319  data_time: 0.0092  memory: 5186  grad_norm: 40.9791  loss: 7.7067  decode.loss_cls: 0.2141  decode.loss_mask: 0.2233  decode.loss_dice: 0.2073  decode.d0.loss_cls: 0.9974  decode.d0.loss_mask: 0.2196  decode.d0.loss_dice: 0.2119  decode.d1.loss_cls: 0.2990  decode.d1.loss_mask: 0.2225  decode.d1.loss_dice: 0.1973  decode.d2.loss_cls: 0.2607  decode.d2.loss_mask: 0.2229  decode.d2.loss_dice: 0.1935  decode.d3.loss_cls: 0.2965  decode.d3.loss_mask: 0.2206  decode.d3.loss_dice: 0.2006  decode.d4.loss_cls: 0.2980  decode.d4.loss_mask: 0.2204  decode.d4.loss_dice: 0.2001  decode.d5.loss_cls: 0.2776  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2007  decode.d6.loss_cls: 0.2451  decode.d6.loss_mask: 0.2234  decode.d6.loss_dice: 0.2092  decode.d7.loss_cls: 0.2988  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.2866  decode.d8.loss_mask: 0.2222  decode.d8.loss_dice: 0.1952
09/28 17:05:43 - mmengine - INFO - Iter(train) [ 21600/320000]  base_lr: 9.3904e-05 lr: 9.3904e-06  eta: 1 day, 12:30:03  time: 0.4314  data_time: 0.0093  memory: 5166  grad_norm: 33.6093  loss: 4.9059  decode.loss_cls: 0.0411  decode.loss_mask: 0.2094  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.8333  decode.d0.loss_mask: 0.2125  decode.d0.loss_dice: 0.1783  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.2048  decode.d1.loss_dice: 0.1640  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.2080  decode.d2.loss_dice: 0.1619  decode.d3.loss_cls: 0.0304  decode.d3.loss_mask: 0.2063  decode.d3.loss_dice: 0.1599  decode.d4.loss_cls: 0.0333  decode.d4.loss_mask: 0.2106  decode.d4.loss_dice: 0.1624  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.2091  decode.d5.loss_dice: 0.1616  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.2064  decode.d6.loss_dice: 0.1635  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.2052  decode.d7.loss_dice: 0.1648  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.1610
09/28 17:06:05 - mmengine - INFO - Iter(train) [ 21650/320000]  base_lr: 9.3890e-05 lr: 9.3890e-06  eta: 1 day, 12:29:38  time: 0.4352  data_time: 0.0092  memory: 5186  grad_norm: 111.7005  loss: 7.3576  decode.loss_cls: 0.1943  decode.loss_mask: 0.2345  decode.loss_dice: 0.2150  decode.d0.loss_cls: 1.1224  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.1988  decode.d1.loss_cls: 0.1504  decode.d1.loss_mask: 0.2320  decode.d1.loss_dice: 0.2271  decode.d2.loss_cls: 0.2133  decode.d2.loss_mask: 0.2448  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.1053  decode.d3.loss_mask: 0.3355  decode.d3.loss_dice: 0.2506  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.2316  decode.d5.loss_cls: 0.1720  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.2328  decode.d6.loss_cls: 0.1718  decode.d6.loss_mask: 0.2874  decode.d6.loss_dice: 0.2244  decode.d7.loss_cls: 0.1252  decode.d7.loss_mask: 0.2644  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.1508  decode.d8.loss_mask: 0.2193  decode.d8.loss_dice: 0.1899
09/28 17:06:27 - mmengine - INFO - Iter(train) [ 21700/320000]  base_lr: 9.3876e-05 lr: 9.3876e-06  eta: 1 day, 12:29:12  time: 0.4345  data_time: 0.0091  memory: 5167  grad_norm: 53.5914  loss: 6.5185  decode.loss_cls: 0.1236  decode.loss_mask: 0.2459  decode.loss_dice: 0.2048  decode.d0.loss_cls: 0.9389  decode.d0.loss_mask: 0.2527  decode.d0.loss_dice: 0.2110  decode.d1.loss_cls: 0.0961  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.2085  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 0.2423  decode.d2.loss_dice: 0.2064  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.2061  decode.d4.loss_cls: 0.1084  decode.d4.loss_mask: 0.2515  decode.d4.loss_dice: 0.2044  decode.d5.loss_cls: 0.1152  decode.d5.loss_mask: 0.2484  decode.d5.loss_dice: 0.2030  decode.d6.loss_cls: 0.1240  decode.d6.loss_mask: 0.2490  decode.d6.loss_dice: 0.2027  decode.d7.loss_cls: 0.1531  decode.d7.loss_mask: 0.2447  decode.d7.loss_dice: 0.1943  decode.d8.loss_cls: 0.1059  decode.d8.loss_mask: 0.2488  decode.d8.loss_dice: 0.2017
09/28 17:06:48 - mmengine - INFO - Iter(train) [ 21750/320000]  base_lr: 9.3862e-05 lr: 9.3862e-06  eta: 1 day, 12:28:46  time: 0.4346  data_time: 0.0092  memory: 5150  grad_norm: 77.5179  loss: 7.7180  decode.loss_cls: 0.1293  decode.loss_mask: 0.2430  decode.loss_dice: 0.2354  decode.d0.loss_cls: 1.1690  decode.d0.loss_mask: 0.2543  decode.d0.loss_dice: 0.2722  decode.d1.loss_cls: 0.2666  decode.d1.loss_mask: 0.2528  decode.d1.loss_dice: 0.2738  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 0.2473  decode.d2.loss_dice: 0.2515  decode.d3.loss_cls: 0.1809  decode.d3.loss_mask: 0.2467  decode.d3.loss_dice: 0.2462  decode.d4.loss_cls: 0.1744  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.2457  decode.d5.loss_cls: 0.1944  decode.d5.loss_mask: 0.2480  decode.d5.loss_dice: 0.2830  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.2441  decode.d6.loss_dice: 0.2584  decode.d7.loss_cls: 0.1257  decode.d7.loss_mask: 0.2461  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2522
09/28 17:07:10 - mmengine - INFO - Iter(train) [ 21800/320000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 1 day, 12:28:21  time: 0.4352  data_time: 0.0093  memory: 5186  grad_norm: 50.0850  loss: 8.0667  decode.loss_cls: 0.1058  decode.loss_mask: 0.2578  decode.loss_dice: 0.2861  decode.d0.loss_cls: 1.2727  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.3058  decode.d1.loss_cls: 0.1565  decode.d1.loss_mask: 0.2653  decode.d1.loss_dice: 0.2969  decode.d2.loss_cls: 0.1351  decode.d2.loss_mask: 0.2618  decode.d2.loss_dice: 0.2943  decode.d3.loss_cls: 0.1069  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.2954  decode.d4.loss_cls: 0.1577  decode.d4.loss_mask: 0.2616  decode.d4.loss_dice: 0.2999  decode.d5.loss_cls: 0.1688  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.2955  decode.d6.loss_cls: 0.1510  decode.d6.loss_mask: 0.2652  decode.d6.loss_dice: 0.2902  decode.d7.loss_cls: 0.1599  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.2925  decode.d8.loss_cls: 0.1051  decode.d8.loss_mask: 0.2581  decode.d8.loss_dice: 0.2955
09/28 17:07:32 - mmengine - INFO - Iter(train) [ 21850/320000]  base_lr: 9.3833e-05 lr: 9.3833e-06  eta: 1 day, 12:27:55  time: 0.4350  data_time: 0.0091  memory: 5166  grad_norm: 49.4330  loss: 5.5834  decode.loss_cls: 0.1229  decode.loss_mask: 0.2072  decode.loss_dice: 0.1827  decode.d0.loss_cls: 0.9130  decode.d0.loss_mask: 0.2077  decode.d0.loss_dice: 0.1972  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2034  decode.d1.loss_dice: 0.1837  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.2076  decode.d2.loss_dice: 0.1855  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.2054  decode.d3.loss_dice: 0.1755  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.2050  decode.d4.loss_dice: 0.1825  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.2032  decode.d5.loss_dice: 0.1767  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.2052  decode.d6.loss_dice: 0.1817  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.2045  decode.d7.loss_dice: 0.1839  decode.d8.loss_cls: 0.1312  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.1759
09/28 17:07:54 - mmengine - INFO - Iter(train) [ 21900/320000]  base_lr: 9.3819e-05 lr: 9.3819e-06  eta: 1 day, 12:27:30  time: 0.4348  data_time: 0.0094  memory: 5186  grad_norm: 69.1870  loss: 7.8518  decode.loss_cls: 0.2184  decode.loss_mask: 0.3355  decode.loss_dice: 0.2816  decode.d0.loss_cls: 0.9000  decode.d0.loss_mask: 0.2707  decode.d0.loss_dice: 0.2854  decode.d1.loss_cls: 0.2476  decode.d1.loss_mask: 0.2585  decode.d1.loss_dice: 0.2654  decode.d2.loss_cls: 0.2045  decode.d2.loss_mask: 0.2481  decode.d2.loss_dice: 0.2510  decode.d3.loss_cls: 0.1969  decode.d3.loss_mask: 0.2471  decode.d3.loss_dice: 0.2404  decode.d4.loss_cls: 0.1491  decode.d4.loss_mask: 0.2476  decode.d4.loss_dice: 0.2655  decode.d5.loss_cls: 0.1514  decode.d5.loss_mask: 0.2470  decode.d5.loss_dice: 0.2787  decode.d6.loss_cls: 0.1595  decode.d6.loss_mask: 0.2475  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.1916  decode.d7.loss_mask: 0.2493  decode.d7.loss_dice: 0.2483  decode.d8.loss_cls: 0.1826  decode.d8.loss_mask: 0.2507  decode.d8.loss_dice: 0.2617
09/28 17:08:15 - mmengine - INFO - Iter(train) [ 21950/320000]  base_lr: 9.3805e-05 lr: 9.3805e-06  eta: 1 day, 12:27:04  time: 0.4351  data_time: 0.0092  memory: 5166  grad_norm: 55.4722  loss: 6.7166  decode.loss_cls: 0.0460  decode.loss_mask: 0.3040  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.9973  decode.d0.loss_mask: 0.2942  decode.d0.loss_dice: 0.2131  decode.d1.loss_cls: 0.1129  decode.d1.loss_mask: 0.2890  decode.d1.loss_dice: 0.2141  decode.d2.loss_cls: 0.0707  decode.d2.loss_mask: 0.2888  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.2877  decode.d3.loss_dice: 0.2090  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.2059  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.3190  decode.d5.loss_dice: 0.2144  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.3228  decode.d6.loss_dice: 0.2173  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.3230  decode.d7.loss_dice: 0.2171  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.2939  decode.d8.loss_dice: 0.2101
09/28 17:08:37 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:08:37 - mmengine - INFO - Iter(train) [ 22000/320000]  base_lr: 9.3791e-05 lr: 9.3791e-06  eta: 1 day, 12:26:38  time: 0.4343  data_time: 0.0091  memory: 5166  grad_norm: 73.0649  loss: 8.5443  decode.loss_cls: 0.1524  decode.loss_mask: 0.3318  decode.loss_dice: 0.2979  decode.d0.loss_cls: 0.9926  decode.d0.loss_mask: 0.3199  decode.d0.loss_dice: 0.2918  decode.d1.loss_cls: 0.2329  decode.d1.loss_mask: 0.3138  decode.d1.loss_dice: 0.2407  decode.d2.loss_cls: 0.1727  decode.d2.loss_mask: 0.3149  decode.d2.loss_dice: 0.2950  decode.d3.loss_cls: 0.1584  decode.d3.loss_mask: 0.3136  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.1817  decode.d4.loss_mask: 0.3128  decode.d4.loss_dice: 0.2646  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.3226  decode.d5.loss_dice: 0.2720  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.3254  decode.d6.loss_dice: 0.2973  decode.d7.loss_cls: 0.1920  decode.d7.loss_mask: 0.3285  decode.d7.loss_dice: 0.2962  decode.d8.loss_cls: 0.1312  decode.d8.loss_mask: 0.3319  decode.d8.loss_dice: 0.3012
09/28 17:08:59 - mmengine - INFO - Iter(train) [ 22050/320000]  base_lr: 9.3777e-05 lr: 9.3777e-06  eta: 1 day, 12:26:13  time: 0.4356  data_time: 0.0091  memory: 5166  grad_norm: 72.9950  loss: 6.9954  decode.loss_cls: 0.1190  decode.loss_mask: 0.2739  decode.loss_dice: 0.2287  decode.d0.loss_cls: 0.9579  decode.d0.loss_mask: 0.2861  decode.d0.loss_dice: 0.2372  decode.d1.loss_cls: 0.1614  decode.d1.loss_mask: 0.2726  decode.d1.loss_dice: 0.2157  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.2262  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.2738  decode.d3.loss_dice: 0.2328  decode.d4.loss_cls: 0.0559  decode.d4.loss_mask: 0.2733  decode.d4.loss_dice: 0.2298  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.2225  decode.d6.loss_cls: 0.1372  decode.d6.loss_mask: 0.2646  decode.d6.loss_dice: 0.2294  decode.d7.loss_cls: 0.1546  decode.d7.loss_mask: 0.2671  decode.d7.loss_dice: 0.2293  decode.d8.loss_cls: 0.1256  decode.d8.loss_mask: 0.2709  decode.d8.loss_dice: 0.2237
09/28 17:09:21 - mmengine - INFO - Iter(train) [ 22100/320000]  base_lr: 9.3763e-05 lr: 9.3763e-06  eta: 1 day, 12:25:47  time: 0.4346  data_time: 0.0091  memory: 5167  grad_norm: 172.9764  loss: 6.8744  decode.loss_cls: 0.1100  decode.loss_mask: 0.2236  decode.loss_dice: 0.2550  decode.d0.loss_cls: 1.0520  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2670  decode.d1.loss_cls: 0.2647  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.2133  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 0.2283  decode.d2.loss_dice: 0.2280  decode.d3.loss_cls: 0.1319  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.2233  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2324  decode.d5.loss_cls: 0.1187  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.2297  decode.d6.loss_cls: 0.1141  decode.d6.loss_mask: 0.2249  decode.d6.loss_dice: 0.2307  decode.d7.loss_cls: 0.1089  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 0.2203  decode.d8.loss_dice: 0.2215
09/28 17:09:42 - mmengine - INFO - Iter(train) [ 22150/320000]  base_lr: 9.3748e-05 lr: 9.3748e-06  eta: 1 day, 12:25:21  time: 0.4344  data_time: 0.0091  memory: 5150  grad_norm: 40.8494  loss: 6.6099  decode.loss_cls: 0.0254  decode.loss_mask: 0.3119  decode.loss_dice: 0.2126  decode.d0.loss_cls: 0.8871  decode.d0.loss_mask: 0.3183  decode.d0.loss_dice: 0.2087  decode.d1.loss_cls: 0.1016  decode.d1.loss_mask: 0.3143  decode.d1.loss_dice: 0.2305  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.3081  decode.d2.loss_dice: 0.2169  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.2157  decode.d4.loss_cls: 0.0333  decode.d4.loss_mask: 0.3103  decode.d4.loss_dice: 0.2167  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.3125  decode.d5.loss_dice: 0.2348  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.3115  decode.d6.loss_dice: 0.2167  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.3118  decode.d7.loss_dice: 0.2319  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.3095  decode.d8.loss_dice: 0.2091
09/28 17:10:04 - mmengine - INFO - Iter(train) [ 22200/320000]  base_lr: 9.3734e-05 lr: 9.3734e-06  eta: 1 day, 12:24:55  time: 0.4344  data_time: 0.0091  memory: 5150  grad_norm: 68.0762  loss: 9.1329  decode.loss_cls: 0.2295  decode.loss_mask: 0.2794  decode.loss_dice: 0.2690  decode.d0.loss_cls: 1.0781  decode.d0.loss_mask: 0.2710  decode.d0.loss_dice: 0.3155  decode.d1.loss_cls: 0.3246  decode.d1.loss_mask: 0.2840  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 0.2783  decode.d2.loss_dice: 0.3089  decode.d3.loss_cls: 0.2685  decode.d3.loss_mask: 0.2707  decode.d3.loss_dice: 0.3113  decode.d4.loss_cls: 0.2753  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.3161  decode.d5.loss_cls: 0.3139  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.3007  decode.d6.loss_cls: 0.2248  decode.d6.loss_mask: 0.2719  decode.d6.loss_dice: 0.2800  decode.d7.loss_cls: 0.2328  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2666  decode.d8.loss_cls: 0.3028  decode.d8.loss_mask: 0.2822  decode.d8.loss_dice: 0.2738
09/28 17:10:26 - mmengine - INFO - Iter(train) [ 22250/320000]  base_lr: 9.3720e-05 lr: 9.3720e-06  eta: 1 day, 12:24:30  time: 0.4358  data_time: 0.0093  memory: 5167  grad_norm: 200.0537  loss: 8.4534  decode.loss_cls: 0.3174  decode.loss_mask: 0.2537  decode.loss_dice: 0.2461  decode.d0.loss_cls: 1.1824  decode.d0.loss_mask: 0.2451  decode.d0.loss_dice: 0.2737  decode.d1.loss_cls: 0.1985  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2352  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2596  decode.d3.loss_cls: 0.2550  decode.d3.loss_mask: 0.2426  decode.d3.loss_dice: 0.2417  decode.d4.loss_cls: 0.3223  decode.d4.loss_mask: 0.2380  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.2723  decode.d5.loss_mask: 0.2481  decode.d5.loss_dice: 0.2531  decode.d6.loss_cls: 0.2874  decode.d6.loss_mask: 0.2412  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.2151  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.2541  decode.d8.loss_cls: 0.2962  decode.d8.loss_mask: 0.2671  decode.d8.loss_dice: 0.2361
09/28 17:10:48 - mmengine - INFO - Iter(train) [ 22300/320000]  base_lr: 9.3706e-05 lr: 9.3706e-06  eta: 1 day, 12:24:04  time: 0.4353  data_time: 0.0093  memory: 5167  grad_norm: 100.6483  loss: 9.5689  decode.loss_cls: 0.2226  decode.loss_mask: 0.2985  decode.loss_dice: 0.2689  decode.d0.loss_cls: 1.0394  decode.d0.loss_mask: 0.3168  decode.d0.loss_dice: 0.3313  decode.d1.loss_cls: 0.3535  decode.d1.loss_mask: 0.3280  decode.d1.loss_dice: 0.2883  decode.d2.loss_cls: 0.2511  decode.d2.loss_mask: 0.3220  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.3014  decode.d3.loss_mask: 0.3395  decode.d3.loss_dice: 0.2853  decode.d4.loss_cls: 0.2400  decode.d4.loss_mask: 0.3586  decode.d4.loss_dice: 0.3093  decode.d5.loss_cls: 0.2684  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.2728  decode.d6.loss_cls: 0.2782  decode.d6.loss_mask: 0.3287  decode.d6.loss_dice: 0.2937  decode.d7.loss_cls: 0.2602  decode.d7.loss_mask: 0.3106  decode.d7.loss_dice: 0.2932  decode.d8.loss_cls: 0.2820  decode.d8.loss_mask: 0.3071  decode.d8.loss_dice: 0.2485
09/28 17:11:09 - mmengine - INFO - Iter(train) [ 22350/320000]  base_lr: 9.3692e-05 lr: 9.3692e-06  eta: 1 day, 12:23:39  time: 0.4361  data_time: 0.0093  memory: 5186  grad_norm: 75.4267  loss: 7.4278  decode.loss_cls: 0.1049  decode.loss_mask: 0.3048  decode.loss_dice: 0.2360  decode.d0.loss_cls: 0.8639  decode.d0.loss_mask: 0.3111  decode.d0.loss_dice: 0.2689  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.2487  decode.d2.loss_cls: 0.1457  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.2369  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.3085  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.1249  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.2619  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.3044  decode.d5.loss_dice: 0.2367  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.3038  decode.d6.loss_dice: 0.2497  decode.d7.loss_cls: 0.0826  decode.d7.loss_mask: 0.3067  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.1315  decode.d8.loss_mask: 0.3093  decode.d8.loss_dice: 0.2417
09/28 17:11:31 - mmengine - INFO - Iter(train) [ 22400/320000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 1 day, 12:23:14  time: 0.4359  data_time: 0.0093  memory: 5166  grad_norm: 156.1378  loss: 8.9811  decode.loss_cls: 0.2853  decode.loss_mask: 0.2215  decode.loss_dice: 0.2884  decode.d0.loss_cls: 1.1336  decode.d0.loss_mask: 0.2059  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.3765  decode.d1.loss_mask: 0.2119  decode.d1.loss_dice: 0.2820  decode.d2.loss_cls: 0.3574  decode.d2.loss_mask: 0.2125  decode.d2.loss_dice: 0.2796  decode.d3.loss_cls: 0.3803  decode.d3.loss_mask: 0.2116  decode.d3.loss_dice: 0.2850  decode.d4.loss_cls: 0.3411  decode.d4.loss_mask: 0.2062  decode.d4.loss_dice: 0.2781  decode.d5.loss_cls: 0.2581  decode.d5.loss_mask: 0.2174  decode.d5.loss_dice: 0.2915  decode.d6.loss_cls: 0.2785  decode.d6.loss_mask: 0.2122  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.3252  decode.d7.loss_mask: 0.2116  decode.d7.loss_dice: 0.2814  decode.d8.loss_cls: 0.2742  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.2844
09/28 17:11:53 - mmengine - INFO - Iter(train) [ 22450/320000]  base_lr: 9.3663e-05 lr: 9.3663e-06  eta: 1 day, 12:22:48  time: 0.4356  data_time: 0.0093  memory: 5186  grad_norm: 52.9361  loss: 7.8405  decode.loss_cls: 0.1644  decode.loss_mask: 0.3307  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.8974  decode.d0.loss_mask: 0.3382  decode.d0.loss_dice: 0.2381  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 0.3354  decode.d1.loss_dice: 0.2331  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.3325  decode.d2.loss_dice: 0.2353  decode.d3.loss_cls: 0.0982  decode.d3.loss_mask: 0.3361  decode.d3.loss_dice: 0.2358  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.3335  decode.d4.loss_dice: 0.2353  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 0.3332  decode.d5.loss_dice: 0.2381  decode.d6.loss_cls: 0.1865  decode.d6.loss_mask: 0.3303  decode.d6.loss_dice: 0.2414  decode.d7.loss_cls: 0.2028  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.3253  decode.d8.loss_dice: 0.2421
09/28 17:12:15 - mmengine - INFO - Iter(train) [ 22500/320000]  base_lr: 9.3649e-05 lr: 9.3649e-06  eta: 1 day, 12:22:23  time: 0.4346  data_time: 0.0091  memory: 5186  grad_norm: 50.2741  loss: 6.6964  decode.loss_cls: 0.2094  decode.loss_mask: 0.2173  decode.loss_dice: 0.1623  decode.d0.loss_cls: 0.8927  decode.d0.loss_mask: 0.2151  decode.d0.loss_dice: 0.1742  decode.d1.loss_cls: 0.2260  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.1668  decode.d2.loss_cls: 0.2974  decode.d2.loss_mask: 0.2217  decode.d2.loss_dice: 0.1562  decode.d3.loss_cls: 0.1837  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.1587  decode.d4.loss_cls: 0.2122  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.1517  decode.d5.loss_cls: 0.2342  decode.d5.loss_mask: 0.2200  decode.d5.loss_dice: 0.1535  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.1549  decode.d7.loss_cls: 0.2405  decode.d7.loss_mask: 0.2176  decode.d7.loss_dice: 0.1588  decode.d8.loss_cls: 0.2145  decode.d8.loss_mask: 0.2183  decode.d8.loss_dice: 0.1600
09/28 17:12:36 - mmengine - INFO - Iter(train) [ 22550/320000]  base_lr: 9.3635e-05 lr: 9.3635e-06  eta: 1 day, 12:21:58  time: 0.4351  data_time: 0.0090  memory: 5166  grad_norm: 61.6960  loss: 6.1326  decode.loss_cls: 0.1653  decode.loss_mask: 0.1770  decode.loss_dice: 0.2071  decode.d0.loss_cls: 0.8975  decode.d0.loss_mask: 0.1862  decode.d0.loss_dice: 0.2210  decode.d1.loss_cls: 0.2067  decode.d1.loss_mask: 0.1820  decode.d1.loss_dice: 0.2075  decode.d2.loss_cls: 0.1709  decode.d2.loss_mask: 0.1784  decode.d2.loss_dice: 0.2148  decode.d3.loss_cls: 0.1453  decode.d3.loss_mask: 0.1794  decode.d3.loss_dice: 0.1982  decode.d4.loss_cls: 0.1237  decode.d4.loss_mask: 0.1785  decode.d4.loss_dice: 0.2174  decode.d5.loss_cls: 0.1219  decode.d5.loss_mask: 0.1778  decode.d5.loss_dice: 0.1907  decode.d6.loss_cls: 0.1255  decode.d6.loss_mask: 0.1751  decode.d6.loss_dice: 0.2178  decode.d7.loss_cls: 0.1481  decode.d7.loss_mask: 0.1775  decode.d7.loss_dice: 0.2161  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 0.1776  decode.d8.loss_dice: 0.2146
09/28 17:12:58 - mmengine - INFO - Iter(train) [ 22600/320000]  base_lr: 9.3621e-05 lr: 9.3621e-06  eta: 1 day, 12:21:32  time: 0.4358  data_time: 0.0092  memory: 5166  grad_norm: 71.6749  loss: 7.8391  decode.loss_cls: 0.1592  decode.loss_mask: 0.3045  decode.loss_dice: 0.2277  decode.d0.loss_cls: 0.9546  decode.d0.loss_mask: 0.3000  decode.d0.loss_dice: 0.2403  decode.d1.loss_cls: 0.1728  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.2280  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.3000  decode.d2.loss_dice: 0.2281  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 0.3096  decode.d3.loss_dice: 0.2341  decode.d4.loss_cls: 0.1456  decode.d4.loss_mask: 0.3105  decode.d4.loss_dice: 0.2350  decode.d5.loss_cls: 0.1537  decode.d5.loss_mask: 0.3098  decode.d5.loss_dice: 0.2327  decode.d6.loss_cls: 0.2364  decode.d6.loss_mask: 0.3005  decode.d6.loss_dice: 0.2271  decode.d7.loss_cls: 0.2160  decode.d7.loss_mask: 0.2989  decode.d7.loss_dice: 0.2235  decode.d8.loss_cls: 0.1725  decode.d8.loss_mask: 0.2993  decode.d8.loss_dice: 0.2262
09/28 17:13:20 - mmengine - INFO - Iter(train) [ 22650/320000]  base_lr: 9.3607e-05 lr: 9.3607e-06  eta: 1 day, 12:21:07  time: 0.4350  data_time: 0.0091  memory: 5149  grad_norm: 331.3553  loss: 9.7532  decode.loss_cls: 0.3189  decode.loss_mask: 0.3184  decode.loss_dice: 0.2729  decode.d0.loss_cls: 0.8203  decode.d0.loss_mask: 0.3344  decode.d0.loss_dice: 0.2785  decode.d1.loss_cls: 0.2942  decode.d1.loss_mask: 0.3490  decode.d1.loss_dice: 0.2952  decode.d2.loss_cls: 0.2953  decode.d2.loss_mask: 0.3244  decode.d2.loss_dice: 0.2774  decode.d3.loss_cls: 0.3061  decode.d3.loss_mask: 0.3360  decode.d3.loss_dice: 0.2855  decode.d4.loss_cls: 0.2860  decode.d4.loss_mask: 0.3277  decode.d4.loss_dice: 0.2841  decode.d5.loss_cls: 0.2714  decode.d5.loss_mask: 0.3422  decode.d5.loss_dice: 0.2931  decode.d6.loss_cls: 0.2561  decode.d6.loss_mask: 0.3405  decode.d6.loss_dice: 0.2932  decode.d7.loss_cls: 0.3274  decode.d7.loss_mask: 0.3176  decode.d7.loss_dice: 0.2762  decode.d8.loss_cls: 0.3772  decode.d8.loss_mask: 0.3528  decode.d8.loss_dice: 0.3011
09/28 17:13:42 - mmengine - INFO - Iter(train) [ 22700/320000]  base_lr: 9.3593e-05 lr: 9.3593e-06  eta: 1 day, 12:20:44  time: 0.4511  data_time: 0.0090  memory: 5186  grad_norm: 34.5389  loss: 5.5927  decode.loss_cls: 0.0400  decode.loss_mask: 0.2317  decode.loss_dice: 0.1741  decode.d0.loss_cls: 0.9690  decode.d0.loss_mask: 0.2369  decode.d0.loss_dice: 0.1981  decode.d1.loss_cls: 0.0439  decode.d1.loss_mask: 0.2333  decode.d1.loss_dice: 0.1840  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.1790  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.2299  decode.d3.loss_dice: 0.1737  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.2278  decode.d4.loss_dice: 0.1881  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.1842  decode.d6.loss_cls: 0.0630  decode.d6.loss_mask: 0.2322  decode.d6.loss_dice: 0.1881  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.2333  decode.d7.loss_dice: 0.1906  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.1726
09/28 17:14:04 - mmengine - INFO - Iter(train) [ 22750/320000]  base_lr: 9.3578e-05 lr: 9.3578e-06  eta: 1 day, 12:20:18  time: 0.4347  data_time: 0.0093  memory: 5186  grad_norm: 45.9138  loss: 7.1798  decode.loss_cls: 0.1121  decode.loss_mask: 0.3043  decode.loss_dice: 0.2261  decode.d0.loss_cls: 1.1148  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.2484  decode.d1.loss_cls: 0.0681  decode.d1.loss_mask: 0.3053  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.2385  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.3092  decode.d3.loss_dice: 0.2327  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.3076  decode.d4.loss_dice: 0.2289  decode.d5.loss_cls: 0.0597  decode.d5.loss_mask: 0.3043  decode.d5.loss_dice: 0.2317  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.3061  decode.d7.loss_dice: 0.2350  decode.d8.loss_cls: 0.1196  decode.d8.loss_mask: 0.3080  decode.d8.loss_dice: 0.2301
09/28 17:14:25 - mmengine - INFO - Iter(train) [ 22800/320000]  base_lr: 9.3564e-05 lr: 9.3564e-06  eta: 1 day, 12:19:53  time: 0.4349  data_time: 0.0091  memory: 5186  grad_norm: 106.5332  loss: 9.2438  decode.loss_cls: 0.3292  decode.loss_mask: 0.2353  decode.loss_dice: 0.3147  decode.d0.loss_cls: 0.9268  decode.d0.loss_mask: 0.2392  decode.d0.loss_dice: 0.2984  decode.d1.loss_cls: 0.3508  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.3038  decode.d2.loss_cls: 0.2712  decode.d2.loss_mask: 0.2452  decode.d2.loss_dice: 0.3130  decode.d3.loss_cls: 0.3115  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.3041  decode.d4.loss_cls: 0.2970  decode.d4.loss_mask: 0.2401  decode.d4.loss_dice: 0.3121  decode.d5.loss_cls: 0.3068  decode.d5.loss_mask: 0.2330  decode.d5.loss_dice: 0.3072  decode.d6.loss_cls: 0.3362  decode.d6.loss_mask: 0.2380  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.3330  decode.d7.loss_mask: 0.2388  decode.d7.loss_dice: 0.2989  decode.d8.loss_cls: 0.3380  decode.d8.loss_mask: 0.2347  decode.d8.loss_dice: 0.3018
09/28 17:14:47 - mmengine - INFO - Iter(train) [ 22850/320000]  base_lr: 9.3550e-05 lr: 9.3550e-06  eta: 1 day, 12:19:28  time: 0.4348  data_time: 0.0092  memory: 5186  grad_norm: 58.4794  loss: 6.4059  decode.loss_cls: 0.0750  decode.loss_mask: 0.2392  decode.loss_dice: 0.2094  decode.d0.loss_cls: 1.0048  decode.d0.loss_mask: 0.2381  decode.d0.loss_dice: 0.2259  decode.d1.loss_cls: 0.1382  decode.d1.loss_mask: 0.2402  decode.d1.loss_dice: 0.2171  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.2391  decode.d2.loss_dice: 0.2232  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 0.2416  decode.d3.loss_dice: 0.2032  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.2339  decode.d4.loss_dice: 0.2043  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.2368  decode.d5.loss_dice: 0.2127  decode.d6.loss_cls: 0.1040  decode.d6.loss_mask: 0.2319  decode.d6.loss_dice: 0.2061  decode.d7.loss_cls: 0.0835  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.2267  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.2369  decode.d8.loss_dice: 0.2121
09/28 17:15:09 - mmengine - INFO - Iter(train) [ 22900/320000]  base_lr: 9.3536e-05 lr: 9.3536e-06  eta: 1 day, 12:19:02  time: 0.4344  data_time: 0.0092  memory: 5166  grad_norm: 99.5279  loss: 7.9912  decode.loss_cls: 0.1050  decode.loss_mask: 0.3605  decode.loss_dice: 0.2872  decode.d0.loss_cls: 0.9071  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.2650  decode.d1.loss_cls: 0.1390  decode.d1.loss_mask: 0.2872  decode.d1.loss_dice: 0.2796  decode.d2.loss_cls: 0.2072  decode.d2.loss_mask: 0.2725  decode.d2.loss_dice: 0.2501  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 0.2807  decode.d3.loss_dice: 0.2515  decode.d4.loss_cls: 0.2155  decode.d4.loss_mask: 0.2747  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 0.2974  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.1317  decode.d6.loss_mask: 0.2916  decode.d6.loss_dice: 0.2788  decode.d7.loss_cls: 0.1403  decode.d7.loss_mask: 0.3214  decode.d7.loss_dice: 0.2985  decode.d8.loss_cls: 0.1253  decode.d8.loss_mask: 0.3114  decode.d8.loss_dice: 0.2988
09/28 17:15:31 - mmengine - INFO - Iter(train) [ 22950/320000]  base_lr: 9.3522e-05 lr: 9.3522e-06  eta: 1 day, 12:18:37  time: 0.4346  data_time: 0.0091  memory: 5186  grad_norm: 87.7529  loss: 9.1225  decode.loss_cls: 0.1606  decode.loss_mask: 0.3581  decode.loss_dice: 0.2901  decode.d0.loss_cls: 1.0191  decode.d0.loss_mask: 0.3349  decode.d0.loss_dice: 0.3268  decode.d1.loss_cls: 0.2080  decode.d1.loss_mask: 0.3670  decode.d1.loss_dice: 0.3106  decode.d2.loss_cls: 0.1931  decode.d2.loss_mask: 0.3561  decode.d2.loss_dice: 0.3016  decode.d3.loss_cls: 0.1333  decode.d3.loss_mask: 0.3506  decode.d3.loss_dice: 0.2883  decode.d4.loss_cls: 0.1447  decode.d4.loss_mask: 0.3649  decode.d4.loss_dice: 0.3027  decode.d5.loss_cls: 0.1477  decode.d5.loss_mask: 0.3557  decode.d5.loss_dice: 0.2878  decode.d6.loss_cls: 0.1405  decode.d6.loss_mask: 0.3679  decode.d6.loss_dice: 0.3184  decode.d7.loss_cls: 0.1566  decode.d7.loss_mask: 0.3658  decode.d7.loss_dice: 0.3121  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 0.3878  decode.d8.loss_dice: 0.3051
09/28 17:15:52 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:15:52 - mmengine - INFO - Iter(train) [ 23000/320000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 1 day, 12:18:12  time: 0.4343  data_time: 0.0091  memory: 5186  grad_norm: 62.8437  loss: 7.4920  decode.loss_cls: 0.1868  decode.loss_mask: 0.2828  decode.loss_dice: 0.2137  decode.d0.loss_cls: 1.0342  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.2190  decode.d1.loss_cls: 0.1813  decode.d1.loss_mask: 0.2831  decode.d1.loss_dice: 0.2042  decode.d2.loss_cls: 0.1725  decode.d2.loss_mask: 0.2796  decode.d2.loss_dice: 0.2081  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 0.2778  decode.d3.loss_dice: 0.1895  decode.d4.loss_cls: 0.1681  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.1934  decode.d5.loss_cls: 0.1686  decode.d5.loss_mask: 0.2826  decode.d5.loss_dice: 0.2233  decode.d6.loss_cls: 0.1736  decode.d6.loss_mask: 0.2796  decode.d6.loss_dice: 0.2072  decode.d7.loss_cls: 0.1765  decode.d7.loss_mask: 0.2817  decode.d7.loss_dice: 0.1990  decode.d8.loss_cls: 0.1880  decode.d8.loss_mask: 0.2829  decode.d8.loss_dice: 0.2014
09/28 17:16:14 - mmengine - INFO - Iter(train) [ 23050/320000]  base_lr: 9.3493e-05 lr: 9.3493e-06  eta: 1 day, 12:17:46  time: 0.4356  data_time: 0.0090  memory: 5166  grad_norm: 98.1077  loss: 7.5316  decode.loss_cls: 0.2301  decode.loss_mask: 0.2140  decode.loss_dice: 0.2312  decode.d0.loss_cls: 0.9292  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.2754  decode.d1.loss_cls: 0.3025  decode.d1.loss_mask: 0.2156  decode.d1.loss_dice: 0.1971  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 0.2190  decode.d2.loss_dice: 0.2347  decode.d3.loss_cls: 0.2256  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.2232  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.2175  decode.d4.loss_dice: 0.2534  decode.d5.loss_cls: 0.2416  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.2347  decode.d6.loss_cls: 0.2505  decode.d6.loss_mask: 0.2160  decode.d6.loss_dice: 0.2169  decode.d7.loss_cls: 0.2337  decode.d7.loss_mask: 0.2131  decode.d7.loss_dice: 0.2363  decode.d8.loss_cls: 0.2265  decode.d8.loss_mask: 0.2150  decode.d8.loss_dice: 0.2062
09/28 17:16:36 - mmengine - INFO - Iter(train) [ 23100/320000]  base_lr: 9.3479e-05 lr: 9.3479e-06  eta: 1 day, 12:17:21  time: 0.4346  data_time: 0.0091  memory: 5167  grad_norm: 55.8503  loss: 6.5997  decode.loss_cls: 0.0879  decode.loss_mask: 0.2427  decode.loss_dice: 0.2050  decode.d0.loss_cls: 1.0726  decode.d0.loss_mask: 0.2458  decode.d0.loss_dice: 0.2138  decode.d1.loss_cls: 0.1965  decode.d1.loss_mask: 0.2384  decode.d1.loss_dice: 0.2068  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.2471  decode.d2.loss_dice: 0.2105  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.2408  decode.d3.loss_dice: 0.2225  decode.d4.loss_cls: 0.1290  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.2011  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.2412  decode.d5.loss_dice: 0.2074  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.2394  decode.d6.loss_dice: 0.1968  decode.d7.loss_cls: 0.1238  decode.d7.loss_mask: 0.2379  decode.d7.loss_dice: 0.2068  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.2455  decode.d8.loss_dice: 0.2231
09/28 17:16:58 - mmengine - INFO - Iter(train) [ 23150/320000]  base_lr: 9.3465e-05 lr: 9.3465e-06  eta: 1 day, 12:16:56  time: 0.4340  data_time: 0.0088  memory: 5167  grad_norm: 59.9617  loss: 7.3971  decode.loss_cls: 0.1803  decode.loss_mask: 0.2248  decode.loss_dice: 0.2278  decode.d0.loss_cls: 1.0574  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2659  decode.d1.loss_cls: 0.2797  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.2439  decode.d2.loss_cls: 0.2308  decode.d2.loss_mask: 0.2296  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.1729  decode.d3.loss_mask: 0.2268  decode.d3.loss_dice: 0.2430  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 0.2236  decode.d4.loss_dice: 0.2431  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 0.2219  decode.d5.loss_dice: 0.2384  decode.d6.loss_cls: 0.1575  decode.d6.loss_mask: 0.2229  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 0.2260  decode.d7.loss_dice: 0.2374  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.2326
09/28 17:17:19 - mmengine - INFO - Iter(train) [ 23200/320000]  base_lr: 9.3451e-05 lr: 9.3451e-06  eta: 1 day, 12:16:30  time: 0.4358  data_time: 0.0090  memory: 5167  grad_norm: 73.9882  loss: 8.2952  decode.loss_cls: 0.2285  decode.loss_mask: 0.2565  decode.loss_dice: 0.2630  decode.d0.loss_cls: 1.0102  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.2850  decode.d1.loss_cls: 0.3199  decode.d1.loss_mask: 0.2593  decode.d1.loss_dice: 0.2806  decode.d2.loss_cls: 0.2075  decode.d2.loss_mask: 0.2597  decode.d2.loss_dice: 0.2766  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 0.2592  decode.d3.loss_dice: 0.2649  decode.d4.loss_cls: 0.2311  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.2598  decode.d5.loss_cls: 0.2017  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.2631  decode.d6.loss_cls: 0.1714  decode.d6.loss_mask: 0.2541  decode.d6.loss_dice: 0.2774  decode.d7.loss_cls: 0.2253  decode.d7.loss_mask: 0.2573  decode.d7.loss_dice: 0.2674  decode.d8.loss_cls: 0.2302  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.2622
09/28 17:17:41 - mmengine - INFO - Iter(train) [ 23250/320000]  base_lr: 9.3437e-05 lr: 9.3437e-06  eta: 1 day, 12:16:05  time: 0.4347  data_time: 0.0091  memory: 5167  grad_norm: 40.2758  loss: 5.2746  decode.loss_cls: 0.0740  decode.loss_mask: 0.1834  decode.loss_dice: 0.1871  decode.d0.loss_cls: 0.9457  decode.d0.loss_mask: 0.1896  decode.d0.loss_dice: 0.2040  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.1855  decode.d1.loss_dice: 0.1918  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.1878  decode.d2.loss_dice: 0.2013  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.1849  decode.d3.loss_dice: 0.1931  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.1847  decode.d4.loss_dice: 0.1864  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.1858  decode.d5.loss_dice: 0.1856  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.1843  decode.d6.loss_dice: 0.1955  decode.d7.loss_cls: 0.0577  decode.d7.loss_mask: 0.1855  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.1842  decode.d8.loss_dice: 0.1898
09/28 17:18:03 - mmengine - INFO - Iter(train) [ 23300/320000]  base_lr: 9.3423e-05 lr: 9.3423e-06  eta: 1 day, 12:15:40  time: 0.4351  data_time: 0.0092  memory: 5166  grad_norm: 49.5997  loss: 6.5661  decode.loss_cls: 0.1216  decode.loss_mask: 0.2451  decode.loss_dice: 0.2051  decode.d0.loss_cls: 1.0285  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.2280  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.2434  decode.d1.loss_dice: 0.2198  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.2455  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.2442  decode.d3.loss_dice: 0.2055  decode.d4.loss_cls: 0.0852  decode.d4.loss_mask: 0.2485  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.0942  decode.d5.loss_mask: 0.2473  decode.d5.loss_dice: 0.2302  decode.d6.loss_cls: 0.1492  decode.d6.loss_mask: 0.2419  decode.d6.loss_dice: 0.1944  decode.d7.loss_cls: 0.1155  decode.d7.loss_mask: 0.2431  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.1181  decode.d8.loss_mask: 0.2415  decode.d8.loss_dice: 0.2243
09/28 17:18:25 - mmengine - INFO - Iter(train) [ 23350/320000]  base_lr: 9.3408e-05 lr: 9.3408e-06  eta: 1 day, 12:15:14  time: 0.4320  data_time: 0.0093  memory: 5149  grad_norm: 93.2374  loss: 7.1841  decode.loss_cls: 0.1797  decode.loss_mask: 0.2343  decode.loss_dice: 0.2020  decode.d0.loss_cls: 0.9593  decode.d0.loss_mask: 0.2299  decode.d0.loss_dice: 0.2186  decode.d1.loss_cls: 0.2005  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.1897  decode.d2.loss_mask: 0.2205  decode.d2.loss_dice: 0.1891  decode.d3.loss_cls: 0.2275  decode.d3.loss_mask: 0.2211  decode.d3.loss_dice: 0.1851  decode.d4.loss_cls: 0.2059  decode.d4.loss_mask: 0.2250  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.1822  decode.d5.loss_mask: 0.2246  decode.d5.loss_dice: 0.1979  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 0.2893  decode.d6.loss_dice: 0.2373  decode.d7.loss_cls: 0.1740  decode.d7.loss_mask: 0.2708  decode.d7.loss_dice: 0.2301  decode.d8.loss_cls: 0.1515  decode.d8.loss_mask: 0.2708  decode.d8.loss_dice: 0.2595
09/28 17:18:46 - mmengine - INFO - Iter(train) [ 23400/320000]  base_lr: 9.3394e-05 lr: 9.3394e-06  eta: 1 day, 12:14:47  time: 0.4328  data_time: 0.0093  memory: 5166  grad_norm: 54.4439  loss: 6.6141  decode.loss_cls: 0.1104  decode.loss_mask: 0.2410  decode.loss_dice: 0.2286  decode.d0.loss_cls: 0.8435  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.2390  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.2424  decode.d1.loss_dice: 0.2368  decode.d2.loss_cls: 0.1392  decode.d2.loss_mask: 0.2402  decode.d2.loss_dice: 0.2271  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.2364  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.2450  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.2364  decode.d5.loss_dice: 0.2321  decode.d6.loss_cls: 0.1073  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.2366  decode.d7.loss_cls: 0.1081  decode.d7.loss_mask: 0.2384  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.1042  decode.d8.loss_mask: 0.2408  decode.d8.loss_dice: 0.2405
09/28 17:19:08 - mmengine - INFO - Iter(train) [ 23450/320000]  base_lr: 9.3380e-05 lr: 9.3380e-06  eta: 1 day, 12:14:21  time: 0.4320  data_time: 0.0092  memory: 5166  grad_norm: 75.4593  loss: 6.8784  decode.loss_cls: 0.1600  decode.loss_mask: 0.2506  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.8990  decode.d0.loss_mask: 0.2667  decode.d0.loss_dice: 0.2095  decode.d1.loss_cls: 0.2444  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.2094  decode.d2.loss_cls: 0.1833  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.2153  decode.d3.loss_cls: 0.1534  decode.d3.loss_mask: 0.2520  decode.d3.loss_dice: 0.2151  decode.d4.loss_cls: 0.1306  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.2063  decode.d5.loss_cls: 0.0868  decode.d5.loss_mask: 0.2499  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.1631  decode.d6.loss_mask: 0.2534  decode.d6.loss_dice: 0.2059  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.2560  decode.d7.loss_dice: 0.2119  decode.d8.loss_cls: 0.1246  decode.d8.loss_mask: 0.2530  decode.d8.loss_dice: 0.1957
09/28 17:19:29 - mmengine - INFO - Iter(train) [ 23500/320000]  base_lr: 9.3366e-05 lr: 9.3366e-06  eta: 1 day, 12:13:54  time: 0.4324  data_time: 0.0093  memory: 5167  grad_norm: 48.8412  loss: 6.3070  decode.loss_cls: 0.1371  decode.loss_mask: 0.2453  decode.loss_dice: 0.2005  decode.d0.loss_cls: 1.0772  decode.d0.loss_mask: 0.2539  decode.d0.loss_dice: 0.2066  decode.d1.loss_cls: 0.1223  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2030  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.2453  decode.d2.loss_dice: 0.2077  decode.d3.loss_cls: 0.0384  decode.d3.loss_mask: 0.2416  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.0937  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.1969  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.2131  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.2389  decode.d6.loss_dice: 0.2232  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2191
09/28 17:19:51 - mmengine - INFO - Iter(train) [ 23550/320000]  base_lr: 9.3352e-05 lr: 9.3352e-06  eta: 1 day, 12:13:27  time: 0.4321  data_time: 0.0093  memory: 5167  grad_norm: 39.1813  loss: 5.2579  decode.loss_cls: 0.0214  decode.loss_mask: 0.2223  decode.loss_dice: 0.1690  decode.d0.loss_cls: 1.0539  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.1772  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.2218  decode.d1.loss_dice: 0.1750  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.1764  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.1691  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 0.2251  decode.d4.loss_dice: 0.1742  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.2244  decode.d5.loss_dice: 0.1715  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.2245  decode.d6.loss_dice: 0.1654  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.2235  decode.d7.loss_dice: 0.1717  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.2247  decode.d8.loss_dice: 0.1763
09/28 17:20:13 - mmengine - INFO - Iter(train) [ 23600/320000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 1 day, 12:13:01  time: 0.4321  data_time: 0.0094  memory: 5166  grad_norm: 78.1954  loss: 6.1355  decode.loss_cls: 0.0741  decode.loss_mask: 0.2472  decode.loss_dice: 0.1890  decode.d0.loss_cls: 1.1307  decode.d0.loss_mask: 0.2519  decode.d0.loss_dice: 0.1957  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.2475  decode.d1.loss_dice: 0.1819  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.1786  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.2445  decode.d3.loss_dice: 0.1796  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.2479  decode.d4.loss_dice: 0.1837  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.2440  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.2440  decode.d6.loss_dice: 0.1804  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.2474  decode.d7.loss_dice: 0.1802  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.1881
09/28 17:20:34 - mmengine - INFO - Iter(train) [ 23650/320000]  base_lr: 9.3323e-05 lr: 9.3323e-06  eta: 1 day, 12:12:34  time: 0.4322  data_time: 0.0092  memory: 5167  grad_norm: 23.8202  loss: 5.5395  decode.loss_cls: 0.0709  decode.loss_mask: 0.2241  decode.loss_dice: 0.1703  decode.d0.loss_cls: 0.8976  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.1783  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.2202  decode.d1.loss_dice: 0.1696  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.1733  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.2181  decode.d3.loss_dice: 0.1691  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.2209  decode.d4.loss_dice: 0.1689  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.2194  decode.d5.loss_dice: 0.1685  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.1638  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 0.2241  decode.d7.loss_dice: 0.1685  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.2210  decode.d8.loss_dice: 0.1663
09/28 17:20:56 - mmengine - INFO - Iter(train) [ 23700/320000]  base_lr: 9.3309e-05 lr: 9.3309e-06  eta: 1 day, 12:12:08  time: 0.4319  data_time: 0.0092  memory: 5167  grad_norm: 87.3650  loss: 9.9176  decode.loss_cls: 0.4668  decode.loss_mask: 0.2595  decode.loss_dice: 0.2530  decode.d0.loss_cls: 0.9704  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2590  decode.d1.loss_cls: 0.3623  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.2603  decode.d2.loss_cls: 0.3798  decode.d2.loss_mask: 0.2913  decode.d2.loss_dice: 0.2763  decode.d3.loss_cls: 0.3879  decode.d3.loss_mask: 0.3358  decode.d3.loss_dice: 0.2760  decode.d4.loss_cls: 0.3456  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.2599  decode.d5.loss_cls: 0.3843  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.2515  decode.d6.loss_cls: 0.4159  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.4098  decode.d7.loss_mask: 0.2546  decode.d7.loss_dice: 0.2474  decode.d8.loss_cls: 0.4472  decode.d8.loss_mask: 0.2558  decode.d8.loss_dice: 0.2516
09/28 17:21:18 - mmengine - INFO - Iter(train) [ 23750/320000]  base_lr: 9.3295e-05 lr: 9.3295e-06  eta: 1 day, 12:11:41  time: 0.4334  data_time: 0.0094  memory: 5167  grad_norm: 22.5415  loss: 6.5690  decode.loss_cls: 0.0797  decode.loss_mask: 0.2731  decode.loss_dice: 0.2374  decode.d0.loss_cls: 0.7965  decode.d0.loss_mask: 0.2854  decode.d0.loss_dice: 0.2505  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.2767  decode.d1.loss_dice: 0.2369  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.2714  decode.d2.loss_dice: 0.2378  decode.d3.loss_cls: 0.0843  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.2369  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.2339  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.2731  decode.d6.loss_dice: 0.2286  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 0.2719  decode.d7.loss_dice: 0.2338  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.2688  decode.d8.loss_dice: 0.2314
09/28 17:21:39 - mmengine - INFO - Iter(train) [ 23800/320000]  base_lr: 9.3281e-05 lr: 9.3281e-06  eta: 1 day, 12:11:15  time: 0.4325  data_time: 0.0093  memory: 5166  grad_norm: 102.6426  loss: 7.4960  decode.loss_cls: 0.2131  decode.loss_mask: 0.2415  decode.loss_dice: 0.2444  decode.d0.loss_cls: 1.0199  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2672  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.2458  decode.d2.loss_cls: 0.1572  decode.d2.loss_mask: 0.2513  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.2051  decode.d3.loss_mask: 0.2489  decode.d3.loss_dice: 0.2428  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 0.2397  decode.d4.loss_dice: 0.2401  decode.d5.loss_cls: 0.1262  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2433  decode.d6.loss_cls: 0.1019  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.2803  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.2630  decode.d7.loss_dice: 0.2812  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 0.2704  decode.d8.loss_dice: 0.2744
09/28 17:22:01 - mmengine - INFO - Iter(train) [ 23850/320000]  base_lr: 9.3267e-05 lr: 9.3267e-06  eta: 1 day, 12:10:48  time: 0.4320  data_time: 0.0093  memory: 5166  grad_norm: 35.1387  loss: 6.4127  decode.loss_cls: 0.0949  decode.loss_mask: 0.2298  decode.loss_dice: 0.1914  decode.d0.loss_cls: 1.1879  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2175  decode.d1.loss_cls: 0.1190  decode.d1.loss_mask: 0.2317  decode.d1.loss_dice: 0.1950  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.2266  decode.d2.loss_dice: 0.1901  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.1892  decode.d4.loss_cls: 0.1345  decode.d4.loss_mask: 0.2282  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 0.2307  decode.d5.loss_dice: 0.1928  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.2321  decode.d6.loss_dice: 0.1933  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 0.2303  decode.d7.loss_dice: 0.2056  decode.d8.loss_cls: 0.0960  decode.d8.loss_mask: 0.2288  decode.d8.loss_dice: 0.1873
09/28 17:22:23 - mmengine - INFO - Iter(train) [ 23900/320000]  base_lr: 9.3253e-05 lr: 9.3253e-06  eta: 1 day, 12:10:21  time: 0.4323  data_time: 0.0093  memory: 5150  grad_norm: 107.4993  loss: 7.1875  decode.loss_cls: 0.1081  decode.loss_mask: 0.2698  decode.loss_dice: 0.2730  decode.d0.loss_cls: 0.9190  decode.d0.loss_mask: 0.2877  decode.d0.loss_dice: 0.2967  decode.d1.loss_cls: 0.0748  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.2871  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.2735  decode.d2.loss_dice: 0.2810  decode.d3.loss_cls: 0.0896  decode.d3.loss_mask: 0.2722  decode.d3.loss_dice: 0.2767  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.2687  decode.d4.loss_dice: 0.2805  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.2705  decode.d5.loss_dice: 0.2754  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.2750  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.2759  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.2686  decode.d8.loss_dice: 0.2648
09/28 17:22:44 - mmengine - INFO - Iter(train) [ 23950/320000]  base_lr: 9.3238e-05 lr: 9.3238e-06  eta: 1 day, 12:09:55  time: 0.4325  data_time: 0.0091  memory: 5186  grad_norm: 25.3794  loss: 5.5017  decode.loss_cls: 0.0761  decode.loss_mask: 0.1893  decode.loss_dice: 0.2092  decode.d0.loss_cls: 1.0378  decode.d0.loss_mask: 0.1917  decode.d0.loss_dice: 0.2141  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.1887  decode.d1.loss_dice: 0.2058  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.1889  decode.d2.loss_dice: 0.2079  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.1879  decode.d3.loss_dice: 0.2021  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.1894  decode.d4.loss_dice: 0.2068  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.1877  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.1903  decode.d6.loss_dice: 0.2095  decode.d7.loss_cls: 0.0427  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.2022  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.1876  decode.d8.loss_dice: 0.2097
09/28 17:23:06 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:23:06 - mmengine - INFO - Iter(train) [ 24000/320000]  base_lr: 9.3224e-05 lr: 9.3224e-06  eta: 1 day, 12:09:28  time: 0.4316  data_time: 0.0094  memory: 5149  grad_norm: 38.5014  loss: 7.7428  decode.loss_cls: 0.1768  decode.loss_mask: 0.2271  decode.loss_dice: 0.2649  decode.d0.loss_cls: 1.0238  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.2979  decode.d1.loss_cls: 0.2506  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.2301  decode.d2.loss_mask: 0.2286  decode.d2.loss_dice: 0.2668  decode.d3.loss_cls: 0.2104  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.2448  decode.d4.loss_cls: 0.2032  decode.d4.loss_mask: 0.2261  decode.d4.loss_dice: 0.2557  decode.d5.loss_cls: 0.1968  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.2570  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.2679  decode.d7.loss_cls: 0.2104  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.2558  decode.d8.loss_cls: 0.1752  decode.d8.loss_mask: 0.2272  decode.d8.loss_dice: 0.2606
09/28 17:23:27 - mmengine - INFO - Iter(train) [ 24050/320000]  base_lr: 9.3210e-05 lr: 9.3210e-06  eta: 1 day, 12:09:01  time: 0.4314  data_time: 0.0092  memory: 5166  grad_norm: 71.8662  loss: 7.7477  decode.loss_cls: 0.2111  decode.loss_mask: 0.2305  decode.loss_dice: 0.2618  decode.d0.loss_cls: 0.8558  decode.d0.loss_mask: 0.2370  decode.d0.loss_dice: 0.2806  decode.d1.loss_cls: 0.2377  decode.d1.loss_mask: 0.2302  decode.d1.loss_dice: 0.2510  decode.d2.loss_cls: 0.2737  decode.d2.loss_mask: 0.2282  decode.d2.loss_dice: 0.2492  decode.d3.loss_cls: 0.2654  decode.d3.loss_mask: 0.2273  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.2241  decode.d4.loss_mask: 0.2307  decode.d4.loss_dice: 0.2355  decode.d5.loss_cls: 0.2355  decode.d5.loss_mask: 0.2323  decode.d5.loss_dice: 0.2689  decode.d6.loss_cls: 0.2036  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.2451  decode.d7.loss_cls: 0.2077  decode.d7.loss_mask: 0.2314  decode.d7.loss_dice: 0.2418  decode.d8.loss_cls: 0.1985  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2376
09/28 17:23:49 - mmengine - INFO - Iter(train) [ 24100/320000]  base_lr: 9.3196e-05 lr: 9.3196e-06  eta: 1 day, 12:08:35  time: 0.4322  data_time: 0.0093  memory: 5150  grad_norm: 111.3083  loss: 7.9252  decode.loss_cls: 0.1432  decode.loss_mask: 0.2470  decode.loss_dice: 0.2635  decode.d0.loss_cls: 1.1973  decode.d0.loss_mask: 0.2579  decode.d0.loss_dice: 0.2385  decode.d1.loss_cls: 0.2631  decode.d1.loss_mask: 0.2510  decode.d1.loss_dice: 0.2521  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.2493  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.1336  decode.d3.loss_mask: 0.2655  decode.d3.loss_dice: 0.2558  decode.d4.loss_cls: 0.1205  decode.d4.loss_mask: 0.2743  decode.d4.loss_dice: 0.2628  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.2842  decode.d5.loss_dice: 0.2689  decode.d6.loss_cls: 0.1534  decode.d6.loss_mask: 0.2454  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.1917  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.3071  decode.d8.loss_cls: 0.1741  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.2734
09/28 17:24:11 - mmengine - INFO - Iter(train) [ 24150/320000]  base_lr: 9.3182e-05 lr: 9.3182e-06  eta: 1 day, 12:08:08  time: 0.4325  data_time: 0.0092  memory: 5186  grad_norm: 270.0383  loss: 7.7931  decode.loss_cls: 0.1069  decode.loss_mask: 0.3138  decode.loss_dice: 0.2354  decode.d0.loss_cls: 0.9653  decode.d0.loss_mask: 0.3225  decode.d0.loss_dice: 0.2451  decode.d1.loss_cls: 0.1935  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.2414  decode.d2.loss_cls: 0.2096  decode.d2.loss_mask: 0.3140  decode.d2.loss_dice: 0.2387  decode.d3.loss_cls: 0.1560  decode.d3.loss_mask: 0.3088  decode.d3.loss_dice: 0.2239  decode.d4.loss_cls: 0.1246  decode.d4.loss_mask: 0.3121  decode.d4.loss_dice: 0.2256  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.3149  decode.d5.loss_dice: 0.2367  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.3075  decode.d6.loss_dice: 0.2269  decode.d7.loss_cls: 0.1528  decode.d7.loss_mask: 0.3135  decode.d7.loss_dice: 0.2301  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 0.3122  decode.d8.loss_dice: 0.2332
09/28 17:24:32 - mmengine - INFO - Iter(train) [ 24200/320000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 1 day, 12:07:41  time: 0.4330  data_time: 0.0091  memory: 5167  grad_norm: 38.1803  loss: 6.5620  decode.loss_cls: 0.1466  decode.loss_mask: 0.1923  decode.loss_dice: 0.2189  decode.d0.loss_cls: 1.0699  decode.d0.loss_mask: 0.1966  decode.d0.loss_dice: 0.2367  decode.d1.loss_cls: 0.1544  decode.d1.loss_mask: 0.1951  decode.d1.loss_dice: 0.2288  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.1947  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.1323  decode.d3.loss_mask: 0.1971  decode.d3.loss_dice: 0.2252  decode.d4.loss_cls: 0.1225  decode.d4.loss_mask: 0.1957  decode.d4.loss_dice: 0.2215  decode.d5.loss_cls: 0.1342  decode.d5.loss_mask: 0.1954  decode.d5.loss_dice: 0.2235  decode.d6.loss_cls: 0.1345  decode.d6.loss_mask: 0.1962  decode.d6.loss_dice: 0.2256  decode.d7.loss_cls: 0.1529  decode.d7.loss_mask: 0.1932  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.1524  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.2273
09/28 17:24:54 - mmengine - INFO - Iter(train) [ 24250/320000]  base_lr: 9.3153e-05 lr: 9.3153e-06  eta: 1 day, 12:07:15  time: 0.4325  data_time: 0.0093  memory: 5186  grad_norm: 30.0485  loss: 5.8417  decode.loss_cls: 0.1085  decode.loss_mask: 0.2158  decode.loss_dice: 0.1785  decode.d0.loss_cls: 0.8435  decode.d0.loss_mask: 0.2176  decode.d0.loss_dice: 0.1871  decode.d1.loss_cls: 0.1091  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.1775  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 0.2153  decode.d2.loss_dice: 0.1790  decode.d3.loss_cls: 0.0963  decode.d3.loss_mask: 0.2142  decode.d3.loss_dice: 0.1795  decode.d4.loss_cls: 0.0933  decode.d4.loss_mask: 0.2182  decode.d4.loss_dice: 0.1807  decode.d5.loss_cls: 0.1342  decode.d5.loss_mask: 0.2158  decode.d5.loss_dice: 0.1778  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.2170  decode.d6.loss_dice: 0.1712  decode.d7.loss_cls: 0.1556  decode.d7.loss_mask: 0.2199  decode.d7.loss_dice: 0.1780  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 0.2137  decode.d8.loss_dice: 0.1736
09/28 17:25:15 - mmengine - INFO - Iter(train) [ 24300/320000]  base_lr: 9.3139e-05 lr: 9.3139e-06  eta: 1 day, 12:06:48  time: 0.4324  data_time: 0.0091  memory: 5186  grad_norm: 67.3767  loss: 6.6569  decode.loss_cls: 0.1162  decode.loss_mask: 0.2753  decode.loss_dice: 0.1892  decode.d0.loss_cls: 0.9053  decode.d0.loss_mask: 0.2742  decode.d0.loss_dice: 0.2172  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 0.2724  decode.d1.loss_dice: 0.1852  decode.d2.loss_cls: 0.1472  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.1896  decode.d3.loss_cls: 0.0998  decode.d3.loss_mask: 0.2726  decode.d3.loss_dice: 0.1862  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.2735  decode.d4.loss_dice: 0.1791  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.2745  decode.d5.loss_dice: 0.1851  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.2805  decode.d6.loss_dice: 0.1842  decode.d7.loss_cls: 0.1244  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.1789  decode.d8.loss_cls: 0.1269  decode.d8.loss_mask: 0.2739  decode.d8.loss_dice: 0.1854
09/28 17:25:37 - mmengine - INFO - Iter(train) [ 24350/320000]  base_lr: 9.3125e-05 lr: 9.3125e-06  eta: 1 day, 12:06:24  time: 0.4512  data_time: 0.0092  memory: 5186  grad_norm: 62.0094  loss: 8.2723  decode.loss_cls: 0.2281  decode.loss_mask: 0.2907  decode.loss_dice: 0.2279  decode.d0.loss_cls: 1.0040  decode.d0.loss_mask: 0.2926  decode.d0.loss_dice: 0.2576  decode.d1.loss_cls: 0.2287  decode.d1.loss_mask: 0.2953  decode.d1.loss_dice: 0.2182  decode.d2.loss_cls: 0.2331  decode.d2.loss_mask: 0.3114  decode.d2.loss_dice: 0.2163  decode.d3.loss_cls: 0.2449  decode.d3.loss_mask: 0.3015  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.2168  decode.d4.loss_mask: 0.3137  decode.d4.loss_dice: 0.2191  decode.d5.loss_cls: 0.2359  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.2172  decode.d6.loss_cls: 0.2057  decode.d6.loss_mask: 0.2896  decode.d6.loss_dice: 0.2055  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 0.2962  decode.d7.loss_dice: 0.2201  decode.d8.loss_cls: 0.2311  decode.d8.loss_mask: 0.3078  decode.d8.loss_dice: 0.2135
09/28 17:25:59 - mmengine - INFO - Iter(train) [ 24400/320000]  base_lr: 9.3111e-05 lr: 9.3111e-06  eta: 1 day, 12:05:58  time: 0.4318  data_time: 0.0091  memory: 5148  grad_norm: 125.0617  loss: 9.1613  decode.loss_cls: 0.2518  decode.loss_mask: 0.3403  decode.loss_dice: 0.2770  decode.d0.loss_cls: 0.8805  decode.d0.loss_mask: 0.3533  decode.d0.loss_dice: 0.2813  decode.d1.loss_cls: 0.2202  decode.d1.loss_mask: 0.3424  decode.d1.loss_dice: 0.2839  decode.d2.loss_cls: 0.1635  decode.d2.loss_mask: 0.3379  decode.d2.loss_dice: 0.2839  decode.d3.loss_cls: 0.1713  decode.d3.loss_mask: 0.3408  decode.d3.loss_dice: 0.2928  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.3407  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.2960  decode.d5.loss_mask: 0.3260  decode.d5.loss_dice: 0.2851  decode.d6.loss_cls: 0.2682  decode.d6.loss_mask: 0.3298  decode.d6.loss_dice: 0.2837  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 0.3313  decode.d7.loss_dice: 0.2767  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 0.3364  decode.d8.loss_dice: 0.2640
09/28 17:26:20 - mmengine - INFO - Iter(train) [ 24450/320000]  base_lr: 9.3097e-05 lr: 9.3097e-06  eta: 1 day, 12:05:31  time: 0.4318  data_time: 0.0093  memory: 5186  grad_norm: 124.1964  loss: 9.5249  decode.loss_cls: 0.3068  decode.loss_mask: 0.3214  decode.loss_dice: 0.2843  decode.d0.loss_cls: 0.9020  decode.d0.loss_mask: 0.3323  decode.d0.loss_dice: 0.3642  decode.d1.loss_cls: 0.2796  decode.d1.loss_mask: 0.3208  decode.d1.loss_dice: 0.3026  decode.d2.loss_cls: 0.2310  decode.d2.loss_mask: 0.3291  decode.d2.loss_dice: 0.3183  decode.d3.loss_cls: 0.2100  decode.d3.loss_mask: 0.3094  decode.d3.loss_dice: 0.2870  decode.d4.loss_cls: 0.2115  decode.d4.loss_mask: 0.3215  decode.d4.loss_dice: 0.3329  decode.d5.loss_cls: 0.2081  decode.d5.loss_mask: 0.3200  decode.d5.loss_dice: 0.3014  decode.d6.loss_cls: 0.2515  decode.d6.loss_mask: 0.3311  decode.d6.loss_dice: 0.3290  decode.d7.loss_cls: 0.2958  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.2965  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 0.3190  decode.d8.loss_dice: 0.3160
09/28 17:26:42 - mmengine - INFO - Iter(train) [ 24500/320000]  base_lr: 9.3082e-05 lr: 9.3082e-06  eta: 1 day, 12:05:05  time: 0.4321  data_time: 0.0091  memory: 5186  grad_norm: 160.3125  loss: 7.2038  decode.loss_cls: 0.0895  decode.loss_mask: 0.2980  decode.loss_dice: 0.2290  decode.d0.loss_cls: 0.9074  decode.d0.loss_mask: 0.3104  decode.d0.loss_dice: 0.2348  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 0.3136  decode.d1.loss_dice: 0.2544  decode.d2.loss_cls: 0.1108  decode.d2.loss_mask: 0.3113  decode.d2.loss_dice: 0.2581  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.3062  decode.d3.loss_dice: 0.2380  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.3051  decode.d4.loss_dice: 0.2392  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.3053  decode.d5.loss_dice: 0.2228  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.2997  decode.d6.loss_dice: 0.2234  decode.d7.loss_cls: 0.0994  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.2255  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.3006  decode.d8.loss_dice: 0.2268
09/28 17:27:04 - mmengine - INFO - Iter(train) [ 24550/320000]  base_lr: 9.3068e-05 lr: 9.3068e-06  eta: 1 day, 12:04:38  time: 0.4327  data_time: 0.0091  memory: 5186  grad_norm: 74.8837  loss: 8.8247  decode.loss_cls: 0.2049  decode.loss_mask: 0.2819  decode.loss_dice: 0.3245  decode.d0.loss_cls: 1.0184  decode.d0.loss_mask: 0.2865  decode.d0.loss_dice: 0.3378  decode.d1.loss_cls: 0.1870  decode.d1.loss_mask: 0.2812  decode.d1.loss_dice: 0.3309  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 0.2799  decode.d2.loss_dice: 0.3193  decode.d3.loss_cls: 0.2444  decode.d3.loss_mask: 0.2854  decode.d3.loss_dice: 0.3173  decode.d4.loss_cls: 0.1414  decode.d4.loss_mask: 0.2804  decode.d4.loss_dice: 0.3342  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.3171  decode.d6.loss_cls: 0.2356  decode.d6.loss_mask: 0.2850  decode.d6.loss_dice: 0.3072  decode.d7.loss_cls: 0.2230  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.3055  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.3325
09/28 17:27:25 - mmengine - INFO - Iter(train) [ 24600/320000]  base_lr: 9.3054e-05 lr: 9.3054e-06  eta: 1 day, 12:04:12  time: 0.4315  data_time: 0.0090  memory: 5150  grad_norm: 85.1444  loss: 5.1957  decode.loss_cls: 0.0621  decode.loss_mask: 0.2321  decode.loss_dice: 0.1667  decode.d0.loss_cls: 0.7508  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.1717  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.1690  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.2311  decode.d2.loss_dice: 0.1674  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.2344  decode.d3.loss_dice: 0.1676  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.2366  decode.d4.loss_dice: 0.1688  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.2360  decode.d5.loss_dice: 0.1662  decode.d6.loss_cls: 0.0530  decode.d6.loss_mask: 0.2322  decode.d6.loss_dice: 0.1648  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.2306  decode.d7.loss_dice: 0.1679  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.2326  decode.d8.loss_dice: 0.1709
09/28 17:27:47 - mmengine - INFO - Iter(train) [ 24650/320000]  base_lr: 9.3040e-05 lr: 9.3040e-06  eta: 1 day, 12:03:46  time: 0.4325  data_time: 0.0091  memory: 5150  grad_norm: 68.1505  loss: 6.7295  decode.loss_cls: 0.1301  decode.loss_mask: 0.2345  decode.loss_dice: 0.2178  decode.d0.loss_cls: 0.9717  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.2547  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.2364  decode.d1.loss_dice: 0.2060  decode.d2.loss_cls: 0.0965  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.2223  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 0.2624  decode.d3.loss_dice: 0.2305  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.2634  decode.d4.loss_dice: 0.2297  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.2307  decode.d6.loss_cls: 0.1010  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.2151  decode.d7.loss_cls: 0.1445  decode.d7.loss_mask: 0.2548  decode.d7.loss_dice: 0.2126  decode.d8.loss_cls: 0.1166  decode.d8.loss_mask: 0.2309  decode.d8.loss_dice: 0.2001
09/28 17:28:09 - mmengine - INFO - Iter(train) [ 24700/320000]  base_lr: 9.3026e-05 lr: 9.3026e-06  eta: 1 day, 12:03:19  time: 0.4321  data_time: 0.0093  memory: 5149  grad_norm: 104.3920  loss: 7.4677  decode.loss_cls: 0.1187  decode.loss_mask: 0.3115  decode.loss_dice: 0.2406  decode.d0.loss_cls: 0.8574  decode.d0.loss_mask: 0.3176  decode.d0.loss_dice: 0.2642  decode.d1.loss_cls: 0.1719  decode.d1.loss_mask: 0.3083  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.3113  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.3092  decode.d3.loss_dice: 0.2405  decode.d4.loss_cls: 0.1558  decode.d4.loss_mask: 0.3105  decode.d4.loss_dice: 0.2377  decode.d5.loss_cls: 0.0884  decode.d5.loss_mask: 0.3176  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.3079  decode.d6.loss_dice: 0.2392  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.3065  decode.d7.loss_dice: 0.2511  decode.d8.loss_cls: 0.1135  decode.d8.loss_mask: 0.3124  decode.d8.loss_dice: 0.2400
09/28 17:28:30 - mmengine - INFO - Iter(train) [ 24750/320000]  base_lr: 9.3012e-05 lr: 9.3012e-06  eta: 1 day, 12:02:53  time: 0.4318  data_time: 0.0089  memory: 5166  grad_norm: 78.3679  loss: 6.0154  decode.loss_cls: 0.0425  decode.loss_mask: 0.2360  decode.loss_dice: 0.2348  decode.d0.loss_cls: 0.9413  decode.d0.loss_mask: 0.2337  decode.d0.loss_dice: 0.2178  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.2453  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.2304  decode.d3.loss_dice: 0.2161  decode.d4.loss_cls: 0.0296  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.2331  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.2432  decode.d5.loss_dice: 0.2414  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.2480  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.2354  decode.d8.loss_dice: 0.2351
09/28 17:28:52 - mmengine - INFO - Iter(train) [ 24800/320000]  base_lr: 9.2997e-05 lr: 9.2997e-06  eta: 1 day, 12:02:26  time: 0.4324  data_time: 0.0089  memory: 5186  grad_norm: 76.7734  loss: 9.9055  decode.loss_cls: 0.2922  decode.loss_mask: 0.3137  decode.loss_dice: 0.3759  decode.d0.loss_cls: 0.8955  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.3806  decode.d1.loss_cls: 0.3377  decode.d1.loss_mask: 0.3101  decode.d1.loss_dice: 0.3406  decode.d2.loss_cls: 0.2811  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.3292  decode.d3.loss_cls: 0.2523  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.3515  decode.d4.loss_cls: 0.2637  decode.d4.loss_mask: 0.3034  decode.d4.loss_dice: 0.3412  decode.d5.loss_cls: 0.2858  decode.d5.loss_mask: 0.3013  decode.d5.loss_dice: 0.3501  decode.d6.loss_cls: 0.2439  decode.d6.loss_mask: 0.3055  decode.d6.loss_dice: 0.3472  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 0.3046  decode.d7.loss_dice: 0.3462  decode.d8.loss_cls: 0.2546  decode.d8.loss_mask: 0.3045  decode.d8.loss_dice: 0.3386
09/28 17:29:13 - mmengine - INFO - Iter(train) [ 24850/320000]  base_lr: 9.2983e-05 lr: 9.2983e-06  eta: 1 day, 12:02:00  time: 0.4312  data_time: 0.0088  memory: 5166  grad_norm: 39.0926  loss: 5.5406  decode.loss_cls: 0.0625  decode.loss_mask: 0.2305  decode.loss_dice: 0.1744  decode.d0.loss_cls: 0.9674  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.1807  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 0.2290  decode.d1.loss_dice: 0.1751  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.1736  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.2285  decode.d3.loss_dice: 0.1745  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.2267  decode.d4.loss_dice: 0.1723  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.1712  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.2292  decode.d6.loss_dice: 0.1718  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.2306  decode.d7.loss_dice: 0.1745  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.2309  decode.d8.loss_dice: 0.1717
09/28 17:29:35 - mmengine - INFO - Iter(train) [ 24900/320000]  base_lr: 9.2969e-05 lr: 9.2969e-06  eta: 1 day, 12:01:33  time: 0.4329  data_time: 0.0093  memory: 5186  grad_norm: 58.5691  loss: 7.6589  decode.loss_cls: 0.2516  decode.loss_mask: 0.2357  decode.loss_dice: 0.2045  decode.d0.loss_cls: 0.8629  decode.d0.loss_mask: 0.2368  decode.d0.loss_dice: 0.2058  decode.d1.loss_cls: 0.2993  decode.d1.loss_mask: 0.2252  decode.d1.loss_dice: 0.2004  decode.d2.loss_cls: 0.3448  decode.d2.loss_mask: 0.2292  decode.d2.loss_dice: 0.1995  decode.d3.loss_cls: 0.3184  decode.d3.loss_mask: 0.2313  decode.d3.loss_dice: 0.1873  decode.d4.loss_cls: 0.3236  decode.d4.loss_mask: 0.2329  decode.d4.loss_dice: 0.1975  decode.d5.loss_cls: 0.2423  decode.d5.loss_mask: 0.2374  decode.d5.loss_dice: 0.2072  decode.d6.loss_cls: 0.2475  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.1744  decode.d7.loss_cls: 0.2562  decode.d7.loss_mask: 0.2332  decode.d7.loss_dice: 0.2047  decode.d8.loss_cls: 0.2219  decode.d8.loss_mask: 0.2336  decode.d8.loss_dice: 0.1763
09/28 17:29:57 - mmengine - INFO - Iter(train) [ 24950/320000]  base_lr: 9.2955e-05 lr: 9.2955e-06  eta: 1 day, 12:01:08  time: 0.4333  data_time: 0.0093  memory: 5186  grad_norm: 46.0942  loss: 6.5243  decode.loss_cls: 0.2193  decode.loss_mask: 0.1823  decode.loss_dice: 0.1812  decode.d0.loss_cls: 1.1386  decode.d0.loss_mask: 0.1911  decode.d0.loss_dice: 0.1841  decode.d1.loss_cls: 0.1326  decode.d1.loss_mask: 0.1840  decode.d1.loss_dice: 0.1860  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.1861  decode.d3.loss_cls: 0.1842  decode.d3.loss_mask: 0.1825  decode.d3.loss_dice: 0.1831  decode.d4.loss_cls: 0.1383  decode.d4.loss_mask: 0.1855  decode.d4.loss_dice: 0.1861  decode.d5.loss_cls: 0.1746  decode.d5.loss_mask: 0.1849  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.2185  decode.d6.loss_mask: 0.1817  decode.d6.loss_dice: 0.1791  decode.d7.loss_cls: 0.2440  decode.d7.loss_mask: 0.1798  decode.d7.loss_dice: 0.2002  decode.d8.loss_cls: 0.2113  decode.d8.loss_mask: 0.1822  decode.d8.loss_dice: 0.1782
09/28 17:30:18 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:30:18 - mmengine - INFO - Iter(train) [ 25000/320000]  base_lr: 9.2941e-05 lr: 9.2941e-06  eta: 1 day, 12:00:42  time: 0.4336  data_time: 0.0093  memory: 5150  grad_norm: 98.0048  loss: 6.9342  decode.loss_cls: 0.1708  decode.loss_mask: 0.2467  decode.loss_dice: 0.1964  decode.d0.loss_cls: 0.9578  decode.d0.loss_mask: 0.2534  decode.d0.loss_dice: 0.2121  decode.d1.loss_cls: 0.2151  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.2022  decode.d2.loss_cls: 0.1672  decode.d2.loss_mask: 0.2462  decode.d2.loss_dice: 0.1938  decode.d3.loss_cls: 0.1492  decode.d3.loss_mask: 0.2466  decode.d3.loss_dice: 0.2013  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 0.2449  decode.d4.loss_dice: 0.2029  decode.d5.loss_cls: 0.1844  decode.d5.loss_mask: 0.2422  decode.d5.loss_dice: 0.1963  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.2457  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.1568  decode.d7.loss_mask: 0.2443  decode.d7.loss_dice: 0.2023  decode.d8.loss_cls: 0.1488  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.2066
09/28 17:30:40 - mmengine - INFO - Iter(train) [ 25050/320000]  base_lr: 9.2927e-05 lr: 9.2927e-06  eta: 1 day, 12:00:16  time: 0.4326  data_time: 0.0091  memory: 5167  grad_norm: 102.1191  loss: 5.8709  decode.loss_cls: 0.0375  decode.loss_mask: 0.2291  decode.loss_dice: 0.1938  decode.d0.loss_cls: 0.9006  decode.d0.loss_mask: 0.2399  decode.d0.loss_dice: 0.2161  decode.d1.loss_cls: 0.0550  decode.d1.loss_mask: 0.2369  decode.d1.loss_dice: 0.2051  decode.d2.loss_cls: 0.1210  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.1912  decode.d3.loss_cls: 0.0493  decode.d3.loss_mask: 0.2356  decode.d3.loss_dice: 0.1903  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.2075  decode.d5.loss_cls: 0.0326  decode.d5.loss_mask: 0.2310  decode.d5.loss_dice: 0.2018  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.1929  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2050  decode.d8.loss_cls: 0.1028  decode.d8.loss_mask: 0.2313  decode.d8.loss_dice: 0.2154
09/28 17:31:02 - mmengine - INFO - Iter(train) [ 25100/320000]  base_lr: 9.2912e-05 lr: 9.2912e-06  eta: 1 day, 11:59:50  time: 0.4324  data_time: 0.0093  memory: 5149  grad_norm: 74.1904  loss: 6.4121  decode.loss_cls: 0.1973  decode.loss_mask: 0.2252  decode.loss_dice: 0.2060  decode.d0.loss_cls: 0.8827  decode.d0.loss_mask: 0.2387  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.1394  decode.d1.loss_mask: 0.2356  decode.d1.loss_dice: 0.2131  decode.d2.loss_cls: 0.1601  decode.d2.loss_mask: 0.2224  decode.d2.loss_dice: 0.2065  decode.d3.loss_cls: 0.1399  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.2090  decode.d4.loss_cls: 0.1205  decode.d4.loss_mask: 0.2254  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.2236  decode.d5.loss_dice: 0.2275  decode.d6.loss_cls: 0.0763  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.2072  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.2327  decode.d7.loss_dice: 0.2041  decode.d8.loss_cls: 0.1658  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1937
09/28 17:31:23 - mmengine - INFO - Iter(train) [ 25150/320000]  base_lr: 9.2898e-05 lr: 9.2898e-06  eta: 1 day, 11:59:24  time: 0.4331  data_time: 0.0093  memory: 5186  grad_norm: 50.1269  loss: 5.0836  decode.loss_cls: 0.0548  decode.loss_mask: 0.2147  decode.loss_dice: 0.1514  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 0.2229  decode.d0.loss_dice: 0.1601  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.1514  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.2147  decode.d2.loss_dice: 0.1517  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.2176  decode.d3.loss_dice: 0.1516  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1532  decode.d5.loss_cls: 0.0440  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.1503  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.2183  decode.d6.loss_dice: 0.1525  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.2216  decode.d7.loss_dice: 0.1510  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.1515
09/28 17:31:45 - mmengine - INFO - Iter(train) [ 25200/320000]  base_lr: 9.2884e-05 lr: 9.2884e-06  eta: 1 day, 11:58:58  time: 0.4335  data_time: 0.0094  memory: 5166  grad_norm: 110.2965  loss: 8.1813  decode.loss_cls: 0.1038  decode.loss_mask: 0.3570  decode.loss_dice: 0.2651  decode.d0.loss_cls: 0.8088  decode.d0.loss_mask: 0.3840  decode.d0.loss_dice: 0.2874  decode.d1.loss_cls: 0.1043  decode.d1.loss_mask: 0.3666  decode.d1.loss_dice: 0.2680  decode.d2.loss_cls: 0.1137  decode.d2.loss_mask: 0.3627  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.1307  decode.d3.loss_mask: 0.3641  decode.d3.loss_dice: 0.2608  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 0.3652  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.3619  decode.d5.loss_dice: 0.2625  decode.d6.loss_cls: 0.1312  decode.d6.loss_mask: 0.3579  decode.d6.loss_dice: 0.2665  decode.d7.loss_cls: 0.1390  decode.d7.loss_mask: 0.3603  decode.d7.loss_dice: 0.2631  decode.d8.loss_cls: 0.1116  decode.d8.loss_mask: 0.3605  decode.d8.loss_dice: 0.2688
09/28 17:32:07 - mmengine - INFO - Iter(train) [ 25250/320000]  base_lr: 9.2870e-05 lr: 9.2870e-06  eta: 1 day, 11:58:33  time: 0.4322  data_time: 0.0093  memory: 5186  grad_norm: 129.2372  loss: 8.6867  decode.loss_cls: 0.2417  decode.loss_mask: 0.2442  decode.loss_dice: 0.2894  decode.d0.loss_cls: 0.9437  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.2973  decode.d1.loss_cls: 0.2886  decode.d1.loss_mask: 0.2499  decode.d1.loss_dice: 0.2938  decode.d2.loss_cls: 0.2040  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.2867  decode.d3.loss_cls: 0.2958  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.2819  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.3155  decode.d5.loss_cls: 0.2550  decode.d5.loss_mask: 0.2492  decode.d5.loss_dice: 0.2829  decode.d6.loss_cls: 0.2760  decode.d6.loss_mask: 0.2482  decode.d6.loss_dice: 0.2837  decode.d7.loss_cls: 0.2403  decode.d7.loss_mask: 0.2483  decode.d7.loss_dice: 0.2931  decode.d8.loss_cls: 0.3266  decode.d8.loss_mask: 0.2487  decode.d8.loss_dice: 0.2835
09/28 17:32:28 - mmengine - INFO - Iter(train) [ 25300/320000]  base_lr: 9.2856e-05 lr: 9.2856e-06  eta: 1 day, 11:58:07  time: 0.4326  data_time: 0.0093  memory: 5186  grad_norm: 158.6334  loss: 11.9422  decode.loss_cls: 0.4398  decode.loss_mask: 0.4571  decode.loss_dice: 0.2861  decode.d0.loss_cls: 1.2186  decode.d0.loss_mask: 0.3225  decode.d0.loss_dice: 0.3368  decode.d1.loss_cls: 0.4690  decode.d1.loss_mask: 0.2928  decode.d1.loss_dice: 0.3142  decode.d2.loss_cls: 0.3584  decode.d2.loss_mask: 0.4502  decode.d2.loss_dice: 0.3237  decode.d3.loss_cls: 0.3267  decode.d3.loss_mask: 0.4769  decode.d3.loss_dice: 0.3176  decode.d4.loss_cls: 0.3652  decode.d4.loss_mask: 0.3462  decode.d4.loss_dice: 0.3216  decode.d5.loss_cls: 0.3734  decode.d5.loss_mask: 0.3974  decode.d5.loss_dice: 0.3069  decode.d6.loss_cls: 0.4149  decode.d6.loss_mask: 0.4152  decode.d6.loss_dice: 0.3113  decode.d7.loss_cls: 0.4122  decode.d7.loss_mask: 0.4161  decode.d7.loss_dice: 0.3252  decode.d8.loss_cls: 0.3777  decode.d8.loss_mask: 0.4636  decode.d8.loss_dice: 0.3047
09/28 17:32:50 - mmengine - INFO - Iter(train) [ 25350/320000]  base_lr: 9.2841e-05 lr: 9.2841e-06  eta: 1 day, 11:57:42  time: 0.4327  data_time: 0.0093  memory: 5186  grad_norm: 141.1892  loss: 10.5516  decode.loss_cls: 0.1447  decode.loss_mask: 0.5704  decode.loss_dice: 0.3380  decode.d0.loss_cls: 0.9297  decode.d0.loss_mask: 0.2883  decode.d0.loss_dice: 0.3029  decode.d1.loss_cls: 0.3359  decode.d1.loss_mask: 0.3004  decode.d1.loss_dice: 0.2870  decode.d2.loss_cls: 0.2055  decode.d2.loss_mask: 0.5095  decode.d2.loss_dice: 0.3393  decode.d3.loss_cls: 0.1929  decode.d3.loss_mask: 0.4591  decode.d3.loss_dice: 0.3204  decode.d4.loss_cls: 0.1863  decode.d4.loss_mask: 0.4955  decode.d4.loss_dice: 0.3077  decode.d5.loss_cls: 0.1223  decode.d5.loss_mask: 0.5060  decode.d5.loss_dice: 0.3239  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.6039  decode.d6.loss_dice: 0.3481  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.5943  decode.d7.loss_dice: 0.3445  decode.d8.loss_cls: 0.0966  decode.d8.loss_mask: 0.5706  decode.d8.loss_dice: 0.3342
09/28 17:33:11 - mmengine - INFO - Iter(train) [ 25400/320000]  base_lr: 9.2827e-05 lr: 9.2827e-06  eta: 1 day, 11:57:16  time: 0.4325  data_time: 0.0093  memory: 5167  grad_norm: 47.6577  loss: 10.4019  decode.loss_cls: 0.3886  decode.loss_mask: 0.3434  decode.loss_dice: 0.2764  decode.d0.loss_cls: 1.0677  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.3144  decode.d1.loss_cls: 0.3941  decode.d1.loss_mask: 0.2868  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.3465  decode.d2.loss_mask: 0.3315  decode.d2.loss_dice: 0.2745  decode.d3.loss_cls: 0.3903  decode.d3.loss_mask: 0.2699  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.3713  decode.d4.loss_mask: 0.3247  decode.d4.loss_dice: 0.3122  decode.d5.loss_cls: 0.2713  decode.d5.loss_mask: 0.4366  decode.d5.loss_dice: 0.2879  decode.d6.loss_cls: 0.2807  decode.d6.loss_mask: 0.3931  decode.d6.loss_dice: 0.2612  decode.d7.loss_cls: 0.2498  decode.d7.loss_mask: 0.4100  decode.d7.loss_dice: 0.2713  decode.d8.loss_cls: 0.3814  decode.d8.loss_mask: 0.3014  decode.d8.loss_dice: 0.2834
09/28 17:33:33 - mmengine - INFO - Iter(train) [ 25450/320000]  base_lr: 9.2813e-05 lr: 9.2813e-06  eta: 1 day, 11:56:50  time: 0.4334  data_time: 0.0093  memory: 5167  grad_norm: 86.5319  loss: 7.0933  decode.loss_cls: 0.0816  decode.loss_mask: 0.2665  decode.loss_dice: 0.2243  decode.d0.loss_cls: 0.9569  decode.d0.loss_mask: 0.2514  decode.d0.loss_dice: 0.2363  decode.d1.loss_cls: 0.1685  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.2315  decode.d2.loss_cls: 0.2631  decode.d2.loss_mask: 0.2548  decode.d2.loss_dice: 0.2250  decode.d3.loss_cls: 0.2157  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.2203  decode.d4.loss_cls: 0.1480  decode.d4.loss_mask: 0.2644  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.2019  decode.d5.loss_mask: 0.2448  decode.d5.loss_dice: 0.2076  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.2091  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.2498  decode.d7.loss_dice: 0.2127  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.2655  decode.d8.loss_dice: 0.2194
09/28 17:33:55 - mmengine - INFO - Iter(train) [ 25500/320000]  base_lr: 9.2799e-05 lr: 9.2799e-06  eta: 1 day, 11:56:24  time: 0.4332  data_time: 0.0093  memory: 5186  grad_norm: 98.3753  loss: 6.4217  decode.loss_cls: 0.0921  decode.loss_mask: 0.2167  decode.loss_dice: 0.1977  decode.d0.loss_cls: 0.9493  decode.d0.loss_mask: 0.2164  decode.d0.loss_dice: 0.2226  decode.d1.loss_cls: 0.2073  decode.d1.loss_mask: 0.2176  decode.d1.loss_dice: 0.2048  decode.d2.loss_cls: 0.2064  decode.d2.loss_mask: 0.2160  decode.d2.loss_dice: 0.1997  decode.d3.loss_cls: 0.1938  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.2011  decode.d4.loss_cls: 0.1690  decode.d4.loss_mask: 0.2162  decode.d4.loss_dice: 0.1894  decode.d5.loss_cls: 0.1100  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.1951  decode.d6.loss_cls: 0.1122  decode.d6.loss_mask: 0.2182  decode.d6.loss_dice: 0.1957  decode.d7.loss_cls: 0.1073  decode.d7.loss_mask: 0.2178  decode.d7.loss_dice: 0.1970  decode.d8.loss_cls: 0.1129  decode.d8.loss_mask: 0.2160  decode.d8.loss_dice: 0.1923
09/28 17:34:16 - mmengine - INFO - Iter(train) [ 25550/320000]  base_lr: 9.2785e-05 lr: 9.2785e-06  eta: 1 day, 11:55:58  time: 0.4323  data_time: 0.0092  memory: 5150  grad_norm: 92.8744  loss: 8.1026  decode.loss_cls: 0.4242  decode.loss_mask: 0.2139  decode.loss_dice: 0.2099  decode.d0.loss_cls: 0.7969  decode.d0.loss_mask: 0.2342  decode.d0.loss_dice: 0.2465  decode.d1.loss_cls: 0.2681  decode.d1.loss_mask: 0.2217  decode.d1.loss_dice: 0.2113  decode.d2.loss_cls: 0.2573  decode.d2.loss_mask: 0.2181  decode.d2.loss_dice: 0.2250  decode.d3.loss_cls: 0.3623  decode.d3.loss_mask: 0.2180  decode.d3.loss_dice: 0.2218  decode.d4.loss_cls: 0.2737  decode.d4.loss_mask: 0.2169  decode.d4.loss_dice: 0.2188  decode.d5.loss_cls: 0.3116  decode.d5.loss_mask: 0.2206  decode.d5.loss_dice: 0.2344  decode.d6.loss_cls: 0.3331  decode.d6.loss_mask: 0.2199  decode.d6.loss_dice: 0.2147  decode.d7.loss_cls: 0.3319  decode.d7.loss_mask: 0.2204  decode.d7.loss_dice: 0.2177  decode.d8.loss_cls: 0.3134  decode.d8.loss_mask: 0.2201  decode.d8.loss_dice: 0.2263
09/28 17:34:38 - mmengine - INFO - Iter(train) [ 25600/320000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 1 day, 11:55:32  time: 0.4319  data_time: 0.0091  memory: 5166  grad_norm: 71.2074  loss: 5.4016  decode.loss_cls: 0.0615  decode.loss_mask: 0.1826  decode.loss_dice: 0.2072  decode.d0.loss_cls: 0.9985  decode.d0.loss_mask: 0.1904  decode.d0.loss_dice: 0.2040  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.1844  decode.d1.loss_dice: 0.2069  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.1847  decode.d2.loss_dice: 0.2157  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.1845  decode.d3.loss_dice: 0.2056  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.1823  decode.d4.loss_dice: 0.2049  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.1838  decode.d5.loss_dice: 0.2510  decode.d6.loss_cls: 0.0408  decode.d6.loss_mask: 0.1869  decode.d6.loss_dice: 0.2210  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.1836  decode.d7.loss_dice: 0.2221  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.1789  decode.d8.loss_dice: 0.2038
09/28 17:35:00 - mmengine - INFO - Iter(train) [ 25650/320000]  base_lr: 9.2756e-05 lr: 9.2756e-06  eta: 1 day, 11:55:06  time: 0.4322  data_time: 0.0092  memory: 5186  grad_norm: 61.5061  loss: 6.4768  decode.loss_cls: 0.1460  decode.loss_mask: 0.2238  decode.loss_dice: 0.1866  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.2131  decode.d1.loss_cls: 0.1575  decode.d1.loss_mask: 0.2160  decode.d1.loss_dice: 0.1831  decode.d2.loss_cls: 0.1717  decode.d2.loss_mask: 0.2221  decode.d2.loss_dice: 0.1901  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.2184  decode.d3.loss_dice: 0.1815  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 0.2227  decode.d4.loss_dice: 0.1826  decode.d5.loss_cls: 0.1645  decode.d5.loss_mask: 0.2230  decode.d5.loss_dice: 0.1834  decode.d6.loss_cls: 0.1565  decode.d6.loss_mask: 0.2276  decode.d6.loss_dice: 0.1886  decode.d7.loss_cls: 0.1658  decode.d7.loss_mask: 0.2258  decode.d7.loss_dice: 0.1830  decode.d8.loss_cls: 0.1666  decode.d8.loss_mask: 0.2246  decode.d8.loss_dice: 0.1809
09/28 17:35:21 - mmengine - INFO - Iter(train) [ 25700/320000]  base_lr: 9.2742e-05 lr: 9.2742e-06  eta: 1 day, 11:54:40  time: 0.4329  data_time: 0.0093  memory: 5186  grad_norm: 90.0416  loss: 5.4516  decode.loss_cls: 0.0229  decode.loss_mask: 0.2375  decode.loss_dice: 0.1982  decode.d0.loss_cls: 0.7280  decode.d0.loss_mask: 0.2419  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 0.2321  decode.d1.loss_dice: 0.1837  decode.d2.loss_cls: 0.0388  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.2104  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.1989  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.2385  decode.d4.loss_dice: 0.2096  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.2380  decode.d5.loss_dice: 0.2116  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.2344  decode.d6.loss_dice: 0.2008  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.1956  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.2363  decode.d8.loss_dice: 0.2097
09/28 17:35:43 - mmengine - INFO - Iter(train) [ 25750/320000]  base_lr: 9.2728e-05 lr: 9.2728e-06  eta: 1 day, 11:54:14  time: 0.4324  data_time: 0.0092  memory: 5150  grad_norm: 121.9227  loss: 5.7957  decode.loss_cls: 0.0447  decode.loss_mask: 0.2287  decode.loss_dice: 0.1999  decode.d0.loss_cls: 1.0395  decode.d0.loss_mask: 0.2199  decode.d0.loss_dice: 0.1979  decode.d1.loss_cls: 0.1362  decode.d1.loss_mask: 0.2264  decode.d1.loss_dice: 0.1950  decode.d2.loss_cls: 0.0723  decode.d2.loss_mask: 0.2307  decode.d2.loss_dice: 0.1896  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.2314  decode.d3.loss_dice: 0.1973  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.2259  decode.d4.loss_dice: 0.1939  decode.d5.loss_cls: 0.0373  decode.d5.loss_mask: 0.2306  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.0351  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.1926  decode.d7.loss_cls: 0.0421  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.1945  decode.d8.loss_cls: 0.0367  decode.d8.loss_mask: 0.2329  decode.d8.loss_dice: 0.1993
09/28 17:36:04 - mmengine - INFO - Iter(train) [ 25800/320000]  base_lr: 9.2714e-05 lr: 9.2714e-06  eta: 1 day, 11:53:49  time: 0.4323  data_time: 0.0092  memory: 5167  grad_norm: 47.8939  loss: 5.6800  decode.loss_cls: 0.0463  decode.loss_mask: 0.2608  decode.loss_dice: 0.1837  decode.d0.loss_cls: 0.9086  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.1787  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.2653  decode.d2.loss_dice: 0.1875  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.2628  decode.d3.loss_dice: 0.1856  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.1787  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.2606  decode.d5.loss_dice: 0.1803  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.2614  decode.d6.loss_dice: 0.1793  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.1817  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 0.2620  decode.d8.loss_dice: 0.1815
09/28 17:36:26 - mmengine - INFO - Iter(train) [ 25850/320000]  base_lr: 9.2700e-05 lr: 9.2700e-06  eta: 1 day, 11:53:23  time: 0.4328  data_time: 0.0093  memory: 5167  grad_norm: 124.8506  loss: 8.3421  decode.loss_cls: 0.2252  decode.loss_mask: 0.2642  decode.loss_dice: 0.2737  decode.d0.loss_cls: 1.1579  decode.d0.loss_mask: 0.2761  decode.d0.loss_dice: 0.3130  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 0.2577  decode.d1.loss_dice: 0.3189  decode.d2.loss_cls: 0.1537  decode.d2.loss_mask: 0.2552  decode.d2.loss_dice: 0.2757  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.3221  decode.d4.loss_cls: 0.1277  decode.d4.loss_mask: 0.2559  decode.d4.loss_dice: 0.3121  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.2647  decode.d5.loss_dice: 0.3508  decode.d6.loss_cls: 0.1875  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.3171  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 0.2604  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.1804  decode.d8.loss_mask: 0.2639  decode.d8.loss_dice: 0.3178
09/28 17:36:48 - mmengine - INFO - Iter(train) [ 25900/320000]  base_lr: 9.2685e-05 lr: 9.2685e-06  eta: 1 day, 11:52:57  time: 0.4330  data_time: 0.0093  memory: 5167  grad_norm: 69.9484  loss: 7.3679  decode.loss_cls: 0.1219  decode.loss_mask: 0.3206  decode.loss_dice: 0.2062  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.3237  decode.d0.loss_dice: 0.2188  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.3302  decode.d1.loss_dice: 0.2056  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 0.3296  decode.d2.loss_dice: 0.2087  decode.d3.loss_cls: 0.1340  decode.d3.loss_mask: 0.3282  decode.d3.loss_dice: 0.2069  decode.d4.loss_cls: 0.1806  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.2055  decode.d5.loss_cls: 0.1227  decode.d5.loss_mask: 0.3229  decode.d5.loss_dice: 0.2064  decode.d6.loss_cls: 0.1582  decode.d6.loss_mask: 0.3216  decode.d6.loss_dice: 0.2072  decode.d7.loss_cls: 0.1387  decode.d7.loss_mask: 0.3245  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.1479  decode.d8.loss_mask: 0.3245  decode.d8.loss_dice: 0.2080
09/28 17:37:09 - mmengine - INFO - Iter(train) [ 25950/320000]  base_lr: 9.2671e-05 lr: 9.2671e-06  eta: 1 day, 11:52:32  time: 0.4324  data_time: 0.0093  memory: 5167  grad_norm: 64.9300  loss: 6.0805  decode.loss_cls: 0.0562  decode.loss_mask: 0.2599  decode.loss_dice: 0.2093  decode.d0.loss_cls: 0.9364  decode.d0.loss_mask: 0.2648  decode.d0.loss_dice: 0.2161  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.2618  decode.d1.loss_dice: 0.2139  decode.d2.loss_cls: 0.0362  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.2112  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.2568  decode.d3.loss_dice: 0.2097  decode.d4.loss_cls: 0.0340  decode.d4.loss_mask: 0.2596  decode.d4.loss_dice: 0.2089  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.2108  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.2523  decode.d6.loss_dice: 0.2055  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.2079  decode.d8.loss_cls: 0.0509  decode.d8.loss_mask: 0.2582  decode.d8.loss_dice: 0.2080
09/28 17:37:31 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:37:31 - mmengine - INFO - Iter(train) [ 26000/320000]  base_lr: 9.2657e-05 lr: 9.2657e-06  eta: 1 day, 11:52:06  time: 0.4328  data_time: 0.0094  memory: 5167  grad_norm: 145.0548  loss: 8.6886  decode.loss_cls: 0.2126  decode.loss_mask: 0.3585  decode.loss_dice: 0.2565  decode.d0.loss_cls: 1.0197  decode.d0.loss_mask: 0.3524  decode.d0.loss_dice: 0.2675  decode.d1.loss_cls: 0.2892  decode.d1.loss_mask: 0.2974  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 0.3020  decode.d2.loss_dice: 0.2376  decode.d3.loss_cls: 0.2421  decode.d3.loss_mask: 0.2978  decode.d3.loss_dice: 0.2291  decode.d4.loss_cls: 0.2300  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.2310  decode.d5.loss_cls: 0.2555  decode.d5.loss_mask: 0.2992  decode.d5.loss_dice: 0.2234  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 0.3124  decode.d6.loss_dice: 0.2361  decode.d7.loss_cls: 0.2423  decode.d7.loss_mask: 0.3207  decode.d7.loss_dice: 0.2516  decode.d8.loss_cls: 0.2193  decode.d8.loss_mask: 0.3098  decode.d8.loss_dice: 0.2349
09/28 17:37:53 - mmengine - INFO - Iter(train) [ 26050/320000]  base_lr: 9.2643e-05 lr: 9.2643e-06  eta: 1 day, 11:51:42  time: 0.4328  data_time: 0.0093  memory: 5186  grad_norm: 114.0566  loss: 10.6697  decode.loss_cls: 0.3954  decode.loss_mask: 0.3079  decode.loss_dice: 0.3096  decode.d0.loss_cls: 1.0251  decode.d0.loss_mask: 0.3054  decode.d0.loss_dice: 0.3501  decode.d1.loss_cls: 0.4350  decode.d1.loss_mask: 0.3026  decode.d1.loss_dice: 0.3078  decode.d2.loss_cls: 0.3827  decode.d2.loss_mask: 0.3016  decode.d2.loss_dice: 0.3291  decode.d3.loss_cls: 0.2973  decode.d3.loss_mask: 0.2972  decode.d3.loss_dice: 0.3090  decode.d4.loss_cls: 0.3325  decode.d4.loss_mask: 0.2993  decode.d4.loss_dice: 0.3184  decode.d5.loss_cls: 0.4577  decode.d5.loss_mask: 0.3048  decode.d5.loss_dice: 0.3225  decode.d6.loss_cls: 0.3241  decode.d6.loss_mask: 0.3046  decode.d6.loss_dice: 0.3216  decode.d7.loss_cls: 0.3711  decode.d7.loss_mask: 0.3037  decode.d7.loss_dice: 0.3226  decode.d8.loss_cls: 0.4030  decode.d8.loss_mask: 0.3084  decode.d8.loss_dice: 0.3196
09/28 17:38:15 - mmengine - INFO - Iter(train) [ 26100/320000]  base_lr: 9.2629e-05 lr: 9.2629e-06  eta: 1 day, 11:51:17  time: 0.4329  data_time: 0.0094  memory: 5186  grad_norm: 172.1580  loss: 12.1168  decode.loss_cls: 0.3648  decode.loss_mask: 0.4127  decode.loss_dice: 0.3658  decode.d0.loss_cls: 1.2539  decode.d0.loss_mask: 0.3428  decode.d0.loss_dice: 0.3404  decode.d1.loss_cls: 0.4344  decode.d1.loss_mask: 0.3191  decode.d1.loss_dice: 0.3569  decode.d2.loss_cls: 0.4377  decode.d2.loss_mask: 0.3108  decode.d2.loss_dice: 0.3348  decode.d3.loss_cls: 0.3804  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.3660  decode.d4.loss_cls: 0.4213  decode.d4.loss_mask: 0.4216  decode.d4.loss_dice: 0.3708  decode.d5.loss_cls: 0.4108  decode.d5.loss_mask: 0.4225  decode.d5.loss_dice: 0.3391  decode.d6.loss_cls: 0.3533  decode.d6.loss_mask: 0.3821  decode.d6.loss_dice: 0.3477  decode.d7.loss_cls: 0.3789  decode.d7.loss_mask: 0.3798  decode.d7.loss_dice: 0.3801  decode.d8.loss_cls: 0.3171  decode.d8.loss_mask: 0.3960  decode.d8.loss_dice: 0.3611
09/28 17:38:36 - mmengine - INFO - Iter(train) [ 26150/320000]  base_lr: 9.2615e-05 lr: 9.2615e-06  eta: 1 day, 11:50:51  time: 0.4321  data_time: 0.0091  memory: 5167  grad_norm: 44.1883  loss: 6.4749  decode.loss_cls: 0.0973  decode.loss_mask: 0.2400  decode.loss_dice: 0.2183  decode.d0.loss_cls: 0.8864  decode.d0.loss_mask: 0.2424  decode.d0.loss_dice: 0.2324  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 0.2431  decode.d1.loss_dice: 0.2131  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 0.2417  decode.d2.loss_dice: 0.2246  decode.d3.loss_cls: 0.1286  decode.d3.loss_mask: 0.2463  decode.d3.loss_dice: 0.2193  decode.d4.loss_cls: 0.1402  decode.d4.loss_mask: 0.2412  decode.d4.loss_dice: 0.2145  decode.d5.loss_cls: 0.0753  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2191  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.2410  decode.d7.loss_dice: 0.2195  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.2381  decode.d8.loss_dice: 0.2298
09/28 17:38:58 - mmengine - INFO - Iter(train) [ 26200/320000]  base_lr: 9.2600e-05 lr: 9.2600e-06  eta: 1 day, 11:50:26  time: 0.4326  data_time: 0.0095  memory: 5186  grad_norm: 131.2034  loss: 8.0652  decode.loss_cls: 0.1065  decode.loss_mask: 0.3232  decode.loss_dice: 0.2631  decode.d0.loss_cls: 1.0157  decode.d0.loss_mask: 0.3388  decode.d0.loss_dice: 0.2840  decode.d1.loss_cls: 0.1748  decode.d1.loss_mask: 0.3318  decode.d1.loss_dice: 0.2885  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.3283  decode.d2.loss_dice: 0.2586  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.3284  decode.d3.loss_dice: 0.2814  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.3296  decode.d4.loss_dice: 0.2804  decode.d5.loss_cls: 0.1309  decode.d5.loss_mask: 0.3250  decode.d5.loss_dice: 0.2608  decode.d6.loss_cls: 0.1584  decode.d6.loss_mask: 0.3237  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.3243  decode.d7.loss_dice: 0.2647  decode.d8.loss_cls: 0.0860  decode.d8.loss_mask: 0.3321  decode.d8.loss_dice: 0.2742
09/28 17:39:19 - mmengine - INFO - Iter(train) [ 26250/320000]  base_lr: 9.2586e-05 lr: 9.2586e-06  eta: 1 day, 11:50:00  time: 0.4327  data_time: 0.0091  memory: 5186  grad_norm: 39.0910  loss: 6.2155  decode.loss_cls: 0.1842  decode.loss_mask: 0.2151  decode.loss_dice: 0.1692  decode.d0.loss_cls: 0.8094  decode.d0.loss_mask: 0.2248  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 0.2199  decode.d1.loss_dice: 0.1685  decode.d2.loss_cls: 0.1511  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.1669  decode.d3.loss_cls: 0.1960  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.1703  decode.d4.loss_cls: 0.1633  decode.d4.loss_mask: 0.2154  decode.d4.loss_dice: 0.1710  decode.d5.loss_cls: 0.1850  decode.d5.loss_mask: 0.2172  decode.d5.loss_dice: 0.1704  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 0.2156  decode.d6.loss_dice: 0.1687  decode.d7.loss_cls: 0.1491  decode.d7.loss_mask: 0.2181  decode.d7.loss_dice: 0.1708  decode.d8.loss_cls: 0.1579  decode.d8.loss_mask: 0.2164  decode.d8.loss_dice: 0.1700
09/28 17:39:41 - mmengine - INFO - Iter(train) [ 26300/320000]  base_lr: 9.2572e-05 lr: 9.2572e-06  eta: 1 day, 11:49:35  time: 0.4329  data_time: 0.0095  memory: 5148  grad_norm: 93.9477  loss: 8.8193  decode.loss_cls: 0.2694  decode.loss_mask: 0.2726  decode.loss_dice: 0.2300  decode.d0.loss_cls: 1.1086  decode.d0.loss_mask: 0.2769  decode.d0.loss_dice: 0.2269  decode.d1.loss_cls: 0.3105  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.2114  decode.d2.loss_cls: 0.2529  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.3321  decode.d3.loss_mask: 0.2729  decode.d3.loss_dice: 0.2316  decode.d4.loss_cls: 0.2976  decode.d4.loss_mask: 0.2747  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.3435  decode.d5.loss_mask: 0.2723  decode.d5.loss_dice: 0.2209  decode.d6.loss_cls: 0.3498  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.2276  decode.d7.loss_cls: 0.2918  decode.d7.loss_mask: 0.2768  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.2689  decode.d8.loss_mask: 0.2746  decode.d8.loss_dice: 0.2265
09/28 17:40:03 - mmengine - INFO - Iter(train) [ 26350/320000]  base_lr: 9.2558e-05 lr: 9.2558e-06  eta: 1 day, 11:49:09  time: 0.4326  data_time: 0.0093  memory: 5186  grad_norm: 86.7899  loss: 8.4728  decode.loss_cls: 0.1890  decode.loss_mask: 0.2572  decode.loss_dice: 0.3106  decode.d0.loss_cls: 1.0847  decode.d0.loss_mask: 0.2560  decode.d0.loss_dice: 0.3524  decode.d1.loss_cls: 0.2499  decode.d1.loss_mask: 0.2460  decode.d1.loss_dice: 0.3047  decode.d2.loss_cls: 0.2020  decode.d2.loss_mask: 0.2558  decode.d2.loss_dice: 0.3242  decode.d3.loss_cls: 0.1673  decode.d3.loss_mask: 0.2569  decode.d3.loss_dice: 0.3129  decode.d4.loss_cls: 0.1671  decode.d4.loss_mask: 0.2627  decode.d4.loss_dice: 0.3285  decode.d5.loss_cls: 0.1528  decode.d5.loss_mask: 0.2629  decode.d5.loss_dice: 0.3387  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 0.2578  decode.d6.loss_dice: 0.3215  decode.d7.loss_cls: 0.1351  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.3236  decode.d8.loss_cls: 0.1760  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.3141
09/28 17:40:24 - mmengine - INFO - Iter(train) [ 26400/320000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 1 day, 11:48:44  time: 0.4326  data_time: 0.0091  memory: 5186  grad_norm: 30.4101  loss: 6.1052  decode.loss_cls: 0.1446  decode.loss_mask: 0.1919  decode.loss_dice: 0.1513  decode.d0.loss_cls: 1.0149  decode.d0.loss_mask: 0.2003  decode.d0.loss_dice: 0.1666  decode.d1.loss_cls: 0.2055  decode.d1.loss_mask: 0.1947  decode.d1.loss_dice: 0.1504  decode.d2.loss_cls: 0.2267  decode.d2.loss_mask: 0.1892  decode.d2.loss_dice: 0.1645  decode.d3.loss_cls: 0.2478  decode.d3.loss_mask: 0.1902  decode.d3.loss_dice: 0.1560  decode.d4.loss_cls: 0.2161  decode.d4.loss_mask: 0.1883  decode.d4.loss_dice: 0.1574  decode.d5.loss_cls: 0.1189  decode.d5.loss_mask: 0.1929  decode.d5.loss_dice: 0.1651  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 0.1876  decode.d6.loss_dice: 0.1607  decode.d7.loss_cls: 0.1332  decode.d7.loss_mask: 0.1889  decode.d7.loss_dice: 0.1630  decode.d8.loss_cls: 0.1671  decode.d8.loss_mask: 0.1909  decode.d8.loss_dice: 0.1580
09/28 17:40:46 - mmengine - INFO - Iter(train) [ 26450/320000]  base_lr: 9.2529e-05 lr: 9.2529e-06  eta: 1 day, 11:48:18  time: 0.4325  data_time: 0.0094  memory: 5150  grad_norm: 69.1677  loss: 9.3367  decode.loss_cls: 0.2168  decode.loss_mask: 0.3016  decode.loss_dice: 0.3169  decode.d0.loss_cls: 0.9913  decode.d0.loss_mask: 0.3010  decode.d0.loss_dice: 0.3268  decode.d1.loss_cls: 0.2721  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.3083  decode.d2.loss_cls: 0.2429  decode.d2.loss_mask: 0.2991  decode.d2.loss_dice: 0.3234  decode.d3.loss_cls: 0.2459  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.3031  decode.d4.loss_cls: 0.2403  decode.d4.loss_mask: 0.2953  decode.d4.loss_dice: 0.3270  decode.d5.loss_cls: 0.2563  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.3212  decode.d6.loss_cls: 0.2255  decode.d6.loss_mask: 0.3027  decode.d6.loss_dice: 0.3368  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 0.3071  decode.d7.loss_dice: 0.3257  decode.d8.loss_cls: 0.2239  decode.d8.loss_mask: 0.3031  decode.d8.loss_dice: 0.3158
09/28 17:41:08 - mmengine - INFO - Iter(train) [ 26500/320000]  base_lr: 9.2515e-05 lr: 9.2515e-06  eta: 1 day, 11:47:52  time: 0.4321  data_time: 0.0092  memory: 5186  grad_norm: 136.7661  loss: 8.4108  decode.loss_cls: 0.1897  decode.loss_mask: 0.3369  decode.loss_dice: 0.2767  decode.d0.loss_cls: 0.9428  decode.d0.loss_mask: 0.3087  decode.d0.loss_dice: 0.3056  decode.d1.loss_cls: 0.1973  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.2671  decode.d2.loss_cls: 0.1499  decode.d2.loss_mask: 0.3116  decode.d2.loss_dice: 0.2928  decode.d3.loss_cls: 0.1369  decode.d3.loss_mask: 0.3088  decode.d3.loss_dice: 0.2733  decode.d4.loss_cls: 0.1727  decode.d4.loss_mask: 0.3003  decode.d4.loss_dice: 0.2528  decode.d5.loss_cls: 0.1692  decode.d5.loss_mask: 0.3099  decode.d5.loss_dice: 0.2630  decode.d6.loss_cls: 0.1649  decode.d6.loss_mask: 0.3220  decode.d6.loss_dice: 0.2648  decode.d7.loss_cls: 0.1800  decode.d7.loss_mask: 0.3416  decode.d7.loss_dice: 0.2676  decode.d8.loss_cls: 0.1692  decode.d8.loss_mask: 0.3462  decode.d8.loss_dice: 0.2848
09/28 17:41:29 - mmengine - INFO - Iter(train) [ 26550/320000]  base_lr: 9.2501e-05 lr: 9.2501e-06  eta: 1 day, 11:47:27  time: 0.4325  data_time: 0.0091  memory: 5186  grad_norm: 50.4955  loss: 4.9461  decode.loss_cls: 0.0672  decode.loss_mask: 0.2052  decode.loss_dice: 0.1676  decode.d0.loss_cls: 0.9171  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.1694  decode.d1.loss_cls: 0.0286  decode.d1.loss_mask: 0.2060  decode.d1.loss_dice: 0.1590  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.1557  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.2085  decode.d3.loss_dice: 0.1584  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.2045  decode.d4.loss_dice: 0.1626  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.2099  decode.d5.loss_dice: 0.1659  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.2051  decode.d6.loss_dice: 0.1564  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.2087  decode.d7.loss_dice: 0.1670  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.2019  decode.d8.loss_dice: 0.1658
09/28 17:41:51 - mmengine - INFO - Iter(train) [ 26600/320000]  base_lr: 9.2487e-05 lr: 9.2487e-06  eta: 1 day, 11:47:01  time: 0.4326  data_time: 0.0092  memory: 5166  grad_norm: 48.0081  loss: 6.0762  decode.loss_cls: 0.0304  decode.loss_mask: 0.2289  decode.loss_dice: 0.2476  decode.d0.loss_cls: 0.9023  decode.d0.loss_mask: 0.2301  decode.d0.loss_dice: 0.2613  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.2309  decode.d1.loss_dice: 0.2561  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.2323  decode.d2.loss_dice: 0.2792  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.2706  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.2281  decode.d4.loss_dice: 0.2525  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.2562  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.2257  decode.d6.loss_dice: 0.2476  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.2297  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.0218  decode.d8.loss_mask: 0.2290  decode.d8.loss_dice: 0.2643
09/28 17:42:12 - mmengine - INFO - Iter(train) [ 26650/320000]  base_lr: 9.2473e-05 lr: 9.2473e-06  eta: 1 day, 11:46:35  time: 0.4324  data_time: 0.0092  memory: 5185  grad_norm: 52.8858  loss: 5.6994  decode.loss_cls: 0.0846  decode.loss_mask: 0.2083  decode.loss_dice: 0.1956  decode.d0.loss_cls: 0.9882  decode.d0.loss_mask: 0.2072  decode.d0.loss_dice: 0.1961  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.2062  decode.d1.loss_dice: 0.1993  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.2085  decode.d2.loss_dice: 0.2090  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.2033  decode.d3.loss_dice: 0.1939  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 0.2071  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.2066  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.2048  decode.d6.loss_dice: 0.1891  decode.d7.loss_cls: 0.0785  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.2115  decode.d8.loss_cls: 0.0803  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.2014
09/28 17:42:34 - mmengine - INFO - Iter(train) [ 26700/320000]  base_lr: 9.2459e-05 lr: 9.2459e-06  eta: 1 day, 11:46:10  time: 0.4330  data_time: 0.0094  memory: 5186  grad_norm: 75.6327  loss: 5.8718  decode.loss_cls: 0.0404  decode.loss_mask: 0.2985  decode.loss_dice: 0.1775  decode.d0.loss_cls: 0.7660  decode.d0.loss_mask: 0.3099  decode.d0.loss_dice: 0.1858  decode.d1.loss_cls: 0.0283  decode.d1.loss_mask: 0.2975  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 0.2952  decode.d2.loss_dice: 0.1772  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.1790  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.3016  decode.d4.loss_dice: 0.1765  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.1758  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.2986  decode.d6.loss_dice: 0.1781  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.3023  decode.d7.loss_dice: 0.1786  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.2984  decode.d8.loss_dice: 0.1749
09/28 17:42:56 - mmengine - INFO - Iter(train) [ 26750/320000]  base_lr: 9.2444e-05 lr: 9.2444e-06  eta: 1 day, 11:45:44  time: 0.4320  data_time: 0.0093  memory: 5166  grad_norm: 19.7903  loss: 4.9168  decode.loss_cls: 0.0155  decode.loss_mask: 0.2218  decode.loss_dice: 0.1719  decode.d0.loss_cls: 0.8202  decode.d0.loss_mask: 0.2226  decode.d0.loss_dice: 0.1829  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.2211  decode.d1.loss_dice: 0.1778  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.2173  decode.d2.loss_dice: 0.1749  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.2191  decode.d3.loss_dice: 0.1747  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.2196  decode.d5.loss_dice: 0.1769  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.1735  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.2201  decode.d7.loss_dice: 0.1761  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2239  decode.d8.loss_dice: 0.1731
09/28 17:43:17 - mmengine - INFO - Iter(train) [ 26800/320000]  base_lr: 9.2430e-05 lr: 9.2430e-06  eta: 1 day, 11:45:19  time: 0.4320  data_time: 0.0093  memory: 5167  grad_norm: 52.3593  loss: 5.7112  decode.loss_cls: 0.1179  decode.loss_mask: 0.2241  decode.loss_dice: 0.1745  decode.d0.loss_cls: 0.8760  decode.d0.loss_mask: 0.2311  decode.d0.loss_dice: 0.1767  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.2277  decode.d1.loss_dice: 0.1767  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.2273  decode.d2.loss_dice: 0.1820  decode.d3.loss_cls: 0.0679  decode.d3.loss_mask: 0.2294  decode.d3.loss_dice: 0.1859  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.2294  decode.d4.loss_dice: 0.1762  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2277  decode.d5.loss_dice: 0.1846  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 0.2273  decode.d6.loss_dice: 0.1806  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.1839  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.2239  decode.d8.loss_dice: 0.1826
09/28 17:43:39 - mmengine - INFO - Iter(train) [ 26850/320000]  base_lr: 9.2416e-05 lr: 9.2416e-06  eta: 1 day, 11:44:53  time: 0.4327  data_time: 0.0094  memory: 5186  grad_norm: 28.9496  loss: 5.3593  decode.loss_cls: 0.1109  decode.loss_mask: 0.2049  decode.loss_dice: 0.1484  decode.d0.loss_cls: 0.8467  decode.d0.loss_mask: 0.2131  decode.d0.loss_dice: 0.1731  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.2027  decode.d1.loss_dice: 0.1546  decode.d2.loss_cls: 0.0778  decode.d2.loss_mask: 0.2046  decode.d2.loss_dice: 0.1519  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.2025  decode.d3.loss_dice: 0.1491  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.2046  decode.d4.loss_dice: 0.1509  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.2042  decode.d5.loss_dice: 0.1515  decode.d6.loss_cls: 0.1300  decode.d6.loss_mask: 0.2045  decode.d6.loss_dice: 0.1505  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.2032  decode.d7.loss_dice: 0.1535  decode.d8.loss_cls: 0.1022  decode.d8.loss_mask: 0.2063  decode.d8.loss_dice: 0.1539
09/28 17:44:01 - mmengine - INFO - Iter(train) [ 26900/320000]  base_lr: 9.2402e-05 lr: 9.2402e-06  eta: 1 day, 11:44:28  time: 0.4324  data_time: 0.0094  memory: 5166  grad_norm: 169.6775  loss: 9.6934  decode.loss_cls: 0.3015  decode.loss_mask: 0.3197  decode.loss_dice: 0.2954  decode.d0.loss_cls: 1.2067  decode.d0.loss_mask: 0.3273  decode.d0.loss_dice: 0.3059  decode.d1.loss_cls: 0.2183  decode.d1.loss_mask: 0.3274  decode.d1.loss_dice: 0.2834  decode.d2.loss_cls: 0.2831  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.2741  decode.d3.loss_cls: 0.2706  decode.d3.loss_mask: 0.3131  decode.d3.loss_dice: 0.2686  decode.d4.loss_cls: 0.2529  decode.d4.loss_mask: 0.3203  decode.d4.loss_dice: 0.2771  decode.d5.loss_cls: 0.2593  decode.d5.loss_mask: 0.3212  decode.d5.loss_dice: 0.2698  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 0.3174  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.2788  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.3026  decode.d8.loss_mask: 0.3206  decode.d8.loss_dice: 0.2819
09/28 17:44:22 - mmengine - INFO - Iter(train) [ 26950/320000]  base_lr: 9.2388e-05 lr: 9.2388e-06  eta: 1 day, 11:44:03  time: 0.4328  data_time: 0.0094  memory: 5167  grad_norm: 55.8544  loss: 7.0657  decode.loss_cls: 0.0875  decode.loss_mask: 0.2779  decode.loss_dice: 0.2439  decode.d0.loss_cls: 0.9705  decode.d0.loss_mask: 0.2779  decode.d0.loss_dice: 0.2685  decode.d1.loss_cls: 0.1253  decode.d1.loss_mask: 0.2793  decode.d1.loss_dice: 0.2622  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.2718  decode.d2.loss_dice: 0.2573  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.2590  decode.d4.loss_cls: 0.0866  decode.d4.loss_mask: 0.2762  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.2766  decode.d5.loss_dice: 0.2522  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.2737  decode.d6.loss_dice: 0.2514  decode.d7.loss_cls: 0.0893  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.2421  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 0.2787  decode.d8.loss_dice: 0.2689
09/28 17:44:44 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:44:44 - mmengine - INFO - Iter(train) [ 27000/320000]  base_lr: 9.2373e-05 lr: 9.2373e-06  eta: 1 day, 11:43:38  time: 0.4322  data_time: 0.0093  memory: 5185  grad_norm: 29.3166  loss: 5.3491  decode.loss_cls: 0.0352  decode.loss_mask: 0.2271  decode.loss_dice: 0.2001  decode.d0.loss_cls: 0.7099  decode.d0.loss_mask: 0.2338  decode.d0.loss_dice: 0.2078  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2012  decode.d2.loss_cls: 0.0397  decode.d2.loss_mask: 0.2240  decode.d2.loss_dice: 0.1994  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.1938  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.2271  decode.d5.loss_dice: 0.1991  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.2285  decode.d6.loss_dice: 0.2026  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.1991  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.2239  decode.d8.loss_dice: 0.2029
09/28 17:45:06 - mmengine - INFO - Iter(train) [ 27050/320000]  base_lr: 9.2359e-05 lr: 9.2359e-06  eta: 1 day, 11:43:12  time: 0.4326  data_time: 0.0093  memory: 5167  grad_norm: 98.0635  loss: 8.1068  decode.loss_cls: 0.0800  decode.loss_mask: 0.3469  decode.loss_dice: 0.2959  decode.d0.loss_cls: 0.9730  decode.d0.loss_mask: 0.3437  decode.d0.loss_dice: 0.2970  decode.d1.loss_cls: 0.1448  decode.d1.loss_mask: 0.3278  decode.d1.loss_dice: 0.2793  decode.d2.loss_cls: 0.1462  decode.d2.loss_mask: 0.3416  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.3337  decode.d3.loss_dice: 0.2839  decode.d4.loss_cls: 0.0899  decode.d4.loss_mask: 0.3271  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.3384  decode.d5.loss_dice: 0.2848  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.3337  decode.d6.loss_dice: 0.2872  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.2816  decode.d8.loss_cls: 0.0950  decode.d8.loss_mask: 0.3283  decode.d8.loss_dice: 0.2849
09/28 17:45:27 - mmengine - INFO - Iter(train) [ 27100/320000]  base_lr: 9.2345e-05 lr: 9.2345e-06  eta: 1 day, 11:42:47  time: 0.4324  data_time: 0.0095  memory: 5167  grad_norm: 63.8206  loss: 5.9820  decode.loss_cls: 0.0408  decode.loss_mask: 0.2255  decode.loss_dice: 0.2165  decode.d0.loss_cls: 0.9494  decode.d0.loss_mask: 0.2380  decode.d0.loss_dice: 0.2491  decode.d1.loss_cls: 0.0488  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.2398  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.2340  decode.d2.loss_dice: 0.2307  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.2289  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.2319  decode.d4.loss_dice: 0.2387  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.2360  decode.d5.loss_dice: 0.2326  decode.d6.loss_cls: 0.0357  decode.d6.loss_mask: 0.2453  decode.d6.loss_dice: 0.2315  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.2379  decode.d7.loss_dice: 0.2389  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.2259
09/28 17:45:49 - mmengine - INFO - Iter(train) [ 27150/320000]  base_lr: 9.2331e-05 lr: 9.2331e-06  eta: 1 day, 11:42:22  time: 0.4337  data_time: 0.0095  memory: 5150  grad_norm: 452.9408  loss: 9.9883  decode.loss_cls: 0.2164  decode.loss_mask: 0.4275  decode.loss_dice: 0.2557  decode.d0.loss_cls: 1.3150  decode.d0.loss_mask: 0.3884  decode.d0.loss_dice: 0.2812  decode.d1.loss_cls: 0.3075  decode.d1.loss_mask: 0.4010  decode.d1.loss_dice: 0.2605  decode.d2.loss_cls: 0.2001  decode.d2.loss_mask: 0.4291  decode.d2.loss_dice: 0.2500  decode.d3.loss_cls: 0.2464  decode.d3.loss_mask: 0.3997  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.1944  decode.d4.loss_mask: 0.3915  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.4213  decode.d5.loss_dice: 0.2503  decode.d6.loss_cls: 0.2211  decode.d6.loss_mask: 0.4146  decode.d6.loss_dice: 0.2512  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 0.4147  decode.d7.loss_dice: 0.2565  decode.d8.loss_cls: 0.1945  decode.d8.loss_mask: 0.4080  decode.d8.loss_dice: 0.2582
09/28 17:46:11 - mmengine - INFO - Iter(train) [ 27200/320000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 1 day, 11:41:57  time: 0.4327  data_time: 0.0095  memory: 5167  grad_norm: 60.8913  loss: 7.1843  decode.loss_cls: 0.1360  decode.loss_mask: 0.2644  decode.loss_dice: 0.2566  decode.d0.loss_cls: 0.7895  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.2773  decode.d1.loss_cls: 0.1248  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.2543  decode.d2.loss_cls: 0.1091  decode.d2.loss_mask: 0.2682  decode.d2.loss_dice: 0.2560  decode.d3.loss_cls: 0.1322  decode.d3.loss_mask: 0.2621  decode.d3.loss_dice: 0.2667  decode.d4.loss_cls: 0.1215  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.2482  decode.d5.loss_cls: 0.1202  decode.d5.loss_mask: 0.2661  decode.d5.loss_dice: 0.2672  decode.d6.loss_cls: 0.1715  decode.d6.loss_mask: 0.2620  decode.d6.loss_dice: 0.2619  decode.d7.loss_cls: 0.1207  decode.d7.loss_mask: 0.2607  decode.d7.loss_dice: 0.2649  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.2619  decode.d8.loss_dice: 0.2714
09/28 17:46:32 - mmengine - INFO - Iter(train) [ 27250/320000]  base_lr: 9.2302e-05 lr: 9.2302e-06  eta: 1 day, 11:41:32  time: 0.4325  data_time: 0.0094  memory: 5150  grad_norm: 46.0948  loss: 6.3388  decode.loss_cls: 0.0508  decode.loss_mask: 0.2471  decode.loss_dice: 0.2676  decode.d0.loss_cls: 0.7951  decode.d0.loss_mask: 0.2505  decode.d0.loss_dice: 0.2631  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.2522  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2408  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.2461  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.0747  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.2415  decode.d5.loss_cls: 0.0546  decode.d5.loss_mask: 0.2529  decode.d5.loss_dice: 0.2477  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.2455  decode.d6.loss_dice: 0.2449  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.2486  decode.d7.loss_dice: 0.2478  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.2479  decode.d8.loss_dice: 0.2309
09/28 17:46:54 - mmengine - INFO - Iter(train) [ 27300/320000]  base_lr: 9.2288e-05 lr: 9.2288e-06  eta: 1 day, 11:41:07  time: 0.4335  data_time: 0.0093  memory: 5167  grad_norm: 231.3195  loss: 9.5093  decode.loss_cls: 0.2947  decode.loss_mask: 0.3283  decode.loss_dice: 0.2670  decode.d0.loss_cls: 0.9629  decode.d0.loss_mask: 0.3379  decode.d0.loss_dice: 0.2887  decode.d1.loss_cls: 0.2310  decode.d1.loss_mask: 0.3237  decode.d1.loss_dice: 0.2552  decode.d2.loss_cls: 0.2521  decode.d2.loss_mask: 0.3313  decode.d2.loss_dice: 0.2688  decode.d3.loss_cls: 0.2847  decode.d3.loss_mask: 0.3320  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.2866  decode.d4.loss_mask: 0.3651  decode.d4.loss_dice: 0.3135  decode.d5.loss_cls: 0.2592  decode.d5.loss_mask: 0.3587  decode.d5.loss_dice: 0.3003  decode.d6.loss_cls: 0.2397  decode.d6.loss_mask: 0.3500  decode.d6.loss_dice: 0.2792  decode.d7.loss_cls: 0.2560  decode.d7.loss_mask: 0.3349  decode.d7.loss_dice: 0.2681  decode.d8.loss_cls: 0.2800  decode.d8.loss_mask: 0.3301  decode.d8.loss_dice: 0.2620
09/28 17:47:16 - mmengine - INFO - Iter(train) [ 27350/320000]  base_lr: 9.2274e-05 lr: 9.2274e-06  eta: 1 day, 11:40:41  time: 0.4318  data_time: 0.0093  memory: 5186  grad_norm: 60.2943  loss: 9.0106  decode.loss_cls: 0.1927  decode.loss_mask: 0.2787  decode.loss_dice: 0.2960  decode.d0.loss_cls: 1.2075  decode.d0.loss_mask: 0.2905  decode.d0.loss_dice: 0.3237  decode.d1.loss_cls: 0.2611  decode.d1.loss_mask: 0.2853  decode.d1.loss_dice: 0.2926  decode.d2.loss_cls: 0.2465  decode.d2.loss_mask: 0.2784  decode.d2.loss_dice: 0.2955  decode.d3.loss_cls: 0.2234  decode.d3.loss_mask: 0.2802  decode.d3.loss_dice: 0.3036  decode.d4.loss_cls: 0.2250  decode.d4.loss_mask: 0.2925  decode.d4.loss_dice: 0.3359  decode.d5.loss_cls: 0.2146  decode.d5.loss_mask: 0.2806  decode.d5.loss_dice: 0.2922  decode.d6.loss_cls: 0.1819  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.2952  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.2826  decode.d7.loss_dice: 0.3162  decode.d8.loss_cls: 0.1982  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.2950
09/28 17:47:37 - mmengine - INFO - Iter(train) [ 27400/320000]  base_lr: 9.2260e-05 lr: 9.2260e-06  eta: 1 day, 11:40:16  time: 0.4331  data_time: 0.0094  memory: 5167  grad_norm: 160.3859  loss: 10.6957  decode.loss_cls: 0.2608  decode.loss_mask: 0.3825  decode.loss_dice: 0.3214  decode.d0.loss_cls: 1.0469  decode.d0.loss_mask: 0.3722  decode.d0.loss_dice: 0.3579  decode.d1.loss_cls: 0.3959  decode.d1.loss_mask: 0.3747  decode.d1.loss_dice: 0.3157  decode.d2.loss_cls: 0.3440  decode.d2.loss_mask: 0.4064  decode.d2.loss_dice: 0.3315  decode.d3.loss_cls: 0.2953  decode.d3.loss_mask: 0.3588  decode.d3.loss_dice: 0.3460  decode.d4.loss_cls: 0.2583  decode.d4.loss_mask: 0.3728  decode.d4.loss_dice: 0.3469  decode.d5.loss_cls: 0.2427  decode.d5.loss_mask: 0.3721  decode.d5.loss_dice: 0.3220  decode.d6.loss_cls: 0.2779  decode.d6.loss_mask: 0.3846  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 0.1957  decode.d7.loss_mask: 0.3784  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.2534  decode.d8.loss_mask: 0.3789  decode.d8.loss_dice: 0.3324
09/28 17:47:59 - mmengine - INFO - Iter(train) [ 27450/320000]  base_lr: 9.2246e-05 lr: 9.2246e-06  eta: 1 day, 11:39:51  time: 0.4334  data_time: 0.0094  memory: 5166  grad_norm: 59.4592  loss: 6.4106  decode.loss_cls: 0.0469  decode.loss_mask: 0.2648  decode.loss_dice: 0.2464  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 0.2646  decode.d0.loss_dice: 0.2343  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.2668  decode.d1.loss_dice: 0.2371  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.2361  decode.d3.loss_cls: 0.1131  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.2704  decode.d4.loss_dice: 0.2410  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.2654  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.2653  decode.d6.loss_dice: 0.2347  decode.d7.loss_cls: 0.0486  decode.d7.loss_mask: 0.2680  decode.d7.loss_dice: 0.2330  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.2635  decode.d8.loss_dice: 0.2299
09/28 17:48:20 - mmengine - INFO - Iter(train) [ 27500/320000]  base_lr: 9.2232e-05 lr: 9.2232e-06  eta: 1 day, 11:39:26  time: 0.4330  data_time: 0.0094  memory: 5150  grad_norm: 27.0471  loss: 6.0701  decode.loss_cls: 0.0576  decode.loss_mask: 0.2413  decode.loss_dice: 0.2151  decode.d0.loss_cls: 0.8333  decode.d0.loss_mask: 0.2458  decode.d0.loss_dice: 0.2304  decode.d1.loss_cls: 0.0937  decode.d1.loss_mask: 0.2444  decode.d1.loss_dice: 0.2282  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.2432  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.2423  decode.d3.loss_dice: 0.2217  decode.d4.loss_cls: 0.0898  decode.d4.loss_mask: 0.2433  decode.d4.loss_dice: 0.2243  decode.d5.loss_cls: 0.0744  decode.d5.loss_mask: 0.2404  decode.d5.loss_dice: 0.2062  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.2231  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.2431  decode.d7.loss_dice: 0.2136  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.2431  decode.d8.loss_dice: 0.2227
09/28 17:48:42 - mmengine - INFO - Iter(train) [ 27550/320000]  base_lr: 9.2217e-05 lr: 9.2217e-06  eta: 1 day, 11:39:00  time: 0.4325  data_time: 0.0093  memory: 5167  grad_norm: 59.9594  loss: 7.3923  decode.loss_cls: 0.1186  decode.loss_mask: 0.3237  decode.loss_dice: 0.2244  decode.d0.loss_cls: 0.9625  decode.d0.loss_mask: 0.3275  decode.d0.loss_dice: 0.2308  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.3373  decode.d1.loss_dice: 0.2636  decode.d2.loss_cls: 0.0816  decode.d2.loss_mask: 0.3185  decode.d2.loss_dice: 0.2352  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.3149  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.0973  decode.d4.loss_mask: 0.3193  decode.d4.loss_dice: 0.2249  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.3150  decode.d5.loss_dice: 0.2224  decode.d6.loss_cls: 0.0879  decode.d6.loss_mask: 0.3185  decode.d6.loss_dice: 0.2229  decode.d7.loss_cls: 0.1217  decode.d7.loss_mask: 0.3257  decode.d7.loss_dice: 0.2258  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 0.3208  decode.d8.loss_dice: 0.2244
09/28 17:49:04 - mmengine - INFO - Iter(train) [ 27600/320000]  base_lr: 9.2203e-05 lr: 9.2203e-06  eta: 1 day, 11:38:35  time: 0.4324  data_time: 0.0093  memory: 5201  grad_norm: 76.0790  loss: 6.9203  decode.loss_cls: 0.1269  decode.loss_mask: 0.2297  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.9843  decode.d0.loss_mask: 0.2334  decode.d0.loss_dice: 0.2816  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 0.2310  decode.d1.loss_dice: 0.2471  decode.d2.loss_cls: 0.1176  decode.d2.loss_mask: 0.2301  decode.d2.loss_dice: 0.2521  decode.d3.loss_cls: 0.1175  decode.d3.loss_mask: 0.2320  decode.d3.loss_dice: 0.2730  decode.d4.loss_cls: 0.1067  decode.d4.loss_mask: 0.2295  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.2482  decode.d6.loss_cls: 0.1077  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.2340  decode.d7.loss_cls: 0.1554  decode.d7.loss_mask: 0.2302  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.1441  decode.d8.loss_mask: 0.2282  decode.d8.loss_dice: 0.2412
09/28 17:49:25 - mmengine - INFO - Iter(train) [ 27650/320000]  base_lr: 9.2189e-05 lr: 9.2189e-06  eta: 1 day, 11:38:10  time: 0.4317  data_time: 0.0093  memory: 5166  grad_norm: 102.4166  loss: 9.1686  decode.loss_cls: 0.2323  decode.loss_mask: 0.3268  decode.loss_dice: 0.2846  decode.d0.loss_cls: 1.0848  decode.d0.loss_mask: 0.3581  decode.d0.loss_dice: 0.3111  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.3514  decode.d1.loss_dice: 0.2947  decode.d2.loss_cls: 0.1383  decode.d2.loss_mask: 0.3487  decode.d2.loss_dice: 0.2803  decode.d3.loss_cls: 0.1575  decode.d3.loss_mask: 0.3526  decode.d3.loss_dice: 0.2715  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.3483  decode.d4.loss_dice: 0.2749  decode.d5.loss_cls: 0.2006  decode.d5.loss_mask: 0.3443  decode.d5.loss_dice: 0.2825  decode.d6.loss_cls: 0.2022  decode.d6.loss_mask: 0.3364  decode.d6.loss_dice: 0.2741  decode.d7.loss_cls: 0.1767  decode.d7.loss_mask: 0.3446  decode.d7.loss_dice: 0.2911  decode.d8.loss_cls: 0.2750  decode.d8.loss_mask: 0.3388  decode.d8.loss_dice: 0.2932
09/28 17:49:47 - mmengine - INFO - Iter(train) [ 27700/320000]  base_lr: 9.2175e-05 lr: 9.2175e-06  eta: 1 day, 11:37:46  time: 0.4314  data_time: 0.0093  memory: 5167  grad_norm: 22.3638  loss: 5.0227  decode.loss_cls: 0.0129  decode.loss_mask: 0.1906  decode.loss_dice: 0.2072  decode.d0.loss_cls: 0.8909  decode.d0.loss_mask: 0.1962  decode.d0.loss_dice: 0.2029  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.1890  decode.d1.loss_dice: 0.1992  decode.d2.loss_cls: 0.0211  decode.d2.loss_mask: 0.1916  decode.d2.loss_dice: 0.2012  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.1912  decode.d3.loss_dice: 0.2020  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.1925  decode.d4.loss_dice: 0.2004  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.1949  decode.d5.loss_dice: 0.2034  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.1919  decode.d6.loss_dice: 0.1929  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.1902  decode.d7.loss_dice: 0.1972  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.1914  decode.d8.loss_dice: 0.2013
09/28 17:50:09 - mmengine - INFO - Iter(train) [ 27750/320000]  base_lr: 9.2161e-05 lr: 9.2161e-06  eta: 1 day, 11:37:21  time: 0.4329  data_time: 0.0094  memory: 5166  grad_norm: 49.3589  loss: 6.9712  decode.loss_cls: 0.1528  decode.loss_mask: 0.2465  decode.loss_dice: 0.1900  decode.d0.loss_cls: 1.0492  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.1843  decode.d1.loss_cls: 0.1926  decode.d1.loss_mask: 0.2496  decode.d1.loss_dice: 0.1834  decode.d2.loss_cls: 0.1738  decode.d2.loss_mask: 0.2477  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.1897  decode.d3.loss_mask: 0.2484  decode.d3.loss_dice: 0.1858  decode.d4.loss_cls: 0.1776  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.1834  decode.d5.loss_cls: 0.1590  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.1862  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 0.2514  decode.d6.loss_dice: 0.1825  decode.d7.loss_cls: 0.1713  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.1859  decode.d8.loss_cls: 0.1732  decode.d8.loss_mask: 0.2493  decode.d8.loss_dice: 0.1855
09/28 17:50:30 - mmengine - INFO - Iter(train) [ 27800/320000]  base_lr: 9.2146e-05 lr: 9.2146e-06  eta: 1 day, 11:36:55  time: 0.4323  data_time: 0.0094  memory: 5167  grad_norm: 52.2860  loss: 5.6000  decode.loss_cls: 0.0357  decode.loss_mask: 0.2546  decode.loss_dice: 0.1875  decode.d0.loss_cls: 0.8819  decode.d0.loss_mask: 0.2565  decode.d0.loss_dice: 0.1993  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.2540  decode.d2.loss_dice: 0.1933  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.1914  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.1854  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.1855  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.1932  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.2560  decode.d8.loss_dice: 0.1939
09/28 17:50:52 - mmengine - INFO - Iter(train) [ 27850/320000]  base_lr: 9.2132e-05 lr: 9.2132e-06  eta: 1 day, 11:36:30  time: 0.4318  data_time: 0.0091  memory: 5167  grad_norm: 153.7692  loss: 8.4483  decode.loss_cls: 0.1838  decode.loss_mask: 0.3659  decode.loss_dice: 0.2431  decode.d0.loss_cls: 0.9830  decode.d0.loss_mask: 0.3385  decode.d0.loss_dice: 0.2491  decode.d1.loss_cls: 0.1337  decode.d1.loss_mask: 0.3506  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 0.3578  decode.d2.loss_dice: 0.2453  decode.d3.loss_cls: 0.1412  decode.d3.loss_mask: 0.3694  decode.d3.loss_dice: 0.2453  decode.d4.loss_cls: 0.1574  decode.d4.loss_mask: 0.3628  decode.d4.loss_dice: 0.2429  decode.d5.loss_cls: 0.1643  decode.d5.loss_mask: 0.3557  decode.d5.loss_dice: 0.2464  decode.d6.loss_cls: 0.1771  decode.d6.loss_mask: 0.3752  decode.d6.loss_dice: 0.2471  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 0.3559  decode.d7.loss_dice: 0.2451  decode.d8.loss_cls: 0.1494  decode.d8.loss_mask: 0.3539  decode.d8.loss_dice: 0.2414
09/28 17:51:14 - mmengine - INFO - Iter(train) [ 27900/320000]  base_lr: 9.2118e-05 lr: 9.2118e-06  eta: 1 day, 11:36:05  time: 0.4319  data_time: 0.0091  memory: 5167  grad_norm: 95.5881  loss: 6.5409  decode.loss_cls: 0.0814  decode.loss_mask: 0.2733  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.8669  decode.d0.loss_mask: 0.2812  decode.d0.loss_dice: 0.2237  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.2749  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.2710  decode.d2.loss_dice: 0.2124  decode.d3.loss_cls: 0.0786  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2194  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.2749  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.0664  decode.d5.loss_mask: 0.2703  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 0.2767  decode.d7.loss_dice: 0.2197  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.2196
09/28 17:51:35 - mmengine - INFO - Iter(train) [ 27950/320000]  base_lr: 9.2104e-05 lr: 9.2104e-06  eta: 1 day, 11:35:40  time: 0.4330  data_time: 0.0093  memory: 5167  grad_norm: 31.4775  loss: 6.0557  decode.loss_cls: 0.0810  decode.loss_mask: 0.2092  decode.loss_dice: 0.1749  decode.d0.loss_cls: 0.8935  decode.d0.loss_mask: 0.2182  decode.d0.loss_dice: 0.2357  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.2098  decode.d1.loss_dice: 0.2021  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.2122  decode.d2.loss_dice: 0.2053  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 0.2118  decode.d3.loss_dice: 0.2104  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.2052  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.2110  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.1205  decode.d6.loss_mask: 0.2112  decode.d6.loss_dice: 0.2106  decode.d7.loss_cls: 0.1511  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.2151  decode.d8.loss_cls: 0.1361  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.2186
09/28 17:51:57 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:51:57 - mmengine - INFO - Iter(train) [ 28000/320000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 1 day, 11:35:14  time: 0.4320  data_time: 0.0093  memory: 5186  grad_norm: 37.6498  loss: 7.5446  decode.loss_cls: 0.1166  decode.loss_mask: 0.3097  decode.loss_dice: 0.2210  decode.d0.loss_cls: 1.1347  decode.d0.loss_mask: 0.3018  decode.d0.loss_dice: 0.2119  decode.d1.loss_cls: 0.1781  decode.d1.loss_mask: 0.2994  decode.d1.loss_dice: 0.2135  decode.d2.loss_cls: 0.1718  decode.d2.loss_mask: 0.2928  decode.d2.loss_dice: 0.2083  decode.d3.loss_cls: 0.1583  decode.d3.loss_mask: 0.2978  decode.d3.loss_dice: 0.2130  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.3127  decode.d4.loss_dice: 0.2300  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 0.3017  decode.d5.loss_dice: 0.2237  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.3089  decode.d6.loss_dice: 0.2284  decode.d7.loss_cls: 0.0959  decode.d7.loss_mask: 0.3221  decode.d7.loss_dice: 0.2352  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.3124  decode.d8.loss_dice: 0.2186
09/28 17:52:18 - mmengine - INFO - Iter(train) [ 28050/320000]  base_lr: 9.2075e-05 lr: 9.2075e-06  eta: 1 day, 11:34:49  time: 0.4324  data_time: 0.0091  memory: 5167  grad_norm: 73.9258  loss: 6.2414  decode.loss_cls: 0.0991  decode.loss_mask: 0.2355  decode.loss_dice: 0.2392  decode.d0.loss_cls: 0.7797  decode.d0.loss_mask: 0.2328  decode.d0.loss_dice: 0.2278  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.2377  decode.d1.loss_dice: 0.1674  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.2358  decode.d2.loss_dice: 0.2116  decode.d3.loss_cls: 0.1360  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2437  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.2354  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.2365  decode.d5.loss_dice: 0.2176  decode.d6.loss_cls: 0.1140  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.2060  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.2259  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.2341  decode.d8.loss_dice: 0.2348
09/28 17:52:40 - mmengine - INFO - Iter(train) [ 28100/320000]  base_lr: 9.2061e-05 lr: 9.2061e-06  eta: 1 day, 11:34:24  time: 0.4326  data_time: 0.0095  memory: 5186  grad_norm: 57.7187  loss: 7.3887  decode.loss_cls: 0.1052  decode.loss_mask: 0.3036  decode.loss_dice: 0.2462  decode.d0.loss_cls: 0.9684  decode.d0.loss_mask: 0.3146  decode.d0.loss_dice: 0.2597  decode.d1.loss_cls: 0.1087  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.2445  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.2431  decode.d3.loss_cls: 0.1129  decode.d3.loss_mask: 0.3071  decode.d3.loss_dice: 0.2500  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.3052  decode.d4.loss_dice: 0.2556  decode.d5.loss_cls: 0.1035  decode.d5.loss_mask: 0.3032  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.3032  decode.d6.loss_dice: 0.2469  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.3029  decode.d7.loss_dice: 0.2501  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.3046  decode.d8.loss_dice: 0.2549
09/28 17:53:02 - mmengine - INFO - Iter(train) [ 28150/320000]  base_lr: 9.2047e-05 lr: 9.2047e-06  eta: 1 day, 11:33:59  time: 0.4323  data_time: 0.0094  memory: 5185  grad_norm: 47.5810  loss: 5.6457  decode.loss_cls: 0.0213  decode.loss_mask: 0.2579  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.8237  decode.d0.loss_mask: 0.2608  decode.d0.loss_dice: 0.2210  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.1895  decode.d3.loss_cls: 0.0341  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.1938  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 0.2547  decode.d4.loss_dice: 0.1905  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.2590  decode.d5.loss_dice: 0.1941  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.2532  decode.d6.loss_dice: 0.1922  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.1891  decode.d8.loss_cls: 0.0241  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.1937
09/28 17:53:23 - mmengine - INFO - Iter(train) [ 28200/320000]  base_lr: 9.2033e-05 lr: 9.2033e-06  eta: 1 day, 11:33:34  time: 0.4325  data_time: 0.0093  memory: 5150  grad_norm: 89.6566  loss: 6.0152  decode.loss_cls: 0.0827  decode.loss_mask: 0.2336  decode.loss_dice: 0.2000  decode.d0.loss_cls: 0.8935  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.2112  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.2342  decode.d1.loss_dice: 0.1976  decode.d2.loss_cls: 0.0852  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.2015  decode.d3.loss_cls: 0.1411  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.1982  decode.d4.loss_cls: 0.0870  decode.d4.loss_mask: 0.2337  decode.d4.loss_dice: 0.1916  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.1956  decode.d6.loss_cls: 0.0996  decode.d6.loss_mask: 0.2340  decode.d6.loss_dice: 0.1928  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.2328  decode.d7.loss_dice: 0.1934  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.1927
09/28 17:53:45 - mmengine - INFO - Iter(train) [ 28250/320000]  base_lr: 9.2019e-05 lr: 9.2019e-06  eta: 1 day, 11:33:09  time: 0.4323  data_time: 0.0094  memory: 5167  grad_norm: 120.9082  loss: 10.1493  decode.loss_cls: 0.2258  decode.loss_mask: 0.3571  decode.loss_dice: 0.3248  decode.d0.loss_cls: 0.8961  decode.d0.loss_mask: 0.3664  decode.d0.loss_dice: 0.3336  decode.d1.loss_cls: 0.2526  decode.d1.loss_mask: 0.3839  decode.d1.loss_dice: 0.3641  decode.d2.loss_cls: 0.1854  decode.d2.loss_mask: 0.4242  decode.d2.loss_dice: 0.3873  decode.d3.loss_cls: 0.2065  decode.d3.loss_mask: 0.4258  decode.d3.loss_dice: 0.3652  decode.d4.loss_cls: 0.1962  decode.d4.loss_mask: 0.3762  decode.d4.loss_dice: 0.3550  decode.d5.loss_cls: 0.1925  decode.d5.loss_mask: 0.3668  decode.d5.loss_dice: 0.3348  decode.d6.loss_cls: 0.2359  decode.d6.loss_mask: 0.3657  decode.d6.loss_dice: 0.3530  decode.d7.loss_cls: 0.2332  decode.d7.loss_mask: 0.3667  decode.d7.loss_dice: 0.3355  decode.d8.loss_cls: 0.2494  decode.d8.loss_mask: 0.3593  decode.d8.loss_dice: 0.3301
09/28 17:54:07 - mmengine - INFO - Iter(train) [ 28300/320000]  base_lr: 9.2004e-05 lr: 9.2004e-06  eta: 1 day, 11:32:44  time: 0.4319  data_time: 0.0092  memory: 5186  grad_norm: 149.1191  loss: 7.5917  decode.loss_cls: 0.1153  decode.loss_mask: 0.3037  decode.loss_dice: 0.2298  decode.d0.loss_cls: 0.8056  decode.d0.loss_mask: 0.3111  decode.d0.loss_dice: 0.2314  decode.d1.loss_cls: 0.2179  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.2409  decode.d2.loss_cls: 0.1213  decode.d2.loss_mask: 0.3613  decode.d2.loss_dice: 0.2425  decode.d3.loss_cls: 0.1595  decode.d3.loss_mask: 0.3105  decode.d3.loss_dice: 0.2268  decode.d4.loss_cls: 0.1200  decode.d4.loss_mask: 0.3414  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.1332  decode.d5.loss_mask: 0.3573  decode.d5.loss_dice: 0.2459  decode.d6.loss_cls: 0.1033  decode.d6.loss_mask: 0.3258  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.0932  decode.d7.loss_mask: 0.3097  decode.d7.loss_dice: 0.2390  decode.d8.loss_cls: 0.1039  decode.d8.loss_mask: 0.3081  decode.d8.loss_dice: 0.2329
09/28 17:54:28 - mmengine - INFO - Iter(train) [ 28350/320000]  base_lr: 9.1990e-05 lr: 9.1990e-06  eta: 1 day, 11:32:19  time: 0.4331  data_time: 0.0094  memory: 5166  grad_norm: 89.9134  loss: 9.1753  decode.loss_cls: 0.2833  decode.loss_mask: 0.2480  decode.loss_dice: 0.2840  decode.d0.loss_cls: 1.0588  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.2877  decode.d1.loss_cls: 0.3515  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.2568  decode.d2.loss_cls: 0.2659  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.3071  decode.d3.loss_cls: 0.2902  decode.d3.loss_mask: 0.2727  decode.d3.loss_dice: 0.2716  decode.d4.loss_cls: 0.2916  decode.d4.loss_mask: 0.2935  decode.d4.loss_dice: 0.2781  decode.d5.loss_cls: 0.2744  decode.d5.loss_mask: 0.2857  decode.d5.loss_dice: 0.2650  decode.d6.loss_cls: 0.3552  decode.d6.loss_mask: 0.2519  decode.d6.loss_dice: 0.2581  decode.d7.loss_cls: 0.3279  decode.d7.loss_mask: 0.2507  decode.d7.loss_dice: 0.2810  decode.d8.loss_cls: 0.3318  decode.d8.loss_mask: 0.2516  decode.d8.loss_dice: 0.2359
09/28 17:54:50 - mmengine - INFO - Iter(train) [ 28400/320000]  base_lr: 9.1976e-05 lr: 9.1976e-06  eta: 1 day, 11:31:54  time: 0.4340  data_time: 0.0094  memory: 5166  grad_norm: 153.9180  loss: 8.5348  decode.loss_cls: 0.1960  decode.loss_mask: 0.3124  decode.loss_dice: 0.2687  decode.d0.loss_cls: 1.1039  decode.d0.loss_mask: 0.3162  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.1930  decode.d1.loss_mask: 0.3513  decode.d1.loss_dice: 0.2635  decode.d2.loss_cls: 0.1925  decode.d2.loss_mask: 0.3197  decode.d2.loss_dice: 0.2707  decode.d3.loss_cls: 0.1276  decode.d3.loss_mask: 0.3582  decode.d3.loss_dice: 0.2563  decode.d4.loss_cls: 0.1480  decode.d4.loss_mask: 0.3393  decode.d4.loss_dice: 0.2717  decode.d5.loss_cls: 0.1359  decode.d5.loss_mask: 0.3139  decode.d5.loss_dice: 0.2572  decode.d6.loss_cls: 0.2069  decode.d6.loss_mask: 0.3142  decode.d6.loss_dice: 0.2511  decode.d7.loss_cls: 0.1640  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.2547  decode.d8.loss_cls: 0.1933  decode.d8.loss_mask: 0.3115  decode.d8.loss_dice: 0.2633
09/28 17:55:12 - mmengine - INFO - Iter(train) [ 28450/320000]  base_lr: 9.1962e-05 lr: 9.1962e-06  eta: 1 day, 11:31:29  time: 0.4333  data_time: 0.0094  memory: 5186  grad_norm: 17.4064  loss: 5.1113  decode.loss_cls: 0.0272  decode.loss_mask: 0.2315  decode.loss_dice: 0.1677  decode.d0.loss_cls: 0.8441  decode.d0.loss_mask: 0.2305  decode.d0.loss_dice: 0.1832  decode.d1.loss_cls: 0.0238  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.1734  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.2299  decode.d2.loss_dice: 0.1767  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.1704  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.2340  decode.d4.loss_dice: 0.1686  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.2318  decode.d5.loss_dice: 0.1733  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.1709  decode.d7.loss_cls: 0.0277  decode.d7.loss_mask: 0.2327  decode.d7.loss_dice: 0.1727  decode.d8.loss_cls: 0.0272  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.1687
09/28 17:55:33 - mmengine - INFO - Iter(train) [ 28500/320000]  base_lr: 9.1948e-05 lr: 9.1948e-06  eta: 1 day, 11:31:04  time: 0.4333  data_time: 0.0094  memory: 5167  grad_norm: 50.9670  loss: 9.0152  decode.loss_cls: 0.2768  decode.loss_mask: 0.2905  decode.loss_dice: 0.2680  decode.d0.loss_cls: 1.0191  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.2721  decode.d1.loss_cls: 0.2180  decode.d1.loss_mask: 0.2695  decode.d1.loss_dice: 0.2724  decode.d2.loss_cls: 0.3134  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.2675  decode.d3.loss_cls: 0.2507  decode.d3.loss_mask: 0.4252  decode.d3.loss_dice: 0.2807  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.3492  decode.d4.loss_dice: 0.2618  decode.d5.loss_cls: 0.1578  decode.d5.loss_mask: 0.3975  decode.d5.loss_dice: 0.2616  decode.d6.loss_cls: 0.2205  decode.d6.loss_mask: 0.3053  decode.d6.loss_dice: 0.2631  decode.d7.loss_cls: 0.2550  decode.d7.loss_mask: 0.3340  decode.d7.loss_dice: 0.2599  decode.d8.loss_cls: 0.2483  decode.d8.loss_mask: 0.2820  decode.d8.loss_dice: 0.2549
09/28 17:55:55 - mmengine - INFO - Iter(train) [ 28550/320000]  base_lr: 9.1934e-05 lr: 9.1934e-06  eta: 1 day, 11:30:40  time: 0.4327  data_time: 0.0092  memory: 5186  grad_norm: 37.0824  loss: 6.1807  decode.loss_cls: 0.1000  decode.loss_mask: 0.2199  decode.loss_dice: 0.1908  decode.d0.loss_cls: 0.9531  decode.d0.loss_mask: 0.2241  decode.d0.loss_dice: 0.2448  decode.d1.loss_cls: 0.0949  decode.d1.loss_mask: 0.2217  decode.d1.loss_dice: 0.2187  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 0.2251  decode.d2.loss_dice: 0.2147  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.2208  decode.d3.loss_dice: 0.2346  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.2155  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.2226  decode.d5.loss_dice: 0.2493  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.2219  decode.d6.loss_dice: 0.2362  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.2195  decode.d7.loss_dice: 0.2303  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2386
09/28 17:56:17 - mmengine - INFO - Iter(train) [ 28600/320000]  base_lr: 9.1919e-05 lr: 9.1919e-06  eta: 1 day, 11:30:15  time: 0.4333  data_time: 0.0094  memory: 5186  grad_norm: 429.7278  loss: 9.0196  decode.loss_cls: 0.1485  decode.loss_mask: 0.4647  decode.loss_dice: 0.2396  decode.d0.loss_cls: 0.9647  decode.d0.loss_mask: 0.4038  decode.d0.loss_dice: 0.2779  decode.d1.loss_cls: 0.1310  decode.d1.loss_mask: 0.4687  decode.d1.loss_dice: 0.2489  decode.d2.loss_cls: 0.1170  decode.d2.loss_mask: 0.4765  decode.d2.loss_dice: 0.2431  decode.d3.loss_cls: 0.1034  decode.d3.loss_mask: 0.4594  decode.d3.loss_dice: 0.2378  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.4649  decode.d4.loss_dice: 0.2392  decode.d5.loss_cls: 0.1044  decode.d5.loss_mask: 0.4329  decode.d5.loss_dice: 0.2411  decode.d6.loss_cls: 0.1434  decode.d6.loss_mask: 0.4358  decode.d6.loss_dice: 0.2373  decode.d7.loss_cls: 0.1486  decode.d7.loss_mask: 0.4400  decode.d7.loss_dice: 0.2341  decode.d8.loss_cls: 0.1420  decode.d8.loss_mask: 0.4302  decode.d8.loss_dice: 0.2293
09/28 17:56:38 - mmengine - INFO - Iter(train) [ 28650/320000]  base_lr: 9.1905e-05 lr: 9.1905e-06  eta: 1 day, 11:29:51  time: 0.4332  data_time: 0.0093  memory: 5186  grad_norm: 39.0872  loss: 6.7499  decode.loss_cls: 0.1701  decode.loss_mask: 0.2011  decode.loss_dice: 0.2149  decode.d0.loss_cls: 0.9488  decode.d0.loss_mask: 0.2071  decode.d0.loss_dice: 0.2573  decode.d1.loss_cls: 0.1838  decode.d1.loss_mask: 0.2068  decode.d1.loss_dice: 0.2252  decode.d2.loss_cls: 0.2539  decode.d2.loss_mask: 0.2049  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 0.2015  decode.d3.loss_dice: 0.1924  decode.d4.loss_cls: 0.2093  decode.d4.loss_mask: 0.2093  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.1472  decode.d5.loss_mask: 0.2020  decode.d5.loss_dice: 0.2088  decode.d6.loss_cls: 0.1726  decode.d6.loss_mask: 0.2023  decode.d6.loss_dice: 0.1941  decode.d7.loss_cls: 0.1371  decode.d7.loss_mask: 0.2013  decode.d7.loss_dice: 0.2058  decode.d8.loss_cls: 0.1461  decode.d8.loss_mask: 0.2043  decode.d8.loss_dice: 0.1961
09/28 17:57:00 - mmengine - INFO - Iter(train) [ 28700/320000]  base_lr: 9.1891e-05 lr: 9.1891e-06  eta: 1 day, 11:29:26  time: 0.4325  data_time: 0.0091  memory: 5166  grad_norm: 65.1139  loss: 6.4643  decode.loss_cls: 0.1216  decode.loss_mask: 0.2253  decode.loss_dice: 0.2183  decode.d0.loss_cls: 0.9383  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.2197  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.2257  decode.d1.loss_dice: 0.2093  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.2279  decode.d2.loss_dice: 0.2265  decode.d3.loss_cls: 0.1248  decode.d3.loss_mask: 0.2247  decode.d3.loss_dice: 0.2079  decode.d4.loss_cls: 0.1342  decode.d4.loss_mask: 0.2244  decode.d4.loss_dice: 0.2167  decode.d5.loss_cls: 0.1551  decode.d5.loss_mask: 0.2269  decode.d5.loss_dice: 0.2031  decode.d6.loss_cls: 0.1271  decode.d6.loss_mask: 0.2269  decode.d6.loss_dice: 0.2199  decode.d7.loss_cls: 0.1137  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.2044  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 0.2239  decode.d8.loss_dice: 0.2084
09/28 17:57:22 - mmengine - INFO - Iter(train) [ 28750/320000]  base_lr: 9.1877e-05 lr: 9.1877e-06  eta: 1 day, 11:29:01  time: 0.4328  data_time: 0.0093  memory: 5167  grad_norm: 109.3065  loss: 6.8821  decode.loss_cls: 0.1282  decode.loss_mask: 0.2504  decode.loss_dice: 0.2097  decode.d0.loss_cls: 0.9095  decode.d0.loss_mask: 0.2534  decode.d0.loss_dice: 0.2141  decode.d1.loss_cls: 0.2018  decode.d1.loss_mask: 0.2437  decode.d1.loss_dice: 0.2122  decode.d2.loss_cls: 0.2783  decode.d2.loss_mask: 0.2451  decode.d2.loss_dice: 0.2059  decode.d3.loss_cls: 0.1661  decode.d3.loss_mask: 0.2496  decode.d3.loss_dice: 0.2126  decode.d4.loss_cls: 0.0989  decode.d4.loss_mask: 0.2726  decode.d4.loss_dice: 0.2245  decode.d5.loss_cls: 0.1081  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.2170  decode.d6.loss_cls: 0.1222  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2065  decode.d7.loss_cls: 0.1200  decode.d7.loss_mask: 0.2443  decode.d7.loss_dice: 0.2103  decode.d8.loss_cls: 0.1188  decode.d8.loss_mask: 0.2506  decode.d8.loss_dice: 0.2078
09/28 17:57:43 - mmengine - INFO - Iter(train) [ 28800/320000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 1 day, 11:28:37  time: 0.4333  data_time: 0.0094  memory: 5150  grad_norm: 95.0578  loss: 7.4134  decode.loss_cls: 0.1678  decode.loss_mask: 0.2307  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.7945  decode.d0.loss_mask: 0.2504  decode.d0.loss_dice: 0.2832  decode.d1.loss_cls: 0.2074  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.2483  decode.d2.loss_cls: 0.2135  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.2481  decode.d3.loss_cls: 0.1806  decode.d3.loss_mask: 0.2329  decode.d3.loss_dice: 0.2609  decode.d4.loss_cls: 0.1948  decode.d4.loss_mask: 0.2306  decode.d4.loss_dice: 0.2515  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 0.2337  decode.d5.loss_dice: 0.2605  decode.d6.loss_cls: 0.2085  decode.d6.loss_mask: 0.2300  decode.d6.loss_dice: 0.2561  decode.d7.loss_cls: 0.2093  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2595  decode.d8.loss_cls: 0.1744  decode.d8.loss_mask: 0.2305  decode.d8.loss_dice: 0.2611
09/28 17:58:05 - mmengine - INFO - Iter(train) [ 28850/320000]  base_lr: 9.1848e-05 lr: 9.1848e-06  eta: 1 day, 11:28:12  time: 0.4329  data_time: 0.0092  memory: 5166  grad_norm: 24.9325  loss: 4.6785  decode.loss_cls: 0.0337  decode.loss_mask: 0.1824  decode.loss_dice: 0.1726  decode.d0.loss_cls: 0.8751  decode.d0.loss_mask: 0.1852  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.1831  decode.d1.loss_dice: 0.1786  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.1853  decode.d2.loss_dice: 0.1690  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.1825  decode.d3.loss_dice: 0.1752  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.1817  decode.d4.loss_dice: 0.1685  decode.d5.loss_cls: 0.0285  decode.d5.loss_mask: 0.1834  decode.d5.loss_dice: 0.1651  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.1843  decode.d6.loss_dice: 0.1621  decode.d7.loss_cls: 0.0197  decode.d7.loss_mask: 0.1849  decode.d7.loss_dice: 0.1648  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.1849  decode.d8.loss_dice: 0.1760
09/28 17:58:27 - mmengine - INFO - Iter(train) [ 28900/320000]  base_lr: 9.1834e-05 lr: 9.1834e-06  eta: 1 day, 11:27:47  time: 0.4334  data_time: 0.0093  memory: 5186  grad_norm: 12.6171  loss: 4.3943  decode.loss_cls: 0.0146  decode.loss_mask: 0.1895  decode.loss_dice: 0.1593  decode.d0.loss_cls: 0.7538  decode.d0.loss_mask: 0.1916  decode.d0.loss_dice: 0.1635  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.1877  decode.d1.loss_dice: 0.1599  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.1867  decode.d2.loss_dice: 0.1632  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.1896  decode.d3.loss_dice: 0.1569  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.1882  decode.d4.loss_dice: 0.1556  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.1893  decode.d5.loss_dice: 0.1569  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.1889  decode.d6.loss_dice: 0.1552  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.1886  decode.d7.loss_dice: 0.1587  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.1889  decode.d8.loss_dice: 0.1566
09/28 17:58:48 - mmengine - INFO - Iter(train) [ 28950/320000]  base_lr: 9.1820e-05 lr: 9.1820e-06  eta: 1 day, 11:27:22  time: 0.4322  data_time: 0.0093  memory: 5150  grad_norm: 41.6995  loss: 7.1001  decode.loss_cls: 0.0950  decode.loss_mask: 0.2565  decode.loss_dice: 0.2369  decode.d0.loss_cls: 0.8734  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.2528  decode.d1.loss_cls: 0.0876  decode.d1.loss_mask: 0.2581  decode.d1.loss_dice: 0.2305  decode.d2.loss_cls: 0.1004  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.1696  decode.d3.loss_mask: 0.2579  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.2588  decode.d4.loss_dice: 0.2228  decode.d5.loss_cls: 0.1643  decode.d5.loss_mask: 0.2547  decode.d5.loss_dice: 0.2298  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.2553  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.2566  decode.d8.loss_dice: 0.2771
09/28 17:59:10 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 17:59:10 - mmengine - INFO - Iter(train) [ 29000/320000]  base_lr: 9.1806e-05 lr: 9.1806e-06  eta: 1 day, 11:26:58  time: 0.4331  data_time: 0.0092  memory: 5167  grad_norm: 41.8391  loss: 5.7519  decode.loss_cls: 0.0171  decode.loss_mask: 0.2321  decode.loss_dice: 0.2057  decode.d0.loss_cls: 1.0027  decode.d0.loss_mask: 0.2361  decode.d0.loss_dice: 0.2241  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.2318  decode.d1.loss_dice: 0.2121  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.2039  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.2339  decode.d3.loss_dice: 0.2070  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.2317  decode.d4.loss_dice: 0.2176  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.2037  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.2288  decode.d6.loss_dice: 0.2006  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.2317  decode.d7.loss_dice: 0.2135  decode.d8.loss_cls: 0.0966  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.2067
09/28 17:59:32 - mmengine - INFO - Iter(train) [ 29050/320000]  base_lr: 9.1792e-05 lr: 9.1792e-06  eta: 1 day, 11:26:33  time: 0.4319  data_time: 0.0093  memory: 5167  grad_norm: 43.3916  loss: 5.5122  decode.loss_cls: 0.0306  decode.loss_mask: 0.2131  decode.loss_dice: 0.2159  decode.d0.loss_cls: 0.8493  decode.d0.loss_mask: 0.2164  decode.d0.loss_dice: 0.2089  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.2135  decode.d1.loss_dice: 0.1824  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.2126  decode.d2.loss_dice: 0.2165  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.2112  decode.d3.loss_dice: 0.2069  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.2116  decode.d4.loss_dice: 0.1985  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.2121  decode.d5.loss_dice: 0.2009  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.2126  decode.d6.loss_dice: 0.2169  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.2121  decode.d7.loss_dice: 0.1998  decode.d8.loss_cls: 0.0328  decode.d8.loss_mask: 0.2117  decode.d8.loss_dice: 0.2082
09/28 17:59:53 - mmengine - INFO - Iter(train) [ 29100/320000]  base_lr: 9.1777e-05 lr: 9.1777e-06  eta: 1 day, 11:26:08  time: 0.4331  data_time: 0.0092  memory: 5167  grad_norm: 372.4402  loss: 9.9956  decode.loss_cls: 0.2677  decode.loss_mask: 0.3742  decode.loss_dice: 0.2900  decode.d0.loss_cls: 1.1900  decode.d0.loss_mask: 0.2749  decode.d0.loss_dice: 0.2609  decode.d1.loss_cls: 0.2918  decode.d1.loss_mask: 0.3376  decode.d1.loss_dice: 0.2846  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 0.3932  decode.d2.loss_dice: 0.2948  decode.d3.loss_cls: 0.3623  decode.d3.loss_mask: 0.3439  decode.d3.loss_dice: 0.2541  decode.d4.loss_cls: 0.2833  decode.d4.loss_mask: 0.3337  decode.d4.loss_dice: 0.2295  decode.d5.loss_cls: 0.2346  decode.d5.loss_mask: 0.4121  decode.d5.loss_dice: 0.2907  decode.d6.loss_cls: 0.2533  decode.d6.loss_mask: 0.3550  decode.d6.loss_dice: 0.2785  decode.d7.loss_cls: 0.3089  decode.d7.loss_mask: 0.3893  decode.d7.loss_dice: 0.2771  decode.d8.loss_cls: 0.1670  decode.d8.loss_mask: 0.4536  decode.d8.loss_dice: 0.2834
09/28 18:00:15 - mmengine - INFO - Iter(train) [ 29150/320000]  base_lr: 9.1763e-05 lr: 9.1763e-06  eta: 1 day, 11:25:43  time: 0.4336  data_time: 0.0093  memory: 5167  grad_norm: 85.6398  loss: 6.1111  decode.loss_cls: 0.1669  decode.loss_mask: 0.2030  decode.loss_dice: 0.1768  decode.d0.loss_cls: 0.9534  decode.d0.loss_mask: 0.2107  decode.d0.loss_dice: 0.1720  decode.d1.loss_cls: 0.1424  decode.d1.loss_mask: 0.2064  decode.d1.loss_dice: 0.1722  decode.d2.loss_cls: 0.1134  decode.d2.loss_mask: 0.2073  decode.d2.loss_dice: 0.1749  decode.d3.loss_cls: 0.1423  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.1778  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.1714  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.1721  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 0.2034  decode.d6.loss_dice: 0.1641  decode.d7.loss_cls: 0.1520  decode.d7.loss_mask: 0.2057  decode.d7.loss_dice: 0.1706  decode.d8.loss_cls: 0.1498  decode.d8.loss_mask: 0.2008  decode.d8.loss_dice: 0.1694
09/28 18:00:37 - mmengine - INFO - Iter(train) [ 29200/320000]  base_lr: 9.1749e-05 lr: 9.1749e-06  eta: 1 day, 11:25:19  time: 0.4340  data_time: 0.0093  memory: 5166  grad_norm: 32.8911  loss: 6.1769  decode.loss_cls: 0.0902  decode.loss_mask: 0.2627  decode.loss_dice: 0.1858  decode.d0.loss_cls: 0.7842  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.1974  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.2635  decode.d1.loss_dice: 0.1902  decode.d2.loss_cls: 0.1156  decode.d2.loss_mask: 0.2596  decode.d2.loss_dice: 0.1895  decode.d3.loss_cls: 0.1041  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.1861  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.2660  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0915  decode.d5.loss_mask: 0.2612  decode.d5.loss_dice: 0.1775  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.2616  decode.d6.loss_dice: 0.1836  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.2632  decode.d7.loss_dice: 0.1773  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 0.2629  decode.d8.loss_dice: 0.1950
09/28 18:00:58 - mmengine - INFO - Iter(train) [ 29250/320000]  base_lr: 9.1735e-05 lr: 9.1735e-06  eta: 1 day, 11:24:54  time: 0.4329  data_time: 0.0093  memory: 5166  grad_norm: 60.9379  loss: 8.7816  decode.loss_cls: 0.2311  decode.loss_mask: 0.2279  decode.loss_dice: 0.3336  decode.d0.loss_cls: 1.0223  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.3074  decode.d1.loss_cls: 0.2895  decode.d1.loss_mask: 0.2274  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.2553  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.3176  decode.d3.loss_cls: 0.2227  decode.d3.loss_mask: 0.2265  decode.d3.loss_dice: 0.3269  decode.d4.loss_cls: 0.2893  decode.d4.loss_mask: 0.2324  decode.d4.loss_dice: 0.3222  decode.d5.loss_cls: 0.2670  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.1971  decode.d6.loss_mask: 0.2313  decode.d6.loss_dice: 0.3251  decode.d7.loss_cls: 0.2157  decode.d7.loss_mask: 0.2304  decode.d7.loss_dice: 0.3431  decode.d8.loss_cls: 0.2057  decode.d8.loss_mask: 0.2308  decode.d8.loss_dice: 0.3545
09/28 18:01:20 - mmengine - INFO - Iter(train) [ 29300/320000]  base_lr: 9.1721e-05 lr: 9.1721e-06  eta: 1 day, 11:24:29  time: 0.4327  data_time: 0.0092  memory: 5186  grad_norm: 49.4136  loss: 6.0650  decode.loss_cls: 0.1592  decode.loss_mask: 0.2105  decode.loss_dice: 0.2063  decode.d0.loss_cls: 0.9178  decode.d0.loss_mask: 0.2177  decode.d0.loss_dice: 0.2140  decode.d1.loss_cls: 0.0889  decode.d1.loss_mask: 0.2113  decode.d1.loss_dice: 0.1884  decode.d2.loss_cls: 0.1108  decode.d2.loss_mask: 0.2097  decode.d2.loss_dice: 0.1843  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.2073  decode.d3.loss_dice: 0.1838  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 0.2067  decode.d4.loss_dice: 0.1996  decode.d5.loss_cls: 0.1060  decode.d5.loss_mask: 0.2072  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 0.2131  decode.d6.loss_dice: 0.1984  decode.d7.loss_cls: 0.1464  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.1965  decode.d8.loss_cls: 0.1637  decode.d8.loss_mask: 0.2079  decode.d8.loss_dice: 0.1925
09/28 18:01:42 - mmengine - INFO - Iter(train) [ 29350/320000]  base_lr: 9.1706e-05 lr: 9.1706e-06  eta: 1 day, 11:24:06  time: 0.4332  data_time: 0.0096  memory: 5166  grad_norm: 42.9489  loss: 6.0119  decode.loss_cls: 0.0142  decode.loss_mask: 0.2905  decode.loss_dice: 0.2153  decode.d0.loss_cls: 0.8175  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.2223  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.2049  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.2903  decode.d2.loss_dice: 0.2116  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.2853  decode.d3.loss_dice: 0.2073  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.2889  decode.d4.loss_dice: 0.2100  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.2928  decode.d5.loss_dice: 0.2122  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.2882  decode.d6.loss_dice: 0.2119  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.2913  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.2933  decode.d8.loss_dice: 0.2163
09/28 18:02:03 - mmengine - INFO - Iter(train) [ 29400/320000]  base_lr: 9.1692e-05 lr: 9.1692e-06  eta: 1 day, 11:23:41  time: 0.4330  data_time: 0.0093  memory: 5166  grad_norm: 52.9857  loss: 7.8045  decode.loss_cls: 0.1880  decode.loss_mask: 0.2711  decode.loss_dice: 0.2505  decode.d0.loss_cls: 0.8599  decode.d0.loss_mask: 0.2706  decode.d0.loss_dice: 0.2771  decode.d1.loss_cls: 0.1971  decode.d1.loss_mask: 0.2720  decode.d1.loss_dice: 0.2539  decode.d2.loss_cls: 0.2200  decode.d2.loss_mask: 0.2726  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.1934  decode.d3.loss_mask: 0.2729  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.1798  decode.d4.loss_mask: 0.2677  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2390  decode.d6.loss_cls: 0.2049  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.2401  decode.d7.loss_cls: 0.1775  decode.d7.loss_mask: 0.2711  decode.d7.loss_dice: 0.2498  decode.d8.loss_cls: 0.2160  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.2453
09/28 18:02:25 - mmengine - INFO - Iter(train) [ 29450/320000]  base_lr: 9.1678e-05 lr: 9.1678e-06  eta: 1 day, 11:23:17  time: 0.4332  data_time: 0.0094  memory: 5186  grad_norm: 93.2004  loss: 6.0472  decode.loss_cls: 0.0348  decode.loss_mask: 0.2744  decode.loss_dice: 0.1998  decode.d0.loss_cls: 0.8490  decode.d0.loss_mask: 0.2777  decode.d0.loss_dice: 0.1983  decode.d1.loss_cls: 0.1487  decode.d1.loss_mask: 0.2768  decode.d1.loss_dice: 0.2097  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.2776  decode.d2.loss_dice: 0.2011  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.2758  decode.d3.loss_dice: 0.2009  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 0.2811  decode.d4.loss_dice: 0.2040  decode.d5.loss_cls: 0.0219  decode.d5.loss_mask: 0.2793  decode.d5.loss_dice: 0.2020  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.2746  decode.d7.loss_dice: 0.2013  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.2014
09/28 18:02:47 - mmengine - INFO - Iter(train) [ 29500/320000]  base_lr: 9.1664e-05 lr: 9.1664e-06  eta: 1 day, 11:22:52  time: 0.4329  data_time: 0.0093  memory: 5150  grad_norm: 38.1964  loss: 7.1287  decode.loss_cls: 0.1482  decode.loss_mask: 0.2465  decode.loss_dice: 0.2441  decode.d0.loss_cls: 0.9708  decode.d0.loss_mask: 0.2480  decode.d0.loss_dice: 0.2461  decode.d1.loss_cls: 0.1603  decode.d1.loss_mask: 0.2409  decode.d1.loss_dice: 0.2464  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2553  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.2430  decode.d3.loss_dice: 0.2337  decode.d4.loss_cls: 0.1499  decode.d4.loss_mask: 0.2386  decode.d4.loss_dice: 0.2403  decode.d5.loss_cls: 0.1803  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2341  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2445  decode.d6.loss_dice: 0.2425  decode.d7.loss_cls: 0.1421  decode.d7.loss_mask: 0.2406  decode.d7.loss_dice: 0.2447  decode.d8.loss_cls: 0.1244  decode.d8.loss_mask: 0.2491  decode.d8.loss_dice: 0.2502
09/28 18:03:08 - mmengine - INFO - Iter(train) [ 29550/320000]  base_lr: 9.1650e-05 lr: 9.1650e-06  eta: 1 day, 11:22:28  time: 0.4334  data_time: 0.0095  memory: 5167  grad_norm: 50.0668  loss: 6.3053  decode.loss_cls: 0.0463  decode.loss_mask: 0.2510  decode.loss_dice: 0.2422  decode.d0.loss_cls: 0.6838  decode.d0.loss_mask: 0.2545  decode.d0.loss_dice: 0.2396  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.2505  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.2525  decode.d2.loss_dice: 0.2338  decode.d3.loss_cls: 0.0825  decode.d3.loss_mask: 0.2509  decode.d3.loss_dice: 0.2281  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.2177  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 0.2489  decode.d5.loss_dice: 0.2343  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.2484  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.2513  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.1049  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.2241
09/28 18:03:30 - mmengine - INFO - Iter(train) [ 29600/320000]  base_lr: 9.1635e-05 lr: 9.1635e-06  eta: 1 day, 11:22:04  time: 0.4340  data_time: 0.0092  memory: 5149  grad_norm: 65.9989  loss: 7.6607  decode.loss_cls: 0.1538  decode.loss_mask: 0.2529  decode.loss_dice: 0.3020  decode.d0.loss_cls: 0.9202  decode.d0.loss_mask: 0.2521  decode.d0.loss_dice: 0.2971  decode.d1.loss_cls: 0.1647  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.2921  decode.d2.loss_cls: 0.1724  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.2684  decode.d3.loss_cls: 0.1610  decode.d3.loss_mask: 0.2493  decode.d3.loss_dice: 0.2915  decode.d4.loss_cls: 0.1542  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.2756  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.2529  decode.d5.loss_dice: 0.2819  decode.d6.loss_cls: 0.1303  decode.d6.loss_mask: 0.2470  decode.d6.loss_dice: 0.2806  decode.d7.loss_cls: 0.1493  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.2768  decode.d8.loss_cls: 0.1359  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.2794
09/28 18:03:52 - mmengine - INFO - Iter(train) [ 29650/320000]  base_lr: 9.1621e-05 lr: 9.1621e-06  eta: 1 day, 11:21:40  time: 0.4344  data_time: 0.0093  memory: 5150  grad_norm: 29.8359  loss: 5.0693  decode.loss_cls: 0.0818  decode.loss_mask: 0.1839  decode.loss_dice: 0.1636  decode.d0.loss_cls: 0.8294  decode.d0.loss_mask: 0.1876  decode.d0.loss_dice: 0.1744  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.1881  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.1847  decode.d2.loss_dice: 0.1711  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.1839  decode.d3.loss_dice: 0.1705  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.1830  decode.d4.loss_dice: 0.1664  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.1870  decode.d5.loss_dice: 0.1671  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.1842  decode.d6.loss_dice: 0.1649  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.1844  decode.d7.loss_dice: 0.1726  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.1811  decode.d8.loss_dice: 0.1698
09/28 18:04:13 - mmengine - INFO - Iter(train) [ 29700/320000]  base_lr: 9.1607e-05 lr: 9.1607e-06  eta: 1 day, 11:21:15  time: 0.4336  data_time: 0.0093  memory: 5186  grad_norm: 45.4667  loss: 7.5402  decode.loss_cls: 0.0869  decode.loss_mask: 0.3577  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.8843  decode.d0.loss_mask: 0.4104  decode.d0.loss_dice: 0.2324  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.3824  decode.d1.loss_dice: 0.2340  decode.d2.loss_cls: 0.0880  decode.d2.loss_mask: 0.3599  decode.d2.loss_dice: 0.2155  decode.d3.loss_cls: 0.1001  decode.d3.loss_mask: 0.3580  decode.d3.loss_dice: 0.2176  decode.d4.loss_cls: 0.1009  decode.d4.loss_mask: 0.3544  decode.d4.loss_dice: 0.2184  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.3519  decode.d5.loss_dice: 0.2078  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 0.4058  decode.d6.loss_dice: 0.2312  decode.d7.loss_cls: 0.0908  decode.d7.loss_mask: 0.3561  decode.d7.loss_dice: 0.2358  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.3537  decode.d8.loss_dice: 0.2159
09/28 18:04:35 - mmengine - INFO - Iter(train) [ 29750/320000]  base_lr: 9.1593e-05 lr: 9.1593e-06  eta: 1 day, 11:20:51  time: 0.4341  data_time: 0.0092  memory: 5167  grad_norm: 166.8684  loss: 8.2439  decode.loss_cls: 0.1707  decode.loss_mask: 0.3003  decode.loss_dice: 0.2440  decode.d0.loss_cls: 0.9287  decode.d0.loss_mask: 0.3111  decode.d0.loss_dice: 0.2848  decode.d1.loss_cls: 0.2173  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.2703  decode.d2.loss_cls: 0.1594  decode.d2.loss_mask: 0.3067  decode.d2.loss_dice: 0.2783  decode.d3.loss_cls: 0.1262  decode.d3.loss_mask: 0.3063  decode.d3.loss_dice: 0.2578  decode.d4.loss_cls: 0.1556  decode.d4.loss_mask: 0.3069  decode.d4.loss_dice: 0.2526  decode.d5.loss_cls: 0.1943  decode.d5.loss_mask: 0.3106  decode.d5.loss_dice: 0.2765  decode.d6.loss_cls: 0.1646  decode.d6.loss_mask: 0.3047  decode.d6.loss_dice: 0.2733  decode.d7.loss_cls: 0.1883  decode.d7.loss_mask: 0.3048  decode.d7.loss_dice: 0.2717  decode.d8.loss_cls: 0.1936  decode.d8.loss_mask: 0.3085  decode.d8.loss_dice: 0.2722
09/28 18:04:57 - mmengine - INFO - Iter(train) [ 29800/320000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 1 day, 11:20:27  time: 0.4342  data_time: 0.0095  memory: 5167  grad_norm: 66.2718  loss: 6.3068  decode.loss_cls: 0.0487  decode.loss_mask: 0.3032  decode.loss_dice: 0.1916  decode.d0.loss_cls: 0.9167  decode.d0.loss_mask: 0.3245  decode.d0.loss_dice: 0.2031  decode.d1.loss_cls: 0.0548  decode.d1.loss_mask: 0.3052  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.3058  decode.d2.loss_dice: 0.1969  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.3031  decode.d3.loss_dice: 0.1949  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.3040  decode.d4.loss_dice: 0.1912  decode.d5.loss_cls: 0.0312  decode.d5.loss_mask: 0.3055  decode.d5.loss_dice: 0.1916  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.3042  decode.d6.loss_dice: 0.1906  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.3030  decode.d7.loss_dice: 0.1899  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.3062  decode.d8.loss_dice: 0.1906
09/28 18:05:18 - mmengine - INFO - Iter(train) [ 29850/320000]  base_lr: 9.1564e-05 lr: 9.1564e-06  eta: 1 day, 11:20:03  time: 0.4338  data_time: 0.0094  memory: 5186  grad_norm: 45.6218  loss: 6.0962  decode.loss_cls: 0.0561  decode.loss_mask: 0.2543  decode.loss_dice: 0.1986  decode.d0.loss_cls: 0.8366  decode.d0.loss_mask: 0.2660  decode.d0.loss_dice: 0.2100  decode.d1.loss_cls: 0.1101  decode.d1.loss_mask: 0.2544  decode.d1.loss_dice: 0.2016  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.2035  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.2545  decode.d3.loss_dice: 0.2028  decode.d4.loss_cls: 0.1562  decode.d4.loss_mask: 0.2535  decode.d4.loss_dice: 0.2034  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.2580  decode.d5.loss_dice: 0.1978  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.1972  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.2012  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.2599  decode.d8.loss_dice: 0.2024
09/28 18:05:40 - mmengine - INFO - Iter(train) [ 29900/320000]  base_lr: 9.1550e-05 lr: 9.1550e-06  eta: 1 day, 11:19:39  time: 0.4336  data_time: 0.0096  memory: 5167  grad_norm: 103.0468  loss: 7.5355  decode.loss_cls: 0.1747  decode.loss_mask: 0.2457  decode.loss_dice: 0.2762  decode.d0.loss_cls: 0.9770  decode.d0.loss_mask: 0.2463  decode.d0.loss_dice: 0.2528  decode.d1.loss_cls: 0.1651  decode.d1.loss_mask: 0.2449  decode.d1.loss_dice: 0.2411  decode.d2.loss_cls: 0.1224  decode.d2.loss_mask: 0.2433  decode.d2.loss_dice: 0.2365  decode.d3.loss_cls: 0.1260  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.2498  decode.d4.loss_cls: 0.2361  decode.d4.loss_mask: 0.2433  decode.d4.loss_dice: 0.2379  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 0.2400  decode.d5.loss_dice: 0.2720  decode.d6.loss_cls: 0.1690  decode.d6.loss_mask: 0.2472  decode.d6.loss_dice: 0.2500  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 0.2409  decode.d7.loss_dice: 0.2398  decode.d8.loss_cls: 0.1889  decode.d8.loss_mask: 0.2407  decode.d8.loss_dice: 0.2531
09/28 18:06:02 - mmengine - INFO - Iter(train) [ 29950/320000]  base_lr: 9.1536e-05 lr: 9.1536e-06  eta: 1 day, 11:19:15  time: 0.4338  data_time: 0.0094  memory: 5166  grad_norm: 68.5446  loss: 7.2499  decode.loss_cls: 0.0883  decode.loss_mask: 0.3002  decode.loss_dice: 0.2438  decode.d0.loss_cls: 0.9992  decode.d0.loss_mask: 0.3054  decode.d0.loss_dice: 0.2320  decode.d1.loss_cls: 0.1207  decode.d1.loss_mask: 0.3009  decode.d1.loss_dice: 0.2212  decode.d2.loss_cls: 0.0871  decode.d2.loss_mask: 0.2986  decode.d2.loss_dice: 0.2346  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.2941  decode.d3.loss_dice: 0.2521  decode.d4.loss_cls: 0.0814  decode.d4.loss_mask: 0.2998  decode.d4.loss_dice: 0.2227  decode.d5.loss_cls: 0.1215  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.2245  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.2986  decode.d6.loss_dice: 0.2239  decode.d7.loss_cls: 0.1454  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.2234  decode.d8.loss_cls: 0.1201  decode.d8.loss_mask: 0.2986  decode.d8.loss_dice: 0.2298
09/28 18:06:24 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:06:24 - mmengine - INFO - Iter(train) [ 30000/320000]  base_lr: 9.1522e-05 lr: 9.1522e-06  eta: 1 day, 11:18:51  time: 0.4331  data_time: 0.0092  memory: 5167  grad_norm: 41.3739  loss: 7.2096  decode.loss_cls: 0.1030  decode.loss_mask: 0.2923  decode.loss_dice: 0.2781  decode.d0.loss_cls: 0.8511  decode.d0.loss_mask: 0.2947  decode.d0.loss_dice: 0.2752  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.2934  decode.d1.loss_dice: 0.2723  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.2937  decode.d2.loss_dice: 0.2751  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.2846  decode.d4.loss_cls: 0.0401  decode.d4.loss_mask: 0.2936  decode.d4.loss_dice: 0.2943  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.2936  decode.d5.loss_dice: 0.2863  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.2926  decode.d6.loss_dice: 0.2911  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.2907  decode.d7.loss_dice: 0.2871  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.2927  decode.d8.loss_dice: 0.2576
09/28 18:06:45 - mmengine - INFO - Iter(train) [ 30050/320000]  base_lr: 9.1508e-05 lr: 9.1508e-06  eta: 1 day, 11:18:27  time: 0.4341  data_time: 0.0093  memory: 5186  grad_norm: 27.5918  loss: 5.3200  decode.loss_cls: 0.0083  decode.loss_mask: 0.2456  decode.loss_dice: 0.1962  decode.d0.loss_cls: 0.7971  decode.d0.loss_mask: 0.2523  decode.d0.loss_dice: 0.1913  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.2492  decode.d1.loss_dice: 0.1965  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2439  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.2474  decode.d3.loss_dice: 0.1959  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.2447  decode.d4.loss_dice: 0.1986  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.2436  decode.d5.loss_dice: 0.2002  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.2408  decode.d6.loss_dice: 0.1940  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.2457  decode.d7.loss_dice: 0.2036  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.2423  decode.d8.loss_dice: 0.1949
09/28 18:07:07 - mmengine - INFO - Iter(train) [ 30100/320000]  base_lr: 9.1493e-05 lr: 9.1493e-06  eta: 1 day, 11:18:03  time: 0.4347  data_time: 0.0094  memory: 5167  grad_norm: 55.0887  loss: 6.5483  decode.loss_cls: 0.1101  decode.loss_mask: 0.2587  decode.loss_dice: 0.1907  decode.d0.loss_cls: 1.1015  decode.d0.loss_mask: 0.2541  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.1056  decode.d2.loss_mask: 0.2606  decode.d2.loss_dice: 0.1958  decode.d3.loss_cls: 0.0942  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.1955  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.2542  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0907  decode.d5.loss_mask: 0.2593  decode.d5.loss_dice: 0.2040  decode.d6.loss_cls: 0.1151  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.1903  decode.d7.loss_cls: 0.1150  decode.d7.loss_mask: 0.2553  decode.d7.loss_dice: 0.1894  decode.d8.loss_cls: 0.1142  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.1938
09/28 18:07:29 - mmengine - INFO - Iter(train) [ 30150/320000]  base_lr: 9.1479e-05 lr: 9.1479e-06  eta: 1 day, 11:17:38  time: 0.4343  data_time: 0.0093  memory: 5186  grad_norm: 108.5116  loss: 6.0390  decode.loss_cls: 0.0685  decode.loss_mask: 0.2468  decode.loss_dice: 0.2139  decode.d0.loss_cls: 0.8611  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.2072  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.2440  decode.d1.loss_dice: 0.2053  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.2107  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.2459  decode.d3.loss_dice: 0.2114  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.2426  decode.d4.loss_dice: 0.2007  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.2427  decode.d5.loss_dice: 0.2067  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.2437  decode.d6.loss_dice: 0.2008  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.2019  decode.d8.loss_cls: 0.0845  decode.d8.loss_mask: 0.2469  decode.d8.loss_dice: 0.2028
09/28 18:07:50 - mmengine - INFO - Iter(train) [ 30200/320000]  base_lr: 9.1465e-05 lr: 9.1465e-06  eta: 1 day, 11:17:15  time: 0.4337  data_time: 0.0093  memory: 5166  grad_norm: 50.5213  loss: 7.4436  decode.loss_cls: 0.1043  decode.loss_mask: 0.3172  decode.loss_dice: 0.2382  decode.d0.loss_cls: 1.0519  decode.d0.loss_mask: 0.3128  decode.d0.loss_dice: 0.2554  decode.d1.loss_cls: 0.0449  decode.d1.loss_mask: 0.3179  decode.d1.loss_dice: 0.2371  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.3158  decode.d2.loss_dice: 0.2479  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.3118  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.1164  decode.d4.loss_mask: 0.3177  decode.d4.loss_dice: 0.2458  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.3126  decode.d5.loss_dice: 0.2483  decode.d6.loss_cls: 0.1248  decode.d6.loss_mask: 0.3117  decode.d6.loss_dice: 0.2384  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.3139  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.0989  decode.d8.loss_mask: 0.3137  decode.d8.loss_dice: 0.2441
09/28 18:08:12 - mmengine - INFO - Iter(train) [ 30250/320000]  base_lr: 9.1451e-05 lr: 9.1451e-06  eta: 1 day, 11:16:50  time: 0.4329  data_time: 0.0094  memory: 5186  grad_norm: 40.9323  loss: 5.6186  decode.loss_cls: 0.0513  decode.loss_mask: 0.2415  decode.loss_dice: 0.1841  decode.d0.loss_cls: 0.7871  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.1916  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.2348  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.0867  decode.d2.loss_mask: 0.2424  decode.d2.loss_dice: 0.1902  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.2431  decode.d3.loss_dice: 0.1961  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.2683  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.2421  decode.d5.loss_dice: 0.1853  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.2509  decode.d6.loss_dice: 0.1895  decode.d7.loss_cls: 0.0342  decode.d7.loss_mask: 0.2682  decode.d7.loss_dice: 0.2030  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.1866
09/28 18:08:34 - mmengine - INFO - Iter(train) [ 30300/320000]  base_lr: 9.1437e-05 lr: 9.1437e-06  eta: 1 day, 11:16:26  time: 0.4333  data_time: 0.0093  memory: 5167  grad_norm: 69.4123  loss: 6.4621  decode.loss_cls: 0.0802  decode.loss_mask: 0.2235  decode.loss_dice: 0.2175  decode.d0.loss_cls: 0.9585  decode.d0.loss_mask: 0.2290  decode.d0.loss_dice: 0.2453  decode.d1.loss_cls: 0.1075  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2333  decode.d2.loss_cls: 0.0924  decode.d2.loss_mask: 0.2858  decode.d2.loss_dice: 0.2360  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.2279  decode.d3.loss_dice: 0.2248  decode.d4.loss_cls: 0.0995  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.2314  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.2199  decode.d5.loss_dice: 0.2279  decode.d6.loss_cls: 0.1143  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.1048  decode.d7.loss_mask: 0.2155  decode.d7.loss_dice: 0.2250  decode.d8.loss_cls: 0.1576  decode.d8.loss_mask: 0.2167  decode.d8.loss_dice: 0.2235
09/28 18:08:55 - mmengine - INFO - Iter(train) [ 30350/320000]  base_lr: 9.1422e-05 lr: 9.1422e-06  eta: 1 day, 11:16:02  time: 0.4344  data_time: 0.0093  memory: 5166  grad_norm: 63.4424  loss: 6.5020  decode.loss_cls: 0.1101  decode.loss_mask: 0.2063  decode.loss_dice: 0.2358  decode.d0.loss_cls: 1.0771  decode.d0.loss_mask: 0.2049  decode.d0.loss_dice: 0.2515  decode.d1.loss_cls: 0.1609  decode.d1.loss_mask: 0.2024  decode.d1.loss_dice: 0.2223  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.2031  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.0940  decode.d3.loss_mask: 0.2016  decode.d3.loss_dice: 0.2315  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.2039  decode.d4.loss_dice: 0.2409  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.2106  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.2061  decode.d6.loss_dice: 0.2382  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.2043  decode.d7.loss_dice: 0.2527  decode.d8.loss_cls: 0.1101  decode.d8.loss_mask: 0.2023  decode.d8.loss_dice: 0.2248
09/28 18:09:17 - mmengine - INFO - Iter(train) [ 30400/320000]  base_lr: 9.1408e-05 lr: 9.1408e-06  eta: 1 day, 11:15:38  time: 0.4329  data_time: 0.0095  memory: 5167  grad_norm: 38.0184  loss: 5.3861  decode.loss_cls: 0.0708  decode.loss_mask: 0.2262  decode.loss_dice: 0.1661  decode.d0.loss_cls: 0.9088  decode.d0.loss_mask: 0.2305  decode.d0.loss_dice: 0.1828  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.1750  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.1750  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.1689  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.1691  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.2297  decode.d5.loss_dice: 0.1705  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.2301  decode.d6.loss_dice: 0.1724  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.2249  decode.d7.loss_dice: 0.1708  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.2230  decode.d8.loss_dice: 0.1645
09/28 18:09:39 - mmengine - INFO - Iter(train) [ 30450/320000]  base_lr: 9.1394e-05 lr: 9.1394e-06  eta: 1 day, 11:15:14  time: 0.4332  data_time: 0.0095  memory: 5167  grad_norm: 172.0623  loss: 6.0080  decode.loss_cls: 0.0892  decode.loss_mask: 0.2154  decode.loss_dice: 0.1858  decode.d0.loss_cls: 0.9249  decode.d0.loss_mask: 0.2163  decode.d0.loss_dice: 0.1954  decode.d1.loss_cls: 0.1634  decode.d1.loss_mask: 0.2188  decode.d1.loss_dice: 0.1887  decode.d2.loss_cls: 0.1107  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.1857  decode.d3.loss_cls: 0.1068  decode.d3.loss_mask: 0.2042  decode.d3.loss_dice: 0.1709  decode.d4.loss_cls: 0.1041  decode.d4.loss_mask: 0.2123  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 0.2163  decode.d5.loss_dice: 0.1850  decode.d6.loss_cls: 0.1075  decode.d6.loss_mask: 0.2466  decode.d6.loss_dice: 0.1965  decode.d7.loss_cls: 0.1124  decode.d7.loss_mask: 0.2154  decode.d7.loss_dice: 0.1881  decode.d8.loss_cls: 0.0828  decode.d8.loss_mask: 0.2545  decode.d8.loss_dice: 0.2061
09/28 18:10:00 - mmengine - INFO - Iter(train) [ 30500/320000]  base_lr: 9.1380e-05 lr: 9.1380e-06  eta: 1 day, 11:14:49  time: 0.4344  data_time: 0.0092  memory: 5167  grad_norm: 123.9773  loss: 5.8457  decode.loss_cls: 0.0544  decode.loss_mask: 0.2549  decode.loss_dice: 0.2164  decode.d0.loss_cls: 0.7984  decode.d0.loss_mask: 0.2580  decode.d0.loss_dice: 0.2056  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.2561  decode.d1.loss_dice: 0.2030  decode.d2.loss_cls: 0.0407  decode.d2.loss_mask: 0.2615  decode.d2.loss_dice: 0.1984  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.2613  decode.d3.loss_dice: 0.2033  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.2554  decode.d4.loss_dice: 0.2118  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.2504  decode.d5.loss_dice: 0.2129  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.2461  decode.d6.loss_dice: 0.2051  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.2511  decode.d7.loss_dice: 0.2104  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.2510  decode.d8.loss_dice: 0.2176
09/28 18:10:22 - mmengine - INFO - Iter(train) [ 30550/320000]  base_lr: 9.1366e-05 lr: 9.1366e-06  eta: 1 day, 11:14:26  time: 0.4348  data_time: 0.0094  memory: 5186  grad_norm: 31.6539  loss: 7.5295  decode.loss_cls: 0.0957  decode.loss_mask: 0.4413  decode.loss_dice: 0.2268  decode.d0.loss_cls: 0.9130  decode.d0.loss_mask: 0.3647  decode.d0.loss_dice: 0.2094  decode.d1.loss_cls: 0.1302  decode.d1.loss_mask: 0.3626  decode.d1.loss_dice: 0.2224  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.4232  decode.d2.loss_dice: 0.2075  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.4203  decode.d3.loss_dice: 0.2041  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.4181  decode.d4.loss_dice: 0.2060  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.3573  decode.d5.loss_dice: 0.2010  decode.d6.loss_cls: 0.1153  decode.d6.loss_mask: 0.3490  decode.d6.loss_dice: 0.2052  decode.d7.loss_cls: 0.1099  decode.d7.loss_mask: 0.3440  decode.d7.loss_dice: 0.2079  decode.d8.loss_cls: 0.1053  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.2055
09/28 18:10:44 - mmengine - INFO - Iter(train) [ 30600/320000]  base_lr: 9.1351e-05 lr: 9.1351e-06  eta: 1 day, 11:14:03  time: 0.4355  data_time: 0.0093  memory: 5186  grad_norm: 92.4850  loss: 8.1307  decode.loss_cls: 0.2007  decode.loss_mask: 0.2327  decode.loss_dice: 0.2439  decode.d0.loss_cls: 1.1262  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.2404  decode.d1.loss_cls: 0.2991  decode.d1.loss_mask: 0.2337  decode.d1.loss_dice: 0.2417  decode.d2.loss_cls: 0.3074  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2371  decode.d3.loss_cls: 0.2655  decode.d3.loss_mask: 0.2396  decode.d3.loss_dice: 0.2394  decode.d4.loss_cls: 0.2284  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.2416  decode.d5.loss_cls: 0.2216  decode.d5.loss_mask: 0.2315  decode.d5.loss_dice: 0.2474  decode.d6.loss_cls: 0.2850  decode.d6.loss_mask: 0.2318  decode.d6.loss_dice: 0.2611  decode.d7.loss_cls: 0.1804  decode.d7.loss_mask: 0.2341  decode.d7.loss_dice: 0.2477  decode.d8.loss_cls: 0.2302  decode.d8.loss_mask: 0.2316  decode.d8.loss_dice: 0.2399
09/28 18:11:06 - mmengine - INFO - Iter(train) [ 30650/320000]  base_lr: 9.1337e-05 lr: 9.1337e-06  eta: 1 day, 11:13:39  time: 0.4341  data_time: 0.0092  memory: 5186  grad_norm: 44.3208  loss: 6.7710  decode.loss_cls: 0.0631  decode.loss_mask: 0.2544  decode.loss_dice: 0.2569  decode.d0.loss_cls: 0.8837  decode.d0.loss_mask: 0.2658  decode.d0.loss_dice: 0.2717  decode.d1.loss_cls: 0.1193  decode.d1.loss_mask: 0.2628  decode.d1.loss_dice: 0.2646  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.2640  decode.d2.loss_dice: 0.2637  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.2639  decode.d3.loss_dice: 0.2557  decode.d4.loss_cls: 0.0993  decode.d4.loss_mask: 0.2577  decode.d4.loss_dice: 0.2727  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.2603  decode.d5.loss_dice: 0.2729  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.2575  decode.d6.loss_dice: 0.2659  decode.d7.loss_cls: 0.0318  decode.d7.loss_mask: 0.2609  decode.d7.loss_dice: 0.2642  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.2519  decode.d8.loss_dice: 0.2665
09/28 18:11:27 - mmengine - INFO - Iter(train) [ 30700/320000]  base_lr: 9.1323e-05 lr: 9.1323e-06  eta: 1 day, 11:13:15  time: 0.4352  data_time: 0.0095  memory: 5167  grad_norm: 49.4389  loss: 5.3585  decode.loss_cls: 0.0660  decode.loss_mask: 0.2090  decode.loss_dice: 0.1860  decode.d0.loss_cls: 0.7461  decode.d0.loss_mask: 0.2100  decode.d0.loss_dice: 0.1870  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.2162  decode.d1.loss_dice: 0.1922  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.1911  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.2121  decode.d3.loss_dice: 0.1848  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.2084  decode.d4.loss_dice: 0.1844  decode.d5.loss_cls: 0.1119  decode.d5.loss_mask: 0.2043  decode.d5.loss_dice: 0.1838  decode.d6.loss_cls: 0.0931  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.1859  decode.d7.loss_cls: 0.0758  decode.d7.loss_mask: 0.2065  decode.d7.loss_dice: 0.1821  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.2078  decode.d8.loss_dice: 0.1879
09/28 18:11:49 - mmengine - INFO - Iter(train) [ 30750/320000]  base_lr: 9.1309e-05 lr: 9.1309e-06  eta: 1 day, 11:12:52  time: 0.4350  data_time: 0.0093  memory: 5166  grad_norm: 76.7207  loss: 5.3445  decode.loss_cls: 0.0060  decode.loss_mask: 0.2451  decode.loss_dice: 0.1959  decode.d0.loss_cls: 0.8464  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.2037  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.2472  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.1976  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.2497  decode.d3.loss_dice: 0.1976  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.2466  decode.d4.loss_dice: 0.1939  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.1939  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.1933  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.2466  decode.d7.loss_dice: 0.1952  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.2459  decode.d8.loss_dice: 0.1936
09/28 18:12:11 - mmengine - INFO - Iter(train) [ 30800/320000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 1 day, 11:12:28  time: 0.4335  data_time: 0.0095  memory: 5186  grad_norm: 107.4338  loss: 6.3391  decode.loss_cls: 0.0933  decode.loss_mask: 0.2645  decode.loss_dice: 0.2006  decode.d0.loss_cls: 0.8800  decode.d0.loss_mask: 0.2759  decode.d0.loss_dice: 0.2087  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.2562  decode.d1.loss_dice: 0.1937  decode.d2.loss_cls: 0.0798  decode.d2.loss_mask: 0.2564  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.1921  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.1947  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.2535  decode.d5.loss_dice: 0.1933  decode.d6.loss_cls: 0.1563  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.1852  decode.d7.loss_cls: 0.1467  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.1890  decode.d8.loss_cls: 0.1043  decode.d8.loss_mask: 0.2612  decode.d8.loss_dice: 0.1919
09/28 18:12:33 - mmengine - INFO - Iter(train) [ 30850/320000]  base_lr: 9.1280e-05 lr: 9.1280e-06  eta: 1 day, 11:12:05  time: 0.4367  data_time: 0.0094  memory: 5167  grad_norm: 77.8731  loss: 8.9099  decode.loss_cls: 0.3078  decode.loss_mask: 0.2640  decode.loss_dice: 0.2383  decode.d0.loss_cls: 0.9452  decode.d0.loss_mask: 0.2666  decode.d0.loss_dice: 0.2975  decode.d1.loss_cls: 0.2999  decode.d1.loss_mask: 0.2608  decode.d1.loss_dice: 0.2502  decode.d2.loss_cls: 0.3160  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.2402  decode.d3.loss_cls: 0.3155  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.2637  decode.d4.loss_cls: 0.2944  decode.d4.loss_mask: 0.2719  decode.d4.loss_dice: 0.2576  decode.d5.loss_cls: 0.2891  decode.d5.loss_mask: 0.2660  decode.d5.loss_dice: 0.2404  decode.d6.loss_cls: 0.3133  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.2381  decode.d7.loss_cls: 0.3501  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.2326  decode.d8.loss_cls: 0.3599  decode.d8.loss_mask: 0.2601  decode.d8.loss_dice: 0.2364
09/28 18:12:55 - mmengine - INFO - Iter(train) [ 30900/320000]  base_lr: 9.1266e-05 lr: 9.1266e-06  eta: 1 day, 11:11:42  time: 0.4380  data_time: 0.0095  memory: 5186  grad_norm: 300.8021  loss: 7.8168  decode.loss_cls: 0.0866  decode.loss_mask: 0.2970  decode.loss_dice: 0.2492  decode.d0.loss_cls: 1.1224  decode.d0.loss_mask: 0.3016  decode.d0.loss_dice: 0.2534  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 0.3240  decode.d1.loss_dice: 0.2512  decode.d2.loss_cls: 0.1592  decode.d2.loss_mask: 0.3134  decode.d2.loss_dice: 0.2471  decode.d3.loss_cls: 0.1304  decode.d3.loss_mask: 0.3125  decode.d3.loss_dice: 0.2456  decode.d4.loss_cls: 0.1103  decode.d4.loss_mask: 0.3025  decode.d4.loss_dice: 0.2480  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 0.3145  decode.d5.loss_dice: 0.2444  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.3092  decode.d6.loss_dice: 0.2553  decode.d7.loss_cls: 0.1056  decode.d7.loss_mask: 0.3116  decode.d7.loss_dice: 0.2482  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.3007  decode.d8.loss_dice: 0.2560
09/28 18:13:16 - mmengine - INFO - Iter(train) [ 30950/320000]  base_lr: 9.1252e-05 lr: 9.1252e-06  eta: 1 day, 11:11:19  time: 0.4361  data_time: 0.0093  memory: 5166  grad_norm: 58.4176  loss: 5.5640  decode.loss_cls: 0.0434  decode.loss_mask: 0.1969  decode.loss_dice: 0.1958  decode.d0.loss_cls: 1.1310  decode.d0.loss_mask: 0.2056  decode.d0.loss_dice: 0.2224  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.1966  decode.d1.loss_dice: 0.1965  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.1956  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0414  decode.d3.loss_mask: 0.1958  decode.d3.loss_dice: 0.2039  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 0.1980  decode.d4.loss_dice: 0.2118  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.1969  decode.d5.loss_dice: 0.2057  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.1958  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2007  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.1943  decode.d8.loss_dice: 0.2038
09/28 18:13:38 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:13:38 - mmengine - INFO - Iter(train) [ 31000/320000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 1 day, 11:10:58  time: 0.4356  data_time: 0.0093  memory: 5150  grad_norm: 58.5566  loss: 6.5190  decode.loss_cls: 0.1746  decode.loss_mask: 0.2123  decode.loss_dice: 0.1938  decode.d0.loss_cls: 0.8335  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.2239  decode.d1.loss_cls: 0.1204  decode.d1.loss_mask: 0.2165  decode.d1.loss_dice: 0.2254  decode.d2.loss_cls: 0.1826  decode.d2.loss_mask: 0.2134  decode.d2.loss_dice: 0.2103  decode.d3.loss_cls: 0.1152  decode.d3.loss_mask: 0.2141  decode.d3.loss_dice: 0.2064  decode.d4.loss_cls: 0.1776  decode.d4.loss_mask: 0.2121  decode.d4.loss_dice: 0.2006  decode.d5.loss_cls: 0.1281  decode.d5.loss_mask: 0.2125  decode.d5.loss_dice: 0.2322  decode.d6.loss_cls: 0.1844  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.2021  decode.d7.loss_cls: 0.1739  decode.d7.loss_mask: 0.2106  decode.d7.loss_dice: 0.2103  decode.d8.loss_cls: 0.1768  decode.d8.loss_mask: 0.2128  decode.d8.loss_dice: 0.2094
09/28 18:14:00 - mmengine - INFO - Iter(train) [ 31050/320000]  base_lr: 9.1223e-05 lr: 9.1223e-06  eta: 1 day, 11:10:35  time: 0.4360  data_time: 0.0094  memory: 5166  grad_norm: 44.2100  loss: 5.9677  decode.loss_cls: 0.0275  decode.loss_mask: 0.2710  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.8514  decode.d0.loss_mask: 0.2739  decode.d0.loss_dice: 0.2087  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.2715  decode.d1.loss_dice: 0.2092  decode.d2.loss_cls: 0.0413  decode.d2.loss_mask: 0.2714  decode.d2.loss_dice: 0.2143  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.2710  decode.d3.loss_dice: 0.2069  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.2124  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.2751  decode.d5.loss_dice: 0.2118  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 0.2738  decode.d6.loss_dice: 0.2132  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 0.2716  decode.d7.loss_dice: 0.2142  decode.d8.loss_cls: 0.0220  decode.d8.loss_mask: 0.2686  decode.d8.loss_dice: 0.2105
09/28 18:14:22 - mmengine - INFO - Iter(train) [ 31100/320000]  base_lr: 9.1209e-05 lr: 9.1209e-06  eta: 1 day, 11:10:13  time: 0.4362  data_time: 0.0095  memory: 5150  grad_norm: 63.3880  loss: 7.2491  decode.loss_cls: 0.1460  decode.loss_mask: 0.2484  decode.loss_dice: 0.2319  decode.d0.loss_cls: 0.8579  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.2669  decode.d1.loss_cls: 0.2613  decode.d1.loss_mask: 0.2477  decode.d1.loss_dice: 0.2289  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.2317  decode.d3.loss_cls: 0.1693  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2357  decode.d4.loss_cls: 0.1296  decode.d4.loss_mask: 0.2516  decode.d4.loss_dice: 0.2502  decode.d5.loss_cls: 0.1805  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.2365  decode.d6.loss_cls: 0.1355  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.1649  decode.d7.loss_mask: 0.2495  decode.d7.loss_dice: 0.2317  decode.d8.loss_cls: 0.1834  decode.d8.loss_mask: 0.2489  decode.d8.loss_dice: 0.2325
09/28 18:14:44 - mmengine - INFO - Iter(train) [ 31150/320000]  base_lr: 9.1195e-05 lr: 9.1195e-06  eta: 1 day, 11:09:50  time: 0.4364  data_time: 0.0093  memory: 5150  grad_norm: 29.6444  loss: 6.1540  decode.loss_cls: 0.0452  decode.loss_mask: 0.2184  decode.loss_dice: 0.2315  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.2197  decode.d0.loss_dice: 0.2690  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.2520  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.2169  decode.d2.loss_dice: 0.2487  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.2177  decode.d3.loss_dice: 0.2604  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.2186  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.0980  decode.d5.loss_mask: 0.2166  decode.d5.loss_dice: 0.2425  decode.d6.loss_cls: 0.0671  decode.d6.loss_mask: 0.2221  decode.d6.loss_dice: 0.2349  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.2222  decode.d7.loss_dice: 0.2569  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.2184  decode.d8.loss_dice: 0.2179
09/28 18:15:06 - mmengine - INFO - Iter(train) [ 31200/320000]  base_lr: 9.1181e-05 lr: 9.1181e-06  eta: 1 day, 11:09:27  time: 0.4363  data_time: 0.0094  memory: 5150  grad_norm: 74.7831  loss: 7.3762  decode.loss_cls: 0.1677  decode.loss_mask: 0.2528  decode.loss_dice: 0.2412  decode.d0.loss_cls: 0.9783  decode.d0.loss_mask: 0.2635  decode.d0.loss_dice: 0.2954  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 0.2536  decode.d1.loss_dice: 0.2541  decode.d2.loss_cls: 0.1460  decode.d2.loss_mask: 0.2538  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1685  decode.d4.loss_mask: 0.2545  decode.d4.loss_dice: 0.2639  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 0.2617  decode.d5.loss_dice: 0.2632  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.2561  decode.d6.loss_dice: 0.2542  decode.d7.loss_cls: 0.1483  decode.d7.loss_mask: 0.2532  decode.d7.loss_dice: 0.2443  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.2590  decode.d8.loss_dice: 0.2505
09/28 18:15:27 - mmengine - INFO - Iter(train) [ 31250/320000]  base_lr: 9.1167e-05 lr: 9.1167e-06  eta: 1 day, 11:09:03  time: 0.4343  data_time: 0.0094  memory: 5186  grad_norm: 107.5400  loss: 7.0709  decode.loss_cls: 0.1116  decode.loss_mask: 0.2598  decode.loss_dice: 0.2328  decode.d0.loss_cls: 0.9504  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.2206  decode.d1.loss_cls: 0.1462  decode.d1.loss_mask: 0.2665  decode.d1.loss_dice: 0.2188  decode.d2.loss_cls: 0.1795  decode.d2.loss_mask: 0.2608  decode.d2.loss_dice: 0.2180  decode.d3.loss_cls: 0.1675  decode.d3.loss_mask: 0.2563  decode.d3.loss_dice: 0.2298  decode.d4.loss_cls: 0.1440  decode.d4.loss_mask: 0.2583  decode.d4.loss_dice: 0.2049  decode.d5.loss_cls: 0.1513  decode.d5.loss_mask: 0.2607  decode.d5.loss_dice: 0.2075  decode.d6.loss_cls: 0.1506  decode.d6.loss_mask: 0.2611  decode.d6.loss_dice: 0.2113  decode.d7.loss_cls: 0.1171  decode.d7.loss_mask: 0.2638  decode.d7.loss_dice: 0.2261  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 0.2588  decode.d8.loss_dice: 0.2165
09/28 18:15:49 - mmengine - INFO - Iter(train) [ 31300/320000]  base_lr: 9.1152e-05 lr: 9.1152e-06  eta: 1 day, 11:08:39  time: 0.4333  data_time: 0.0094  memory: 5150  grad_norm: 103.0611  loss: 5.6442  decode.loss_cls: 0.0408  decode.loss_mask: 0.2309  decode.loss_dice: 0.2073  decode.d0.loss_cls: 0.8547  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 0.2308  decode.d1.loss_dice: 0.2056  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.2086  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.2335  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.2317  decode.d5.loss_dice: 0.2100  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.2298  decode.d6.loss_dice: 0.2041  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.2272  decode.d7.loss_dice: 0.2092  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.2314  decode.d8.loss_dice: 0.2071
09/28 18:16:11 - mmengine - INFO - Iter(train) [ 31350/320000]  base_lr: 9.1138e-05 lr: 9.1138e-06  eta: 1 day, 11:08:15  time: 0.4343  data_time: 0.0095  memory: 5167  grad_norm: 49.5360  loss: 5.4833  decode.loss_cls: 0.0738  decode.loss_mask: 0.2359  decode.loss_dice: 0.1950  decode.d0.loss_cls: 0.7448  decode.d0.loss_mask: 0.2584  decode.d0.loss_dice: 0.1969  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.2351  decode.d1.loss_dice: 0.1909  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.2377  decode.d3.loss_dice: 0.1971  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.2364  decode.d4.loss_dice: 0.2015  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.2423  decode.d5.loss_dice: 0.2019  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.2375  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.2382  decode.d8.loss_dice: 0.1903
09/28 18:16:32 - mmengine - INFO - Iter(train) [ 31400/320000]  base_lr: 9.1124e-05 lr: 9.1124e-06  eta: 1 day, 11:07:51  time: 0.4333  data_time: 0.0094  memory: 5186  grad_norm: 26.6573  loss: 7.0956  decode.loss_cls: 0.0620  decode.loss_mask: 0.3400  decode.loss_dice: 0.2333  decode.d0.loss_cls: 1.0015  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2267  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.2190  decode.d3.loss_cls: 0.1278  decode.d3.loss_mask: 0.2641  decode.d3.loss_dice: 0.2201  decode.d4.loss_cls: 0.1678  decode.d4.loss_mask: 0.2740  decode.d4.loss_dice: 0.2417  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.3458  decode.d5.loss_dice: 0.2352  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 0.2613  decode.d6.loss_dice: 0.2257  decode.d7.loss_cls: 0.1373  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.2188  decode.d8.loss_cls: 0.1311  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.2201
09/28 18:16:54 - mmengine - INFO - Iter(train) [ 31450/320000]  base_lr: 9.1110e-05 lr: 9.1110e-06  eta: 1 day, 11:07:29  time: 0.4368  data_time: 0.0095  memory: 5167  grad_norm: 68.9722  loss: 7.0151  decode.loss_cls: 0.1236  decode.loss_mask: 0.2324  decode.loss_dice: 0.2249  decode.d0.loss_cls: 1.0228  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2747  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.1310  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.2545  decode.d3.loss_cls: 0.1318  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.2378  decode.d4.loss_cls: 0.1493  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2335  decode.d5.loss_cls: 0.1448  decode.d5.loss_mask: 0.2328  decode.d5.loss_dice: 0.2400  decode.d6.loss_cls: 0.1072  decode.d6.loss_mask: 0.2348  decode.d6.loss_dice: 0.2338  decode.d7.loss_cls: 0.1550  decode.d7.loss_mask: 0.2408  decode.d7.loss_dice: 0.2255  decode.d8.loss_cls: 0.1152  decode.d8.loss_mask: 0.2366  decode.d8.loss_dice: 0.2381
09/28 18:17:16 - mmengine - INFO - Iter(train) [ 31500/320000]  base_lr: 9.1096e-05 lr: 9.1096e-06  eta: 1 day, 11:07:06  time: 0.4367  data_time: 0.0093  memory: 5167  grad_norm: 28.8985  loss: 4.8706  decode.loss_cls: 0.0102  decode.loss_mask: 0.1969  decode.loss_dice: 0.1754  decode.d0.loss_cls: 0.7788  decode.d0.loss_mask: 0.1955  decode.d0.loss_dice: 0.1951  decode.d1.loss_cls: 0.1104  decode.d1.loss_mask: 0.1914  decode.d1.loss_dice: 0.1815  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.1941  decode.d2.loss_dice: 0.1750  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.1994  decode.d3.loss_dice: 0.1824  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.1974  decode.d4.loss_dice: 0.1788  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.1961  decode.d5.loss_dice: 0.1783  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.1949  decode.d6.loss_dice: 0.1739  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.1935  decode.d7.loss_dice: 0.1766  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.1939  decode.d8.loss_dice: 0.1723
09/28 18:17:38 - mmengine - INFO - Iter(train) [ 31550/320000]  base_lr: 9.1081e-05 lr: 9.1081e-06  eta: 1 day, 11:06:43  time: 0.4357  data_time: 0.0092  memory: 5149  grad_norm: 35.4718  loss: 5.0648  decode.loss_cls: 0.0450  decode.loss_mask: 0.2079  decode.loss_dice: 0.1690  decode.d0.loss_cls: 0.9105  decode.d0.loss_mask: 0.2117  decode.d0.loss_dice: 0.1840  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.1655  decode.d2.loss_cls: 0.0410  decode.d2.loss_mask: 0.2068  decode.d2.loss_dice: 0.1590  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.2027  decode.d3.loss_dice: 0.1571  decode.d4.loss_cls: 0.0850  decode.d4.loss_mask: 0.2052  decode.d4.loss_dice: 0.1617  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.2047  decode.d5.loss_dice: 0.1606  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.2046  decode.d6.loss_dice: 0.1620  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.2058  decode.d7.loss_dice: 0.1625  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 0.2034  decode.d8.loss_dice: 0.1618
09/28 18:18:00 - mmengine - INFO - Iter(train) [ 31600/320000]  base_lr: 9.1067e-05 lr: 9.1067e-06  eta: 1 day, 11:06:20  time: 0.4372  data_time: 0.0095  memory: 5167  grad_norm: 55.2250  loss: 7.0766  decode.loss_cls: 0.0253  decode.loss_mask: 0.3351  decode.loss_dice: 0.2489  decode.d0.loss_cls: 1.0578  decode.d0.loss_mask: 0.3342  decode.d0.loss_dice: 0.2406  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.3281  decode.d1.loss_dice: 0.2409  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.2387  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.3232  decode.d3.loss_dice: 0.2596  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.3202  decode.d4.loss_dice: 0.2583  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.3203  decode.d5.loss_dice: 0.2478  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.3200  decode.d6.loss_dice: 0.2420  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.3314  decode.d7.loss_dice: 0.2786  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.3178  decode.d8.loss_dice: 0.2310
09/28 18:18:21 - mmengine - INFO - Iter(train) [ 31650/320000]  base_lr: 9.1053e-05 lr: 9.1053e-06  eta: 1 day, 11:05:57  time: 0.4363  data_time: 0.0093  memory: 5167  grad_norm: 59.7408  loss: 6.7935  decode.loss_cls: 0.1006  decode.loss_mask: 0.2540  decode.loss_dice: 0.2463  decode.d0.loss_cls: 0.9194  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2126  decode.d1.loss_cls: 0.1496  decode.d1.loss_mask: 0.2336  decode.d1.loss_dice: 0.2158  decode.d2.loss_cls: 0.1303  decode.d2.loss_mask: 0.2366  decode.d2.loss_dice: 0.2032  decode.d3.loss_cls: 0.1606  decode.d3.loss_mask: 0.2359  decode.d3.loss_dice: 0.2046  decode.d4.loss_cls: 0.1185  decode.d4.loss_mask: 0.2377  decode.d4.loss_dice: 0.2260  decode.d5.loss_cls: 0.1643  decode.d5.loss_mask: 0.2406  decode.d5.loss_dice: 0.2384  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.2384  decode.d6.loss_dice: 0.2143  decode.d7.loss_cls: 0.1439  decode.d7.loss_mask: 0.2437  decode.d7.loss_dice: 0.2430  decode.d8.loss_cls: 0.1393  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.2359
09/28 18:18:43 - mmengine - INFO - Iter(train) [ 31700/320000]  base_lr: 9.1039e-05 lr: 9.1039e-06  eta: 1 day, 11:05:34  time: 0.4367  data_time: 0.0092  memory: 5167  grad_norm: 42.1341  loss: 6.4952  decode.loss_cls: 0.1421  decode.loss_mask: 0.1980  decode.loss_dice: 0.2107  decode.d0.loss_cls: 0.9727  decode.d0.loss_mask: 0.2068  decode.d0.loss_dice: 0.2362  decode.d1.loss_cls: 0.2087  decode.d1.loss_mask: 0.1988  decode.d1.loss_dice: 0.2241  decode.d2.loss_cls: 0.1384  decode.d2.loss_mask: 0.2003  decode.d2.loss_dice: 0.2333  decode.d3.loss_cls: 0.1395  decode.d3.loss_mask: 0.1979  decode.d3.loss_dice: 0.2129  decode.d4.loss_cls: 0.1100  decode.d4.loss_mask: 0.1987  decode.d4.loss_dice: 0.2212  decode.d5.loss_cls: 0.1171  decode.d5.loss_mask: 0.1985  decode.d5.loss_dice: 0.2258  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 0.2017  decode.d6.loss_dice: 0.2210  decode.d7.loss_cls: 0.1138  decode.d7.loss_mask: 0.1993  decode.d7.loss_dice: 0.2236  decode.d8.loss_cls: 0.2012  decode.d8.loss_mask: 0.2001  decode.d8.loss_dice: 0.2122
09/28 18:19:05 - mmengine - INFO - Iter(train) [ 31750/320000]  base_lr: 9.1025e-05 lr: 9.1025e-06  eta: 1 day, 11:05:12  time: 0.4366  data_time: 0.0094  memory: 5166  grad_norm: 40.9122  loss: 5.4491  decode.loss_cls: 0.1166  decode.loss_mask: 0.2106  decode.loss_dice: 0.1505  decode.d0.loss_cls: 0.9035  decode.d0.loss_mask: 0.2194  decode.d0.loss_dice: 0.1831  decode.d1.loss_cls: 0.1699  decode.d1.loss_mask: 0.2124  decode.d1.loss_dice: 0.1469  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.2112  decode.d2.loss_dice: 0.1478  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.2107  decode.d3.loss_dice: 0.1454  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.2135  decode.d4.loss_dice: 0.1501  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.2112  decode.d5.loss_dice: 0.1491  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.2123  decode.d6.loss_dice: 0.1517  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2113  decode.d7.loss_dice: 0.1522  decode.d8.loss_cls: 0.1032  decode.d8.loss_mask: 0.2104  decode.d8.loss_dice: 0.1508
09/28 18:19:27 - mmengine - INFO - Iter(train) [ 31800/320000]  base_lr: 9.1010e-05 lr: 9.1010e-06  eta: 1 day, 11:04:49  time: 0.4362  data_time: 0.0094  memory: 5167  grad_norm: 91.3927  loss: 8.5583  decode.loss_cls: 0.1399  decode.loss_mask: 0.3787  decode.loss_dice: 0.2594  decode.d0.loss_cls: 0.7226  decode.d0.loss_mask: 0.3948  decode.d0.loss_dice: 0.3010  decode.d1.loss_cls: 0.1431  decode.d1.loss_mask: 0.3777  decode.d1.loss_dice: 0.2631  decode.d2.loss_cls: 0.1717  decode.d2.loss_mask: 0.3817  decode.d2.loss_dice: 0.2650  decode.d3.loss_cls: 0.1462  decode.d3.loss_mask: 0.3870  decode.d3.loss_dice: 0.2673  decode.d4.loss_cls: 0.1602  decode.d4.loss_mask: 0.3795  decode.d4.loss_dice: 0.2671  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 0.3773  decode.d5.loss_dice: 0.2704  decode.d6.loss_cls: 0.1549  decode.d6.loss_mask: 0.3851  decode.d6.loss_dice: 0.2598  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 0.3777  decode.d7.loss_dice: 0.2610  decode.d8.loss_cls: 0.1524  decode.d8.loss_mask: 0.3762  decode.d8.loss_dice: 0.2560
09/28 18:19:49 - mmengine - INFO - Iter(train) [ 31850/320000]  base_lr: 9.0996e-05 lr: 9.0996e-06  eta: 1 day, 11:04:27  time: 0.4354  data_time: 0.0094  memory: 5186  grad_norm: 84.0438  loss: 7.2631  decode.loss_cls: 0.1214  decode.loss_mask: 0.2673  decode.loss_dice: 0.2346  decode.d0.loss_cls: 0.8116  decode.d0.loss_mask: 0.2805  decode.d0.loss_dice: 0.2829  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 0.2735  decode.d1.loss_dice: 0.2529  decode.d2.loss_cls: 0.1524  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2607  decode.d3.loss_cls: 0.0769  decode.d3.loss_mask: 0.2697  decode.d3.loss_dice: 0.2561  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2679  decode.d6.loss_cls: 0.1388  decode.d6.loss_mask: 0.2654  decode.d6.loss_dice: 0.2505  decode.d7.loss_cls: 0.1749  decode.d7.loss_mask: 0.2649  decode.d7.loss_dice: 0.2419  decode.d8.loss_cls: 0.1242  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.2756
09/28 18:20:11 - mmengine - INFO - Iter(train) [ 31900/320000]  base_lr: 9.0982e-05 lr: 9.0982e-06  eta: 1 day, 11:04:04  time: 0.4358  data_time: 0.0093  memory: 5186  grad_norm: 75.0543  loss: 9.0467  decode.loss_cls: 0.2595  decode.loss_mask: 0.3488  decode.loss_dice: 0.2236  decode.d0.loss_cls: 1.0789  decode.d0.loss_mask: 0.3338  decode.d0.loss_dice: 0.2322  decode.d1.loss_cls: 0.3102  decode.d1.loss_mask: 0.3257  decode.d1.loss_dice: 0.2147  decode.d2.loss_cls: 0.2628  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.2441  decode.d3.loss_cls: 0.1793  decode.d3.loss_mask: 0.3811  decode.d3.loss_dice: 0.2513  decode.d4.loss_cls: 0.2538  decode.d4.loss_mask: 0.3088  decode.d4.loss_dice: 0.2249  decode.d5.loss_cls: 0.2738  decode.d5.loss_mask: 0.3383  decode.d5.loss_dice: 0.2271  decode.d6.loss_cls: 0.2547  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.2282  decode.d7.loss_cls: 0.2350  decode.d7.loss_mask: 0.3494  decode.d7.loss_dice: 0.2168  decode.d8.loss_cls: 0.2798  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.2356
09/28 18:20:32 - mmengine - INFO - Iter(train) [ 31950/320000]  base_lr: 9.0968e-05 lr: 9.0968e-06  eta: 1 day, 11:03:41  time: 0.4368  data_time: 0.0092  memory: 5167  grad_norm: 106.0585  loss: 7.6300  decode.loss_cls: 0.1828  decode.loss_mask: 0.2740  decode.loss_dice: 0.2277  decode.d0.loss_cls: 0.9017  decode.d0.loss_mask: 0.2836  decode.d0.loss_dice: 0.2480  decode.d1.loss_cls: 0.2799  decode.d1.loss_mask: 0.2743  decode.d1.loss_dice: 0.2109  decode.d2.loss_cls: 0.1815  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.2300  decode.d3.loss_cls: 0.1693  decode.d3.loss_mask: 0.2735  decode.d3.loss_dice: 0.2438  decode.d4.loss_cls: 0.1623  decode.d4.loss_mask: 0.2768  decode.d4.loss_dice: 0.2276  decode.d5.loss_cls: 0.1393  decode.d5.loss_mask: 0.2758  decode.d5.loss_dice: 0.2297  decode.d6.loss_cls: 0.1506  decode.d6.loss_mask: 0.2749  decode.d6.loss_dice: 0.2328  decode.d7.loss_cls: 0.1605  decode.d7.loss_mask: 0.2721  decode.d7.loss_dice: 0.2307  decode.d8.loss_cls: 0.2313  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.2312
09/28 18:20:54 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:20:54 - mmengine - INFO - Iter(train) [ 32000/320000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 1 day, 11:03:19  time: 0.4376  data_time: 0.0095  memory: 5150  grad_norm: 60.2986  loss: 5.5547  decode.loss_cls: 0.0460  decode.loss_mask: 0.2191  decode.loss_dice: 0.1791  decode.d0.loss_cls: 1.0094  decode.d0.loss_mask: 0.2275  decode.d0.loss_dice: 0.1645  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.2204  decode.d1.loss_dice: 0.1617  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.2193  decode.d2.loss_dice: 0.1641  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.2166  decode.d3.loss_dice: 0.1611  decode.d4.loss_cls: 0.1134  decode.d4.loss_mask: 0.2192  decode.d4.loss_dice: 0.1620  decode.d5.loss_cls: 0.1100  decode.d5.loss_mask: 0.2188  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.2163  decode.d6.loss_dice: 0.1610  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.1631  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.1696
09/28 18:21:16 - mmengine - INFO - Iter(train) [ 32050/320000]  base_lr: 9.0939e-05 lr: 9.0939e-06  eta: 1 day, 11:02:56  time: 0.4365  data_time: 0.0093  memory: 5186  grad_norm: 70.5710  loss: 7.1978  decode.loss_cls: 0.0900  decode.loss_mask: 0.3137  decode.loss_dice: 0.2237  decode.d0.loss_cls: 0.9315  decode.d0.loss_mask: 0.3217  decode.d0.loss_dice: 0.2213  decode.d1.loss_cls: 0.1590  decode.d1.loss_mask: 0.3147  decode.d1.loss_dice: 0.2208  decode.d2.loss_cls: 0.1181  decode.d2.loss_mask: 0.3162  decode.d2.loss_dice: 0.2207  decode.d3.loss_cls: 0.0904  decode.d3.loss_mask: 0.3215  decode.d3.loss_dice: 0.2183  decode.d4.loss_cls: 0.0891  decode.d4.loss_mask: 0.3168  decode.d4.loss_dice: 0.2243  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.3217  decode.d5.loss_dice: 0.2278  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.3229  decode.d6.loss_dice: 0.2177  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.3230  decode.d7.loss_dice: 0.2224  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.3152  decode.d8.loss_dice: 0.2230
09/28 18:21:38 - mmengine - INFO - Iter(train) [ 32100/320000]  base_lr: 9.0925e-05 lr: 9.0925e-06  eta: 1 day, 11:02:33  time: 0.4370  data_time: 0.0095  memory: 5186  grad_norm: 53.3631  loss: 5.7873  decode.loss_cls: 0.1298  decode.loss_mask: 0.2069  decode.loss_dice: 0.1949  decode.d0.loss_cls: 0.8075  decode.d0.loss_mask: 0.2074  decode.d0.loss_dice: 0.1956  decode.d1.loss_cls: 0.1018  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.1924  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.2079  decode.d2.loss_dice: 0.1909  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 0.2054  decode.d3.loss_dice: 0.1886  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.2089  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.2082  decode.d5.loss_dice: 0.1959  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.2103  decode.d6.loss_dice: 0.1942  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 0.2081  decode.d7.loss_dice: 0.1884  decode.d8.loss_cls: 0.0989  decode.d8.loss_mask: 0.2072  decode.d8.loss_dice: 0.1924
09/28 18:22:00 - mmengine - INFO - Iter(train) [ 32150/320000]  base_lr: 9.0911e-05 lr: 9.0911e-06  eta: 1 day, 11:02:11  time: 0.4357  data_time: 0.0093  memory: 5186  grad_norm: 43.5127  loss: 5.2682  decode.loss_cls: 0.0183  decode.loss_mask: 0.2325  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.7655  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.1948  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.2420  decode.d1.loss_dice: 0.1836  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.1911  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.2381  decode.d3.loss_dice: 0.1956  decode.d4.loss_cls: 0.0299  decode.d4.loss_mask: 0.2384  decode.d4.loss_dice: 0.1880  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.1940  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.2341  decode.d6.loss_dice: 0.1871  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.2389  decode.d7.loss_dice: 0.1874  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.2350  decode.d8.loss_dice: 0.1919
09/28 18:22:22 - mmengine - INFO - Iter(train) [ 32200/320000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 1 day, 11:01:48  time: 0.4363  data_time: 0.0094  memory: 5186  grad_norm: 81.0184  loss: 9.1570  decode.loss_cls: 0.1763  decode.loss_mask: 0.2610  decode.loss_dice: 0.3980  decode.d0.loss_cls: 1.0799  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.4072  decode.d1.loss_cls: 0.2620  decode.d1.loss_mask: 0.2548  decode.d1.loss_dice: 0.3664  decode.d2.loss_cls: 0.2580  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.3719  decode.d3.loss_cls: 0.2110  decode.d3.loss_mask: 0.2600  decode.d3.loss_dice: 0.3697  decode.d4.loss_cls: 0.1780  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.3446  decode.d5.loss_cls: 0.1890  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.3645  decode.d6.loss_cls: 0.1396  decode.d6.loss_mask: 0.2634  decode.d6.loss_dice: 0.3635  decode.d7.loss_cls: 0.1706  decode.d7.loss_mask: 0.2560  decode.d7.loss_dice: 0.3630  decode.d8.loss_cls: 0.1655  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.3691
09/28 18:22:43 - mmengine - INFO - Iter(train) [ 32250/320000]  base_lr: 9.0882e-05 lr: 9.0882e-06  eta: 1 day, 11:01:25  time: 0.4360  data_time: 0.0093  memory: 5150  grad_norm: 32.8111  loss: 5.3449  decode.loss_cls: 0.0476  decode.loss_mask: 0.2316  decode.loss_dice: 0.1863  decode.d0.loss_cls: 0.9148  decode.d0.loss_mask: 0.2364  decode.d0.loss_dice: 0.2024  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.2313  decode.d1.loss_dice: 0.1907  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.1879  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.2328  decode.d3.loss_dice: 0.1877  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2315  decode.d4.loss_dice: 0.1878  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.2323  decode.d5.loss_dice: 0.1891  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.2341  decode.d6.loss_dice: 0.2013  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.2312  decode.d7.loss_dice: 0.1920  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.2303  decode.d8.loss_dice: 0.2223
09/28 18:23:05 - mmengine - INFO - Iter(train) [ 32300/320000]  base_lr: 9.0868e-05 lr: 9.0868e-06  eta: 1 day, 11:01:03  time: 0.4359  data_time: 0.0093  memory: 5186  grad_norm: 33.2611  loss: 5.8486  decode.loss_cls: 0.0768  decode.loss_mask: 0.2066  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.7894  decode.d0.loss_mask: 0.2081  decode.d0.loss_dice: 0.2495  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.2081  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.2045  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.1055  decode.d3.loss_mask: 0.2062  decode.d3.loss_dice: 0.2025  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.2064  decode.d4.loss_dice: 0.2016  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.2063  decode.d5.loss_dice: 0.1765  decode.d6.loss_cls: 0.1507  decode.d6.loss_mask: 0.2083  decode.d6.loss_dice: 0.2427  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.2056  decode.d7.loss_dice: 0.2339  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.2066  decode.d8.loss_dice: 0.2206
09/28 18:23:27 - mmengine - INFO - Iter(train) [ 32350/320000]  base_lr: 9.0854e-05 lr: 9.0854e-06  eta: 1 day, 11:00:40  time: 0.4365  data_time: 0.0094  memory: 5150  grad_norm: 166.8780  loss: 7.2274  decode.loss_cls: 0.1515  decode.loss_mask: 0.2740  decode.loss_dice: 0.1975  decode.d0.loss_cls: 1.0274  decode.d0.loss_mask: 0.2990  decode.d0.loss_dice: 0.2112  decode.d1.loss_cls: 0.1114  decode.d1.loss_mask: 0.2871  decode.d1.loss_dice: 0.2009  decode.d2.loss_cls: 0.1326  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.2005  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.1953  decode.d4.loss_cls: 0.1586  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.2003  decode.d5.loss_cls: 0.1528  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.1982  decode.d6.loss_cls: 0.1771  decode.d6.loss_mask: 0.2724  decode.d6.loss_dice: 0.1945  decode.d7.loss_cls: 0.1815  decode.d7.loss_mask: 0.2772  decode.d7.loss_dice: 0.1959  decode.d8.loss_cls: 0.1921  decode.d8.loss_mask: 0.2773  decode.d8.loss_dice: 0.1963
09/28 18:23:49 - mmengine - INFO - Iter(train) [ 32400/320000]  base_lr: 9.0840e-05 lr: 9.0840e-06  eta: 1 day, 11:00:18  time: 0.4374  data_time: 0.0095  memory: 5167  grad_norm: 59.1455  loss: 7.5352  decode.loss_cls: 0.1526  decode.loss_mask: 0.2605  decode.loss_dice: 0.2742  decode.d0.loss_cls: 0.9696  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.2762  decode.d1.loss_cls: 0.1869  decode.d1.loss_mask: 0.2640  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 0.2601  decode.d2.loss_dice: 0.2843  decode.d3.loss_cls: 0.1157  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.2845  decode.d4.loss_cls: 0.1534  decode.d4.loss_mask: 0.2590  decode.d4.loss_dice: 0.2643  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 0.2632  decode.d5.loss_dice: 0.2691  decode.d6.loss_cls: 0.0815  decode.d6.loss_mask: 0.2648  decode.d6.loss_dice: 0.2836  decode.d7.loss_cls: 0.1282  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.2790  decode.d8.loss_cls: 0.1625  decode.d8.loss_mask: 0.2633  decode.d8.loss_dice: 0.2641
09/28 18:24:11 - mmengine - INFO - Iter(train) [ 32450/320000]  base_lr: 9.0826e-05 lr: 9.0826e-06  eta: 1 day, 10:59:55  time: 0.4360  data_time: 0.0091  memory: 5167  grad_norm: 147.9969  loss: 6.3969  decode.loss_cls: 0.0768  decode.loss_mask: 0.2481  decode.loss_dice: 0.1851  decode.d0.loss_cls: 0.9874  decode.d0.loss_mask: 0.2565  decode.d0.loss_dice: 0.2177  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.2518  decode.d1.loss_dice: 0.1946  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.2490  decode.d2.loss_dice: 0.1965  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.1943  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 0.2461  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.1276  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.1121  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.1928  decode.d7.loss_cls: 0.0966  decode.d7.loss_mask: 0.2448  decode.d7.loss_dice: 0.1914  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 0.2465  decode.d8.loss_dice: 0.1838
09/28 18:24:33 - mmengine - INFO - Iter(train) [ 32500/320000]  base_lr: 9.0811e-05 lr: 9.0811e-06  eta: 1 day, 10:59:32  time: 0.4359  data_time: 0.0094  memory: 5186  grad_norm: 132.1951  loss: 8.5801  decode.loss_cls: 0.0413  decode.loss_mask: 0.4746  decode.loss_dice: 0.2961  decode.d0.loss_cls: 1.0219  decode.d0.loss_mask: 0.3732  decode.d0.loss_dice: 0.2807  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.3856  decode.d1.loss_dice: 0.2982  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.3995  decode.d2.loss_dice: 0.3010  decode.d3.loss_cls: 0.0866  decode.d3.loss_mask: 0.4051  decode.d3.loss_dice: 0.2712  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.3950  decode.d4.loss_dice: 0.2733  decode.d5.loss_cls: 0.0729  decode.d5.loss_mask: 0.3687  decode.d5.loss_dice: 0.2707  decode.d6.loss_cls: 0.0889  decode.d6.loss_mask: 0.3789  decode.d6.loss_dice: 0.2760  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.3576  decode.d7.loss_dice: 0.2713  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.4055  decode.d8.loss_dice: 0.2859
09/28 18:24:54 - mmengine - INFO - Iter(train) [ 32550/320000]  base_lr: 9.0797e-05 lr: 9.0797e-06  eta: 1 day, 10:59:09  time: 0.4366  data_time: 0.0093  memory: 5166  grad_norm: 61.3752  loss: 6.4882  decode.loss_cls: 0.2028  decode.loss_mask: 0.2273  decode.loss_dice: 0.1951  decode.d0.loss_cls: 0.8471  decode.d0.loss_mask: 0.2331  decode.d0.loss_dice: 0.2022  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.2479  decode.d1.loss_dice: 0.1921  decode.d2.loss_cls: 0.1606  decode.d2.loss_mask: 0.2278  decode.d2.loss_dice: 0.1791  decode.d3.loss_cls: 0.1413  decode.d3.loss_mask: 0.2337  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.1497  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.1870  decode.d5.loss_cls: 0.1153  decode.d5.loss_mask: 0.2368  decode.d5.loss_dice: 0.1864  decode.d6.loss_cls: 0.1587  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.1896  decode.d7.loss_cls: 0.1920  decode.d7.loss_mask: 0.2290  decode.d7.loss_dice: 0.1889  decode.d8.loss_cls: 0.1971  decode.d8.loss_mask: 0.2285  decode.d8.loss_dice: 0.1846
09/28 18:25:16 - mmengine - INFO - Iter(train) [ 32600/320000]  base_lr: 9.0783e-05 lr: 9.0783e-06  eta: 1 day, 10:58:47  time: 0.4364  data_time: 0.0094  memory: 5167  grad_norm: 47.5750  loss: 7.0779  decode.loss_cls: 0.1470  decode.loss_mask: 0.2507  decode.loss_dice: 0.2099  decode.d0.loss_cls: 1.0735  decode.d0.loss_mask: 0.2571  decode.d0.loss_dice: 0.2292  decode.d1.loss_cls: 0.1064  decode.d1.loss_mask: 0.2480  decode.d1.loss_dice: 0.2402  decode.d2.loss_cls: 0.1363  decode.d2.loss_mask: 0.2485  decode.d2.loss_dice: 0.2287  decode.d3.loss_cls: 0.1359  decode.d3.loss_mask: 0.2503  decode.d3.loss_dice: 0.2460  decode.d4.loss_cls: 0.1349  decode.d4.loss_mask: 0.2501  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.2227  decode.d6.loss_cls: 0.1811  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.1482  decode.d7.loss_mask: 0.2521  decode.d7.loss_dice: 0.2054  decode.d8.loss_cls: 0.1514  decode.d8.loss_mask: 0.2499  decode.d8.loss_dice: 0.2253
09/28 18:25:38 - mmengine - INFO - Iter(train) [ 32650/320000]  base_lr: 9.0769e-05 lr: 9.0769e-06  eta: 1 day, 10:58:26  time: 0.4359  data_time: 0.0094  memory: 5167  grad_norm: 208.9601  loss: 11.0525  decode.loss_cls: 0.4068  decode.loss_mask: 0.3042  decode.loss_dice: 0.3565  decode.d0.loss_cls: 1.1696  decode.d0.loss_mask: 0.2847  decode.d0.loss_dice: 0.3165  decode.d1.loss_cls: 0.4379  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.3477  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.3189  decode.d3.loss_cls: 0.3542  decode.d3.loss_mask: 0.2908  decode.d3.loss_dice: 0.3384  decode.d4.loss_cls: 0.3700  decode.d4.loss_mask: 0.3138  decode.d4.loss_dice: 0.3844  decode.d5.loss_cls: 0.3642  decode.d5.loss_mask: 0.3058  decode.d5.loss_dice: 0.3952  decode.d6.loss_cls: 0.4609  decode.d6.loss_mask: 0.2880  decode.d6.loss_dice: 0.3380  decode.d7.loss_cls: 0.4687  decode.d7.loss_mask: 0.2814  decode.d7.loss_dice: 0.2669  decode.d8.loss_cls: 0.4411  decode.d8.loss_mask: 0.2678  decode.d8.loss_dice: 0.3205
09/28 18:26:00 - mmengine - INFO - Iter(train) [ 32700/320000]  base_lr: 9.0755e-05 lr: 9.0755e-06  eta: 1 day, 10:58:03  time: 0.4364  data_time: 0.0095  memory: 5186  grad_norm: 37.0398  loss: 6.1278  decode.loss_cls: 0.0567  decode.loss_mask: 0.2579  decode.loss_dice: 0.2118  decode.d0.loss_cls: 0.9996  decode.d0.loss_mask: 0.2622  decode.d0.loss_dice: 0.2247  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.2596  decode.d1.loss_dice: 0.2314  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.2231  decode.d3.loss_cls: 0.0319  decode.d3.loss_mask: 0.2576  decode.d3.loss_dice: 0.2337  decode.d4.loss_cls: 0.0296  decode.d4.loss_mask: 0.2603  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.0216  decode.d6.loss_mask: 0.2581  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.2560  decode.d7.loss_dice: 0.2110  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.2592  decode.d8.loss_dice: 0.2115
09/28 18:26:22 - mmengine - INFO - Iter(train) [ 32750/320000]  base_lr: 9.0740e-05 lr: 9.0740e-06  eta: 1 day, 10:57:40  time: 0.4357  data_time: 0.0093  memory: 5167  grad_norm: 81.3259  loss: 8.4911  decode.loss_cls: 0.2304  decode.loss_mask: 0.2697  decode.loss_dice: 0.2962  decode.d0.loss_cls: 0.8336  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.2955  decode.d1.loss_cls: 0.2820  decode.d1.loss_mask: 0.2760  decode.d1.loss_dice: 0.2806  decode.d2.loss_cls: 0.2243  decode.d2.loss_mask: 0.2701  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.2150  decode.d3.loss_mask: 0.2751  decode.d3.loss_dice: 0.2908  decode.d4.loss_cls: 0.2063  decode.d4.loss_mask: 0.2748  decode.d4.loss_dice: 0.2818  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 0.2759  decode.d5.loss_dice: 0.2746  decode.d6.loss_cls: 0.2166  decode.d6.loss_mask: 0.2682  decode.d6.loss_dice: 0.2892  decode.d7.loss_cls: 0.2261  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.2525  decode.d8.loss_cls: 0.2527  decode.d8.loss_mask: 0.2731  decode.d8.loss_dice: 0.2896
09/28 18:26:44 - mmengine - INFO - Iter(train) [ 32800/320000]  base_lr: 9.0726e-05 lr: 9.0726e-06  eta: 1 day, 10:57:18  time: 0.4370  data_time: 0.0096  memory: 5167  grad_norm: 368.9230  loss: 7.2265  decode.loss_cls: 0.1090  decode.loss_mask: 0.2865  decode.loss_dice: 0.2219  decode.d0.loss_cls: 1.2066  decode.d0.loss_mask: 0.2905  decode.d0.loss_dice: 0.2370  decode.d1.loss_cls: 0.1287  decode.d1.loss_mask: 0.2971  decode.d1.loss_dice: 0.2338  decode.d2.loss_cls: 0.1151  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.2270  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.2322  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.2194  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.2944  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.2890  decode.d6.loss_dice: 0.2182  decode.d7.loss_cls: 0.1226  decode.d7.loss_mask: 0.2868  decode.d7.loss_dice: 0.2185  decode.d8.loss_cls: 0.1081  decode.d8.loss_mask: 0.2947  decode.d8.loss_dice: 0.2149
09/28 18:27:06 - mmengine - INFO - Iter(train) [ 32850/320000]  base_lr: 9.0712e-05 lr: 9.0712e-06  eta: 1 day, 10:56:55  time: 0.4360  data_time: 0.0093  memory: 5167  grad_norm: 73.8856  loss: 6.8905  decode.loss_cls: 0.1327  decode.loss_mask: 0.2370  decode.loss_dice: 0.2019  decode.d0.loss_cls: 0.9373  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.2435  decode.d1.loss_cls: 0.1401  decode.d1.loss_mask: 0.2395  decode.d1.loss_dice: 0.2175  decode.d2.loss_cls: 0.1394  decode.d2.loss_mask: 0.2385  decode.d2.loss_dice: 0.2149  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 0.2353  decode.d3.loss_dice: 0.2125  decode.d4.loss_cls: 0.1828  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.2077  decode.d5.loss_cls: 0.1744  decode.d5.loss_mask: 0.2390  decode.d5.loss_dice: 0.1993  decode.d6.loss_cls: 0.1616  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2025  decode.d7.loss_cls: 0.1690  decode.d7.loss_mask: 0.2399  decode.d7.loss_dice: 0.2174  decode.d8.loss_cls: 0.1322  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2129
09/28 18:27:27 - mmengine - INFO - Iter(train) [ 32900/320000]  base_lr: 9.0698e-05 lr: 9.0698e-06  eta: 1 day, 10:56:32  time: 0.4368  data_time: 0.0094  memory: 5150  grad_norm: 29.9879  loss: 4.9525  decode.loss_cls: 0.0142  decode.loss_mask: 0.2274  decode.loss_dice: 0.1614  decode.d0.loss_cls: 0.8358  decode.d0.loss_mask: 0.2597  decode.d0.loss_dice: 0.1826  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.2278  decode.d1.loss_dice: 0.1638  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.2280  decode.d2.loss_dice: 0.1664  decode.d3.loss_cls: 0.0205  decode.d3.loss_mask: 0.2250  decode.d3.loss_dice: 0.1630  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.1630  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.2258  decode.d5.loss_dice: 0.1648  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.2270  decode.d6.loss_dice: 0.1637  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.2269  decode.d7.loss_dice: 0.1652  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.2342  decode.d8.loss_dice: 0.1641
09/28 18:27:51 - mmengine - INFO - Iter(train) [ 32950/320000]  base_lr: 9.0683e-05 lr: 9.0683e-06  eta: 1 day, 10:56:25  time: 0.4739  data_time: 0.0090  memory: 5186  grad_norm: 32.7820  loss: 5.4796  decode.loss_cls: 0.1006  decode.loss_mask: 0.1732  decode.loss_dice: 0.1831  decode.d0.loss_cls: 0.8575  decode.d0.loss_mask: 0.1740  decode.d0.loss_dice: 0.1784  decode.d1.loss_cls: 0.1722  decode.d1.loss_mask: 0.1780  decode.d1.loss_dice: 0.1807  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.1696  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.1081  decode.d3.loss_mask: 0.1748  decode.d3.loss_dice: 0.1776  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.1741  decode.d4.loss_dice: 0.1825  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.1693  decode.d5.loss_dice: 0.1802  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.1795  decode.d6.loss_dice: 0.1917  decode.d7.loss_cls: 0.1735  decode.d7.loss_mask: 0.1794  decode.d7.loss_dice: 0.1927  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.1713  decode.d8.loss_dice: 0.1778
09/28 18:28:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:28:15 - mmengine - INFO - Iter(train) [ 33000/320000]  base_lr: 9.0669e-05 lr: 9.0669e-06  eta: 1 day, 10:56:17  time: 0.4726  data_time: 0.0094  memory: 5167  grad_norm: 55.0692  loss: 6.5013  decode.loss_cls: 0.0727  decode.loss_mask: 0.2291  decode.loss_dice: 0.2318  decode.d0.loss_cls: 0.8135  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 0.2218  decode.d1.loss_dice: 0.2264  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.2506  decode.d3.loss_cls: 0.1184  decode.d3.loss_mask: 0.2243  decode.d3.loss_dice: 0.2199  decode.d4.loss_cls: 0.0761  decode.d4.loss_mask: 0.2226  decode.d4.loss_dice: 0.2219  decode.d5.loss_cls: 0.0618  decode.d5.loss_mask: 0.2247  decode.d5.loss_dice: 0.2260  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.2616  decode.d6.loss_dice: 0.2332  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.3281  decode.d7.loss_dice: 0.2411  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.3223  decode.d8.loss_dice: 0.2317
09/28 18:28:38 - mmengine - INFO - Iter(train) [ 33050/320000]  base_lr: 9.0655e-05 lr: 9.0655e-06  eta: 1 day, 10:56:10  time: 0.4705  data_time: 0.0095  memory: 5185  grad_norm: 110.9511  loss: 8.5667  decode.loss_cls: 0.3182  decode.loss_mask: 0.2750  decode.loss_dice: 0.2507  decode.d0.loss_cls: 0.9595  decode.d0.loss_mask: 0.2848  decode.d0.loss_dice: 0.2506  decode.d1.loss_cls: 0.3034  decode.d1.loss_mask: 0.2744  decode.d1.loss_dice: 0.2443  decode.d2.loss_cls: 0.2517  decode.d2.loss_mask: 0.2754  decode.d2.loss_dice: 0.2391  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.2510  decode.d4.loss_cls: 0.2476  decode.d4.loss_mask: 0.2736  decode.d4.loss_dice: 0.2385  decode.d5.loss_cls: 0.2186  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.2693  decode.d6.loss_mask: 0.2707  decode.d6.loss_dice: 0.2497  decode.d7.loss_cls: 0.2781  decode.d7.loss_mask: 0.2794  decode.d7.loss_dice: 0.2390  decode.d8.loss_cls: 0.2921  decode.d8.loss_mask: 0.2748  decode.d8.loss_dice: 0.2479
09/28 18:29:02 - mmengine - INFO - Iter(train) [ 33100/320000]  base_lr: 9.0641e-05 lr: 9.0641e-06  eta: 1 day, 10:56:03  time: 0.4733  data_time: 0.0094  memory: 5166  grad_norm: 54.9220  loss: 7.6582  decode.loss_cls: 0.2049  decode.loss_mask: 0.1999  decode.loss_dice: 0.2747  decode.d0.loss_cls: 1.0135  decode.d0.loss_mask: 0.2071  decode.d0.loss_dice: 0.2504  decode.d1.loss_cls: 0.2472  decode.d1.loss_mask: 0.1977  decode.d1.loss_dice: 0.2414  decode.d2.loss_cls: 0.2718  decode.d2.loss_mask: 0.1996  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.1992  decode.d3.loss_mask: 0.1983  decode.d3.loss_dice: 0.2573  decode.d4.loss_cls: 0.2636  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.2645  decode.d5.loss_cls: 0.2145  decode.d5.loss_mask: 0.2018  decode.d5.loss_dice: 0.2521  decode.d6.loss_cls: 0.2140  decode.d6.loss_mask: 0.1982  decode.d6.loss_dice: 0.2624  decode.d7.loss_cls: 0.2152  decode.d7.loss_mask: 0.2016  decode.d7.loss_dice: 0.2623  decode.d8.loss_cls: 0.2458  decode.d8.loss_mask: 0.1953  decode.d8.loss_dice: 0.2591
09/28 18:29:25 - mmengine - INFO - Iter(train) [ 33150/320000]  base_lr: 9.0627e-05 lr: 9.0627e-06  eta: 1 day, 10:55:55  time: 0.4721  data_time: 0.0095  memory: 5150  grad_norm: 98.1534  loss: 8.3543  decode.loss_cls: 0.2100  decode.loss_mask: 0.3037  decode.loss_dice: 0.2011  decode.d0.loss_cls: 1.0230  decode.d0.loss_mask: 0.3236  decode.d0.loss_dice: 0.2144  decode.d1.loss_cls: 0.1390  decode.d1.loss_mask: 0.3024  decode.d1.loss_dice: 0.2042  decode.d2.loss_cls: 0.1985  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.2187  decode.d3.loss_cls: 0.2312  decode.d3.loss_mask: 0.2999  decode.d3.loss_dice: 0.2186  decode.d4.loss_cls: 0.2878  decode.d4.loss_mask: 0.3044  decode.d4.loss_dice: 0.2151  decode.d5.loss_cls: 0.2938  decode.d5.loss_mask: 0.3097  decode.d5.loss_dice: 0.2026  decode.d6.loss_cls: 0.2793  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.1993  decode.d7.loss_cls: 0.2684  decode.d7.loss_mask: 0.3034  decode.d7.loss_dice: 0.1996  decode.d8.loss_cls: 0.2882  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.2001
09/28 18:29:49 - mmengine - INFO - Iter(train) [ 33200/320000]  base_lr: 9.0612e-05 lr: 9.0612e-06  eta: 1 day, 10:55:48  time: 0.4721  data_time: 0.0092  memory: 5149  grad_norm: 45.9659  loss: 7.3301  decode.loss_cls: 0.1303  decode.loss_mask: 0.2653  decode.loss_dice: 0.2622  decode.d0.loss_cls: 0.8747  decode.d0.loss_mask: 0.2753  decode.d0.loss_dice: 0.2657  decode.d1.loss_cls: 0.1144  decode.d1.loss_mask: 0.2670  decode.d1.loss_dice: 0.2668  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.2669  decode.d2.loss_dice: 0.2510  decode.d3.loss_cls: 0.1246  decode.d3.loss_mask: 0.2646  decode.d3.loss_dice: 0.2560  decode.d4.loss_cls: 0.1362  decode.d4.loss_mask: 0.2655  decode.d4.loss_dice: 0.2593  decode.d5.loss_cls: 0.1338  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2634  decode.d6.loss_cls: 0.1438  decode.d6.loss_mask: 0.2694  decode.d6.loss_dice: 0.2587  decode.d7.loss_cls: 0.1642  decode.d7.loss_mask: 0.2681  decode.d7.loss_dice: 0.2642  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.2575
09/28 18:30:13 - mmengine - INFO - Iter(train) [ 33250/320000]  base_lr: 9.0598e-05 lr: 9.0598e-06  eta: 1 day, 10:55:40  time: 0.4721  data_time: 0.0095  memory: 5167  grad_norm: 30.2155  loss: 6.3626  decode.loss_cls: 0.1261  decode.loss_mask: 0.2670  decode.loss_dice: 0.1960  decode.d0.loss_cls: 0.9011  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.2119  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 0.2651  decode.d1.loss_dice: 0.1915  decode.d2.loss_cls: 0.1048  decode.d2.loss_mask: 0.2663  decode.d2.loss_dice: 0.1905  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.2635  decode.d3.loss_dice: 0.1860  decode.d4.loss_cls: 0.1001  decode.d4.loss_mask: 0.2629  decode.d4.loss_dice: 0.1857  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.1622  decode.d6.loss_cls: 0.1076  decode.d6.loss_mask: 0.2642  decode.d6.loss_dice: 0.1603  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.1840  decode.d8.loss_cls: 0.1219  decode.d8.loss_mask: 0.2593  decode.d8.loss_dice: 0.1883
09/28 18:30:36 - mmengine - INFO - Iter(train) [ 33300/320000]  base_lr: 9.0584e-05 lr: 9.0584e-06  eta: 1 day, 10:55:32  time: 0.4699  data_time: 0.0092  memory: 5167  grad_norm: 46.8001  loss: 4.8809  decode.loss_cls: 0.0518  decode.loss_mask: 0.1993  decode.loss_dice: 0.1659  decode.d0.loss_cls: 0.8010  decode.d0.loss_mask: 0.2009  decode.d0.loss_dice: 0.1638  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.1985  decode.d1.loss_dice: 0.1661  decode.d2.loss_cls: 0.0226  decode.d2.loss_mask: 0.1978  decode.d2.loss_dice: 0.1611  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.1996  decode.d3.loss_dice: 0.1624  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.1719  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.1998  decode.d5.loss_dice: 0.1668  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.1966  decode.d6.loss_dice: 0.1640  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.1967  decode.d7.loss_dice: 0.1627  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.1993  decode.d8.loss_dice: 0.1638
09/28 18:31:00 - mmengine - INFO - Iter(train) [ 33350/320000]  base_lr: 9.0570e-05 lr: 9.0570e-06  eta: 1 day, 10:55:25  time: 0.4733  data_time: 0.0097  memory: 5186  grad_norm: 38.1194  loss: 6.8184  decode.loss_cls: 0.0401  decode.loss_mask: 0.3168  decode.loss_dice: 0.2606  decode.d0.loss_cls: 0.8270  decode.d0.loss_mask: 0.3163  decode.d0.loss_dice: 0.2296  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.3112  decode.d1.loss_dice: 0.2241  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.3075  decode.d2.loss_dice: 0.2262  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.2166  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.3102  decode.d4.loss_dice: 0.2212  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.3073  decode.d5.loss_dice: 0.2295  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.3078  decode.d6.loss_dice: 0.2259  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.3112  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.0639  decode.d8.loss_mask: 0.3085  decode.d8.loss_dice: 0.2626
09/28 18:31:23 - mmengine - INFO - Iter(train) [ 33400/320000]  base_lr: 9.0555e-05 lr: 9.0555e-06  eta: 1 day, 10:55:17  time: 0.4708  data_time: 0.0095  memory: 5150  grad_norm: 54.4451  loss: 5.8049  decode.loss_cls: 0.0577  decode.loss_mask: 0.2345  decode.loss_dice: 0.2009  decode.d0.loss_cls: 0.8967  decode.d0.loss_mask: 0.2443  decode.d0.loss_dice: 0.2088  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2002  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.2359  decode.d2.loss_dice: 0.1939  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.2350  decode.d3.loss_dice: 0.1961  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.2388  decode.d4.loss_dice: 0.1970  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.2345  decode.d5.loss_dice: 0.1930  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.2382  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.2368  decode.d7.loss_dice: 0.1966  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.2365  decode.d8.loss_dice: 0.2013
09/28 18:31:47 - mmengine - INFO - Iter(train) [ 33450/320000]  base_lr: 9.0541e-05 lr: 9.0541e-06  eta: 1 day, 10:55:10  time: 0.4726  data_time: 0.0093  memory: 5186  grad_norm: 80.4650  loss: 9.5151  decode.loss_cls: 0.1553  decode.loss_mask: 0.4012  decode.loss_dice: 0.3007  decode.d0.loss_cls: 1.0909  decode.d0.loss_mask: 0.3270  decode.d0.loss_dice: 0.3220  decode.d1.loss_cls: 0.2478  decode.d1.loss_mask: 0.3983  decode.d1.loss_dice: 0.3061  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 0.4045  decode.d2.loss_dice: 0.2926  decode.d3.loss_cls: 0.1624  decode.d3.loss_mask: 0.4018  decode.d3.loss_dice: 0.2914  decode.d4.loss_cls: 0.1620  decode.d4.loss_mask: 0.3978  decode.d4.loss_dice: 0.2905  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 0.4003  decode.d5.loss_dice: 0.2929  decode.d6.loss_cls: 0.1612  decode.d6.loss_mask: 0.3983  decode.d6.loss_dice: 0.2918  decode.d7.loss_cls: 0.1745  decode.d7.loss_mask: 0.3375  decode.d7.loss_dice: 0.2995  decode.d8.loss_cls: 0.1293  decode.d8.loss_mask: 0.4049  decode.d8.loss_dice: 0.3071
09/28 18:32:11 - mmengine - INFO - Iter(train) [ 33500/320000]  base_lr: 9.0527e-05 lr: 9.0527e-06  eta: 1 day, 10:55:02  time: 0.4726  data_time: 0.0095  memory: 5186  grad_norm: 85.3939  loss: 7.7844  decode.loss_cls: 0.3069  decode.loss_mask: 0.2383  decode.loss_dice: 0.1966  decode.d0.loss_cls: 0.9486  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.2265  decode.d1.loss_cls: 0.2887  decode.d1.loss_mask: 0.2395  decode.d1.loss_dice: 0.1880  decode.d2.loss_cls: 0.2554  decode.d2.loss_mask: 0.2407  decode.d2.loss_dice: 0.1866  decode.d3.loss_cls: 0.2356  decode.d3.loss_mask: 0.2391  decode.d3.loss_dice: 0.1905  decode.d4.loss_cls: 0.2764  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.1883  decode.d5.loss_cls: 0.2550  decode.d5.loss_mask: 0.2391  decode.d5.loss_dice: 0.1852  decode.d6.loss_cls: 0.3079  decode.d6.loss_mask: 0.2395  decode.d6.loss_dice: 0.1914  decode.d7.loss_cls: 0.2740  decode.d7.loss_mask: 0.2427  decode.d7.loss_dice: 0.1952  decode.d8.loss_cls: 0.2879  decode.d8.loss_mask: 0.2397  decode.d8.loss_dice: 0.2018
09/28 18:32:34 - mmengine - INFO - Iter(train) [ 33550/320000]  base_lr: 9.0513e-05 lr: 9.0513e-06  eta: 1 day, 10:54:55  time: 0.4712  data_time: 0.0093  memory: 5167  grad_norm: 48.1691  loss: 5.8456  decode.loss_cls: 0.1100  decode.loss_mask: 0.2212  decode.loss_dice: 0.1757  decode.d0.loss_cls: 0.8246  decode.d0.loss_mask: 0.2251  decode.d0.loss_dice: 0.1895  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 0.2245  decode.d1.loss_dice: 0.1839  decode.d2.loss_cls: 0.1118  decode.d2.loss_mask: 0.2228  decode.d2.loss_dice: 0.1842  decode.d3.loss_cls: 0.0839  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.1870  decode.d4.loss_cls: 0.1066  decode.d4.loss_mask: 0.2232  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.0952  decode.d5.loss_mask: 0.2212  decode.d5.loss_dice: 0.1885  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.2212  decode.d6.loss_dice: 0.1848  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.1713  decode.d8.loss_cls: 0.1257  decode.d8.loss_mask: 0.2224  decode.d8.loss_dice: 0.1746
09/28 18:32:58 - mmengine - INFO - Iter(train) [ 33600/320000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 1 day, 10:54:47  time: 0.4719  data_time: 0.0094  memory: 5166  grad_norm: 51.7557  loss: 9.2605  decode.loss_cls: 0.3196  decode.loss_mask: 0.2618  decode.loss_dice: 0.2605  decode.d0.loss_cls: 1.0012  decode.d0.loss_mask: 0.2712  decode.d0.loss_dice: 0.2821  decode.d1.loss_cls: 0.3110  decode.d1.loss_mask: 0.2684  decode.d1.loss_dice: 0.2599  decode.d2.loss_cls: 0.3849  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2717  decode.d3.loss_cls: 0.2849  decode.d3.loss_mask: 0.2631  decode.d3.loss_dice: 0.2601  decode.d4.loss_cls: 0.3154  decode.d4.loss_mask: 0.2607  decode.d4.loss_dice: 0.2729  decode.d5.loss_cls: 0.3294  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.2601  decode.d6.loss_cls: 0.3269  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.2648  decode.d7.loss_cls: 0.3428  decode.d7.loss_mask: 0.2636  decode.d7.loss_dice: 0.2646  decode.d8.loss_cls: 0.3451  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.2657
09/28 18:33:21 - mmengine - INFO - Iter(train) [ 33650/320000]  base_lr: 9.0484e-05 lr: 9.0484e-06  eta: 1 day, 10:54:39  time: 0.4712  data_time: 0.0096  memory: 5166  grad_norm: 154.1455  loss: 7.3936  decode.loss_cls: 0.0894  decode.loss_mask: 0.3194  decode.loss_dice: 0.2402  decode.d0.loss_cls: 0.7881  decode.d0.loss_mask: 0.3331  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.3246  decode.d1.loss_dice: 0.2602  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.3183  decode.d2.loss_dice: 0.2438  decode.d3.loss_cls: 0.1539  decode.d3.loss_mask: 0.3217  decode.d3.loss_dice: 0.2478  decode.d4.loss_cls: 0.1194  decode.d4.loss_mask: 0.3216  decode.d4.loss_dice: 0.2501  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.3199  decode.d5.loss_dice: 0.2488  decode.d6.loss_cls: 0.0916  decode.d6.loss_mask: 0.3228  decode.d6.loss_dice: 0.2422  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.3217  decode.d7.loss_dice: 0.2473  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.3203  decode.d8.loss_dice: 0.2470
09/28 18:33:45 - mmengine - INFO - Iter(train) [ 33700/320000]  base_lr: 9.0470e-05 lr: 9.0470e-06  eta: 1 day, 10:54:31  time: 0.4719  data_time: 0.0093  memory: 5167  grad_norm: 79.1232  loss: 6.7284  decode.loss_cls: 0.1262  decode.loss_mask: 0.2460  decode.loss_dice: 0.2405  decode.d0.loss_cls: 0.8905  decode.d0.loss_mask: 0.2598  decode.d0.loss_dice: 0.2338  decode.d1.loss_cls: 0.1741  decode.d1.loss_mask: 0.2470  decode.d1.loss_dice: 0.1986  decode.d2.loss_cls: 0.1771  decode.d2.loss_mask: 0.2531  decode.d2.loss_dice: 0.1966  decode.d3.loss_cls: 0.1745  decode.d3.loss_mask: 0.2505  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.1629  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.1951  decode.d6.loss_cls: 0.1023  decode.d6.loss_mask: 0.2459  decode.d6.loss_dice: 0.2044  decode.d7.loss_cls: 0.0946  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.1989  decode.d8.loss_cls: 0.1371  decode.d8.loss_mask: 0.2433  decode.d8.loss_dice: 0.2016
09/28 18:34:09 - mmengine - INFO - Iter(train) [ 33750/320000]  base_lr: 9.0456e-05 lr: 9.0456e-06  eta: 1 day, 10:54:23  time: 0.4726  data_time: 0.0095  memory: 5186  grad_norm: 53.4302  loss: 6.6050  decode.loss_cls: 0.1616  decode.loss_mask: 0.2078  decode.loss_dice: 0.2212  decode.d0.loss_cls: 0.8758  decode.d0.loss_mask: 0.2161  decode.d0.loss_dice: 0.2193  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.2101  decode.d1.loss_dice: 0.2207  decode.d2.loss_cls: 0.1551  decode.d2.loss_mask: 0.2050  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.1531  decode.d3.loss_mask: 0.2068  decode.d3.loss_dice: 0.2029  decode.d4.loss_cls: 0.1759  decode.d4.loss_mask: 0.2088  decode.d4.loss_dice: 0.2215  decode.d5.loss_cls: 0.1393  decode.d5.loss_mask: 0.2103  decode.d5.loss_dice: 0.2204  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.2112  decode.d7.loss_cls: 0.1566  decode.d7.loss_mask: 0.2055  decode.d7.loss_dice: 0.2405  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 0.2048  decode.d8.loss_dice: 0.2100
09/28 18:34:32 - mmengine - INFO - Iter(train) [ 33800/320000]  base_lr: 9.0442e-05 lr: 9.0442e-06  eta: 1 day, 10:54:15  time: 0.4708  data_time: 0.0094  memory: 5166  grad_norm: 81.6219  loss: 5.9523  decode.loss_cls: 0.1096  decode.loss_mask: 0.2467  decode.loss_dice: 0.1784  decode.d0.loss_cls: 0.8467  decode.d0.loss_mask: 0.2508  decode.d0.loss_dice: 0.1866  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.1817  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.2437  decode.d2.loss_dice: 0.1790  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.2414  decode.d3.loss_dice: 0.1794  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.2452  decode.d4.loss_dice: 0.1808  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.2449  decode.d5.loss_dice: 0.1764  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.1797  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.2451  decode.d7.loss_dice: 0.1768  decode.d8.loss_cls: 0.1119  decode.d8.loss_mask: 0.2425  decode.d8.loss_dice: 0.1748
09/28 18:34:56 - mmengine - INFO - Iter(train) [ 33850/320000]  base_lr: 9.0428e-05 lr: 9.0428e-06  eta: 1 day, 10:54:07  time: 0.4717  data_time: 0.0098  memory: 5150  grad_norm: 20.8397  loss: 4.8656  decode.loss_cls: 0.0151  decode.loss_mask: 0.2123  decode.loss_dice: 0.1721  decode.d0.loss_cls: 0.8405  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.1780  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.2127  decode.d1.loss_dice: 0.1825  decode.d2.loss_cls: 0.0164  decode.d2.loss_mask: 0.2104  decode.d2.loss_dice: 0.1773  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.2131  decode.d3.loss_dice: 0.1778  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.2115  decode.d4.loss_dice: 0.1785  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.2139  decode.d5.loss_dice: 0.1747  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.1776  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.2104  decode.d7.loss_dice: 0.1750  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.2149  decode.d8.loss_dice: 0.1753
09/28 18:35:19 - mmengine - INFO - Iter(train) [ 33900/320000]  base_lr: 9.0413e-05 lr: 9.0413e-06  eta: 1 day, 10:53:58  time: 0.4709  data_time: 0.0096  memory: 5148  grad_norm: 22.0103  loss: 5.0508  decode.loss_cls: 0.0086  decode.loss_mask: 0.2129  decode.loss_dice: 0.1817  decode.d0.loss_cls: 0.8434  decode.d0.loss_mask: 0.2137  decode.d0.loss_dice: 0.1993  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2075  decode.d1.loss_dice: 0.1889  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.2111  decode.d2.loss_dice: 0.1980  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.2125  decode.d3.loss_dice: 0.1935  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.2113  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2114  decode.d5.loss_dice: 0.2125  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.2129  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2114  decode.d7.loss_dice: 0.2062  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.2136  decode.d8.loss_dice: 0.2005
09/28 18:35:43 - mmengine - INFO - Iter(train) [ 33950/320000]  base_lr: 9.0399e-05 lr: 9.0399e-06  eta: 1 day, 10:53:50  time: 0.4704  data_time: 0.0093  memory: 5186  grad_norm: 44.4558  loss: 8.0772  decode.loss_cls: 0.2310  decode.loss_mask: 0.2773  decode.loss_dice: 0.2694  decode.d0.loss_cls: 0.8811  decode.d0.loss_mask: 0.2808  decode.d0.loss_dice: 0.2690  decode.d1.loss_cls: 0.2402  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.2673  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.2566  decode.d3.loss_cls: 0.2096  decode.d3.loss_mask: 0.2844  decode.d3.loss_dice: 0.2611  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 0.2806  decode.d4.loss_dice: 0.2511  decode.d5.loss_cls: 0.1941  decode.d5.loss_mask: 0.2794  decode.d5.loss_dice: 0.2668  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 0.2834  decode.d6.loss_dice: 0.2744  decode.d7.loss_cls: 0.1546  decode.d7.loss_mask: 0.2778  decode.d7.loss_dice: 0.2713  decode.d8.loss_cls: 0.1688  decode.d8.loss_mask: 0.2745  decode.d8.loss_dice: 0.2609
09/28 18:36:07 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:36:07 - mmengine - INFO - Iter(train) [ 34000/320000]  base_lr: 9.0385e-05 lr: 9.0385e-06  eta: 1 day, 10:53:42  time: 0.4721  data_time: 0.0093  memory: 5167  grad_norm: 76.1315  loss: 5.5131  decode.loss_cls: 0.0393  decode.loss_mask: 0.2233  decode.loss_dice: 0.1924  decode.d0.loss_cls: 0.9473  decode.d0.loss_mask: 0.2307  decode.d0.loss_dice: 0.2165  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2197  decode.d1.loss_dice: 0.1947  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.2226  decode.d2.loss_dice: 0.1874  decode.d3.loss_cls: 0.0398  decode.d3.loss_mask: 0.2251  decode.d3.loss_dice: 0.1905  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.2231  decode.d4.loss_dice: 0.1915  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.2223  decode.d5.loss_dice: 0.1851  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.2224  decode.d6.loss_dice: 0.1937  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.2211  decode.d7.loss_dice: 0.1871  decode.d8.loss_cls: 0.0582  decode.d8.loss_mask: 0.2246  decode.d8.loss_dice: 0.1847
09/28 18:36:30 - mmengine - INFO - Iter(train) [ 34050/320000]  base_lr: 9.0371e-05 lr: 9.0371e-06  eta: 1 day, 10:53:34  time: 0.4730  data_time: 0.0097  memory: 5186  grad_norm: 46.8251  loss: 5.9674  decode.loss_cls: 0.0608  decode.loss_mask: 0.2545  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.8660  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.2161  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.2513  decode.d1.loss_dice: 0.1934  decode.d2.loss_cls: 0.0768  decode.d2.loss_mask: 0.2582  decode.d2.loss_dice: 0.1984  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.1889  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.1898  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.1931  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.1914  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.2566  decode.d7.loss_dice: 0.1912  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.1899
09/28 18:36:54 - mmengine - INFO - Iter(train) [ 34100/320000]  base_lr: 9.0356e-05 lr: 9.0356e-06  eta: 1 day, 10:53:26  time: 0.4716  data_time: 0.0094  memory: 5150  grad_norm: 99.2675  loss: 7.9673  decode.loss_cls: 0.1608  decode.loss_mask: 0.3685  decode.loss_dice: 0.2880  decode.d0.loss_cls: 0.7675  decode.d0.loss_mask: 0.2506  decode.d0.loss_dice: 0.2475  decode.d1.loss_cls: 0.2731  decode.d1.loss_mask: 0.2465  decode.d1.loss_dice: 0.2516  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.3402  decode.d2.loss_dice: 0.2575  decode.d3.loss_cls: 0.0881  decode.d3.loss_mask: 0.3448  decode.d3.loss_dice: 0.2517  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.3524  decode.d4.loss_dice: 0.2663  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.3645  decode.d5.loss_dice: 0.2703  decode.d6.loss_cls: 0.2221  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.2614  decode.d7.loss_cls: 0.2083  decode.d7.loss_mask: 0.2827  decode.d7.loss_dice: 0.2602  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.2614
09/28 18:37:17 - mmengine - INFO - Iter(train) [ 34150/320000]  base_lr: 9.0342e-05 lr: 9.0342e-06  eta: 1 day, 10:53:18  time: 0.4745  data_time: 0.0096  memory: 5167  grad_norm: 65.0185  loss: 6.2457  decode.loss_cls: 0.0791  decode.loss_mask: 0.2370  decode.loss_dice: 0.2458  decode.d0.loss_cls: 0.7518  decode.d0.loss_mask: 0.2377  decode.d0.loss_dice: 0.2598  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.2340  decode.d1.loss_dice: 0.2366  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.2316  decode.d2.loss_dice: 0.2321  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.2324  decode.d3.loss_dice: 0.2426  decode.d4.loss_cls: 0.1043  decode.d4.loss_mask: 0.2320  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 0.2327  decode.d5.loss_dice: 0.2341  decode.d6.loss_cls: 0.1058  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2356  decode.d7.loss_cls: 0.0952  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.2323  decode.d8.loss_dice: 0.2378
09/28 18:37:41 - mmengine - INFO - Iter(train) [ 34200/320000]  base_lr: 9.0328e-05 lr: 9.0328e-06  eta: 1 day, 10:53:10  time: 0.4723  data_time: 0.0094  memory: 5149  grad_norm: 114.7816  loss: 7.3039  decode.loss_cls: 0.1606  decode.loss_mask: 0.2363  decode.loss_dice: 0.2686  decode.d0.loss_cls: 0.7439  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.2570  decode.d1.loss_cls: 0.1633  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.1399  decode.d2.loss_mask: 0.2384  decode.d2.loss_dice: 0.2741  decode.d3.loss_cls: 0.1142  decode.d3.loss_mask: 0.2428  decode.d3.loss_dice: 0.2945  decode.d4.loss_cls: 0.1321  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.2871  decode.d5.loss_cls: 0.1525  decode.d5.loss_mask: 0.2471  decode.d5.loss_dice: 0.2979  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 0.2418  decode.d6.loss_dice: 0.2951  decode.d7.loss_cls: 0.1620  decode.d7.loss_mask: 0.2387  decode.d7.loss_dice: 0.2886  decode.d8.loss_cls: 0.1527  decode.d8.loss_mask: 0.2390  decode.d8.loss_dice: 0.2876
09/28 18:38:05 - mmengine - INFO - Iter(train) [ 34250/320000]  base_lr: 9.0314e-05 lr: 9.0314e-06  eta: 1 day, 10:53:02  time: 0.4734  data_time: 0.0098  memory: 5166  grad_norm: 226.3203  loss: 8.7463  decode.loss_cls: 0.1351  decode.loss_mask: 0.3076  decode.loss_dice: 0.2659  decode.d0.loss_cls: 1.0800  decode.d0.loss_mask: 0.2957  decode.d0.loss_dice: 0.2888  decode.d1.loss_cls: 0.2629  decode.d1.loss_mask: 0.3085  decode.d1.loss_dice: 0.2905  decode.d2.loss_cls: 0.2195  decode.d2.loss_mask: 0.3044  decode.d2.loss_dice: 0.2643  decode.d3.loss_cls: 0.1598  decode.d3.loss_mask: 0.3089  decode.d3.loss_dice: 0.2672  decode.d4.loss_cls: 0.1649  decode.d4.loss_mask: 0.3113  decode.d4.loss_dice: 0.2848  decode.d5.loss_cls: 0.2455  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.2628  decode.d6.loss_cls: 0.1806  decode.d6.loss_mask: 0.3069  decode.d6.loss_dice: 0.2917  decode.d7.loss_cls: 0.2433  decode.d7.loss_mask: 0.3174  decode.d7.loss_dice: 0.2797  decode.d8.loss_cls: 0.2022  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.2775
09/28 18:38:29 - mmengine - INFO - Iter(train) [ 34300/320000]  base_lr: 9.0300e-05 lr: 9.0300e-06  eta: 1 day, 10:52:55  time: 0.4732  data_time: 0.0095  memory: 5166  grad_norm: 49.8064  loss: 6.8441  decode.loss_cls: 0.0613  decode.loss_mask: 0.2707  decode.loss_dice: 0.2543  decode.d0.loss_cls: 0.8291  decode.d0.loss_mask: 0.2618  decode.d0.loss_dice: 0.2473  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.2572  decode.d1.loss_dice: 0.2249  decode.d2.loss_cls: 0.1002  decode.d2.loss_mask: 0.2646  decode.d2.loss_dice: 0.2471  decode.d3.loss_cls: 0.1237  decode.d3.loss_mask: 0.2609  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.2704  decode.d4.loss_dice: 0.2431  decode.d5.loss_cls: 0.1056  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.2391  decode.d6.loss_cls: 0.1170  decode.d6.loss_mask: 0.2692  decode.d6.loss_dice: 0.2536  decode.d7.loss_cls: 0.1244  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.2351  decode.d8.loss_cls: 0.1191  decode.d8.loss_mask: 0.2524  decode.d8.loss_dice: 0.2339
09/28 18:38:52 - mmengine - INFO - Iter(train) [ 34350/320000]  base_lr: 9.0285e-05 lr: 9.0285e-06  eta: 1 day, 10:52:47  time: 0.4733  data_time: 0.0094  memory: 5166  grad_norm: 40.9316  loss: 5.5083  decode.loss_cls: 0.1244  decode.loss_mask: 0.1942  decode.loss_dice: 0.1890  decode.d0.loss_cls: 0.7959  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.1957  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.1967  decode.d1.loss_dice: 0.1883  decode.d2.loss_cls: 0.0939  decode.d2.loss_mask: 0.1966  decode.d2.loss_dice: 0.1918  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.1901  decode.d3.loss_dice: 0.1813  decode.d4.loss_cls: 0.1430  decode.d4.loss_mask: 0.1924  decode.d4.loss_dice: 0.1849  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.1939  decode.d5.loss_dice: 0.1783  decode.d6.loss_cls: 0.0861  decode.d6.loss_mask: 0.1918  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.1048  decode.d7.loss_mask: 0.1903  decode.d7.loss_dice: 0.1842  decode.d8.loss_cls: 0.1034  decode.d8.loss_mask: 0.1942  decode.d8.loss_dice: 0.1898
09/28 18:39:16 - mmengine - INFO - Iter(train) [ 34400/320000]  base_lr: 9.0271e-05 lr: 9.0271e-06  eta: 1 day, 10:52:39  time: 0.4727  data_time: 0.0092  memory: 5166  grad_norm: 24.7882  loss: 5.2572  decode.loss_cls: 0.0195  decode.loss_mask: 0.2301  decode.loss_dice: 0.1670  decode.d0.loss_cls: 1.0670  decode.d0.loss_mask: 0.2349  decode.d0.loss_dice: 0.1718  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.1704  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.2320  decode.d2.loss_dice: 0.1664  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.2317  decode.d3.loss_dice: 0.1664  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.2301  decode.d4.loss_dice: 0.1666  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.2312  decode.d5.loss_dice: 0.1697  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.2337  decode.d6.loss_dice: 0.1735  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.2327  decode.d7.loss_dice: 0.1710  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2114
09/28 18:39:39 - mmengine - INFO - Iter(train) [ 34450/320000]  base_lr: 9.0257e-05 lr: 9.0257e-06  eta: 1 day, 10:52:30  time: 0.4734  data_time: 0.0098  memory: 5150  grad_norm: 52.0824  loss: 6.9039  decode.loss_cls: 0.0990  decode.loss_mask: 0.2587  decode.loss_dice: 0.2189  decode.d0.loss_cls: 1.0428  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2205  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.2044  decode.d2.loss_cls: 0.0931  decode.d2.loss_mask: 0.2545  decode.d2.loss_dice: 0.2389  decode.d3.loss_cls: 0.1122  decode.d3.loss_mask: 0.2552  decode.d3.loss_dice: 0.2340  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2034  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.2555  decode.d5.loss_dice: 0.2269  decode.d6.loss_cls: 0.1092  decode.d6.loss_mask: 0.2621  decode.d6.loss_dice: 0.2301  decode.d7.loss_cls: 0.1119  decode.d7.loss_mask: 0.2533  decode.d7.loss_dice: 0.2100  decode.d8.loss_cls: 0.1306  decode.d8.loss_mask: 0.2623  decode.d8.loss_dice: 0.2289
09/28 18:40:03 - mmengine - INFO - Iter(train) [ 34500/320000]  base_lr: 9.0243e-05 lr: 9.0243e-06  eta: 1 day, 10:52:22  time: 0.4718  data_time: 0.0094  memory: 5185  grad_norm: 184.8686  loss: 9.8512  decode.loss_cls: 0.2043  decode.loss_mask: 0.3690  decode.loss_dice: 0.3055  decode.d0.loss_cls: 1.0959  decode.d0.loss_mask: 0.3461  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.2144  decode.d1.loss_mask: 0.3703  decode.d1.loss_dice: 0.3382  decode.d2.loss_cls: 0.2136  decode.d2.loss_mask: 0.4020  decode.d2.loss_dice: 0.3190  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.4468  decode.d3.loss_dice: 0.3027  decode.d4.loss_cls: 0.2135  decode.d4.loss_mask: 0.3935  decode.d4.loss_dice: 0.3234  decode.d5.loss_cls: 0.2189  decode.d5.loss_mask: 0.4044  decode.d5.loss_dice: 0.3087  decode.d6.loss_cls: 0.2036  decode.d6.loss_mask: 0.3732  decode.d6.loss_dice: 0.2668  decode.d7.loss_cls: 0.1960  decode.d7.loss_mask: 0.3747  decode.d7.loss_dice: 0.2826  decode.d8.loss_cls: 0.1847  decode.d8.loss_mask: 0.3771  decode.d8.loss_dice: 0.2874
09/28 18:40:27 - mmengine - INFO - Iter(train) [ 34550/320000]  base_lr: 9.0228e-05 lr: 9.0228e-06  eta: 1 day, 10:52:14  time: 0.4728  data_time: 0.0094  memory: 5166  grad_norm: 204.4790  loss: 6.1075  decode.loss_cls: 0.0462  decode.loss_mask: 0.2845  decode.loss_dice: 0.2209  decode.d0.loss_cls: 0.7617  decode.d0.loss_mask: 0.2862  decode.d0.loss_dice: 0.2105  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.2882  decode.d1.loss_dice: 0.2297  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.2849  decode.d2.loss_dice: 0.2281  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.2300  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.2842  decode.d4.loss_dice: 0.2305  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.2199  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.2839  decode.d6.loss_dice: 0.2231  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.2832  decode.d7.loss_dice: 0.2299  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.2807  decode.d8.loss_dice: 0.2300
09/28 18:40:50 - mmengine - INFO - Iter(train) [ 34600/320000]  base_lr: 9.0214e-05 lr: 9.0214e-06  eta: 1 day, 10:52:05  time: 0.4725  data_time: 0.0095  memory: 5149  grad_norm: 45.7395  loss: 7.5095  decode.loss_cls: 0.0879  decode.loss_mask: 0.2814  decode.loss_dice: 0.2568  decode.d0.loss_cls: 1.0109  decode.d0.loss_mask: 0.2889  decode.d0.loss_dice: 0.2642  decode.d1.loss_cls: 0.2206  decode.d1.loss_mask: 0.2826  decode.d1.loss_dice: 0.2481  decode.d2.loss_cls: 0.1969  decode.d2.loss_mask: 0.2821  decode.d2.loss_dice: 0.2478  decode.d3.loss_cls: 0.1366  decode.d3.loss_mask: 0.2814  decode.d3.loss_dice: 0.2494  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.2821  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.1341  decode.d5.loss_mask: 0.2839  decode.d5.loss_dice: 0.2442  decode.d6.loss_cls: 0.1085  decode.d6.loss_mask: 0.2866  decode.d6.loss_dice: 0.2460  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.2806  decode.d7.loss_dice: 0.2466  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 0.2824  decode.d8.loss_dice: 0.2543
09/28 18:41:14 - mmengine - INFO - Iter(train) [ 34650/320000]  base_lr: 9.0200e-05 lr: 9.0200e-06  eta: 1 day, 10:51:57  time: 0.4738  data_time: 0.0094  memory: 5186  grad_norm: 29.0248  loss: 7.8327  decode.loss_cls: 0.2293  decode.loss_mask: 0.2426  decode.loss_dice: 0.2218  decode.d0.loss_cls: 0.9623  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.2677  decode.d1.loss_cls: 0.2274  decode.d1.loss_mask: 0.2587  decode.d1.loss_dice: 0.2052  decode.d2.loss_cls: 0.2210  decode.d2.loss_mask: 0.2456  decode.d2.loss_dice: 0.2368  decode.d3.loss_cls: 0.2498  decode.d3.loss_mask: 0.2414  decode.d3.loss_dice: 0.2374  decode.d4.loss_cls: 0.2031  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.2648  decode.d5.loss_cls: 0.1974  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2631  decode.d6.loss_cls: 0.2389  decode.d6.loss_mask: 0.2424  decode.d6.loss_dice: 0.2468  decode.d7.loss_cls: 0.2370  decode.d7.loss_mask: 0.2370  decode.d7.loss_dice: 0.2334  decode.d8.loss_cls: 0.2178  decode.d8.loss_mask: 0.2490  decode.d8.loss_dice: 0.1967
09/28 18:41:38 - mmengine - INFO - Iter(train) [ 34700/320000]  base_lr: 9.0186e-05 lr: 9.0186e-06  eta: 1 day, 10:51:48  time: 0.4735  data_time: 0.0097  memory: 5186  grad_norm: 161.6695  loss: 10.4808  decode.loss_cls: 0.2105  decode.loss_mask: 0.4576  decode.loss_dice: 0.2892  decode.d0.loss_cls: 1.2122  decode.d0.loss_mask: 0.3614  decode.d0.loss_dice: 0.3164  decode.d1.loss_cls: 0.3824  decode.d1.loss_mask: 0.3769  decode.d1.loss_dice: 0.3056  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.4827  decode.d2.loss_dice: 0.2925  decode.d3.loss_cls: 0.1331  decode.d3.loss_mask: 0.4623  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.1737  decode.d4.loss_mask: 0.3756  decode.d4.loss_dice: 0.2901  decode.d5.loss_cls: 0.2936  decode.d5.loss_mask: 0.3664  decode.d5.loss_dice: 0.2740  decode.d6.loss_cls: 0.2314  decode.d6.loss_mask: 0.4680  decode.d6.loss_dice: 0.2796  decode.d7.loss_cls: 0.2649  decode.d7.loss_mask: 0.4562  decode.d7.loss_dice: 0.2943  decode.d8.loss_cls: 0.2487  decode.d8.loss_mask: 0.4772  decode.d8.loss_dice: 0.2902
09/28 18:42:01 - mmengine - INFO - Iter(train) [ 34750/320000]  base_lr: 9.0172e-05 lr: 9.0172e-06  eta: 1 day, 10:51:40  time: 0.4731  data_time: 0.0094  memory: 5150  grad_norm: 128.5381  loss: 8.8481  decode.loss_cls: 0.0670  decode.loss_mask: 0.4192  decode.loss_dice: 0.2612  decode.d0.loss_cls: 1.2084  decode.d0.loss_mask: 0.3629  decode.d0.loss_dice: 0.2681  decode.d1.loss_cls: 0.2356  decode.d1.loss_mask: 0.3582  decode.d1.loss_dice: 0.2807  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.4160  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.4402  decode.d3.loss_dice: 0.2620  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.4210  decode.d4.loss_dice: 0.2649  decode.d5.loss_cls: 0.0859  decode.d5.loss_mask: 0.4201  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.4205  decode.d6.loss_dice: 0.2689  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.4300  decode.d7.loss_dice: 0.2612  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.4156  decode.d8.loss_dice: 0.2640
09/28 18:42:23 - mmengine - INFO - Iter(train) [ 34800/320000]  base_lr: 9.0157e-05 lr: 9.0157e-06  eta: 1 day, 10:51:19  time: 0.4334  data_time: 0.0091  memory: 5186  grad_norm: 58.3979  loss: 7.3802  decode.loss_cls: 0.2311  decode.loss_mask: 0.2221  decode.loss_dice: 0.2469  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 0.2230  decode.d0.loss_dice: 0.2402  decode.d1.loss_cls: 0.2068  decode.d1.loss_mask: 0.2228  decode.d1.loss_dice: 0.2088  decode.d2.loss_cls: 0.2412  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.2052  decode.d3.loss_cls: 0.2246  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.1980  decode.d4.loss_cls: 0.2243  decode.d4.loss_mask: 0.2217  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.2002  decode.d5.loss_mask: 0.2179  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.2250  decode.d6.loss_mask: 0.2272  decode.d6.loss_dice: 0.2368  decode.d7.loss_cls: 0.2291  decode.d7.loss_mask: 0.2315  decode.d7.loss_dice: 0.2387  decode.d8.loss_cls: 0.2204  decode.d8.loss_mask: 0.2282  decode.d8.loss_dice: 0.2395
09/28 18:42:45 - mmengine - INFO - Iter(train) [ 34850/320000]  base_lr: 9.0143e-05 lr: 9.0143e-06  eta: 1 day, 10:50:54  time: 0.4328  data_time: 0.0092  memory: 5167  grad_norm: 60.9930  loss: 5.1155  decode.loss_cls: 0.0581  decode.loss_mask: 0.1882  decode.loss_dice: 0.1713  decode.d0.loss_cls: 0.9593  decode.d0.loss_mask: 0.1948  decode.d0.loss_dice: 0.2132  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.1916  decode.d1.loss_dice: 0.1775  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.1894  decode.d2.loss_dice: 0.1741  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.1933  decode.d3.loss_dice: 0.1675  decode.d4.loss_cls: 0.0691  decode.d4.loss_mask: 0.1920  decode.d4.loss_dice: 0.1707  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.1956  decode.d5.loss_dice: 0.1686  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.1901  decode.d6.loss_dice: 0.1745  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.1903  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.1905  decode.d8.loss_dice: 0.1666
09/28 18:43:07 - mmengine - INFO - Iter(train) [ 34900/320000]  base_lr: 9.0129e-05 lr: 9.0129e-06  eta: 1 day, 10:50:30  time: 0.4342  data_time: 0.0092  memory: 5186  grad_norm: 81.1517  loss: 6.5520  decode.loss_cls: 0.0738  decode.loss_mask: 0.2587  decode.loss_dice: 0.2078  decode.d0.loss_cls: 0.9810  decode.d0.loss_mask: 0.2540  decode.d0.loss_dice: 0.2182  decode.d1.loss_cls: 0.1303  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.2057  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.2549  decode.d3.loss_dice: 0.1989  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.2317  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.1966  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.2075  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2540  decode.d7.loss_dice: 0.1960  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.2521  decode.d8.loss_dice: 0.1990
09/28 18:43:29 - mmengine - INFO - Iter(train) [ 34950/320000]  base_lr: 9.0115e-05 lr: 9.0115e-06  eta: 1 day, 10:50:05  time: 0.4337  data_time: 0.0092  memory: 5186  grad_norm: 249.9744  loss: 14.1943  decode.loss_cls: 0.4338  decode.loss_mask: 0.4707  decode.loss_dice: 0.3374  decode.d0.loss_cls: 1.3125  decode.d0.loss_mask: 0.4763  decode.d0.loss_dice: 0.4239  decode.d1.loss_cls: 0.6480  decode.d1.loss_mask: 0.4597  decode.d1.loss_dice: 0.3810  decode.d2.loss_cls: 0.4480  decode.d2.loss_mask: 0.4571  decode.d2.loss_dice: 0.3663  decode.d3.loss_cls: 0.3238  decode.d3.loss_mask: 0.6176  decode.d3.loss_dice: 0.3944  decode.d4.loss_cls: 0.2973  decode.d4.loss_mask: 0.6015  decode.d4.loss_dice: 0.4205  decode.d5.loss_cls: 0.2817  decode.d5.loss_mask: 0.6402  decode.d5.loss_dice: 0.4315  decode.d6.loss_cls: 0.3478  decode.d6.loss_mask: 0.5590  decode.d6.loss_dice: 0.3897  decode.d7.loss_cls: 0.3324  decode.d7.loss_mask: 0.5748  decode.d7.loss_dice: 0.4210  decode.d8.loss_cls: 0.4375  decode.d8.loss_mask: 0.5093  decode.d8.loss_dice: 0.3999
09/28 18:43:50 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:43:50 - mmengine - INFO - Iter(train) [ 35000/320000]  base_lr: 9.0100e-05 lr: 9.0100e-06  eta: 1 day, 10:49:41  time: 0.4335  data_time: 0.0092  memory: 5149  grad_norm: 59.0745  loss: 7.6810  decode.loss_cls: 0.1437  decode.loss_mask: 0.2701  decode.loss_dice: 0.2514  decode.d0.loss_cls: 0.9492  decode.d0.loss_mask: 0.2750  decode.d0.loss_dice: 0.2697  decode.d1.loss_cls: 0.1420  decode.d1.loss_mask: 0.2662  decode.d1.loss_dice: 0.2434  decode.d2.loss_cls: 0.1653  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.1767  decode.d3.loss_mask: 0.2676  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.2073  decode.d4.loss_mask: 0.2749  decode.d4.loss_dice: 0.2419  decode.d5.loss_cls: 0.2093  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.2497  decode.d6.loss_cls: 0.1707  decode.d6.loss_mask: 0.2690  decode.d6.loss_dice: 0.2442  decode.d7.loss_cls: 0.1662  decode.d7.loss_mask: 0.2725  decode.d7.loss_dice: 0.2554  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.2719  decode.d8.loss_dice: 0.2556
09/28 18:44:12 - mmengine - INFO - Iter(train) [ 35050/320000]  base_lr: 9.0086e-05 lr: 9.0086e-06  eta: 1 day, 10:49:16  time: 0.4331  data_time: 0.0091  memory: 5186  grad_norm: 110.2545  loss: 9.6939  decode.loss_cls: 0.3784  decode.loss_mask: 0.2764  decode.loss_dice: 0.3214  decode.d0.loss_cls: 0.8151  decode.d0.loss_mask: 0.2809  decode.d0.loss_dice: 0.3476  decode.d1.loss_cls: 0.2789  decode.d1.loss_mask: 0.2734  decode.d1.loss_dice: 0.3188  decode.d2.loss_cls: 0.3228  decode.d2.loss_mask: 0.2761  decode.d2.loss_dice: 0.3117  decode.d3.loss_cls: 0.3430  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.3517  decode.d4.loss_cls: 0.3315  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.3116  decode.d5.loss_cls: 0.2706  decode.d5.loss_mask: 0.2706  decode.d5.loss_dice: 0.3259  decode.d6.loss_cls: 0.2980  decode.d6.loss_mask: 0.2709  decode.d6.loss_dice: 0.3190  decode.d7.loss_cls: 0.3496  decode.d7.loss_mask: 0.2695  decode.d7.loss_dice: 0.3288  decode.d8.loss_cls: 0.3054  decode.d8.loss_mask: 0.2738  decode.d8.loss_dice: 0.3271
09/28 18:44:34 - mmengine - INFO - Iter(train) [ 35100/320000]  base_lr: 9.0072e-05 lr: 9.0072e-06  eta: 1 day, 10:48:51  time: 0.4332  data_time: 0.0092  memory: 5150  grad_norm: 104.1660  loss: 6.9516  decode.loss_cls: 0.1384  decode.loss_mask: 0.2414  decode.loss_dice: 0.2068  decode.d0.loss_cls: 0.9749  decode.d0.loss_mask: 0.2532  decode.d0.loss_dice: 0.2436  decode.d1.loss_cls: 0.2482  decode.d1.loss_mask: 0.2424  decode.d1.loss_dice: 0.2093  decode.d2.loss_cls: 0.1696  decode.d2.loss_mask: 0.2378  decode.d2.loss_dice: 0.2001  decode.d3.loss_cls: 0.1620  decode.d3.loss_mask: 0.2424  decode.d3.loss_dice: 0.2104  decode.d4.loss_cls: 0.1328  decode.d4.loss_mask: 0.2429  decode.d4.loss_dice: 0.2164  decode.d5.loss_cls: 0.1280  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.2081  decode.d6.loss_cls: 0.1503  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2083  decode.d7.loss_cls: 0.1271  decode.d7.loss_mask: 0.2402  decode.d7.loss_dice: 0.2129  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 0.2420  decode.d8.loss_dice: 0.2134
09/28 18:44:55 - mmengine - INFO - Iter(train) [ 35150/320000]  base_lr: 9.0058e-05 lr: 9.0058e-06  eta: 1 day, 10:48:27  time: 0.4329  data_time: 0.0092  memory: 5149  grad_norm: 92.0668  loss: 6.8090  decode.loss_cls: 0.1225  decode.loss_mask: 0.2720  decode.loss_dice: 0.2032  decode.d0.loss_cls: 0.8062  decode.d0.loss_mask: 0.2699  decode.d0.loss_dice: 0.2138  decode.d1.loss_cls: 0.1139  decode.d1.loss_mask: 0.2576  decode.d1.loss_dice: 0.2042  decode.d2.loss_cls: 0.1102  decode.d2.loss_mask: 0.2646  decode.d2.loss_dice: 0.2061  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.1936  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.2565  decode.d4.loss_dice: 0.2056  decode.d5.loss_cls: 0.2145  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.2261  decode.d6.loss_cls: 0.1591  decode.d6.loss_mask: 0.2570  decode.d6.loss_dice: 0.2073  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.2537  decode.d7.loss_dice: 0.2068  decode.d8.loss_cls: 0.1591  decode.d8.loss_mask: 0.2559  decode.d8.loss_dice: 0.2005
09/28 18:45:17 - mmengine - INFO - Iter(train) [ 35200/320000]  base_lr: 9.0043e-05 lr: 9.0043e-06  eta: 1 day, 10:48:02  time: 0.4340  data_time: 0.0094  memory: 5186  grad_norm: 106.8195  loss: 5.0452  decode.loss_cls: 0.0531  decode.loss_mask: 0.2031  decode.loss_dice: 0.1772  decode.d0.loss_cls: 0.8132  decode.d0.loss_mask: 0.2048  decode.d0.loss_dice: 0.1828  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.2040  decode.d1.loss_dice: 0.1784  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.2065  decode.d2.loss_dice: 0.1725  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.2047  decode.d4.loss_dice: 0.1732  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.2042  decode.d5.loss_dice: 0.1745  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.2043  decode.d6.loss_dice: 0.1750  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.2070  decode.d7.loss_dice: 0.1742  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.2035  decode.d8.loss_dice: 0.1817
09/28 18:45:39 - mmengine - INFO - Iter(train) [ 35250/320000]  base_lr: 9.0029e-05 lr: 9.0029e-06  eta: 1 day, 10:47:38  time: 0.4332  data_time: 0.0094  memory: 5186  grad_norm: 37.2074  loss: 7.2600  decode.loss_cls: 0.1524  decode.loss_mask: 0.2536  decode.loss_dice: 0.2455  decode.d0.loss_cls: 0.9079  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.2503  decode.d1.loss_cls: 0.1925  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.2265  decode.d2.loss_cls: 0.1497  decode.d2.loss_mask: 0.2516  decode.d2.loss_dice: 0.2406  decode.d3.loss_cls: 0.1389  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.2424  decode.d4.loss_cls: 0.1622  decode.d4.loss_mask: 0.2582  decode.d4.loss_dice: 0.2445  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.2505  decode.d5.loss_dice: 0.2433  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.2406  decode.d7.loss_cls: 0.1578  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.2455  decode.d8.loss_cls: 0.1565  decode.d8.loss_mask: 0.2492  decode.d8.loss_dice: 0.2387
09/28 18:46:00 - mmengine - INFO - Iter(train) [ 35300/320000]  base_lr: 9.0015e-05 lr: 9.0015e-06  eta: 1 day, 10:47:13  time: 0.4327  data_time: 0.0094  memory: 5166  grad_norm: 109.1479  loss: 7.8548  decode.loss_cls: 0.1501  decode.loss_mask: 0.2671  decode.loss_dice: 0.2365  decode.d0.loss_cls: 1.0117  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.2593  decode.d1.loss_cls: 0.2589  decode.d1.loss_mask: 0.2709  decode.d1.loss_dice: 0.2437  decode.d2.loss_cls: 0.2322  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.2492  decode.d3.loss_cls: 0.1828  decode.d3.loss_mask: 0.2658  decode.d3.loss_dice: 0.2261  decode.d4.loss_cls: 0.1855  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.2339  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2399  decode.d6.loss_cls: 0.1883  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.2462  decode.d7.loss_cls: 0.1541  decode.d7.loss_mask: 0.2729  decode.d7.loss_dice: 0.2530  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 0.2687  decode.d8.loss_dice: 0.2460
09/28 18:46:22 - mmengine - INFO - Iter(train) [ 35350/320000]  base_lr: 9.0001e-05 lr: 9.0001e-06  eta: 1 day, 10:46:48  time: 0.4330  data_time: 0.0092  memory: 5166  grad_norm: 33.4391  loss: 6.4988  decode.loss_cls: 0.1879  decode.loss_mask: 0.2203  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.9836  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.2015  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.1822  decode.d2.loss_cls: 0.1749  decode.d2.loss_mask: 0.2271  decode.d2.loss_dice: 0.1665  decode.d3.loss_cls: 0.1761  decode.d3.loss_mask: 0.2202  decode.d3.loss_dice: 0.1633  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 0.2043  decode.d4.loss_dice: 0.1676  decode.d5.loss_cls: 0.1813  decode.d5.loss_mask: 0.2055  decode.d5.loss_dice: 0.1743  decode.d6.loss_cls: 0.1741  decode.d6.loss_mask: 0.2088  decode.d6.loss_dice: 0.1742  decode.d7.loss_cls: 0.1521  decode.d7.loss_mask: 0.2109  decode.d7.loss_dice: 0.1787  decode.d8.loss_cls: 0.1756  decode.d8.loss_mask: 0.2120  decode.d8.loss_dice: 0.1681
09/28 18:46:44 - mmengine - INFO - Iter(train) [ 35400/320000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 1 day, 10:46:24  time: 0.4340  data_time: 0.0093  memory: 5167  grad_norm: 39.0363  loss: 7.3822  decode.loss_cls: 0.1624  decode.loss_mask: 0.2786  decode.loss_dice: 0.2275  decode.d0.loss_cls: 0.7706  decode.d0.loss_mask: 0.2818  decode.d0.loss_dice: 0.2501  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.2584  decode.d2.loss_cls: 0.1704  decode.d2.loss_mask: 0.2798  decode.d2.loss_dice: 0.2460  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 0.2743  decode.d3.loss_dice: 0.2127  decode.d4.loss_cls: 0.1805  decode.d4.loss_mask: 0.2759  decode.d4.loss_dice: 0.2291  decode.d5.loss_cls: 0.1743  decode.d5.loss_mask: 0.2777  decode.d5.loss_dice: 0.2154  decode.d6.loss_cls: 0.1614  decode.d6.loss_mask: 0.2748  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.1680  decode.d7.loss_mask: 0.2753  decode.d7.loss_dice: 0.2416  decode.d8.loss_cls: 0.1795  decode.d8.loss_mask: 0.2811  decode.d8.loss_dice: 0.2468
09/28 18:47:05 - mmengine - INFO - Iter(train) [ 35450/320000]  base_lr: 8.9972e-05 lr: 8.9972e-06  eta: 1 day, 10:45:59  time: 0.4339  data_time: 0.0094  memory: 5186  grad_norm: 52.1101  loss: 7.4019  decode.loss_cls: 0.0932  decode.loss_mask: 0.2901  decode.loss_dice: 0.2355  decode.d0.loss_cls: 1.0241  decode.d0.loss_mask: 0.2904  decode.d0.loss_dice: 0.2097  decode.d1.loss_cls: 0.1566  decode.d1.loss_mask: 0.2856  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.1649  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.2114  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.2904  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.1854  decode.d4.loss_mask: 0.2882  decode.d4.loss_dice: 0.2099  decode.d5.loss_cls: 0.2035  decode.d5.loss_mask: 0.2867  decode.d5.loss_dice: 0.2097  decode.d6.loss_cls: 0.1393  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.2087  decode.d7.loss_cls: 0.1106  decode.d7.loss_mask: 0.2945  decode.d7.loss_dice: 0.2373  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.2961  decode.d8.loss_dice: 0.2299
09/28 18:47:27 - mmengine - INFO - Iter(train) [ 35500/320000]  base_lr: 8.9958e-05 lr: 8.9958e-06  eta: 1 day, 10:45:35  time: 0.4335  data_time: 0.0093  memory: 5186  grad_norm: 51.7445  loss: 5.3073  decode.loss_cls: 0.0556  decode.loss_mask: 0.2346  decode.loss_dice: 0.1765  decode.d0.loss_cls: 0.8207  decode.d0.loss_mask: 0.2371  decode.d0.loss_dice: 0.1821  decode.d1.loss_cls: 0.0548  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.1715  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.1748  decode.d3.loss_cls: 0.0334  decode.d3.loss_mask: 0.2338  decode.d3.loss_dice: 0.1711  decode.d4.loss_cls: 0.0277  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.1702  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.2314  decode.d5.loss_dice: 0.1756  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.2314  decode.d6.loss_dice: 0.1743  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.2307  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0533  decode.d8.loss_mask: 0.2321  decode.d8.loss_dice: 0.1721
09/28 18:47:49 - mmengine - INFO - Iter(train) [ 35550/320000]  base_lr: 8.9944e-05 lr: 8.9944e-06  eta: 1 day, 10:45:14  time: 0.4708  data_time: 0.0090  memory: 5166  grad_norm: 109.8128  loss: 6.2528  decode.loss_cls: 0.0497  decode.loss_mask: 0.2750  decode.loss_dice: 0.2120  decode.d0.loss_cls: 0.9923  decode.d0.loss_mask: 0.2736  decode.d0.loss_dice: 0.2200  decode.d1.loss_cls: 0.0808  decode.d1.loss_mask: 0.2683  decode.d1.loss_dice: 0.2118  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.2047  decode.d3.loss_cls: 0.0310  decode.d3.loss_mask: 0.2727  decode.d3.loss_dice: 0.2051  decode.d4.loss_cls: 0.0327  decode.d4.loss_mask: 0.2682  decode.d4.loss_dice: 0.2050  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.2679  decode.d5.loss_dice: 0.2105  decode.d6.loss_cls: 0.0429  decode.d6.loss_mask: 0.2675  decode.d6.loss_dice: 0.2106  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.2726  decode.d7.loss_dice: 0.2364  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.2684  decode.d8.loss_dice: 0.2082
09/28 18:48:13 - mmengine - INFO - Iter(train) [ 35600/320000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 1 day, 10:45:05  time: 0.4729  data_time: 0.0097  memory: 5150  grad_norm: 38.0952  loss: 5.9826  decode.loss_cls: 0.0517  decode.loss_mask: 0.2431  decode.loss_dice: 0.2291  decode.d0.loss_cls: 0.9477  decode.d0.loss_mask: 0.2410  decode.d0.loss_dice: 0.2070  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.0797  decode.d2.loss_mask: 0.2413  decode.d2.loss_dice: 0.2002  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 0.2402  decode.d3.loss_dice: 0.1912  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.2387  decode.d4.loss_dice: 0.1941  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.2397  decode.d5.loss_dice: 0.1982  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.1986  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.2397  decode.d7.loss_dice: 0.2192  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.2414  decode.d8.loss_dice: 0.2008
09/28 18:48:36 - mmengine - INFO - Iter(train) [ 35650/320000]  base_lr: 8.9915e-05 lr: 8.9915e-06  eta: 1 day, 10:44:56  time: 0.4712  data_time: 0.0092  memory: 5167  grad_norm: 31.2820  loss: 5.9764  decode.loss_cls: 0.0306  decode.loss_mask: 0.2081  decode.loss_dice: 0.2640  decode.d0.loss_cls: 0.7896  decode.d0.loss_mask: 0.2080  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.2066  decode.d1.loss_dice: 0.2680  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.2110  decode.d2.loss_dice: 0.2964  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.2093  decode.d3.loss_dice: 0.2721  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.2076  decode.d4.loss_dice: 0.2704  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.2065  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.2076  decode.d6.loss_dice: 0.2574  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.2054  decode.d7.loss_dice: 0.2638  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.2082  decode.d8.loss_dice: 0.2557
09/28 18:49:00 - mmengine - INFO - Iter(train) [ 35700/320000]  base_lr: 8.9901e-05 lr: 8.9901e-06  eta: 1 day, 10:44:46  time: 0.4720  data_time: 0.0096  memory: 5150  grad_norm: 36.4882  loss: 6.2201  decode.loss_cls: 0.1619  decode.loss_mask: 0.1966  decode.loss_dice: 0.1691  decode.d0.loss_cls: 0.9840  decode.d0.loss_mask: 0.2038  decode.d0.loss_dice: 0.1895  decode.d1.loss_cls: 0.1501  decode.d1.loss_mask: 0.1973  decode.d1.loss_dice: 0.1946  decode.d2.loss_cls: 0.1671  decode.d2.loss_mask: 0.1982  decode.d2.loss_dice: 0.1684  decode.d3.loss_cls: 0.1638  decode.d3.loss_mask: 0.2000  decode.d3.loss_dice: 0.1688  decode.d4.loss_cls: 0.1755  decode.d4.loss_mask: 0.2004  decode.d4.loss_dice: 0.1740  decode.d5.loss_cls: 0.1742  decode.d5.loss_mask: 0.1971  decode.d5.loss_dice: 0.1737  decode.d6.loss_cls: 0.1494  decode.d6.loss_mask: 0.1967  decode.d6.loss_dice: 0.1774  decode.d7.loss_cls: 0.1544  decode.d7.loss_mask: 0.1976  decode.d7.loss_dice: 0.1738  decode.d8.loss_cls: 0.1871  decode.d8.loss_mask: 0.1971  decode.d8.loss_dice: 0.1785
09/28 18:49:23 - mmengine - INFO - Iter(train) [ 35750/320000]  base_lr: 8.9887e-05 lr: 8.9887e-06  eta: 1 day, 10:44:37  time: 0.4714  data_time: 0.0094  memory: 5186  grad_norm: 73.4233  loss: 6.1922  decode.loss_cls: 0.1920  decode.loss_mask: 0.2322  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.8472  decode.d0.loss_mask: 0.2367  decode.d0.loss_dice: 0.2066  decode.d1.loss_cls: 0.1135  decode.d1.loss_mask: 0.2307  decode.d1.loss_dice: 0.1963  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.2294  decode.d2.loss_dice: 0.2004  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.2333  decode.d3.loss_dice: 0.2185  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.2345  decode.d4.loss_dice: 0.2116  decode.d5.loss_cls: 0.1348  decode.d5.loss_mask: 0.2296  decode.d5.loss_dice: 0.2032  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.2296  decode.d6.loss_dice: 0.1853  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 0.2305  decode.d7.loss_dice: 0.2037  decode.d8.loss_cls: 0.1036  decode.d8.loss_mask: 0.2301  decode.d8.loss_dice: 0.2104
09/28 18:49:47 - mmengine - INFO - Iter(train) [ 35800/320000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 1 day, 10:44:27  time: 0.4721  data_time: 0.0092  memory: 5186  grad_norm: 64.8170  loss: 6.1761  decode.loss_cls: 0.0462  decode.loss_mask: 0.2670  decode.loss_dice: 0.2062  decode.d0.loss_cls: 0.8963  decode.d0.loss_mask: 0.2730  decode.d0.loss_dice: 0.2171  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.2712  decode.d1.loss_dice: 0.2088  decode.d2.loss_cls: 0.0169  decode.d2.loss_mask: 0.2695  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.2698  decode.d3.loss_dice: 0.2145  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2143  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.2701  decode.d5.loss_dice: 0.2099  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.2707  decode.d6.loss_dice: 0.2081  decode.d7.loss_cls: 0.0629  decode.d7.loss_mask: 0.2695  decode.d7.loss_dice: 0.2091  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.2728  decode.d8.loss_dice: 0.2155
09/28 18:50:10 - mmengine - INFO - Iter(train) [ 35850/320000]  base_lr: 8.9858e-05 lr: 8.9858e-06  eta: 1 day, 10:44:11  time: 0.4329  data_time: 0.0090  memory: 5186  grad_norm: 39.3121  loss: 4.8184  decode.loss_cls: 0.0357  decode.loss_mask: 0.2041  decode.loss_dice: 0.1648  decode.d0.loss_cls: 0.9170  decode.d0.loss_mask: 0.1975  decode.d0.loss_dice: 0.1723  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.1670  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.2017  decode.d2.loss_dice: 0.1672  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.2008  decode.d3.loss_dice: 0.1656  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.2020  decode.d4.loss_dice: 0.1645  decode.d5.loss_cls: 0.0315  decode.d5.loss_mask: 0.2031  decode.d5.loss_dice: 0.1636  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.2036  decode.d6.loss_dice: 0.1638  decode.d7.loss_cls: 0.0323  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1651  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.2022  decode.d8.loss_dice: 0.1640
09/28 18:50:31 - mmengine - INFO - Iter(train) [ 35900/320000]  base_lr: 8.9844e-05 lr: 8.9844e-06  eta: 1 day, 10:43:46  time: 0.4333  data_time: 0.0091  memory: 5167  grad_norm: 43.6025  loss: 5.9121  decode.loss_cls: 0.0285  decode.loss_mask: 0.2863  decode.loss_dice: 0.1833  decode.d0.loss_cls: 0.8552  decode.d0.loss_mask: 0.2877  decode.d0.loss_dice: 0.1886  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.2919  decode.d1.loss_dice: 0.1919  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.2833  decode.d2.loss_dice: 0.1898  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.2881  decode.d3.loss_dice: 0.1893  decode.d4.loss_cls: 0.0323  decode.d4.loss_mask: 0.2841  decode.d4.loss_dice: 0.1902  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.2843  decode.d5.loss_dice: 0.1921  decode.d6.loss_cls: 0.0382  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.1892  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.2903  decode.d7.loss_dice: 0.1914  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.2844  decode.d8.loss_dice: 0.1891
09/28 18:50:53 - mmengine - INFO - Iter(train) [ 35950/320000]  base_lr: 8.9830e-05 lr: 8.9830e-06  eta: 1 day, 10:43:23  time: 0.4326  data_time: 0.0090  memory: 5167  grad_norm: 62.2751  loss: 4.9944  decode.loss_cls: 0.0283  decode.loss_mask: 0.1868  decode.loss_dice: 0.1724  decode.d0.loss_cls: 0.9806  decode.d0.loss_mask: 0.1913  decode.d0.loss_dice: 0.1791  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.1950  decode.d1.loss_dice: 0.1872  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.1985  decode.d2.loss_dice: 0.1897  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.1956  decode.d3.loss_dice: 0.1782  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.1956  decode.d4.loss_dice: 0.1804  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.1916  decode.d5.loss_dice: 0.1784  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.1902  decode.d6.loss_dice: 0.1782  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.1908  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.1866  decode.d8.loss_dice: 0.1732
09/28 18:51:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:51:15 - mmengine - INFO - Iter(train) [ 36000/320000]  base_lr: 8.9816e-05 lr: 8.9816e-06  eta: 1 day, 10:42:58  time: 0.4329  data_time: 0.0091  memory: 5186  grad_norm: 161.4162  loss: 8.6951  decode.loss_cls: 0.2409  decode.loss_mask: 0.3458  decode.loss_dice: 0.2365  decode.d0.loss_cls: 1.0523  decode.d0.loss_mask: 0.3487  decode.d0.loss_dice: 0.2568  decode.d1.loss_cls: 0.2719  decode.d1.loss_mask: 0.3415  decode.d1.loss_dice: 0.2506  decode.d2.loss_cls: 0.2110  decode.d2.loss_mask: 0.3268  decode.d2.loss_dice: 0.2192  decode.d3.loss_cls: 0.1510  decode.d3.loss_mask: 0.3260  decode.d3.loss_dice: 0.2167  decode.d4.loss_cls: 0.1394  decode.d4.loss_mask: 0.3396  decode.d4.loss_dice: 0.2222  decode.d5.loss_cls: 0.1978  decode.d5.loss_mask: 0.3300  decode.d5.loss_dice: 0.2183  decode.d6.loss_cls: 0.1924  decode.d6.loss_mask: 0.3590  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.1832  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.2545  decode.d8.loss_cls: 0.2644  decode.d8.loss_mask: 0.3500  decode.d8.loss_dice: 0.2360
09/28 18:51:37 - mmengine - INFO - Iter(train) [ 36050/320000]  base_lr: 8.9802e-05 lr: 8.9802e-06  eta: 1 day, 10:42:33  time: 0.4329  data_time: 0.0090  memory: 5186  grad_norm: 138.2583  loss: 7.5913  decode.loss_cls: 0.1440  decode.loss_mask: 0.3559  decode.loss_dice: 0.2074  decode.d0.loss_cls: 0.8746  decode.d0.loss_mask: 0.2999  decode.d0.loss_dice: 0.2049  decode.d1.loss_cls: 0.1757  decode.d1.loss_mask: 0.3169  decode.d1.loss_dice: 0.1864  decode.d2.loss_cls: 0.0371  decode.d2.loss_mask: 0.4399  decode.d2.loss_dice: 0.1995  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.4468  decode.d3.loss_dice: 0.2013  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.4455  decode.d4.loss_dice: 0.2020  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.4540  decode.d5.loss_dice: 0.2145  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.4575  decode.d6.loss_dice: 0.2153  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.4414  decode.d7.loss_dice: 0.2043  decode.d8.loss_cls: 0.0171  decode.d8.loss_mask: 0.4616  decode.d8.loss_dice: 0.2151
09/28 18:51:58 - mmengine - INFO - Iter(train) [ 36100/320000]  base_lr: 8.9787e-05 lr: 8.9787e-06  eta: 1 day, 10:42:08  time: 0.4328  data_time: 0.0092  memory: 5186  grad_norm: 132.1886  loss: 7.3889  decode.loss_cls: 0.1745  decode.loss_mask: 0.3246  decode.loss_dice: 0.2537  decode.d0.loss_cls: 1.0215  decode.d0.loss_mask: 0.3028  decode.d0.loss_dice: 0.2254  decode.d1.loss_cls: 0.1116  decode.d1.loss_mask: 0.3050  decode.d1.loss_dice: 0.2219  decode.d2.loss_cls: 0.1606  decode.d2.loss_mask: 0.2992  decode.d2.loss_dice: 0.2077  decode.d3.loss_cls: 0.1085  decode.d3.loss_mask: 0.2871  decode.d3.loss_dice: 0.1986  decode.d4.loss_cls: 0.1144  decode.d4.loss_mask: 0.3031  decode.d4.loss_dice: 0.2367  decode.d5.loss_cls: 0.1082  decode.d5.loss_mask: 0.3036  decode.d5.loss_dice: 0.2172  decode.d6.loss_cls: 0.1024  decode.d6.loss_mask: 0.3097  decode.d6.loss_dice: 0.2213  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.3080  decode.d7.loss_dice: 0.2059  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 0.3026  decode.d8.loss_dice: 0.2234
09/28 18:52:20 - mmengine - INFO - Iter(train) [ 36150/320000]  base_lr: 8.9773e-05 lr: 8.9773e-06  eta: 1 day, 10:41:43  time: 0.4335  data_time: 0.0093  memory: 5166  grad_norm: 91.3289  loss: 5.7576  decode.loss_cls: 0.0336  decode.loss_mask: 0.2425  decode.loss_dice: 0.1915  decode.d0.loss_cls: 0.8172  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.2171  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.1911  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.2452  decode.d2.loss_dice: 0.1938  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.2498  decode.d3.loss_dice: 0.1930  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.2484  decode.d4.loss_dice: 0.2019  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.2532  decode.d5.loss_dice: 0.2038  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.2506  decode.d6.loss_dice: 0.1949  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 0.2450  decode.d7.loss_dice: 0.1918  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.2469  decode.d8.loss_dice: 0.1955
09/28 18:52:42 - mmengine - INFO - Iter(train) [ 36200/320000]  base_lr: 8.9759e-05 lr: 8.9759e-06  eta: 1 day, 10:41:19  time: 0.4330  data_time: 0.0091  memory: 5150  grad_norm: 50.2428  loss: 4.7072  decode.loss_cls: 0.0180  decode.loss_mask: 0.2013  decode.loss_dice: 0.1511  decode.d0.loss_cls: 0.8918  decode.d0.loss_mask: 0.2079  decode.d0.loss_dice: 0.1569  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.2028  decode.d1.loss_dice: 0.1549  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.2023  decode.d2.loss_dice: 0.1555  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.2046  decode.d3.loss_dice: 0.1570  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.2026  decode.d4.loss_dice: 0.1542  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.2019  decode.d5.loss_dice: 0.1549  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.2010  decode.d6.loss_dice: 0.1553  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.2012  decode.d7.loss_dice: 0.1542  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.2002  decode.d8.loss_dice: 0.1526
09/28 18:53:03 - mmengine - INFO - Iter(train) [ 36250/320000]  base_lr: 8.9745e-05 lr: 8.9745e-06  eta: 1 day, 10:40:54  time: 0.4337  data_time: 0.0093  memory: 5166  grad_norm: 46.1998  loss: 5.9090  decode.loss_cls: 0.0438  decode.loss_mask: 0.2190  decode.loss_dice: 0.2252  decode.d0.loss_cls: 0.8040  decode.d0.loss_mask: 0.2179  decode.d0.loss_dice: 0.2337  decode.d1.loss_cls: 0.1244  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.1183  decode.d2.loss_mask: 0.2207  decode.d2.loss_dice: 0.2332  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.2166  decode.d3.loss_dice: 0.2217  decode.d4.loss_cls: 0.0982  decode.d4.loss_mask: 0.2176  decode.d4.loss_dice: 0.2218  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.2210  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.2169  decode.d6.loss_dice: 0.2199  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.2170  decode.d7.loss_dice: 0.2246  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.2178  decode.d8.loss_dice: 0.2301
09/28 18:53:25 - mmengine - INFO - Iter(train) [ 36300/320000]  base_lr: 8.9730e-05 lr: 8.9730e-06  eta: 1 day, 10:40:30  time: 0.4340  data_time: 0.0092  memory: 5150  grad_norm: 148.7586  loss: 5.4038  decode.loss_cls: 0.0295  decode.loss_mask: 0.2431  decode.loss_dice: 0.1754  decode.d0.loss_cls: 1.0037  decode.d0.loss_mask: 0.2398  decode.d0.loss_dice: 0.1912  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 0.2728  decode.d1.loss_dice: 0.1881  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.2468  decode.d2.loss_dice: 0.1821  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.2315  decode.d3.loss_dice: 0.1704  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.2334  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.2266  decode.d5.loss_dice: 0.1729  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.2305  decode.d6.loss_dice: 0.1736  decode.d7.loss_cls: 0.0537  decode.d7.loss_mask: 0.2292  decode.d7.loss_dice: 0.1770  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.2311  decode.d8.loss_dice: 0.1767
09/28 18:53:47 - mmengine - INFO - Iter(train) [ 36350/320000]  base_lr: 8.9716e-05 lr: 8.9716e-06  eta: 1 day, 10:40:05  time: 0.4327  data_time: 0.0091  memory: 5149  grad_norm: 28.9939  loss: 6.4600  decode.loss_cls: 0.1329  decode.loss_mask: 0.2182  decode.loss_dice: 0.2235  decode.d0.loss_cls: 1.0093  decode.d0.loss_mask: 0.2161  decode.d0.loss_dice: 0.2502  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.2161  decode.d1.loss_dice: 0.2313  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.2208  decode.d2.loss_dice: 0.2300  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.2120  decode.d3.loss_dice: 0.2401  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 0.2186  decode.d4.loss_dice: 0.2261  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.2314  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.2407  decode.d7.loss_cls: 0.1045  decode.d7.loss_mask: 0.2187  decode.d7.loss_dice: 0.2408  decode.d8.loss_cls: 0.1084  decode.d8.loss_mask: 0.2147  decode.d8.loss_dice: 0.2325
09/28 18:54:08 - mmengine - INFO - Iter(train) [ 36400/320000]  base_lr: 8.9702e-05 lr: 8.9702e-06  eta: 1 day, 10:39:40  time: 0.4328  data_time: 0.0090  memory: 5167  grad_norm: 164.8392  loss: 8.1743  decode.loss_cls: 0.2344  decode.loss_mask: 0.2490  decode.loss_dice: 0.2586  decode.d0.loss_cls: 0.9501  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.2629  decode.d1.loss_cls: 0.2451  decode.d1.loss_mask: 0.2539  decode.d1.loss_dice: 0.2541  decode.d2.loss_cls: 0.2718  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.2571  decode.d3.loss_cls: 0.2457  decode.d3.loss_mask: 0.2508  decode.d3.loss_dice: 0.2532  decode.d4.loss_cls: 0.2498  decode.d4.loss_mask: 0.2509  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.2427  decode.d5.loss_mask: 0.2464  decode.d5.loss_dice: 0.2376  decode.d6.loss_cls: 0.2283  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2223  decode.d7.loss_cls: 0.2701  decode.d7.loss_mask: 0.2475  decode.d7.loss_dice: 0.2398  decode.d8.loss_cls: 0.2502  decode.d8.loss_mask: 0.2513  decode.d8.loss_dice: 0.2440
09/28 18:54:30 - mmengine - INFO - Iter(train) [ 36450/320000]  base_lr: 8.9688e-05 lr: 8.9688e-06  eta: 1 day, 10:39:15  time: 0.4328  data_time: 0.0090  memory: 5166  grad_norm: 87.6662  loss: 6.5311  decode.loss_cls: 0.0331  decode.loss_mask: 0.2758  decode.loss_dice: 0.2486  decode.d0.loss_cls: 0.7556  decode.d0.loss_mask: 0.2867  decode.d0.loss_dice: 0.2413  decode.d1.loss_cls: 0.0976  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.2509  decode.d2.loss_cls: 0.1256  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.2604  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.2474  decode.d4.loss_cls: 0.0241  decode.d4.loss_mask: 0.2775  decode.d4.loss_dice: 0.2446  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.2775  decode.d5.loss_dice: 0.2446  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.2741  decode.d6.loss_dice: 0.2372  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.2697  decode.d7.loss_dice: 0.2397  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.2352
09/28 18:54:51 - mmengine - INFO - Iter(train) [ 36500/320000]  base_lr: 8.9673e-05 lr: 8.9673e-06  eta: 1 day, 10:38:51  time: 0.4330  data_time: 0.0090  memory: 5166  grad_norm: 88.0574  loss: 6.5813  decode.loss_cls: 0.0542  decode.loss_mask: 0.3994  decode.loss_dice: 0.2119  decode.d0.loss_cls: 0.9157  decode.d0.loss_mask: 0.2481  decode.d0.loss_dice: 0.2021  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.1832  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.2026  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.3692  decode.d3.loss_dice: 0.1968  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.3276  decode.d4.loss_dice: 0.1854  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.3463  decode.d5.loss_dice: 0.2040  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 0.2965  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.3279  decode.d7.loss_dice: 0.2056  decode.d8.loss_cls: 0.0656  decode.d8.loss_mask: 0.2740  decode.d8.loss_dice: 0.1998
09/28 18:55:13 - mmengine - INFO - Iter(train) [ 36550/320000]  base_lr: 8.9659e-05 lr: 8.9659e-06  eta: 1 day, 10:38:26  time: 0.4340  data_time: 0.0091  memory: 5166  grad_norm: 33.0503  loss: 4.8922  decode.loss_cls: 0.0092  decode.loss_mask: 0.2167  decode.loss_dice: 0.1621  decode.d0.loss_cls: 0.8066  decode.d0.loss_mask: 0.2216  decode.d0.loss_dice: 0.1694  decode.d1.loss_cls: 0.1106  decode.d1.loss_mask: 0.2198  decode.d1.loss_dice: 0.1629  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.2141  decode.d2.loss_dice: 0.1618  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.2189  decode.d3.loss_dice: 0.1617  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.1606  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.2145  decode.d5.loss_dice: 0.1582  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.2151  decode.d6.loss_dice: 0.1638  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.2175  decode.d7.loss_dice: 0.1631  decode.d8.loss_cls: 0.0106  decode.d8.loss_mask: 0.2150  decode.d8.loss_dice: 0.1598
09/28 18:55:35 - mmengine - INFO - Iter(train) [ 36600/320000]  base_lr: 8.9645e-05 lr: 8.9645e-06  eta: 1 day, 10:38:02  time: 0.4341  data_time: 0.0091  memory: 5167  grad_norm: 72.4473  loss: 7.6295  decode.loss_cls: 0.2480  decode.loss_mask: 0.2319  decode.loss_dice: 0.2463  decode.d0.loss_cls: 0.8030  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2458  decode.d1.loss_cls: 0.2450  decode.d1.loss_mask: 0.2304  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.1856  decode.d2.loss_mask: 0.2346  decode.d2.loss_dice: 0.2464  decode.d3.loss_cls: 0.2291  decode.d3.loss_mask: 0.2354  decode.d3.loss_dice: 0.2465  decode.d4.loss_cls: 0.2046  decode.d4.loss_mask: 0.2352  decode.d4.loss_dice: 0.2531  decode.d5.loss_cls: 0.2271  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.2416  decode.d6.loss_cls: 0.1898  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2413  decode.d7.loss_cls: 0.2462  decode.d7.loss_mask: 0.2336  decode.d7.loss_dice: 0.2475  decode.d8.loss_cls: 0.2688  decode.d8.loss_mask: 0.2315  decode.d8.loss_dice: 0.2334
09/28 18:55:57 - mmengine - INFO - Iter(train) [ 36650/320000]  base_lr: 8.9631e-05 lr: 8.9631e-06  eta: 1 day, 10:37:37  time: 0.4332  data_time: 0.0091  memory: 5167  grad_norm: 27.7441  loss: 6.0311  decode.loss_cls: 0.1189  decode.loss_mask: 0.2139  decode.loss_dice: 0.2057  decode.d0.loss_cls: 0.8566  decode.d0.loss_mask: 0.2148  decode.d0.loss_dice: 0.2228  decode.d1.loss_cls: 0.1223  decode.d1.loss_mask: 0.2141  decode.d1.loss_dice: 0.1985  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 0.2146  decode.d2.loss_dice: 0.2140  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.2148  decode.d3.loss_dice: 0.2001  decode.d4.loss_cls: 0.1092  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1975  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.2181  decode.d6.loss_dice: 0.1987  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.2131  decode.d7.loss_dice: 0.2035  decode.d8.loss_cls: 0.1067  decode.d8.loss_mask: 0.2159  decode.d8.loss_dice: 0.2025
09/28 18:56:18 - mmengine - INFO - Iter(train) [ 36700/320000]  base_lr: 8.9617e-05 lr: 8.9617e-06  eta: 1 day, 10:37:13  time: 0.4334  data_time: 0.0091  memory: 5150  grad_norm: 21.5769  loss: 5.5874  decode.loss_cls: 0.0079  decode.loss_mask: 0.2655  decode.loss_dice: 0.2104  decode.d0.loss_cls: 0.7692  decode.d0.loss_mask: 0.2689  decode.d0.loss_dice: 0.2013  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.2630  decode.d1.loss_dice: 0.2030  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.2664  decode.d2.loss_dice: 0.2066  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.2037  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.2655  decode.d4.loss_dice: 0.2117  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.2670  decode.d5.loss_dice: 0.2091  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.2608  decode.d6.loss_dice: 0.2057  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.2645  decode.d7.loss_dice: 0.2066  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.2123
09/28 18:56:40 - mmengine - INFO - Iter(train) [ 36750/320000]  base_lr: 8.9602e-05 lr: 8.9602e-06  eta: 1 day, 10:36:48  time: 0.4334  data_time: 0.0091  memory: 5186  grad_norm: 181.1679  loss: 6.0277  decode.loss_cls: 0.0937  decode.loss_mask: 0.2134  decode.loss_dice: 0.2150  decode.d0.loss_cls: 0.8261  decode.d0.loss_mask: 0.2156  decode.d0.loss_dice: 0.2198  decode.d1.loss_cls: 0.1222  decode.d1.loss_mask: 0.2153  decode.d1.loss_dice: 0.2089  decode.d2.loss_cls: 0.0874  decode.d2.loss_mask: 0.2166  decode.d2.loss_dice: 0.2286  decode.d3.loss_cls: 0.0994  decode.d3.loss_mask: 0.2129  decode.d3.loss_dice: 0.2117  decode.d4.loss_cls: 0.1050  decode.d4.loss_mask: 0.2127  decode.d4.loss_dice: 0.2273  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.2319  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.2138  decode.d6.loss_dice: 0.2197  decode.d7.loss_cls: 0.0881  decode.d7.loss_mask: 0.2161  decode.d7.loss_dice: 0.2237  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.2168  decode.d8.loss_dice: 0.2129
09/28 18:57:02 - mmengine - INFO - Iter(train) [ 36800/320000]  base_lr: 8.9588e-05 lr: 8.9588e-06  eta: 1 day, 10:36:24  time: 0.4345  data_time: 0.0093  memory: 5167  grad_norm: 65.6483  loss: 7.2026  decode.loss_cls: 0.1661  decode.loss_mask: 0.2374  decode.loss_dice: 0.2421  decode.d0.loss_cls: 0.8801  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2632  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.2392  decode.d1.loss_dice: 0.2583  decode.d2.loss_cls: 0.1445  decode.d2.loss_mask: 0.2411  decode.d2.loss_dice: 0.2472  decode.d3.loss_cls: 0.1748  decode.d3.loss_mask: 0.2380  decode.d3.loss_dice: 0.2554  decode.d4.loss_cls: 0.1343  decode.d4.loss_mask: 0.2378  decode.d4.loss_dice: 0.2495  decode.d5.loss_cls: 0.1757  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2586  decode.d6.loss_cls: 0.1993  decode.d6.loss_mask: 0.2363  decode.d6.loss_dice: 0.2417  decode.d7.loss_cls: 0.2022  decode.d7.loss_mask: 0.2377  decode.d7.loss_dice: 0.2495  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.2505
09/28 18:57:23 - mmengine - INFO - Iter(train) [ 36850/320000]  base_lr: 8.9574e-05 lr: 8.9574e-06  eta: 1 day, 10:36:00  time: 0.4332  data_time: 0.0090  memory: 5150  grad_norm: 63.3110  loss: 9.3001  decode.loss_cls: 0.1989  decode.loss_mask: 0.2920  decode.loss_dice: 0.3023  decode.d0.loss_cls: 1.1771  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.3306  decode.d1.loss_cls: 0.2260  decode.d1.loss_mask: 0.2986  decode.d1.loss_dice: 0.3276  decode.d2.loss_cls: 0.2404  decode.d2.loss_mask: 0.3053  decode.d2.loss_dice: 0.3364  decode.d3.loss_cls: 0.2145  decode.d3.loss_mask: 0.2988  decode.d3.loss_dice: 0.2930  decode.d4.loss_cls: 0.1883  decode.d4.loss_mask: 0.2913  decode.d4.loss_dice: 0.2845  decode.d5.loss_cls: 0.2366  decode.d5.loss_mask: 0.2974  decode.d5.loss_dice: 0.3140  decode.d6.loss_cls: 0.2067  decode.d6.loss_mask: 0.2964  decode.d6.loss_dice: 0.3110  decode.d7.loss_cls: 0.2342  decode.d7.loss_mask: 0.2959  decode.d7.loss_dice: 0.2991  decode.d8.loss_cls: 0.3495  decode.d8.loss_mask: 0.2902  decode.d8.loss_dice: 0.2645
09/28 18:57:45 - mmengine - INFO - Iter(train) [ 36900/320000]  base_lr: 8.9560e-05 lr: 8.9560e-06  eta: 1 day, 10:35:35  time: 0.4345  data_time: 0.0096  memory: 5186  grad_norm: 77.5072  loss: 6.6017  decode.loss_cls: 0.0739  decode.loss_mask: 0.2330  decode.loss_dice: 0.2749  decode.d0.loss_cls: 0.9486  decode.d0.loss_mask: 0.2224  decode.d0.loss_dice: 0.2420  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 0.2248  decode.d1.loss_dice: 0.2503  decode.d2.loss_cls: 0.1139  decode.d2.loss_mask: 0.2212  decode.d2.loss_dice: 0.2573  decode.d3.loss_cls: 0.1024  decode.d3.loss_mask: 0.2226  decode.d3.loss_dice: 0.2410  decode.d4.loss_cls: 0.1012  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2448  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2316  decode.d5.loss_dice: 0.2795  decode.d6.loss_cls: 0.0943  decode.d6.loss_mask: 0.2252  decode.d6.loss_dice: 0.2651  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.2264  decode.d7.loss_dice: 0.2717  decode.d8.loss_cls: 0.0824  decode.d8.loss_mask: 0.2245  decode.d8.loss_dice: 0.2677
09/28 18:58:07 - mmengine - INFO - Iter(train) [ 36950/320000]  base_lr: 8.9545e-05 lr: 8.9545e-06  eta: 1 day, 10:35:11  time: 0.4342  data_time: 0.0093  memory: 5166  grad_norm: 83.9595  loss: 7.1527  decode.loss_cls: 0.0507  decode.loss_mask: 0.2809  decode.loss_dice: 0.2278  decode.d0.loss_cls: 1.1379  decode.d0.loss_mask: 0.2925  decode.d0.loss_dice: 0.2583  decode.d1.loss_cls: 0.0995  decode.d1.loss_mask: 0.2838  decode.d1.loss_dice: 0.2465  decode.d2.loss_cls: 0.0946  decode.d2.loss_mask: 0.2789  decode.d2.loss_dice: 0.2381  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.2944  decode.d3.loss_dice: 0.2627  decode.d4.loss_cls: 0.1742  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.2381  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.2425  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.2396  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.2880  decode.d7.loss_dice: 0.2371  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.2922  decode.d8.loss_dice: 0.2316
09/28 18:58:28 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 18:58:28 - mmengine - INFO - Iter(train) [ 37000/320000]  base_lr: 8.9531e-05 lr: 8.9531e-06  eta: 1 day, 10:34:47  time: 0.4335  data_time: 0.0092  memory: 5166  grad_norm: 25.8016  loss: 4.7135  decode.loss_cls: 0.0540  decode.loss_mask: 0.1802  decode.loss_dice: 0.1484  decode.d0.loss_cls: 0.9992  decode.d0.loss_mask: 0.1843  decode.d0.loss_dice: 0.1559  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 0.1831  decode.d1.loss_dice: 0.1506  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.1855  decode.d2.loss_dice: 0.1508  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.1800  decode.d3.loss_dice: 0.1463  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.1832  decode.d4.loss_dice: 0.1484  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.1783  decode.d5.loss_dice: 0.1476  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.1779  decode.d6.loss_dice: 0.1459  decode.d7.loss_cls: 0.0498  decode.d7.loss_mask: 0.1779  decode.d7.loss_dice: 0.1507  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.1802  decode.d8.loss_dice: 0.1512
09/28 18:58:50 - mmengine - INFO - Iter(train) [ 37050/320000]  base_lr: 8.9517e-05 lr: 8.9517e-06  eta: 1 day, 10:34:22  time: 0.4337  data_time: 0.0092  memory: 5166  grad_norm: 32.1988  loss: 5.3345  decode.loss_cls: 0.0085  decode.loss_mask: 0.2331  decode.loss_dice: 0.1987  decode.d0.loss_cls: 0.8697  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.1978  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.2341  decode.d1.loss_dice: 0.1991  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.1953  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.2379  decode.d3.loss_dice: 0.1979  decode.d4.loss_cls: 0.0112  decode.d4.loss_mask: 0.2376  decode.d4.loss_dice: 0.1989  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.2358  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.2371  decode.d6.loss_dice: 0.1970  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.2052  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.2352  decode.d8.loss_dice: 0.1947
09/28 18:59:12 - mmengine - INFO - Iter(train) [ 37100/320000]  base_lr: 8.9503e-05 lr: 8.9503e-06  eta: 1 day, 10:33:58  time: 0.4344  data_time: 0.0091  memory: 5167  grad_norm: 75.9121  loss: 5.9114  decode.loss_cls: 0.1157  decode.loss_mask: 0.2185  decode.loss_dice: 0.1807  decode.d0.loss_cls: 0.9847  decode.d0.loss_mask: 0.2232  decode.d0.loss_dice: 0.2085  decode.d1.loss_cls: 0.0315  decode.d1.loss_mask: 0.2203  decode.d1.loss_dice: 0.2038  decode.d2.loss_cls: 0.0631  decode.d2.loss_mask: 0.2199  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.2164  decode.d3.loss_dice: 0.1816  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.2167  decode.d4.loss_dice: 0.2041  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.1988  decode.d6.loss_cls: 0.0919  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.1825  decode.d7.loss_cls: 0.0783  decode.d7.loss_mask: 0.2182  decode.d7.loss_dice: 0.1936  decode.d8.loss_cls: 0.1341  decode.d8.loss_mask: 0.2196  decode.d8.loss_dice: 0.2017
09/28 18:59:33 - mmengine - INFO - Iter(train) [ 37150/320000]  base_lr: 8.9488e-05 lr: 8.9488e-06  eta: 1 day, 10:33:34  time: 0.4334  data_time: 0.0092  memory: 5167  grad_norm: 44.2242  loss: 6.4579  decode.loss_cls: 0.0896  decode.loss_mask: 0.2318  decode.loss_dice: 0.2265  decode.d0.loss_cls: 0.9801  decode.d0.loss_mask: 0.2365  decode.d0.loss_dice: 0.2245  decode.d1.loss_cls: 0.1664  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2236  decode.d2.loss_cls: 0.1291  decode.d2.loss_mask: 0.2338  decode.d2.loss_dice: 0.2194  decode.d3.loss_cls: 0.0899  decode.d3.loss_mask: 0.2346  decode.d3.loss_dice: 0.2247  decode.d4.loss_cls: 0.1119  decode.d4.loss_mask: 0.2333  decode.d4.loss_dice: 0.2198  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.2325  decode.d5.loss_dice: 0.2208  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.2370  decode.d6.loss_dice: 0.2304  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.2333  decode.d7.loss_dice: 0.2268  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.2333  decode.d8.loss_dice: 0.2233
09/28 18:59:55 - mmengine - INFO - Iter(train) [ 37200/320000]  base_lr: 8.9474e-05 lr: 8.9474e-06  eta: 1 day, 10:33:09  time: 0.4342  data_time: 0.0095  memory: 5149  grad_norm: 47.1194  loss: 5.3834  decode.loss_cls: 0.0864  decode.loss_mask: 0.2044  decode.loss_dice: 0.1661  decode.d0.loss_cls: 0.8757  decode.d0.loss_mask: 0.2074  decode.d0.loss_dice: 0.1686  decode.d1.loss_cls: 0.0864  decode.d1.loss_mask: 0.2072  decode.d1.loss_dice: 0.1687  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.2047  decode.d2.loss_dice: 0.1664  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.2037  decode.d3.loss_dice: 0.1682  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.1671  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.2039  decode.d5.loss_dice: 0.1616  decode.d6.loss_cls: 0.1089  decode.d6.loss_mask: 0.2045  decode.d6.loss_dice: 0.1603  decode.d7.loss_cls: 0.0906  decode.d7.loss_mask: 0.2080  decode.d7.loss_dice: 0.1670  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.2054  decode.d8.loss_dice: 0.1686
09/28 19:00:17 - mmengine - INFO - Iter(train) [ 37250/320000]  base_lr: 8.9460e-05 lr: 8.9460e-06  eta: 1 day, 10:32:46  time: 0.4346  data_time: 0.0094  memory: 5150  grad_norm: 99.9483  loss: 6.3172  decode.loss_cls: 0.1099  decode.loss_mask: 0.2253  decode.loss_dice: 0.1991  decode.d0.loss_cls: 0.9646  decode.d0.loss_mask: 0.2372  decode.d0.loss_dice: 0.1948  decode.d1.loss_cls: 0.2046  decode.d1.loss_mask: 0.2260  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.2278  decode.d2.loss_dice: 0.2006  decode.d3.loss_cls: 0.1640  decode.d3.loss_mask: 0.2225  decode.d3.loss_dice: 0.1984  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.2241  decode.d4.loss_dice: 0.1988  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.2240  decode.d5.loss_dice: 0.1954  decode.d6.loss_cls: 0.1048  decode.d6.loss_mask: 0.2297  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.1299  decode.d7.loss_mask: 0.2281  decode.d7.loss_dice: 0.1916  decode.d8.loss_cls: 0.1048  decode.d8.loss_mask: 0.2258  decode.d8.loss_dice: 0.1899
09/28 19:00:39 - mmengine - INFO - Iter(train) [ 37300/320000]  base_lr: 8.9446e-05 lr: 8.9446e-06  eta: 1 day, 10:32:21  time: 0.4335  data_time: 0.0095  memory: 5166  grad_norm: 36.3426  loss: 4.7859  decode.loss_cls: 0.0031  decode.loss_mask: 0.2122  decode.loss_dice: 0.1763  decode.d0.loss_cls: 0.8197  decode.d0.loss_mask: 0.2147  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.2129  decode.d1.loss_dice: 0.1770  decode.d2.loss_cls: 0.0094  decode.d2.loss_mask: 0.2151  decode.d2.loss_dice: 0.1875  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.2147  decode.d3.loss_dice: 0.1727  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.2137  decode.d4.loss_dice: 0.1778  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.1761  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2125  decode.d6.loss_dice: 0.1744  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.2120  decode.d7.loss_dice: 0.1736  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2133  decode.d8.loss_dice: 0.1782
09/28 19:01:00 - mmengine - INFO - Iter(train) [ 37350/320000]  base_lr: 8.9431e-05 lr: 8.9431e-06  eta: 1 day, 10:31:58  time: 0.4350  data_time: 0.0096  memory: 5167  grad_norm: 123.7402  loss: 10.0783  decode.loss_cls: 0.2722  decode.loss_mask: 0.3140  decode.loss_dice: 0.3337  decode.d0.loss_cls: 1.1393  decode.d0.loss_mask: 0.3121  decode.d0.loss_dice: 0.3422  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.3185  decode.d1.loss_dice: 0.3474  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.3414  decode.d3.loss_cls: 0.2212  decode.d3.loss_mask: 0.3076  decode.d3.loss_dice: 0.3430  decode.d4.loss_cls: 0.2523  decode.d4.loss_mask: 0.3138  decode.d4.loss_dice: 0.3552  decode.d5.loss_cls: 0.2797  decode.d5.loss_mask: 0.3120  decode.d5.loss_dice: 0.3681  decode.d6.loss_cls: 0.3142  decode.d6.loss_mask: 0.3114  decode.d6.loss_dice: 0.3444  decode.d7.loss_cls: 0.3006  decode.d7.loss_mask: 0.3208  decode.d7.loss_dice: 0.3500  decode.d8.loss_cls: 0.3111  decode.d8.loss_mask: 0.3187  decode.d8.loss_dice: 0.3348
09/28 19:01:22 - mmengine - INFO - Iter(train) [ 37400/320000]  base_lr: 8.9417e-05 lr: 8.9417e-06  eta: 1 day, 10:31:34  time: 0.4353  data_time: 0.0096  memory: 5150  grad_norm: 32.7793  loss: 7.6499  decode.loss_cls: 0.0731  decode.loss_mask: 0.3462  decode.loss_dice: 0.2193  decode.d0.loss_cls: 1.1538  decode.d0.loss_mask: 0.3536  decode.d0.loss_dice: 0.2294  decode.d1.loss_cls: 0.1722  decode.d1.loss_mask: 0.3502  decode.d1.loss_dice: 0.2290  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.3499  decode.d2.loss_dice: 0.2261  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.3533  decode.d3.loss_dice: 0.2218  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.3543  decode.d4.loss_dice: 0.2299  decode.d5.loss_cls: 0.0713  decode.d5.loss_mask: 0.3439  decode.d5.loss_dice: 0.2243  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.3432  decode.d6.loss_dice: 0.2255  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.3498  decode.d7.loss_dice: 0.2230  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.3413  decode.d8.loss_dice: 0.2192
09/28 19:01:44 - mmengine - INFO - Iter(train) [ 37450/320000]  base_lr: 8.9403e-05 lr: 8.9403e-06  eta: 1 day, 10:31:10  time: 0.4347  data_time: 0.0094  memory: 5167  grad_norm: 64.5046  loss: 5.8781  decode.loss_cls: 0.1566  decode.loss_mask: 0.1964  decode.loss_dice: 0.1737  decode.d0.loss_cls: 1.1022  decode.d0.loss_mask: 0.1655  decode.d0.loss_dice: 0.1751  decode.d1.loss_cls: 0.1115  decode.d1.loss_mask: 0.1969  decode.d1.loss_dice: 0.1713  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.1972  decode.d2.loss_dice: 0.1735  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.1823  decode.d3.loss_dice: 0.1673  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 0.1820  decode.d4.loss_dice: 0.1809  decode.d5.loss_cls: 0.1541  decode.d5.loss_mask: 0.1957  decode.d5.loss_dice: 0.1782  decode.d6.loss_cls: 0.1384  decode.d6.loss_mask: 0.2017  decode.d6.loss_dice: 0.1817  decode.d7.loss_cls: 0.1459  decode.d7.loss_mask: 0.1887  decode.d7.loss_dice: 0.1742  decode.d8.loss_cls: 0.1471  decode.d8.loss_mask: 0.1932  decode.d8.loss_dice: 0.1825
09/28 19:02:06 - mmengine - INFO - Iter(train) [ 37500/320000]  base_lr: 8.9389e-05 lr: 8.9389e-06  eta: 1 day, 10:30:46  time: 0.4342  data_time: 0.0094  memory: 5186  grad_norm: 28.4700  loss: 5.4283  decode.loss_cls: 0.0607  decode.loss_mask: 0.2224  decode.loss_dice: 0.1894  decode.d0.loss_cls: 0.9265  decode.d0.loss_mask: 0.2272  decode.d0.loss_dice: 0.2081  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.2237  decode.d1.loss_dice: 0.1984  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.2275  decode.d2.loss_dice: 0.1952  decode.d3.loss_cls: 0.0211  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2000  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.2258  decode.d4.loss_dice: 0.1924  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.2288  decode.d5.loss_dice: 0.1978  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.2239  decode.d6.loss_dice: 0.1967  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.2255  decode.d7.loss_dice: 0.1949  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.2250  decode.d8.loss_dice: 0.1890
09/28 19:02:27 - mmengine - INFO - Iter(train) [ 37550/320000]  base_lr: 8.9375e-05 lr: 8.9375e-06  eta: 1 day, 10:30:22  time: 0.4355  data_time: 0.0095  memory: 5186  grad_norm: 33.8087  loss: 6.1954  decode.loss_cls: 0.1578  decode.loss_mask: 0.2232  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.8403  decode.d0.loss_mask: 0.2276  decode.d0.loss_dice: 0.2262  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2179  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.2234  decode.d2.loss_dice: 0.2154  decode.d3.loss_cls: 0.1148  decode.d3.loss_mask: 0.2244  decode.d3.loss_dice: 0.2122  decode.d4.loss_cls: 0.1597  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.2141  decode.d5.loss_cls: 0.0803  decode.d5.loss_mask: 0.2265  decode.d5.loss_dice: 0.2128  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.2201  decode.d6.loss_dice: 0.2097  decode.d7.loss_cls: 0.0829  decode.d7.loss_mask: 0.2225  decode.d7.loss_dice: 0.2135  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.2217  decode.d8.loss_dice: 0.2144
09/28 19:02:49 - mmengine - INFO - Iter(train) [ 37600/320000]  base_lr: 8.9360e-05 lr: 8.9360e-06  eta: 1 day, 10:29:59  time: 0.4344  data_time: 0.0094  memory: 5150  grad_norm: 54.3839  loss: 5.4830  decode.loss_cls: 0.0141  decode.loss_mask: 0.2512  decode.loss_dice: 0.1769  decode.d0.loss_cls: 0.8959  decode.d0.loss_mask: 0.2509  decode.d0.loss_dice: 0.1794  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.2505  decode.d1.loss_dice: 0.1810  decode.d2.loss_cls: 0.0327  decode.d2.loss_mask: 0.2500  decode.d2.loss_dice: 0.1776  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.1818  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.2535  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.2549  decode.d5.loss_dice: 0.1812  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.2525  decode.d6.loss_dice: 0.1780  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.1783  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.2517  decode.d8.loss_dice: 0.1797
09/28 19:03:11 - mmengine - INFO - Iter(train) [ 37650/320000]  base_lr: 8.9346e-05 lr: 8.9346e-06  eta: 1 day, 10:29:35  time: 0.4343  data_time: 0.0095  memory: 5150  grad_norm: 31.3209  loss: 6.5597  decode.loss_cls: 0.1444  decode.loss_mask: 0.2457  decode.loss_dice: 0.2021  decode.d0.loss_cls: 0.9777  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.1991  decode.d1.loss_cls: 0.1312  decode.d1.loss_mask: 0.2512  decode.d1.loss_dice: 0.2171  decode.d2.loss_cls: 0.1424  decode.d2.loss_mask: 0.2455  decode.d2.loss_dice: 0.1924  decode.d3.loss_cls: 0.1472  decode.d3.loss_mask: 0.2486  decode.d3.loss_dice: 0.1928  decode.d4.loss_cls: 0.1303  decode.d4.loss_mask: 0.2459  decode.d4.loss_dice: 0.1910  decode.d5.loss_cls: 0.0978  decode.d5.loss_mask: 0.2476  decode.d5.loss_dice: 0.2051  decode.d6.loss_cls: 0.1200  decode.d6.loss_mask: 0.2487  decode.d6.loss_dice: 0.1884  decode.d7.loss_cls: 0.1148  decode.d7.loss_mask: 0.2472  decode.d7.loss_dice: 0.2059  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.1887
09/28 19:03:33 - mmengine - INFO - Iter(train) [ 37700/320000]  base_lr: 8.9332e-05 lr: 8.9332e-06  eta: 1 day, 10:29:11  time: 0.4351  data_time: 0.0094  memory: 5166  grad_norm: 51.0512  loss: 6.3188  decode.loss_cls: 0.0579  decode.loss_mask: 0.2550  decode.loss_dice: 0.2002  decode.d0.loss_cls: 1.0730  decode.d0.loss_mask: 0.2589  decode.d0.loss_dice: 0.1924  decode.d1.loss_cls: 0.1221  decode.d1.loss_mask: 0.2520  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.1953  decode.d3.loss_cls: 0.1269  decode.d3.loss_mask: 0.2544  decode.d3.loss_dice: 0.1984  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 0.2511  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.2516  decode.d5.loss_dice: 0.1986  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.2540  decode.d6.loss_dice: 0.2012  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.2528  decode.d7.loss_dice: 0.2023  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.2522  decode.d8.loss_dice: 0.1991
09/28 19:03:54 - mmengine - INFO - Iter(train) [ 37750/320000]  base_lr: 8.9318e-05 lr: 8.9318e-06  eta: 1 day, 10:28:47  time: 0.4347  data_time: 0.0095  memory: 5167  grad_norm: 84.0047  loss: 7.6889  decode.loss_cls: 0.1386  decode.loss_mask: 0.2804  decode.loss_dice: 0.2963  decode.d0.loss_cls: 0.8613  decode.d0.loss_mask: 0.2940  decode.d0.loss_dice: 0.2965  decode.d1.loss_cls: 0.1714  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.2902  decode.d2.loss_cls: 0.1736  decode.d2.loss_mask: 0.2824  decode.d2.loss_dice: 0.2763  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.2783  decode.d3.loss_dice: 0.2889  decode.d4.loss_cls: 0.1132  decode.d4.loss_mask: 0.2714  decode.d4.loss_dice: 0.2951  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.2730  decode.d5.loss_dice: 0.2804  decode.d6.loss_cls: 0.1001  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.2975  decode.d7.loss_cls: 0.1070  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2849  decode.d8.loss_cls: 0.1219  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.2832
09/28 19:04:16 - mmengine - INFO - Iter(train) [ 37800/320000]  base_lr: 8.9303e-05 lr: 8.9303e-06  eta: 1 day, 10:28:23  time: 0.4351  data_time: 0.0096  memory: 5167  grad_norm: 76.3104  loss: 6.8492  decode.loss_cls: 0.1794  decode.loss_mask: 0.2099  decode.loss_dice: 0.2224  decode.d0.loss_cls: 0.8576  decode.d0.loss_mask: 0.2175  decode.d0.loss_dice: 0.2130  decode.d1.loss_cls: 0.1889  decode.d1.loss_mask: 0.2115  decode.d1.loss_dice: 0.2225  decode.d2.loss_cls: 0.1535  decode.d2.loss_mask: 0.2084  decode.d2.loss_dice: 0.1950  decode.d3.loss_cls: 0.2106  decode.d3.loss_mask: 0.2086  decode.d3.loss_dice: 0.1998  decode.d4.loss_cls: 0.1442  decode.d4.loss_mask: 0.2075  decode.d4.loss_dice: 0.2264  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 0.2088  decode.d5.loss_dice: 0.2296  decode.d6.loss_cls: 0.1814  decode.d6.loss_mask: 0.2108  decode.d6.loss_dice: 0.2724  decode.d7.loss_cls: 0.1851  decode.d7.loss_mask: 0.2079  decode.d7.loss_dice: 0.2544  decode.d8.loss_cls: 0.1865  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2402
09/28 19:04:38 - mmengine - INFO - Iter(train) [ 37850/320000]  base_lr: 8.9289e-05 lr: 8.9289e-06  eta: 1 day, 10:28:00  time: 0.4346  data_time: 0.0094  memory: 5186  grad_norm: 66.3810  loss: 7.1012  decode.loss_cls: 0.1103  decode.loss_mask: 0.2827  decode.loss_dice: 0.2470  decode.d0.loss_cls: 1.0171  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.2580  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.2537  decode.d2.loss_cls: 0.1188  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.2413  decode.d3.loss_cls: 0.1406  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.2364  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.2801  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.0530  decode.d5.loss_mask: 0.2816  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.1324  decode.d6.loss_mask: 0.2842  decode.d6.loss_dice: 0.2389  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.2841  decode.d7.loss_dice: 0.2362  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.2845  decode.d8.loss_dice: 0.2274
09/28 19:05:00 - mmengine - INFO - Iter(train) [ 37900/320000]  base_lr: 8.9275e-05 lr: 8.9275e-06  eta: 1 day, 10:27:36  time: 0.4355  data_time: 0.0094  memory: 5167  grad_norm: 44.1788  loss: 7.7227  decode.loss_cls: 0.1676  decode.loss_mask: 0.2383  decode.loss_dice: 0.2840  decode.d0.loss_cls: 0.8603  decode.d0.loss_mask: 0.2389  decode.d0.loss_dice: 0.2904  decode.d1.loss_cls: 0.1970  decode.d1.loss_mask: 0.2382  decode.d1.loss_dice: 0.2745  decode.d2.loss_cls: 0.1987  decode.d2.loss_mask: 0.2397  decode.d2.loss_dice: 0.2804  decode.d3.loss_cls: 0.1286  decode.d3.loss_mask: 0.2375  decode.d3.loss_dice: 0.3023  decode.d4.loss_cls: 0.1591  decode.d4.loss_mask: 0.2374  decode.d4.loss_dice: 0.2881  decode.d5.loss_cls: 0.2178  decode.d5.loss_mask: 0.2346  decode.d5.loss_dice: 0.2708  decode.d6.loss_cls: 0.2085  decode.d6.loss_mask: 0.2368  decode.d6.loss_dice: 0.2890  decode.d7.loss_cls: 0.1778  decode.d7.loss_mask: 0.2370  decode.d7.loss_dice: 0.2892  decode.d8.loss_cls: 0.1735  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2900
09/28 19:05:21 - mmengine - INFO - Iter(train) [ 37950/320000]  base_lr: 8.9261e-05 lr: 8.9261e-06  eta: 1 day, 10:27:12  time: 0.4362  data_time: 0.0097  memory: 5167  grad_norm: 121.4239  loss: 6.2642  decode.loss_cls: 0.0809  decode.loss_mask: 0.2121  decode.loss_dice: 0.1939  decode.d0.loss_cls: 1.0346  decode.d0.loss_mask: 0.2213  decode.d0.loss_dice: 0.1966  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.2234  decode.d1.loss_dice: 0.2144  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.2811  decode.d2.loss_dice: 0.2265  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.3574  decode.d3.loss_dice: 0.2181  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2208  decode.d5.loss_cls: 0.0223  decode.d5.loss_mask: 0.3138  decode.d5.loss_dice: 0.2165  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.2953  decode.d6.loss_dice: 0.2252  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.2247  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.3274  decode.d8.loss_dice: 0.2248
09/28 19:05:43 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:05:43 - mmengine - INFO - Iter(train) [ 38000/320000]  base_lr: 8.9246e-05 lr: 8.9246e-06  eta: 1 day, 10:26:48  time: 0.4359  data_time: 0.0097  memory: 5166  grad_norm: 54.2762  loss: 6.6218  decode.loss_cls: 0.0689  decode.loss_mask: 0.2864  decode.loss_dice: 0.2121  decode.d0.loss_cls: 0.8193  decode.d0.loss_mask: 0.2957  decode.d0.loss_dice: 0.2258  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.2848  decode.d1.loss_dice: 0.2283  decode.d2.loss_cls: 0.0407  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.2471  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.2274  decode.d4.loss_cls: 0.1322  decode.d4.loss_mask: 0.2881  decode.d4.loss_dice: 0.2183  decode.d5.loss_cls: 0.1472  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.0673  decode.d6.loss_mask: 0.2888  decode.d6.loss_dice: 0.2158  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.2844  decode.d7.loss_dice: 0.2131  decode.d8.loss_cls: 0.0828  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.2245
09/28 19:06:05 - mmengine - INFO - Iter(train) [ 38050/320000]  base_lr: 8.9232e-05 lr: 8.9232e-06  eta: 1 day, 10:26:25  time: 0.4351  data_time: 0.0095  memory: 5167  grad_norm: 26.3934  loss: 5.2235  decode.loss_cls: 0.0045  decode.loss_mask: 0.2308  decode.loss_dice: 0.1937  decode.d0.loss_cls: 0.8457  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.1952  decode.d1.loss_cls: 0.0162  decode.d1.loss_mask: 0.2319  decode.d1.loss_dice: 0.1996  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.2319  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.2331  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.2299  decode.d4.loss_dice: 0.1958  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.2015  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2309  decode.d6.loss_dice: 0.2026  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2301  decode.d7.loss_dice: 0.1980  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.2313  decode.d8.loss_dice: 0.2035
09/28 19:06:27 - mmengine - INFO - Iter(train) [ 38100/320000]  base_lr: 8.9218e-05 lr: 8.9218e-06  eta: 1 day, 10:26:00  time: 0.4340  data_time: 0.0094  memory: 5186  grad_norm: 43.3467  loss: 6.7935  decode.loss_cls: 0.1101  decode.loss_mask: 0.2950  decode.loss_dice: 0.2038  decode.d0.loss_cls: 0.9178  decode.d0.loss_mask: 0.3031  decode.d0.loss_dice: 0.2133  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.2977  decode.d1.loss_dice: 0.2093  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.2971  decode.d2.loss_dice: 0.2062  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.2057  decode.d4.loss_cls: 0.0822  decode.d4.loss_mask: 0.2956  decode.d4.loss_dice: 0.2053  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.2987  decode.d5.loss_dice: 0.2070  decode.d6.loss_cls: 0.1056  decode.d6.loss_mask: 0.2961  decode.d6.loss_dice: 0.1995  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.2946  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.1066  decode.d8.loss_mask: 0.2956  decode.d8.loss_dice: 0.2057
09/28 19:06:48 - mmengine - INFO - Iter(train) [ 38150/320000]  base_lr: 8.9204e-05 lr: 8.9204e-06  eta: 1 day, 10:25:37  time: 0.4348  data_time: 0.0094  memory: 5166  grad_norm: 19.6189  loss: 4.9996  decode.loss_cls: 0.0176  decode.loss_mask: 0.1996  decode.loss_dice: 0.1857  decode.d0.loss_cls: 1.0305  decode.d0.loss_mask: 0.1992  decode.d0.loss_dice: 0.1840  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.2026  decode.d1.loss_dice: 0.1850  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.1969  decode.d2.loss_dice: 0.1921  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.2015  decode.d3.loss_dice: 0.1907  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2000  decode.d4.loss_dice: 0.1850  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.2048  decode.d5.loss_dice: 0.1932  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.1991  decode.d6.loss_dice: 0.1882  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.1989  decode.d7.loss_dice: 0.1910  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.2021  decode.d8.loss_dice: 0.1818
09/28 19:07:10 - mmengine - INFO - Iter(train) [ 38200/320000]  base_lr: 8.9189e-05 lr: 8.9189e-06  eta: 1 day, 10:25:13  time: 0.4352  data_time: 0.0095  memory: 5166  grad_norm: 99.3981  loss: 6.3384  decode.loss_cls: 0.0504  decode.loss_mask: 0.2544  decode.loss_dice: 0.2505  decode.d0.loss_cls: 0.8812  decode.d0.loss_mask: 0.2614  decode.d0.loss_dice: 0.2481  decode.d1.loss_cls: 0.1216  decode.d1.loss_mask: 0.2430  decode.d1.loss_dice: 0.2383  decode.d2.loss_cls: 0.0324  decode.d2.loss_mask: 0.2547  decode.d2.loss_dice: 0.2470  decode.d3.loss_cls: 0.0295  decode.d3.loss_mask: 0.2577  decode.d3.loss_dice: 0.2528  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.2610  decode.d4.loss_dice: 0.2490  decode.d5.loss_cls: 0.0300  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.2551  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.2499  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.2593  decode.d7.loss_dice: 0.2477  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.2513  decode.d8.loss_dice: 0.2461
09/28 19:07:32 - mmengine - INFO - Iter(train) [ 38250/320000]  base_lr: 8.9175e-05 lr: 8.9175e-06  eta: 1 day, 10:24:49  time: 0.4352  data_time: 0.0096  memory: 5186  grad_norm: 75.6148  loss: 8.4335  decode.loss_cls: 0.2921  decode.loss_mask: 0.2812  decode.loss_dice: 0.2204  decode.d0.loss_cls: 1.0901  decode.d0.loss_mask: 0.2895  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.2498  decode.d1.loss_mask: 0.3275  decode.d1.loss_dice: 0.2357  decode.d2.loss_cls: 0.2630  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.2156  decode.d3.loss_cls: 0.2001  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.2153  decode.d4.loss_cls: 0.2600  decode.d4.loss_mask: 0.2823  decode.d4.loss_dice: 0.2190  decode.d5.loss_cls: 0.2358  decode.d5.loss_mask: 0.2783  decode.d5.loss_dice: 0.2150  decode.d6.loss_cls: 0.2300  decode.d6.loss_mask: 0.2821  decode.d6.loss_dice: 0.2065  decode.d7.loss_cls: 0.2355  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.2048  decode.d8.loss_cls: 0.2868  decode.d8.loss_mask: 0.2935  decode.d8.loss_dice: 0.2182
09/28 19:07:54 - mmengine - INFO - Iter(train) [ 38300/320000]  base_lr: 8.9161e-05 lr: 8.9161e-06  eta: 1 day, 10:24:25  time: 0.4345  data_time: 0.0096  memory: 5150  grad_norm: 60.3374  loss: 7.6899  decode.loss_cls: 0.1792  decode.loss_mask: 0.2945  decode.loss_dice: 0.2473  decode.d0.loss_cls: 1.0703  decode.d0.loss_mask: 0.3079  decode.d0.loss_dice: 0.2710  decode.d1.loss_cls: 0.1530  decode.d1.loss_mask: 0.2900  decode.d1.loss_dice: 0.2362  decode.d2.loss_cls: 0.1575  decode.d2.loss_mask: 0.2941  decode.d2.loss_dice: 0.2424  decode.d3.loss_cls: 0.1113  decode.d3.loss_mask: 0.2915  decode.d3.loss_dice: 0.2659  decode.d4.loss_cls: 0.1121  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.2466  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 0.2877  decode.d5.loss_dice: 0.2401  decode.d6.loss_cls: 0.0972  decode.d6.loss_mask: 0.2986  decode.d6.loss_dice: 0.2537  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.3073  decode.d7.loss_dice: 0.2510  decode.d8.loss_cls: 0.1055  decode.d8.loss_mask: 0.2940  decode.d8.loss_dice: 0.2470
09/28 19:08:15 - mmengine - INFO - Iter(train) [ 38350/320000]  base_lr: 8.9147e-05 lr: 8.9147e-06  eta: 1 day, 10:24:01  time: 0.4343  data_time: 0.0094  memory: 5186  grad_norm: 44.6374  loss: 5.2505  decode.loss_cls: 0.0380  decode.loss_mask: 0.2473  decode.loss_dice: 0.1742  decode.d0.loss_cls: 0.7896  decode.d0.loss_mask: 0.2509  decode.d0.loss_dice: 0.1732  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2513  decode.d1.loss_dice: 0.1762  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.2465  decode.d2.loss_dice: 0.1777  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.2499  decode.d3.loss_dice: 0.1764  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.1770  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.2518  decode.d5.loss_dice: 0.1776  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.2492  decode.d6.loss_dice: 0.1665  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.2506  decode.d7.loss_dice: 0.1718  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.2531  decode.d8.loss_dice: 0.1761
09/28 19:08:37 - mmengine - INFO - Iter(train) [ 38400/320000]  base_lr: 8.9132e-05 lr: 8.9132e-06  eta: 1 day, 10:23:38  time: 0.4348  data_time: 0.0095  memory: 5150  grad_norm: 81.3497  loss: 8.3564  decode.loss_cls: 0.2308  decode.loss_mask: 0.2437  decode.loss_dice: 0.2309  decode.d0.loss_cls: 0.9652  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.2654  decode.d1.loss_cls: 0.2499  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2598  decode.d2.loss_cls: 0.2322  decode.d2.loss_mask: 0.2440  decode.d2.loss_dice: 0.2429  decode.d3.loss_cls: 0.2538  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.2272  decode.d4.loss_cls: 0.2392  decode.d4.loss_mask: 0.2441  decode.d4.loss_dice: 0.2554  decode.d5.loss_cls: 0.2798  decode.d5.loss_mask: 0.2434  decode.d5.loss_dice: 0.2470  decode.d6.loss_cls: 0.3195  decode.d6.loss_mask: 0.2479  decode.d6.loss_dice: 0.2758  decode.d7.loss_cls: 0.3593  decode.d7.loss_mask: 0.2464  decode.d7.loss_dice: 0.2297  decode.d8.loss_cls: 0.2748  decode.d8.loss_mask: 0.2449  decode.d8.loss_dice: 0.2601
09/28 19:08:59 - mmengine - INFO - Iter(train) [ 38450/320000]  base_lr: 8.9118e-05 lr: 8.9118e-06  eta: 1 day, 10:23:14  time: 0.4347  data_time: 0.0095  memory: 5148  grad_norm: 44.3821  loss: 6.0396  decode.loss_cls: 0.0344  decode.loss_mask: 0.2522  decode.loss_dice: 0.1990  decode.d0.loss_cls: 1.0694  decode.d0.loss_mask: 0.2579  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.2565  decode.d1.loss_dice: 0.1913  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.2536  decode.d2.loss_dice: 0.1861  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.2552  decode.d3.loss_dice: 0.1883  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.2546  decode.d4.loss_dice: 0.1917  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.2161  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.2513  decode.d6.loss_dice: 0.2114  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.2504  decode.d7.loss_dice: 0.1923  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.1919
09/28 19:09:21 - mmengine - INFO - Iter(train) [ 38500/320000]  base_lr: 8.9104e-05 lr: 8.9104e-06  eta: 1 day, 10:22:50  time: 0.4347  data_time: 0.0094  memory: 5186  grad_norm: 25.6270  loss: 4.8713  decode.loss_cls: 0.0448  decode.loss_mask: 0.1784  decode.loss_dice: 0.1634  decode.d0.loss_cls: 1.0187  decode.d0.loss_mask: 0.1797  decode.d0.loss_dice: 0.1718  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.1761  decode.d1.loss_dice: 0.1635  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.1777  decode.d2.loss_dice: 0.1658  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.1778  decode.d3.loss_dice: 0.1707  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.1777  decode.d4.loss_dice: 0.1676  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.1790  decode.d5.loss_dice: 0.1679  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.1756  decode.d6.loss_dice: 0.1648  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.1790  decode.d7.loss_dice: 0.1652  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.1798  decode.d8.loss_dice: 0.1632
09/28 19:09:42 - mmengine - INFO - Iter(train) [ 38550/320000]  base_lr: 8.9090e-05 lr: 8.9090e-06  eta: 1 day, 10:22:26  time: 0.4339  data_time: 0.0095  memory: 5186  grad_norm: 52.6324  loss: 7.1284  decode.loss_cls: 0.0657  decode.loss_mask: 0.3112  decode.loss_dice: 0.2258  decode.d0.loss_cls: 0.9628  decode.d0.loss_mask: 0.3239  decode.d0.loss_dice: 0.2388  decode.d1.loss_cls: 0.0869  decode.d1.loss_mask: 0.3188  decode.d1.loss_dice: 0.2318  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.3177  decode.d2.loss_dice: 0.2260  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.3148  decode.d3.loss_dice: 0.2301  decode.d4.loss_cls: 0.0979  decode.d4.loss_mask: 0.3159  decode.d4.loss_dice: 0.2216  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.3181  decode.d5.loss_dice: 0.2266  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.2247  decode.d7.loss_cls: 0.0785  decode.d7.loss_mask: 0.3154  decode.d7.loss_dice: 0.2281  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.3170  decode.d8.loss_dice: 0.2263
09/28 19:10:04 - mmengine - INFO - Iter(train) [ 38600/320000]  base_lr: 8.9075e-05 lr: 8.9075e-06  eta: 1 day, 10:22:02  time: 0.4343  data_time: 0.0094  memory: 5150  grad_norm: 80.7307  loss: 6.6345  decode.loss_cls: 0.0932  decode.loss_mask: 0.2703  decode.loss_dice: 0.2257  decode.d0.loss_cls: 0.9363  decode.d0.loss_mask: 0.2601  decode.d0.loss_dice: 0.2122  decode.d1.loss_cls: 0.1125  decode.d1.loss_mask: 0.2573  decode.d1.loss_dice: 0.2358  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.2637  decode.d2.loss_dice: 0.2345  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.2298  decode.d4.loss_cls: 0.0982  decode.d4.loss_mask: 0.2671  decode.d4.loss_dice: 0.2287  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.2618  decode.d5.loss_dice: 0.2268  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.2665  decode.d6.loss_dice: 0.2230  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.2620  decode.d7.loss_dice: 0.2204  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.2310
09/28 19:10:26 - mmengine - INFO - Iter(train) [ 38650/320000]  base_lr: 8.9061e-05 lr: 8.9061e-06  eta: 1 day, 10:21:39  time: 0.4347  data_time: 0.0095  memory: 5166  grad_norm: 32.8976  loss: 6.2401  decode.loss_cls: 0.1267  decode.loss_mask: 0.2003  decode.loss_dice: 0.2103  decode.d0.loss_cls: 0.8254  decode.d0.loss_mask: 0.2061  decode.d0.loss_dice: 0.2228  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 0.2038  decode.d1.loss_dice: 0.1993  decode.d2.loss_cls: 0.1864  decode.d2.loss_mask: 0.2087  decode.d2.loss_dice: 0.2079  decode.d3.loss_cls: 0.1514  decode.d3.loss_mask: 0.2074  decode.d3.loss_dice: 0.2078  decode.d4.loss_cls: 0.1364  decode.d4.loss_mask: 0.2049  decode.d4.loss_dice: 0.2102  decode.d5.loss_cls: 0.1101  decode.d5.loss_mask: 0.2061  decode.d5.loss_dice: 0.2217  decode.d6.loss_cls: 0.1253  decode.d6.loss_mask: 0.2032  decode.d6.loss_dice: 0.2106  decode.d7.loss_cls: 0.1151  decode.d7.loss_mask: 0.2045  decode.d7.loss_dice: 0.2413  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 0.2060  decode.d8.loss_dice: 0.2114
09/28 19:10:48 - mmengine - INFO - Iter(train) [ 38700/320000]  base_lr: 8.9047e-05 lr: 8.9047e-06  eta: 1 day, 10:21:15  time: 0.4365  data_time: 0.0095  memory: 5186  grad_norm: 81.6248  loss: 8.5353  decode.loss_cls: 0.1291  decode.loss_mask: 0.3093  decode.loss_dice: 0.3071  decode.d0.loss_cls: 1.0669  decode.d0.loss_mask: 0.2952  decode.d0.loss_dice: 0.3368  decode.d1.loss_cls: 0.1868  decode.d1.loss_mask: 0.3141  decode.d1.loss_dice: 0.3022  decode.d2.loss_cls: 0.2238  decode.d2.loss_mask: 0.2962  decode.d2.loss_dice: 0.3135  decode.d3.loss_cls: 0.1124  decode.d3.loss_mask: 0.3098  decode.d3.loss_dice: 0.2961  decode.d4.loss_cls: 0.1583  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.3084  decode.d5.loss_cls: 0.1333  decode.d5.loss_mask: 0.3135  decode.d5.loss_dice: 0.3033  decode.d6.loss_cls: 0.1088  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.3057  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.3166  decode.d7.loss_dice: 0.3112  decode.d8.loss_cls: 0.1191  decode.d8.loss_mask: 0.3053  decode.d8.loss_dice: 0.3158
09/28 19:11:09 - mmengine - INFO - Iter(train) [ 38750/320000]  base_lr: 8.9033e-05 lr: 8.9033e-06  eta: 1 day, 10:20:51  time: 0.4349  data_time: 0.0094  memory: 5150  grad_norm: 30.7039  loss: 5.1984  decode.loss_cls: 0.0349  decode.loss_mask: 0.2302  decode.loss_dice: 0.1959  decode.d0.loss_cls: 0.8810  decode.d0.loss_mask: 0.2084  decode.d0.loss_dice: 0.1897  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.2063  decode.d1.loss_dice: 0.1824  decode.d2.loss_cls: 0.0315  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.1762  decode.d3.loss_cls: 0.0272  decode.d3.loss_mask: 0.2047  decode.d3.loss_dice: 0.1759  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.2056  decode.d4.loss_dice: 0.1855  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.2071  decode.d5.loss_dice: 0.1754  decode.d6.loss_cls: 0.0266  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.2013  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.2218  decode.d7.loss_dice: 0.1940  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.2233  decode.d8.loss_dice: 0.2004
09/28 19:11:31 - mmengine - INFO - Iter(train) [ 38800/320000]  base_lr: 8.9018e-05 lr: 8.9018e-06  eta: 1 day, 10:20:27  time: 0.4350  data_time: 0.0094  memory: 5186  grad_norm: 74.8252  loss: 8.1339  decode.loss_cls: 0.0854  decode.loss_mask: 0.3640  decode.loss_dice: 0.2778  decode.d0.loss_cls: 0.8374  decode.d0.loss_mask: 0.3715  decode.d0.loss_dice: 0.3051  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 0.3630  decode.d1.loss_dice: 0.2953  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.3614  decode.d2.loss_dice: 0.2831  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.3675  decode.d3.loss_dice: 0.2812  decode.d4.loss_cls: 0.0814  decode.d4.loss_mask: 0.3705  decode.d4.loss_dice: 0.2818  decode.d5.loss_cls: 0.1023  decode.d5.loss_mask: 0.3644  decode.d5.loss_dice: 0.2793  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.3599  decode.d6.loss_dice: 0.2778  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.3700  decode.d7.loss_dice: 0.2837  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.3641  decode.d8.loss_dice: 0.2709
09/28 19:11:53 - mmengine - INFO - Iter(train) [ 38850/320000]  base_lr: 8.9004e-05 lr: 8.9004e-06  eta: 1 day, 10:20:04  time: 0.4350  data_time: 0.0093  memory: 5166  grad_norm: 41.0009  loss: 7.0283  decode.loss_cls: 0.1260  decode.loss_mask: 0.2209  decode.loss_dice: 0.2536  decode.d0.loss_cls: 1.0201  decode.d0.loss_mask: 0.2252  decode.d0.loss_dice: 0.2768  decode.d1.loss_cls: 0.2282  decode.d1.loss_mask: 0.2213  decode.d1.loss_dice: 0.2582  decode.d2.loss_cls: 0.1288  decode.d2.loss_mask: 0.2202  decode.d2.loss_dice: 0.2633  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.2185  decode.d4.loss_dice: 0.2549  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.2200  decode.d5.loss_dice: 0.2623  decode.d6.loss_cls: 0.1364  decode.d6.loss_mask: 0.2203  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.1303  decode.d7.loss_mask: 0.2183  decode.d7.loss_dice: 0.2552  decode.d8.loss_cls: 0.1557  decode.d8.loss_mask: 0.2208  decode.d8.loss_dice: 0.2663
09/28 19:12:15 - mmengine - INFO - Iter(train) [ 38900/320000]  base_lr: 8.8990e-05 lr: 8.8990e-06  eta: 1 day, 10:19:40  time: 0.4357  data_time: 0.0094  memory: 5186  grad_norm: 34.6528  loss: 6.0473  decode.loss_cls: 0.1217  decode.loss_mask: 0.2262  decode.loss_dice: 0.2300  decode.d0.loss_cls: 0.8528  decode.d0.loss_mask: 0.2252  decode.d0.loss_dice: 0.2336  decode.d1.loss_cls: 0.1053  decode.d1.loss_mask: 0.2241  decode.d1.loss_dice: 0.2192  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 0.2274  decode.d2.loss_dice: 0.2128  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.2238  decode.d3.loss_dice: 0.2242  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.2277  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.2242  decode.d5.loss_dice: 0.2321  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.2243  decode.d6.loss_dice: 0.2174  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.2246  decode.d7.loss_dice: 0.2314  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.2262  decode.d8.loss_dice: 0.2245
09/28 19:12:36 - mmengine - INFO - Iter(train) [ 38950/320000]  base_lr: 8.8976e-05 lr: 8.8976e-06  eta: 1 day, 10:19:16  time: 0.4356  data_time: 0.0096  memory: 5167  grad_norm: 245.4385  loss: 5.9872  decode.loss_cls: 0.0343  decode.loss_mask: 0.2560  decode.loss_dice: 0.2058  decode.d0.loss_cls: 1.0093  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.2083  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.2163  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.2534  decode.d2.loss_dice: 0.2051  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.2512  decode.d3.loss_dice: 0.1936  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.2488  decode.d4.loss_dice: 0.1925  decode.d5.loss_cls: 0.0657  decode.d5.loss_mask: 0.2500  decode.d5.loss_dice: 0.1968  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.1960  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.1955  decode.d8.loss_cls: 0.0301  decode.d8.loss_mask: 0.2613  decode.d8.loss_dice: 0.2014
09/28 19:12:58 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:12:58 - mmengine - INFO - Iter(train) [ 39000/320000]  base_lr: 8.8961e-05 lr: 8.8961e-06  eta: 1 day, 10:18:52  time: 0.4342  data_time: 0.0093  memory: 5166  grad_norm: 39.5334  loss: 5.2370  decode.loss_cls: 0.0705  decode.loss_mask: 0.2001  decode.loss_dice: 0.1528  decode.d0.loss_cls: 0.8577  decode.d0.loss_mask: 0.2113  decode.d0.loss_dice: 0.1644  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.1569  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.2039  decode.d2.loss_dice: 0.1550  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 0.2032  decode.d3.loss_dice: 0.1704  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.2028  decode.d4.loss_dice: 0.1573  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.2040  decode.d5.loss_dice: 0.1549  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.2047  decode.d6.loss_dice: 0.1547  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.2019  decode.d7.loss_dice: 0.1520  decode.d8.loss_cls: 0.0856  decode.d8.loss_mask: 0.2047  decode.d8.loss_dice: 0.1575
09/28 19:13:20 - mmengine - INFO - Iter(train) [ 39050/320000]  base_lr: 8.8947e-05 lr: 8.8947e-06  eta: 1 day, 10:18:28  time: 0.4347  data_time: 0.0093  memory: 5167  grad_norm: 49.8665  loss: 5.3492  decode.loss_cls: 0.0793  decode.loss_mask: 0.2190  decode.loss_dice: 0.1684  decode.d0.loss_cls: 0.7427  decode.d0.loss_mask: 0.2269  decode.d0.loss_dice: 0.1656  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.1679  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.2200  decode.d2.loss_dice: 0.1808  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.2160  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.1105  decode.d4.loss_mask: 0.2195  decode.d4.loss_dice: 0.1595  decode.d5.loss_cls: 0.0869  decode.d5.loss_mask: 0.2186  decode.d5.loss_dice: 0.1754  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.2169  decode.d6.loss_dice: 0.1686  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.2182  decode.d7.loss_dice: 0.1869  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.2177  decode.d8.loss_dice: 0.1568
09/28 19:13:42 - mmengine - INFO - Iter(train) [ 39100/320000]  base_lr: 8.8933e-05 lr: 8.8933e-06  eta: 1 day, 10:18:05  time: 0.4345  data_time: 0.0094  memory: 5186  grad_norm: 69.4968  loss: 5.7741  decode.loss_cls: 0.0884  decode.loss_mask: 0.2067  decode.loss_dice: 0.1831  decode.d0.loss_cls: 1.0185  decode.d0.loss_mask: 0.1920  decode.d0.loss_dice: 0.1830  decode.d1.loss_cls: 0.1812  decode.d1.loss_mask: 0.1882  decode.d1.loss_dice: 0.1757  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.2216  decode.d2.loss_dice: 0.2005  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.1940  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.1928  decode.d4.loss_dice: 0.1755  decode.d5.loss_cls: 0.0947  decode.d5.loss_mask: 0.1999  decode.d5.loss_dice: 0.1914  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.2121  decode.d6.loss_dice: 0.2062  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 0.1970  decode.d7.loss_dice: 0.1857  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.1882  decode.d8.loss_dice: 0.1765
09/28 19:14:03 - mmengine - INFO - Iter(train) [ 39150/320000]  base_lr: 8.8919e-05 lr: 8.8919e-06  eta: 1 day, 10:17:41  time: 0.4338  data_time: 0.0096  memory: 5186  grad_norm: 44.9734  loss: 6.4336  decode.loss_cls: 0.0695  decode.loss_mask: 0.2422  decode.loss_dice: 0.2252  decode.d0.loss_cls: 0.8711  decode.d0.loss_mask: 0.2538  decode.d0.loss_dice: 0.1916  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 0.2406  decode.d1.loss_dice: 0.2375  decode.d2.loss_cls: 0.1056  decode.d2.loss_mask: 0.2412  decode.d2.loss_dice: 0.2364  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.2455  decode.d3.loss_dice: 0.1965  decode.d4.loss_cls: 0.1100  decode.d4.loss_mask: 0.2403  decode.d4.loss_dice: 0.2280  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 0.2444  decode.d5.loss_dice: 0.2514  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.2443  decode.d6.loss_dice: 0.2236  decode.d7.loss_cls: 0.1037  decode.d7.loss_mask: 0.2426  decode.d7.loss_dice: 0.2402  decode.d8.loss_cls: 0.1010  decode.d8.loss_mask: 0.2406  decode.d8.loss_dice: 0.2330
09/28 19:14:25 - mmengine - INFO - Iter(train) [ 39200/320000]  base_lr: 8.8904e-05 lr: 8.8904e-06  eta: 1 day, 10:17:17  time: 0.4342  data_time: 0.0092  memory: 5166  grad_norm: 72.6322  loss: 5.8158  decode.loss_cls: 0.0336  decode.loss_mask: 0.2409  decode.loss_dice: 0.1961  decode.d0.loss_cls: 1.0274  decode.d0.loss_mask: 0.2482  decode.d0.loss_dice: 0.2040  decode.d1.loss_cls: 0.0402  decode.d1.loss_mask: 0.2451  decode.d1.loss_dice: 0.1996  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.2426  decode.d2.loss_dice: 0.1923  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.2442  decode.d3.loss_dice: 0.1917  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.2434  decode.d4.loss_dice: 0.1949  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.2416  decode.d5.loss_dice: 0.1906  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.2417  decode.d6.loss_dice: 0.1991  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.2435  decode.d7.loss_dice: 0.1919  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.2456  decode.d8.loss_dice: 0.1913
09/28 19:14:47 - mmengine - INFO - Iter(train) [ 39250/320000]  base_lr: 8.8890e-05 lr: 8.8890e-06  eta: 1 day, 10:16:54  time: 0.4348  data_time: 0.0096  memory: 5186  grad_norm: 34.1133  loss: 5.6704  decode.loss_cls: 0.0559  decode.loss_mask: 0.2517  decode.loss_dice: 0.1793  decode.d0.loss_cls: 0.9213  decode.d0.loss_mask: 0.2629  decode.d0.loss_dice: 0.1782  decode.d1.loss_cls: 0.0246  decode.d1.loss_mask: 0.2553  decode.d1.loss_dice: 0.1859  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.1852  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.1783  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.2519  decode.d4.loss_dice: 0.1779  decode.d5.loss_cls: 0.0402  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.1753  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.2566  decode.d6.loss_dice: 0.1762  decode.d7.loss_cls: 0.0367  decode.d7.loss_mask: 0.2565  decode.d7.loss_dice: 0.1779  decode.d8.loss_cls: 0.0480  decode.d8.loss_mask: 0.2543  decode.d8.loss_dice: 0.1800
09/28 19:15:09 - mmengine - INFO - Iter(train) [ 39300/320000]  base_lr: 8.8876e-05 lr: 8.8876e-06  eta: 1 day, 10:16:31  time: 0.4347  data_time: 0.0096  memory: 5167  grad_norm: 106.9830  loss: 7.1953  decode.loss_cls: 0.2134  decode.loss_mask: 0.2131  decode.loss_dice: 0.2175  decode.d0.loss_cls: 1.1367  decode.d0.loss_mask: 0.1792  decode.d0.loss_dice: 0.2177  decode.d1.loss_cls: 0.1863  decode.d1.loss_mask: 0.1804  decode.d1.loss_dice: 0.2269  decode.d2.loss_cls: 0.2002  decode.d2.loss_mask: 0.1821  decode.d2.loss_dice: 0.2232  decode.d3.loss_cls: 0.2055  decode.d3.loss_mask: 0.1810  decode.d3.loss_dice: 0.2187  decode.d4.loss_cls: 0.1971  decode.d4.loss_mask: 0.1803  decode.d4.loss_dice: 0.2197  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.1802  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.2296  decode.d6.loss_mask: 0.2223  decode.d6.loss_dice: 0.2418  decode.d7.loss_cls: 0.2173  decode.d7.loss_mask: 0.1806  decode.d7.loss_dice: 0.2262  decode.d8.loss_cls: 0.2317  decode.d8.loss_mask: 0.2453  decode.d8.loss_dice: 0.2235
09/28 19:15:30 - mmengine - INFO - Iter(train) [ 39350/320000]  base_lr: 8.8862e-05 lr: 8.8862e-06  eta: 1 day, 10:16:07  time: 0.4350  data_time: 0.0097  memory: 5166  grad_norm: 90.1998  loss: 6.3159  decode.loss_cls: 0.1362  decode.loss_mask: 0.2034  decode.loss_dice: 0.2345  decode.d0.loss_cls: 0.9137  decode.d0.loss_mask: 0.2076  decode.d0.loss_dice: 0.2496  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.2009  decode.d1.loss_dice: 0.2392  decode.d2.loss_cls: 0.0804  decode.d2.loss_mask: 0.2046  decode.d2.loss_dice: 0.2672  decode.d3.loss_cls: 0.1179  decode.d3.loss_mask: 0.2026  decode.d3.loss_dice: 0.2419  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.1999  decode.d4.loss_dice: 0.2358  decode.d5.loss_cls: 0.1180  decode.d5.loss_mask: 0.1983  decode.d5.loss_dice: 0.2301  decode.d6.loss_cls: 0.1158  decode.d6.loss_mask: 0.2004  decode.d6.loss_dice: 0.2326  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.2028  decode.d7.loss_dice: 0.2302  decode.d8.loss_cls: 0.0996  decode.d8.loss_mask: 0.2031  decode.d8.loss_dice: 0.2269
09/28 19:15:52 - mmengine - INFO - Iter(train) [ 39400/320000]  base_lr: 8.8847e-05 lr: 8.8847e-06  eta: 1 day, 10:15:44  time: 0.4351  data_time: 0.0096  memory: 5148  grad_norm: 80.5001  loss: 5.9449  decode.loss_cls: 0.1036  decode.loss_mask: 0.2004  decode.loss_dice: 0.1866  decode.d0.loss_cls: 1.1092  decode.d0.loss_mask: 0.1956  decode.d0.loss_dice: 0.2011  decode.d1.loss_cls: 0.1432  decode.d1.loss_mask: 0.1999  decode.d1.loss_dice: 0.1785  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.2020  decode.d2.loss_dice: 0.1792  decode.d3.loss_cls: 0.1246  decode.d3.loss_mask: 0.1950  decode.d3.loss_dice: 0.1852  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.1988  decode.d4.loss_dice: 0.1923  decode.d5.loss_cls: 0.1148  decode.d5.loss_mask: 0.1977  decode.d5.loss_dice: 0.1832  decode.d6.loss_cls: 0.0684  decode.d6.loss_mask: 0.1966  decode.d6.loss_dice: 0.1885  decode.d7.loss_cls: 0.1106  decode.d7.loss_mask: 0.1965  decode.d7.loss_dice: 0.1802  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.2000  decode.d8.loss_dice: 0.1809
09/28 19:16:14 - mmengine - INFO - Iter(train) [ 39450/320000]  base_lr: 8.8833e-05 lr: 8.8833e-06  eta: 1 day, 10:15:20  time: 0.4344  data_time: 0.0094  memory: 5186  grad_norm: 53.9289  loss: 4.4325  decode.loss_cls: 0.0424  decode.loss_mask: 0.1872  decode.loss_dice: 0.1459  decode.d0.loss_cls: 0.7733  decode.d0.loss_mask: 0.1901  decode.d0.loss_dice: 0.1546  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.1894  decode.d1.loss_dice: 0.1484  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.1865  decode.d2.loss_dice: 0.1464  decode.d3.loss_cls: 0.0282  decode.d3.loss_mask: 0.1866  decode.d3.loss_dice: 0.1445  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.1874  decode.d4.loss_dice: 0.1501  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.1858  decode.d5.loss_dice: 0.1433  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.1438  decode.d7.loss_cls: 0.0395  decode.d7.loss_mask: 0.1880  decode.d7.loss_dice: 0.1460  decode.d8.loss_cls: 0.0399  decode.d8.loss_mask: 0.1872  decode.d8.loss_dice: 0.1444
09/28 19:16:36 - mmengine - INFO - Iter(train) [ 39500/320000]  base_lr: 8.8819e-05 lr: 8.8819e-06  eta: 1 day, 10:14:56  time: 0.4347  data_time: 0.0096  memory: 5186  grad_norm: 18.1257  loss: 4.7182  decode.loss_cls: 0.0082  decode.loss_mask: 0.2031  decode.loss_dice: 0.1851  decode.d0.loss_cls: 0.7720  decode.d0.loss_mask: 0.2120  decode.d0.loss_dice: 0.1972  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.2066  decode.d1.loss_dice: 0.1779  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.2063  decode.d2.loss_dice: 0.1794  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.2049  decode.d3.loss_dice: 0.1729  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.2061  decode.d4.loss_dice: 0.1800  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.2057  decode.d5.loss_dice: 0.1739  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.2081  decode.d6.loss_dice: 0.1738  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.1772  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.2068  decode.d8.loss_dice: 0.1789
09/28 19:16:57 - mmengine - INFO - Iter(train) [ 39550/320000]  base_lr: 8.8805e-05 lr: 8.8805e-06  eta: 1 day, 10:14:33  time: 0.4353  data_time: 0.0097  memory: 5186  grad_norm: 64.7805  loss: 6.4394  decode.loss_cls: 0.1268  decode.loss_mask: 0.2072  decode.loss_dice: 0.2160  decode.d0.loss_cls: 1.1005  decode.d0.loss_mask: 0.2101  decode.d0.loss_dice: 0.2205  decode.d1.loss_cls: 0.1535  decode.d1.loss_mask: 0.2089  decode.d1.loss_dice: 0.2114  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.2040  decode.d2.loss_dice: 0.1889  decode.d3.loss_cls: 0.1321  decode.d3.loss_mask: 0.2100  decode.d3.loss_dice: 0.2133  decode.d4.loss_cls: 0.1331  decode.d4.loss_mask: 0.2080  decode.d4.loss_dice: 0.2073  decode.d5.loss_cls: 0.1187  decode.d5.loss_mask: 0.2093  decode.d5.loss_dice: 0.2120  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.2124  decode.d6.loss_dice: 0.2133  decode.d7.loss_cls: 0.1199  decode.d7.loss_mask: 0.2076  decode.d7.loss_dice: 0.2161  decode.d8.loss_cls: 0.1239  decode.d8.loss_mask: 0.2098  decode.d8.loss_dice: 0.2033
09/28 19:17:19 - mmengine - INFO - Iter(train) [ 39600/320000]  base_lr: 8.8790e-05 lr: 8.8790e-06  eta: 1 day, 10:14:09  time: 0.4358  data_time: 0.0099  memory: 5185  grad_norm: 92.5049  loss: 7.0021  decode.loss_cls: 0.0556  decode.loss_mask: 0.2898  decode.loss_dice: 0.2411  decode.d0.loss_cls: 0.9025  decode.d0.loss_mask: 0.3109  decode.d0.loss_dice: 0.2544  decode.d1.loss_cls: 0.0937  decode.d1.loss_mask: 0.3064  decode.d1.loss_dice: 0.2496  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.3048  decode.d2.loss_dice: 0.2582  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.3018  decode.d3.loss_dice: 0.2492  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.2963  decode.d4.loss_dice: 0.2455  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.2501  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.3044  decode.d6.loss_dice: 0.2485  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.2982  decode.d7.loss_dice: 0.2506  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.2950  decode.d8.loss_dice: 0.2450
09/28 19:17:41 - mmengine - INFO - Iter(train) [ 39650/320000]  base_lr: 8.8776e-05 lr: 8.8776e-06  eta: 1 day, 10:13:46  time: 0.4360  data_time: 0.0097  memory: 5167  grad_norm: 29.4751  loss: 5.9221  decode.loss_cls: 0.0251  decode.loss_mask: 0.2756  decode.loss_dice: 0.2181  decode.d0.loss_cls: 0.8162  decode.d0.loss_mask: 0.2786  decode.d0.loss_dice: 0.2114  decode.d1.loss_cls: 0.0409  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.2107  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.2733  decode.d2.loss_dice: 0.2179  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.2715  decode.d3.loss_dice: 0.2079  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.2700  decode.d4.loss_dice: 0.2087  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.2695  decode.d5.loss_dice: 0.2106  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.2125  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.2723  decode.d7.loss_dice: 0.2103  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.2718  decode.d8.loss_dice: 0.2097
09/28 19:18:04 - mmengine - INFO - Iter(train) [ 39700/320000]  base_lr: 8.8762e-05 lr: 8.8762e-06  eta: 1 day, 10:13:34  time: 0.4731  data_time: 0.0095  memory: 5150  grad_norm: 382.4889  loss: 6.0137  decode.loss_cls: 0.0147  decode.loss_mask: 0.2965  decode.loss_dice: 0.1909  decode.d0.loss_cls: 0.8465  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.2217  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.3068  decode.d1.loss_dice: 0.1994  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.3053  decode.d2.loss_dice: 0.1960  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.2999  decode.d3.loss_dice: 0.1978  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.3016  decode.d4.loss_dice: 0.1926  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.1942  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2943  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.2938  decode.d7.loss_dice: 0.1995  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.3065  decode.d8.loss_dice: 0.1971
09/28 19:18:28 - mmengine - INFO - Iter(train) [ 39750/320000]  base_lr: 8.8748e-05 lr: 8.8748e-06  eta: 1 day, 10:13:24  time: 0.4730  data_time: 0.0098  memory: 5150  grad_norm: 68.4174  loss: 7.1518  decode.loss_cls: 0.2040  decode.loss_mask: 0.2368  decode.loss_dice: 0.2413  decode.d0.loss_cls: 1.0709  decode.d0.loss_mask: 0.2395  decode.d0.loss_dice: 0.2324  decode.d1.loss_cls: 0.1292  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2339  decode.d2.loss_cls: 0.1226  decode.d2.loss_mask: 0.2364  decode.d2.loss_dice: 0.2468  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 0.2419  decode.d3.loss_dice: 0.2476  decode.d4.loss_cls: 0.1334  decode.d4.loss_mask: 0.2444  decode.d4.loss_dice: 0.2425  decode.d5.loss_cls: 0.1583  decode.d5.loss_mask: 0.2418  decode.d5.loss_dice: 0.2465  decode.d6.loss_cls: 0.1016  decode.d6.loss_mask: 0.2415  decode.d6.loss_dice: 0.2547  decode.d7.loss_cls: 0.1100  decode.d7.loss_mask: 0.2380  decode.d7.loss_dice: 0.2403  decode.d8.loss_cls: 0.1401  decode.d8.loss_mask: 0.2395  decode.d8.loss_dice: 0.2553
09/28 19:18:52 - mmengine - INFO - Iter(train) [ 39800/320000]  base_lr: 8.8733e-05 lr: 8.8733e-06  eta: 1 day, 10:13:13  time: 0.4722  data_time: 0.0096  memory: 5167  grad_norm: 69.4300  loss: 7.6663  decode.loss_cls: 0.0724  decode.loss_mask: 0.3000  decode.loss_dice: 0.3211  decode.d0.loss_cls: 0.8693  decode.d0.loss_mask: 0.2865  decode.d0.loss_dice: 0.3260  decode.d1.loss_cls: 0.0296  decode.d1.loss_mask: 0.2977  decode.d1.loss_dice: 0.3284  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.3196  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.3278  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.2998  decode.d4.loss_dice: 0.3121  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.3042  decode.d5.loss_dice: 0.3301  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.3023  decode.d6.loss_dice: 0.3060  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.3053  decode.d7.loss_dice: 0.3054  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.2975  decode.d8.loss_dice: 0.3175
09/28 19:19:15 - mmengine - INFO - Iter(train) [ 39850/320000]  base_lr: 8.8719e-05 lr: 8.8719e-06  eta: 1 day, 10:13:03  time: 0.4735  data_time: 0.0098  memory: 5167  grad_norm: 112.8014  loss: 9.2890  decode.loss_cls: 0.2465  decode.loss_mask: 0.2909  decode.loss_dice: 0.2922  decode.d0.loss_cls: 0.9437  decode.d0.loss_mask: 0.3078  decode.d0.loss_dice: 0.3148  decode.d1.loss_cls: 0.2951  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.2634  decode.d2.loss_cls: 0.2227  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.2674  decode.d3.loss_cls: 0.2595  decode.d3.loss_mask: 0.2898  decode.d3.loss_dice: 0.2911  decode.d4.loss_cls: 0.3085  decode.d4.loss_mask: 0.2908  decode.d4.loss_dice: 0.3040  decode.d5.loss_cls: 0.3105  decode.d5.loss_mask: 0.2876  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.3344  decode.d6.loss_mask: 0.2907  decode.d6.loss_dice: 0.2873  decode.d7.loss_cls: 0.2840  decode.d7.loss_mask: 0.2904  decode.d7.loss_dice: 0.2703  decode.d8.loss_cls: 0.2907  decode.d8.loss_mask: 0.2907  decode.d8.loss_dice: 0.2906
09/28 19:19:39 - mmengine - INFO - Iter(train) [ 39900/320000]  base_lr: 8.8705e-05 lr: 8.8705e-06  eta: 1 day, 10:12:53  time: 0.4724  data_time: 0.0097  memory: 5148  grad_norm: 46.7962  loss: 7.3500  decode.loss_cls: 0.0903  decode.loss_mask: 0.2386  decode.loss_dice: 0.2623  decode.d0.loss_cls: 0.9132  decode.d0.loss_mask: 0.2355  decode.d0.loss_dice: 0.2627  decode.d1.loss_cls: 0.1974  decode.d1.loss_mask: 0.2327  decode.d1.loss_dice: 0.2527  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.2536  decode.d3.loss_cls: 0.1722  decode.d3.loss_mask: 0.2368  decode.d3.loss_dice: 0.2495  decode.d4.loss_cls: 0.1578  decode.d4.loss_mask: 0.2349  decode.d4.loss_dice: 0.2522  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 0.2366  decode.d5.loss_dice: 0.2537  decode.d6.loss_cls: 0.1948  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2510  decode.d7.loss_cls: 0.1831  decode.d7.loss_mask: 0.2313  decode.d7.loss_dice: 0.2529  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 0.2337  decode.d8.loss_dice: 0.2491
09/28 19:20:03 - mmengine - INFO - Iter(train) [ 39950/320000]  base_lr: 8.8691e-05 lr: 8.8691e-06  eta: 1 day, 10:12:43  time: 0.4723  data_time: 0.0095  memory: 5186  grad_norm: 165.0249  loss: 8.4182  decode.loss_cls: 0.1514  decode.loss_mask: 0.3132  decode.loss_dice: 0.2721  decode.d0.loss_cls: 1.0103  decode.d0.loss_mask: 0.3066  decode.d0.loss_dice: 0.2565  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 0.3343  decode.d1.loss_dice: 0.2893  decode.d2.loss_cls: 0.1445  decode.d2.loss_mask: 0.3138  decode.d2.loss_dice: 0.2757  decode.d3.loss_cls: 0.1908  decode.d3.loss_mask: 0.3280  decode.d3.loss_dice: 0.2864  decode.d4.loss_cls: 0.1897  decode.d4.loss_mask: 0.3214  decode.d4.loss_dice: 0.2837  decode.d5.loss_cls: 0.1788  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.2833  decode.d6.loss_cls: 0.1592  decode.d6.loss_mask: 0.3145  decode.d6.loss_dice: 0.2881  decode.d7.loss_cls: 0.1311  decode.d7.loss_mask: 0.3095  decode.d7.loss_dice: 0.2767  decode.d8.loss_cls: 0.1587  decode.d8.loss_mask: 0.3112  decode.d8.loss_dice: 0.2725
09/28 19:20:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:20:25 - mmengine - INFO - Iter(train) [ 40000/320000]  base_lr: 8.8676e-05 lr: 8.8676e-06  eta: 1 day, 10:12:22  time: 0.4348  data_time: 0.0094  memory: 5166  grad_norm: 24.6806  loss: 6.9856  decode.loss_cls: 0.1280  decode.loss_mask: 0.2782  decode.loss_dice: 0.2102  decode.d0.loss_cls: 0.9338  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.2193  decode.d1.loss_cls: 0.1116  decode.d1.loss_mask: 0.2677  decode.d1.loss_dice: 0.2097  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.2731  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.1394  decode.d3.loss_mask: 0.2715  decode.d3.loss_dice: 0.2095  decode.d4.loss_cls: 0.1274  decode.d4.loss_mask: 0.2723  decode.d4.loss_dice: 0.2089  decode.d5.loss_cls: 0.1467  decode.d5.loss_mask: 0.2656  decode.d5.loss_dice: 0.2148  decode.d6.loss_cls: 0.1678  decode.d6.loss_mask: 0.2762  decode.d6.loss_dice: 0.2129  decode.d7.loss_cls: 0.1449  decode.d7.loss_mask: 0.2715  decode.d7.loss_dice: 0.2026  decode.d8.loss_cls: 0.1249  decode.d8.loss_mask: 0.2704  decode.d8.loss_dice: 0.2082
09/28 19:20:25 - mmengine - INFO - Saving checkpoint at 40000 iterations
09/28 19:20:40 - mmengine - INFO - Iter(val) [ 50/204]    eta: 0:00:40  time: 0.1727  data_time: 0.0043  memory: 9554  
09/28 19:20:48 - mmengine - INFO - Iter(val) [100/204]    eta: 0:00:22  time: 0.1737  data_time: 0.0045  memory: 3002  
09/28 19:20:57 - mmengine - INFO - Iter(val) [150/204]    eta: 0:00:10  time: 0.1737  data_time: 0.0048  memory: 3002  
09/28 19:21:06 - mmengine - INFO - Iter(val) [200/204]    eta: 0:00:00  time: 0.1718  data_time: 0.0041  memory: 3002  
09/28 19:21:06 - mmengine - INFO - per class results:
09/28 19:21:06 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|      background     | 99.04 |  99.6 |
|   beetroot poriyal  | 97.04 | 98.61 |
|        bhindi       | 38.01 | 46.52 |
| capsicum green peas | 71.98 | 95.96 |
|     dosakay dal     | 74.95 | 76.27 |
|    dosakaya curry   | 74.97 | 97.62 |
|    jaipuri sabji    | 97.29 | 98.29 |
|  ladiesfinger curry | 97.27 | 98.92 |
|    lobiya masala    | 89.57 | 97.93 |
|        pongal       | 96.67 | 97.66 |
|    pumpkin gravy    | 98.09 | 99.22 |
|     pumpkin dry     | 80.91 | 82.48 |
|     rajma masala    | 97.71 | 99.12 |
|      tomato dal     | 91.06 |  92.7 |
|     turai moong     | 83.19 | 93.15 |
|     turai tomato    | 85.71 | 86.71 |
|    beerakay curry   | 96.89 | 97.76 |
|   cabbage poriyal   | 96.72 | 97.57 |
|    capsicum gravy   | 97.72 | 98.84 |
|     chana masala    | 97.12 | 98.19 |
|       chapathi      | 97.63 | 98.62 |
|      chow-chow      | 97.13 | 98.23 |
|       chutney       |  96.9 | 98.58 |
|      curd rice      | 97.26 | 98.11 |
|         dal         | 90.77 | 92.49 |
|      dal tadka      | 97.07 | 97.73 |
|        daliya       | 97.74 | 98.68 |
|     daliya upma     | 91.94 | 97.94 |
|     donda curry     | 97.63 | 98.27 |
|    dosakaya gravy   | 91.59 | 97.66 |
|      egg white      | 90.52 | 93.86 |
|         idly        | 97.12 | 98.35 |
|       khichdi       | 91.77 |  96.5 |
| ladies finger gravy |  96.9 | 98.16 |
|      methi dal      | 97.79 | 99.01 |
|  mixed veg poriyal  | 92.63 | 93.79 |
|   palak soya curry  | 96.17 | 97.25 |
|     paneer gravy    | 97.62 | 98.52 |
|         poha        | 97.25 |  98.7 |
|    pumpkin masala   | 97.16 | 98.04 |
|    raw banana dry   | 94.72 | 95.82 |
|         rice        | 96.21 |  97.9 |
|         roti        | 95.97 | 97.11 |
|        sambar       | 81.09 | 98.48 |
|    snakegourd dry   | 51.85 | 52.85 |
|   snakeguard curry  | 97.76 |  99.0 |
|      soya gravy     | 90.37 | 90.95 |
|   thotakura pappu   | 93.45 | 98.32 |
|         upma        |  0.0  |  0.0  |
|       uttapam       | 98.31 | 99.56 |
+---------------------+-------+-------+
09/28 19:21:06 - mmengine - INFO - Iter(val) [204/204]    aAcc: 98.9300  mIoU: 89.4400  mAcc: 92.6300  data_time: 0.0067  time: 0.1951
09/28 19:21:08 - mmengine - INFO - The best checkpoint with 89.4400 mIoU at 40000 iter is saved to best_mIoU_iter_40000.pth.
09/28 19:21:35 - mmengine - INFO - Iter(train) [ 40050/320000]  base_lr: 8.8662e-05 lr: 8.8662e-06  eta: 1 day, 10:12:46  time: 0.4363  data_time: 0.0093  memory: 5163  grad_norm: 114.7165  loss: 5.9966  decode.loss_cls: 0.0434  decode.loss_mask: 0.2563  decode.loss_dice: 0.2062  decode.d0.loss_cls: 0.9847  decode.d0.loss_mask: 0.2663  decode.d0.loss_dice: 0.2133  decode.d1.loss_cls: 0.0336  decode.d1.loss_mask: 0.2598  decode.d1.loss_dice: 0.2027  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.2075  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.2085  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.2089  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.2540  decode.d5.loss_dice: 0.2045  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.2592  decode.d6.loss_dice: 0.1981  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 0.2608  decode.d7.loss_dice: 0.2039  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.2559  decode.d8.loss_dice: 0.2069
09/28 19:21:57 - mmengine - INFO - Iter(train) [ 40100/320000]  base_lr: 8.8648e-05 lr: 8.8648e-06  eta: 1 day, 10:12:22  time: 0.4368  data_time: 0.0096  memory: 5147  grad_norm: 39.1668  loss: 7.1076  decode.loss_cls: 0.0978  decode.loss_mask: 0.2210  decode.loss_dice: 0.3030  decode.d0.loss_cls: 1.1707  decode.d0.loss_mask: 0.2249  decode.d0.loss_dice: 0.2941  decode.d1.loss_cls: 0.1426  decode.d1.loss_mask: 0.2207  decode.d1.loss_dice: 0.2725  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.2791  decode.d3.loss_cls: 0.0907  decode.d3.loss_mask: 0.2201  decode.d3.loss_dice: 0.2872  decode.d4.loss_cls: 0.0706  decode.d4.loss_mask: 0.2194  decode.d4.loss_dice: 0.2709  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.2162  decode.d5.loss_dice: 0.2688  decode.d6.loss_cls: 0.0904  decode.d6.loss_mask: 0.2185  decode.d6.loss_dice: 0.2771  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.2230  decode.d7.loss_dice: 0.2504  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.2236  decode.d8.loss_dice: 0.3039
09/28 19:22:19 - mmengine - INFO - Iter(train) [ 40150/320000]  base_lr: 8.8634e-05 lr: 8.8634e-06  eta: 1 day, 10:11:59  time: 0.4372  data_time: 0.0095  memory: 5147  grad_norm: 52.2269  loss: 6.7524  decode.loss_cls: 0.0588  decode.loss_mask: 0.2661  decode.loss_dice: 0.2410  decode.d0.loss_cls: 0.7598  decode.d0.loss_mask: 0.2468  decode.d0.loss_dice: 0.2617  decode.d1.loss_cls: 0.1447  decode.d1.loss_mask: 0.2515  decode.d1.loss_dice: 0.2482  decode.d2.loss_cls: 0.1334  decode.d2.loss_mask: 0.2553  decode.d2.loss_dice: 0.2423  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.2439  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.2665  decode.d4.loss_dice: 0.2438  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.2794  decode.d5.loss_dice: 0.2436  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.2629  decode.d6.loss_dice: 0.2404  decode.d7.loss_cls: 0.1368  decode.d7.loss_mask: 0.2417  decode.d7.loss_dice: 0.2369  decode.d8.loss_cls: 0.1495  decode.d8.loss_mask: 0.2467  decode.d8.loss_dice: 0.2391
09/28 19:22:41 - mmengine - INFO - Iter(train) [ 40200/320000]  base_lr: 8.8619e-05 lr: 8.8619e-06  eta: 1 day, 10:11:36  time: 0.4364  data_time: 0.0095  memory: 5147  grad_norm: 131.9065  loss: 6.6735  decode.loss_cls: 0.1282  decode.loss_mask: 0.2363  decode.loss_dice: 0.2065  decode.d0.loss_cls: 0.9410  decode.d0.loss_mask: 0.2461  decode.d0.loss_dice: 0.2031  decode.d1.loss_cls: 0.1304  decode.d1.loss_mask: 0.2434  decode.d1.loss_dice: 0.2284  decode.d2.loss_cls: 0.1021  decode.d2.loss_mask: 0.2629  decode.d2.loss_dice: 0.2466  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.2625  decode.d3.loss_dice: 0.2567  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.2719  decode.d5.loss_dice: 0.2673  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.2553  decode.d6.loss_dice: 0.2410  decode.d7.loss_cls: 0.1304  decode.d7.loss_mask: 0.2404  decode.d7.loss_dice: 0.2140  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 0.2388  decode.d8.loss_dice: 0.2007
09/28 19:23:02 - mmengine - INFO - Iter(train) [ 40250/320000]  base_lr: 8.8605e-05 lr: 8.8605e-06  eta: 1 day, 10:11:13  time: 0.4368  data_time: 0.0095  memory: 5147  grad_norm: 114.8210  loss: 7.1885  decode.loss_cls: 0.1073  decode.loss_mask: 0.2453  decode.loss_dice: 0.2340  decode.d0.loss_cls: 0.8969  decode.d0.loss_mask: 0.2501  decode.d0.loss_dice: 0.2247  decode.d1.loss_cls: 0.1440  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.1195  decode.d2.loss_mask: 0.2510  decode.d2.loss_dice: 0.2814  decode.d3.loss_cls: 0.1410  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.3025  decode.d4.loss_cls: 0.1433  decode.d4.loss_mask: 0.2791  decode.d4.loss_dice: 0.3051  decode.d5.loss_cls: 0.1171  decode.d5.loss_mask: 0.2732  decode.d5.loss_dice: 0.2982  decode.d6.loss_cls: 0.1461  decode.d6.loss_mask: 0.2473  decode.d6.loss_dice: 0.2362  decode.d7.loss_cls: 0.1218  decode.d7.loss_mask: 0.2473  decode.d7.loss_dice: 0.2452  decode.d8.loss_cls: 0.0993  decode.d8.loss_mask: 0.2415  decode.d8.loss_dice: 0.2307
09/28 19:23:24 - mmengine - INFO - Iter(train) [ 40300/320000]  base_lr: 8.8591e-05 lr: 8.8591e-06  eta: 1 day, 10:10:50  time: 0.4371  data_time: 0.0094  memory: 5117  grad_norm: 84.2551  loss: 5.0393  decode.loss_cls: 0.0087  decode.loss_mask: 0.2174  decode.loss_dice: 0.2129  decode.d0.loss_cls: 0.7466  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2152  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.2023  decode.d1.loss_dice: 0.2032  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.2026  decode.d2.loss_dice: 0.2036  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.2055  decode.d3.loss_dice: 0.2065  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.2093  decode.d4.loss_dice: 0.2104  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.2063  decode.d5.loss_dice: 0.2153  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.2107  decode.d6.loss_dice: 0.2094  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2151  decode.d7.loss_dice: 0.2122  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.2090  decode.d8.loss_dice: 0.2106
09/28 19:23:46 - mmengine - INFO - Iter(train) [ 40350/320000]  base_lr: 8.8577e-05 lr: 8.8577e-06  eta: 1 day, 10:10:27  time: 0.4367  data_time: 0.0094  memory: 5117  grad_norm: 76.1521  loss: 8.9358  decode.loss_cls: 0.3230  decode.loss_mask: 0.2213  decode.loss_dice: 0.2556  decode.d0.loss_cls: 0.8701  decode.d0.loss_mask: 0.2296  decode.d0.loss_dice: 0.2902  decode.d1.loss_cls: 0.3378  decode.d1.loss_mask: 0.2265  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.3128  decode.d2.loss_mask: 0.2272  decode.d2.loss_dice: 0.2839  decode.d3.loss_cls: 0.3242  decode.d3.loss_mask: 0.2228  decode.d3.loss_dice: 0.2573  decode.d4.loss_cls: 0.3375  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.2904  decode.d5.loss_cls: 0.3676  decode.d5.loss_mask: 0.2229  decode.d5.loss_dice: 0.2768  decode.d6.loss_cls: 0.3817  decode.d6.loss_mask: 0.2238  decode.d6.loss_dice: 0.2857  decode.d7.loss_cls: 0.3727  decode.d7.loss_mask: 0.2231  decode.d7.loss_dice: 0.2565  decode.d8.loss_cls: 0.3619  decode.d8.loss_mask: 0.2202  decode.d8.loss_dice: 0.2614
09/28 19:24:08 - mmengine - INFO - Iter(train) [ 40400/320000]  base_lr: 8.8562e-05 lr: 8.8562e-06  eta: 1 day, 10:10:04  time: 0.4368  data_time: 0.0095  memory: 5147  grad_norm: 50.5275  loss: 5.2734  decode.loss_cls: 0.0168  decode.loss_mask: 0.2351  decode.loss_dice: 0.1783  decode.d0.loss_cls: 0.8887  decode.d0.loss_mask: 0.2386  decode.d0.loss_dice: 0.1831  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.2389  decode.d1.loss_dice: 0.1789  decode.d2.loss_cls: 0.0253  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.1824  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.2334  decode.d3.loss_dice: 0.1801  decode.d4.loss_cls: 0.0156  decode.d4.loss_mask: 0.2346  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.2355  decode.d5.loss_dice: 0.1825  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.2328  decode.d6.loss_dice: 0.1782  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.2378  decode.d7.loss_dice: 0.1832  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.1807
09/28 19:24:30 - mmengine - INFO - Iter(train) [ 40450/320000]  base_lr: 8.8548e-05 lr: 8.8548e-06  eta: 1 day, 10:09:41  time: 0.4366  data_time: 0.0096  memory: 5132  grad_norm: 126.7471  loss: 6.6271  decode.loss_cls: 0.0568  decode.loss_mask: 0.2823  decode.loss_dice: 0.2281  decode.d0.loss_cls: 0.8763  decode.d0.loss_mask: 0.2944  decode.d0.loss_dice: 0.2283  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.2912  decode.d1.loss_dice: 0.2261  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.2306  decode.d3.loss_cls: 0.0301  decode.d3.loss_mask: 0.2873  decode.d3.loss_dice: 0.2412  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.2879  decode.d4.loss_dice: 0.2317  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.2378  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.2910  decode.d6.loss_dice: 0.2303  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.2865  decode.d7.loss_dice: 0.2277  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.2291
09/28 19:24:52 - mmengine - INFO - Iter(train) [ 40500/320000]  base_lr: 8.8534e-05 lr: 8.8534e-06  eta: 1 day, 10:09:18  time: 0.4373  data_time: 0.0096  memory: 5117  grad_norm: 119.8674  loss: 8.3125  decode.loss_cls: 0.1471  decode.loss_mask: 0.3350  decode.loss_dice: 0.2482  decode.d0.loss_cls: 0.9050  decode.d0.loss_mask: 0.3421  decode.d0.loss_dice: 0.2476  decode.d1.loss_cls: 0.2611  decode.d1.loss_mask: 0.3416  decode.d1.loss_dice: 0.2280  decode.d2.loss_cls: 0.2513  decode.d2.loss_mask: 0.3382  decode.d2.loss_dice: 0.2294  decode.d3.loss_cls: 0.2493  decode.d3.loss_mask: 0.3037  decode.d3.loss_dice: 0.2270  decode.d4.loss_cls: 0.2632  decode.d4.loss_mask: 0.3017  decode.d4.loss_dice: 0.2160  decode.d5.loss_cls: 0.1791  decode.d5.loss_mask: 0.3068  decode.d5.loss_dice: 0.2418  decode.d6.loss_cls: 0.2040  decode.d6.loss_mask: 0.3070  decode.d6.loss_dice: 0.2168  decode.d7.loss_cls: 0.1536  decode.d7.loss_mask: 0.3130  decode.d7.loss_dice: 0.2444  decode.d8.loss_cls: 0.1617  decode.d8.loss_mask: 0.3083  decode.d8.loss_dice: 0.2404
09/28 19:25:13 - mmengine - INFO - Iter(train) [ 40550/320000]  base_lr: 8.8520e-05 lr: 8.8520e-06  eta: 1 day, 10:08:55  time: 0.4376  data_time: 0.0096  memory: 5147  grad_norm: 119.4268  loss: 9.1624  decode.loss_cls: 0.2114  decode.loss_mask: 0.3213  decode.loss_dice: 0.2883  decode.d0.loss_cls: 1.1109  decode.d0.loss_mask: 0.2515  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.2521  decode.d1.loss_mask: 0.2613  decode.d1.loss_dice: 0.2883  decode.d2.loss_cls: 0.2205  decode.d2.loss_mask: 0.2574  decode.d2.loss_dice: 0.2532  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.2740  decode.d4.loss_cls: 0.2912  decode.d4.loss_mask: 0.3104  decode.d4.loss_dice: 0.2725  decode.d5.loss_cls: 0.2841  decode.d5.loss_mask: 0.2844  decode.d5.loss_dice: 0.3032  decode.d6.loss_cls: 0.3296  decode.d6.loss_mask: 0.2951  decode.d6.loss_dice: 0.2933  decode.d7.loss_cls: 0.2399  decode.d7.loss_mask: 0.3343  decode.d7.loss_dice: 0.2958  decode.d8.loss_cls: 0.2652  decode.d8.loss_mask: 0.2685  decode.d8.loss_dice: 0.2803
09/28 19:25:36 - mmengine - INFO - Iter(train) [ 40600/320000]  base_lr: 8.8505e-05 lr: 8.8505e-06  eta: 1 day, 10:08:33  time: 0.4567  data_time: 0.0094  memory: 5132  grad_norm: 66.6924  loss: 7.3138  decode.loss_cls: 0.2134  decode.loss_mask: 0.2266  decode.loss_dice: 0.2211  decode.d0.loss_cls: 0.9898  decode.d0.loss_mask: 0.2330  decode.d0.loss_dice: 0.2356  decode.d1.loss_cls: 0.2505  decode.d1.loss_mask: 0.2266  decode.d1.loss_dice: 0.1904  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 0.2245  decode.d2.loss_dice: 0.1849  decode.d3.loss_cls: 0.1894  decode.d3.loss_mask: 0.2248  decode.d3.loss_dice: 0.2023  decode.d4.loss_cls: 0.1643  decode.d4.loss_mask: 0.2255  decode.d4.loss_dice: 0.1972  decode.d5.loss_cls: 0.2135  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.2147  decode.d6.loss_cls: 0.2173  decode.d6.loss_mask: 0.2255  decode.d6.loss_dice: 0.2072  decode.d7.loss_cls: 0.2574  decode.d7.loss_mask: 0.2263  decode.d7.loss_dice: 0.2106  decode.d8.loss_cls: 0.2253  decode.d8.loss_mask: 0.2275  decode.d8.loss_dice: 0.2247
09/28 19:25:57 - mmengine - INFO - Iter(train) [ 40650/320000]  base_lr: 8.8491e-05 lr: 8.8491e-06  eta: 1 day, 10:08:10  time: 0.4364  data_time: 0.0094  memory: 5117  grad_norm: 50.8916  loss: 6.6023  decode.loss_cls: 0.1043  decode.loss_mask: 0.2298  decode.loss_dice: 0.2165  decode.d0.loss_cls: 0.9682  decode.d0.loss_mask: 0.2375  decode.d0.loss_dice: 0.2362  decode.d1.loss_cls: 0.1673  decode.d1.loss_mask: 0.2300  decode.d1.loss_dice: 0.1816  decode.d2.loss_cls: 0.1630  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.2324  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.2303  decode.d3.loss_dice: 0.2286  decode.d4.loss_cls: 0.0899  decode.d4.loss_mask: 0.2324  decode.d4.loss_dice: 0.2322  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.2369  decode.d5.loss_dice: 0.2212  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.2376  decode.d6.loss_dice: 0.2487  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.2359  decode.d7.loss_dice: 0.2281  decode.d8.loss_cls: 0.1465  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.2053
09/28 19:26:19 - mmengine - INFO - Iter(train) [ 40700/320000]  base_lr: 8.8477e-05 lr: 8.8477e-06  eta: 1 day, 10:07:47  time: 0.4372  data_time: 0.0096  memory: 5147  grad_norm: 56.6602  loss: 5.5776  decode.loss_cls: 0.0595  decode.loss_mask: 0.2196  decode.loss_dice: 0.1868  decode.d0.loss_cls: 0.8974  decode.d0.loss_mask: 0.2210  decode.d0.loss_dice: 0.1919  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.2202  decode.d1.loss_dice: 0.1875  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.1815  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.2186  decode.d3.loss_dice: 0.1828  decode.d4.loss_cls: 0.0940  decode.d4.loss_mask: 0.2199  decode.d4.loss_dice: 0.1965  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.2194  decode.d5.loss_dice: 0.1646  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.2216  decode.d6.loss_dice: 0.1861  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.1825  decode.d8.loss_cls: 0.0892  decode.d8.loss_mask: 0.2197  decode.d8.loss_dice: 0.1788
09/28 19:26:41 - mmengine - INFO - Iter(train) [ 40750/320000]  base_lr: 8.8463e-05 lr: 8.8463e-06  eta: 1 day, 10:07:24  time: 0.4369  data_time: 0.0094  memory: 5147  grad_norm: 25.0384  loss: 5.7531  decode.loss_cls: 0.0519  decode.loss_mask: 0.2299  decode.loss_dice: 0.1996  decode.d0.loss_cls: 0.8207  decode.d0.loss_mask: 0.2320  decode.d0.loss_dice: 0.2074  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.2272  decode.d1.loss_dice: 0.1982  decode.d2.loss_cls: 0.0867  decode.d2.loss_mask: 0.2288  decode.d2.loss_dice: 0.1995  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.2296  decode.d3.loss_dice: 0.1976  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 0.2313  decode.d4.loss_dice: 0.1986  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.2320  decode.d5.loss_dice: 0.1973  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.2290  decode.d6.loss_dice: 0.2010  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.2307  decode.d7.loss_dice: 0.1994  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.1951
09/28 19:27:03 - mmengine - INFO - Iter(train) [ 40800/320000]  base_lr: 8.8448e-05 lr: 8.8448e-06  eta: 1 day, 10:07:01  time: 0.4365  data_time: 0.0093  memory: 5147  grad_norm: 41.0071  loss: 4.8965  decode.loss_cls: 0.0430  decode.loss_mask: 0.2060  decode.loss_dice: 0.1590  decode.d0.loss_cls: 0.8589  decode.d0.loss_mask: 0.2062  decode.d0.loss_dice: 0.1657  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.2032  decode.d1.loss_dice: 0.1611  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 0.2068  decode.d2.loss_dice: 0.1593  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.2053  decode.d3.loss_dice: 0.1566  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.1641  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.2050  decode.d5.loss_dice: 0.1585  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.2021  decode.d6.loss_dice: 0.1559  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.2049  decode.d7.loss_dice: 0.1587  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.2018  decode.d8.loss_dice: 0.1549
09/28 19:27:25 - mmengine - INFO - Iter(train) [ 40850/320000]  base_lr: 8.8434e-05 lr: 8.8434e-06  eta: 1 day, 10:06:38  time: 0.4371  data_time: 0.0094  memory: 5117  grad_norm: 20.4262  loss: 4.9537  decode.loss_cls: 0.0119  decode.loss_mask: 0.2066  decode.loss_dice: 0.1889  decode.d0.loss_cls: 0.8259  decode.d0.loss_mask: 0.2077  decode.d0.loss_dice: 0.1931  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.2088  decode.d1.loss_dice: 0.1942  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.2048  decode.d2.loss_dice: 0.1970  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.2056  decode.d3.loss_dice: 0.1948  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.2030  decode.d4.loss_dice: 0.1951  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.2030  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.2063  decode.d6.loss_dice: 0.1905  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2064  decode.d7.loss_dice: 0.1920  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.2042  decode.d8.loss_dice: 0.1924
09/28 19:27:47 - mmengine - INFO - Iter(train) [ 40900/320000]  base_lr: 8.8420e-05 lr: 8.8420e-06  eta: 1 day, 10:06:15  time: 0.4365  data_time: 0.0096  memory: 5147  grad_norm: 57.5740  loss: 6.1220  decode.loss_cls: 0.0689  decode.loss_mask: 0.2204  decode.loss_dice: 0.2226  decode.d0.loss_cls: 0.9640  decode.d0.loss_mask: 0.2205  decode.d0.loss_dice: 0.1902  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 0.2155  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.2137  decode.d2.loss_dice: 0.2125  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.2161  decode.d3.loss_dice: 0.1983  decode.d4.loss_cls: 0.0973  decode.d4.loss_mask: 0.2203  decode.d4.loss_dice: 0.2342  decode.d5.loss_cls: 0.0995  decode.d5.loss_mask: 0.2151  decode.d5.loss_dice: 0.1950  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.2161  decode.d6.loss_dice: 0.1847  decode.d7.loss_cls: 0.0945  decode.d7.loss_mask: 0.2160  decode.d7.loss_dice: 0.2294  decode.d8.loss_cls: 0.0969  decode.d8.loss_mask: 0.2152  decode.d8.loss_dice: 0.2372
09/28 19:28:09 - mmengine - INFO - Iter(train) [ 40950/320000]  base_lr: 8.8406e-05 lr: 8.8406e-06  eta: 1 day, 10:05:52  time: 0.4367  data_time: 0.0094  memory: 5147  grad_norm: 143.3370  loss: 10.7059  decode.loss_cls: 0.2741  decode.loss_mask: 0.4737  decode.loss_dice: 0.2203  decode.d0.loss_cls: 0.9139  decode.d0.loss_mask: 0.5001  decode.d0.loss_dice: 0.2636  decode.d1.loss_cls: 0.3108  decode.d1.loss_mask: 0.4827  decode.d1.loss_dice: 0.2550  decode.d2.loss_cls: 0.2980  decode.d2.loss_mask: 0.5027  decode.d2.loss_dice: 0.2467  decode.d3.loss_cls: 0.3389  decode.d3.loss_mask: 0.5127  decode.d3.loss_dice: 0.2440  decode.d4.loss_cls: 0.3187  decode.d4.loss_mask: 0.4844  decode.d4.loss_dice: 0.2269  decode.d5.loss_cls: 0.2508  decode.d5.loss_mask: 0.4734  decode.d5.loss_dice: 0.2255  decode.d6.loss_cls: 0.2464  decode.d6.loss_mask: 0.4821  decode.d6.loss_dice: 0.2224  decode.d7.loss_cls: 0.2640  decode.d7.loss_mask: 0.4718  decode.d7.loss_dice: 0.2205  decode.d8.loss_cls: 0.2793  decode.d8.loss_mask: 0.4744  decode.d8.loss_dice: 0.2283
09/28 19:28:30 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:28:30 - mmengine - INFO - Iter(train) [ 41000/320000]  base_lr: 8.8391e-05 lr: 8.8391e-06  eta: 1 day, 10:05:30  time: 0.4374  data_time: 0.0096  memory: 5117  grad_norm: 55.0455  loss: 7.9976  decode.loss_cls: 0.0406  decode.loss_mask: 0.3881  decode.loss_dice: 0.2817  decode.d0.loss_cls: 0.7791  decode.d0.loss_mask: 0.4069  decode.d0.loss_dice: 0.2855  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.3944  decode.d1.loss_dice: 0.2756  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.3932  decode.d2.loss_dice: 0.2799  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.3947  decode.d3.loss_dice: 0.2792  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.3923  decode.d4.loss_dice: 0.2767  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.3994  decode.d5.loss_dice: 0.2836  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.3948  decode.d6.loss_dice: 0.2813  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 0.3888  decode.d7.loss_dice: 0.2817  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.3935  decode.d8.loss_dice: 0.2807
09/28 19:28:52 - mmengine - INFO - Iter(train) [ 41050/320000]  base_lr: 8.8377e-05 lr: 8.8377e-06  eta: 1 day, 10:05:07  time: 0.4375  data_time: 0.0096  memory: 5117  grad_norm: 63.1151  loss: 5.6129  decode.loss_cls: 0.1137  decode.loss_mask: 0.2198  decode.loss_dice: 0.2005  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 0.2220  decode.d0.loss_dice: 0.1915  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.2203  decode.d1.loss_dice: 0.1925  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.2158  decode.d2.loss_dice: 0.1884  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.2185  decode.d3.loss_dice: 0.1906  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.2172  decode.d4.loss_dice: 0.1874  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.2196  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0711  decode.d6.loss_mask: 0.2172  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.2169  decode.d7.loss_dice: 0.1894  decode.d8.loss_cls: 0.0961  decode.d8.loss_mask: 0.2183  decode.d8.loss_dice: 0.1941
09/28 19:29:14 - mmengine - INFO - Iter(train) [ 41100/320000]  base_lr: 8.8363e-05 lr: 8.8363e-06  eta: 1 day, 10:04:44  time: 0.4373  data_time: 0.0095  memory: 5133  grad_norm: 97.6549  loss: 6.9978  decode.loss_cls: 0.1135  decode.loss_mask: 0.2792  decode.loss_dice: 0.2272  decode.d0.loss_cls: 0.8955  decode.d0.loss_mask: 0.2898  decode.d0.loss_dice: 0.2569  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.2812  decode.d1.loss_dice: 0.2367  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.2202  decode.d3.loss_cls: 0.0715  decode.d3.loss_mask: 0.2846  decode.d3.loss_dice: 0.2210  decode.d4.loss_cls: 0.0804  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.2381  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.2865  decode.d5.loss_dice: 0.2383  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.3015  decode.d7.loss_dice: 0.2457  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.2603
09/28 19:29:36 - mmengine - INFO - Iter(train) [ 41150/320000]  base_lr: 8.8349e-05 lr: 8.8349e-06  eta: 1 day, 10:04:21  time: 0.4365  data_time: 0.0094  memory: 5147  grad_norm: 60.9487  loss: 6.9802  decode.loss_cls: 0.1192  decode.loss_mask: 0.2207  decode.loss_dice: 0.2348  decode.d0.loss_cls: 0.7967  decode.d0.loss_mask: 0.2246  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.2000  decode.d1.loss_mask: 0.2208  decode.d1.loss_dice: 0.2648  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 0.2234  decode.d2.loss_dice: 0.2152  decode.d3.loss_cls: 0.2062  decode.d3.loss_mask: 0.2216  decode.d3.loss_dice: 0.2335  decode.d4.loss_cls: 0.1804  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.2627  decode.d5.loss_cls: 0.1964  decode.d5.loss_mask: 0.2204  decode.d5.loss_dice: 0.2396  decode.d6.loss_cls: 0.2043  decode.d6.loss_mask: 0.2218  decode.d6.loss_dice: 0.2614  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.2233  decode.d7.loss_dice: 0.2392  decode.d8.loss_cls: 0.1244  decode.d8.loss_mask: 0.2216  decode.d8.loss_dice: 0.1966
09/28 19:29:58 - mmengine - INFO - Iter(train) [ 41200/320000]  base_lr: 8.8334e-05 lr: 8.8334e-06  eta: 1 day, 10:03:58  time: 0.4376  data_time: 0.0093  memory: 5147  grad_norm: 58.0066  loss: 6.1519  decode.loss_cls: 0.0960  decode.loss_mask: 0.2025  decode.loss_dice: 0.2227  decode.d0.loss_cls: 1.0234  decode.d0.loss_mask: 0.2053  decode.d0.loss_dice: 0.2228  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.2121  decode.d1.loss_dice: 0.2170  decode.d2.loss_cls: 0.1333  decode.d2.loss_mask: 0.2046  decode.d2.loss_dice: 0.2274  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.2063  decode.d3.loss_dice: 0.2192  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.2045  decode.d4.loss_dice: 0.1938  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.2046  decode.d5.loss_dice: 0.2258  decode.d6.loss_cls: 0.1215  decode.d6.loss_mask: 0.2040  decode.d6.loss_dice: 0.1969  decode.d7.loss_cls: 0.1045  decode.d7.loss_mask: 0.2060  decode.d7.loss_dice: 0.2206  decode.d8.loss_cls: 0.1108  decode.d8.loss_mask: 0.2054  decode.d8.loss_dice: 0.2220
09/28 19:30:20 - mmengine - INFO - Iter(train) [ 41250/320000]  base_lr: 8.8320e-05 lr: 8.8320e-06  eta: 1 day, 10:03:35  time: 0.4373  data_time: 0.0093  memory: 5133  grad_norm: 72.8057  loss: 6.4013  decode.loss_cls: 0.0793  decode.loss_mask: 0.2778  decode.loss_dice: 0.2171  decode.d0.loss_cls: 0.8540  decode.d0.loss_mask: 0.2973  decode.d0.loss_dice: 0.2261  decode.d1.loss_cls: 0.1051  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.2117  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.2644  decode.d2.loss_dice: 0.2232  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.2618  decode.d3.loss_dice: 0.2184  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 0.2670  decode.d4.loss_dice: 0.2139  decode.d5.loss_cls: 0.0753  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.2082  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.2110  decode.d7.loss_cls: 0.0427  decode.d7.loss_mask: 0.2680  decode.d7.loss_dice: 0.2259  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.2727  decode.d8.loss_dice: 0.2080
09/28 19:30:42 - mmengine - INFO - Iter(train) [ 41300/320000]  base_lr: 8.8306e-05 lr: 8.8306e-06  eta: 1 day, 10:03:12  time: 0.4369  data_time: 0.0094  memory: 5132  grad_norm: 26.5150  loss: 6.1296  decode.loss_cls: 0.0776  decode.loss_mask: 0.2141  decode.loss_dice: 0.2056  decode.d0.loss_cls: 0.9574  decode.d0.loss_mask: 0.2179  decode.d0.loss_dice: 0.2171  decode.d1.loss_cls: 0.1399  decode.d1.loss_mask: 0.2130  decode.d1.loss_dice: 0.2114  decode.d2.loss_cls: 0.0943  decode.d2.loss_mask: 0.2124  decode.d2.loss_dice: 0.2051  decode.d3.loss_cls: 0.1033  decode.d3.loss_mask: 0.2128  decode.d3.loss_dice: 0.2231  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.2114  decode.d5.loss_cls: 0.1280  decode.d5.loss_mask: 0.2130  decode.d5.loss_dice: 0.2249  decode.d6.loss_cls: 0.0878  decode.d6.loss_mask: 0.2099  decode.d6.loss_dice: 0.2213  decode.d7.loss_cls: 0.1036  decode.d7.loss_mask: 0.2139  decode.d7.loss_dice: 0.2060  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.2134  decode.d8.loss_dice: 0.2006
09/28 19:31:03 - mmengine - INFO - Iter(train) [ 41350/320000]  base_lr: 8.8292e-05 lr: 8.8292e-06  eta: 1 day, 10:02:49  time: 0.4361  data_time: 0.0094  memory: 5147  grad_norm: 129.5866  loss: 9.1719  decode.loss_cls: 0.2693  decode.loss_mask: 0.2604  decode.loss_dice: 0.2726  decode.d0.loss_cls: 0.9991  decode.d0.loss_mask: 0.2844  decode.d0.loss_dice: 0.2717  decode.d1.loss_cls: 0.3343  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.3068  decode.d2.loss_cls: 0.2880  decode.d2.loss_mask: 0.2830  decode.d2.loss_dice: 0.3037  decode.d3.loss_cls: 0.2505  decode.d3.loss_mask: 0.2681  decode.d3.loss_dice: 0.3248  decode.d4.loss_cls: 0.3366  decode.d4.loss_mask: 0.2680  decode.d4.loss_dice: 0.2999  decode.d5.loss_cls: 0.2652  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.2799  decode.d6.loss_cls: 0.3242  decode.d6.loss_mask: 0.2823  decode.d6.loss_dice: 0.2526  decode.d7.loss_cls: 0.2292  decode.d7.loss_mask: 0.2786  decode.d7.loss_dice: 0.2708  decode.d8.loss_cls: 0.2805  decode.d8.loss_mask: 0.2673  decode.d8.loss_dice: 0.2724
09/28 19:31:25 - mmengine - INFO - Iter(train) [ 41400/320000]  base_lr: 8.8277e-05 lr: 8.8277e-06  eta: 1 day, 10:02:26  time: 0.4372  data_time: 0.0096  memory: 5133  grad_norm: 27.8664  loss: 5.5307  decode.loss_cls: 0.0030  decode.loss_mask: 0.2518  decode.loss_dice: 0.2022  decode.d0.loss_cls: 0.8688  decode.d0.loss_mask: 0.2524  decode.d0.loss_dice: 0.2137  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.2520  decode.d2.loss_dice: 0.2017  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.2525  decode.d3.loss_dice: 0.1996  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.2510  decode.d4.loss_dice: 0.2198  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.2501  decode.d5.loss_dice: 0.2094  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.2108  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.2538  decode.d7.loss_dice: 0.2061  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.2523  decode.d8.loss_dice: 0.2064
09/28 19:31:47 - mmengine - INFO - Iter(train) [ 41450/320000]  base_lr: 8.8263e-05 lr: 8.8263e-06  eta: 1 day, 10:02:04  time: 0.4400  data_time: 0.0096  memory: 5117  grad_norm: 54.3035  loss: 6.9914  decode.loss_cls: 0.1532  decode.loss_mask: 0.2362  decode.loss_dice: 0.1933  decode.d0.loss_cls: 1.0209  decode.d0.loss_mask: 0.2115  decode.d0.loss_dice: 0.2294  decode.d1.loss_cls: 0.1568  decode.d1.loss_mask: 0.2691  decode.d1.loss_dice: 0.2019  decode.d2.loss_cls: 0.1370  decode.d2.loss_mask: 0.2372  decode.d2.loss_dice: 0.1982  decode.d3.loss_cls: 0.2022  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.2064  decode.d4.loss_cls: 0.1682  decode.d4.loss_mask: 0.2433  decode.d4.loss_dice: 0.2037  decode.d5.loss_cls: 0.1668  decode.d5.loss_mask: 0.2285  decode.d5.loss_dice: 0.2038  decode.d6.loss_cls: 0.1519  decode.d6.loss_mask: 0.2465  decode.d6.loss_dice: 0.1835  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.2920  decode.d7.loss_dice: 0.1976  decode.d8.loss_cls: 0.1568  decode.d8.loss_mask: 0.2706  decode.d8.loss_dice: 0.2041
09/28 19:32:09 - mmengine - INFO - Iter(train) [ 41500/320000]  base_lr: 8.8249e-05 lr: 8.8249e-06  eta: 1 day, 10:01:41  time: 0.4372  data_time: 0.0096  memory: 5117  grad_norm: 82.5792  loss: 6.4789  decode.loss_cls: 0.0858  decode.loss_mask: 0.2325  decode.loss_dice: 0.2465  decode.d0.loss_cls: 0.8232  decode.d0.loss_mask: 0.2362  decode.d0.loss_dice: 0.2337  decode.d1.loss_cls: 0.1718  decode.d1.loss_mask: 0.2320  decode.d1.loss_dice: 0.2510  decode.d2.loss_cls: 0.1015  decode.d2.loss_mask: 0.2330  decode.d2.loss_dice: 0.2551  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.2362  decode.d3.loss_dice: 0.2631  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.2309  decode.d4.loss_dice: 0.2460  decode.d5.loss_cls: 0.0978  decode.d5.loss_mask: 0.2281  decode.d5.loss_dice: 0.2309  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2219  decode.d7.loss_cls: 0.0846  decode.d7.loss_mask: 0.2365  decode.d7.loss_dice: 0.2438  decode.d8.loss_cls: 0.0990  decode.d8.loss_mask: 0.2364  decode.d8.loss_dice: 0.2477
09/28 19:32:31 - mmengine - INFO - Iter(train) [ 41550/320000]  base_lr: 8.8235e-05 lr: 8.8235e-06  eta: 1 day, 10:01:18  time: 0.4377  data_time: 0.0097  memory: 5133  grad_norm: 97.6344  loss: 8.0443  decode.loss_cls: 0.1898  decode.loss_mask: 0.2513  decode.loss_dice: 0.2393  decode.d0.loss_cls: 1.1753  decode.d0.loss_mask: 0.2406  decode.d0.loss_dice: 0.2212  decode.d1.loss_cls: 0.2168  decode.d1.loss_mask: 0.2613  decode.d1.loss_dice: 0.2449  decode.d2.loss_cls: 0.2487  decode.d2.loss_mask: 0.2485  decode.d2.loss_dice: 0.2365  decode.d3.loss_cls: 0.2082  decode.d3.loss_mask: 0.2499  decode.d3.loss_dice: 0.2376  decode.d4.loss_cls: 0.1922  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.2447  decode.d5.loss_cls: 0.1902  decode.d5.loss_mask: 0.2763  decode.d5.loss_dice: 0.2665  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 0.2624  decode.d6.loss_dice: 0.2751  decode.d7.loss_cls: 0.1834  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.2656  decode.d8.loss_cls: 0.2028  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.2441
09/28 19:32:53 - mmengine - INFO - Iter(train) [ 41600/320000]  base_lr: 8.8220e-05 lr: 8.8220e-06  eta: 1 day, 10:00:55  time: 0.4355  data_time: 0.0093  memory: 5147  grad_norm: 35.8703  loss: 5.1382  decode.loss_cls: 0.0069  decode.loss_mask: 0.2352  decode.loss_dice: 0.1777  decode.d0.loss_cls: 0.8724  decode.d0.loss_mask: 0.2402  decode.d0.loss_dice: 0.2102  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.2361  decode.d1.loss_dice: 0.1829  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.1774  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.2327  decode.d3.loss_dice: 0.1802  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.2311  decode.d4.loss_dice: 0.1780  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.1809  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2350  decode.d6.loss_dice: 0.1820  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2369  decode.d7.loss_dice: 0.1801  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.2325  decode.d8.loss_dice: 0.1751
09/28 19:33:15 - mmengine - INFO - Iter(train) [ 41650/320000]  base_lr: 8.8206e-05 lr: 8.8206e-06  eta: 1 day, 10:00:32  time: 0.4343  data_time: 0.0092  memory: 5132  grad_norm: 40.2162  loss: 5.7075  decode.loss_cls: 0.0623  decode.loss_mask: 0.2312  decode.loss_dice: 0.1941  decode.d0.loss_cls: 0.9208  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.2027  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.2368  decode.d1.loss_dice: 0.1920  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.1935  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.2367  decode.d3.loss_dice: 0.2000  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2027  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.2385  decode.d5.loss_dice: 0.1963  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.2312  decode.d6.loss_dice: 0.1934  decode.d7.loss_cls: 0.0520  decode.d7.loss_mask: 0.2342  decode.d7.loss_dice: 0.1919  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.2378  decode.d8.loss_dice: 0.2023
09/28 19:33:36 - mmengine - INFO - Iter(train) [ 41700/320000]  base_lr: 8.8192e-05 lr: 8.8192e-06  eta: 1 day, 10:00:08  time: 0.4348  data_time: 0.0095  memory: 5117  grad_norm: 80.2142  loss: 6.7905  decode.loss_cls: 0.1571  decode.loss_mask: 0.2301  decode.loss_dice: 0.2484  decode.d0.loss_cls: 0.9393  decode.d0.loss_mask: 0.2238  decode.d0.loss_dice: 0.2166  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 0.2181  decode.d1.loss_dice: 0.2202  decode.d2.loss_cls: 0.1343  decode.d2.loss_mask: 0.2291  decode.d2.loss_dice: 0.2414  decode.d3.loss_cls: 0.1287  decode.d3.loss_mask: 0.2192  decode.d3.loss_dice: 0.2215  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.2273  decode.d4.loss_dice: 0.2270  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.2227  decode.d5.loss_dice: 0.2287  decode.d6.loss_cls: 0.1229  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.2349  decode.d7.loss_cls: 0.1155  decode.d7.loss_mask: 0.2605  decode.d7.loss_dice: 0.2461  decode.d8.loss_cls: 0.1753  decode.d8.loss_mask: 0.2428  decode.d8.loss_dice: 0.2477
09/28 19:33:58 - mmengine - INFO - Iter(train) [ 41750/320000]  base_lr: 8.8178e-05 lr: 8.8178e-06  eta: 1 day, 9:59:45  time: 0.4368  data_time: 0.0093  memory: 5133  grad_norm: 66.7966  loss: 5.0884  decode.loss_cls: 0.0261  decode.loss_mask: 0.2365  decode.loss_dice: 0.1821  decode.d0.loss_cls: 0.8098  decode.d0.loss_mask: 0.2308  decode.d0.loss_dice: 0.1819  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.2322  decode.d1.loss_dice: 0.1811  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.2333  decode.d2.loss_dice: 0.1758  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.2353  decode.d3.loss_dice: 0.1728  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.2342  decode.d4.loss_dice: 0.1771  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.1796  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.2336  decode.d6.loss_dice: 0.1822  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2319  decode.d7.loss_dice: 0.1818  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.2306  decode.d8.loss_dice: 0.1859
09/28 19:34:20 - mmengine - INFO - Iter(train) [ 41800/320000]  base_lr: 8.8163e-05 lr: 8.8163e-06  eta: 1 day, 9:59:22  time: 0.4378  data_time: 0.0095  memory: 5147  grad_norm: 216.0955  loss: 6.6473  decode.loss_cls: 0.1172  decode.loss_mask: 0.2197  decode.loss_dice: 0.1597  decode.d0.loss_cls: 0.9307  decode.d0.loss_mask: 0.2238  decode.d0.loss_dice: 0.2047  decode.d1.loss_cls: 0.1838  decode.d1.loss_mask: 0.2192  decode.d1.loss_dice: 0.2016  decode.d2.loss_cls: 0.1069  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 0.2212  decode.d3.loss_dice: 0.2175  decode.d4.loss_cls: 0.1564  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.2244  decode.d5.loss_cls: 0.1551  decode.d5.loss_mask: 0.4541  decode.d5.loss_dice: 0.2213  decode.d6.loss_cls: 0.1430  decode.d6.loss_mask: 0.2226  decode.d6.loss_dice: 0.2026  decode.d7.loss_cls: 0.1265  decode.d7.loss_mask: 0.2203  decode.d7.loss_dice: 0.1888  decode.d8.loss_cls: 0.1086  decode.d8.loss_mask: 0.2181  decode.d8.loss_dice: 0.1778
09/28 19:34:42 - mmengine - INFO - Iter(train) [ 41850/320000]  base_lr: 8.8149e-05 lr: 8.8149e-06  eta: 1 day, 9:59:00  time: 0.4388  data_time: 0.0095  memory: 5147  grad_norm: 97.3936  loss: 7.2792  decode.loss_cls: 0.1386  decode.loss_mask: 0.2629  decode.loss_dice: 0.2712  decode.d0.loss_cls: 0.8935  decode.d0.loss_mask: 0.2608  decode.d0.loss_dice: 0.2589  decode.d1.loss_cls: 0.1290  decode.d1.loss_mask: 0.2683  decode.d1.loss_dice: 0.2455  decode.d2.loss_cls: 0.1367  decode.d2.loss_mask: 0.2618  decode.d2.loss_dice: 0.2373  decode.d3.loss_cls: 0.1563  decode.d3.loss_mask: 0.2627  decode.d3.loss_dice: 0.2506  decode.d4.loss_cls: 0.1355  decode.d4.loss_mask: 0.2583  decode.d4.loss_dice: 0.2385  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.2594  decode.d5.loss_dice: 0.2206  decode.d6.loss_cls: 0.1912  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.2501  decode.d7.loss_cls: 0.1410  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.2498  decode.d8.loss_cls: 0.1404  decode.d8.loss_mask: 0.2594  decode.d8.loss_dice: 0.2341
09/28 19:35:04 - mmengine - INFO - Iter(train) [ 41900/320000]  base_lr: 8.8135e-05 lr: 8.8135e-06  eta: 1 day, 9:58:36  time: 0.4344  data_time: 0.0094  memory: 5147  grad_norm: 47.7278  loss: 6.9693  decode.loss_cls: 0.1540  decode.loss_mask: 0.2208  decode.loss_dice: 0.2406  decode.d0.loss_cls: 0.9793  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.2626  decode.d1.loss_cls: 0.1966  decode.d1.loss_mask: 0.2206  decode.d1.loss_dice: 0.2313  decode.d2.loss_cls: 0.1774  decode.d2.loss_mask: 0.2119  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.1876  decode.d3.loss_mask: 0.2097  decode.d3.loss_dice: 0.2201  decode.d4.loss_cls: 0.1735  decode.d4.loss_mask: 0.2102  decode.d4.loss_dice: 0.2178  decode.d5.loss_cls: 0.1499  decode.d5.loss_mask: 0.2119  decode.d5.loss_dice: 0.2153  decode.d6.loss_cls: 0.1542  decode.d6.loss_mask: 0.2115  decode.d6.loss_dice: 0.2274  decode.d7.loss_cls: 0.1597  decode.d7.loss_mask: 0.2163  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 0.2155  decode.d8.loss_dice: 0.2401
09/28 19:35:25 - mmengine - INFO - Iter(train) [ 41950/320000]  base_lr: 8.8120e-05 lr: 8.8120e-06  eta: 1 day, 9:58:12  time: 0.4345  data_time: 0.0096  memory: 5132  grad_norm: 36.6988  loss: 4.8911  decode.loss_cls: 0.0051  decode.loss_mask: 0.2243  decode.loss_dice: 0.1714  decode.d0.loss_cls: 0.8155  decode.d0.loss_mask: 0.2293  decode.d0.loss_dice: 0.1767  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.1738  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.2253  decode.d3.loss_dice: 0.1753  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.2265  decode.d4.loss_dice: 0.1737  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.2276  decode.d5.loss_dice: 0.1649  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.2231  decode.d6.loss_dice: 0.1643  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.2214  decode.d7.loss_dice: 0.1703  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2241  decode.d8.loss_dice: 0.1692
09/28 19:35:47 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:35:47 - mmengine - INFO - Iter(train) [ 42000/320000]  base_lr: 8.8106e-05 lr: 8.8106e-06  eta: 1 day, 9:57:48  time: 0.4356  data_time: 0.0096  memory: 5133  grad_norm: 104.0041  loss: 8.6795  decode.loss_cls: 0.1889  decode.loss_mask: 0.3092  decode.loss_dice: 0.3066  decode.d0.loss_cls: 1.0707  decode.d0.loss_mask: 0.2908  decode.d0.loss_dice: 0.3045  decode.d1.loss_cls: 0.1605  decode.d1.loss_mask: 0.2962  decode.d1.loss_dice: 0.2992  decode.d2.loss_cls: 0.1513  decode.d2.loss_mask: 0.3054  decode.d2.loss_dice: 0.2977  decode.d3.loss_cls: 0.2075  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.2575  decode.d4.loss_cls: 0.1650  decode.d4.loss_mask: 0.2974  decode.d4.loss_dice: 0.2762  decode.d5.loss_cls: 0.1925  decode.d5.loss_mask: 0.3116  decode.d5.loss_dice: 0.2908  decode.d6.loss_cls: 0.2089  decode.d6.loss_mask: 0.3497  decode.d6.loss_dice: 0.3033  decode.d7.loss_cls: 0.1947  decode.d7.loss_mask: 0.2923  decode.d7.loss_dice: 0.2861  decode.d8.loss_cls: 0.1877  decode.d8.loss_mask: 0.2962  decode.d8.loss_dice: 0.2895
09/28 19:36:09 - mmengine - INFO - Iter(train) [ 42050/320000]  base_lr: 8.8092e-05 lr: 8.8092e-06  eta: 1 day, 9:57:25  time: 0.4344  data_time: 0.0095  memory: 5147  grad_norm: 26.8875  loss: 4.9318  decode.loss_cls: 0.0170  decode.loss_mask: 0.2131  decode.loss_dice: 0.1811  decode.d0.loss_cls: 0.8394  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.1914  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.2115  decode.d1.loss_dice: 0.1820  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2127  decode.d2.loss_dice: 0.1868  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.2116  decode.d3.loss_dice: 0.1780  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.2132  decode.d4.loss_dice: 0.1866  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.2109  decode.d5.loss_dice: 0.1809  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.2117  decode.d6.loss_dice: 0.1802  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.2135  decode.d7.loss_dice: 0.1833  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.2118  decode.d8.loss_dice: 0.1812
09/28 19:36:31 - mmengine - INFO - Iter(train) [ 42100/320000]  base_lr: 8.8078e-05 lr: 8.8078e-06  eta: 1 day, 9:57:02  time: 0.4367  data_time: 0.0094  memory: 5147  grad_norm: 51.6860  loss: 9.2227  decode.loss_cls: 0.1274  decode.loss_mask: 0.4536  decode.loss_dice: 0.2447  decode.d0.loss_cls: 1.0187  decode.d0.loss_mask: 0.3575  decode.d0.loss_dice: 0.2484  decode.d1.loss_cls: 0.1554  decode.d1.loss_mask: 0.4622  decode.d1.loss_dice: 0.2410  decode.d2.loss_cls: 0.1539  decode.d2.loss_mask: 0.4641  decode.d2.loss_dice: 0.2395  decode.d3.loss_cls: 0.1541  decode.d3.loss_mask: 0.4445  decode.d3.loss_dice: 0.2336  decode.d4.loss_cls: 0.1733  decode.d4.loss_mask: 0.4559  decode.d4.loss_dice: 0.2388  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 0.4568  decode.d5.loss_dice: 0.2484  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.4630  decode.d6.loss_dice: 0.2485  decode.d7.loss_cls: 0.1242  decode.d7.loss_mask: 0.4640  decode.d7.loss_dice: 0.2420  decode.d8.loss_cls: 0.1254  decode.d8.loss_mask: 0.4570  decode.d8.loss_dice: 0.2376
09/28 19:36:53 - mmengine - INFO - Iter(train) [ 42150/320000]  base_lr: 8.8063e-05 lr: 8.8063e-06  eta: 1 day, 9:56:38  time: 0.4341  data_time: 0.0092  memory: 5147  grad_norm: 70.2289  loss: 6.0757  decode.loss_cls: 0.0990  decode.loss_mask: 0.2204  decode.loss_dice: 0.1846  decode.d0.loss_cls: 1.0307  decode.d0.loss_mask: 0.2343  decode.d0.loss_dice: 0.2029  decode.d1.loss_cls: 0.1346  decode.d1.loss_mask: 0.2232  decode.d1.loss_dice: 0.1831  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.2290  decode.d2.loss_dice: 0.1840  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.2223  decode.d3.loss_dice: 0.1829  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.2189  decode.d4.loss_dice: 0.1811  decode.d5.loss_cls: 0.1245  decode.d5.loss_mask: 0.2278  decode.d5.loss_dice: 0.1914  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.2282  decode.d6.loss_dice: 0.1888  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.2214  decode.d7.loss_dice: 0.1775  decode.d8.loss_cls: 0.0942  decode.d8.loss_mask: 0.2199  decode.d8.loss_dice: 0.1777
09/28 19:37:15 - mmengine - INFO - Iter(train) [ 42200/320000]  base_lr: 8.8049e-05 lr: 8.8049e-06  eta: 1 day, 9:56:17  time: 0.4743  data_time: 0.0100  memory: 5132  grad_norm: 164.9702  loss: 8.0460  decode.loss_cls: 0.1263  decode.loss_mask: 0.3057  decode.loss_dice: 0.2775  decode.d0.loss_cls: 0.8037  decode.d0.loss_mask: 0.3443  decode.d0.loss_dice: 0.2950  decode.d1.loss_cls: 0.1131  decode.d1.loss_mask: 0.3451  decode.d1.loss_dice: 0.2742  decode.d2.loss_cls: 0.1860  decode.d2.loss_mask: 0.3098  decode.d2.loss_dice: 0.2884  decode.d3.loss_cls: 0.1028  decode.d3.loss_mask: 0.3481  decode.d3.loss_dice: 0.2820  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.3545  decode.d4.loss_dice: 0.2873  decode.d5.loss_cls: 0.1460  decode.d5.loss_mask: 0.3021  decode.d5.loss_dice: 0.2821  decode.d6.loss_cls: 0.1521  decode.d6.loss_mask: 0.3017  decode.d6.loss_dice: 0.2812  decode.d7.loss_cls: 0.1093  decode.d7.loss_mask: 0.3038  decode.d7.loss_dice: 0.2805  decode.d8.loss_cls: 0.1516  decode.d8.loss_mask: 0.3120  decode.d8.loss_dice: 0.2687
09/28 19:37:38 - mmengine - INFO - Iter(train) [ 42250/320000]  base_lr: 8.8035e-05 lr: 8.8035e-06  eta: 1 day, 9:56:06  time: 0.4898  data_time: 0.0093  memory: 5147  grad_norm: 33.5047  loss: 4.4012  decode.loss_cls: 0.0090  decode.loss_mask: 0.1835  decode.loss_dice: 0.1610  decode.d0.loss_cls: 0.7645  decode.d0.loss_mask: 0.1860  decode.d0.loss_dice: 0.1722  decode.d1.loss_cls: 0.0545  decode.d1.loss_mask: 0.1835  decode.d1.loss_dice: 0.1631  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.1805  decode.d2.loss_dice: 0.1596  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.1840  decode.d3.loss_dice: 0.1571  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.1834  decode.d4.loss_dice: 0.1593  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.1837  decode.d5.loss_dice: 0.1589  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.1844  decode.d6.loss_dice: 0.1582  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.1838  decode.d7.loss_dice: 0.1573  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.1825  decode.d8.loss_dice: 0.1600
09/28 19:38:02 - mmengine - INFO - Iter(train) [ 42300/320000]  base_lr: 8.8021e-05 lr: 8.8021e-06  eta: 1 day, 9:55:55  time: 0.4732  data_time: 0.0098  memory: 5147  grad_norm: 40.5278  loss: 6.6190  decode.loss_cls: 0.1108  decode.loss_mask: 0.2405  decode.loss_dice: 0.2647  decode.d0.loss_cls: 0.8549  decode.d0.loss_mask: 0.2429  decode.d0.loss_dice: 0.2527  decode.d1.loss_cls: 0.0957  decode.d1.loss_mask: 0.2400  decode.d1.loss_dice: 0.2532  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.2469  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.2294  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.2360  decode.d5.loss_cls: 0.0838  decode.d5.loss_mask: 0.2414  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.2387  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.2430  decode.d7.loss_dice: 0.2629  decode.d8.loss_cls: 0.1059  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.2409
09/28 19:38:26 - mmengine - INFO - Iter(train) [ 42350/320000]  base_lr: 8.8006e-05 lr: 8.8006e-06  eta: 1 day, 9:55:44  time: 0.4714  data_time: 0.0094  memory: 5133  grad_norm: 46.9519  loss: 5.8335  decode.loss_cls: 0.0486  decode.loss_mask: 0.2710  decode.loss_dice: 0.1837  decode.d0.loss_cls: 0.8843  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.2020  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.2756  decode.d1.loss_dice: 0.1892  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.2764  decode.d2.loss_dice: 0.2098  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.2721  decode.d3.loss_dice: 0.1886  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.2768  decode.d4.loss_dice: 0.1916  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.2709  decode.d5.loss_dice: 0.1865  decode.d6.loss_cls: 0.0195  decode.d6.loss_mask: 0.2744  decode.d6.loss_dice: 0.1858  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.2710  decode.d7.loss_dice: 0.1880  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.2765  decode.d8.loss_dice: 0.1891
09/28 19:38:49 - mmengine - INFO - Iter(train) [ 42400/320000]  base_lr: 8.7992e-05 lr: 8.7992e-06  eta: 1 day, 9:55:33  time: 0.4697  data_time: 0.0093  memory: 5132  grad_norm: 99.0038  loss: 5.9561  decode.loss_cls: 0.0875  decode.loss_mask: 0.2478  decode.loss_dice: 0.1828  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 0.2543  decode.d0.loss_dice: 0.2037  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.1853  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.2515  decode.d2.loss_dice: 0.1898  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.1846  decode.d4.loss_cls: 0.0852  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.1870  decode.d5.loss_cls: 0.1041  decode.d5.loss_mask: 0.2460  decode.d5.loss_dice: 0.1884  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.1818  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.1873  decode.d8.loss_cls: 0.0886  decode.d8.loss_mask: 0.2472  decode.d8.loss_dice: 0.1853
09/28 19:39:13 - mmengine - INFO - Iter(train) [ 42450/320000]  base_lr: 8.7978e-05 lr: 8.7978e-06  eta: 1 day, 9:55:21  time: 0.4721  data_time: 0.0094  memory: 5133  grad_norm: 188.9962  loss: 6.8717  decode.loss_cls: 0.0640  decode.loss_mask: 0.3044  decode.loss_dice: 0.1961  decode.d0.loss_cls: 0.9320  decode.d0.loss_mask: 0.3105  decode.d0.loss_dice: 0.2082  decode.d1.loss_cls: 0.1842  decode.d1.loss_mask: 0.3032  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.1625  decode.d2.loss_mask: 0.3127  decode.d2.loss_dice: 0.1990  decode.d3.loss_cls: 0.1135  decode.d3.loss_mask: 0.3105  decode.d3.loss_dice: 0.2033  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.2039  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.3083  decode.d5.loss_dice: 0.1974  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.3091  decode.d6.loss_dice: 0.2059  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.3059  decode.d7.loss_dice: 0.2007  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.3040  decode.d8.loss_dice: 0.2045
09/28 19:39:37 - mmengine - INFO - Iter(train) [ 42500/320000]  base_lr: 8.7964e-05 lr: 8.7964e-06  eta: 1 day, 9:55:10  time: 0.4737  data_time: 0.0098  memory: 5132  grad_norm: 285.5998  loss: 8.8355  decode.loss_cls: 0.2232  decode.loss_mask: 0.3794  decode.loss_dice: 0.2597  decode.d0.loss_cls: 1.0603  decode.d0.loss_mask: 0.3024  decode.d0.loss_dice: 0.2487  decode.d1.loss_cls: 0.1674  decode.d1.loss_mask: 0.3792  decode.d1.loss_dice: 0.2384  decode.d2.loss_cls: 0.1626  decode.d2.loss_mask: 0.3787  decode.d2.loss_dice: 0.2407  decode.d3.loss_cls: 0.1793  decode.d3.loss_mask: 0.3751  decode.d3.loss_dice: 0.2582  decode.d4.loss_cls: 0.1578  decode.d4.loss_mask: 0.3751  decode.d4.loss_dice: 0.2485  decode.d5.loss_cls: 0.1624  decode.d5.loss_mask: 0.3774  decode.d5.loss_dice: 0.2409  decode.d6.loss_cls: 0.1476  decode.d6.loss_mask: 0.3857  decode.d6.loss_dice: 0.2456  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.4296  decode.d7.loss_dice: 0.2449  decode.d8.loss_cls: 0.2544  decode.d8.loss_mask: 0.3803  decode.d8.loss_dice: 0.2470
09/28 19:40:00 - mmengine - INFO - Iter(train) [ 42550/320000]  base_lr: 8.7949e-05 lr: 8.7949e-06  eta: 1 day, 9:54:58  time: 0.4712  data_time: 0.0093  memory: 5147  grad_norm: 40.7594  loss: 6.1867  decode.loss_cls: 0.0882  decode.loss_mask: 0.2506  decode.loss_dice: 0.1980  decode.d0.loss_cls: 0.8889  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.2016  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.2504  decode.d1.loss_dice: 0.2041  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.2535  decode.d2.loss_dice: 0.2042  decode.d3.loss_cls: 0.0772  decode.d3.loss_mask: 0.2542  decode.d3.loss_dice: 0.2012  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.2541  decode.d4.loss_dice: 0.2014  decode.d5.loss_cls: 0.0664  decode.d5.loss_mask: 0.2539  decode.d5.loss_dice: 0.1986  decode.d6.loss_cls: 0.1063  decode.d6.loss_mask: 0.2552  decode.d6.loss_dice: 0.1963  decode.d7.loss_cls: 0.1017  decode.d7.loss_mask: 0.2558  decode.d7.loss_dice: 0.2002  decode.d8.loss_cls: 0.0976  decode.d8.loss_mask: 0.2535  decode.d8.loss_dice: 0.1922
09/28 19:40:24 - mmengine - INFO - Iter(train) [ 42600/320000]  base_lr: 8.7935e-05 lr: 8.7935e-06  eta: 1 day, 9:54:47  time: 0.4711  data_time: 0.0093  memory: 5147  grad_norm: 33.3671  loss: 4.9321  decode.loss_cls: 0.0799  decode.loss_mask: 0.1870  decode.loss_dice: 0.1546  decode.d0.loss_cls: 0.8422  decode.d0.loss_mask: 0.1875  decode.d0.loss_dice: 0.1627  decode.d1.loss_cls: 0.0899  decode.d1.loss_mask: 0.1897  decode.d1.loss_dice: 0.1596  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.1858  decode.d2.loss_dice: 0.1572  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.1857  decode.d3.loss_dice: 0.1531  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 0.1856  decode.d4.loss_dice: 0.1556  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.1897  decode.d5.loss_dice: 0.1590  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.1904  decode.d6.loss_dice: 0.1595  decode.d7.loss_cls: 0.0348  decode.d7.loss_mask: 0.1869  decode.d7.loss_dice: 0.1569  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.1872  decode.d8.loss_dice: 0.1559
09/28 19:40:47 - mmengine - INFO - Iter(train) [ 42650/320000]  base_lr: 8.7921e-05 lr: 8.7921e-06  eta: 1 day, 9:54:35  time: 0.4719  data_time: 0.0099  memory: 5147  grad_norm: 76.9613  loss: 10.0049  decode.loss_cls: 0.2162  decode.loss_mask: 0.3316  decode.loss_dice: 0.3710  decode.d0.loss_cls: 0.9400  decode.d0.loss_mask: 0.3128  decode.d0.loss_dice: 0.3329  decode.d1.loss_cls: 0.3132  decode.d1.loss_mask: 0.3112  decode.d1.loss_dice: 0.3508  decode.d2.loss_cls: 0.2525  decode.d2.loss_mask: 0.3214  decode.d2.loss_dice: 0.3692  decode.d3.loss_cls: 0.1893  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.3638  decode.d4.loss_cls: 0.2173  decode.d4.loss_mask: 0.3109  decode.d4.loss_dice: 0.3701  decode.d5.loss_cls: 0.2071  decode.d5.loss_mask: 0.3297  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.2264  decode.d6.loss_mask: 0.3238  decode.d6.loss_dice: 0.3860  decode.d7.loss_cls: 0.2559  decode.d7.loss_mask: 0.3588  decode.d7.loss_dice: 0.3762  decode.d8.loss_cls: 0.2623  decode.d8.loss_mask: 0.3339  decode.d8.loss_dice: 0.3737
09/28 19:41:11 - mmengine - INFO - Iter(train) [ 42700/320000]  base_lr: 8.7907e-05 lr: 8.7907e-06  eta: 1 day, 9:54:23  time: 0.4739  data_time: 0.0097  memory: 5147  grad_norm: 36.5620  loss: 4.9181  decode.loss_cls: 0.0182  decode.loss_mask: 0.2105  decode.loss_dice: 0.1736  decode.d0.loss_cls: 0.8527  decode.d0.loss_mask: 0.2091  decode.d0.loss_dice: 0.1735  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.2087  decode.d1.loss_dice: 0.1801  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 0.2101  decode.d2.loss_dice: 0.1755  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.2092  decode.d3.loss_dice: 0.1745  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.2114  decode.d4.loss_dice: 0.1726  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.2081  decode.d5.loss_dice: 0.1757  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.2095  decode.d6.loss_dice: 0.1739  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2124  decode.d7.loss_dice: 0.1763  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.2101  decode.d8.loss_dice: 0.1768
09/28 19:41:35 - mmengine - INFO - Iter(train) [ 42750/320000]  base_lr: 8.7892e-05 lr: 8.7892e-06  eta: 1 day, 9:54:12  time: 0.4711  data_time: 0.0096  memory: 5133  grad_norm: 82.1224  loss: 10.6699  decode.loss_cls: 0.2090  decode.loss_mask: 0.3810  decode.loss_dice: 0.3673  decode.d0.loss_cls: 0.8726  decode.d0.loss_mask: 0.3688  decode.d0.loss_dice: 0.3669  decode.d1.loss_cls: 0.3048  decode.d1.loss_mask: 0.3613  decode.d1.loss_dice: 0.3668  decode.d2.loss_cls: 0.3563  decode.d2.loss_mask: 0.3594  decode.d2.loss_dice: 0.3619  decode.d3.loss_cls: 0.3222  decode.d3.loss_mask: 0.3614  decode.d3.loss_dice: 0.3582  decode.d4.loss_cls: 0.2882  decode.d4.loss_mask: 0.3627  decode.d4.loss_dice: 0.3479  decode.d5.loss_cls: 0.2997  decode.d5.loss_mask: 0.3662  decode.d5.loss_dice: 0.3544  decode.d6.loss_cls: 0.2266  decode.d6.loss_mask: 0.3861  decode.d6.loss_dice: 0.3801  decode.d7.loss_cls: 0.2337  decode.d7.loss_mask: 0.3740  decode.d7.loss_dice: 0.3827  decode.d8.loss_cls: 0.1680  decode.d8.loss_mask: 0.3905  decode.d8.loss_dice: 0.3915
09/28 19:41:58 - mmengine - INFO - Iter(train) [ 42800/320000]  base_lr: 8.7878e-05 lr: 8.7878e-06  eta: 1 day, 9:54:00  time: 0.4716  data_time: 0.0093  memory: 5133  grad_norm: 118.2549  loss: 6.6985  decode.loss_cls: 0.0404  decode.loss_mask: 0.2498  decode.loss_dice: 0.2454  decode.d0.loss_cls: 1.0365  decode.d0.loss_mask: 0.2352  decode.d0.loss_dice: 0.2311  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2553  decode.d2.loss_cls: 0.0565  decode.d2.loss_mask: 0.2675  decode.d2.loss_dice: 0.2660  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.2733  decode.d3.loss_dice: 0.2672  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.2592  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.2642  decode.d5.loss_dice: 0.2566  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.2477  decode.d6.loss_dice: 0.2519  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.2619  decode.d7.loss_dice: 0.2558  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.2636  decode.d8.loss_dice: 0.2595
09/28 19:42:22 - mmengine - INFO - Iter(train) [ 42850/320000]  base_lr: 8.7864e-05 lr: 8.7864e-06  eta: 1 day, 9:53:48  time: 0.4711  data_time: 0.0094  memory: 5133  grad_norm: 92.7241  loss: 6.3711  decode.loss_cls: 0.1308  decode.loss_mask: 0.2082  decode.loss_dice: 0.2199  decode.d0.loss_cls: 0.9832  decode.d0.loss_mask: 0.2041  decode.d0.loss_dice: 0.1997  decode.d1.loss_cls: 0.1674  decode.d1.loss_mask: 0.2054  decode.d1.loss_dice: 0.2023  decode.d2.loss_cls: 0.1667  decode.d2.loss_mask: 0.2109  decode.d2.loss_dice: 0.2007  decode.d3.loss_cls: 0.1367  decode.d3.loss_mask: 0.2060  decode.d3.loss_dice: 0.2107  decode.d4.loss_cls: 0.1233  decode.d4.loss_mask: 0.2101  decode.d4.loss_dice: 0.2003  decode.d5.loss_cls: 0.1355  decode.d5.loss_mask: 0.2043  decode.d5.loss_dice: 0.1967  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 0.2101  decode.d6.loss_dice: 0.2249  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.2059  decode.d7.loss_dice: 0.2105  decode.d8.loss_cls: 0.1196  decode.d8.loss_mask: 0.2111  decode.d8.loss_dice: 0.2165
09/28 19:42:45 - mmengine - INFO - Iter(train) [ 42900/320000]  base_lr: 8.7849e-05 lr: 8.7849e-06  eta: 1 day, 9:53:36  time: 0.4732  data_time: 0.0095  memory: 5133  grad_norm: 72.7363  loss: 5.6672  decode.loss_cls: 0.0640  decode.loss_mask: 0.2408  decode.loss_dice: 0.1803  decode.d0.loss_cls: 0.8005  decode.d0.loss_mask: 0.2494  decode.d0.loss_dice: 0.1925  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.2430  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.2437  decode.d2.loss_dice: 0.1941  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.2452  decode.d3.loss_dice: 0.1833  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.2436  decode.d4.loss_dice: 0.1900  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.2428  decode.d5.loss_dice: 0.1842  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.2429  decode.d6.loss_dice: 0.1852  decode.d7.loss_cls: 0.1155  decode.d7.loss_mask: 0.2422  decode.d7.loss_dice: 0.1814  decode.d8.loss_cls: 0.0993  decode.d8.loss_mask: 0.2418  decode.d8.loss_dice: 0.1786
09/28 19:43:09 - mmengine - INFO - Iter(train) [ 42950/320000]  base_lr: 8.7835e-05 lr: 8.7835e-06  eta: 1 day, 9:53:24  time: 0.4716  data_time: 0.0093  memory: 5133  grad_norm: 74.6433  loss: 8.6892  decode.loss_cls: 0.1807  decode.loss_mask: 0.3395  decode.loss_dice: 0.2504  decode.d0.loss_cls: 1.0810  decode.d0.loss_mask: 0.3503  decode.d0.loss_dice: 0.2636  decode.d1.loss_cls: 0.2002  decode.d1.loss_mask: 0.3395  decode.d1.loss_dice: 0.2429  decode.d2.loss_cls: 0.2232  decode.d2.loss_mask: 0.3400  decode.d2.loss_dice: 0.2507  decode.d3.loss_cls: 0.1738  decode.d3.loss_mask: 0.3404  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.2107  decode.d4.loss_mask: 0.3513  decode.d4.loss_dice: 0.2476  decode.d5.loss_cls: 0.1793  decode.d5.loss_mask: 0.3431  decode.d5.loss_dice: 0.2435  decode.d6.loss_cls: 0.1861  decode.d6.loss_mask: 0.3399  decode.d6.loss_dice: 0.2429  decode.d7.loss_cls: 0.1824  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.1530  decode.d8.loss_mask: 0.3479  decode.d8.loss_dice: 0.2450
09/28 19:43:32 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:43:32 - mmengine - INFO - Iter(train) [ 43000/320000]  base_lr: 8.7821e-05 lr: 8.7821e-06  eta: 1 day, 9:53:12  time: 0.4722  data_time: 0.0096  memory: 5133  grad_norm: 41.2593  loss: 7.5754  decode.loss_cls: 0.1437  decode.loss_mask: 0.2335  decode.loss_dice: 0.2632  decode.d0.loss_cls: 1.0366  decode.d0.loss_mask: 0.2391  decode.d0.loss_dice: 0.2769  decode.d1.loss_cls: 0.1840  decode.d1.loss_mask: 0.2359  decode.d1.loss_dice: 0.3110  decode.d2.loss_cls: 0.2190  decode.d2.loss_mask: 0.2331  decode.d2.loss_dice: 0.2493  decode.d3.loss_cls: 0.1740  decode.d3.loss_mask: 0.2330  decode.d3.loss_dice: 0.2943  decode.d4.loss_cls: 0.1446  decode.d4.loss_mask: 0.2335  decode.d4.loss_dice: 0.2822  decode.d5.loss_cls: 0.1709  decode.d5.loss_mask: 0.2335  decode.d5.loss_dice: 0.2561  decode.d6.loss_cls: 0.1489  decode.d6.loss_mask: 0.2337  decode.d6.loss_dice: 0.2749  decode.d7.loss_cls: 0.1313  decode.d7.loss_mask: 0.2349  decode.d7.loss_dice: 0.2722  decode.d8.loss_cls: 0.1624  decode.d8.loss_mask: 0.2344  decode.d8.loss_dice: 0.2356
09/28 19:43:56 - mmengine - INFO - Iter(train) [ 43050/320000]  base_lr: 8.7807e-05 lr: 8.7807e-06  eta: 1 day, 9:52:59  time: 0.4694  data_time: 0.0091  memory: 5133  grad_norm: 51.1749  loss: 6.1020  decode.loss_cls: 0.0662  decode.loss_mask: 0.3006  decode.loss_dice: 0.1844  decode.d0.loss_cls: 0.8349  decode.d0.loss_mask: 0.2818  decode.d0.loss_dice: 0.1771  decode.d1.loss_cls: 0.1165  decode.d1.loss_mask: 0.2146  decode.d1.loss_dice: 0.1745  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.2916  decode.d2.loss_dice: 0.1829  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.2838  decode.d3.loss_dice: 0.1835  decode.d4.loss_cls: 0.0758  decode.d4.loss_mask: 0.2989  decode.d4.loss_dice: 0.1870  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.2880  decode.d5.loss_dice: 0.1811  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.2915  decode.d6.loss_dice: 0.1862  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.3006  decode.d7.loss_dice: 0.1846  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.2982  decode.d8.loss_dice: 0.1843
09/28 19:44:20 - mmengine - INFO - Iter(train) [ 43100/320000]  base_lr: 8.7792e-05 lr: 8.7792e-06  eta: 1 day, 9:52:48  time: 0.4726  data_time: 0.0093  memory: 5133  grad_norm: 30.6142  loss: 6.5805  decode.loss_cls: 0.1407  decode.loss_mask: 0.2193  decode.loss_dice: 0.2496  decode.d0.loss_cls: 0.9018  decode.d0.loss_mask: 0.2217  decode.d0.loss_dice: 0.2552  decode.d1.loss_cls: 0.1263  decode.d1.loss_mask: 0.2172  decode.d1.loss_dice: 0.2367  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.2177  decode.d2.loss_dice: 0.2535  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.2146  decode.d3.loss_dice: 0.2519  decode.d4.loss_cls: 0.1199  decode.d4.loss_mask: 0.2179  decode.d4.loss_dice: 0.2467  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.2156  decode.d5.loss_dice: 0.2359  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.2220  decode.d6.loss_dice: 0.2412  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.2240  decode.d7.loss_dice: 0.2432  decode.d8.loss_cls: 0.1233  decode.d8.loss_mask: 0.2211  decode.d8.loss_dice: 0.2539
09/28 19:44:43 - mmengine - INFO - Iter(train) [ 43150/320000]  base_lr: 8.7778e-05 lr: 8.7778e-06  eta: 1 day, 9:52:36  time: 0.4715  data_time: 0.0094  memory: 5133  grad_norm: 79.0778  loss: 5.2106  decode.loss_cls: 0.1040  decode.loss_mask: 0.1941  decode.loss_dice: 0.1681  decode.d0.loss_cls: 0.8249  decode.d0.loss_mask: 0.1910  decode.d0.loss_dice: 0.1783  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.1909  decode.d1.loss_dice: 0.1667  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.1927  decode.d2.loss_dice: 0.1693  decode.d3.loss_cls: 0.1084  decode.d3.loss_mask: 0.1898  decode.d3.loss_dice: 0.1649  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.1908  decode.d4.loss_dice: 0.1645  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.1901  decode.d5.loss_dice: 0.1657  decode.d6.loss_cls: 0.1304  decode.d6.loss_mask: 0.1912  decode.d6.loss_dice: 0.1697  decode.d7.loss_cls: 0.1012  decode.d7.loss_mask: 0.1913  decode.d7.loss_dice: 0.1712  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.1920  decode.d8.loss_dice: 0.1747
09/28 19:45:07 - mmengine - INFO - Iter(train) [ 43200/320000]  base_lr: 8.7764e-05 lr: 8.7764e-06  eta: 1 day, 9:52:24  time: 0.4705  data_time: 0.0093  memory: 5133  grad_norm: 57.7769  loss: 5.6335  decode.loss_cls: 0.0524  decode.loss_mask: 0.2137  decode.loss_dice: 0.2088  decode.d0.loss_cls: 0.9451  decode.d0.loss_mask: 0.2108  decode.d0.loss_dice: 0.2221  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.2103  decode.d1.loss_dice: 0.2020  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.2109  decode.d2.loss_dice: 0.2038  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.2101  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.2130  decode.d4.loss_dice: 0.2035  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 0.2113  decode.d5.loss_dice: 0.2001  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.2081  decode.d6.loss_dice: 0.2006  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2115  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.2125  decode.d8.loss_dice: 0.2077
09/28 19:45:30 - mmengine - INFO - Iter(train) [ 43250/320000]  base_lr: 8.7750e-05 lr: 8.7750e-06  eta: 1 day, 9:52:12  time: 0.4716  data_time: 0.0094  memory: 5117  grad_norm: 77.1119  loss: 6.7654  decode.loss_cls: 0.0895  decode.loss_mask: 0.2773  decode.loss_dice: 0.2370  decode.d0.loss_cls: 1.0053  decode.d0.loss_mask: 0.2633  decode.d0.loss_dice: 0.2360  decode.d1.loss_cls: 0.1325  decode.d1.loss_mask: 0.2601  decode.d1.loss_dice: 0.2372  decode.d2.loss_cls: 0.0946  decode.d2.loss_mask: 0.2535  decode.d2.loss_dice: 0.2289  decode.d3.loss_cls: 0.1218  decode.d3.loss_mask: 0.2547  decode.d3.loss_dice: 0.2287  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.2544  decode.d4.loss_dice: 0.2235  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2269  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.2496  decode.d6.loss_dice: 0.2303  decode.d7.loss_cls: 0.1041  decode.d7.loss_mask: 0.2472  decode.d7.loss_dice: 0.2309  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.2506  decode.d8.loss_dice: 0.2335
09/28 19:45:54 - mmengine - INFO - Iter(train) [ 43300/320000]  base_lr: 8.7735e-05 lr: 8.7735e-06  eta: 1 day, 9:52:00  time: 0.4733  data_time: 0.0093  memory: 5133  grad_norm: 48.9784  loss: 8.7380  decode.loss_cls: 0.1781  decode.loss_mask: 0.2916  decode.loss_dice: 0.3062  decode.d0.loss_cls: 0.9128  decode.d0.loss_mask: 0.2996  decode.d0.loss_dice: 0.3390  decode.d1.loss_cls: 0.2579  decode.d1.loss_mask: 0.2857  decode.d1.loss_dice: 0.2927  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 0.2955  decode.d2.loss_dice: 0.3130  decode.d3.loss_cls: 0.1767  decode.d3.loss_mask: 0.2997  decode.d3.loss_dice: 0.3258  decode.d4.loss_cls: 0.1796  decode.d4.loss_mask: 0.2931  decode.d4.loss_dice: 0.3276  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 0.3010  decode.d5.loss_dice: 0.3196  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 0.2925  decode.d6.loss_dice: 0.2954  decode.d7.loss_cls: 0.1898  decode.d7.loss_mask: 0.2913  decode.d7.loss_dice: 0.2940  decode.d8.loss_cls: 0.1788  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.2948
09/28 19:46:18 - mmengine - INFO - Iter(train) [ 43350/320000]  base_lr: 8.7721e-05 lr: 8.7721e-06  eta: 1 day, 9:51:48  time: 0.4759  data_time: 0.0095  memory: 5132  grad_norm: 45.1368  loss: 6.6316  decode.loss_cls: 0.0861  decode.loss_mask: 0.2259  decode.loss_dice: 0.2415  decode.d0.loss_cls: 1.0249  decode.d0.loss_mask: 0.2580  decode.d0.loss_dice: 0.2429  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.2263  decode.d1.loss_dice: 0.2412  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.2228  decode.d2.loss_dice: 0.2267  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.2259  decode.d3.loss_dice: 0.2387  decode.d4.loss_cls: 0.1206  decode.d4.loss_mask: 0.2286  decode.d4.loss_dice: 0.2488  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.2255  decode.d5.loss_dice: 0.2454  decode.d6.loss_cls: 0.1168  decode.d6.loss_mask: 0.2271  decode.d6.loss_dice: 0.2395  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.2284  decode.d7.loss_dice: 0.2331  decode.d8.loss_cls: 0.0999  decode.d8.loss_mask: 0.2249  decode.d8.loss_dice: 0.2332
09/28 19:46:41 - mmengine - INFO - Iter(train) [ 43400/320000]  base_lr: 8.7707e-05 lr: 8.7707e-06  eta: 1 day, 9:51:36  time: 0.4730  data_time: 0.0095  memory: 5147  grad_norm: 38.4303  loss: 4.9587  decode.loss_cls: 0.0411  decode.loss_mask: 0.1896  decode.loss_dice: 0.1891  decode.d0.loss_cls: 0.8109  decode.d0.loss_mask: 0.1924  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.1917  decode.d1.loss_dice: 0.1923  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.1906  decode.d2.loss_dice: 0.1891  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.1894  decode.d3.loss_dice: 0.1886  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.1887  decode.d4.loss_dice: 0.1875  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.1874  decode.d5.loss_dice: 0.1920  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.1879  decode.d6.loss_dice: 0.1867  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.1895  decode.d7.loss_dice: 0.1931  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.1906  decode.d8.loss_dice: 0.1945
09/28 19:47:05 - mmengine - INFO - Iter(train) [ 43450/320000]  base_lr: 8.7693e-05 lr: 8.7693e-06  eta: 1 day, 9:51:24  time: 0.4697  data_time: 0.0094  memory: 5147  grad_norm: 42.4484  loss: 7.4534  decode.loss_cls: 0.1729  decode.loss_mask: 0.2389  decode.loss_dice: 0.2561  decode.d0.loss_cls: 0.9340  decode.d0.loss_mask: 0.2350  decode.d0.loss_dice: 0.2536  decode.d1.loss_cls: 0.2069  decode.d1.loss_mask: 0.2365  decode.d1.loss_dice: 0.2461  decode.d2.loss_cls: 0.2025  decode.d2.loss_mask: 0.2392  decode.d2.loss_dice: 0.2482  decode.d3.loss_cls: 0.1866  decode.d3.loss_mask: 0.2383  decode.d3.loss_dice: 0.2242  decode.d4.loss_cls: 0.2043  decode.d4.loss_mask: 0.2417  decode.d4.loss_dice: 0.2332  decode.d5.loss_cls: 0.1806  decode.d5.loss_mask: 0.2379  decode.d5.loss_dice: 0.2508  decode.d6.loss_cls: 0.1853  decode.d6.loss_mask: 0.2372  decode.d6.loss_dice: 0.2419  decode.d7.loss_cls: 0.2043  decode.d7.loss_mask: 0.2366  decode.d7.loss_dice: 0.2263  decode.d8.loss_cls: 0.1988  decode.d8.loss_mask: 0.2398  decode.d8.loss_dice: 0.2155
09/28 19:47:28 - mmengine - INFO - Iter(train) [ 43500/320000]  base_lr: 8.7678e-05 lr: 8.7678e-06  eta: 1 day, 9:51:12  time: 0.4758  data_time: 0.0096  memory: 5117  grad_norm: 113.6600  loss: 9.8155  decode.loss_cls: 0.1702  decode.loss_mask: 0.4530  decode.loss_dice: 0.2979  decode.d0.loss_cls: 0.8157  decode.d0.loss_mask: 0.4800  decode.d0.loss_dice: 0.3221  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.4595  decode.d1.loss_dice: 0.3046  decode.d2.loss_cls: 0.1578  decode.d2.loss_mask: 0.4507  decode.d2.loss_dice: 0.3066  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 0.4498  decode.d3.loss_dice: 0.3091  decode.d4.loss_cls: 0.1349  decode.d4.loss_mask: 0.4523  decode.d4.loss_dice: 0.2998  decode.d5.loss_cls: 0.1303  decode.d5.loss_mask: 0.4551  decode.d5.loss_dice: 0.3149  decode.d6.loss_cls: 0.1703  decode.d6.loss_mask: 0.4506  decode.d6.loss_dice: 0.3149  decode.d7.loss_cls: 0.1375  decode.d7.loss_mask: 0.4543  decode.d7.loss_dice: 0.3117  decode.d8.loss_cls: 0.1660  decode.d8.loss_mask: 0.4505  decode.d8.loss_dice: 0.3081
09/28 19:47:52 - mmengine - INFO - Iter(train) [ 43550/320000]  base_lr: 8.7664e-05 lr: 8.7664e-06  eta: 1 day, 9:51:00  time: 0.4711  data_time: 0.0094  memory: 5147  grad_norm: 38.8790  loss: 4.5908  decode.loss_cls: 0.0275  decode.loss_mask: 0.1923  decode.loss_dice: 0.1650  decode.d0.loss_cls: 0.7881  decode.d0.loss_mask: 0.1937  decode.d0.loss_dice: 0.1623  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.1648  decode.d2.loss_cls: 0.0204  decode.d2.loss_mask: 0.1905  decode.d2.loss_dice: 0.1644  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.1954  decode.d3.loss_dice: 0.1649  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.1938  decode.d4.loss_dice: 0.1610  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.1924  decode.d5.loss_dice: 0.1629  decode.d6.loss_cls: 0.0290  decode.d6.loss_mask: 0.1956  decode.d6.loss_dice: 0.1628  decode.d7.loss_cls: 0.0285  decode.d7.loss_mask: 0.1951  decode.d7.loss_dice: 0.1678  decode.d8.loss_cls: 0.0286  decode.d8.loss_mask: 0.1927  decode.d8.loss_dice: 0.1597
09/28 19:48:16 - mmengine - INFO - Iter(train) [ 43600/320000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 1 day, 9:50:47  time: 0.4704  data_time: 0.0093  memory: 5133  grad_norm: 43.1243  loss: 6.6226  decode.loss_cls: 0.0707  decode.loss_mask: 0.2246  decode.loss_dice: 0.2724  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 0.2207  decode.d0.loss_dice: 0.2665  decode.d1.loss_cls: 0.1482  decode.d1.loss_mask: 0.2189  decode.d1.loss_dice: 0.2705  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.2180  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.2209  decode.d3.loss_dice: 0.2528  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.2214  decode.d4.loss_dice: 0.2556  decode.d5.loss_cls: 0.0960  decode.d5.loss_mask: 0.2250  decode.d5.loss_dice: 0.2653  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.2211  decode.d6.loss_dice: 0.2692  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.2276  decode.d7.loss_dice: 0.2580  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.2219  decode.d8.loss_dice: 0.2775
09/28 19:48:39 - mmengine - INFO - Iter(train) [ 43650/320000]  base_lr: 8.7635e-05 lr: 8.7635e-06  eta: 1 day, 9:50:35  time: 0.4742  data_time: 0.0091  memory: 5133  grad_norm: 51.8395  loss: 5.9415  decode.loss_cls: 0.1007  decode.loss_mask: 0.2364  decode.loss_dice: 0.1842  decode.d0.loss_cls: 0.8191  decode.d0.loss_mask: 0.2427  decode.d0.loss_dice: 0.1904  decode.d1.loss_cls: 0.1824  decode.d1.loss_mask: 0.2210  decode.d1.loss_dice: 0.1761  decode.d2.loss_cls: 0.1563  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.1788  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 0.2233  decode.d3.loss_dice: 0.1746  decode.d4.loss_cls: 0.1048  decode.d4.loss_mask: 0.2249  decode.d4.loss_dice: 0.1870  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.2185  decode.d5.loss_dice: 0.1795  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.2194  decode.d6.loss_dice: 0.1785  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.2223  decode.d7.loss_dice: 0.1755  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.2220  decode.d8.loss_dice: 0.1730
09/28 19:49:03 - mmengine - INFO - Iter(train) [ 43700/320000]  base_lr: 8.7621e-05 lr: 8.7621e-06  eta: 1 day, 9:50:23  time: 0.4721  data_time: 0.0097  memory: 5117  grad_norm: 80.2650  loss: 7.2407  decode.loss_cls: 0.1637  decode.loss_mask: 0.2496  decode.loss_dice: 0.2489  decode.d0.loss_cls: 0.8688  decode.d0.loss_mask: 0.2502  decode.d0.loss_dice: 0.2466  decode.d1.loss_cls: 0.2395  decode.d1.loss_mask: 0.2450  decode.d1.loss_dice: 0.2112  decode.d2.loss_cls: 0.1416  decode.d2.loss_mask: 0.2462  decode.d2.loss_dice: 0.2062  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.2499  decode.d4.loss_cls: 0.1882  decode.d4.loss_mask: 0.2465  decode.d4.loss_dice: 0.2362  decode.d5.loss_cls: 0.1938  decode.d5.loss_mask: 0.2467  decode.d5.loss_dice: 0.2333  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 0.2474  decode.d6.loss_dice: 0.2342  decode.d7.loss_cls: 0.1699  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.2376  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 0.2514  decode.d8.loss_dice: 0.2251
09/28 19:49:27 - mmengine - INFO - Iter(train) [ 43750/320000]  base_lr: 8.7607e-05 lr: 8.7607e-06  eta: 1 day, 9:50:11  time: 0.4726  data_time: 0.0094  memory: 5117  grad_norm: 168.6635  loss: 5.2530  decode.loss_cls: 0.0164  decode.loss_mask: 0.2543  decode.loss_dice: 0.1589  decode.d0.loss_cls: 0.8447  decode.d0.loss_mask: 0.2681  decode.d0.loss_dice: 0.1693  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.1562  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.2560  decode.d2.loss_dice: 0.1664  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.2662  decode.d3.loss_dice: 0.1684  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.2720  decode.d4.loss_dice: 0.1570  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.2653  decode.d5.loss_dice: 0.1581  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.2585  decode.d6.loss_dice: 0.1566  decode.d7.loss_cls: 0.0237  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.1573  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.2511  decode.d8.loss_dice: 0.1554
09/28 19:49:50 - mmengine - INFO - Iter(train) [ 43800/320000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 1 day, 9:49:58  time: 0.4708  data_time: 0.0093  memory: 5133  grad_norm: 163.3434  loss: 8.4213  decode.loss_cls: 0.1155  decode.loss_mask: 0.3067  decode.loss_dice: 0.3211  decode.d0.loss_cls: 1.0561  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.3107  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 0.2885  decode.d1.loss_dice: 0.2806  decode.d2.loss_cls: 0.1474  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.2875  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.2793  decode.d4.loss_cls: 0.1443  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.3067  decode.d5.loss_cls: 0.1313  decode.d5.loss_mask: 0.3201  decode.d5.loss_dice: 0.3171  decode.d6.loss_cls: 0.1122  decode.d6.loss_mask: 0.3005  decode.d6.loss_dice: 0.3065  decode.d7.loss_cls: 0.1419  decode.d7.loss_mask: 0.3501  decode.d7.loss_dice: 0.3326  decode.d8.loss_cls: 0.1259  decode.d8.loss_mask: 0.3042  decode.d8.loss_dice: 0.3283
09/28 19:50:14 - mmengine - INFO - Iter(train) [ 43850/320000]  base_lr: 8.7578e-05 lr: 8.7578e-06  eta: 1 day, 9:49:46  time: 0.4715  data_time: 0.0091  memory: 5147  grad_norm: 31.6683  loss: 5.3246  decode.loss_cls: 0.0973  decode.loss_mask: 0.1767  decode.loss_dice: 0.1812  decode.d0.loss_cls: 0.8304  decode.d0.loss_mask: 0.1794  decode.d0.loss_dice: 0.1888  decode.d1.loss_cls: 0.0748  decode.d1.loss_mask: 0.1770  decode.d1.loss_dice: 0.1761  decode.d2.loss_cls: 0.1157  decode.d2.loss_mask: 0.1732  decode.d2.loss_dice: 0.1811  decode.d3.loss_cls: 0.1112  decode.d3.loss_mask: 0.1758  decode.d3.loss_dice: 0.1787  decode.d4.loss_cls: 0.0799  decode.d4.loss_mask: 0.1785  decode.d4.loss_dice: 0.1766  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.1766  decode.d5.loss_dice: 0.1817  decode.d6.loss_cls: 0.1100  decode.d6.loss_mask: 0.1751  decode.d6.loss_dice: 0.1815  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.1797  decode.d7.loss_dice: 0.1868  decode.d8.loss_cls: 0.1078  decode.d8.loss_mask: 0.1779  decode.d8.loss_dice: 0.1915
09/28 19:50:37 - mmengine - INFO - Iter(train) [ 43900/320000]  base_lr: 8.7564e-05 lr: 8.7564e-06  eta: 1 day, 9:49:35  time: 0.4912  data_time: 0.0094  memory: 5132  grad_norm: 133.3941  loss: 5.9533  decode.loss_cls: 0.0334  decode.loss_mask: 0.2487  decode.loss_dice: 0.2011  decode.d0.loss_cls: 0.8250  decode.d0.loss_mask: 0.2500  decode.d0.loss_dice: 0.1985  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.2018  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.2504  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.0826  decode.d3.loss_mask: 0.2536  decode.d3.loss_dice: 0.2185  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.2528  decode.d4.loss_dice: 0.2040  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.2466  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.2458  decode.d6.loss_dice: 0.2014  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.2509  decode.d7.loss_dice: 0.1987  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.2484  decode.d8.loss_dice: 0.2019
09/28 19:51:01 - mmengine - INFO - Iter(train) [ 43950/320000]  base_lr: 8.7550e-05 lr: 8.7550e-06  eta: 1 day, 9:49:22  time: 0.4699  data_time: 0.0095  memory: 5132  grad_norm: 50.1773  loss: 6.7186  decode.loss_cls: 0.1759  decode.loss_mask: 0.2599  decode.loss_dice: 0.1812  decode.d0.loss_cls: 0.7567  decode.d0.loss_mask: 0.2649  decode.d0.loss_dice: 0.1965  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 0.2552  decode.d1.loss_dice: 0.1812  decode.d2.loss_cls: 0.1231  decode.d2.loss_mask: 0.2595  decode.d2.loss_dice: 0.1826  decode.d3.loss_cls: 0.1342  decode.d3.loss_mask: 0.2583  decode.d3.loss_dice: 0.1843  decode.d4.loss_cls: 0.1794  decode.d4.loss_mask: 0.2586  decode.d4.loss_dice: 0.1800  decode.d5.loss_cls: 0.2328  decode.d5.loss_mask: 0.2572  decode.d5.loss_dice: 0.1873  decode.d6.loss_cls: 0.2094  decode.d6.loss_mask: 0.2586  decode.d6.loss_dice: 0.1874  decode.d7.loss_cls: 0.2059  decode.d7.loss_mask: 0.2525  decode.d7.loss_dice: 0.1811  decode.d8.loss_cls: 0.1855  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.1802
09/28 19:51:25 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:51:25 - mmengine - INFO - Iter(train) [ 44000/320000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 1 day, 9:49:10  time: 0.4709  data_time: 0.0094  memory: 5146  grad_norm: 88.2737  loss: 8.3896  decode.loss_cls: 0.2644  decode.loss_mask: 0.2832  decode.loss_dice: 0.2709  decode.d0.loss_cls: 0.9985  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.2777  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.2507  decode.d2.loss_cls: 0.2751  decode.d2.loss_mask: 0.2831  decode.d2.loss_dice: 0.2723  decode.d3.loss_cls: 0.2288  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.2615  decode.d4.loss_cls: 0.1834  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.2550  decode.d5.loss_cls: 0.1729  decode.d5.loss_mask: 0.2878  decode.d5.loss_dice: 0.2655  decode.d6.loss_cls: 0.2186  decode.d6.loss_mask: 0.2807  decode.d6.loss_dice: 0.2539  decode.d7.loss_cls: 0.1666  decode.d7.loss_mask: 0.2891  decode.d7.loss_dice: 0.2510  decode.d8.loss_cls: 0.2257  decode.d8.loss_mask: 0.2814  decode.d8.loss_dice: 0.2585
09/28 19:51:48 - mmengine - INFO - Iter(train) [ 44050/320000]  base_lr: 8.7521e-05 lr: 8.7521e-06  eta: 1 day, 9:48:58  time: 0.4751  data_time: 0.0098  memory: 5117  grad_norm: 108.5999  loss: 5.8739  decode.loss_cls: 0.1177  decode.loss_mask: 0.2073  decode.loss_dice: 0.1719  decode.d0.loss_cls: 0.9596  decode.d0.loss_mask: 0.2075  decode.d0.loss_dice: 0.1935  decode.d1.loss_cls: 0.1027  decode.d1.loss_mask: 0.2069  decode.d1.loss_dice: 0.1773  decode.d2.loss_cls: 0.0890  decode.d2.loss_mask: 0.2120  decode.d2.loss_dice: 0.1838  decode.d3.loss_cls: 0.1177  decode.d3.loss_mask: 0.2072  decode.d3.loss_dice: 0.1820  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.2089  decode.d4.loss_dice: 0.1733  decode.d5.loss_cls: 0.1330  decode.d5.loss_mask: 0.2079  decode.d5.loss_dice: 0.2048  decode.d6.loss_cls: 0.1645  decode.d6.loss_mask: 0.2094  decode.d6.loss_dice: 0.1714  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 0.2056  decode.d7.loss_dice: 0.1690  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.2067  decode.d8.loss_dice: 0.1879
09/28 19:52:12 - mmengine - INFO - Iter(train) [ 44100/320000]  base_lr: 8.7507e-05 lr: 8.7507e-06  eta: 1 day, 9:48:46  time: 0.4731  data_time: 0.0094  memory: 5147  grad_norm: 67.0324  loss: 6.5175  decode.loss_cls: 0.0626  decode.loss_mask: 0.2465  decode.loss_dice: 0.2183  decode.d0.loss_cls: 0.9281  decode.d0.loss_mask: 0.2616  decode.d0.loss_dice: 0.2053  decode.d1.loss_cls: 0.1455  decode.d1.loss_mask: 0.2534  decode.d1.loss_dice: 0.2092  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.2658  decode.d2.loss_dice: 0.2203  decode.d3.loss_cls: 0.1445  decode.d3.loss_mask: 0.2721  decode.d3.loss_dice: 0.2154  decode.d4.loss_cls: 0.1246  decode.d4.loss_mask: 0.2710  decode.d4.loss_dice: 0.2148  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.2949  decode.d5.loss_dice: 0.2175  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.2689  decode.d6.loss_dice: 0.2265  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.2176  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.2195
09/28 19:52:36 - mmengine - INFO - Iter(train) [ 44150/320000]  base_lr: 8.7493e-05 lr: 8.7493e-06  eta: 1 day, 9:48:34  time: 0.4752  data_time: 0.0098  memory: 5117  grad_norm: 58.7823  loss: 7.3939  decode.loss_cls: 0.1161  decode.loss_mask: 0.2738  decode.loss_dice: 0.2614  decode.d0.loss_cls: 0.9878  decode.d0.loss_mask: 0.2783  decode.d0.loss_dice: 0.2770  decode.d1.loss_cls: 0.1497  decode.d1.loss_mask: 0.2750  decode.d1.loss_dice: 0.2566  decode.d2.loss_cls: 0.1063  decode.d2.loss_mask: 0.2730  decode.d2.loss_dice: 0.2606  decode.d3.loss_cls: 0.0907  decode.d3.loss_mask: 0.2707  decode.d3.loss_dice: 0.2571  decode.d4.loss_cls: 0.1087  decode.d4.loss_mask: 0.2695  decode.d4.loss_dice: 0.2530  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 0.2675  decode.d5.loss_dice: 0.2593  decode.d6.loss_cls: 0.1401  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.2636  decode.d7.loss_cls: 0.1309  decode.d7.loss_mask: 0.2744  decode.d7.loss_dice: 0.2610  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.2716  decode.d8.loss_dice: 0.2589
09/28 19:52:59 - mmengine - INFO - Iter(train) [ 44200/320000]  base_lr: 8.7478e-05 lr: 8.7478e-06  eta: 1 day, 9:48:21  time: 0.4716  data_time: 0.0097  memory: 5132  grad_norm: 83.4565  loss: 7.8801  decode.loss_cls: 0.2079  decode.loss_mask: 0.2551  decode.loss_dice: 0.2199  decode.d0.loss_cls: 1.0778  decode.d0.loss_mask: 0.2589  decode.d0.loss_dice: 0.2414  decode.d1.loss_cls: 0.2063  decode.d1.loss_mask: 0.2553  decode.d1.loss_dice: 0.2185  decode.d2.loss_cls: 0.1923  decode.d2.loss_mask: 0.2563  decode.d2.loss_dice: 0.2555  decode.d3.loss_cls: 0.2597  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2112  decode.d4.loss_cls: 0.2564  decode.d4.loss_mask: 0.2549  decode.d4.loss_dice: 0.2153  decode.d5.loss_cls: 0.2002  decode.d5.loss_mask: 0.2541  decode.d5.loss_dice: 0.2226  decode.d6.loss_cls: 0.1941  decode.d6.loss_mask: 0.2551  decode.d6.loss_dice: 0.2103  decode.d7.loss_cls: 0.2189  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.2322  decode.d8.loss_cls: 0.2535  decode.d8.loss_mask: 0.2548  decode.d8.loss_dice: 0.2311
09/28 19:53:23 - mmengine - INFO - Iter(train) [ 44250/320000]  base_lr: 8.7464e-05 lr: 8.7464e-06  eta: 1 day, 9:48:09  time: 0.4723  data_time: 0.0094  memory: 5133  grad_norm: 113.1563  loss: 7.4066  decode.loss_cls: 0.2464  decode.loss_mask: 0.2158  decode.loss_dice: 0.2105  decode.d0.loss_cls: 0.9125  decode.d0.loss_mask: 0.2187  decode.d0.loss_dice: 0.2378  decode.d1.loss_cls: 0.1867  decode.d1.loss_mask: 0.2145  decode.d1.loss_dice: 0.2347  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 0.2152  decode.d2.loss_dice: 0.2149  decode.d3.loss_cls: 0.2191  decode.d3.loss_mask: 0.2140  decode.d3.loss_dice: 0.2267  decode.d4.loss_cls: 0.2490  decode.d4.loss_mask: 0.2183  decode.d4.loss_dice: 0.2220  decode.d5.loss_cls: 0.2674  decode.d5.loss_mask: 0.2188  decode.d5.loss_dice: 0.2307  decode.d6.loss_cls: 0.1964  decode.d6.loss_mask: 0.2164  decode.d6.loss_dice: 0.2337  decode.d7.loss_cls: 0.2410  decode.d7.loss_mask: 0.2177  decode.d7.loss_dice: 0.2415  decode.d8.loss_cls: 0.2301  decode.d8.loss_mask: 0.2166  decode.d8.loss_dice: 0.2280
09/28 19:53:46 - mmengine - INFO - Iter(train) [ 44300/320000]  base_lr: 8.7450e-05 lr: 8.7450e-06  eta: 1 day, 9:47:56  time: 0.4737  data_time: 0.0095  memory: 5147  grad_norm: 28.9044  loss: 5.8199  decode.loss_cls: 0.1159  decode.loss_mask: 0.1857  decode.loss_dice: 0.2149  decode.d0.loss_cls: 0.7908  decode.d0.loss_mask: 0.1889  decode.d0.loss_dice: 0.2381  decode.d1.loss_cls: 0.1541  decode.d1.loss_mask: 0.1858  decode.d1.loss_dice: 0.2063  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.1860  decode.d2.loss_dice: 0.2205  decode.d3.loss_cls: 0.1209  decode.d3.loss_mask: 0.1864  decode.d3.loss_dice: 0.2179  decode.d4.loss_cls: 0.1076  decode.d4.loss_mask: 0.1849  decode.d4.loss_dice: 0.2087  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.1863  decode.d5.loss_dice: 0.2222  decode.d6.loss_cls: 0.0881  decode.d6.loss_mask: 0.1862  decode.d6.loss_dice: 0.2036  decode.d7.loss_cls: 0.1267  decode.d7.loss_mask: 0.1849  decode.d7.loss_dice: 0.1923  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.1860  decode.d8.loss_dice: 0.2132
09/28 19:54:10 - mmengine - INFO - Iter(train) [ 44350/320000]  base_lr: 8.7436e-05 lr: 8.7436e-06  eta: 1 day, 9:47:44  time: 0.4704  data_time: 0.0093  memory: 5117  grad_norm: 19.6917  loss: 4.7857  decode.loss_cls: 0.0211  decode.loss_mask: 0.2137  decode.loss_dice: 0.1620  decode.d0.loss_cls: 0.8298  decode.d0.loss_mask: 0.2190  decode.d0.loss_dice: 0.1664  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.2190  decode.d1.loss_dice: 0.1577  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.2157  decode.d2.loss_dice: 0.1595  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.2171  decode.d3.loss_dice: 0.1579  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.2178  decode.d4.loss_dice: 0.1583  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.2169  decode.d5.loss_dice: 0.1599  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.2196  decode.d6.loss_dice: 0.1598  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.2178  decode.d7.loss_dice: 0.1617  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.2183  decode.d8.loss_dice: 0.1605
09/28 19:54:34 - mmengine - INFO - Iter(train) [ 44400/320000]  base_lr: 8.7421e-05 lr: 8.7421e-06  eta: 1 day, 9:47:31  time: 0.4718  data_time: 0.0095  memory: 5147  grad_norm: 24.0409  loss: 5.2141  decode.loss_cls: 0.0243  decode.loss_mask: 0.2231  decode.loss_dice: 0.1927  decode.d0.loss_cls: 0.8279  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.1847  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.2215  decode.d1.loss_dice: 0.1914  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.2206  decode.d2.loss_dice: 0.1933  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.2198  decode.d3.loss_dice: 0.1932  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.2196  decode.d4.loss_dice: 0.1933  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.2219  decode.d5.loss_dice: 0.1916  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.2232  decode.d6.loss_dice: 0.1905  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.2240  decode.d7.loss_dice: 0.1937  decode.d8.loss_cls: 0.0188  decode.d8.loss_mask: 0.2205  decode.d8.loss_dice: 0.1918
09/28 19:54:57 - mmengine - INFO - Iter(train) [ 44450/320000]  base_lr: 8.7407e-05 lr: 8.7407e-06  eta: 1 day, 9:47:19  time: 0.4720  data_time: 0.0096  memory: 5133  grad_norm: 45.8002  loss: 7.8368  decode.loss_cls: 0.1888  decode.loss_mask: 0.2174  decode.loss_dice: 0.2493  decode.d0.loss_cls: 0.9461  decode.d0.loss_mask: 0.2183  decode.d0.loss_dice: 0.2885  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 0.2144  decode.d1.loss_dice: 0.2581  decode.d2.loss_cls: 0.2237  decode.d2.loss_mask: 0.2139  decode.d2.loss_dice: 0.2766  decode.d3.loss_cls: 0.2326  decode.d3.loss_mask: 0.2162  decode.d3.loss_dice: 0.2576  decode.d4.loss_cls: 0.2682  decode.d4.loss_mask: 0.2154  decode.d4.loss_dice: 0.2917  decode.d5.loss_cls: 0.2743  decode.d5.loss_mask: 0.2148  decode.d5.loss_dice: 0.2661  decode.d6.loss_cls: 0.2404  decode.d6.loss_mask: 0.2165  decode.d6.loss_dice: 0.2981  decode.d7.loss_cls: 0.2064  decode.d7.loss_mask: 0.2166  decode.d7.loss_dice: 0.2470  decode.d8.loss_cls: 0.1560  decode.d8.loss_mask: 0.2176  decode.d8.loss_dice: 0.2929
09/28 19:55:21 - mmengine - INFO - Iter(train) [ 44500/320000]  base_lr: 8.7393e-05 lr: 8.7393e-06  eta: 1 day, 9:47:06  time: 0.4736  data_time: 0.0099  memory: 5117  grad_norm: 148.4680  loss: 12.5637  decode.loss_cls: 0.2651  decode.loss_mask: 0.5585  decode.loss_dice: 0.3406  decode.d0.loss_cls: 1.0510  decode.d0.loss_mask: 0.5912  decode.d0.loss_dice: 0.3465  decode.d1.loss_cls: 0.2917  decode.d1.loss_mask: 0.5615  decode.d1.loss_dice: 0.3503  decode.d2.loss_cls: 0.2354  decode.d2.loss_mask: 0.5447  decode.d2.loss_dice: 0.3423  decode.d3.loss_cls: 0.2526  decode.d3.loss_mask: 0.6714  decode.d3.loss_dice: 0.3384  decode.d4.loss_cls: 0.2527  decode.d4.loss_mask: 0.5291  decode.d4.loss_dice: 0.3572  decode.d5.loss_cls: 0.2321  decode.d5.loss_mask: 0.5357  decode.d5.loss_dice: 0.3247  decode.d6.loss_cls: 0.3990  decode.d6.loss_mask: 0.4646  decode.d6.loss_dice: 0.3209  decode.d7.loss_cls: 0.3410  decode.d7.loss_mask: 0.5318  decode.d7.loss_dice: 0.3332  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 0.5792  decode.d8.loss_dice: 0.3238
09/28 19:55:44 - mmengine - INFO - Iter(train) [ 44550/320000]  base_lr: 8.7379e-05 lr: 8.7379e-06  eta: 1 day, 9:46:53  time: 0.4719  data_time: 0.0094  memory: 5133  grad_norm: 40.1639  loss: 6.1941  decode.loss_cls: 0.1766  decode.loss_mask: 0.2091  decode.loss_dice: 0.1848  decode.d0.loss_cls: 0.9197  decode.d0.loss_mask: 0.2134  decode.d0.loss_dice: 0.1784  decode.d1.loss_cls: 0.1647  decode.d1.loss_mask: 0.2079  decode.d1.loss_dice: 0.1747  decode.d2.loss_cls: 0.1328  decode.d2.loss_mask: 0.2068  decode.d2.loss_dice: 0.1824  decode.d3.loss_cls: 0.1277  decode.d3.loss_mask: 0.2102  decode.d3.loss_dice: 0.1819  decode.d4.loss_cls: 0.1185  decode.d4.loss_mask: 0.2105  decode.d4.loss_dice: 0.1781  decode.d5.loss_cls: 0.1613  decode.d5.loss_mask: 0.2096  decode.d5.loss_dice: 0.1806  decode.d6.loss_cls: 0.1621  decode.d6.loss_mask: 0.2077  decode.d6.loss_dice: 0.1798  decode.d7.loss_cls: 0.1771  decode.d7.loss_mask: 0.2096  decode.d7.loss_dice: 0.1761  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 0.2071  decode.d8.loss_dice: 0.1786
09/28 19:56:08 - mmengine - INFO - Iter(train) [ 44600/320000]  base_lr: 8.7364e-05 lr: 8.7364e-06  eta: 1 day, 9:46:40  time: 0.4704  data_time: 0.0093  memory: 5147  grad_norm: 60.6142  loss: 7.1953  decode.loss_cls: 0.1088  decode.loss_mask: 0.2595  decode.loss_dice: 0.2153  decode.d0.loss_cls: 1.1112  decode.d0.loss_mask: 0.2610  decode.d0.loss_dice: 0.2178  decode.d1.loss_cls: 0.1932  decode.d1.loss_mask: 0.2633  decode.d1.loss_dice: 0.2111  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.2040  decode.d3.loss_cls: 0.1366  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.2193  decode.d4.loss_cls: 0.1618  decode.d4.loss_mask: 0.2695  decode.d4.loss_dice: 0.2243  decode.d5.loss_cls: 0.1469  decode.d5.loss_mask: 0.2621  decode.d5.loss_dice: 0.2156  decode.d6.loss_cls: 0.1296  decode.d6.loss_mask: 0.2610  decode.d6.loss_dice: 0.2222  decode.d7.loss_cls: 0.1380  decode.d7.loss_mask: 0.2596  decode.d7.loss_dice: 0.2124  decode.d8.loss_cls: 0.1426  decode.d8.loss_mask: 0.2596  decode.d8.loss_dice: 0.2103
09/28 19:56:32 - mmengine - INFO - Iter(train) [ 44650/320000]  base_lr: 8.7350e-05 lr: 8.7350e-06  eta: 1 day, 9:46:28  time: 0.4723  data_time: 0.0095  memory: 5133  grad_norm: 46.1037  loss: 7.3471  decode.loss_cls: 0.0798  decode.loss_mask: 0.3017  decode.loss_dice: 0.2589  decode.d0.loss_cls: 0.9451  decode.d0.loss_mask: 0.3114  decode.d0.loss_dice: 0.2733  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.3034  decode.d1.loss_dice: 0.2567  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.3001  decode.d2.loss_dice: 0.2600  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.2987  decode.d3.loss_dice: 0.2635  decode.d4.loss_cls: 0.0933  decode.d4.loss_mask: 0.2977  decode.d4.loss_dice: 0.2641  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.2969  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.0830  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.2584  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.2514  decode.d8.loss_cls: 0.0729  decode.d8.loss_mask: 0.3018  decode.d8.loss_dice: 0.2685
09/28 19:56:55 - mmengine - INFO - Iter(train) [ 44700/320000]  base_lr: 8.7336e-05 lr: 8.7336e-06  eta: 1 day, 9:46:15  time: 0.4731  data_time: 0.0097  memory: 5132  grad_norm: 29.4946  loss: 5.4984  decode.loss_cls: 0.0225  decode.loss_mask: 0.2701  decode.loss_dice: 0.1774  decode.d0.loss_cls: 0.7682  decode.d0.loss_mask: 0.2731  decode.d0.loss_dice: 0.1805  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.2736  decode.d1.loss_dice: 0.1871  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.1790  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.2718  decode.d4.loss_dice: 0.1826  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.2680  decode.d5.loss_dice: 0.1819  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.2740  decode.d6.loss_dice: 0.1770  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.2673  decode.d7.loss_dice: 0.1814  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.2706  decode.d8.loss_dice: 0.1773
09/28 19:57:19 - mmengine - INFO - Iter(train) [ 44750/320000]  base_lr: 8.7321e-05 lr: 8.7321e-06  eta: 1 day, 9:46:03  time: 0.4723  data_time: 0.0095  memory: 5147  grad_norm: 104.2374  loss: 8.0891  decode.loss_cls: 0.0903  decode.loss_mask: 0.3006  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.9817  decode.d0.loss_mask: 0.3043  decode.d0.loss_dice: 0.3087  decode.d1.loss_cls: 0.1605  decode.d1.loss_mask: 0.3049  decode.d1.loss_dice: 0.2881  decode.d2.loss_cls: 0.1201  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.2932  decode.d3.loss_cls: 0.1518  decode.d3.loss_mask: 0.2924  decode.d3.loss_dice: 0.2919  decode.d4.loss_cls: 0.1249  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.2698  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 0.3209  decode.d5.loss_dice: 0.2855  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.3145  decode.d6.loss_dice: 0.2905  decode.d7.loss_cls: 0.1554  decode.d7.loss_mask: 0.2955  decode.d7.loss_dice: 0.2843  decode.d8.loss_cls: 0.1742  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.2857
09/28 19:57:43 - mmengine - INFO - Iter(train) [ 44800/320000]  base_lr: 8.7307e-05 lr: 8.7307e-06  eta: 1 day, 9:45:50  time: 0.4705  data_time: 0.0095  memory: 5147  grad_norm: 60.7131  loss: 7.6962  decode.loss_cls: 0.2142  decode.loss_mask: 0.2537  decode.loss_dice: 0.2582  decode.d0.loss_cls: 0.8455  decode.d0.loss_mask: 0.2613  decode.d0.loss_dice: 0.2720  decode.d1.loss_cls: 0.1931  decode.d1.loss_mask: 0.2536  decode.d1.loss_dice: 0.2594  decode.d2.loss_cls: 0.1816  decode.d2.loss_mask: 0.2544  decode.d2.loss_dice: 0.2433  decode.d3.loss_cls: 0.1825  decode.d3.loss_mask: 0.2543  decode.d3.loss_dice: 0.2696  decode.d4.loss_cls: 0.2068  decode.d4.loss_mask: 0.2495  decode.d4.loss_dice: 0.2515  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 0.2560  decode.d5.loss_dice: 0.2425  decode.d6.loss_cls: 0.1772  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2848  decode.d7.loss_cls: 0.1723  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.2603  decode.d8.loss_cls: 0.1928  decode.d8.loss_mask: 0.2561  decode.d8.loss_dice: 0.2444
09/28 19:58:06 - mmengine - INFO - Iter(train) [ 44850/320000]  base_lr: 8.7293e-05 lr: 8.7293e-06  eta: 1 day, 9:45:38  time: 0.4731  data_time: 0.0095  memory: 5117  grad_norm: 42.7489  loss: 5.9265  decode.loss_cls: 0.0983  decode.loss_mask: 0.2392  decode.loss_dice: 0.2100  decode.d0.loss_cls: 0.8867  decode.d0.loss_mask: 0.2403  decode.d0.loss_dice: 0.1745  decode.d1.loss_cls: 0.1657  decode.d1.loss_mask: 0.2321  decode.d1.loss_dice: 0.1691  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.2352  decode.d2.loss_dice: 0.1768  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.2361  decode.d3.loss_dice: 0.1811  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.2348  decode.d4.loss_dice: 0.2025  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.2333  decode.d5.loss_dice: 0.1983  decode.d6.loss_cls: 0.0818  decode.d6.loss_mask: 0.2385  decode.d6.loss_dice: 0.1762  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.2354  decode.d7.loss_dice: 0.1901  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.2244
09/28 19:58:29 - mmengine - INFO - Iter(train) [ 44900/320000]  base_lr: 8.7279e-05 lr: 8.7279e-06  eta: 1 day, 9:45:19  time: 0.4334  data_time: 0.0093  memory: 5132  grad_norm: 53.5367  loss: 6.3350  decode.loss_cls: 0.0682  decode.loss_mask: 0.2154  decode.loss_dice: 0.2415  decode.d0.loss_cls: 0.9212  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.2445  decode.d1.loss_cls: 0.2102  decode.d1.loss_mask: 0.2162  decode.d1.loss_dice: 0.2338  decode.d2.loss_cls: 0.1617  decode.d2.loss_mask: 0.2154  decode.d2.loss_dice: 0.2372  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.2151  decode.d3.loss_dice: 0.2281  decode.d4.loss_cls: 0.0516  decode.d4.loss_mask: 0.2162  decode.d4.loss_dice: 0.2405  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.2123  decode.d5.loss_dice: 0.2325  decode.d6.loss_cls: 0.1108  decode.d6.loss_mask: 0.2134  decode.d6.loss_dice: 0.2397  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.2138  decode.d7.loss_dice: 0.2381  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.2116  decode.d8.loss_dice: 0.2428
09/28 19:58:52 - mmengine - INFO - Iter(train) [ 44950/320000]  base_lr: 8.7264e-05 lr: 8.7264e-06  eta: 1 day, 9:45:03  time: 0.4729  data_time: 0.0095  memory: 5132  grad_norm: 35.6730  loss: 5.9303  decode.loss_cls: 0.1434  decode.loss_mask: 0.1475  decode.loss_dice: 0.2283  decode.d0.loss_cls: 1.0274  decode.d0.loss_mask: 0.1453  decode.d0.loss_dice: 0.2312  decode.d1.loss_cls: 0.1529  decode.d1.loss_mask: 0.1469  decode.d1.loss_dice: 0.2183  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 0.1453  decode.d2.loss_dice: 0.1950  decode.d3.loss_cls: 0.1644  decode.d3.loss_mask: 0.1453  decode.d3.loss_dice: 0.2191  decode.d4.loss_cls: 0.1524  decode.d4.loss_mask: 0.1476  decode.d4.loss_dice: 0.2248  decode.d5.loss_cls: 0.1447  decode.d5.loss_mask: 0.1464  decode.d5.loss_dice: 0.2294  decode.d6.loss_cls: 0.1351  decode.d6.loss_mask: 0.1482  decode.d6.loss_dice: 0.1982  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.1476  decode.d7.loss_dice: 0.2106  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.1461  decode.d8.loss_dice: 0.2371
09/28 19:59:15 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 19:59:15 - mmengine - INFO - Iter(train) [ 45000/320000]  base_lr: 8.7250e-05 lr: 8.7250e-06  eta: 1 day, 9:44:50  time: 0.4708  data_time: 0.0094  memory: 5133  grad_norm: 69.5564  loss: 7.1164  decode.loss_cls: 0.1592  decode.loss_mask: 0.2226  decode.loss_dice: 0.2152  decode.d0.loss_cls: 0.9908  decode.d0.loss_mask: 0.2207  decode.d0.loss_dice: 0.2222  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 0.2235  decode.d1.loss_dice: 0.2257  decode.d2.loss_cls: 0.1728  decode.d2.loss_mask: 0.2185  decode.d2.loss_dice: 0.2094  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 0.2217  decode.d3.loss_dice: 0.2163  decode.d4.loss_cls: 0.1891  decode.d4.loss_mask: 0.2246  decode.d4.loss_dice: 0.2275  decode.d5.loss_cls: 0.1687  decode.d5.loss_mask: 0.2181  decode.d5.loss_dice: 0.2139  decode.d6.loss_cls: 0.1916  decode.d6.loss_mask: 0.2740  decode.d6.loss_dice: 0.2166  decode.d7.loss_cls: 0.1751  decode.d7.loss_mask: 0.2299  decode.d7.loss_dice: 0.2349  decode.d8.loss_cls: 0.2086  decode.d8.loss_mask: 0.2238  decode.d8.loss_dice: 0.2257
09/28 19:59:39 - mmengine - INFO - Iter(train) [ 45050/320000]  base_lr: 8.7236e-05 lr: 8.7236e-06  eta: 1 day, 9:44:37  time: 0.4748  data_time: 0.0094  memory: 5133  grad_norm: 49.3496  loss: 5.2375  decode.loss_cls: 0.0395  decode.loss_mask: 0.2013  decode.loss_dice: 0.1894  decode.d0.loss_cls: 0.7900  decode.d0.loss_mask: 0.2027  decode.d0.loss_dice: 0.1849  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.2016  decode.d1.loss_dice: 0.1858  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.2011  decode.d2.loss_dice: 0.1867  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.2035  decode.d3.loss_dice: 0.1894  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.2014  decode.d4.loss_dice: 0.1797  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.2011  decode.d5.loss_dice: 0.1894  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.2016  decode.d6.loss_dice: 0.1846  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.2016  decode.d7.loss_dice: 0.1874  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.2017  decode.d8.loss_dice: 0.1877
09/28 20:00:03 - mmengine - INFO - Iter(train) [ 45100/320000]  base_lr: 8.7221e-05 lr: 8.7221e-06  eta: 1 day, 9:44:25  time: 0.4727  data_time: 0.0098  memory: 5132  grad_norm: 27.1985  loss: 5.2394  decode.loss_cls: 0.0708  decode.loss_mask: 0.1997  decode.loss_dice: 0.1713  decode.d0.loss_cls: 0.9434  decode.d0.loss_mask: 0.2014  decode.d0.loss_dice: 0.1789  decode.d1.loss_cls: 0.0567  decode.d1.loss_mask: 0.2012  decode.d1.loss_dice: 0.1731  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.2001  decode.d2.loss_dice: 0.1738  decode.d3.loss_cls: 0.1050  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.1702  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.1993  decode.d4.loss_dice: 0.1723  decode.d5.loss_cls: 0.0966  decode.d5.loss_mask: 0.1995  decode.d5.loss_dice: 0.1751  decode.d6.loss_cls: 0.0428  decode.d6.loss_mask: 0.1992  decode.d6.loss_dice: 0.1754  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.2016  decode.d7.loss_dice: 0.1725  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.1978  decode.d8.loss_dice: 0.1709
09/28 20:00:26 - mmengine - INFO - Iter(train) [ 45150/320000]  base_lr: 8.7207e-05 lr: 8.7207e-06  eta: 1 day, 9:44:11  time: 0.4710  data_time: 0.0096  memory: 5133  grad_norm: 73.2985  loss: 6.5758  decode.loss_cls: 0.1994  decode.loss_mask: 0.2217  decode.loss_dice: 0.2028  decode.d0.loss_cls: 0.8224  decode.d0.loss_mask: 0.2237  decode.d0.loss_dice: 0.2108  decode.d1.loss_cls: 0.1340  decode.d1.loss_mask: 0.2256  decode.d1.loss_dice: 0.1754  decode.d2.loss_cls: 0.1387  decode.d2.loss_mask: 0.2244  decode.d2.loss_dice: 0.2099  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 0.2241  decode.d3.loss_dice: 0.2060  decode.d4.loss_cls: 0.1998  decode.d4.loss_mask: 0.2218  decode.d4.loss_dice: 0.2159  decode.d5.loss_cls: 0.2031  decode.d5.loss_mask: 0.2201  decode.d5.loss_dice: 0.1757  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.2190  decode.d7.loss_cls: 0.1775  decode.d7.loss_mask: 0.2216  decode.d7.loss_dice: 0.1981  decode.d8.loss_cls: 0.1675  decode.d8.loss_mask: 0.2225  decode.d8.loss_dice: 0.2056
09/28 20:00:50 - mmengine - INFO - Iter(train) [ 45200/320000]  base_lr: 8.7193e-05 lr: 8.7193e-06  eta: 1 day, 9:43:59  time: 0.4776  data_time: 0.0100  memory: 5147  grad_norm: 30.5852  loss: 5.6351  decode.loss_cls: 0.0218  decode.loss_mask: 0.2667  decode.loss_dice: 0.2066  decode.d0.loss_cls: 0.7187  decode.d0.loss_mask: 0.2686  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.0269  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.2075  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.2666  decode.d2.loss_dice: 0.2103  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.2666  decode.d3.loss_dice: 0.2091  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.2651  decode.d4.loss_dice: 0.2044  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2068  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.2680  decode.d6.loss_dice: 0.2054  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.2646  decode.d7.loss_dice: 0.1997  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.2635  decode.d8.loss_dice: 0.2037
09/28 20:01:14 - mmengine - INFO - Iter(train) [ 45250/320000]  base_lr: 8.7179e-05 lr: 8.7179e-06  eta: 1 day, 9:43:46  time: 0.4716  data_time: 0.0097  memory: 5133  grad_norm: 100.9622  loss: 7.3432  decode.loss_cls: 0.2185  decode.loss_mask: 0.2074  decode.loss_dice: 0.2429  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 0.2166  decode.d0.loss_dice: 0.2329  decode.d1.loss_cls: 0.2594  decode.d1.loss_mask: 0.2118  decode.d1.loss_dice: 0.2267  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.2113  decode.d2.loss_dice: 0.2423  decode.d3.loss_cls: 0.2521  decode.d3.loss_mask: 0.2092  decode.d3.loss_dice: 0.2428  decode.d4.loss_cls: 0.2314  decode.d4.loss_mask: 0.2095  decode.d4.loss_dice: 0.2134  decode.d5.loss_cls: 0.2024  decode.d5.loss_mask: 0.2085  decode.d5.loss_dice: 0.2329  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 0.2116  decode.d6.loss_dice: 0.2541  decode.d7.loss_cls: 0.2143  decode.d7.loss_mask: 0.2089  decode.d7.loss_dice: 0.2439  decode.d8.loss_cls: 0.1889  decode.d8.loss_mask: 0.2122  decode.d8.loss_dice: 0.2341
09/28 20:01:37 - mmengine - INFO - Iter(train) [ 45300/320000]  base_lr: 8.7164e-05 lr: 8.7164e-06  eta: 1 day, 9:43:33  time: 0.4716  data_time: 0.0098  memory: 5132  grad_norm: 37.4324  loss: 6.2014  decode.loss_cls: 0.0102  decode.loss_mask: 0.2613  decode.loss_dice: 0.2457  decode.d0.loss_cls: 0.8805  decode.d0.loss_mask: 0.2544  decode.d0.loss_dice: 0.2420  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.2582  decode.d1.loss_dice: 0.2422  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.2630  decode.d2.loss_dice: 0.2574  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2635  decode.d3.loss_dice: 0.2485  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.2607  decode.d4.loss_dice: 0.2505  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.2610  decode.d5.loss_dice: 0.2434  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.2656  decode.d6.loss_dice: 0.2587  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.2548  decode.d7.loss_dice: 0.2584  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.2609  decode.d8.loss_dice: 0.2548
09/28 20:02:01 - mmengine - INFO - Iter(train) [ 45350/320000]  base_lr: 8.7150e-05 lr: 8.7150e-06  eta: 1 day, 9:43:20  time: 0.4703  data_time: 0.0094  memory: 5132  grad_norm: 67.9847  loss: 5.8461  decode.loss_cls: 0.0188  decode.loss_mask: 0.2720  decode.loss_dice: 0.1903  decode.d0.loss_cls: 0.9673  decode.d0.loss_mask: 0.2826  decode.d0.loss_dice: 0.1953  decode.d1.loss_cls: 0.0308  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.1974  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.2687  decode.d2.loss_dice: 0.1905  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.1883  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.1863  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.1835  decode.d6.loss_cls: 0.0246  decode.d6.loss_mask: 0.2712  decode.d6.loss_dice: 0.1931  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.2747  decode.d7.loss_dice: 0.1958  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.2730  decode.d8.loss_dice: 0.1977
09/28 20:02:24 - mmengine - INFO - Iter(train) [ 45400/320000]  base_lr: 8.7136e-05 lr: 8.7136e-06  eta: 1 day, 9:43:06  time: 0.4709  data_time: 0.0094  memory: 5147  grad_norm: 31.2651  loss: 6.1093  decode.loss_cls: 0.0348  decode.loss_mask: 0.2422  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.9001  decode.d0.loss_mask: 0.2360  decode.d0.loss_dice: 0.2310  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.2363  decode.d1.loss_dice: 0.2462  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.2400  decode.d2.loss_dice: 0.2342  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.2336  decode.d3.loss_dice: 0.2384  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.2467  decode.d4.loss_dice: 0.2402  decode.d5.loss_cls: 0.0257  decode.d5.loss_mask: 0.2415  decode.d5.loss_dice: 0.2332  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.2412  decode.d6.loss_dice: 0.2433  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.2363  decode.d7.loss_dice: 0.2417  decode.d8.loss_cls: 0.0371  decode.d8.loss_mask: 0.2404  decode.d8.loss_dice: 0.2339
09/28 20:02:48 - mmengine - INFO - Iter(train) [ 45450/320000]  base_lr: 8.7122e-05 lr: 8.7122e-06  eta: 1 day, 9:42:53  time: 0.4723  data_time: 0.0095  memory: 5132  grad_norm: 60.5738  loss: 6.7347  decode.loss_cls: 0.0477  decode.loss_mask: 0.2679  decode.loss_dice: 0.2461  decode.d0.loss_cls: 0.8956  decode.d0.loss_mask: 0.2775  decode.d0.loss_dice: 0.2730  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.2674  decode.d1.loss_dice: 0.2638  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.2688  decode.d2.loss_dice: 0.2660  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.2700  decode.d3.loss_dice: 0.2360  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.2696  decode.d4.loss_dice: 0.2443  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.2496  decode.d6.loss_cls: 0.0733  decode.d6.loss_mask: 0.2660  decode.d6.loss_dice: 0.2559  decode.d7.loss_cls: 0.0709  decode.d7.loss_mask: 0.2635  decode.d7.loss_dice: 0.2308  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.2691  decode.d8.loss_dice: 0.2529
09/28 20:03:12 - mmengine - INFO - Iter(train) [ 45500/320000]  base_lr: 8.7107e-05 lr: 8.7107e-06  eta: 1 day, 9:42:40  time: 0.4718  data_time: 0.0096  memory: 5133  grad_norm: 77.0598  loss: 7.0408  decode.loss_cls: 0.0990  decode.loss_mask: 0.2729  decode.loss_dice: 0.2359  decode.d0.loss_cls: 1.0232  decode.d0.loss_mask: 0.2321  decode.d0.loss_dice: 0.2591  decode.d1.loss_cls: 0.1242  decode.d1.loss_mask: 0.2484  decode.d1.loss_dice: 0.2424  decode.d2.loss_cls: 0.1659  decode.d2.loss_mask: 0.2594  decode.d2.loss_dice: 0.2436  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.2636  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.2686  decode.d4.loss_dice: 0.2533  decode.d5.loss_cls: 0.0883  decode.d5.loss_mask: 0.2682  decode.d5.loss_dice: 0.2492  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.2617  decode.d6.loss_dice: 0.2375  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.2709  decode.d7.loss_dice: 0.2247  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.2694  decode.d8.loss_dice: 0.2423
09/28 20:03:35 - mmengine - INFO - Iter(train) [ 45550/320000]  base_lr: 8.7093e-05 lr: 8.7093e-06  eta: 1 day, 9:42:28  time: 0.4891  data_time: 0.0096  memory: 5147  grad_norm: 40.6369  loss: 7.0273  decode.loss_cls: 0.1401  decode.loss_mask: 0.2453  decode.loss_dice: 0.2281  decode.d0.loss_cls: 0.9657  decode.d0.loss_mask: 0.2447  decode.d0.loss_dice: 0.2412  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.2388  decode.d1.loss_dice: 0.2368  decode.d2.loss_cls: 0.1663  decode.d2.loss_mask: 0.2507  decode.d2.loss_dice: 0.2378  decode.d3.loss_cls: 0.1266  decode.d3.loss_mask: 0.2550  decode.d3.loss_dice: 0.2313  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.2507  decode.d4.loss_dice: 0.2349  decode.d5.loss_cls: 0.1668  decode.d5.loss_mask: 0.2503  decode.d5.loss_dice: 0.2288  decode.d6.loss_cls: 0.1516  decode.d6.loss_mask: 0.2481  decode.d6.loss_dice: 0.2318  decode.d7.loss_cls: 0.1287  decode.d7.loss_mask: 0.2463  decode.d7.loss_dice: 0.2366  decode.d8.loss_cls: 0.1522  decode.d8.loss_mask: 0.2464  decode.d8.loss_dice: 0.2334
09/28 20:03:59 - mmengine - INFO - Iter(train) [ 45600/320000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 1 day, 9:42:15  time: 0.4721  data_time: 0.0096  memory: 5147  grad_norm: 34.8325  loss: 5.7561  decode.loss_cls: 0.1091  decode.loss_mask: 0.2238  decode.loss_dice: 0.1728  decode.d0.loss_cls: 0.7383  decode.d0.loss_mask: 0.2225  decode.d0.loss_dice: 0.1718  decode.d1.loss_cls: 0.1093  decode.d1.loss_mask: 0.2216  decode.d1.loss_dice: 0.1726  decode.d2.loss_cls: 0.1231  decode.d2.loss_mask: 0.2230  decode.d2.loss_dice: 0.1742  decode.d3.loss_cls: 0.1211  decode.d3.loss_mask: 0.2230  decode.d3.loss_dice: 0.1752  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.2229  decode.d4.loss_dice: 0.1736  decode.d5.loss_cls: 0.1248  decode.d5.loss_mask: 0.2197  decode.d5.loss_dice: 0.1755  decode.d6.loss_cls: 0.1093  decode.d6.loss_mask: 0.2206  decode.d6.loss_dice: 0.1724  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 0.2213  decode.d7.loss_dice: 0.1741  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 0.2237  decode.d8.loss_dice: 0.1731
09/28 20:04:23 - mmengine - INFO - Iter(train) [ 45650/320000]  base_lr: 8.7064e-05 lr: 8.7064e-06  eta: 1 day, 9:42:02  time: 0.4755  data_time: 0.0097  memory: 5117  grad_norm: 74.8277  loss: 7.2037  decode.loss_cls: 0.0844  decode.loss_mask: 0.2908  decode.loss_dice: 0.2615  decode.d0.loss_cls: 0.8774  decode.d0.loss_mask: 0.3065  decode.d0.loss_dice: 0.2851  decode.d1.loss_cls: 0.1020  decode.d1.loss_mask: 0.2938  decode.d1.loss_dice: 0.2566  decode.d2.loss_cls: 0.0828  decode.d2.loss_mask: 0.3004  decode.d2.loss_dice: 0.2578  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.2600  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.2609  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.2598  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.2577  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.2592  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.3013  decode.d8.loss_dice: 0.2600
09/28 20:04:46 - mmengine - INFO - Iter(train) [ 45700/320000]  base_lr: 8.7050e-05 lr: 8.7050e-06  eta: 1 day, 9:41:49  time: 0.4695  data_time: 0.0094  memory: 5147  grad_norm: 39.3011  loss: 6.2083  decode.loss_cls: 0.0875  decode.loss_mask: 0.2701  decode.loss_dice: 0.1874  decode.d0.loss_cls: 0.8693  decode.d0.loss_mask: 0.2703  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.2733  decode.d1.loss_dice: 0.1797  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.2725  decode.d2.loss_dice: 0.1924  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.2679  decode.d3.loss_dice: 0.2170  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.2713  decode.d4.loss_dice: 0.1980  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.1878  decode.d6.loss_cls: 0.0412  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.2121  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.2675  decode.d7.loss_dice: 0.1897  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.1975
09/28 20:05:10 - mmengine - INFO - Iter(train) [ 45750/320000]  base_lr: 8.7036e-05 lr: 8.7036e-06  eta: 1 day, 9:41:36  time: 0.4730  data_time: 0.0094  memory: 5147  grad_norm: 65.1597  loss: 5.2310  decode.loss_cls: 0.0223  decode.loss_mask: 0.2170  decode.loss_dice: 0.2077  decode.d0.loss_cls: 0.8149  decode.d0.loss_mask: 0.2144  decode.d0.loss_dice: 0.2026  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.2163  decode.d1.loss_dice: 0.1970  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.2155  decode.d2.loss_dice: 0.2043  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.2114  decode.d3.loss_dice: 0.1954  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.2134  decode.d4.loss_dice: 0.2001  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.2097  decode.d5.loss_dice: 0.2057  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.2148  decode.d6.loss_dice: 0.2070  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.2127  decode.d7.loss_dice: 0.2075  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.2139  decode.d8.loss_dice: 0.1833
09/28 20:05:33 - mmengine - INFO - Iter(train) [ 45800/320000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 1 day, 9:41:23  time: 0.4766  data_time: 0.0101  memory: 5132  grad_norm: 40.3975  loss: 4.2647  decode.loss_cls: 0.0055  decode.loss_mask: 0.1748  decode.loss_dice: 0.1710  decode.d0.loss_cls: 0.7650  decode.d0.loss_mask: 0.1796  decode.d0.loss_dice: 0.1744  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.1720  decode.d1.loss_dice: 0.1742  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.1733  decode.d2.loss_dice: 0.1690  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.1727  decode.d3.loss_dice: 0.1745  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.1723  decode.d4.loss_dice: 0.1752  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.1729  decode.d5.loss_dice: 0.1710  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.1752  decode.d6.loss_dice: 0.1699  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.1735  decode.d7.loss_dice: 0.1677  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.1707  decode.d8.loss_dice: 0.1693
09/28 20:05:57 - mmengine - INFO - Iter(train) [ 45850/320000]  base_lr: 8.7007e-05 lr: 8.7007e-06  eta: 1 day, 9:41:10  time: 0.4747  data_time: 0.0094  memory: 5117  grad_norm: 32.1084  loss: 5.2777  decode.loss_cls: 0.0796  decode.loss_mask: 0.2001  decode.loss_dice: 0.2076  decode.d0.loss_cls: 0.8742  decode.d0.loss_mask: 0.1995  decode.d0.loss_dice: 0.2061  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.2006  decode.d1.loss_dice: 0.2058  decode.d2.loss_cls: 0.0274  decode.d2.loss_mask: 0.2051  decode.d2.loss_dice: 0.1970  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.2022  decode.d3.loss_dice: 0.1992  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.2022  decode.d4.loss_dice: 0.1898  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.1989  decode.d5.loss_dice: 0.2039  decode.d6.loss_cls: 0.0385  decode.d6.loss_mask: 0.2003  decode.d6.loss_dice: 0.1963  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.2007  decode.d7.loss_dice: 0.2048  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.1998  decode.d8.loss_dice: 0.1967
09/28 20:06:21 - mmengine - INFO - Iter(train) [ 45900/320000]  base_lr: 8.6993e-05 lr: 8.6993e-06  eta: 1 day, 9:40:56  time: 0.4711  data_time: 0.0093  memory: 5147  grad_norm: 62.3451  loss: 6.2344  decode.loss_cls: 0.0258  decode.loss_mask: 0.3095  decode.loss_dice: 0.1952  decode.d0.loss_cls: 0.9139  decode.d0.loss_mask: 0.3154  decode.d0.loss_dice: 0.2065  decode.d1.loss_cls: 0.0383  decode.d1.loss_mask: 0.3076  decode.d1.loss_dice: 0.1897  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.3093  decode.d2.loss_dice: 0.1910  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.3070  decode.d3.loss_dice: 0.1897  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.3098  decode.d4.loss_dice: 0.1935  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.1959  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.3092  decode.d6.loss_dice: 0.1915  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.1940  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.3058  decode.d8.loss_dice: 0.1915
09/28 20:06:44 - mmengine - INFO - Iter(train) [ 45950/320000]  base_lr: 8.6979e-05 lr: 8.6979e-06  eta: 1 day, 9:40:43  time: 0.4698  data_time: 0.0093  memory: 5147  grad_norm: 38.4712  loss: 5.4455  decode.loss_cls: 0.0193  decode.loss_mask: 0.2375  decode.loss_dice: 0.1932  decode.d0.loss_cls: 0.8443  decode.d0.loss_mask: 0.2385  decode.d0.loss_dice: 0.2144  decode.d1.loss_cls: 0.0460  decode.d1.loss_mask: 0.2396  decode.d1.loss_dice: 0.1987  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.2376  decode.d2.loss_dice: 0.1967  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.2342  decode.d3.loss_dice: 0.1963  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.2355  decode.d4.loss_dice: 0.1962  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.2359  decode.d5.loss_dice: 0.1946  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.2347  decode.d6.loss_dice: 0.1958  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.2324  decode.d7.loss_dice: 0.1962  decode.d8.loss_cls: 0.0232  decode.d8.loss_mask: 0.2357  decode.d8.loss_dice: 0.2040
09/28 20:07:08 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 20:07:08 - mmengine - INFO - Iter(train) [ 46000/320000]  base_lr: 8.6964e-05 lr: 8.6964e-06  eta: 1 day, 9:40:30  time: 0.4760  data_time: 0.0095  memory: 5133  grad_norm: 73.5259  loss: 7.5606  decode.loss_cls: 0.1193  decode.loss_mask: 0.3000  decode.loss_dice: 0.2478  decode.d0.loss_cls: 0.9031  decode.d0.loss_mask: 0.3057  decode.d0.loss_dice: 0.2581  decode.d1.loss_cls: 0.1613  decode.d1.loss_mask: 0.3007  decode.d1.loss_dice: 0.2385  decode.d2.loss_cls: 0.1458  decode.d2.loss_mask: 0.2998  decode.d2.loss_dice: 0.2445  decode.d3.loss_cls: 0.1375  decode.d3.loss_mask: 0.3024  decode.d3.loss_dice: 0.2570  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 0.2993  decode.d4.loss_dice: 0.2391  decode.d5.loss_cls: 0.1080  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.2374  decode.d6.loss_cls: 0.1359  decode.d6.loss_mask: 0.2964  decode.d6.loss_dice: 0.2391  decode.d7.loss_cls: 0.1581  decode.d7.loss_mask: 0.2973  decode.d7.loss_dice: 0.2552  decode.d8.loss_cls: 0.1113  decode.d8.loss_mask: 0.3012  decode.d8.loss_dice: 0.2472
09/28 20:07:31 - mmengine - INFO - Iter(train) [ 46050/320000]  base_lr: 8.6950e-05 lr: 8.6950e-06  eta: 1 day, 9:40:15  time: 0.4415  data_time: 0.0093  memory: 5133  grad_norm: 81.1837  loss: 5.6657  decode.loss_cls: 0.0635  decode.loss_mask: 0.2267  decode.loss_dice: 0.2074  decode.d0.loss_cls: 0.8433  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.2084  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.2276  decode.d1.loss_dice: 0.1964  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.2286  decode.d2.loss_dice: 0.2045  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.2232  decode.d3.loss_dice: 0.1855  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.2257  decode.d4.loss_dice: 0.1942  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 0.2280  decode.d5.loss_dice: 0.1944  decode.d6.loss_cls: 0.1124  decode.d6.loss_mask: 0.2250  decode.d6.loss_dice: 0.1988  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.2224  decode.d7.loss_dice: 0.1923  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.2261  decode.d8.loss_dice: 0.2006
09/28 20:07:53 - mmengine - INFO - Iter(train) [ 46100/320000]  base_lr: 8.6936e-05 lr: 8.6936e-06  eta: 1 day, 9:39:50  time: 0.4363  data_time: 0.0094  memory: 5133  grad_norm: 41.4169  loss: 5.3334  decode.loss_cls: 0.0409  decode.loss_mask: 0.2214  decode.loss_dice: 0.1873  decode.d0.loss_cls: 0.7499  decode.d0.loss_mask: 0.2274  decode.d0.loss_dice: 0.2240  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.2239  decode.d1.loss_dice: 0.1837  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.2250  decode.d2.loss_dice: 0.1813  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.2224  decode.d3.loss_dice: 0.1812  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.2245  decode.d4.loss_dice: 0.2276  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.2214  decode.d5.loss_dice: 0.2270  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.2225  decode.d6.loss_dice: 0.2150  decode.d7.loss_cls: 0.0374  decode.d7.loss_mask: 0.2243  decode.d7.loss_dice: 0.1878  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.2224  decode.d8.loss_dice: 0.1863
09/28 20:08:15 - mmengine - INFO - Iter(train) [ 46150/320000]  base_lr: 8.6922e-05 lr: 8.6922e-06  eta: 1 day, 9:39:26  time: 0.4339  data_time: 0.0096  memory: 5147  grad_norm: 26.8208  loss: 5.6176  decode.loss_cls: 0.0083  decode.loss_mask: 0.2566  decode.loss_dice: 0.2092  decode.d0.loss_cls: 0.8443  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.2121  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.2578  decode.d1.loss_dice: 0.2060  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 0.2598  decode.d2.loss_dice: 0.2033  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.1990  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.2580  decode.d4.loss_dice: 0.2048  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.2552  decode.d5.loss_dice: 0.1992  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.2000  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.2589  decode.d7.loss_dice: 0.1982  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.2585  decode.d8.loss_dice: 0.2003
09/28 20:08:37 - mmengine - INFO - Iter(train) [ 46200/320000]  base_lr: 8.6907e-05 lr: 8.6907e-06  eta: 1 day, 9:39:06  time: 0.4732  data_time: 0.0100  memory: 5133  grad_norm: 51.5016  loss: 7.0807  decode.loss_cls: 0.1791  decode.loss_mask: 0.2310  decode.loss_dice: 0.2297  decode.d0.loss_cls: 0.9977  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.2578  decode.d1.loss_cls: 0.1480  decode.d1.loss_mask: 0.2284  decode.d1.loss_dice: 0.2320  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 0.2309  decode.d2.loss_dice: 0.2382  decode.d3.loss_cls: 0.1185  decode.d3.loss_mask: 0.2318  decode.d3.loss_dice: 0.2446  decode.d4.loss_cls: 0.1498  decode.d4.loss_mask: 0.2329  decode.d4.loss_dice: 0.2366  decode.d5.loss_cls: 0.1535  decode.d5.loss_mask: 0.2331  decode.d5.loss_dice: 0.2374  decode.d6.loss_cls: 0.1466  decode.d6.loss_mask: 0.2358  decode.d6.loss_dice: 0.2411  decode.d7.loss_cls: 0.1743  decode.d7.loss_mask: 0.2311  decode.d7.loss_dice: 0.2433  decode.d8.loss_cls: 0.1703  decode.d8.loss_mask: 0.2293  decode.d8.loss_dice: 0.2337
09/28 20:09:01 - mmengine - INFO - Iter(train) [ 46250/320000]  base_lr: 8.6893e-05 lr: 8.6893e-06  eta: 1 day, 9:38:53  time: 0.4739  data_time: 0.0097  memory: 5147  grad_norm: 61.0076  loss: 7.1347  decode.loss_cls: 0.0888  decode.loss_mask: 0.2718  decode.loss_dice: 0.2450  decode.d0.loss_cls: 1.0951  decode.d0.loss_mask: 0.2797  decode.d0.loss_dice: 0.2571  decode.d1.loss_cls: 0.1030  decode.d1.loss_mask: 0.2723  decode.d1.loss_dice: 0.2618  decode.d2.loss_cls: 0.0968  decode.d2.loss_mask: 0.2706  decode.d2.loss_dice: 0.2520  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.2698  decode.d3.loss_dice: 0.2342  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.2510  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.2743  decode.d5.loss_dice: 0.2555  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.2758  decode.d6.loss_dice: 0.2819  decode.d7.loss_cls: 0.0893  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.2435  decode.d8.loss_cls: 0.0990  decode.d8.loss_mask: 0.2709  decode.d8.loss_dice: 0.2508
09/28 20:09:24 - mmengine - INFO - Iter(train) [ 46300/320000]  base_lr: 8.6879e-05 lr: 8.6879e-06  eta: 1 day, 9:38:40  time: 0.4724  data_time: 0.0097  memory: 5132  grad_norm: 56.0802  loss: 6.7781  decode.loss_cls: 0.1356  decode.loss_mask: 0.2373  decode.loss_dice: 0.2413  decode.d0.loss_cls: 0.9410  decode.d0.loss_mask: 0.2341  decode.d0.loss_dice: 0.2878  decode.d1.loss_cls: 0.1307  decode.d1.loss_mask: 0.2300  decode.d1.loss_dice: 0.2466  decode.d2.loss_cls: 0.1250  decode.d2.loss_mask: 0.2321  decode.d2.loss_dice: 0.2576  decode.d3.loss_cls: 0.0678  decode.d3.loss_mask: 0.2406  decode.d3.loss_dice: 0.2527  decode.d4.loss_cls: 0.1121  decode.d4.loss_mask: 0.2326  decode.d4.loss_dice: 0.2421  decode.d5.loss_cls: 0.1352  decode.d5.loss_mask: 0.2294  decode.d5.loss_dice: 0.2561  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 0.2356  decode.d6.loss_dice: 0.2509  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.2386  decode.d7.loss_dice: 0.2465  decode.d8.loss_cls: 0.0904  decode.d8.loss_mask: 0.2327  decode.d8.loss_dice: 0.2542
09/28 20:09:48 - mmengine - INFO - Iter(train) [ 46350/320000]  base_lr: 8.6864e-05 lr: 8.6864e-06  eta: 1 day, 9:38:26  time: 0.4703  data_time: 0.0095  memory: 5133  grad_norm: 55.0534  loss: 5.2484  decode.loss_cls: 0.0835  decode.loss_mask: 0.1939  decode.loss_dice: 0.1884  decode.d0.loss_cls: 0.9042  decode.d0.loss_mask: 0.1928  decode.d0.loss_dice: 0.1982  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.1906  decode.d1.loss_dice: 0.1900  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.1914  decode.d2.loss_dice: 0.1954  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.1919  decode.d3.loss_dice: 0.1830  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.1898  decode.d4.loss_dice: 0.1946  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.1892  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.1899  decode.d6.loss_dice: 0.1812  decode.d7.loss_cls: 0.0539  decode.d7.loss_mask: 0.1905  decode.d7.loss_dice: 0.1892  decode.d8.loss_cls: 0.0756  decode.d8.loss_mask: 0.1888  decode.d8.loss_dice: 0.1917
09/28 20:10:12 - mmengine - INFO - Iter(train) [ 46400/320000]  base_lr: 8.6850e-05 lr: 8.6850e-06  eta: 1 day, 9:38:13  time: 0.4718  data_time: 0.0094  memory: 5147  grad_norm: 41.8737  loss: 7.4299  decode.loss_cls: 0.1292  decode.loss_mask: 0.2313  decode.loss_dice: 0.2546  decode.d0.loss_cls: 0.9342  decode.d0.loss_mask: 0.2363  decode.d0.loss_dice: 0.2736  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 0.2367  decode.d1.loss_dice: 0.2452  decode.d2.loss_cls: 0.1540  decode.d2.loss_mask: 0.2353  decode.d2.loss_dice: 0.2606  decode.d3.loss_cls: 0.1822  decode.d3.loss_mask: 0.2348  decode.d3.loss_dice: 0.2872  decode.d4.loss_cls: 0.1761  decode.d4.loss_mask: 0.2338  decode.d4.loss_dice: 0.2634  decode.d5.loss_cls: 0.1749  decode.d5.loss_mask: 0.2371  decode.d5.loss_dice: 0.2479  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.2323  decode.d6.loss_dice: 0.2856  decode.d7.loss_cls: 0.1558  decode.d7.loss_mask: 0.2394  decode.d7.loss_dice: 0.2835  decode.d8.loss_cls: 0.1677  decode.d8.loss_mask: 0.2386  decode.d8.loss_dice: 0.2506
09/28 20:10:35 - mmengine - INFO - Iter(train) [ 46450/320000]  base_lr: 8.6836e-05 lr: 8.6836e-06  eta: 1 day, 9:37:59  time: 0.4729  data_time: 0.0098  memory: 5133  grad_norm: 87.7029  loss: 5.7658  decode.loss_cls: 0.0136  decode.loss_mask: 0.2739  decode.loss_dice: 0.2066  decode.d0.loss_cls: 0.7444  decode.d0.loss_mask: 0.2781  decode.d0.loss_dice: 0.2136  decode.d1.loss_cls: 0.0549  decode.d1.loss_mask: 0.2744  decode.d1.loss_dice: 0.2102  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.2706  decode.d2.loss_dice: 0.2082  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.2748  decode.d3.loss_dice: 0.2081  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.2730  decode.d4.loss_dice: 0.2039  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.2747  decode.d5.loss_dice: 0.2053  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.2732  decode.d6.loss_dice: 0.2046  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.2684  decode.d7.loss_dice: 0.2070  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.2754  decode.d8.loss_dice: 0.2084
09/28 20:10:59 - mmengine - INFO - Iter(train) [ 46500/320000]  base_lr: 8.6822e-05 lr: 8.6822e-06  eta: 1 day, 9:37:46  time: 0.4717  data_time: 0.0094  memory: 5147  grad_norm: 37.8716  loss: 5.9073  decode.loss_cls: 0.1020  decode.loss_mask: 0.2216  decode.loss_dice: 0.2012  decode.d0.loss_cls: 0.9048  decode.d0.loss_mask: 0.2156  decode.d0.loss_dice: 0.1986  decode.d1.loss_cls: 0.1044  decode.d1.loss_mask: 0.2126  decode.d1.loss_dice: 0.1885  decode.d2.loss_cls: 0.1172  decode.d2.loss_mask: 0.2156  decode.d2.loss_dice: 0.1837  decode.d3.loss_cls: 0.0953  decode.d3.loss_mask: 0.2174  decode.d3.loss_dice: 0.1916  decode.d4.loss_cls: 0.0835  decode.d4.loss_mask: 0.2202  decode.d4.loss_dice: 0.1977  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.2426  decode.d5.loss_dice: 0.2068  decode.d6.loss_cls: 0.0866  decode.d6.loss_mask: 0.2140  decode.d6.loss_dice: 0.1891  decode.d7.loss_cls: 0.0873  decode.d7.loss_mask: 0.2184  decode.d7.loss_dice: 0.1946  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.2264  decode.d8.loss_dice: 0.1988
09/28 20:11:23 - mmengine - INFO - Iter(train) [ 46550/320000]  base_lr: 8.6807e-05 lr: 8.6807e-06  eta: 1 day, 9:37:32  time: 0.4704  data_time: 0.0094  memory: 5147  grad_norm: 35.3459  loss: 6.4068  decode.loss_cls: 0.0704  decode.loss_mask: 0.2467  decode.loss_dice: 0.2505  decode.d0.loss_cls: 0.9415  decode.d0.loss_mask: 0.2517  decode.d0.loss_dice: 0.2514  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.2474  decode.d1.loss_dice: 0.2551  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.2476  decode.d2.loss_dice: 0.2282  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.2485  decode.d3.loss_dice: 0.2550  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.2445  decode.d4.loss_dice: 0.2549  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.2446  decode.d5.loss_dice: 0.2240  decode.d6.loss_cls: 0.0860  decode.d6.loss_mask: 0.2467  decode.d6.loss_dice: 0.2564  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.2478  decode.d7.loss_dice: 0.2432  decode.d8.loss_cls: 0.0502  decode.d8.loss_mask: 0.2484  decode.d8.loss_dice: 0.2201
09/28 20:11:46 - mmengine - INFO - Iter(train) [ 46600/320000]  base_lr: 8.6793e-05 lr: 8.6793e-06  eta: 1 day, 9:37:19  time: 0.4747  data_time: 0.0096  memory: 5132  grad_norm: 29.8089  loss: 5.5736  decode.loss_cls: 0.0049  decode.loss_mask: 0.2839  decode.loss_dice: 0.1935  decode.d0.loss_cls: 0.7539  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.2036  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.1938  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.1964  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.2789  decode.d3.loss_dice: 0.1960  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2788  decode.d4.loss_dice: 0.1930  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.2823  decode.d5.loss_dice: 0.1945  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.1932  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2810  decode.d7.loss_dice: 0.1924  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.2818  decode.d8.loss_dice: 0.1920
09/28 20:12:10 - mmengine - INFO - Iter(train) [ 46650/320000]  base_lr: 8.6779e-05 lr: 8.6779e-06  eta: 1 day, 9:37:05  time: 0.4727  data_time: 0.0099  memory: 5133  grad_norm: 63.3606  loss: 7.1636  decode.loss_cls: 0.0723  decode.loss_mask: 0.3191  decode.loss_dice: 0.2354  decode.d0.loss_cls: 0.8583  decode.d0.loss_mask: 0.3251  decode.d0.loss_dice: 0.2433  decode.d1.loss_cls: 0.1308  decode.d1.loss_mask: 0.3212  decode.d1.loss_dice: 0.2160  decode.d2.loss_cls: 0.0917  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.2447  decode.d3.loss_cls: 0.0959  decode.d3.loss_mask: 0.3197  decode.d3.loss_dice: 0.2135  decode.d4.loss_cls: 0.0954  decode.d4.loss_mask: 0.3201  decode.d4.loss_dice: 0.2108  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.3193  decode.d5.loss_dice: 0.2069  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.3203  decode.d6.loss_dice: 0.2525  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.3187  decode.d7.loss_dice: 0.2140  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.3173  decode.d8.loss_dice: 0.2447
09/28 20:12:33 - mmengine - INFO - Iter(train) [ 46700/320000]  base_lr: 8.6764e-05 lr: 8.6764e-06  eta: 1 day, 9:36:52  time: 0.4717  data_time: 0.0096  memory: 5133  grad_norm: 41.9269  loss: 6.4410  decode.loss_cls: 0.1256  decode.loss_mask: 0.1922  decode.loss_dice: 0.2794  decode.d0.loss_cls: 0.7979  decode.d0.loss_mask: 0.1951  decode.d0.loss_dice: 0.2853  decode.d1.loss_cls: 0.1130  decode.d1.loss_mask: 0.1929  decode.d1.loss_dice: 0.2730  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.1925  decode.d2.loss_dice: 0.2768  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.1897  decode.d3.loss_dice: 0.2728  decode.d4.loss_cls: 0.0957  decode.d4.loss_mask: 0.1915  decode.d4.loss_dice: 0.2694  decode.d5.loss_cls: 0.1174  decode.d5.loss_mask: 0.1920  decode.d5.loss_dice: 0.2709  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 0.1905  decode.d6.loss_dice: 0.2718  decode.d7.loss_cls: 0.1068  decode.d7.loss_mask: 0.1914  decode.d7.loss_dice: 0.2762  decode.d8.loss_cls: 0.1233  decode.d8.loss_mask: 0.1893  decode.d8.loss_dice: 0.2609
09/28 20:12:57 - mmengine - INFO - Iter(train) [ 46750/320000]  base_lr: 8.6750e-05 lr: 8.6750e-06  eta: 1 day, 9:36:38  time: 0.4698  data_time: 0.0095  memory: 5117  grad_norm: 92.6049  loss: 6.2314  decode.loss_cls: 0.0562  decode.loss_mask: 0.2929  decode.loss_dice: 0.2003  decode.d0.loss_cls: 0.8910  decode.d0.loss_mask: 0.2964  decode.d0.loss_dice: 0.1982  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.2927  decode.d1.loss_dice: 0.1853  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.2921  decode.d2.loss_dice: 0.1921  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.1865  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.2940  decode.d4.loss_dice: 0.1887  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.1879  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.2931  decode.d6.loss_dice: 0.1933  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.2933  decode.d7.loss_dice: 0.1934  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.2912  decode.d8.loss_dice: 0.1941
09/28 20:13:21 - mmengine - INFO - Iter(train) [ 46800/320000]  base_lr: 8.6736e-05 lr: 8.6736e-06  eta: 1 day, 9:36:25  time: 0.4733  data_time: 0.0098  memory: 5132  grad_norm: 23.2970  loss: 5.6300  decode.loss_cls: 0.0234  decode.loss_mask: 0.2529  decode.loss_dice: 0.2065  decode.d0.loss_cls: 0.7687  decode.d0.loss_mask: 0.2568  decode.d0.loss_dice: 0.2038  decode.d1.loss_cls: 0.0340  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.1958  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.2593  decode.d2.loss_dice: 0.1946  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.2589  decode.d3.loss_dice: 0.1893  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.2079  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.2564  decode.d5.loss_dice: 0.1915  decode.d6.loss_cls: 0.0347  decode.d6.loss_mask: 0.2560  decode.d6.loss_dice: 0.2039  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.2565  decode.d7.loss_dice: 0.1938  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.2549  decode.d8.loss_dice: 0.2173
09/28 20:13:44 - mmengine - INFO - Iter(train) [ 46850/320000]  base_lr: 8.6722e-05 lr: 8.6722e-06  eta: 1 day, 9:36:11  time: 0.4712  data_time: 0.0096  memory: 5117  grad_norm: 51.4443  loss: 5.9100  decode.loss_cls: 0.0132  decode.loss_mask: 0.2860  decode.loss_dice: 0.2096  decode.d0.loss_cls: 0.7195  decode.d0.loss_mask: 0.2997  decode.d0.loss_dice: 0.2169  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.2874  decode.d1.loss_dice: 0.2151  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.2888  decode.d2.loss_dice: 0.2146  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 0.2866  decode.d3.loss_dice: 0.2106  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.2904  decode.d4.loss_dice: 0.2162  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.2044  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2863  decode.d6.loss_dice: 0.2194  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.2888  decode.d7.loss_dice: 0.2173  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.2137
09/28 20:14:08 - mmengine - INFO - Iter(train) [ 46900/320000]  base_lr: 8.6707e-05 lr: 8.6707e-06  eta: 1 day, 9:35:57  time: 0.4734  data_time: 0.0094  memory: 5132  grad_norm: 132.4616  loss: 7.7515  decode.loss_cls: 0.1803  decode.loss_mask: 0.2322  decode.loss_dice: 0.2534  decode.d0.loss_cls: 0.7805  decode.d0.loss_mask: 0.2197  decode.d0.loss_dice: 0.2453  decode.d1.loss_cls: 0.3069  decode.d1.loss_mask: 0.2287  decode.d1.loss_dice: 0.2477  decode.d2.loss_cls: 0.2480  decode.d2.loss_mask: 0.2175  decode.d2.loss_dice: 0.2503  decode.d3.loss_cls: 0.2456  decode.d3.loss_mask: 0.2203  decode.d3.loss_dice: 0.2549  decode.d4.loss_cls: 0.2306  decode.d4.loss_mask: 0.2552  decode.d4.loss_dice: 0.2567  decode.d5.loss_cls: 0.1904  decode.d5.loss_mask: 0.2456  decode.d5.loss_dice: 0.2706  decode.d6.loss_cls: 0.2306  decode.d6.loss_mask: 0.2428  decode.d6.loss_dice: 0.2502  decode.d7.loss_cls: 0.2839  decode.d7.loss_mask: 0.2268  decode.d7.loss_dice: 0.2562  decode.d8.loss_cls: 0.1744  decode.d8.loss_mask: 0.2486  decode.d8.loss_dice: 0.2576
09/28 20:14:31 - mmengine - INFO - Iter(train) [ 46950/320000]  base_lr: 8.6693e-05 lr: 8.6693e-06  eta: 1 day, 9:35:44  time: 0.4722  data_time: 0.0094  memory: 5133  grad_norm: 67.2013  loss: 7.0035  decode.loss_cls: 0.1077  decode.loss_mask: 0.2591  decode.loss_dice: 0.2575  decode.d0.loss_cls: 0.9912  decode.d0.loss_mask: 0.2705  decode.d0.loss_dice: 0.2661  decode.d1.loss_cls: 0.1673  decode.d1.loss_mask: 0.2589  decode.d1.loss_dice: 0.2522  decode.d2.loss_cls: 0.1130  decode.d2.loss_mask: 0.2581  decode.d2.loss_dice: 0.2659  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.2652  decode.d3.loss_dice: 0.2525  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.2587  decode.d4.loss_dice: 0.2483  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.2624  decode.d5.loss_dice: 0.2596  decode.d6.loss_cls: 0.0673  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.2510  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.2645  decode.d7.loss_dice: 0.2551  decode.d8.loss_cls: 0.1110  decode.d8.loss_mask: 0.2602  decode.d8.loss_dice: 0.2563
09/28 20:14:55 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 20:14:55 - mmengine - INFO - Iter(train) [ 47000/320000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 1 day, 9:35:30  time: 0.4725  data_time: 0.0096  memory: 5117  grad_norm: 178.5953  loss: 8.2153  decode.loss_cls: 0.1412  decode.loss_mask: 0.3346  decode.loss_dice: 0.2858  decode.d0.loss_cls: 1.0558  decode.d0.loss_mask: 0.2760  decode.d0.loss_dice: 0.2391  decode.d1.loss_cls: 0.2001  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.2515  decode.d2.loss_cls: 0.2031  decode.d2.loss_mask: 0.2895  decode.d2.loss_dice: 0.2454  decode.d3.loss_cls: 0.2002  decode.d3.loss_mask: 0.3024  decode.d3.loss_dice: 0.2607  decode.d4.loss_cls: 0.2523  decode.d4.loss_mask: 0.2923  decode.d4.loss_dice: 0.2592  decode.d5.loss_cls: 0.1538  decode.d5.loss_mask: 0.2900  decode.d5.loss_dice: 0.2450  decode.d6.loss_cls: 0.1593  decode.d6.loss_mask: 0.2974  decode.d6.loss_dice: 0.2597  decode.d7.loss_cls: 0.1550  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.2614  decode.d8.loss_cls: 0.1295  decode.d8.loss_mask: 0.3154  decode.d8.loss_dice: 0.2819
09/28 20:15:19 - mmengine - INFO - Iter(train) [ 47050/320000]  base_lr: 8.6664e-05 lr: 8.6664e-06  eta: 1 day, 9:35:17  time: 0.4741  data_time: 0.0095  memory: 5147  grad_norm: 29.2236  loss: 5.4353  decode.loss_cls: 0.0913  decode.loss_mask: 0.1715  decode.loss_dice: 0.1820  decode.d0.loss_cls: 1.0226  decode.d0.loss_mask: 0.1710  decode.d0.loss_dice: 0.1701  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.1715  decode.d1.loss_dice: 0.1764  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.1710  decode.d2.loss_dice: 0.1744  decode.d3.loss_cls: 0.0949  decode.d3.loss_mask: 0.1732  decode.d3.loss_dice: 0.1842  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.1709  decode.d4.loss_dice: 0.1805  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.1782  decode.d5.loss_dice: 0.1861  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.1763  decode.d6.loss_dice: 0.1809  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.1723  decode.d7.loss_dice: 0.1796  decode.d8.loss_cls: 0.1026  decode.d8.loss_mask: 0.1742  decode.d8.loss_dice: 0.1906
09/28 20:15:42 - mmengine - INFO - Iter(train) [ 47100/320000]  base_lr: 8.6650e-05 lr: 8.6650e-06  eta: 1 day, 9:35:03  time: 0.4718  data_time: 0.0095  memory: 5133  grad_norm: 22.7992  loss: 4.9414  decode.loss_cls: 0.0409  decode.loss_mask: 0.1746  decode.loss_dice: 0.1792  decode.d0.loss_cls: 0.8602  decode.d0.loss_mask: 0.1755  decode.d0.loss_dice: 0.2045  decode.d1.loss_cls: 0.0465  decode.d1.loss_mask: 0.1754  decode.d1.loss_dice: 0.1967  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.1763  decode.d2.loss_dice: 0.2044  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.1780  decode.d3.loss_dice: 0.1849  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.1755  decode.d4.loss_dice: 0.1814  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.1766  decode.d5.loss_dice: 0.1840  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.1767  decode.d6.loss_dice: 0.2095  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.1755  decode.d7.loss_dice: 0.1767  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.1782  decode.d8.loss_dice: 0.2165
09/28 20:16:06 - mmengine - INFO - Iter(train) [ 47150/320000]  base_lr: 8.6636e-05 lr: 8.6636e-06  eta: 1 day, 9:34:49  time: 0.4733  data_time: 0.0094  memory: 5133  grad_norm: 89.5333  loss: 6.3385  decode.loss_cls: 0.1142  decode.loss_mask: 0.2546  decode.loss_dice: 0.2170  decode.d0.loss_cls: 0.7794  decode.d0.loss_mask: 0.2576  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 0.2525  decode.d1.loss_dice: 0.2293  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.2557  decode.d2.loss_dice: 0.2213  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.2200  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2242  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.2505  decode.d5.loss_dice: 0.2241  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.2491  decode.d6.loss_dice: 0.2242  decode.d7.loss_cls: 0.0828  decode.d7.loss_mask: 0.2511  decode.d7.loss_dice: 0.2218  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.2138
09/28 20:16:30 - mmengine - INFO - Iter(train) [ 47200/320000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 1 day, 9:34:36  time: 0.4920  data_time: 0.0096  memory: 5133  grad_norm: 45.8504  loss: 5.9750  decode.loss_cls: 0.0758  decode.loss_mask: 0.2372  decode.loss_dice: 0.1888  decode.d0.loss_cls: 0.7630  decode.d0.loss_mask: 0.2424  decode.d0.loss_dice: 0.1881  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.2324  decode.d1.loss_dice: 0.1899  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.3471  decode.d2.loss_dice: 0.2011  decode.d3.loss_cls: 0.0907  decode.d3.loss_mask: 0.2490  decode.d3.loss_dice: 0.2052  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.2506  decode.d4.loss_dice: 0.1966  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 0.2340  decode.d5.loss_dice: 0.1888  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.2316  decode.d6.loss_dice: 0.1875  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.2356  decode.d7.loss_dice: 0.1893  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.3458  decode.d8.loss_dice: 0.2018
09/28 20:16:53 - mmengine - INFO - Iter(train) [ 47250/320000]  base_lr: 8.6607e-05 lr: 8.6607e-06  eta: 1 day, 9:34:23  time: 0.4726  data_time: 0.0099  memory: 5133  grad_norm: 55.6700  loss: 5.5785  decode.loss_cls: 0.0322  decode.loss_mask: 0.2600  decode.loss_dice: 0.1857  decode.d0.loss_cls: 0.7443  decode.d0.loss_mask: 0.2659  decode.d0.loss_dice: 0.1794  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.2631  decode.d1.loss_dice: 0.1844  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.1833  decode.d3.loss_cls: 0.0392  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.1886  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.2661  decode.d4.loss_dice: 0.1866  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.2634  decode.d5.loss_dice: 0.1855  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.2603  decode.d6.loss_dice: 0.1848  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.2620  decode.d7.loss_dice: 0.1837  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.2637  decode.d8.loss_dice: 0.1892
09/28 20:17:17 - mmengine - INFO - Iter(train) [ 47300/320000]  base_lr: 8.6593e-05 lr: 8.6593e-06  eta: 1 day, 9:34:09  time: 0.4730  data_time: 0.0098  memory: 5147  grad_norm: 100.8441  loss: 6.6898  decode.loss_cls: 0.2098  decode.loss_mask: 0.2382  decode.loss_dice: 0.1832  decode.d0.loss_cls: 0.9509  decode.d0.loss_mask: 0.2287  decode.d0.loss_dice: 0.1743  decode.d1.loss_cls: 0.1754  decode.d1.loss_mask: 0.2275  decode.d1.loss_dice: 0.1859  decode.d2.loss_cls: 0.1650  decode.d2.loss_mask: 0.2314  decode.d2.loss_dice: 0.1802  decode.d3.loss_cls: 0.1793  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.1826  decode.d4.loss_cls: 0.1548  decode.d4.loss_mask: 0.2360  decode.d4.loss_dice: 0.1858  decode.d5.loss_cls: 0.1611  decode.d5.loss_mask: 0.2370  decode.d5.loss_dice: 0.1902  decode.d6.loss_cls: 0.1450  decode.d6.loss_mask: 0.2421  decode.d6.loss_dice: 0.1872  decode.d7.loss_cls: 0.1856  decode.d7.loss_mask: 0.2343  decode.d7.loss_dice: 0.1788  decode.d8.loss_cls: 0.1888  decode.d8.loss_mask: 0.2361  decode.d8.loss_dice: 0.1821
09/28 20:17:41 - mmengine - INFO - Iter(train) [ 47350/320000]  base_lr: 8.6579e-05 lr: 8.6579e-06  eta: 1 day, 9:33:55  time: 0.4698  data_time: 0.0093  memory: 5147  grad_norm: 36.2619  loss: 5.4315  decode.loss_cls: 0.0449  decode.loss_mask: 0.2428  decode.loss_dice: 0.2035  decode.d0.loss_cls: 0.7878  decode.d0.loss_mask: 0.2495  decode.d0.loss_dice: 0.2110  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.2425  decode.d1.loss_dice: 0.1983  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.2420  decode.d2.loss_dice: 0.1836  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.2432  decode.d3.loss_dice: 0.1876  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.2406  decode.d4.loss_dice: 0.1927  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.2429  decode.d5.loss_dice: 0.1939  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.2442  decode.d6.loss_dice: 0.1898  decode.d7.loss_cls: 0.0278  decode.d7.loss_mask: 0.2439  decode.d7.loss_dice: 0.1924  decode.d8.loss_cls: 0.0238  decode.d8.loss_mask: 0.2452  decode.d8.loss_dice: 0.1884
09/28 20:18:04 - mmengine - INFO - Iter(train) [ 47400/320000]  base_lr: 8.6564e-05 lr: 8.6564e-06  eta: 1 day, 9:33:41  time: 0.4729  data_time: 0.0096  memory: 5132  grad_norm: 66.1515  loss: 5.6215  decode.loss_cls: 0.1190  decode.loss_mask: 0.2024  decode.loss_dice: 0.1651  decode.d0.loss_cls: 0.8954  decode.d0.loss_mask: 0.2119  decode.d0.loss_dice: 0.1666  decode.d1.loss_cls: 0.1644  decode.d1.loss_mask: 0.2004  decode.d1.loss_dice: 0.1628  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.2035  decode.d2.loss_dice: 0.1572  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.2028  decode.d3.loss_dice: 0.1575  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.2013  decode.d4.loss_dice: 0.1586  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 0.2049  decode.d5.loss_dice: 0.1554  decode.d6.loss_cls: 0.0956  decode.d6.loss_mask: 0.2055  decode.d6.loss_dice: 0.1599  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.2048  decode.d7.loss_dice: 0.1550  decode.d8.loss_cls: 0.1271  decode.d8.loss_mask: 0.2014  decode.d8.loss_dice: 0.1555
09/28 20:18:28 - mmengine - INFO - Iter(train) [ 47450/320000]  base_lr: 8.6550e-05 lr: 8.6550e-06  eta: 1 day, 9:33:27  time: 0.4738  data_time: 0.0098  memory: 5117  grad_norm: 43.7098  loss: 7.8281  decode.loss_cls: 0.2423  decode.loss_mask: 0.2049  decode.loss_dice: 0.2635  decode.d0.loss_cls: 0.9738  decode.d0.loss_mask: 0.2107  decode.d0.loss_dice: 0.2772  decode.d1.loss_cls: 0.2453  decode.d1.loss_mask: 0.2040  decode.d1.loss_dice: 0.2596  decode.d2.loss_cls: 0.2267  decode.d2.loss_mask: 0.2040  decode.d2.loss_dice: 0.2337  decode.d3.loss_cls: 0.2479  decode.d3.loss_mask: 0.2048  decode.d3.loss_dice: 0.2479  decode.d4.loss_cls: 0.2430  decode.d4.loss_mask: 0.2054  decode.d4.loss_dice: 0.2595  decode.d5.loss_cls: 0.2572  decode.d5.loss_mask: 0.2098  decode.d5.loss_dice: 0.2662  decode.d6.loss_cls: 0.2517  decode.d6.loss_mask: 0.2059  decode.d6.loss_dice: 0.2572  decode.d7.loss_cls: 0.2531  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.2585  decode.d8.loss_cls: 0.2342  decode.d8.loss_mask: 0.2074  decode.d8.loss_dice: 0.2619
09/28 20:18:51 - mmengine - INFO - Iter(train) [ 47500/320000]  base_lr: 8.6536e-05 lr: 8.6536e-06  eta: 1 day, 9:33:14  time: 0.4704  data_time: 0.0092  memory: 5133  grad_norm: 21.9782  loss: 4.2581  decode.loss_cls: 0.0118  decode.loss_mask: 0.1765  decode.loss_dice: 0.1498  decode.d0.loss_cls: 0.8902  decode.d0.loss_mask: 0.1802  decode.d0.loss_dice: 0.1479  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.1793  decode.d1.loss_dice: 0.1486  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.1793  decode.d2.loss_dice: 0.1411  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.1771  decode.d3.loss_dice: 0.1487  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.1748  decode.d4.loss_dice: 0.1450  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.1798  decode.d5.loss_dice: 0.1517  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.1789  decode.d6.loss_dice: 0.1480  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.1789  decode.d7.loss_dice: 0.1458  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.1784  decode.d8.loss_dice: 0.1477
09/28 20:19:15 - mmengine - INFO - Iter(train) [ 47550/320000]  base_lr: 8.6522e-05 lr: 8.6522e-06  eta: 1 day, 9:33:00  time: 0.4722  data_time: 0.0095  memory: 5117  grad_norm: 25.7553  loss: 6.3806  decode.loss_cls: 0.1327  decode.loss_mask: 0.1961  decode.loss_dice: 0.2143  decode.d0.loss_cls: 0.8486  decode.d0.loss_mask: 0.2040  decode.d0.loss_dice: 0.2410  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 0.2030  decode.d1.loss_dice: 0.2287  decode.d2.loss_cls: 0.1840  decode.d2.loss_mask: 0.2067  decode.d2.loss_dice: 0.1903  decode.d3.loss_cls: 0.1385  decode.d3.loss_mask: 0.2103  decode.d3.loss_dice: 0.2484  decode.d4.loss_cls: 0.1278  decode.d4.loss_mask: 0.1974  decode.d4.loss_dice: 0.2309  decode.d5.loss_cls: 0.1314  decode.d5.loss_mask: 0.1992  decode.d5.loss_dice: 0.2368  decode.d6.loss_cls: 0.1194  decode.d6.loss_mask: 0.1983  decode.d6.loss_dice: 0.2058  decode.d7.loss_cls: 0.1402  decode.d7.loss_mask: 0.1980  decode.d7.loss_dice: 0.2275  decode.d8.loss_cls: 0.1248  decode.d8.loss_mask: 0.1945  decode.d8.loss_dice: 0.2147
09/28 20:19:39 - mmengine - INFO - Iter(train) [ 47600/320000]  base_lr: 8.6507e-05 lr: 8.6507e-06  eta: 1 day, 9:32:46  time: 0.4723  data_time: 0.0097  memory: 5133  grad_norm: 39.5443  loss: 7.4068  decode.loss_cls: 0.0428  decode.loss_mask: 0.3730  decode.loss_dice: 0.2348  decode.d0.loss_cls: 0.9157  decode.d0.loss_mask: 0.3885  decode.d0.loss_dice: 0.2539  decode.d1.loss_cls: 0.0982  decode.d1.loss_mask: 0.3800  decode.d1.loss_dice: 0.2315  decode.d2.loss_cls: 0.0312  decode.d2.loss_mask: 0.3704  decode.d2.loss_dice: 0.2450  decode.d3.loss_cls: 0.0262  decode.d3.loss_mask: 0.3737  decode.d3.loss_dice: 0.2451  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.3720  decode.d4.loss_dice: 0.2347  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.3710  decode.d5.loss_dice: 0.2402  decode.d6.loss_cls: 0.0324  decode.d6.loss_mask: 0.3701  decode.d6.loss_dice: 0.2310  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.3766  decode.d7.loss_dice: 0.2252  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.3632  decode.d8.loss_dice: 0.2297
09/28 20:20:02 - mmengine - INFO - Iter(train) [ 47650/320000]  base_lr: 8.6493e-05 lr: 8.6493e-06  eta: 1 day, 9:32:32  time: 0.4729  data_time: 0.0095  memory: 5147  grad_norm: 60.8814  loss: 5.9354  decode.loss_cls: 0.0706  decode.loss_mask: 0.2117  decode.loss_dice: 0.2116  decode.d0.loss_cls: 1.0013  decode.d0.loss_mask: 0.2186  decode.d0.loss_dice: 0.2321  decode.d1.loss_cls: 0.1539  decode.d1.loss_mask: 0.2110  decode.d1.loss_dice: 0.2072  decode.d2.loss_cls: 0.1183  decode.d2.loss_mask: 0.2099  decode.d2.loss_dice: 0.2043  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.2089  decode.d3.loss_dice: 0.2003  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.2119  decode.d4.loss_dice: 0.1992  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.2108  decode.d5.loss_dice: 0.2013  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.2102  decode.d6.loss_dice: 0.2053  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.2107  decode.d7.loss_dice: 0.2019  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.2126  decode.d8.loss_dice: 0.2084
09/28 20:20:26 - mmengine - INFO - Iter(train) [ 47700/320000]  base_lr: 8.6479e-05 lr: 8.6479e-06  eta: 1 day, 9:32:19  time: 0.4747  data_time: 0.0099  memory: 5133  grad_norm: 42.3906  loss: 6.6565  decode.loss_cls: 0.0859  decode.loss_mask: 0.3167  decode.loss_dice: 0.2666  decode.d0.loss_cls: 0.9662  decode.d0.loss_mask: 0.2192  decode.d0.loss_dice: 0.2145  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.2148  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.2134  decode.d2.loss_dice: 0.2052  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.2170  decode.d3.loss_dice: 0.2123  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.2498  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.3009  decode.d5.loss_dice: 0.2597  decode.d6.loss_cls: 0.0793  decode.d6.loss_mask: 0.2572  decode.d6.loss_dice: 0.2658  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 0.4479  decode.d7.loss_dice: 0.2536  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 0.2986  decode.d8.loss_dice: 0.2668
09/28 20:20:50 - mmengine - INFO - Iter(train) [ 47750/320000]  base_lr: 8.6464e-05 lr: 8.6464e-06  eta: 1 day, 9:32:05  time: 0.4744  data_time: 0.0097  memory: 5133  grad_norm: 101.1663  loss: 8.6760  decode.loss_cls: 0.2227  decode.loss_mask: 0.3396  decode.loss_dice: 0.2805  decode.d0.loss_cls: 0.9162  decode.d0.loss_mask: 0.2955  decode.d0.loss_dice: 0.2898  decode.d1.loss_cls: 0.1806  decode.d1.loss_mask: 0.2825  decode.d1.loss_dice: 0.2569  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.3371  decode.d2.loss_dice: 0.2529  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 0.3391  decode.d3.loss_dice: 0.2783  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 0.3436  decode.d4.loss_dice: 0.2764  decode.d5.loss_cls: 0.1973  decode.d5.loss_mask: 0.3311  decode.d5.loss_dice: 0.2629  decode.d6.loss_cls: 0.2585  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.2738  decode.d7.loss_cls: 0.2387  decode.d7.loss_mask: 0.3155  decode.d7.loss_dice: 0.2832  decode.d8.loss_cls: 0.2742  decode.d8.loss_mask: 0.3203  decode.d8.loss_dice: 0.2955
09/28 20:21:13 - mmengine - INFO - Iter(train) [ 47800/320000]  base_lr: 8.6450e-05 lr: 8.6450e-06  eta: 1 day, 9:31:51  time: 0.4718  data_time: 0.0094  memory: 5147  grad_norm: 80.6166  loss: 6.4613  decode.loss_cls: 0.1354  decode.loss_mask: 0.2340  decode.loss_dice: 0.2205  decode.d0.loss_cls: 0.8664  decode.d0.loss_mask: 0.2462  decode.d0.loss_dice: 0.2487  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.2413  decode.d1.loss_dice: 0.2245  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.2403  decode.d2.loss_dice: 0.2370  decode.d3.loss_cls: 0.0894  decode.d3.loss_mask: 0.2326  decode.d3.loss_dice: 0.2309  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.2353  decode.d4.loss_dice: 0.2128  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.2321  decode.d5.loss_dice: 0.2115  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 0.2332  decode.d6.loss_dice: 0.2261  decode.d7.loss_cls: 0.0977  decode.d7.loss_mask: 0.2318  decode.d7.loss_dice: 0.2196  decode.d8.loss_cls: 0.1294  decode.d8.loss_mask: 0.2351  decode.d8.loss_dice: 0.2257
09/28 20:21:37 - mmengine - INFO - Iter(train) [ 47850/320000]  base_lr: 8.6436e-05 lr: 8.6436e-06  eta: 1 day, 9:31:37  time: 0.4735  data_time: 0.0100  memory: 5117  grad_norm: 48.3673  loss: 6.5889  decode.loss_cls: 0.1620  decode.loss_mask: 0.2269  decode.loss_dice: 0.2203  decode.d0.loss_cls: 0.8986  decode.d0.loss_mask: 0.2254  decode.d0.loss_dice: 0.2434  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 0.2295  decode.d1.loss_dice: 0.2450  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.2312  decode.d2.loss_dice: 0.2166  decode.d3.loss_cls: 0.0904  decode.d3.loss_mask: 0.2305  decode.d3.loss_dice: 0.2310  decode.d4.loss_cls: 0.0825  decode.d4.loss_mask: 0.2285  decode.d4.loss_dice: 0.2453  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.2260  decode.d5.loss_dice: 0.2403  decode.d6.loss_cls: 0.1390  decode.d6.loss_mask: 0.2274  decode.d6.loss_dice: 0.2393  decode.d7.loss_cls: 0.1109  decode.d7.loss_mask: 0.2245  decode.d7.loss_dice: 0.2263  decode.d8.loss_cls: 0.1316  decode.d8.loss_mask: 0.2296  decode.d8.loss_dice: 0.2315
09/28 20:22:01 - mmengine - INFO - Iter(train) [ 47900/320000]  base_lr: 8.6422e-05 lr: 8.6422e-06  eta: 1 day, 9:31:24  time: 0.4709  data_time: 0.0095  memory: 5133  grad_norm: 63.2139  loss: 7.0775  decode.loss_cls: 0.1565  decode.loss_mask: 0.2452  decode.loss_dice: 0.2360  decode.d0.loss_cls: 0.9393  decode.d0.loss_mask: 0.2441  decode.d0.loss_dice: 0.2701  decode.d1.loss_cls: 0.1740  decode.d1.loss_mask: 0.2345  decode.d1.loss_dice: 0.2395  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 0.2339  decode.d2.loss_dice: 0.2356  decode.d3.loss_cls: 0.1484  decode.d3.loss_mask: 0.2444  decode.d3.loss_dice: 0.2382  decode.d4.loss_cls: 0.1425  decode.d4.loss_mask: 0.2445  decode.d4.loss_dice: 0.2433  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 0.2348  decode.d5.loss_dice: 0.2444  decode.d6.loss_cls: 0.1622  decode.d6.loss_mask: 0.2355  decode.d6.loss_dice: 0.2332  decode.d7.loss_cls: 0.1234  decode.d7.loss_mask: 0.2361  decode.d7.loss_dice: 0.2368  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.2368  decode.d8.loss_dice: 0.2458
09/28 20:22:24 - mmengine - INFO - Iter(train) [ 47950/320000]  base_lr: 8.6407e-05 lr: 8.6407e-06  eta: 1 day, 9:31:10  time: 0.4728  data_time: 0.0095  memory: 5147  grad_norm: 72.4590  loss: 5.6313  decode.loss_cls: 0.0715  decode.loss_mask: 0.1789  decode.loss_dice: 0.1959  decode.d0.loss_cls: 0.9449  decode.d0.loss_mask: 0.1799  decode.d0.loss_dice: 0.2042  decode.d1.loss_cls: 0.0815  decode.d1.loss_mask: 0.1814  decode.d1.loss_dice: 0.1933  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.1841  decode.d2.loss_dice: 0.1947  decode.d3.loss_cls: 0.1506  decode.d3.loss_mask: 0.1778  decode.d3.loss_dice: 0.1859  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.1807  decode.d4.loss_dice: 0.2153  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.1812  decode.d5.loss_dice: 0.2320  decode.d6.loss_cls: 0.1491  decode.d6.loss_mask: 0.1811  decode.d6.loss_dice: 0.1860  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.1814  decode.d7.loss_dice: 0.2239  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.1831  decode.d8.loss_dice: 0.2112
09/28 20:22:48 - mmengine - INFO - Exp name: mask2former_r50_8xb2-80k_MYDATA-512x1024_20250928_142701
09/28 20:22:48 - mmengine - INFO - Iter(train) [ 48000/320000]  base_lr: 8.6393e-05 lr: 8.6393e-06  eta: 1 day, 9:30:56  time: 0.4722  data_time: 0.0095  memory: 5133  grad_norm: 23.7022  loss: 6.1930  decode.loss_cls: 0.0864  decode.loss_mask: 0.1976  decode.loss_dice: 0.2318  decode.d0.loss_cls: 0.8939  decode.d0.loss_mask: 0.1973  decode.d0.loss_dice: 0.2274  decode.d1.loss_cls: 0.1505  decode.d1.loss_mask: 0.1968  decode.d1.loss_dice: 0.2383  decode.d2.loss_cls: 0.1301  decode.d2.loss_mask: 0.1965  decode.d2.loss_dice: 0.2173  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.1987  decode.d3.loss_dice: 0.2260  decode.d4.loss_cls: 0.1490  decode.d4.loss_mask: 0.1998  decode.d4.loss_dice: 0.2169  decode.d5.loss_cls: 0.1178  decode.d5.loss_mask: 0.1940  decode.d5.loss_dice: 0.2178  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.1972  decode.d6.loss_dice: 0.2291  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.1998  decode.d7.loss_dice: 0.2232  decode.d8.loss_cls: 0.0990  decode.d8.loss_mask: 0.1970  decode.d8.loss_dice: 0.2160
09/28 20:23:12 - mmengine - INFO - Iter(train) [ 48050/320000]  base_lr: 8.6379e-05 lr: 8.6379e-06  eta: 1 day, 9:30:43  time: 0.4736  data_time: 0.0100  memory: 5147  grad_norm: 254.6380  loss: 5.4972  decode.loss_cls: 0.0364  decode.loss_mask: 0.2345  decode.loss_dice: 0.2082  decode.d0.loss_cls: 0.7151  decode.d0.loss_mask: 0.2357  decode.d0.loss_dice: 0.2097  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.2343  decode.d1.loss_dice: 0.2083  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.2347  decode.d2.loss_dice: 0.2017  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.2369  decode.d3.loss_dice: 0.1978  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.2365  decode.d4.loss_dice: 0.2077  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.2402  decode.d5.loss_dice: 0.2057  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.2373  decode.d6.loss_dice: 0.2051  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.2373  decode.d7.loss_dice: 0.2061  decode.d8.loss_cls: 0.0279  decode.d8.loss_mask: 0.2353  decode.d8.loss_dice: 0.2138
09/28 20:23:35 - mmengine - INFO - Iter(train) [ 48100/320000]  base_lr: 8.6364e-05 lr: 8.6364e-06  eta: 1 day, 9:30:29  time: 0.4721  data_time: 0.0094  memory: 5133  grad_norm: 121.0558  loss: 6.9718  decode.loss_cls: 0.2277  decode.loss_mask: 0.2024  decode.loss_dice: 0.2184  decode.d0.loss_cls: 0.8521  decode.d0.loss_mask: 0.2156  decode.d0.loss_dice: 0.2203  decode.d1.loss_cls: 0.2058  decode.d1.loss_mask: 0.2036  decode.d1.loss_dice: 0.2452  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 0.2043  decode.d2.loss_dice: 0.2438  decode.d3.loss_cls: 0.1838  decode.d3.loss_mask: 0.2021  decode.d3.loss_dice: 0.2437  decode.d4.loss_cls: 0.1732  decode.d4.loss_mask: 0.2051  decode.d4.loss_dice: 0.2310  decode.d5.loss_cls: 0.1758  decode.d5.loss_mask: 0.2058  decode.d5.loss_dice: 0.2379  decode.d6.loss_cls: 0.1649  decode.d6.loss_mask: 0.2029  decode.d6.loss_dice: 0.2583  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 0.2037  decode.d7.loss_dice: 0.2565  decode.d8.loss_cls: 0.2166  decode.d8.loss_mask: 0.2045  decode.d8.loss_dice: 0.2362
09/28 20:23:59 - mmengine - INFO - Iter(train) [ 48150/320000]  base_lr: 8.6350e-05 lr: 8.6350e-06  eta: 1 day, 9:30:15  time: 0.4741  data_time: 0.0098  memory: 5147  grad_norm: 46.0296  loss: 7.0402  decode.loss_cls: 0.0926  decode.loss_mask: 0.2850  decode.loss_dice: 0.2626  decode.d0.loss_cls: 0.8388  decode.d0.loss_mask: 0.2934  decode.d0.loss_dice: 0.2995  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.2835  decode.d1.loss_dice: 0.2728  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.2861  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.2843  decode.d3.loss_dice: 0.2733  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.2840  decode.d4.loss_dice: 0.2573  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.2726  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.2797  decode.d6.loss_dice: 0.2770  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.2811  decode.d7.loss_dice: 0.2819  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.2820
09/28 20:24:23 - mmengine - INFO - Iter(train) [ 48200/320000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 1 day, 9:30:01  time: 0.4712  data_time: 0.0096  memory: 5133  grad_norm: 66.0460  loss: 8.2355  decode.loss_cls: 0.1969  decode.loss_mask: 0.3192  decode.loss_dice: 0.2484  decode.d0.loss_cls: 1.0238  decode.d0.loss_mask: 0.2620  decode.d0.loss_dice: 0.2549  decode.d1.loss_cls: 0.2102  decode.d1.loss_mask: 0.3228  decode.d1.loss_dice: 0.2468  decode.d2.loss_cls: 0.2306  decode.d2.loss_mask: 0.2616  decode.d2.loss_dice: 0.2566  decode.d3.loss_cls: 0.1596  decode.d3.loss_mask: 0.3244  decode.d3.loss_dice: 0.2530  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 0.3345  decode.d4.loss_dice: 0.2380  decode.d5.loss_cls: 0.1381  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.2459  decode.d6.loss_cls: 0.1539  decode.d6.loss_mask: 0.3470  decode.d6.loss_dice: 0.2498  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 0.3282  decode.d7.loss_dice: 0.2432  decode.d8.loss_cls: 0.1564  decode.d8.loss_mask: 0.3357  decode.d8.loss_dice: 0.2588
09/28 20:24:45 - mmengine - INFO - Iter(train) [ 48250/320000]  base_lr: 8.6321e-05 lr: 8.6321e-06  eta: 1 day, 9:29:40  time: 0.4346  data_time: 0.0095  memory: 5133  grad_norm: 231.3131  loss: 10.5731  decode.loss_cls: 0.2464  decode.loss_mask: 0.4263  decode.loss_dice: 0.3417  decode.d0.loss_cls: 0.9089  decode.d0.loss_mask: 0.4457  decode.d0.loss_dice: 0.3304  decode.d1.loss_cls: 0.1975  decode.d1.loss_mask: 0.4428  decode.d1.loss_dice: 0.3346  decode.d2.loss_cls: 0.2868  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.3218  decode.d3.loss_cls: 0.2302  decode.d3.loss_mask: 0.4244  decode.d3.loss_dice: 0.3425  decode.d4.loss_cls: 0.2678  decode.d4.loss_mask: 0.4148  decode.d4.loss_dice: 0.3391  decode.d5.loss_cls: 0.2644  decode.d5.loss_mask: 0.4002  decode.d5.loss_dice: 0.3383  decode.d6.loss_cls: 0.3605  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.3114  decode.d7.loss_cls: 0.2545  decode.d7.loss_mask: 0.4209  decode.d7.loss_dice: 0.3389  decode.d8.loss_cls: 0.2673  decode.d8.loss_mask: 0.4015  decode.d8.loss_dice: 0.3372
09/28 20:25:07 - mmengine - INFO - Iter(train) [ 48300/320000]  base_lr: 8.6307e-05 lr: 8.6307e-06  eta: 1 day, 9:29:15  time: 0.4350  data_time: 0.0094  memory: 5147  grad_norm: 24.3685  loss: 5.1078  decode.loss_cls: 0.0172  decode.loss_mask: 0.2075  decode.loss_dice: 0.2157  decode.d0.loss_cls: 0.8039  decode.d0.loss_mask: 0.2052  decode.d0.loss_dice: 0.2141  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.2078  decode.d1.loss_dice: 0.2126  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.2058  decode.d2.loss_dice: 0.2158  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.2035  decode.d3.loss_dice: 0.2117  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.2060  decode.d4.loss_dice: 0.2091  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.2044  decode.d5.loss_dice: 0.2111  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.2049  decode.d6.loss_dice: 0.2193  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.2027  decode.d7.loss_dice: 0.2068  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.2049  decode.d8.loss_dice: 0.2126
09/28 20:25:29 - mmengine - INFO - Iter(train) [ 48350/320000]  base_lr: 8.6293e-05 lr: 8.6293e-06  eta: 1 day, 9:28:50  time: 0.4346  data_time: 0.0096  memory: 5132  grad_norm: 130.8907  loss: 9.4376  decode.loss_cls: 0.2347  decode.loss_mask: 0.3726  decode.loss_dice: 0.2554  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 0.3812  decode.d0.loss_dice: 0.2893  decode.d1.loss_cls: 0.3031  decode.d1.loss_mask: 0.3225  decode.d1.loss_dice: 0.2607  decode.d2.loss_cls: 0.3375  decode.d2.loss_mask: 0.3257  decode.d2.loss_dice: 0.2690  decode.d3.loss_cls: 0.2900  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.2719  decode.d4.loss_cls: 0.2436  decode.d4.loss_mask: 0.3639  decode.d4.loss_dice: 0.2586  decode.d5.loss_cls: 0.2980  decode.d5.loss_mask: 0.3256  decode.d5.loss_dice: 0.2579  decode.d6.loss_cls: 0.2996  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.2635  decode.d7.loss_cls: 0.2286  decode.d7.loss_mask: 0.3677  decode.d7.loss_dice: 0.2549  decode.d8.loss_cls: 0.2118  decode.d8.loss_mask: 0.3685  decode.d8.loss_dice: 0.2586
09/28 20:25:50 - mmengine - INFO - Iter(train) [ 48400/320000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 1 day, 9:28:26  time: 0.4344  data_time: 0.0094  memory: 5117  grad_norm: 105.8936  loss: 8.2160  decode.loss_cls: 0.1722  decode.loss_mask: 0.3233  decode.loss_dice: 0.2650  decode.d0.loss_cls: 0.8759  decode.d0.loss_mask: 0.3393  decode.d0.loss_dice: 0.2630  decode.d1.loss_cls: 0.1612  decode.d1.loss_mask: 0.3308  decode.d1.loss_dice: 0.2574  decode.d2.loss_cls: 0.1686  decode.d2.loss_mask: 0.3267  decode.d2.loss_dice: 0.2585  decode.d3.loss_cls: 0.1630  decode.d3.loss_mask: 0.3246  decode.d3.loss_dice: 0.2514  decode.d4.loss_cls: 0.1517  decode.d4.loss_mask: 0.3238  decode.d4.loss_dice: 0.2537  decode.d5.loss_cls: 0.1495  decode.d5.loss_mask: 0.3200  decode.d5.loss_dice: 0.2627  decode.d6.loss_cls: 0.1555  decode.d6.loss_mask: 0.3259  decode.d6.loss_dice: 0.2587  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.3252  decode.d7.loss_dice: 0.2573  decode.d8.loss_cls: 0.1894  decode.d8.loss_mask: 0.3279  decode.d8.loss_dice: 0.2753
09/28 20:26:14 - mmengine - INFO - Iter(train) [ 48450/320000]  base_lr: 8.6264e-05 lr: 8.6264e-06  eta: 1 day, 9:28:10  time: 0.4731  data_time: 0.0098  memory: 5147  grad_norm: 45.0525  loss: 5.5165  decode.loss_cls: 0.0902  decode.loss_mask: 0.1963  decode.loss_dice: 0.1974  decode.d0.loss_cls: 0.7806  decode.d0.loss_mask: 0.1989  decode.d0.loss_dice: 0.1988  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.1924  decode.d1.loss_dice: 0.2047  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.1943  decode.d2.loss_dice: 0.2097  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.1972  decode.d3.loss_dice: 0.2062  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.1956  decode.d4.loss_dice: 0.2086  decode.d5.loss_cls: 0.0756  decode.d5.loss_mask: 0.1942  decode.d5.loss_dice: 0.2091  decode.d6.loss_cls: 0.0931  decode.d6.loss_mask: 0.1944  decode.d6.loss_dice: 0.1978  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 0.1957  decode.d7.loss_dice: 0.2033  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.1931  decode.d8.loss_dice: 0.2039
09/28 20:26:37 - mmengine - INFO - Iter(train) [ 48500/320000]  base_lr: 8.6250e-05 lr: 8.6250e-06  eta: 1 day, 9:27:56  time: 0.4710  data_time: 0.0096  memory: 5133  grad_norm: 59.6803  loss: 6.1835  decode.loss_cls: 0.1092  decode.loss_mask: 0.2378  decode.loss_dice: 0.1950  decode.d0.loss_cls: 0.9115  decode.d0.loss_mask: 0.2417  decode.d0.loss_dice: 0.1854  decode.d1.loss_cls: 0.1377  decode.d1.loss_mask: 0.2387  decode.d1.loss_dice: 0.1995  decode.d2.loss_cls: 0.1080  decode.d2.loss_mask: 0.2389  decode.d2.loss_dice: 0.2026  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.2390  decode.d3.loss_dice: 0.1983  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.2395  decode.d4.loss_dice: 0.1998  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.2411  decode.d5.loss_dice: 0.2038  decode.d6.loss_cls: 0.0955  decode.d6.loss_mask: 0.2403  decode.d6.loss_dice: 0.1924  decode.d7.loss_cls: 0.1416  decode.d7.loss_mask: 0.2392  decode.d7.loss_dice: 0.1888  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.2393  decode.d8.loss_dice: 0.1976
09/28 20:27:01 - mmengine - INFO - Iter(train) [ 48550/320000]  base_lr: 8.6236e-05 lr: 8.6236e-06  eta: 1 day, 9:27:42  time: 0.4758  data_time: 0.0095  memory: 5133  grad_norm: 30.5171  loss: 5.7039  decode.loss_cls: 0.0586  decode.loss_mask: 0.2477  decode.loss_dice: 0.1925  decode.d0.loss_cls: 0.7743  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.2004  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.2464  decode.d1.loss_dice: 0.2091  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.2460  decode.d2.loss_dice: 0.1892  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.2440  decode.d3.loss_dice: 0.1909  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.2477  decode.d4.loss_dice: 0.2000  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.2495  decode.d5.loss_dice: 0.1881  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.2472  decode.d6.loss_dice: 0.1847  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.2500  decode.d7.loss_dice: 0.1999  decode.d8.loss_cls: 0.0412  decode.d8.loss_mask: 0.2469  decode.d8.loss_dice: 0.1912
09/28 20:27:25 - mmengine - INFO - Iter(train) [ 48600/320000]  base_lr: 8.6221e-05 lr: 8.6221e-06  eta: 1 day, 9:27:28  time: 0.4727  data_time: 0.0098  memory: 5133  grad_norm: 126.8694  loss: 5.3061  decode.loss_cls: 0.1103  decode.loss_mask: 0.2027  decode.loss_dice: 0.1800  decode.d0.loss_cls: 0.8005  decode.d0.loss_mask: 0.2028  decode.d0.loss_dice: 0.1837  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.2009  decode.d1.loss_dice: 0.1775  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.1997  decode.d2.loss_dice: 0.1747  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.2045  decode.d3.loss_dice: 0.1730  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.2045  decode.d4.loss_dice: 0.1736  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.2020  decode.d5.loss_dice: 0.1760  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.2028  decode.d6.loss_dice: 0.1754  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.2047  decode.d7.loss_dice: 0.1754  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.2013  decode.d8.loss_dice: 0.1737
09/28 20:27:48 - mmengine - INFO - Iter(train) [ 48650/320000]  base_lr: 8.6207e-05 lr: 8.6207e-06  eta: 1 day, 9:27:13  time: 0.4718  data_time: 0.0093  memory: 5133  grad_norm: 52.3011  loss: 5.7293  decode.loss_cls: 0.0190  decode.loss_mask: 0.2238  decode.loss_dice: 0.2053  decode.d0.loss_cls: 1.0479  decode.d0.loss_mask: 0.2270  decode.d0.loss_dice: 0.2041  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 0.2229  decode.d1.loss_dice: 0.1986  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.2277  decode.d2.loss_dice: 0.2110  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 0.2291  decode.d3.loss_dice: 0.2008  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.2253  decode.d4.loss_dice: 0.2092  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.2243  decode.d5.loss_dice: 0.2066  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.2246  decode.d6.loss_dice: 0.2038  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.2234  decode.d7.loss_dice: 0.2008  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.2252  decode.d8.loss_dice: 0.2019
09/28 20:28:12 - mmengine - INFO - Iter(train) [ 48700/320000]  base_lr: 8.6193e-05 lr: 8.6193e-06  eta: 1 day, 9:26:59  time: 0.4737  data_time: 0.0099  memory: 5133  grad_norm: 78.1359  loss: 7.6149  decode.loss_cls: 0.1401  decode.loss_mask: 0.3066  decode.loss_dice: 0.2011  decode.d0.loss_cls: 0.9190  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.2066  decode.d1.loss_cls: 0.2590  decode.d1.loss_mask: 0.2791  decode.d1.loss_dice: 0.2036  decode.d2.loss_cls: 0.2273  decode.d2.loss_mask: 0.2813  decode.d2.loss_dice: 0.2009  decode.d3.loss_cls: 0.2267  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.2050  decode.d4.loss_cls: 0.2578  decode.d4.loss_mask: 0.2771  decode.d4.loss_dice: 0.2007  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 0.2972  decode.d5.loss_dice: 0.2365  decode.d6.loss_cls: 0.1539  decode.d6.loss_mask: 0.2932  decode.d6.loss_dice: 0.2036  decode.d7.loss_cls: 0.1179  decode.d7.loss_mask: 0.3077  decode.d7.loss_dice: 0.2043  decode.d8.loss_cls: 0.1822  decode.d8.loss_mask: 0.2807  decode.d8.loss_dice: 0.1981
09/28 20:28:35 - mmengine - INFO - Iter(train) [ 48750/320000]  base_lr: 8.6179e-05 lr: 8.6179e-06  eta: 1 day, 9:26:45  time: 0.4700  data_time: 0.0095  memory: 5147  grad_norm: 79.1209  loss: 7.1925  decode.loss_cls: 0.2162  decode.loss_mask: 0.1978  decode.loss_dice: 0.2924  decode.d0.loss_cls: 0.9346  decode.d0.loss_mask: 0.1977  decode.d0.loss_dice: 0.2849  decode.d1.loss_cls: 0.2246  decode.d1.loss_mask: 0.1949  decode.d1.loss_dice: 0.2622  decode.d2.loss_cls: 0.1884  decode.d2.loss_mask: 0.1947  decode.d2.loss_dice: 0.2455  decode.d3.loss_cls: 0.1942  decode.d3.loss_mask: 0.1908  decode.d3.loss_dice: 0.2355  decode.d4.loss_cls: 0.1876  decode.d4.loss_mask: 0.1958  decode.d4.loss_dice: 0.2546  decode.d5.loss_cls: 0.1929  decode.d5.loss_mask: 0.1943  decode.d5.loss_dice: 0.2834  decode.d6.loss_cls: 0.1521  decode.d6.loss_mask: 0.1969  decode.d6.loss_dice: 0.2507  decode.d7.loss_cls: 0.1566  decode.d7.loss_mask: 0.1931  decode.d7.loss_dice: 0.2366  decode.d8.loss_cls: 0.1938  decode.d8.loss_mask: 0.1952  decode.d8.loss_dice: 0.2544
09/28 20:28:59 - mmengine - INFO - Iter(train) [ 48800/320000]  base_lr: 8.6164e-05 lr: 8.6164e-06  eta: 1 day, 9:26:31  time: 0.4733  data_time: 0.0096  memory: 5147  grad_norm: 40.0232  loss: 5.5889  decode.loss_cls: 0.0164  decode.loss_mask: 0.2349  decode.loss_dice: 0.2168  decode.d0.loss_cls: 0.8790  decode.d0.loss_mask: 0.2509  decode.d0.loss_dice: 0.2383  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 0.2489  decode.d1.loss_dice: 0.2266  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.2351  decode.d2.loss_dice: 0.2109  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2343  decode.d3.loss_dice: 0.2166  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.2347  decode.d4.loss_dice: 0.2113  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.2338  decode.d5.loss_dice: 0.2164  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.2335  decode.d6.loss_dice: 0.2157  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.2348  decode.d7.loss_dice: 0.2146  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.2328  decode.d8.loss_dice: 0.2158
09/28 20:29:23 - mmengine - INFO - Iter(train) [ 48850/320000]  base_lr: 8.6150e-05 lr: 8.6150e-06  eta: 1 day, 9:26:16  time: 0.4716  data_time: 0.0095  memory: 5132  grad_norm: 53.4035  loss: 5.5851  decode.loss_cls: 0.0852  decode.loss_mask: 0.1977  decode.loss_dice: 0.2162  decode.d0.loss_cls: 0.8738  decode.d0.loss_mask: 0.1963  decode.d0.loss_dice: 0.2194  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.2005  decode.d1.loss_dice: 0.2249  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.2012  decode.d2.loss_dice: 0.2082  decode.d3.loss_cls: 0.0310  decode.d3.loss_mask: 0.1989  decode.d3.loss_dice: 0.2233  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.1986  decode.d4.loss_dice: 0.2190  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.2002  decode.d5.loss_dice: 0.2222  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.1983  decode.d6.loss_dice: 0.2085  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.1992  decode.d7.loss_dice: 0.2158  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.1997  decode.d8.loss_dice: 0.2067
